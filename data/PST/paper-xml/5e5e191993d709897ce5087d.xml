<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-09-12">12 Sep 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
							<email>xiaoxuez@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
							<email>srinivasksun@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
							<email>raghavgupta@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Pranav</forename><surname>Khaitan</surname></persName>
							<email>pranavkhaitan@google.com</email>
						</author>
						<title level="a" type="main">Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-12">12 Sep 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1909.05855v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Virtual assistants such as Google Assistant, Alexa and Siri provide a conversational interface to a large number of services and APIs spanning multiple domains. Such systems need to support an ever-increasing number of services with possibly overlapping functionality. Furthermore, some of these services have little to no training data available. Existing public datasets for task-oriented dialogue do not sufficiently capture these challenges since they cover few domains and assume a single static ontology per domain. In this work, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing over 16k multi-domain conversations spanning 16 domains. Our dataset exceeds the existing task-oriented dialogue corpora in scale, while also highlighting the challenges associated with building large-scale virtual assistants. It provides a challenging testbed for a number of tasks including language understanding, slot filling, dialogue state tracking and response generation. Along the same lines, we present a schema-guided paradigm for task-oriented dialogue, in which predictions are made over a dynamic set of intents and slots, provided as input, using their natural language descriptions. This allows a single dialogue system to easily support a large number of services and facilitates simple integration of new services without requiring additional training data. Building upon the proposed paradigm, we release a zero-shot dialogue state tracking model that achieves state-of-the-art performance on recent benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Virtual assistants help users accomplish tasks including but not limited to finding flights, booking restaurants and, more recently, navigating user interfaces, by providing a natural language interface to services and APIs on the web. The recent popularity of conversational interfaces and the advent of frameworks like Actions on Google and Alexa Skills, which allow developers to easily add support for new services, has resulted in a major increase in the number of application domains and individual services that assistants need to support, following the pattern of smartphone applications.</p><p>Consequently, recent work has focused on scalable dialogue systems that can handle tasks across multiple application domains. Data-driven deep learning based approaches for multi-domain modeling have shown promise, both for end-to-end and modular systems involving dialogue state tracking and policy learning. This line of work has been facilitated by the release of multi-domain dialogue corpora such as MultiWOZ <ref type="bibr" target="#b1">(Budzianowski et al. 2018)</ref>, M2M <ref type="bibr" target="#b15">(Shah et al. 2018</ref>) and FRAMES <ref type="bibr" target="#b4">(El Asri et al. 2017)</ref>.</p><p>However, existing datasets for multi-domain task-oriented dialogue do not sufficiently capture a number of challenges that arise with scaling virtual assistants in production. These assistants need to support a large <ref type="bibr" target="#b11">(Kim et al. 2018)</ref>, constantly increasing number of services over a large number of domains. In comparison, existing public datasets cover few domains. Furthermore, they define a single static API per domain, whereas multiple services with overlapping functionality, but heterogeneous interfaces, exist in the real world.</p><p>To highlight these challenges, we introduce the Schema-Guided Dialogue (SGD) dataset 1 , which is, to the best of our knowledge, the largest public task-oriented dialogue corpus. It exceeds existing corpora in scale, with over 16000 dialogues in the training set spanning 26 services belonging to 16 domains (more details in Table <ref type="table" target="#tab_0">1</ref>). Further, to adequately test the models' ability to generalize in zero-shot settings, the evaluation sets contain unseen services and domains. The dataset is designed to serve as an effective testbed for intent prediction, slot filling, state tracking and language generation, among other tasks in large-scale virtual assistants.</p><p>We also propose the schema-guided paradigm for taskoriented dialogue, advocating building a single unified dialogue model for all services and APIs. Using a service's schema as input, the model would make predictions over this dynamic set of intents and slots present in the schema. This setting enables effective sharing of knowledge among all services, by relating the semantic information in the schemas, and allows the model to handle unseen services and APIs. Under the proposed paradigm, we present a novel architecture for multi-domain dialogue state tracking. By using large pretrained models like BERT <ref type="bibr" target="#b3">(Devlin et al. 2019)</ref>, our model can generalize to unseen services and is robust to API changes, while achieving state-of-the-art results on the original and updated <ref type="bibr" target="#b5">(Eric et al. 2019)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Task-oriented dialogue systems have constituted an active area of research for decades. The growth of this field has been consistently fueled by the development of new datasets. Initial datasets were limited to one domain, such as ATIS <ref type="bibr" target="#b7">(Hemphill, Godfrey, and Doddington 1990)</ref> for spoken language understanding for flights. The Dialogue State Tracking Challenges <ref type="bibr" target="#b18">(Williams et al. 2013;</ref><ref type="bibr">Henderson, Thomson, and Williams 2014a;</ref><ref type="bibr" target="#b8">Henderson, Thomson, and Williams 2014b;</ref><ref type="bibr" target="#b10">Kim et al. 2017</ref>) contributed to the creation of dialogue datasets with increasing complexity. Other notable related datasets include WOZ2.0 <ref type="bibr" target="#b17">(Wen et al. 2017</ref><ref type="bibr">), FRAMES (El Asri et al. 2017)</ref>, M2M <ref type="bibr" target="#b15">(Shah et al. 2018</ref>) and Multi-WOZ <ref type="bibr" target="#b1">(Budzianowski et al. 2018</ref>). These datasets have utilized a variety of data collection techniques, falling within two broad categories:</p><p>• Wizard-of-Oz This setup (Kelley 1984) connects two crowd workers playing the roles of the user and the system. The user is provided a goal to satisfy, and the system accesses a database of entities, which it queries as per the user's preferences. WOZ2.0, FRAMES and MultiWOZ, among others, have utilized such methods.</p><p>• Machine-machine Interaction A related line of work explores simulation-based dialogue generation, where the user and system roles are simulated to generate a complete conversation flow, which can then be converted to natural language using crowd workers <ref type="bibr" target="#b15">(Shah et al. 2018)</ref>. Such a framework may be cost-effective and error-resistant since the underlying crowd worker task is simpler, and semantic annotations are obtained automatically.</p><p>As virtual assistants incorporate diverse domains, recent work has focused on zero-shot modeling <ref type="bibr" target="#b0">(Bapna et al. 2017;</ref><ref type="bibr" target="#b20">Xia et al. 2018;</ref><ref type="bibr" target="#b16">Shah et al. 2019)</ref>, domain adaptation and transfer learning techniques <ref type="bibr" target="#b14">(Rastogi, Hakkani-Tür, and Heck 2017)</ref>. Deep-learning based approaches have achieved state of the art performance on dialogue state tracking tasks. Popular approaches on small-scale datasets estimate the dialogue state as a distribution over all possible slot-values <ref type="bibr" target="#b9">(Henderson, Thomson, and Young 2014;</ref><ref type="bibr" target="#b17">Wen et al. 2017)</ref> or individually score all slot-value combinations <ref type="bibr" target="#b12">(Mrkšić et al. 2017;</ref><ref type="bibr" target="#b21">Zhong, Xiong, and Socher 2018)</ref>. Such approaches are not practical for deployment in virtual assistants operating over real-world services having a very large and dy-namic set of possible values. Addressing these concerns, approaches utilizing a dynamic vocabulary of slot values have been proposed <ref type="bibr" target="#b13">(Rastogi, Gupta, and Hakkani-Tur 2018;</ref><ref type="bibr" target="#b6">Goel, Paul, and Hakkani-Tür 2019;</ref><ref type="bibr" target="#b19">Wu et al. 2019</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Schema-Guided Dialogue Dataset</head><p>An important goal of this work is to create a benchmark dataset highlighting the challenges associated with building large-scale virtual assistants. Table <ref type="table" target="#tab_0">1</ref> compares our dataset with other public datasets. Our Schema-Guided Dialogue (SGD) dataset exceeds other datasets in most of the metrics at scale. The especially larger number of domains, slots, and slot values, and the presence of multiple services per domain, are representative of these scale-related challenges. Furthermore, our evaluation sets contain many services, and consequently slots, which are not present in the training set, to help evaluate model performance on unseen services.</p><p>The 17 domains ('Alarm' domain not included in training) present in our dataset are listed in Table <ref type="table">2</ref>. We create synthetic implementations of a total of 34 services or APIs over these domains. Our simulator framework interacts with these services to generate dialogue outlines, which are a structured representation of dialogue semantics. We then used a crowdsourcing procedure to paraphrase these outlines to natural language utterances. Our novel crowd-sourcing procedure preserves all annotations obtained from the simulator and does not require any extra annotations after dialogue collection. In this section, we describe these steps in detail and then present analyses of the collected dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Services and APIs</head><p>We define the schema for a service as a combination of intents and slots with additional constraints, with an example in Figure <ref type="figure" target="#fig_0">1</ref>. We implement all services using a SQL engine. For constructing the underlying tables, we sample a set of entities from Freebase and obtain the values for slots defined in the schema from the appropriate attribute in Freebase. We decided to use Freebase to sample real-world entities instead of synthetic ones since entity attributes are often correlated (e.g, a restaurant's name is indicative of the cuisine served). Some slots like event dates/times and available ticket counts, which are not present in Freebase, are synthetically sampled.</p><p>To reflect the constraints present in real-world services and APIs, we impose a few other restrictions. First, our Table <ref type="table">2</ref>: The number of intents (services in parentheses) and dialogues for each domain in the train and dev sets. Multidomain dialogues contribute to counts of each domain. The domain Service includes salons, dentists, doctors etc.</p><p>dataset does not expose the set of all possible slot values for some slots. Having such a list is impractical for slots like date or time because they have infinitely many possible values or for slots like movie or song names, for which new values are periodically added. Our dataset specifically identifies such slots as non-categorical and does not provide a set of all possible values for these. We also ensure that the evaluation sets have a considerable fraction of slot values not present in the training set to evaluate the models in the presence of new values. Some slots like gender, number of people, day of the week etc. are defined as categorical and we specify the set of all possible values taken by them. However, these values are not assumed to be consistent across services. E.g., different services may use ('male', 'female'), ('M', 'F') or ('he', 'she') as possible values for gender slot. Second, real-world services can only be invoked with a limited number of slot combinations: e.g. restaurant reservation APIs do not let the user search for restaurants by date without specifying a location. However, existing datasets simplistically allow service calls with any given combination of slot values, thus giving rise to flows unsupported by actual services or APIs. As in Figure <ref type="figure" target="#fig_0">1</ref>, the different service calls supported by a service are listed as intents. Each intent specifies a set of required slots and the system is not allowed to call this intent without specifying values for these required slots. Each intent also lists a set of optional slots with default values, which the user can override.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dialogue Simulator Framework</head><p>The dialogue simulator interacts with the services to generate dialogue outlines. Figure <ref type="figure" target="#fig_1">2</ref> shows the overall architecture of our dialogue simulator framework. It consists of two agents playing the roles of the user and the system. Both agents interact with each other using a finite set of actions specified through dialogue acts over a probabilistic automaton designed to capture varied dialogue trajectories. These dialogue acts can take a slot or a slot-value pair as argument.</p><p>Figure <ref type="figure" target="#fig_4">4b</ref> shows all dialogue acts supported by the agents.</p><p>At the start of a conversation, the user agent is seeded with a scenario, which is a sequence of intents to be fulfilled. We identified over 200 distinct scenarios for the train- ing set, each comprising up to 5 intents. For multi-domain dialogues, we also identify combinations of slots whose values may be transferred when switching intents e.g. the 'address' slot value in a restaurant service could be transferred to the 'destination' slot for a taxi service invoked right after.</p><p>The user agent then generates the dialogue acts to be output in the next turn. It may retrieve arguments i.e. slot values for some of the generated acts by accessing either the service schema or the raw SQL backend. The acts, combined with the respective parameters yield the corresponding user actions. Next, the system agent generates the next set of actions using a similar procedure. Unlike the user agent, however, the system agent has restricted access to the services (denoted by dashed line), e.g. it can only query the services by supplying values for all required slots for some service call. This helps us ensure that all generated flows are valid.</p><p>After an intent is fulfilled through a series of user and system actions, the user agent queries the scenario to proceed to the next intent. Alternatively, the system may suggest related intents e.g. reserving a table after searching for a restaurant. The simulator also allows for multiple intents to be active during a given turn. While we skip many implementation details for brevity, it is worth noting that we do not include any domain-specific constraints in the simulation automaton. All domain-specific constraints are encoded in the schema and scenario, allowing us to conveniently use the simulator across a wide variety of domains and services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dialogue Paraphrasing</head><p>The dialogue paraphrasing framework converts the outlines generated by the simulator into a natural conversation. Figure <ref type="figure" target="#fig_2">3a</ref> shows a snippet of the dialogue outline generated by the simulator, containing a sequence of user and system actions. The slot values present in these actions are in a canonical form because they obtained directly from the service. However, users may refer to these values in various different ways during the conversation, e.g., "los angeles" may be referred to as "LA" or "LAX". To introduce these natural variations in the slot values, we replace different slot values with a randomly selected variation (kept consistent across user turns in a dialogue) as shown in Figure <ref type="figure" target="#fig_2">3b</ref>.</p><p>Next we define a set of action templates for converting each action into a utterance. A few examples of such templates are shown below. These templates are used to convert each action into a natural language utterance, and the resulting utterances for the different actions in a turn are concatenated together as shown in Figure <ref type="figure" target="#fig_2">3c</ref>. The dialogue transformed by these steps is then sent to the crowd workers. One crowd worker is tasked with paraphrasing all utterances of a dialogue to ensure naturalness and coherence.</p><p>REQUEST(location) → Which city are you in?</p><formula xml:id="formula_0">INFORM(location=$x) → I want to eat in $x. OFFER(restaurant=$x) → $x is a nice restaurant.</formula><p>In our paraphrasing task, the crowd workers are instructed to exactly repeat the slot values in their paraphrases. This not only helps us verify the correctness of the paraphrases, but also lets us automatically obtain slot spans in the generated utterances by string search. This automatic slot span generation greatly reduced the annotation effort required, with little impact on dialogue naturalness, thus allowing us to collect more data with the same resources. Furthermore, it is important to note that this entire procedure preserves all other annotations obtained from the simulator including the dialogue state. Hence, no further annotation is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Dataset Analysis</head><p>With over 16000 dialogues in the training set, the Schema-Guided Dialogue dataset is the largest publicly available annotated task-oriented dialogue dataset. The annotations include the active intents and dialogue states for each user utterance and the system actions for every system utterance. We have a few other annotations like the user actions but we withhold them from the public release. These annotations enable our dataset to be used as benchmark for tasks like intent detection, dialogue state tracking, imitation learning of dialogue policy, dialogue act to text generation etc. The schemas contain semantic information about the schema and the constituent intents and slots, in the form of natural language descriptions and other details (example in Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>The single-domain dialogues in our dataset contain an average of 15.3 turns, whereas the multi-domain ones contain 23 turns on an average. These numbers are also reflected in Figure <ref type="figure" target="#fig_4">4a</ref> showing the histogram of dialogue lengths on the training set. Table <ref type="table">2</ref> shows the distribution of dialogues across the different domains. We note that the dataset is largely balanced in terms of the domains and services covered, with the exception of Alarm domain, which is only present in the development set. Figure <ref type="figure" target="#fig_4">4b</ref> shows the frequency of dialogue acts contained in the dataset. Note that all dialogue acts except INFORM, REQUEST and GOODBYE are specific to either the user or the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Schema-Guided Approach</head><p>Virtual assistants aim to support a large number of services available on the web. One possible approach is to define a large unified schema for the assistant, to which different service providers can integrate with. However, it is difficult to come up with a common schema covering all use cases. Having a common schema also complicates integration of tail services with limited developer support. We propose the schema-guided approach as an alternative to allow easy integration of new services and APIs.</p><p>Under our proposed approach, each service provides a schema listing the supported slots and intents along with their natural language descriptions (Figure <ref type="figure" target="#fig_0">1</ref> shows an example). These descriptions are used to obtain a semantic representation of these schema elements. The assistant employs a single unified model containing no domain or service specific parameters to make predictions conditioned on these schema elements. For example, Figure <ref type="figure">5</ref> shows how dialogue state representation for the same dialogue can vary for two different services. Here, the departure and arrival cities are captured by analogously functioning but differently named slots in both schemas. Furthermore, values for the number stops and direct only slots highlight idiosyncrasies between services interpreting the same concept.</p><p>There are many advantages to this approach. First, using a single model facilitates representation and transfer of common knowledge across related services. Second, since the model utilizes semantic representation of schema elements  as input, it can interface with unseen services or APIs on which it has not been trained. Third, it is robust to changes like addition of new intents or slots to the service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Zero-Shot Dialogue State Tracking</head><p>Models in the schema-guided setting can condition on the pertinent services' schemas using descriptions of intents and slots. These models, however, also need access to representations for potentially unseen inputs from new services. Recent pretrained models like ELMo <ref type="bibr" target="#b13">(Peters et al. 2018)</ref> and BERT <ref type="bibr" target="#b3">(Devlin et al. 2019</ref>) can help, since they are trained on very large corpora. Building upon these, we present our zero-shot schema-guided dialogue state tracking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model</head><p>We use a single model 2 , shared among all services and domains, to make these predictions. We first encode all the intents, slots and slot values for categorical slots present in the schema into an embedded representation. Since different schemas can have differing numbers of intents or slots, predictions are made over dynamic sets of schema elements by conditioning them on the corresponding schema embeddings. This is in contrast to existing models which make predictions over a static schema and are hence unable to share knowledge across domains and services. They are also not robust to changes in schema and require the model to be retrained with new annotated data upon addition of a new intent, slot, or in some cases, a slot value to a service.</p><p>2 Our model code is available at github.com/googleresearch/google-research/tree/master/schema guided dst Schema Embedding This component obtains the embedded representations of intents, slots and categorical slot values in each service schema. Table <ref type="table">3</ref> shows the sequence pairs used for embedding each schema element. These sequence pairs are fed to a pretrained BERT encoder shown in Figure <ref type="figure">6</ref> and the output u CLS is used as the schema embedding.</p><p>For a given service with I intents and S slots, let {i j }, 1 ≤ j ≤ I and {s j }, 1 ≤ j ≤ S be the embeddings of all intents and slots respectively. As a special case, we let {s n j }, 1 ≤ j ≤ N ≤ S denote the embeddings for the N noncategorical slots in the service. Also, let {v k j }, 1 ≤ j ≤ V k denote the embeddings for all possible values taken by the k th categorical slot, 1 ≤ k ≤ C, with C being the number of categorical slots and N + C = S. All these embeddings are collectively called schema embeddings. Utterance Encoding Like (Chao and Lane 2019), we use BERT to encode the user utterance and the preceding system utterance to obtain utterance pair embedding u = u CLS and token level representations t 1 , t 2 • • • t M , M being the total number of tokens in the two utterances. The utterance and schema embeddings are used together to obtain model predictions using a set of projections (defined below).</p><p>Projection Let x, y ∈ R d . For a task K, we define l = F K (x, y, p) as a projection transforming x and y into the vector l ∈ R p using Equations 1-3. Here, h 1 , h 2 ∈ R d , W K i and b K i for 1 ≤ i ≤ 3 are trainable parameters of suitable dimensions and A is the activation function. We use gelu (Hendrycks and Gimpel 2016) activation as in BERT.</p><formula xml:id="formula_1">h 1 = A(W K 1 x + b K 1 )<label>(1)</label></formula><formula xml:id="formula_2">h 2 = A(W K 2 (y ⊕ h 1 ) + b K 2 ) (2) l = W K 3 h 2 + b K 3 (3)</formula><p>Active Intent For a given service, the active intent denotes the intent requested by the user and currently being fulfilled by the system. It takes the value "NONE" if no intent for the service is currently being processed. Let i 0 be a trainable parameter in R d for the "NONE" intent. We define the intent network as below.</p><formula xml:id="formula_3">l j int = F int (u, i j , 1), 0 ≤ j ≤ I<label>(4)</label></formula><p>The logits l j int are normalized using softmax to yield a distribution over all I intents and the "NONE" intent. During inference, we predict the highest probability intent as active.</p><p>Requested Slots These are the slots whose values are requested by the user in the current utterance. Projection F req predicts logit l j req for the j th slot. Obtained logits are normalized using sigmoid to get a score in [0, 1]. During inference, Figure <ref type="figure">5</ref>: The predicted dialogue state (shown with dashed edges) for the first two user turns for an example dialogue, showing the active intent and slot assignments, with two related annotation schemas. Note that the dialogue state representation is conditioned on the schema under consideration, which is provided as input, as are the user and system utterances.</p><p>Figure <ref type="figure">6</ref>: BERT encoder, taking in two sequences p and q as input and outputs an embedded sequence pair representation u CLS and token level representations {t 1 • • • t n+m }. We use BERT to obtain schema element embeddings and encode system and user utterances for dialogue state tracking. all slots with score &gt; 0.5 are predicted as requested.</p><p>l j req = F req (u, s j , 1), 1 ≤ j ≤ S (5)</p><p>User Goal We define the user goal as the user constraints specified over the dialogue context till the current user utterance. Instead of predicting the entire user goal after each user utterance, we predict the difference between the user goal for the current turn and preceding user turn. During inference, the predicted user goal updates are accumulated to yield the predicted user goal. We predict the user goal updates in two stages. First, for each slot, a distribution of size 3 denoting the slot status and taking values none, dontcare and active is obtained by normalizing the logits obtained in equation 6 using softmax. If the status of a slot is predicted to be none, its assigned value is assumed to be unchanged. If the prediction is dontcare, then the special dontcare value is assigned to it. Otherwise, a slot value is predicted and assigned to it in the second stage.</p><p>l j status = F status (u, s j , 3), 1 ≤ j ≤ S (6)</p><formula xml:id="formula_4">l j,k value = F value (u, v k j , 1), 1 ≤ j ≤ V k , 1 ≤ k ≤ C (7) l j,k start = F start (t k , s n j , 1), 1 ≤ j ≤ N, 1 ≤ k ≤ M (8) l j,k end = F end (t k , s n j , 1), 1 ≤ j ≤ N, 1 ≤ k ≤ M<label>(9)</label></formula><p>In the second stage, equation 7 is used to obtain a logit for each value taken by each categorical slot. Logits for a given categorical slot are normalized using softmax to get a distribution over all possible values. The value with the maximum mass is assigned to the slot. For each non-categorical slot, logits obtained using equations 8 and 9 are normalized using softmax to yield two distributions over all tokens. These two distributions respectively correspond to the start and end index of the span corresponding to the slot. The indices p ≤ q maximizing start[p] + end[q] are predicted to be the span boundary and the corresponding value is assigned to the slot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>We consider the following metrics for evaluation of the dialogue state tracking task:</p><p>1. Active Intent Accuracy: The fraction of user turns for which the active intent has been correctly predicted. 2. Requested Slot F1: The macro-averaged F1 score for requested slots over all eligible turns. Turns with no requested slots in ground truth and predictions are skipped. 3. Average Goal Accuracy: For each turn, we predict a single value for each slot present in the dialogue state. The slots which have a non-empty assignment in the ground truth dialogue state are considered for accuracy. This is the average accuracy of predicting the value of a slot correctly. A fuzzy matching score is used for non-categorical slots to reward partial matches with the ground truth. 4. Joint Goal Accuracy: This is the average accuracy of predicting all slot assignments for a turn correctly. For non-categorical slots a fuzzy matching score is used.</p><p>Performance on other datasets We evaluate our model on public datasets WOZ2.0, MultiWOZ 2.0 and the updated MultiWOZ 2.1 <ref type="bibr" target="#b5">(Eric et al. 2019)</ref>. As results in Table <ref type="table" target="#tab_3">4</ref> show, our model performs competitively on all these datasets. Furthermore, we obtain state-of-the-art joint goal accuracies of 0.516 on MultiWOZ 2.0 and 0.489 on MultiWOZ 2.1 test sets respectively, exceeding the best-known results of 0.486 and 0.456 on these datasets as reported in <ref type="bibr" target="#b5">(Eric et al. 2019)</ref>.</p><p>Performance on SGD The model performs well for Active Intent Accuracy and Requested Slots F1 across both seen and unseen services, shown in Table <ref type="table" target="#tab_3">4</ref>. For joint goal and average goal accuracy, the model performs better on seen services compared to unseen ones (Figure <ref type="figure" target="#fig_6">7</ref>). The main reason for this performance difference is a significantly higher OOV rate for slot values of unseen services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance on different domains (SGD)</head><p>The model performance also varies across various domains. The performance for the different domains is shown in (Table <ref type="table" target="#tab_5">5</ref>) below.</p><p>We observe that one of the factors affecting the performance across domains is still the presence of the service in the training data (seen services). Among the seen services, those in the 'Events' domain have a very low OOV rate for slot values and the largest number of training examples which might be contributing to the high joint goal accuracy. For unseen services, we notice that the 'Services' domain has a lower joint goal accuracy because of higher OOV rate and higher average turns per dialogue. For 'Services' and 'Flights' domains, the difference between joint goal accuracy and average accuracy indicates a possible skew in performance across slots where the performance on a few of the slots is much worse compared to all the other slots, thus considerably degrading the joint goal accuracy. The 'RideSharing' domain also exhibits poor performance, since it possesses the largest number of the possible slot values across the dataset. We also notice that for categorical slots, with similar slot values (e.g. "Psychologist" and "Psychiatrist"), there is a very weak signal for the model to distinguish between the different classes, resulting in inferior performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>It is often argued that simulation-based data collection does not yield natural dialogues or sufficient coverage, when compared to other approaches such as Wizard-of-Oz. We argue that simulation-based collection is a better alternative for collecting datasets like this owing to the factors below.</p><p>• Fewer Annotation Errors: All annotations are automatically generated, so these errors are rare. In contrast, <ref type="bibr" target="#b5">(Eric et al. 2019</ref>) reported annotation errors in 40% of turns in MultiWOZ 2.0 which utilized a Wizard-of-Oz setup. • Simpler Task: The crowd worker task of paraphrasing a readable utterance for each turn is simple. The error-prone annotation task requiring skilled workers is not needed.   For other domains, the service in the dev set was also seen in the training set. We see that the model generally performs better for domains containing services seen during training.</p><p>• Low Cost: The simplicity of the crowd worker task and lack of an annotation task greatly cut data collection costs. • Better Coverage: A wide variety of dialogue flows can be collected and specific usecases can be targeted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We presented the Schema-Guided Dialogue dataset to encourage scalable modeling approaches for virtual assistants.</p><p>We also introduced the schema-guided paradigm for taskoriented dialogue that simplifies the integration of new services and APIs with large scale virtual assistants. Building upon this paradigm, we present a scalable zero-shot dialogue state tracking model achieving state-of-the-art results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example schema for a digital wallet service.</figDesc><graphic url="image-1.png" coords="3,348.03,54.00,181.44,201.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall architecture of the dialogue simulation framework for generating dialogue outlines.</figDesc><graphic url="image-2.png" coords="4,54.81,54.00,236.88,87.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Steps for obtaining paraphrased conversations. To increase the presence of relative dates like tomorrow, next Monday, the current date is assumed to be March 1, 2019.</figDesc><graphic url="image-3.png" coords="4,332.91,54.00,211.67,162.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Histogram of lengths of training set dialogues. (b) Distribution of dialogue acts in training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Detailed statistics of the SGD dataset.</figDesc><graphic url="image-5.png" coords="5,54.00,182.22,238.50,117.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Input sequences for the pretrained BERT model to obtain embeddings of different schema elements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Performance of the model on all services, services seen in training data, services not seen in training data.</figDesc><graphic url="image-8.png" coords="7,320.31,54.00,236.89,117.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-6.png" coords="6,74.16,54.00,463.65,119.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-9.png" coords="11,61.56,453.82,488.88,183.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>MultiWOZ datasets. Comparison of our SGD dataset to existing related datasets for task-oriented dialogue. Note that the numbers reported are for the training portions for all datasets except FRAMES, where the numbers for the complete dataset are reported.</figDesc><table><row><cell>Metric ↓ Dataset →</cell><cell cols="5">DSTC2 WOZ2.0 FRAMES M2M MultiWOZ</cell><cell>SGD</cell></row><row><cell>No. of domains</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>2</cell><cell>7</cell><cell>16</cell></row><row><cell>No. of dialogues</cell><cell>1,612</cell><cell>600</cell><cell>1,369</cell><cell>1,500</cell><cell>8,438</cell><cell>16,142</cell></row><row><cell>Total no. of turns</cell><cell>23,354</cell><cell>4,472</cell><cell>19,986</cell><cell>14,796</cell><cell>113,556</cell><cell>329,964</cell></row><row><cell>Avg. turns per dialogue</cell><cell>14.49</cell><cell>7.45</cell><cell>14.60</cell><cell>9.86</cell><cell>13.46</cell><cell>20.44</cell></row><row><cell>Avg. tokens per turn</cell><cell>8.54</cell><cell>11.24</cell><cell>12.60</cell><cell>8.24</cell><cell>13.13</cell><cell>9.75</cell></row><row><cell>Total unique tokens</cell><cell>986</cell><cell>2,142</cell><cell>12,043</cell><cell>1,008</cell><cell>23,689</cell><cell>30,352</cell></row><row><cell>No. of slots</cell><cell>8</cell><cell>4</cell><cell>61</cell><cell>13</cell><cell>24</cell><cell>214</cell></row><row><cell>No. of slot values</cell><cell>212</cell><cell>99</cell><cell>3,871</cell><cell>138</cell><cell>4,510</cell><cell>14,139</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Model performance on test sets of the respective datasets (except SGD variants, where dev sets were used). SGD-Single model is trained and evaluated on singledomain dialogues only whereas SGD-All model is trained and evaluated on the entire dataset. We also report results on MultiWOZ 2.0, the updated MultiWOZ 2.1, and WOZ2.0. N.A. indicates tasks not available for those datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Model performance per domain (GA: goal accuracy). Domains marked with '*' are those for which the service in the dev set is not present in the training set. Hotels domain marked with '**' has one unseen and one seen service.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements The authors thank Guan-Lin Chao for help with model design and implementation, and Amir Fayazi and Maria Wang for help with data collection.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix User</head><p>I have some free time this weekend and I am looking for some interesting events to go to. Can you find me any interesting events I could attend? System Is there a particular city you would like me to search for events in. Do you have a preference on the category of events. User I am interested in events around New York. I enjoy going to sports games. System I found 10 events that you would enjoy. The Mets vs Braves are playing at Citi Field on March 13th at 6 pm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Please share some more information with me. Where is the venue located? System This is a baseball game. The address is 123-01 Roosevelt Avenue User This is perfect! Can you find some other events for me? I will be in Toronto, Ontario. Please look for events happening near Toronto on Friday next week. System There is a Blue Jays vs Braves game. They are playing at the Rogers Centre next Friday at 8 pm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>This is perfect! Please reserve 2 tickets to the Blue Jays vs. Indians game for me System Please confirm the following details: You are reserving 2 tickets for the Blue Jays vs Indians event. This reservation is for next Friday in Toronto.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Incorrect. I would like to reserve four tickets. System Please confirm the following details: You are reserving 4 tickets for the Blue Jays vs. Indians event in Toronto.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Yes, this is the correct information. May you provide me the address of the venue? System Your reservation is confirmed Enjoy the game! The address is 1 Blue Jays Way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Thank you so much for your help! That is all I need. System Have a great day.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>My buddy is getting married and I need to find a bus ticket. System I can help you with that. Can you give me a little more information like where you are traveling from, where you are traveling to, and when you would like to leave. User I need to go from Las Vegas to Sacramento on the 7th of this month. System Great, I was able to find 4 buss's matching that criteria. How does a bus with 1 transfer, leaving at 7:20 am, for $88 sound? User That sounds like just what i'm looking for. I will also be needing a rental car until the 11th of this month. System Will this car be from Sacramento from March 7th. User I would like to pick up the car on the 8th around two in the afternoon. System The first of 5 cars I have found for you is a standard Accord, located at SMF International Airport, available for pickup on March 8th.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>That one sounds perfect. System Would you like me to proceed with making that reservation for you? User</p><p>Yes, let's go ahead with that car. System Before I reserve this I would like to make sure all the details I have are correct. You would like to pickup a standard vehicle from SMF International Airport on March 8th at 2 pm, and will be returning the car on March 11th.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Yes, that is all correct but can you give me an estimated price too please? System I was successfully able to reserve that with a total cost of $105 for you.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Great, could you also help me find an online movie to watch? System What genre of movie are you looking for? User I am really into detective movies right now. System The 2 movies I found that you may like are Body Double and Citizen Kane. User I would really like to see Body Double now if possible, I heard it's pretty good. System Okay, so you would like me to begin playing the movie Body Double without subtitles now. Is that correct? User Yes, that would be great. System I've went ahead and started playing that movie for you.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head><p>Thanks so much! System Is there anything else I can help you with for now? User</p><p>No, that's all for now. System Have a good day and enjoy your movie!  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards zero-shot frame semantic parsing for domain scaling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-20">2017. 2017. August 20-24, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiwoza large-scale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5016" to="5026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Bert-dst: Scalable end-to-end dialogue state tracking with bidirectional encoder representations from transformer</title>
		<author>
			<persName><forename type="first">G.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03040</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Frames: a corpus for adding memory to goal-oriented dialogue systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>El Asri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
				<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="207" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multiwoz 2.1: Multi-domain dialogue state corrections and state tracking baselines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01669</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Hyst: A hybrid approach for flexible and accurate dialogue state tracking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.00883</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The atis spoken language systems pilot corpus</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
				<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)<address><addrLine>Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-06-24">1990. June 24-27, 1990. 2014a</date>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
	<note>Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The third dialog state tracking challenge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spoken Language Technology Workshop</title>
		<imprint>
			<biblScope unit="issue">SLT</biblScope>
			<biblScope unit="page" from="324" to="329" />
			<date type="published" when="2014">2014b. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An iterative design methodology for user-friendly natural language office information applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08415</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kelley</surname></persName>
		</editor>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="1984">2014. 2016. 1984</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="26" to="41" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Wordbased dialog state tracking with recurrent neural networks</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The fourth dialog state tracking challenge</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Dharo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dialogues with Social Robots</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="435" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient large-scale neural domain classification with personalized attention</title>
		<author>
			<persName><forename type="first">Y.-B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2214" to="2224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Ó</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1777" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multitask learning for joint language understanding and dialogue state tracking</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</title>
				<meeting>the 19th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="376" to="384" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Deep contextualized word representations</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable multi-domain dialogue state tracking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Building a conversational agent overnight with dialogue self-play</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04871</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust zero-shot cross-domain slot filling with example values</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fayazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5484" to="5490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mrkšíc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gašíc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL 2017-Proceedings of Conference</title>
				<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
	<note>In 15th Conference of the European Chapter</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The dialog state tracking challenge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
				<meeting>the SIGDIAL 2013 Conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="404" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Transferable multi-domain state generator for task-oriented dialogue systems</title>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="808" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Zero-shot user intent detection via capsule neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3090" to="3099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Global-locally self-attentive encoder for dialogue state tracking</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1458" to="1467" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
