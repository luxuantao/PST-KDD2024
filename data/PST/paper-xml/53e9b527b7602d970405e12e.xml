<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Physically-Based Approach to Reflection Separation: From Physical Modeling to Constrained Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Naejin</forename><surname>Kong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut fu ¨r Intelligente Systeme</orgName>
								<address>
									<addrLine>Spemann-strasse 41</addrLine>
									<postCode>72076</postCode>
									<settlement>Tu ¨bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut fu ¨r Intelligente Systeme</orgName>
								<address>
									<addrLine>Spemann-strasse 41</addrLine>
									<postCode>72076</postCode>
									<settlement>Tu ¨bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Joseph</forename><forename type="middle">S</forename><surname>Shin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max-Planck-Institut fu ¨r Intelligente Systeme</orgName>
								<address>
									<addrLine>Spemann-strasse 41</addrLine>
									<postCode>72076</postCode>
									<settlement>Tu ¨bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="middle">N</forename><surname>Kong</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<addrLine>291 Daehak-ro, Yuseong-gu</addrLine>
									<postCode>305-701</postCode>
									<settlement>Daejeon</settlement>
									<country>Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Korea</forename><forename type="middle">J S</forename><surname>Shin</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<addrLine>291 Daehak-ro, Yuseong-gu</addrLine>
									<postCode>305-701</postCode>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Physically-Based Approach to Reflection Separation: From Physical Modeling to Constrained Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">00017FC13D704069A92A87780C165196</idno>
					<idno type="DOI">10.1109/TPAMI.2013.45</idno>
					<note type="submission">Manuscript received 13 Apr. 2012; revised 1 Nov. 2012; accepted 5 Feb. 2013; published online 15 Feb. 2013. Recommended for acceptance by D. Forsyth.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Reflection separation</term>
					<term>image enhancement</term>
					<term>polarized light</term>
					<term>computational photography</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a physically-based approach to separate reflection using multiple polarized images with a background scene captured behind glass. The input consists of three polarized images, each captured from the same view point but with a different polarizer angle separated by 45 degrees. The output is the high-quality separation of the reflection and background layers from each of the input images. A main technical challenge for this problem is that the mixing coefficient for the reflection and background layers depends on the angle of incidence and the orientation of the plane of incidence, which are spatially varying over the pixels of an image. Exploiting physical properties of polarization for a double-surfaced glass medium, we propose a multiscale scheme which automatically finds the optimal separation of the reflection and background layers. Through experiments, we demonstrate that our approach can generate superior results to those of previous methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>W E address the problem of reflection separation for images such as photographs of scenes taken through glass windows or photographs of objects placed inside glass showcases in retail store and museum settings. By separating the contribution of reflection, one can enhance a captured image to better see the desired scene. Since light reflected off the surface of a reflective medium is polarized <ref type="bibr" target="#b0">[1]</ref>, a common practice to reduce the effect of reflection is to place a polarizer in front of a camera lens to filter out the reflected light being polarized. However, such a method works only if the image is captured at Brewster's angle (around 56 degrees for glass reflection), which is rarely set for image capture in practice. Consequently, weak reflection still remains in the filtered image.</p><p>For reflection separation, we exploit physical properties of reflection and transmission for a double-surfaced glass medium, where both the reflected light and the transmitted light are polarized. Derived from physical equations of polarization, the effect of reflection and transmission can be modeled by the following equation (see Section 3):</p><formula xml:id="formula_0">IðxÞ ¼ ðxÞ L R ðxÞ 2 þ 1 À ðxÞ ½ L B ðxÞ 2 ;<label>ð1Þ</label></formula><p>where I is the intensity of light received by an image sensor, L R is the intensity of light from the scene reflected off a glass surface, L B is the intensity of light from the background scene behind the glass, and is a mixing coefficient.</p><p>The value of depends on the refractive index of glass, the orientation of the plane of incidence, the angle of incidence, and the polarizer angle at pixel position x. Assuming that the camera response function to an image sensor is linear, I is equal to the image recorded by the image sensor. Under this assumption, our goal is to estimate L R and L B , given I captured with a polarizer. The form of ( <ref type="formula" target="#formula_0">1</ref>) is similar to that of a matting equation <ref type="bibr" target="#b1">[2]</ref>. In the typical matting problem, there are a large number of foreground/background pixels with equal to either 0 or 1. In the reflection separation problem, however, is rarely equal to 0 or 1 but varies over an image between 0 and 1. In addition, conventional matting algorithms tend to blur the foreground/background regions where is between 0 and 1 as the focus of the matting problem is natural image composition. On the other hand, it is desirable that the reflection/background layers are sharp and clear in the reflection separation problem. Hence, although <ref type="bibr" target="#b0">(1)</ref> is similar to the matting equation, the conventional matting algorithms cannot be applicable to our reflection separation problem.</p><p>Solving <ref type="bibr" target="#b0">(1)</ref> with a single input image is an ill-posed problem. Our main contribution is that the reflection separation problem can be solved automatically by using three input images. Each of these images is captured with a polarizer angle separated by 45 degrees while the mixing coefficient is allowed to be spatially varying. In most of previous methods, is assumed to be constant over an image that is often invalid for real images. Therefore, the results produced with these methods may not be satisfactory for real-world examples. Based on the reflection model in <ref type="bibr" target="#b0">(1)</ref>, our method achieves high-quality reflection separation results for various examples. We show that our results are superior both quantitatively for synthetic examples and qualitatively for real-world examples to the results of the previous methods. Fig. <ref type="figure" target="#fig_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>illustrates one of our real-world examples.</head><p>A shorter version of this work appeared in <ref type="bibr" target="#b2">[3]</ref>. The current version extends our conference version with further technical details in reflection separation. In addition, we present a multiscale scheme to accelerate reflection separation and provide additional results. For self-completeness, we also provide a detailed discussion on reflectance/ transmittance for a single-or double-surfaced medium.</p><p>The remainder of this paper consists of as follows: We discuss the previous methods related to reflection separation in Section 2. Our reflection model in ( <ref type="formula" target="#formula_0">1</ref>) is derived in Section 3. Details of our method for reflection separation is presented in Section 4. Section 5 shows results of our method and their quantitative and qualitative comparisons to those of previous methods, followed by robustness tests of our algorithm. Finally, we conclude this paper with discussions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Reflection separation methods can be categorized into two groups: image-based methods and physically-based methods.</p><p>We start with reviewing image-based methods. Early work by Ohnishi et al. <ref type="bibr" target="#b3">[4]</ref> used multiple polarized images with different polarizer angles for reflection separation. They regarded the minimum intensity image as the background layer, and the difference between the maximum and minimum intensity images as the reflection layer. However, weak reflection may still remain in the recovered background image because reflection with partial polarization is not fully separated by a polarizer. Farid and Andelson <ref type="bibr" target="#b4">[5]</ref> presented a method to further reduce remaining reflection based on independent component analysis (ICA). Bronstein et al. <ref type="bibr" target="#b5">[6]</ref> generalized the ICA-based method to allow multiple polarized images, while improving its accuracy and efficiency based on sparsity of large image gradients.</p><p>Multiple polarized images with different polarizer angles were also used in <ref type="bibr" target="#b6">[7]</ref>. In this work, the reflection model considered the spatially varying mixing coefficient. However, the model only dealt with single-surface reflection, but not polarization of the transmitted light. Moreover, user corrections were often required to enhance the quality of the reflection separation. On the other hand, our physically-based reflection model deals with doublesurface reflection and the spatially varying mixing coefficient of both layers. In addition, our solution method is fully automatic.</p><p>Sarel and Irani <ref type="bibr" target="#b7">[8]</ref> and Yan et al. <ref type="bibr" target="#b8">[9]</ref> also dealt with the spatially varying mixing coefficient of reflection. Similar to the approach in <ref type="bibr" target="#b6">[7]</ref>, their approaches are based on an assumption that the structures from two sources, the reflection and background layers, are statistically uncorrelated. This statistical assumption may fail in the presence of overlapping edges from different layers. Adopting a physically-based approach, we avoid the assumption to better handle such overlapping edges.</p><p>Levin and Weiss <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> used a single image and user-provided pixel-wise gradient locations labeled as either the reflection or background layer. An automatic method by Levin et al. <ref type="bibr" target="#b11">[12]</ref> found the most likely decomposition that minimizes the total number of edges and corners in the recovered layers by using a database of natural images. However, these methods may not work well for a complex image containing many intersections of edges from the reflection and background layers: The manual gradient labeling would become very hard for the method in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, and the desired decomposition may not be obtained by database search for the method in <ref type="bibr" target="#b11">[12]</ref>. On the other hand, our method mainly relies on physical properties of polarization that are less affected by the complex edge intersections.</p><p>Projection of gradients between a pair of flash and noflash images can be used to separate reflection in a flash image. Agrawal et al. <ref type="bibr" target="#b12">[13]</ref> detected edges introduced by reflection based on the coherency of gradient directions between the images, and separated these edges by taking the projection between the flash image gradients and the no-flash image gradients. In <ref type="bibr" target="#b13">[14]</ref>, they adopted structure tensors of the flash and no-flash images to better detect the edges from reflection, and separated these by taking an affine transformation. They assumed that there is neither reflection nor saturation in the flash image. However, it is hard to obtain such a flash image because the flash power is so strong as to have most pixels saturated or is so weak as to make reflection remain.</p><p>Another useful image-based information is "misalignment" of image contents between layers. Irani et al. <ref type="bibr" target="#b14">[15]</ref> and Szeliksi et al. <ref type="bibr" target="#b15">[16]</ref> used temporal misalignment of each layer in the intensity domain in a sequence of images, and Gai et al. <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> detected the temporal misalignment in the gradient domain via gradient sparsity. Schechner et al. <ref type="bibr" target="#b18">[19]</ref> used focus difference between the background and reflected scenes. Tsin et al. <ref type="bibr" target="#b19">[20]</ref> solved the stereo matching problem in the presence of superimposed reflection. These methods assume that a static reflection layer is defocused by convolution with a single defocus blur kernel <ref type="bibr" target="#b18">[19]</ref>, or is transformed between images due to stereo motion <ref type="bibr" target="#b19">[20]</ref> or general motion such as camera movement, glass surface movement, or target object movement <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>Schechner et al. <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> proposed a physically based method that separate reflection by exploiting physical properties of polarization. They assumed that the mixing coefficient for the reflection and background layers is static over an image and that the two layers are statistically independent of each other. Under these assumptions, the angle of incidence is chosen by maximizing the statistical independence of the layers in terms of mutual information <ref type="bibr" target="#b21">[22]</ref> or their cross covariance <ref type="bibr" target="#b20">[21]</ref>.</p><p>Except for the work in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, all of above methods assume that the mixing coefficient for the reflection and background layers is spatially invariant over the image, which is rarely satisfied for a real polarized image. Based on physical properties of polarization, our reflection model uses an alpha matte to model the spatially varying mixing coefficient (see Section 3). We also present a fully automatic method to determine the mixing coefficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">REFLECTION MODEL</head><p>In this section, we discuss a physically-based reflection model in <ref type="bibr" target="#b0">(1)</ref>. We derive the model based on physical properties of polarization in Section 3.1. For self-completeness, we also provide a detailed discussion on reflectance and transmittance for a single-or double-surfaced medium in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Derivation</head><p>We describe properties of polarization in reflection and transmission for a double-surfaced medium such as a sheet of glass. Light reflected off or transmitted through a glass surface is partially polarized and expressed as the sum of two orthogonal polarized components, which are perpendicular and parallel to the plane of incidence as illustrated in Fig. <ref type="figure" target="#fig_1">2a</ref>. We define R as the reflectance that models the relative strength of light reflected off a glass surface, and T as the transmittance that models the relative strength of light transmitted through the glass surface, as the angle of incidence, and as the polarizer angle. Special subscripts ? and k are added to R and T that correspond to the polarized components perpendicular and parallel to the plane of incidence, respectively. Hence, R ? and R k represent two orthogonal polarized components of R such that R ¼ R ? þ R k . Similarly, T ¼ T ? þ T k . We define k as the angle for the orientation of the intersection line between the polarizer and the plane of incidence, and</p><formula xml:id="formula_1">? ¼ k þ 90 .</formula><p>Each polarized component in R and T is a function that depends on and the refractive index of a reflection medium. Exact forms of Rð; Þ and T ð; Þ are given in Section 3.2. Since ¼ 1:474 for glass reflection, we hide for R and T in the remainder. As shown in Fig. <ref type="figure" target="#fig_1">2b</ref>, the relative strength of each polarized component varies smoothly in . In addition, the weak parallel component of reflectance completely disappears only when the angle of incidence is equal to the Brewster's angle (around 56 degrees for glass reflection), while none of transmittance components disappears at any angle of incidence. A polarizer fully eliminates the effect of the reflected light only at the Brewster's angle, which is rarely set for image capture.</p><p>When taking an image with a polarizer, the amount of light that passes through the polarizer is given by Malus' law <ref type="bibr" target="#b0">[1]</ref>:</p><formula xml:id="formula_2">L cos 2 ð Þ;<label>ð2Þ</label></formula><p>where L is the intensity of incoming polarized light, is the angle between the polarization direction of the incoming light and the transmission axis of the polarizer. We assume that the intensities of two components in incoming light, that is, L R before reflection and L B before transmission are unpolarized, and thus that even energy is contained in each component, i.e., L R?</p><formula xml:id="formula_3">¼ L Rk ¼ L R =2 and L B? ¼ L Bk ¼ L B =2.</formula><p>Then, the intensity of light at a single pixel of an image sensor after passing through the polarizer is</p><formula xml:id="formula_4">I ¼ Â R ? ðÞ cos 2 ð À ? Þ þ R k ðÞ cos 2 ð À k Þ Ã L R 2 þ Â T ? ðÞ cos 2 ð À ? Þ þ T k ðÞ cos 2 ð À k Þ Ã L B 2 ;<label>ð3Þ</label></formula><p>which is a function of , and ? . Thus, we obtain the reflection model in (1) by setting which is the mixing coefficient for L R . 1 À is the mixing coefficient for L B since T ? ðÞ ¼ 1 À R ? ðÞ and T k ðÞ ¼ 1 À R k ðÞ (see Section 3.2). Now, let us take a closer look on the reflection model in <ref type="bibr" target="#b2">(3)</ref>. For an input image captured with a polarizer, is constant and and ? are spatially varying over the image, as illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>. In addition, we can see that the variations of the last two quantities are spatially smooth over a planar glass surface or a glass surface with small curvature. The reflectance and transmittance are also smooth with respect to , as shown in Fig. <ref type="figure" target="#fig_1">2b</ref>. Consequently, the mixing coefficient is a function of and ? , which is spatially smooth over an image. In this paper, we explicitly deal with the spatially varying mixing coefficient to achieve high-quality reflection separation.</p><formula xml:id="formula_5">¼ Â R ? ðÞ cos 2 ð À ? Þ þ R k ðÞ sin 2 ð À ? Þ Ã ;<label>ð4Þ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reflectance and Transmittance</head><p>This section describes double-surface reflectance and transmittance represented as functions of single-surface reflectance and transmittance, and their physical properties in detail.</p><p>For a single-surfaced medium, whose refractive index is , two polarized components perpendicular and parallel to the plane of incidence of reflectance are defined as</p><formula xml:id="formula_6">R s ? ð; Þ ¼ sin 2 ðÀtð;ÞÞ sin 2 ðþtð;ÞÞ and R s k ð; Þ ¼ tan 2 ðÀtð;ÞÞ tan 2 ðþtð;ÞÞ ;<label>ð5Þ</label></formula><p>respectively, according to the Fresnel equations <ref type="bibr" target="#b0">[1]</ref>. Here, is the angle of incidence and t ð; Þ ¼ arcsinð 1 sin Þ from Snell's law <ref type="bibr" target="#b0">[1]</ref>. For a given with fixed, reflectance and transmittance for each polarized component always sum to 1. Therefore, two polarized components perpendicular and parallel to the plane of incidence of transmittance are</p><formula xml:id="formula_7">T s ? ð; Þ ¼ 1 À R s ? ð; Þ and T s k ð; Þ ¼ 1 À R s k ð; Þ;<label>ð6Þ</label></formula><p>respectively. The values of R s ? , R s k , T s ? , and T s k with respect to are plotted in Fig. <ref type="figure" target="#fig_3">4a</ref>. The plotted graph shows partial polarization caused by the relationship between reflectance and transmittance, where the amount of polarization smoothly varies with respect to the angle of incidence from 0 to 90 degrees, and has the maximum at Brewster's angle (around 56 degrees for glass reflection).</p><p>For a double-surfaced medium, light transmitted through the medium undergoes a series of internal (single-surface) reflections between the front and back surfaces of the medium as illustrated in Fig. <ref type="figure" target="#fig_4">5</ref>. Each of the internal reflection produces a ray transmitted outside the medium. As a result, the observed light outside the front surface is the sum of the first reflected ray at the front surface and the internal reflection rays transmitted through the front surface. Similarly, the observed light outside the back surface is the sum of all internal reflection rays transmitted through the back surface.</p><p>Let and t be the angle of incidence and the angle of transmittance for the first reflection outside the front surface, respectively. According to the law of reflection <ref type="bibr" target="#b0">[1]</ref>, it is trivial that t is the angle of incidence and is the angle of transmittance for internal reflection. Moreover, ¼ arcsinð sin t Þ by Snell's law. We can easily prove that ( <ref type="formula" target="#formula_6">5</ref>) and ( <ref type="formula" target="#formula_7">6</ref>) remain unchanged for internal reflection. Thus, ( <ref type="formula" target="#formula_6">5</ref>) and ( <ref type="formula" target="#formula_7">6</ref>) can still be applied to the internal reflection.</p><p>Schechner et al. <ref type="bibr" target="#b20">[21]</ref> assumed that only the first few observed rays significantly contribute to the intensity of the observed reflected light or the observed transmitted light, while others have negligibly weak intensities. In addition, assuming that the thickness of the medium is thin enough, spatial shift between those significant observed rays can be ignored. Thus, double-surface reflectance R and double-surface transmittance T can be approximated as functions of single-surface reflectance and transmittance in <ref type="bibr" target="#b4">(5)</ref> and <ref type="bibr" target="#b5">(6)</ref>. The polarized components perpendicular and parallel to the plane of incidence in the double-surface reflectance are   respectively. The polarized components perpendicular and parallel to the plane of incidence in the double-surface transmittance are</p><formula xml:id="formula_8">R ? ð; Þ ¼ 2R s ? ð;Þ 1þR s ? ð;Þ and R k ð; Þ ¼ 2R s k ð;Þ 1þR s k ð;Þ ;<label>ð7Þ</label></formula><formula xml:id="formula_9">T ? ð; Þ ¼ 1ÀR s ? ð;Þ 1þR s ? ð;Þ ¼ 1 À R ? ð; Þ and T k ð; Þ ¼ 1ÀR s k ð;Þ 1þR s k ð;Þ ¼ 1 À R k ð; Þ;<label>ð8Þ</label></formula><p>respectively, which implies that the double-surface reflectance and transmittance for each polarized component sum to 1 under the same and . The values of R ? , R k , T ? , and T k with respect to are plotted in Fig. <ref type="figure" target="#fig_3">4b</ref>. Note that comparing this plot to that in Fig. <ref type="figure" target="#fig_3">4a</ref> on singlesurfaced reflectance and transmittance, only the shapes of the graphs are different but the properties on polarization remain identical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">REFLECTION SEPARATION METHOD</head><p>In this section, two versions of our reflection separation method are presented. We begin with the basic algorithm in Section 4.1 and then provide its multiscale extension in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Basic Algorithm</head><p>The basic algorithm consists of four steps as illustrated in Fig. <ref type="figure" target="#fig_5">6</ref>: orthogonal image extraction, image separation, reflection refinement, and weak-edge suppression. The first step extracts a pair of orthogonal images from three polarized images each captured with a polarizer angle separated by 45 degrees. The next step separates the reflection and background layers by estimating the spatially varying angle of incidence. The third step refines these layers by employing constrained optimization. Finally, the last step postprocesses the results with edge suppression <ref type="bibr" target="#b13">[14]</ref> to remove remaining weak edges. We further illustrate the behavior of our algorithm by providing results of each step for synthetic polarized images shown in Fig. <ref type="figure" target="#fig_12">11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Orthogonal Image Extraction</head><p>Consider three polarized images, I i ðxÞ, i ¼ 1; 2; 3, each of which was captured with a polarized angle separated by 45 degrees, i.e., i ¼ 1 , 1 þ 45 , and 1 þ 90 . From these three images, we compute 1 À ? ðxÞ instead of the explicit values of 1 and ? ðxÞ. We then compute two orthogonal images I ? ðxÞ and I k ðxÞ. I ? ðxÞ is the sum of intensities for the perpendicular components in the reflected and transmitted light, and I k ðxÞ is defined similarly:</p><formula xml:id="formula_10">I ? ðxÞ ¼ R ? ððxÞÞ L R ðxÞ 2 þ T ? ððxÞÞ L B ðxÞ 2 ;<label>ð9Þ</label></formula><formula xml:id="formula_11">I k ðxÞ ¼ R k ððxÞÞ L R ðxÞ 2 þ T k ððxÞÞ L B ðxÞ 2 :<label>ð10Þ</label></formula><p>By substituting the above equations into (3), we can express an input image I i ðxÞ, i ¼ 1; 2; 3, in terms of I ? ðxÞ, I k ðxÞ, and i À ? ðxÞ:</p><formula xml:id="formula_12">I i ðxÞ ¼ I ? ðxÞ cos 2 ½ i À ? ðxÞ þ I k ðxÞ sin 2 ½ i À ? ðxÞ ¼ I ? ðxÞ þ I k ðxÞ 2 þ I ? ðxÞ À I k ðxÞ 2 cos 2½ i À ? ðxÞ:<label>ð11Þ</label></formula><p>Now, we can derive the following three equations from ( <ref type="formula" target="#formula_12">11</ref>) by substituting <ref type="bibr" target="#b22">[23]</ref>: </p><formula xml:id="formula_13">ðI 1 ; 1 Þ, ðI 2 ; 1 þ 45 Þ, and<label>ðI</label></formula><formula xml:id="formula_14">3 ; 1 þ 90 Þ for ðI i ; i Þ, respectively</formula><formula xml:id="formula_15">I 1 ðxÞ þ I 3 ðxÞ ¼ I ? ðxÞ þ I k ðxÞ;<label>ð12Þ</label></formula><formula xml:id="formula_16">I</formula><formula xml:id="formula_17">I ? ðxÞ ¼ I 1 ðxÞ þ I 3 ðxÞ 2 þ I 1 ðxÞ À I 3 ðxÞ 2 cos 2½ 1 À ? ðxÞ ;<label>ð15Þ</label></formula><formula xml:id="formula_18">I k ðxÞ ¼ I 1 ðxÞ þ I 3 ðxÞ 2 À I 1 ðxÞ À I 3 ðxÞ 2 cos 2½ 1 À ? ðxÞ :<label>ð16Þ</label></formula><p>We assume 1 À ? ðxÞ is within ½À45 ; 45 for the unique solution of 1 2 arctanðÁÞ A similar assumption was made in <ref type="bibr" target="#b21">[22]</ref>. If 1 À ? ðxÞ is smaller than À45% or larger than 45 , the computed value is different AE90 from the true value. In this case, we simply exchange I ? and I k because the sign of cos 2ðÁÞ is reversed. For justification of this assumption, we refer the readers to <ref type="bibr" target="#b23">[24,</ref><ref type="bibr">Appendix]</ref>. Results of this step are shown in Fig. <ref type="figure" target="#fig_6">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Image Separation</head><p>In this step, we present how to separate an image into L R and L B by estimating the angle of incidence ðxÞ. We also show how to compute an alpha matte ðxÞ for each input image, which will be used in the next step.</p><p>Since T ? ðÞ ¼ 1 À R ? ðÞ and T k ðÞ ¼ 1 À R k ðÞ; L R , and L B can be derived from ( <ref type="formula" target="#formula_10">9</ref>) and <ref type="bibr" target="#b9">(10)</ref> as follows <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>: </p><formula xml:id="formula_20">L R ðxÞ ¼ 2½ð1 À R k ððxÞÞÞI ? ðxÞ À ð1 À R ? ððxÞÞÞI k ðxÞ R ? ððxÞÞ À R k ððxÞÞ ;<label>ð18Þ</label></formula><p>where I ? and I k have been computed in the previous step.</p><p>The range of ðxÞ is limited between 5 and 85 to avoid division by zero because R ? ¼ R k when ¼ 0 or 90 . In the above equations, L R ðxÞ and L B ðxÞ are functions of ðxÞ that is unknown. The mutual information between two images L R and L B is defined as follows:</p><formula xml:id="formula_22">IðL R ; L B Þ ¼ X lR;lB2L P ðl R ; l B Þ log P ðl R ; l B Þ P ðl R ÞP ðl B Þ ;<label>ð20Þ</label></formula><p>where P ðl R Þ and P ðl B Þ are the probabilities for certain intensity levels l R and l B in L R and L B , respectively, P ðl R ; l B Þ is the joint probability for l R and l B , and L is a set of all possible intensity levels in image histograms. To reduce the sensitivity to the contrast of images, Schechner et al. <ref type="bibr" target="#b21">[22]</ref> introduced a new measure:</p><formula xml:id="formula_23">I n ðL R ; L B Þ ¼ IðL R ; L B Þ=K RB ;<label>ð21Þ</label></formula><p>where</p><formula xml:id="formula_24">K RB ¼ À 1 2 X l R 2L P ðl R Þ log P ðl R Þ þ X l B 2L P ðl B Þ log P ðl B Þ " # :<label>ð22Þ</label></formula><p>K RB is the mean self-information between L R and L B . Therefore, I n ðL R ; L B Þ is the ratio of the mutual information to the mean self-information, which we call the "normalized" mutual information. For convenience, however, I n ðL R ; L B Þ will be referred to as the mutual information in what follows unless explicitly stated otherwise.</p><p>To estimate ðxÞ, we make an assumption that there is no correlation between the image contents in the reflected scene and the background scene. Hence, the best ðxÞ tends to minimize the mutual information between L R and L B . We prepare all candidate pairs of L R ðxÞ and L B ðxÞ evaluated at a sequence of regularly sampled values of ðxÞ by using <ref type="bibr" target="#b17">(18)</ref> and <ref type="bibr" target="#b18">(19)</ref>. Since ðxÞ varies smoothly over an image, we use belief propagation <ref type="bibr" target="#b24">[25]</ref> to choose the best ðxÞ at each pixel over the image by solving the following minimization problem:</p><formula xml:id="formula_25">arg min ðxÞ X x ÈððxÞÞ þ X x X y2N<label>ðxÞ</label></formula><formula xml:id="formula_26">ÉððxÞ; ðyÞÞ;<label>ð23Þ</label></formula><p>where ÈððxÞÞ is the data cost function, and ÉððxÞ; ðyÞÞ is the neighborhood cost function, and N ðxÞ is the firstorder neighbors of x. ÈððxÞÞ measures the cost of assigning ðxÞ to pixel x, and ÉððxÞ; ðyÞÞ measures the cost of assigning ðxÞ and ðyÞ to a pair of neighboring pixels x and y, respectively. Schechner et al. <ref type="bibr" target="#b21">[22]</ref> defined a data cost function in terms of the mutual information between L R ðxÞ and L B ðxÞ at each angle ðxÞ. Under the assumptions that is static over the image and that image contents in L R and L B are statistically uncorrelated, they showed that the image pair ðL R ; L B Þ at the best has the smallest mutual information. We adopt this function to our problem setting. However, it cannot be directly applied to our problem setting in which is spatially varying. Instead, we assume that is static locally, i.e., spatially invariant within a small patch around each pixel, based on its smoothness condition in a spatial domain. Then, our data cost function can be defined in terms of the patch-wise mutual information:</p><formula xml:id="formula_27">ÈððxÞÞ ¼ I n À L ½x R ; L ½x B Á ;<label>ð24Þ</label></formula><p>where</p><formula xml:id="formula_28">I n ðL ½x R ; L ½x B Þ is the mutual information for image patches L ½x R and L ½x B around x.</formula><p>We have also tested the data cost function proposed by Levin et al. <ref type="bibr" target="#b11">[12]</ref> to choose the image pair with the minimum number of corners and edges. However, we found that the mutual information generally produces better results for our problem.</p><p>Our neighborhood cost function is defined as</p><formula xml:id="formula_29">ÉððxÞ; ðyÞÞ ¼ jðxÞ À ðyÞj;<label>ð25Þ</label></formula><p>where ¼ 0:5 is a weight. Note that, if we simply maximize the data cost for each pixel without using the neighborhood cost function, the estimated value of ðxÞ over the image would be noisy and inaccurate.</p><p>After choosing ðxÞ, we obtain two separate layers L R ðxÞ and L B ðxÞ by evaluating <ref type="bibr" target="#b17">(18)</ref> and <ref type="bibr" target="#b18">(19)</ref> with ðxÞ. We also compute ðxÞ for each input image based on its definition in (4), by setting ðxÞ to the value obtained from belief propagation and 1 À ? ðxÞ to the value obtained in the previous step. Results of this step are shown in Fig. <ref type="figure" target="#fig_8">8</ref>, where blocking artifacts are observed apparently in Fig. <ref type="figure" target="#fig_8">8b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Reflection Refinement</head><p>The separation results include the blocking artifacts due to the patch-wise data cost function defined in <ref type="bibr" target="#b23">(24)</ref>. This section describes how to further refine the separation results to improve their quality.</p><p>We formulate a minimization problem with an objective function given in (26) to refine i and ðL R ; L B Þ:</p><formula xml:id="formula_30">X 3 i¼1 X x 2I i ðxÞ À i ðxÞL R ðxÞ À 1 À i ðxÞ ð Þ L B ðxÞ k k 2 þ c i ðxÞ À 0 i ðxÞ 2 þ s r i ðxÞ k k 2 :<label>ð26Þ</label></formula><p>The objective function consists of three terms: The first one is the data term derived from (1) for the input images.</p><p>The second one is a soft constraint that ensures i ðxÞ to be similar to 0 i ðxÞ, which denotes the mixing coefficient estimated in Step 2. This term enforces consistent estimation of i ðxÞ over each input image. The third one is the smoothness term that minimizes the variation of i ðxÞ. c and s are weighting parameters. Inspired by the work in <ref type="bibr" target="#b6">[7]</ref>, our optimization scheme first initializes 0 i , L R , and L B with i , LR , and LB , respectively, which are obtained with the image separation step (Section 4.1.2), and then minimizes the objective function by solving two convex subproblems alternatingly: solving for i while fixing L R and L B in one iteration, and solving for L R and L B while fixing i in the next iteration. Our algorithm is guaranteed to converge to a local minimum as the objective function value is strictly decreasing in every iteration. Results of this step are shown in Fig. <ref type="figure" target="#fig_7">9</ref>. The refined layers are now very close to their ground truth, but the reflection layer still contains some weak false edges as observed in Fig. <ref type="figure" target="#fig_7">9b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Weak Edge Suppression</head><p>Either of L R and L B after reflection refinement may still contain a very weak false edge that belongs to the other layer. We adopt cross-projection tensors <ref type="bibr" target="#b13">[14]</ref> to suppress the false edges in L R and L B . An edge at x in L can be detected with its smoothed structure tensor G defined as follows:</p><formula xml:id="formula_31">G ¼ rLrL T À Á Ã K ;<label>ð27Þ</label></formula><p>where L was obtained by converting the color space from RGB to YUV and taking the Y channel values, rL denotes the gradient vector at x, Ã denotes convolution, and K is a normalized 2D Gaussian kernel of variance . The matrix G can be decomposed as follows:</p><formula xml:id="formula_32">G ¼ VAEV T ¼ u 1 u 2 ½ 1 0 0 2 ! u T 1 u T 2 ! ;<label>ð28Þ</label></formula><p>where u 1 and u 2 are the eigenvectors of G corresponding to the eigenvalues 1 and 2 , respectively, and 1 ! 2 . Using this decomposition, the structure of L can be characterized locally: For a homogeneous region, 1 ¼ 2 ¼ 0. If 1 &gt; 0 and 2 ¼ 0, then an edge appears at x and its direction is given by u 1 . Based on this, we can detect an edge at x each of L R and L B if any.</p><p>To suppress a weak false edge, the cross-projection tensor at x in L R is defined as</p><formula xml:id="formula_33">D R ðxÞ ¼ v 1 v 2 ½ 1 0 0 2 ! v T 1 v T 2 ! :<label>ð29Þ</label></formula><p>Here, v 1 and v 2 are the major and minor eigenvectors of the smoothed structure tensor, respectively, which is derived from the gradient of at x in L B . We assume that a true edge in L R or L B has a larger gradient magnitude than its corresponding false edge in the other layer. In <ref type="bibr" target="#b13">[14]</ref>, the edge in L R is suppressed whenever an edge appears at the same location in L B . In our approach, however, we selectively suppress the edge in L R by setting the values of 1 and 2 of the cross-projection tensor D R based on our assumption on weak false edges. There are two cases: Case 1: There is an edge at x in L R . In this case, there are two subcases depending on whether or not there is an edge at x in L B . If there is no edge in L B , then the edge in L R is trivially a true edge. Suppose that there is an edge in L B . In this subcase, the edge in L R is a true edge if the gradient magnitude at x in L R is greater than that in L B . Otherwise, the edge in L R is a false edge. Our method sets 1 ¼ 1 and 2 ¼ 1 to retain the edge if it is a true edge. Otherwise, the method sets 1 ¼ 0 and 2 ¼ 1 to suppress the edge by projecting it onto the orthogonal vector of the edge in L B .</p><p>Case 2: There is no edge in L R . In this case, our method sets 1 ¼ 0 and 2 ¼ 0 to set the gradient at x in L R to a zero vector (see (30)). Symmetrically, the cross-projection tensor D B ðxÞ at x in L B can be constructed.</p><p>To suppress a false edge and retain the true edge, the gradients rL R ðxÞ and rL B ðxÞ are modified as follows:</p><formula xml:id="formula_34">rL 0 R ðxÞ ¼ D R ðxÞ Á rL R ðxÞ; rL 0 B ðxÞ ¼ D B ðxÞ Á rL B ðxÞ:<label>ð30Þ</label></formula><p>Then, the modified gradients rL 0 R ðxÞ and rL 0 B ðxÞ are integrated and the results are converted back to the RGB space to obtain the final separation results. As shown in   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MultiScale Extension</head><p>Our basic algorithm (Section 4.1) works well for small-sized images such as 64 Â 64 images. However, the computation time of this algorithm is demanding. For instance, it takes a couple of hours on a PC (2.6 GHz processor, 12.0 GB RAM) even for a 256 Â 256 image. The bottleneck is Step 2 (image separation) due to image histogram preparation and belief propagation (Section 4.1.2). To get around this difficulty, we adopt a multiscale reflection separation scheme based on the Gaussian pyramids of input images with a scale factor of 2.</p><p>Our multiscale scheme performs Step 3 (Section 4. </p><formula xml:id="formula_35">cÂ 2 þ 1; h=16 b cÂ 2 þ<label>1Þ</label></formula><p>, where ðw; hÞ specifies the image size at the coarsest scale. At each scale, the two convex problems are alternatingly solved for i and ðL R ; L B Þ, respectively, as described in Section 4.1.3. The solutions, i , LR , and LB at the current scale is upsampled to initialize 0 i , L R , and L B at the next finer scale, respectively. Here, we used fixed values c ¼ 2 and s ¼ 100 at all scales for the parameters of (26).</p><p>After completing Step 3 at the finest scale, Step 4 (Section 4.1.4) is performed to postprocess the separation results. Exploiting physical properties of polarization, Steps 1 and 2 compute i , LR , and LB close to their ground-truth values at the coarsest scale. With good initial values of 0 i , L R , and L B , our multiscale scheme converges quickly to a solution at each scale. Fig. <ref type="figure" target="#fig_14">12</ref> illustrates each step of our multiscale scheme with the input images in Fig. <ref type="figure" target="#fig_12">11</ref>. The multiscale scheme accelerates reflection separation greatly: For a 256 Â 256 image, the reflection separation completes in about 5 minutes with our multiscale scheme.</p><p>In our experiments, we found that the solution of the multiscale scheme does not necessarily converge to that of the basic (single-scale) algorithm. However, both singleand multiscale solutions are close enough to show good visual quality and small RMSEs. In our supplemental materials, which can be found in the Computer Society Digital Library at http://doi.ieeecomputersociety.org/ 10.1109/TPAMI.2013.45, we included results from a test which compares single-and multiscale solutions qualitatively and quantitatively with our two synthetic examples used in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we present our experimental results. The experiments were performed on an Intel i7PC (2.6 GHz processor, 12.0 GB RAM) with C++ and Matlab implementation. It takes about 5 minutes for an image of 256 Â 256 with our multiscale scheme to complete the reflection separation. In the remainder of this paper, by our method we refer to the multiscale scheme (Section 4.2).</p><p>We compared our method with those in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b5">[6]</ref>, and <ref type="bibr" target="#b21">[22]</ref>. For the method in <ref type="bibr" target="#b10">[11]</ref>, the maximum intensity image was used as the input image, and large gradient pixels of our projected gradients rL 0 R and rL 0 B (Section 4.1.4) were used to provide the gradient locations on the image. For the methods in <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b5">[6]</ref>, we employed the source codes  available on the web 1 to generate their results. We admit that the comparisons are not entirely fair because the input requirements of our method are different from those of the compared methods. We showed their results obtained with the best parameter settings as a reference to evaluate the quality of our results.</p><p>Figs. 13 and 14 show the results for synthetic examples. Based on ( <ref type="formula" target="#formula_10">9</ref>), <ref type="bibr" target="#b9">(10)</ref>, and <ref type="bibr" target="#b10">(11)</ref>, the input images were synthesized from their ground-truth layers by setting the values of ðxÞ and ? ðxÞ as visualized in Figs. <ref type="figure" target="#fig_12">11f</ref> and<ref type="figure" target="#fig_12">11g</ref>, respectively, and 1 ¼ 0 . Our method generated separation results close to the ground-truth layers: We quantitatively compared our method with the others by measuring a rootmean-square error (RMSE) of each layer, which quantifies the difference between an estimated layer and its ground truth. Our results showed lower RMSEs than those of the others. Comparing visual quality, our separation results looked almost similar to their ground-truth layers. On the other hand, the results of <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, and <ref type="bibr" target="#b21">[22]</ref> exhibited weak edges from different layers, and unnatural discontinuities were observed in the results of <ref type="bibr" target="#b10">[11]</ref>.</p><p>For the synthetic example in Fig. <ref type="figure" target="#fig_13">13</ref>, we tested a modified multiscale scheme by performing Step 3 (Section 4.1.3) only at the finest scale, while initializing the optimization with up-sampled alpha mattes from Step 2 (Section 4.1.2) performed at the coarsest scale. In Step 2, we compute an initial alpha matte for each input image (denoted by i ) based on (4) by setting to the value obtained from belief propagation at the coarsest scale, and 1 À ? to the value from Step 1 (Section 4.1.1) performed at the coarsest scale. Then, the value of i is up-sampled to the finest scale. Optimization in Step 3 is performed only at finest scale, after initializing 0 i at this scale with the value of up-sampled i , and ðL R ; L B Þ at this scale with the 1. http://www.wisdom.weizmann.ac.il/$evina/papers/reflections.zip; http://visl.technion.ac.il/bron/spica/.  <ref type="bibr" target="#b3">[4]</ref>, (c) results of <ref type="bibr" target="#b10">[11]</ref>, (d) results of <ref type="bibr" target="#b5">[6]</ref>, (e) results of <ref type="bibr" target="#b21">[22]</ref>. The first row shows the background layers, and the second row shows the reflection layers. values estimated by minimizing the objective function P 3 i¼1 P</p><p>x 2I i ðxÞ À 0 i ðxÞL R ðxÞ À ð1 À 0 i ðxÞÞL B ðxÞ 2 . This objective function was derived from the data term in (26) by substituting 0 i for the variable i . As we have discussed earlier, Step 2 generates alpha mattes with blocking artifacts due to belief propagation. If we simply up-sample alpha mattes from belief propagation performed at the coarsest scale, the blocking artifacts will be propagated and accumulated to the finest scale. Fig. <ref type="figure" target="#fig_15">15</ref> illustrates the final alpha mattes from Step 3 based on different reflection separation schemes. As illustrated in Fig. <ref type="figure" target="#fig_15">15a</ref>, the blocking artifacts in the alpha mattes still   remained strong with the modified multiscale scheme, while they almost disappeared with our multiscale scheme as shown in Fig. <ref type="figure" target="#fig_15">15b</ref>. The alpha mattes estimated with our single-scale scheme (Fig. <ref type="figure" target="#fig_15">15c</ref>) showed the most accurate values compared to the others, but the computation time was too long (a couple of hours). Therefore, we performed the physically-based refinement (Step 3) in a multiscale scheme to avoid the blocking artifact efficiently.</p><p>Figs. <ref type="bibr">16, 17, and 18</ref> show the results on real-world examples. More results on real-world examples can be found in our supplemental materials, available online. Similar to the synthetic examples, our method consistently produced better results in terms of visual quality than those of the others. Although very weak reflection was captured at all input images, as shown in Fig. <ref type="figure" target="#fig_6">17</ref>, our method still achieved good reflection separation. Results on more realworld examples are available in our supplemental materials, available online.</p><p>Next, we compared the results of the image-based method in <ref type="bibr" target="#b6">[7]</ref> and those of our physically-based method. Fig. <ref type="figure" target="#fig_18">19</ref> shows this comparison by using the real example in Fig. <ref type="figure" target="#fig_17">16</ref>. The method in <ref type="bibr" target="#b6">[7]</ref> is based on a sparse gradient assumption, that is, a large image gradient comes from either the background layer or the reflection layer but not both, which may not always be satisfied in practice. Therefore, some of the image features were smoothed out with the method in <ref type="bibr" target="#b6">[7]</ref>, while those were relatively well recovered with our method.</p><p>We finally tested the robustness of our method to errors in the polarizer angle and the refractive index. Our results from the robustness tests showed very small variances in RMSEs and little visual differences, compared to the ground-truth layers: We performed a sensitivity test to polarizer angle errors for two synthetic examples, one in Fig. <ref type="figure" target="#fig_13">13</ref> and the other in Fig. <ref type="figure" target="#fig_16">14</ref>. The input images were Fig. <ref type="figure" target="#fig_6">17</ref>. Results for a real example. (a) Our results, (b) results of <ref type="bibr" target="#b3">[4]</ref>, (c) results of <ref type="bibr" target="#b10">[11]</ref>, (d) results of <ref type="bibr" target="#b5">[6]</ref>, (e) results of <ref type="bibr" target="#b21">[22]</ref>, (f) input images. In (a)-(e), the first row shows the background layers, and the second row shows the reflection layers. Fig. <ref type="figure" target="#fig_8">18</ref>. Results for a real example. (a) Our results, (b) results of <ref type="bibr" target="#b3">[4]</ref>, (c) results of <ref type="bibr" target="#b10">[11]</ref>, (d) results of <ref type="bibr" target="#b5">[6]</ref>, (e) results of <ref type="bibr" target="#b21">[22]</ref>, (f) input images. In (a)-(e), the first row shows the background layers, and the second row shows the reflection layers. We employed gamma correction and contrast adjustment for better visual presentation. regenerated by adding angular perturbations " 2 and " 3 in ½À10 ; þ10 to 2 and 3 , respectively. Figs. <ref type="figure" target="#fig_1">20a,</ref><ref type="figure" target="#fig_1">20b</ref>, and 20c plot the average RMSEs of each layer over the two examples by varying the angular perturbations. Fig. <ref type="figure" target="#fig_1">20d</ref> shows the estimated layers for largest angular perturbations (" 2 ¼ " 3 ¼ þ10 ). For the same examples, we also performed a sensitivity test to an error in the refractive index. Fig. <ref type="figure" target="#fig_1">20e</ref> plots the average RMSEs of each layer estimated by varying the refractive index from 1.4 to 1.6, where the input images were generated by setting the refractive index to 1.471. Fig. <ref type="figure" target="#fig_1">20f</ref> shows the results for the refractive index with the largest error <ref type="bibr">(1.6)</ref>. These results support that our method is robust to small variations in the polarizer angles and the refractive index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSIONS AND CONCLUSIONS</head><p>We have proposed a reflection separation method based on physical properties of polarization. Given a series of three polarized images, each captured with the different polarizer angle separated by 45 degrees, our method produces high-quality separation of the reflection and background layers. We have derived a physically-based reflection model to estimate the spatially varying mixing coefficient (that is, the alpha mattes) of the two layers for an input image. On top of the model, we have proposed a multiscale scheme for reflection separation. Our scheme works fully automatically in a hierarchical manner.</p><p>In the remainder of this paper, we discuss limitations of our approach as well as future work. Our reflection model assumes the incoming light to the glass medium is unpolarized (see Section 3). When there are polarized specular highlights in the background or reflection layer, our result contains errors as shown in Fig. <ref type="figure" target="#fig_1">21</ref>. Our approach also cannot model the effect of contaminators on the glass surface such as dusts, water droplets, cracks, or air bubbles. When the reflected or transmitted light is diffused by the contaminators, the physical equations for polarization may not hold true anymore. Fig. <ref type="figure" target="#fig_1">22</ref> shows a failure example in which the glass surface contains many air bubbles. Finally, our approach assumes the camera and the captured scene are static. However, as discussed in Section 2, moving objects provide an alternative hint for reflection separation. As future work, we will study how to incorporate the additional information on moving objects into our approach to handle a dynamic scene.  <ref type="figure" target="#fig_13">13</ref> and the other in Fig. <ref type="figure" target="#fig_16">14</ref>). (a)-(c) Average RMSEs for each of L B and L R over the two examples with respect to an angular perturbation of 2 (represented by " 2 ) and that of 3 (represented by " 3 ), both ranging in ½À10 ; þ10 , (d) results with largest angular perturbations (" 2 ¼ " 3 ¼ þ10 ) for the example in Fig. <ref type="figure" target="#fig_13">13</ref>, (e) Average RMSEs for L B and L R over the two examples with respect to the refractive index ranging in ½1:4; 1:6, (f) results with index 1.6 for the example in Fig. <ref type="figure" target="#fig_13">13</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a), (b), (c) Input images, (d) the estimated background layer, (e) the estimated reflection layer. Note that image details as well as image noise are favorably reconstructed in (d) and (e). We employed gamma correction for better visual presentation.</figDesc><graphic coords="2,41.69,52.25,92.30,95.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Reflectance R or transmittance T is expressed as the sum of two orthogonal polarized components, that is, R ¼ R ? þ R k , T ¼ T ? þ T k , (b) R and T vary with respect to the angle of incidence , where R is completely polarized only at the Brewster's angle (around 56 degrees for glass reflection), where the relative strength of each polarized component in R or T is shown as a curve in a different color, (c) the amount of light received by a camera depends on the amount of polarization in the reflected and transmitted light.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. When a camera is close to a reflection medium, and ? vary spatially, as shown in (a) and (b), respectively.</figDesc><graphic coords="4,36.41,51.89,143.54,59.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Reflectance and transmittance depending on the varying angle of incidence for a single-or double-surfaced medium with the same refractive index. The relative strength of each polarized component is shown as a curve in a different color. (a) Single-surface reflectance/ transmittance for glass, where R s ? and R s k denote two orthogonal components of reflectance, and T s ? and T s k denote two orthogonal components of transmittance, (b) double-surface reflectance/transmittance for glass, where R ? and R k denote two orthogonal components of reflectance, and T ? and T k denote two orthogonal components of transmittance. The perpendicular and parallel polarized components are represented by the subscripts ? and k , respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Reflection and transmission for a double-surfaced medium. Black arrow: incoming light ray, red and blue dotted arrows: rays produced by single-surface reflection and single-surface transmission, respectively, shaded area: internal part of the medium.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Basic algorithm overview: Step 1 extracts a pair of orthogonal images from three input polarized images. Step 2 separates the reflection and background layers by estimating the spatially varying angle of incidence. Step 3 refines these layers by employing constrained optimization. Step 4 postprocesses the refined layers with edge suppression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Results of Step 1 from the input images in Fig. 11. (a), (b) Images of the parallel and perpendicular components, (c) physical quantity 1 À ?, where 1 ¼ 0 , hence it is À ? .</figDesc><graphic coords="6,51.77,63.17,55.10,55.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Results of Step 3. (a), (b) Refined background and reflection layers, (c)-(e) refined alpha mattes. We adjusted contrast of the layers for better visual presentation.</figDesc><graphic coords="7,327.65,194.57,54.50,54.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Results of Step 2. (a), (b) Initial background and reflection layers, (c) initial angle of incidence, (d)-(f) initial alpha mattes. We adjusted contrast of the layers for better visual presentation.</figDesc><graphic coords="7,36.53,196.49,54.50,54.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 ,</head><label>10</label><figDesc>Fig. 10, the weak false edges are well suppressed in the final separation.</figDesc><graphic coords="8,35.09,63.29,116.06,116.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>1.3) in a hierarchical fashion from the coarsest scale after initializing 0 i , L R , and L B at this scale with values i , LR , and LB computed by Steps 1 and 2 (Sections 4.1.1 and 4.1.2). In Step 2, we set the patch size to ð w=16 b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Results of Step 4. (a), (b) Images with false edges suppressed. We adjusted contrast for better visual presentation.</figDesc><graphic coords="8,298.61,169.37,116.06,116.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Input images and ground-truth values for Figs. 7, 8, 9, and 10, and Figs. 12 and 13. (a)-(c) Three polarized images were synthetically created from the ground-truth values in (d)-(j) with 1 , 1 þ 45 , and 1 þ 90 , respectively, where 1 ¼ 0 ; (d), (e) ground-truth background and reflection layers; (f) ground-truth angle of incidence; (g) ground-truth angle for the orientation of the line perpendicular to the intersection line between the polarizer and the plane of incidence; (h)-(j) ground-truth alpha mattes.</figDesc><graphic coords="8,328.01,364.61,54.50,54.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Results for a synthetic example in Fig. 11. (a) Our results, (b) results of<ref type="bibr" target="#b3">[4]</ref>, (c) results of<ref type="bibr" target="#b10">[11]</ref>, (d) results of<ref type="bibr" target="#b5">[6]</ref>, (e) results of<ref type="bibr" target="#b21">[22]</ref>. The first row shows the background layers, and the second row shows the reflection layers.</figDesc><graphic coords="9,66.29,415.73,89.66,59.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Results of our multiscale extension. From left to right: (a)-(c) results of Step 1 (the coarsest scale); (a), (b) images of the parallel and perpendicular components; (c) physical quantity 1 À ? , where 1 ¼ 0 , hence it is À ? ; (d)-(i) results of Step 2 (the coarsest scale); (d),(e) initial background and reflection layers; (f) initial angle of incidence; (g)-(i) initial alpha mattes; (j)-(n) results after multiscale reflection refinement in Step 3 (the finest scale); (o), (p) results after edge suppression in Step 4 (the finest scale).</figDesc><graphic coords="9,66.29,342.41,89.66,59.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. i at the finest scale from Step 3 based on different reflection separation schemes. (a) i from Step 3 performed only at the finest scale by initializing the optimization with up-sampled alpha mattes, (b) i estimated with our multiscale scheme, (c) i estimated with our single-scale scheme.</figDesc><graphic coords="10,64.97,422.69,90.26,59.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Results for a synthetic example. (a) Our results, (b) results of<ref type="bibr" target="#b3">[4]</ref>, (c) results of<ref type="bibr" target="#b10">[11]</ref>, (d) results of<ref type="bibr" target="#b5">[6]</ref>, (e) results of<ref type="bibr" target="#b21">[22]</ref>, (f) input images, (g) ground truth L B and L R from left to right. In (a)-(e), the first row shows the background layers, and the second row shows the reflection layers.</figDesc><graphic coords="10,121.97,212.21,59.90,60.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 16 .</head><label>16</label><figDesc>Fig.<ref type="bibr" target="#b15">16</ref>. Results for a real example. (a) Our results, (b) results of<ref type="bibr" target="#b3">[4]</ref>, (c) results of<ref type="bibr" target="#b10">[11]</ref>, (d) results of<ref type="bibr" target="#b5">[6]</ref>, (e) results of<ref type="bibr" target="#b21">[22]</ref>, (f) Input images. In (a)-(e), the first row shows the background layers, and the second row shows the reflection layers.</figDesc><graphic coords="10,189.17,563.69,60.50,59.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Comparison to the method in [7] for the real example in Figs. 16. (a) and (b) Estimated L B , (c), (d) estimated L R .</figDesc><graphic coords="12,33.53,176.69,98.42,56.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 21 .Fig. 22 .</head><label>2122</label><figDesc>Fig. 21. Failure example. (a)-(c) Input images, (d), (e) L B and L R estimated with our method. Our method failed to properly separate reflection around specular highlights of glossy surfaces in the background scene. Nevertheless, our method still produced reasonable L B .</figDesc><graphic coords="12,212.57,254.33,57.74,57.74" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported by the MCST and KOCCA in the Culture Technology (CT) Research &amp; Development Program 2012 (R2010050008_00000003), and the National Research Foundation (NRF) of Korea (No. 2012-0003359).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Hecht</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Pearson Education</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Bayesian Approach to Digital Matting</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;01)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Physically-Based Approach to Reflection Separation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;12)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Separating Real and Virtual Objects from Their Overlapping Images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ohnishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kumaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision (ECCV &apos;96)</title>
		<meeting>European Conf. Computer Vision (ECCV &apos;96)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1065</biblScope>
			<biblScope unit="page" from="636" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Separating Reflections from Images by Use of Independent Components Analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. Am</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="2136" to="2145" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sparse ICA for Blind Separation of Transmitted and Reflected Images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Imaging Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="91" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">High-Quality Reflection Separation Using Polarized Images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3393" to="3405" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Separating Transparent Layers through Layer Information Exchange</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision (ECCV &apos;04)</title>
		<meeting>European Conf. Computer Vision (ECCV &apos;04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="328" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Separating Reflections from a Single Image Using Spatial Smoothness and Structure Information</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Kuruoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kayabol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth Int&apos;l Conf. Latent Variable Analysis and Signal Separation (LVA/ICA &apos;10)</title>
		<meeting>Ninth Int&apos;l Conf. Latent Variable Analysis and Signal Separation (LVA/ICA &apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="637" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">User Assisted Separation of Reflections from a Single Image Using a Sparsity Prior</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision (ECCV)</title>
		<meeting>European Conf. Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3021</biblScope>
			<biblScope unit="page" from="602" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">User Assisted Separation of Reflections from a Single Image Using a Sparsity Prior</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1647" to="1654" />
			<date type="published" when="2007-09">Sept. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Separating Reflections from a Single Image Using Local Features</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;04)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Removing Photography Artifacts Using Gradient Projection and Flash-Exposure Sampling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="828" to="835" />
			<date type="published" when="2005-07">July 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Edge Suppression by Gradient Field Transformation Using Cross-Projection Tensors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;06)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2301" to="2308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Computing Occluding and Transparent Motions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rousso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="1994-02">Feb. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Layer Extraction from Multiple Images Containing Reflections and Transparency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliksi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;00)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;00)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Blindly Separating Mixtures of Multiple Layers with Spatial Shifts</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;08)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Blind Separation of Superimposed Images with Unknown Motions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;09)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;09)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1881" to="1888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Blind Recovery of Transparent and Semireflected Scenes</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiryati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;00)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;00)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="38" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stereo Matching with Reflections and Translucency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;03)</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition (CVPR &apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="702" to="709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Polarization-Based Decorrelation of Transparent Layers: The Inclination Angle of an Invisible Surface</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiryati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Computer Vision (ICCV &apos;99)</title>
		<meeting>IEEE Int&apos;l Conf. Computer Vision (ICCV &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="814" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Polarization and Statistical Analysis of Scenes Containing a Semireflector</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Schechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiryati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. Am</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="276" to="284" />
			<date type="published" when="2000-02">Feb. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Polarization Camera for Computer Vision with a Beam Splitter</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. Am</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2935" to="2945" />
			<date type="published" when="1994-11">Nov. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Physically-Based Reflection Separation Using Polarized Images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>KAIST</publisher>
		</imprint>
	</monogr>
	<note type="report_type">PhD dissertation</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient Belief Propagation for Early Vision</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="54" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
