<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yue</forename><surname>Fei</surname></persName>
							<email>yuefei97@yahoo.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kelvin</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
							<email>kelvin.wang@okstate.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Allen</forename><surname>Zhang</surname></persName>
							<email>allen.zhang@okstate.edu</email>
							<idno type="ORCID">0000-0002-2565-9894</idno>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Southwest Jiaotong University</orgName>
								<address>
									<postCode>610031</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guangwei</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Baoxian</forename><surname>Li</surname></persName>
							<email>baoxianlee@126.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Civil and Environmental Engineering</orgName>
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Fei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">C</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">Q</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Y</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Oklahoma State University</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2B143F660DA68548E18A6DA8E0E5DC0C</idno>
					<idno type="DOI">10.1109/TITS.2019.2891167</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CrackNet</term>
					<term>CrackNet-V</term>
					<term>deep learning</term>
					<term>surface cracks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A few recent developments have demonstrated that deep-learning-based solutions can outperform traditional algorithms for automated pavement crack detection. In this paper, an efficient deep network called CrackNet-V is proposed for automated pixel-level crack detection on 3D asphalt pavement images. Compared with the original CrackNet, CrackNet-V has a deeper architecture but fewer parameters, resulting in improved accuracy and computation efficiency. Inspired by CrackNet, CrackNet-V uses invariant spatial size through all layers such that supervised learning can be conducted at pixel level. Following the VGG network, CrackNet-V uses 3 × 3 size of filters for the first six convolutional layers and stacks several 3 × 3 convolutional layers together for deep abstraction, resulting in reduced number of parameters and efficient feature extraction. CrackNet-V has 64 113 parameters and consists of ten layers, including one pre-process layer, eight convolutional layers, and one output layer. A new activation function leaky rectified tanh is proposed in this paper for higher accuracy in detecting shallow cracks. The training of CrackNet-V was completed after 3000 iterations, which took only one day on a GeForce GTX 1080Ti device. According to the experimental results on 500 testing images, CrackNet-V achieves a high performance with a Precision of 84.31%, Recall of 90.12%, and an F-1 score of 87.12%. It is shown that CrackNet-V yields better overall performance particularly in detecting fine cracks compared with CrackNet. The efficiency of CrackNet-V further reveals the advantages of deep learning techniques for automated pixel-level pavement crack detection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There are two major tasks involved in automated pavement survey: automated data collection and interpretation. Due to technological innovations in hardware equipment, automated pavement data collection has become increasingly mature and widely used in recent years.</p><p>Although automated pavement data collection has made remarkable progress, fully-automated pavement distress survey still faces challenges. As a major task of automated distress survey, pavement crack detection has been studied for decades and demonstrated certain level of successes <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Thresholding algorithms were proposed to separate cracks from local background <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b8">[9]</ref>. However, the thresholding algorithms failed to achieve high accuracies for most of the time due to unevenly distributed illuminance on images. Although Morphological Algorithms were also introduced to reduce false detections <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b11">[12]</ref>, the detection results were still heavily dependent on the choices of threshold values. Wavelet-based Approaches utilized Wavelet Transform to decompose the original pavement data into different frequency sub-bands such that cracks can be captured more easily following the assumption that cracks are mainly preserved in high frequency sub-bands <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b16">[17]</ref>. Nevertheless, the decomposition of original data into frequency domain adversely impacts the spatial entirety of pavement cracks and thus may result in discontinued cracks. Filter-based Algorithms were also introduced by researchers to transform original data and seek for cracks with anticipated responses <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b20">[21]</ref>. However, the filter-based approaches may fail to detect some cracks that have weak responses to the predesigned filters. Machine Learning Algorithms, such as Artificial Neural Networks (ANNs) and Support Vector Machines (SVMs), can also be found in many studies to perform classifications on pavement cracks <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b26">[27]</ref>. However, these machine learning techniques generally represent only one or two layers of abstraction and may not fully reflect the complexity of pavement surface.</p><p>The automated algorithms above for crack detection have showed various successes under specific pavement environments. However, none of them have demonstrated consistently high accuracies for diverse road surfaces. Over the past decades, the private and public endeavors on worldwide basis vastly underestimated the challenges and difficulties in developing automated analysis tools for pavement cracks with full considerations on the complexity as well as the diversity of pavement surfaces <ref type="bibr" target="#b27">[28]</ref>. The limitations of traditional automated algorithms are primarily resulted from attempts to mimic human cognition capability based on shallow level of abstractions or simple and uncomprehensive hypotheses <ref type="bibr" target="#b28">[29]</ref>.</p><p>The recent progress in deep learning shows an opportunity to improve the performance of automated crack detection algorithms through learning from diverse examples. Deep learning is an effective machine learning approach that allows computers to understand the world by learning multiple levels of data representations from experiences <ref type="bibr" target="#b29">[30]</ref>- <ref type="bibr" target="#b30">[31]</ref>. The powerful adaptability of deep learning for complex problems has been demonstrated in many recent researches <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b35">[36]</ref>. Meanwhile, deep learning based transportation solutions were also developed recently for traffic flow prediction, traffic data imputation, and passenger demand forecasting <ref type="bibr" target="#b36">[37]</ref>- <ref type="bibr" target="#b38">[39]</ref>. Specifically, the deep Convolutional Neural Network (CNN) has revealed the remarkable capability of deep learning in image classification based on large-scale comprehensive data sets <ref type="bibr" target="#b39">[40]</ref>- <ref type="bibr" target="#b43">[44]</ref>.</p><p>The CNN structure is designed to classify grid-like images based on shift-and distortion-invariant features obtained via sparse connectivity with shared weights and pooling layers <ref type="bibr" target="#b44">[45]</ref>. Inspired by the CNN structure, several applications have also been introduced for pavement crack detection. An application of CNN in crack recognition was developed for classifying small image cells with size of 99 × 99, demonstrating the superior performances of deep CNN in comparison with SVMs and Boosting methods <ref type="bibr" target="#b45">[46]</ref>. Similarly in 2017, another deep CNN was proposed for crack recognition based on pavement image cells <ref type="bibr" target="#b46">[47]</ref> and further showed the advantages of deep learning techniques over traditional algorithms such as Canny and Sobel edge detectors. However, both of the two aforementioned networks were not developed on the basis of true pixel-level accuracy, and did not train the networks with a large set of diversified pavement surface data representing varying textures. Also in 2017, CrackNet was developed for crack detection based on a large set of diverse 3D pavement surface data <ref type="bibr" target="#b28">[29]</ref>. Unlike the traditional CNN architecture, CrackNet does not use any pooling layers that downsize the original data. Consequently, the supervised learning can be conducted at pixel level with invariant data size. It was demonstrated that CrackNet achieved high level of pixel-perfect accuracy in detecting cracks on asphalt surfaces and outperformed traditional algorithms such as SVM and 3D Shadow Modeling <ref type="bibr" target="#b47">[48]</ref>. However, the feature generator used in CrackNet implements fixed operations and produces handcrafted features using pre-designed line filters, which resulted in some limitations in learning capability. More importantly, the processing speed of CrackNet is slow due to huge number of parameters and large data depth at hidden layers.</p><p>For fast and efficient performance, an improved version of CrackNet called CrackNet-V is proposed in the paper for crack detection on 3D asphalt pavement surfaces. Compared with CrackNet, the CrackNet-V presents a deeper network structure but with fewer parameters. Inspired by CrackNet, no pooling layers are used in CrackNet-V. Consequently, the errors can be learned at pixel level, leading to enhanced pixel-perfect accuracy. Following the VGG network <ref type="bibr" target="#b42">[43]</ref>, CrackNet-V uses small filters (3 × 3) in the first six convolutional layers to reduce the number of parameters. In the meantime, several 3×3 convolution layers are stacked together for deep abstraction and multiple levels of feature extraction. In addition, a new activation unit called "Leaky Rectified Tanh" is proposed for more accurate detection on shallow cracks. The CrackNet-V only takes 0.33 second on average for pixel-level crack detection, which is roughly 3-4 times faster than CrackNet. Additionally, it is demonstrated in the paper that CrackNet-V also achieves improved overall performance compared with CrackNet. All the data used in the paper is based on 1-mm 3D pavement surface data collected by the PaveVision3D system made by WayLink. The PaveVision3D System mounted on a Digital Highway Data Vehicle (DHDV) (Fig. <ref type="figure" target="#fig_0">1</ref>) is able to acquire full-lane-scale 3D data in 1-mm resolution at a highway speed up to 60 mph no matter during night-or day-time <ref type="bibr" target="#b48">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Image Library</head><p>For machine learning purposes, the research team of this paper built an image library specifically for CrackNet-V development that consists of more than 6,000 3D pavement images and corresponding ground-truth images with labeled pavement cracks. All 3D pavement images in the image library were collected by the PaveVision3D system in last 5 years on different pavements. Each image covers an area of 4-meter (width) by 2-meter (length). The established image library represents diversified variations of cracks and pavement surface textures. There is no overlap between any two images, and no more than 100 images are from the same pavement section. The ground-truths of cracks on all images are manually processed with close supervisions on pixel-perfect accuracies by multiple teams. A three-round inspection is conducted to ensure the ground-truths are accurate at pixel level. For the first round, several well-trained operators manually mark the cracks on provided 3D pavement images with full resolution. For the second round, several other well-trained operators examine and refine the ground-truths for correcting errors and reducing subjectivity. Finally, the ground-truths are further inspected and verified by experts. The entire process of preparing ground-truths of cracks is completed on continuing basis for more than one year. Fig. <ref type="figure" target="#fig_1">2</ref> shows several examples of 1-mm 3D pavement images with corresponding ground truths. 3,083 asphalt pavement images in total from the image library are divided into three groups: 2,568 images are utilized as training data to feed CrackNet-V for supervised learning; 15 images representing typical conditions of asphalt pavement surfaces are used as validation data to monitor the network performance  during training; 500 images are applied as the testing data for the final evaluation of network performance. The network input images are downsized from 4096 × 2048 to 512 × 256 using the average pooling method. In other words, the average value of an 8×8 data block becomes the value of an individual pixel on the downsized image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network Architecture</head><p>The CrackNet-V architecture for crack detection with pixellevel accuracy is shown in Fig. <ref type="figure" target="#fig_2">3</ref>. It consists of three major components: one pre-processing layer, eight consecutive convolutional layers and one output unit. At the beginning of CrackNet-V, the pre-processing layer prepares 4 rectified inputs that are within a standard data range. Afterwards, eight cascaded convolutional layers are utilized for hierarchical feature extraction on pre-processed layer inputs and then to produce a series of feature maps. Finally, the output unit applies 1 × 1 convolutions to merge feature maps of the last convolutional layer and then to generate the crack map.</p><p>In convolutional layers, feature maps between adjacent layers are connected by corresponding convolutional filters. To emphasize spatial invariance, the same set of filter kernels are shared at each pixel to produce a feature map. All feature maps generated at hidden layers have the same spatial size of the input and output images. At the seventh convolutional layer, a series of filters in size of 15×15 are applied to connect a small visual receptive field surrounding at each pixel. The subsequent two layers use 1 × 1 convolutions to provide more non-linear activations for accuracy improvement.</p><p>In the first six convolutional layers, the sizes of all filter kernels are set to 3 × 3 for reducing the number of learnable parameters while increasing network depth at the same time to enhance network performance <ref type="bibr" target="#b42">[43]</ref>. As Fig. <ref type="figure" target="#fig_3">4</ref> shows, two successive convolutional layers using 3 × 3 kernels (Fig. <ref type="figure" target="#fig_3">4(a)</ref>) are able to represent a 5 × 5 visual receptive field, which are almost equal to one single layer using a 5 × 5 kernel (Fig. <ref type="figure" target="#fig_3">4(b)</ref>). However, the number of parameters in Fig. <ref type="figure" target="#fig_3">4</ref>(a) is 2 × 3 × 3 = 18, which is much fewer than that in Fig. <ref type="figure" target="#fig_3">4</ref>(b) (i.e. 5 × 5 = 25). Similarly, three successive convolutional layers using 3 × 3 kernels have a 7 × 7 effective receptive field, but the number of parameters are only 27. Based on such a concept, CrackNet-V increases the depth of convolutional layers while introducing only a small number of extra parameters.</p><p>No pooling layers are used in CrackNet-V. Pooling layer is an important characteristic of CNN to reduce the original data size while conveying shift-and distortion-invariant global information for image classification. However, the goal of pixel-level crack detection is to determine a specific pixel inside a small visual receptive field is crack pixel or not. The global information for pixel-level crack detection is not as important as that for large-scale image classification. Therefore, if a pixel is shifted away from its original position, the original information of the shifted pixel might be lost, which means pooling layer is unnecessary in the case of pixel-level crack detection. In fact, CrackNet <ref type="bibr" target="#b28">[29]</ref> demonstrated a success of crack detection at pixel level without using any pooling layers. In addition, some researches also indicated that pooling layers could increase computational costs while contributing little to the network accuracy <ref type="bibr" target="#b49">[50]</ref>.</p><p>CrackNet-V only has a total of 64,113 learnable parameters. Compared with CrackNet using more than one million parameters, the number of parameters used in CrackNet-V is significantly reduced, resulting in potentially faster performance. The entire network architecture is developed with C++ and CUDA Toolkit 8.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Pre-Processing Layer</head><p>Image pre-processing is an important task to prepare the input data. The original 3D pavement surfaces sometimes are uneven due to cross slope, rutting and other surface deformations. The unevenness of pavement surface impedes the feature extraction based on the weight-sharing concept defined in CNN structure. Therefore, it is necessary to pre-process the original 3D pavement images and rectify the surface unevenness. Two procedures are conducted at the pre-processing layer to enhance the local motifs while ignoring global unevenness. First, median filter is used to determine the representative elevation of a local region. Subsequently, the elevation of each pixel within the local region is then adjusted based on the representative local elevation. Second, Z-score Normalization is implemented to confine the data in a standard range.</p><p>As a result, the pre-processing layer can greatly suppress the negative effects caused by surface unevenness presented on the down-sampled 3D image (Fig. <ref type="figure" target="#fig_4">5</ref>), and prepare wellrectified input data for CrackNet-V. It should be noted that the pre-processing layer produces 4-channel input data. As the optimal size of median filter is hard to be determined, 4 different sizes of median filters are respectively applied for each channel in the pre-processed layer. In other words, totally 4 pre-processed images participate as input data in network training and testing. The median filter size at the 1st channel is set to 9 × 9, and then gradually expands by 2 × 2 so that the 4th channel eventually reaches the size of 15 × 15. According to experiments, the network performance based on multiple pre-processed inputs is significantly improved by contrast with that based on only one pre-processed input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Activation Unit in Hidden Layers</head><p>3D data sets are able to represent realistic pavement cracks at different depths. However, the responses of cracks after convolution may have a large difference due to the variation of crack depths. After passing through the general activation unit Leaky Rectifier Linear Unit (ReLU) <ref type="bibr" target="#b50">[51]</ref>, those convolutional differences still remain in the following layers of the network, which causes the network to concentrate on learning the depth range of cracks. Besides, the depth range of cracks is not unique when other noise patterns are considered. The uniqueness of cracks is highly related with the morphological information instead of the depth information.</p><p>In fact, the proposed network always ignores some shallow cracks if Leaky ReLU is applied at the hidden layers. To solve this problem, the new activation unit called Leaky Rectified Tanh is proposed in this paper to control the magnitude of convolution results such that the shallow cracks have similar responses with deeper cracks.</p><p>The proposed activation unit Leaky Rectified Tanh is identified in the paper as:</p><formula xml:id="formula_0">σ (x) = max 1.7159 × tanh 2 3 x , 0 +min(0.1 x, 0)<label>(1)</label></formula><p>The tanh with scale factors of 1.7159 in y-axis and 2 3 in x-axis is used to regulate data magnitude as same as data magnitude of output neuron. Fig. <ref type="figure" target="#fig_5">6</ref> describes the difference between Leaky Rectified Tanh and Leaky ReLU. In general, the pattern of Leaky Rectified Tanh is similar to that of Leaky ReLU when x ∈ (-∞, 1]; however, Leaky Rectified Tanh can effectively control the data magnitude if x ∈ (1, +∞]. In other words, if the responses after convolution are positive, the differences among responses of cracks with different depths can be suppressed with Leaky Rectified Tanh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Activation Unit of Output Neuron</head><p>Currently, soft-max layers are widely used as the output layer of CNN on the task of multi-objects classification.  Considering crack detection is essentially a binary classification problem, the sigmoid-like unit is applied at the output neuron of CrackNet-V for binary classification. The recommended activation unit at output neuron is the LeCun Tanh <ref type="bibr" target="#b51">[52]</ref> shown below:</p><formula xml:id="formula_1">σ(x) = 1.7159 × tanh( 2 3 x) (2)</formula><p>Compared with the traditional sigmoid unit, the LeCun Tanh has several advantages (Fig. <ref type="figure" target="#fig_6">7</ref>). First of all, the range of LeCun Tanh is larger than that of traditional sigmoid unit, which means the learnable parameters have more space to be adjusted by back-propagation algorithm. Second, LeCun Tanh has both positive and negative parts in y-axis, which is suitable for a typical binary classification problem. Last, the first order derivative of LeCun Tanh is larger and more effective than that of sigmoid unit, which means the gradients can be better backpropagated inside the network. Even though the derivative is not concerned at the output neuron with the application of cross-entropy, it is critical for gradient backpropagation at hidden layers when the proposed unit Leaky Rectified Tanh is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Evaluation Methods</head><p>The performance indicators Precision (Pr), Recall (Re), and F-1 Score (F1) are utilized to evaluate the network performance during both training and testing process <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b52">[53]</ref>. Those indicators are defined as followings:</p><formula xml:id="formula_2">P r = TP TP + FP (3) Re = TP TP + FN (4) F 1 = 2 × P × R P + R (<label>5</label></formula><formula xml:id="formula_3">)</formula><p>where TP is the true-positive pixel, which means a crack pixel classified correctly; FP is the false-positive pixel, which means a non-crack pixel classified incorrectly; and FN is the false-negative pixel, which means a crack pixel classified incorrectly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. NETWORK TRAINING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cost Function</head><p>The sigmoid-like unit LeCun Tanh at the output neuron generates a probability map for all individual pixels. The range of the predicted value for a pixel of the probability map is between -1.7159 and 1.7159. If the predicted value of a pixel is larger than 0, then this pixel is treated as a crack pixel. Otherwise it is regarded as a non-crack pixel. Each pixel of the input data has a corresponding target value based on the manually marked ground-truth. The target value of a pixel is set as 1.7159 if it is a crack pixel, otherwise it is -1.7159.</p><p>The objective of training is to minimize the dissimilarity between the predicted value and target value at each pixel. The error per pixel is evaluated by the cross-entropy cost function combined with L2 weight decay <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref>:</p><formula xml:id="formula_4">C = 3 4 × [(t -1.7159) × ln (1.7159 -a) -(t + 1.7159) × ln (1.7159 + a)] + const + L 2 Item (<label>6</label></formula><formula xml:id="formula_5">)</formula><p>where C is the evaluated error of a pixel; t is the target value of a pixel; a is the predicted value of a pixel; const is a constant term used to ensure that the error is non-negative, as well as that the error approaches to zero when predicted value is close to expected target value (const is set to 3.174 in this paper); L 2 Item equals to 0.5 × λ × W 2 (λ is the weight decay parameter, and W represents all learnable weights in the network). The cost function in the form of cross-entropy is helpful to speed up training as the errors between predicted and target values are directly back-propagated. On the other hand, L2 weight decay prevents network overfitting by penalizing large weights in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameters Initialization and Training Considerations</head><p>Effective initialization of weights is important to a network because poor initialization may result in limited network performance or even unmanageable behaviors during network training. As the pre-processed inputs have zero mean, an efficient method called Xavier Initialization <ref type="bibr" target="#b55">[56]</ref> is a good option to initialize all parameters of CrackNet-V. Following this method, the weight of a neuron in a certain layer should be drawn from a uniform distribution defined as:</p><formula xml:id="formula_6">W = [- √ 6 √ n i + n j , √ 6 √ n i + n j ]<label>(7)</label></formula><p>where n i is the number of input connections and n j is the number of output connections.</p><p>It is worth noticing that for a w×h filter connecting between n i feature maps from the previous layer and n j feature maps at current layer, the weights of this filter are subject to a uniform distribution defined as:</p><formula xml:id="formula_7">W ftr = [- √ 6 w × h × n i + n j , √ 6 w × h × n i + n j ]<label>(8)</label></formula><p>The biases of all layers are set as 0.01. The advantage of Xavier Initialization is that the variances of feature maps in forward pass and gradients in backward pass are maintained in a rational range such that the network can be trained more easily.</p><p>The network training is based on the Stochastic Gradient Descent algorithm. In this paper, the mini-batch size is 4 at the beginning and then gradually increases to 8 as training continues. The momentum variable is set as 0.9, which is found to be very helpful for stabilizing network training. L2 weight decay is 0.0005 during entire training process. All layers share the same learning rate. The learning rate is set as 0.01 at the beginning, and then divided by 2 (i.e. 0.005) after 200 iterations training or divided by 3 (i.e. 0.0033) after 500 iterations training. Finally, the network is fine-tuned with learning rate 0.0025 to seek for further optimization after 1,000 iterations. No Drop-Out technique is applied in the network. The network training with 3,000 iterations is completed in only one day with the aid of a single GPU device (NVidia GeForce GTX 1080Ti).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Training Process</head><p>The validation set is used to monitor and measure the network performance during training process <ref type="bibr" target="#b56">[57]</ref>. 15 different asphalt images are selected from the 3,083 asphalt images in the image library. As Fig. <ref type="figure" target="#fig_7">8</ref> shows, validation sets from #1 to #7 are selected to represent normal cracks on asphalt pavements; sets from #8 to #10 are selected to represent tiny cracks; sets from #11 to #12 have pavement shoulders on the right side of the images; sets from #13 to #14 have shallow cracks near the pavement markers on the left of the images; #15 represents intact pavement surface without any cracks.</p><p>During training process, both the cost function value and F1-score are monitored for the validation set. Although the size of validation set is smaller, it is sufficient for monitoring the overall network performance during training process because the validation set is selected to represent typical pavement surface textures and severity levels of pavement cracks. In addition, using validation set of smaller size can reduce the training time.</p><p>To evaluate the effectiveness of Leaky Rectified Tanh, two networks with different activation units are trained for comparison study. The network with proposed Leaky Rectified Tanh is denoted as Config-A, while the network with traditional Leaky ReLU is denoted as Config-B.</p><p>Totally 2,568 images are involved in network training. Fig. <ref type="figure" target="#fig_8">9</ref> shows the comparison on the validation set between the two networks at every 10 iterations. It is noticed that the network performances during training process without pre-processing layers are much worse than those with pre-processing layers, which demonstrates that pre-processing layers are necessary for improving network performance. In the following sections, only the networks with preprocessing layers are discussed.</p><p>Fig. <ref type="figure" target="#fig_8">9</ref>(a) shows the cost function values through iterations. The Config-B is slightly faster than the Config-A to reduce the cost function value. However, there is no significant difference after 700 iterations. In Fig. <ref type="figure" target="#fig_8">9</ref>(b), Config-B yields higher F-1 scores at the first 300 iterations compared with Config-A. In other words, Config-B learns faster at the beginning. This is reasonable because Leaky Rectified Tanh uses sigmoid-like function and may result in zero gradients due to saturation. In a general view, the Config-B yields more consistent F-1 scores.</p><p>However, for the first 1,000 iterations, the best F-1 score achieved by Config-A on validation data is better than that produced by Config-B (Table <ref type="table" target="#tab_0">I</ref>). The best F-1 score has little change from 1,000 to 3,000 iterations, thus the network   training is finally stopped after 3,000 iterations. As shown in Table <ref type="table" target="#tab_0">I</ref>, compared with Config-B, Config-A yields generally higher F-1 scores and particularly higher Recalls, indicating that Config-A is able to detect more shallow cracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. TESTING AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance on Testing Data</head><p>After the network training is completed with 3,000 iterations, the network parameters that yield the highest F1 score on validation data set are considered as optimal parameters. Based on the optimal parameters, the network performance is further evaluated using 500 testing images. Fig. <ref type="figure" target="#fig_9">10</ref> shows several representative outputs produced by CrackNet-V with Leaky Rectified Tanh. Table <ref type="table" target="#tab_1">II</ref> summarizes the performance of CrackNet-V on the testing data. It is noticeable that the performance on testing set shown in Table <ref type="table" target="#tab_1">II</ref> is similar to those on validation set in Table <ref type="table" target="#tab_0">I</ref>, indicating that the size of validation set is sufficient for assessing the overall network accuracy.</p><p>For CrackNet-V, there is no big difference between Config-A and Config-B. The F-1 score of Config-A (87.12%) is slightly better than that of Config-B (86.46%). In addition, both Precision and Recall of Config-A are similar to those of Config-B. On the other hand, although the parameters in CrackNet-V is roughly 17 times fewer than those of CrackNet, the F-1 score difference in between is very little. The F-1 score of CrackNet-V (87.12% or 86.46%) slightly surpasses the F-1 score produced by CrackNet (85.62%). CrackNet yields a high Precision up to 90.86%, while the Precision of CrackNet-V is roughly 84%. However, CrackNet-V can achieve a significantly higher Recall 90.12% in comparison with the Recall 80.96% resulted from CrackNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Leaky Rectified Tanh vs. Leaky ReLU</head><p>Comparing to traditional activation unit Leaky ReLU, CrackNet-V with the proposed Leaky Rectified Tanh has better performance in detecting shallow cracks, as illustrated in Fig. <ref type="figure" target="#fig_10">11</ref>. Fig. <ref type="figure" target="#fig_10">11(a</ref>) and (b) show several typical shallow cracks with 3D effect. These shallow cracks are difficult to be perceived even by human eyes under the 3D environment. In Fig. <ref type="figure" target="#fig_10">11(c</ref>), CrackNet-V with activation unit Leaky ReLU tends to detect cracks whose depths exceed certain values, while omitting the shallow cracks. On the other hand, CrackNet-V with Leaky Rectified Tanh can yield more accurate detection on shallow cracks, as illustrated in Fig. <ref type="figure" target="#fig_10">11(d)</ref>. The bounding property of Leaky Rectified Tanh intends to minimize the difference between a shallow crack and a deep crack, and thus encourages the network to learn more geometrical features of cracks instead of being purely dependent on the depth information.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CrackNet-V vs. CrackNet</head><p>The testing data are 500 images that do not participate in training process. The CrackNet-V is comparable to Crack-Net in terms of overall performance. Generally, CrackNet-V is more robust in detecting fine or shallow cracks, while CrackNet performs better for wide cracks. Fig. <ref type="figure" target="#fig_11">12</ref> and  Fig. <ref type="figure" target="#fig_11">12</ref>(a) and (b) show some typical fine cracks under 3D environment locating on the right-side of the images. In Fig. <ref type="figure" target="#fig_11">12(c</ref>), CrackNet is able to detect most cracks in the middle but misses some fine cracks on the right-side, although these fine cracks have no obvious changes in width compared with other cracks in the middle. A possible reason is that these fine cracks are not fully extracted by the pre-designed filters used in CrackNet due to their shallow depths. In Fig. <ref type="figure" target="#fig_11">12(d)</ref>, the fine cracks missed by CrackNet are captured by CrackNet-V successfully. In other words, CrackNet-V is more sensitive to fine cracks, which probably benefits from the use of filter kernels with extremely small size (3 × 3).</p><p>In Fig. <ref type="figure" target="#fig_12">13</ref>, however, CrackNet outperforms CrackNet-V in detecting wide cracks. Fig. <ref type="figure" target="#fig_12">13</ref>(a) and (b) show some wide cracks near the pavement markers on the left-side of images. In Fig. <ref type="figure" target="#fig_14">13(c</ref>), CrackNet is able to detect the whole of wide cracks near the markers. In Fig. <ref type="figure" target="#fig_14">13(d</ref>), CrackNet-V only recognizes parts of the wide cracks while missing some wide parts, which is probably caused by the adverse impacts of small filters. Even though the successive layers with small filters theoretically represent a wide range of local receptive fields, the wide cracks could not be completely perceived by such small filters.</p><p>In summary, the small size of filter kernels used in CrackNet-V has both advantage and disadvantage. On the one hand, small filters concentrate on feature extraction in small receptive field, thus they are more sensitive and efficient in detecting fine cracks. On the other hand, small filters in successive layers could not perfectly represent a wide receptive field, resulting in partial detection of wide cracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. CrackNet-V vs. CrackForest (SVM)</head><p>In order to better assess the performance of CrackNet-V, a road crack detection framework called CrackForest is introduced for a comparison study on the public dataset named CFD <ref type="bibr" target="#b57">[58]</ref>. This CFD dataset consists of 118 urban road surface images with manually labeled ground truths. In the paper, 60% images from the CFD dataset are randomly selected as training data, and the rest 40% images are used for testing. As CFD dataset is composed of color images, the original pre-processing layer for 3D surface data is removed from CrackNet-V. Instead, the color images from CFD dataset are converted to gray-scale images, and then normalized for a uniform data range between -1 and 1.</p><p>The comparison results between CrackForest (SVM) <ref type="bibr" target="#b57">[58]</ref> and CrackNet-V (Config-A) are shown in Fig. <ref type="figure" target="#fig_13">14</ref>, and the summary statistics are in Table <ref type="table" target="#tab_2">III</ref>. Fig. <ref type="figure" target="#fig_13">14</ref> and<ref type="figure">Table III</ref> show that the CrackForest (SVM) generates 89.44% recall and 82.28% precision. CrackNet-V (Config-A) yields 86.03% recall, slightly lower than that of CrackForest. However, CrackNet-V results in a much higher precision 92.58%, indicating that CrackNet-V can eliminate more noises. The overall F1 score of CrackNet-V is 89.18% versus 85.71% of CrackForest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Network Speed</head><p>As the number of parameters is much fewer than that of CrackNet, CrackNet-V is more time-efficient.  four days. With the aid of the same GPU device, by contrast, the time of forward pass and backward pass for CrackNet-V are 0.33 and 2.28 second respectively. As a result, the training time takes only one day. Generally, CrackNet-V is about 3-4 times faster than CrackNet. The improved computational efficiency of CrackNet-V is beneficial for real-time processing in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS AND FUTURE WORK</head><p>In this paper, an efficient and improved version of CrackNet called CrackNet-V is described for pixel-level automated crack detection on 3D asphalt pavements. Similar to CrackNet, CrackNet-V does not use pooling layers that downsize original data for explicit requirements on pixel-perfect accuracy. Following the VGG network, all filters used at the first six convolutional layers have fixed small size of 3×3. Through the stack of multiple 3 × 3 convolutional layers, the CrackNet-V is capable of representing receptive fields larger than 3 × 3, while reducing the number of parameters significantly. The CrackNet-V only introduces 64,113 parameters which are much fewer than the parameters of CrackNet. In addition, the successive convolutional layers used in CrackNet-V also result in efficient feature extraction. To enhance the capability of detecting shallow cracks, Leaky Rectified is proposed in this paper to minimize the difference between a shallow crack and a deep crack in terms of depth value. It is demonstrated that the proposed Leaky Rectified Tanh activation function yields more accurate detection on shallow cracks than that based on the traditional Leaky ReLU.</p><p>According to the overall performances on 500 testing images, the well-trained CrackNet-V slightly outperforms CrackNet in terms of F-1 score. Particularly, the Recall of CrackNet-V (90.12%) is much higher than that of Crack-Net (80.96%), indicating more cracks can be found through CrackNet-V. It is also demonstrated that CrackNet-V is more robust in detecting fine and shallow cracks, although its performance on wide cracks is worse than CrackNet. In addition, compared with the SVM-based CrackForest method, CrackNet-V also achieves better F1 score on the public CFD dataset, which reveals the potentials of deep learning in crack detection. Moreover, CrackNet-V is about 3-4 times faster than CrackNet due to fewer parameters. Such improved computational efficiency can enhance the application of CrackNet-V in real-time processing in the future.</p><p>Although CrackNet-V is effective for most 3D asphalt images, it could suffer the limitations caused by the extremely small size of filters. Particularly, the detection accuracy on wide cracks are still not satisfying. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. DHDV (WayLink) and 1-mm resolution 3D pavement data.</figDesc><graphic coords="2,316.55,58.37,109.70,61.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples from image library. (a) Raw pavement images. (b) Manually labeled ground-truths.</figDesc><graphic coords="3,84.95,218.57,441.62,194.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Architecture of CrackNet-V.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. A stack of two consecutive 3 × 3 conv. layers represent an effective receptive field of 5 × 5. (a) Two consecutive 3 × 3 conv. layers. (b) One 5 × 5 conv. layer.</figDesc><graphic coords="3,329.99,457.01,117.86,93.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Comparison between original and pre-processed 3D Data in OpenGL. (a) Sample image before pre-processing. (b) Sample image after pre-processing.</figDesc><graphic coords="4,312.47,58.97,249.86,111.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Comparison between Leaky Rectified Tanh and Leaky ReLU.</figDesc><graphic coords="5,86.03,58.61,177.02,128.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparison between the LeCun Tanh unit and traditional sigmoid unit. (a) Activated units comparison. (b) The first order derivatives comparison.</figDesc><graphic coords="5,83.99,338.21,180.50,96.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Validation set for monitoring network performance during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Performance comparison on validation set during training. (a) Cost function comparison. (b) F-1 measure (%) comparison.</figDesc><graphic coords="7,150.71,218.45,102.14,51.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Representative detection results of CrackNet-V (Config.A).</figDesc><graphic coords="7,149.76,385.22,102.00,51.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Comparison between Leaky ReLU and Leaky Rectified Tanh in CrackNet-V. (a) 3D testing images. (b) 3D rendering of testing images. (c) Detection results of Leaky ReLU. (d) Detection results of Leaky Rectified Tanh.</figDesc><graphic coords="8,67.79,249.29,102.62,51.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Comparison between CrackNet and CrackNet-V (Config-A) on fine cracks. (a) 3D testing images. (b) 3D rendering of testing images. (c) Detection results of CrackNet. (d) Detection results of CrackNet-V.</figDesc><graphic coords="8,332.51,358.49,101.90,51.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Comparison between CrackNet and CrackNet-V (Config-A) on wide cracks. (a) 3D testing images. (b) 3D rendering of testing images. (c) Detection results of CrackNet. (d) Detection results of CrackNet-V.</figDesc><graphic coords="8,330.83,549.53,102.62,51.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Comparison between CrackForest (SVM) and CrackNet-V (Config-A) on CFD dataset. (a) Original testing images. (b) Detection results of CrackForest (SVM). (c) Detection results of CrackNet-V (Config-A).</figDesc><graphic coords="9,106.26,183.69,76.50,51.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 13</head><label>13</label><figDesc>Fig.13illustrate the comparison between CrackNet and CrackNet-V in detecting fine cracks and wide cracks respectively.Fig.12(a) and (b) show some typical fine cracks under 3D environment locating on the right-side of the images. In Fig.12(c), CrackNet is able to detect most cracks in the middle but misses some fine cracks on the right-side, although these fine cracks have no obvious changes in width compared with other cracks in the middle. A possible reason is that these fine cracks are not fully extracted by the pre-designed filters used in CrackNet due to their shallow depths. In Fig.12(d), the fine cracks missed by CrackNet are captured by CrackNet-V successfully. In other words, CrackNet-V is more sensitive to fine cracks, which probably benefits from the use of filter kernels with extremely small size (3 × 3).In Fig.13, however, CrackNet outperforms CrackNet-V in detecting wide cracks. Fig.13(a) and (b) show some wide cracks near the pavement markers on the left-side of images. In Fig.13(c), CrackNet is able to detect the whole of wide cracks near the markers. In Fig.13(d), CrackNet-V only recognizes parts of the wide cracks while missing some wide parts, which is probably caused by the adverse impacts of small filters. Even though the successive layers with small filters theoretically represent a wide range of local receptive fields, the wide cracks could not be completely perceived by such small filters.In summary, the small size of filter kernels used in CrackNet-V has both advantage and disadvantage. On the one hand, small filters concentrate on feature extraction in small receptive field, thus they are more sensitive and efficient in detecting fine cracks. On the other hand, small filters in successive layers could not perfectly represent a wide receptive field, resulting in partial detection of wide cracks.</figDesc><graphic coords="9,185.76,183.69,76.50,51.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Future developments can be conducted to enlarge the receptive fields by stacking more 3 × 3 convolutional layers or other means. Most importantly, both the CrackNet-V and the original CrackNet successfully demonstrate a promising approach to automated pixel-level pavement crack detection via learning from diverse examples with the aid of advanced deep learning techniques. Yue Fei received the B.S. degree in computer and communication engineering from Southwest Jiaotong University, Chengdu, China, in 2011, and the M.S. degree in civil engineering from Oklahoma State University-Stillwater, Stillwater, OK, USA, in 2015, where he is currently pursuing the Ph.D. degree in civil engineering. From 2013 to 2018, he was a Research Assistant in civil engineering. His research interests include development of automated pavement survey using digital image processing, computer vision, and machine learning. Kelvin C. P. Wang received the B.S. degree from Southwest Jiaotong University, China, the M.S. degree from Beijing Jiaotong University, China, and the Ph.D. degree from Arizona State University. His professional career started at Arizona DOT in 1989, where he has been a university faculty since 1993. He is currently a Professor of civil engineering with Oklahoma State University-Stillwater, where he holds the Dawson Chair. He received the ASCE 2011 Frank M. Masters Transportation Engineering Award and the ASCE 2018 Turner Award. He was the President of the Transportation and Development Institute of the American Society of Civil Engineers for FY 2017.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COMPARISON</head><label>I</label><figDesc>BETWEEN Leaky Rectify Tanh AND Leaky ReLU ON VALIDATION DATA</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II COMPARISON</head><label>II</label><figDesc></figDesc><table /><note><p>BETWEEN CRACKNET AND CRACKNET-V ON TESTING DATA</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III COMPARISON</head><label>III</label><figDesc>BETWEEN CRACKFOREST AND CRACKNET-V ON CFD</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Table IV summarizes the speeds of CrackNet and CrackNet-V on a single 512 × 256 image. With a single GPU device NVidia GeForce GTX 1080Ti, the time of forward pass and backward pass for CrackNet are 1.21 and 8.25 second respectively, and the training of CrackNet using 512 × 256 images normally needs</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV AVERAGE</head><label>IV</label><figDesc>NETWORK SPEEDS ON SINGLE 512 × 256 IMAGE</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the National Natural Science Foundation of China under Grant U1534203. The Associate Editor for this paper was S. S. Nedevschi.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A study of manual vs. automated pavement condition surveys</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Timm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
		<idno>IR-04-01</idno>
	</analytic>
	<monogr>
		<title level="j">Highway Res. Center, Auburn Univ</title>
		<imprint>
			<date type="published" when="2004-04">Apr. 2004</date>
			<pubPlace>Auburn, AL, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comprehensive system for AASHTO PP67-10 based asphalt surfaced pavement cracking evaluation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can. J. Civil Eng</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cracking classification using minimum rectangular cover-based support vector machine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Civil Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4017027</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pavement crack width measurement based on laplace&apos;s equation for continuity and unambiguity</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Braham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="DOI">10.1111/mice.12319</idno>
	</analytic>
	<monogr>
		<title level="j">J. Comput.-Aided Civil Infrastruct. Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="123" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Primitive-based classification of pavement cracking images</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Koutsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Transp. Eng</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="418" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Surface defects detection for ceramic tiles using image processing and morphological techniques</title>
		<author>
			<persName><forename type="first">H</forename><surname>Elbehiery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hefnaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elewa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. World Acad. Sci., Eng. Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="158" to="162" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Digital image processing for pavement distress analyses</title>
		<author>
			<persName><forename type="first">E</forename><surname>Teomete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Smadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Mid-Continent Transp</title>
		<meeting>Mid-Continent Transp</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Pavement crack detection system through localized thresholding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Katakam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Toledo, OH, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>College Eng., Univ. Toledo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic road crack segmentation using entropy and image dynamic thresholding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Correia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Eur. Signal Process</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A crack detection method in road surface images using morphology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uematsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Mach</title>
		<meeting>Workshop Mach</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="154" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image analysis and mathematical morphology for civil engineering materials</title>
		<author>
			<persName><forename type="first">M</forename><surname>Coster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Chermant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cement Concrete Composites</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="133" to="151" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A robust approach for automatic detection and segmentation of cracks in underground pipeline images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="921" to="933" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wavelet-based pavement distress classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-P</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. Rec., J. Transp. Res. Board</title>
		<imprint>
			<biblScope unit="volume">1940</biblScope>
			<biblScope unit="page" from="89" to="98" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Wavelet-based pavement distress image edge detection with a trous algorithm</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Transp. Res. Board, Transp. Res. Rec</title>
		<imprint>
			<biblScope unit="volume">2024</biblScope>
			<biblScope unit="page" from="73" to="81" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Introduction of a wavelet transform based on 2D matched filter in a Markov random field for fine structure extraction: Application on road crack detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Subirats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dumoulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2009-02">Feb. 2009</date>
			<biblScope unit="volume">7251</biblScope>
			<biblScope unit="page">72510</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using wavelet technology for pavement crack detection</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Q</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Logistics Eng. Manage</title>
		<meeting>Int. Conf. Logistics Eng. Manage</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">387</biblScope>
			<biblScope unit="page" from="2482" to="2487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wavelet transform on multi-GPU for real-time pavement distress detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Georgieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>König</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. J. Comput. Civil Eng</title>
		<meeting>J. Comput. Civil Eng</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="99" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detection of blood vessels in retinal images using two-dimensional matched filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="269" />
			<date type="published" when="1989-09">Sep. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Classification of painting cracks for content-based analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Abas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2003-05">May 2003</date>
			<biblScope unit="volume">5011</biblScope>
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automation of pavement surface crack detection with a matched filtering to define the mother wavelet function used</title>
		<author>
			<persName><forename type="first">P</forename><surname>Subirats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Legeay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Signal Process. Conf</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Matched filtering algorithm for pavement cracking detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Transp. Res. Rec</title>
		<imprint>
			<biblScope unit="volume">2367</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A neural network-based methodology for pavement crack detection and classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kaseko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Ritchie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. C, Emerg. Technol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="275" to="291" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pavement distress classification using neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst</title>
		<meeting>IEEE Int. Conf. Syst</meeting>
		<imprint>
			<date type="published" when="1994-10">Oct. 1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="397" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Airport pavement distress image classification using moment invariant neural network</title>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Asian Conf. Remote Sens</title>
		<meeting>Asian Conf. Remote Sens</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="216" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic detection and classification of defect on road pavement using anisotropy measure</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Begot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Eur. Signal Process. Conf</title>
		<meeting>17th Eur. Signal ess. Conf<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-08">Aug. 2009</date>
			<biblScope unit="page" from="617" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new technique for automatic detection and parameters estimation of pavement crack</title>
		<author>
			<persName><forename type="first">G</forename><surname>Moussa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Int. Multi-Conf. Eng</title>
		<meeting>4th Int. Multi-Conf. Eng<address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic road distress detection and analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Preeja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="18" to="23" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient system of cracking-detection algorithms with 1-mm 3D-surface models and performance measures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Civil Eng</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">4016020</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated pixel-level pavement crack detection on 3D asphalt surfaces using a deep-learning network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput.-Aided Civil Infrastruct. Eng</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="805" to="819" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Learning</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning from simulated and unsupervised images through adversarial training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Susskind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Webb</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1612.07828" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1609.04802" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Traffic flow prediction with big data: A deep learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="865" to="873" />
			<date type="published" when="2015-04">Apr. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An efficient realization of deep learning for traffic data imputation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transp. Res. C, Emerg. Technol</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="168" to="181" />
			<date type="published" when="2016-11">Nov. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Short-term forecasting of passenger demand under on-demand ride services: A spatio-temporal deep learning approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Transp. Res. C, Emerg. Technol</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="591" to="608" />
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1409.4842" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learn. Represent</title>
		<meeting>Int. Conf. Learn. Represent</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Road crack detection using deep convolutional neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Image Process</title>
		<meeting>IEEE Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2016-09">Sep. 2016</date>
			<biblScope unit="page" from="3708" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep learning-based crack damage detection using convolutional neural networks</title>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Büyüköztürk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput.-Aided Civil Infrastruct. Eng</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="361" to="378" />
			<date type="published" when="2017-05">May 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">3D shadow modeling for detection of descended patterns on 3D pavement surface</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Civil Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">4017019</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Automated survey of pavement distress based on 2D and 3D laser images</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tracy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>Fayetteville, AR, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Mack-Blackwell Transp. Center, Univ. Arkansas</orgName>
		</respStmt>
	</monogr>
	<note>Tech. Rep. MBTC-3023</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.6806" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 30th ICML</title>
		<meeting>30th ICML</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Efficient BackProp</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<meeting><address><addrLine>London, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="9" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">An introduction to ROC analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Accelerated learning in layered neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fleisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="625" to="640" />
			<date type="published" when="1988-12">Dec. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="951" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Hagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Demuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Beale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Jesús</surname></persName>
		</author>
		<title level="m">Neural Network Design</title>
		<meeting><address><addrLine>Stillwater, OK, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Oklahoma State Univ</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automatic road crack detection using random structured forests</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3434" to="3445" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
