<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Noise Removal Using Smoothed Normals and Surface Fitting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marius</forename><surname>Lysaker</surname></persName>
							<email>mariul@simula.no</email>
						</author>
						<author>
							<persName><forename type="first">Stanley</forename><surname>Osher</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xue-Cheng</forename><surname>Tai</surname></persName>
							<email>tai@mi.uib.no</email>
						</author>
						<author>
							<persName><forename type="first">Fernando</forename><forename type="middle">M B M</forename><surname>Pereira</surname></persName>
						</author>
						<author>
							<persName><surname>Lysaker</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Scientific Computing</orgName>
								<orgName type="laboratory">Simula Research Laboratory AS</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Mathematics</orgName>
								<orgName type="institution">Henan University</orgName>
								<address>
									<postCode>475001</postCode>
									<settlement>Kaifeng</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Bergen</orgName>
								<address>
									<postCode>N-5008</postCode>
									<settlement>Bergen</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90024</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Noise Removal Using Smoothed Normals and Surface Fitting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6CD4544C45E892F516678917BC0A42C8</idno>
					<idno type="DOI">10.1109/TIP.2004.834662</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Anisotropic diffusion</term>
					<term>image denoising</term>
					<term>nonlinear partial differential equations (PDEs)</term>
					<term>normal processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we use partial differential equation techniques to remove noise from digital images. The removal is done in two steps. We first use a total-variation filter to smooth the normal vectors of the level curves of a noise image. After this, we try to find a surface to fit the smoothed normal vectors. For each of these two stages, the problem is reduced to a nonlinear partial differential equation. Finite difference schemes are used to solve these equations. A broad range of numerical examples are given in the paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A digital image can contain random noise superimposed on the pixel intensity value by the formula <ref type="bibr" target="#b0">(1)</ref> We would like to recover the true image from its noisy observation . Noise is recognized as rapidly oscillating signals and can, therefore, be removed by the process of low-pass filtering or smoothing, unfortunately at the expense of some high-frequency information (i.e. edges). Wavelet-based methods, statistical methods, and diffusion filter methods have successfully been used to remove noise from digital images. Wavelet methods exploit the decomposition of the data into the wavelet basis and shrink the wavelet coefficients in order to denoise the images <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. However, the space of functions of bounded variation, which allows for edges in our reconstruction, cannot be used easily with wavelet based methods. For statistical methods used in image restoration, we refer to the nonlinear median-type filters <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>. Median and mean filters replace every pixel of an image with respectively the median and the arithmetic mean of the pixels contained in a window around the pixel. Mean filtering is usually used for suppressing Gaussian noise while median filtering is a powerful tool for removing impulse-like noise. However, in this work, we are more engrossed by diffusion filters coming from partial differential equations (PDEs). In the end of Section II, we outline some benefits inherited with this approach. Among various PDE techniques proposed in the literature, let us mention <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref>. The TV-norm filter proposed in <ref type="bibr" target="#b6">[7]</ref> gives a rigorous mathematical tool to introduce nonlinear diffusion filters and it has been used as a regularization method for many other applications where one needs to identify discontinuous functions. The TV-norm filter preserves edges but has the sometimes undesirable staircase effect, meaning that smooth functions are transformed into piecewise constants. To overcome this problem (but, then, maybe sacrifice the good property of TV norm on the edges), many other nonlinear filters have been suggested in the literature, and, during the last few years, higher order PDEs have been of special interest <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b15">[16]</ref>. The method we shall use in this paper is somewhat related to the methods using higher order PDEs. We solve two second-order nonlinear PDEs sequentially. If we combine the two equations together, we would need to solve one higher order nonlinear PDE. To be more precise, our method is a two-step method. In the first step, we smooth the normal vectors of the level set curves of the noise image using a TV-norm filter. After the normal vectors are smoothed, we try to find an image that fits the normal vectors and this image is taken as the recovered image for the corrupted observation.</p><p>Our method is related to some techniques already in the literature. In Kenney and Langan <ref type="bibr" target="#b16">[17]</ref>, a method to restore images from modified flow field was proposed. In its simplest form, this process takes a single image, modifies its gradient field, and then constructs a new image from the modified field. They introduce an objective function based on a flow field to implicitly determine the edges of the image.</p><p>The idea we use in this paper is more inspired by the work <ref type="bibr" target="#b17">[18]</ref>. In that work, they tried to process three dimensional surfaces. The essential idea was to manipulate the normal vectors for a given three dimensional surface and then find a new surface that matches the processed normal vectors in a suitable way. In this work, we are extending the idea of <ref type="bibr" target="#b17">[18]</ref> to do image noise removal. Further, we would like to mention that normal processing has also been used in shape from shading reconstruction <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> and in mesh optimization <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>.</p><p>Another closely related paper is the inpainting approach of <ref type="bibr" target="#b22">[23]</ref>. In this paper, they try to minimize an energy functional with respect to two variables: a vector field which represents the direction of the level curves of and the intensity value . Note that image denoising is quite different from inpainting. In <ref type="bibr" target="#b22">[23]</ref>, they clearly point out how shape recovery is achieved by first computing the vector field approximately, and then include this information to the reconstruction process.</p><p>We also utilized this idea in our algorithm. In fact, the functional for the minimization problem we solve in the second step is identical to one of the terms in the inpainting functional of <ref type="bibr" target="#b22">[23]</ref>. Another closely related work is <ref type="bibr" target="#b23">[24]</ref>. That paper deals with minimization of constrained functionals, and in particular with -harmonic maps. For a vector valued function , they proposed an elegant way of solving <ref type="bibr" target="#b1">(2)</ref> with Dirichlet or Neumann boundary conditions. The tools we shall use to smooth the normal vectors are closely related to problem <ref type="bibr" target="#b1">(2)</ref>. In our approach, we are essentially taking and in (2), and we add a fidelity term to balance the smoothing and the edge preserving [see <ref type="bibr" target="#b5">(6)</ref>].</p><p>Moreover, the approach we propose here is also strongly motivated by the fourth-order method proposed in <ref type="bibr" target="#b10">[11]</ref> and the second-order method <ref type="bibr" target="#b6">[7]</ref>. The original TV-norm filter is to obtain a restored image as a solution of the constrained optimization problem subject to <ref type="bibr" target="#b2">(3)</ref> where denotes the variance of the noise. In order to overcome the stair-case effects, it was suggested in <ref type="bibr" target="#b10">[11]</ref> to replace the cost functional in (3) by or (4)</p><p>With these minimization functionals, we try to minimize the total variational norm of instead of . Rather good numerical performance was obtained in <ref type="bibr" target="#b10">[11]</ref>. We could go one step further. Instead of minimizing the TV norm of or , we could minimize the TV norm of , i.e.</p><p>subject to <ref type="bibr" target="#b4">(5)</ref> We know that is the unit normal vectors for the level curves of . However, the Euler-Lagrange equation obtained by minimizing the above functional is hard to solve numerically because of the restrictive time step needed. In this paper, we propose to split this into two steps, i.e., we first smooth the unit normal vectors and then find a surface to fit the obtained normal vectors.</p><p>For images with discontinuities, the algorithm proposed here is clearly an improved version of the noise removal algorithm of <ref type="bibr" target="#b24">[25,</ref><ref type="bibr">Section 4.2]</ref>. In <ref type="bibr" target="#b24">[25]</ref>, the functions that need to be smoothed are always continuous.</p><p>This paper is organized in the following way. In Section II, we introduce the two-step method we use for noise removal. Details are given to show how we obtain and solve the associated nonlinear PDEs coming from the two-step method. Finite difference approximations and some implementation details are explained in Section III. Numerical results are given in Section IV. In the numerical experiments, we compare our method with some related algorithms in the literature. Finally, we have a Conclusion section followed by an Appendix, where we describe a transformation used in Section II.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. FLOW FIELD SMOOTHING AND SURFACE FITTING</head><p>For a given image , is the unit normal vector of the level curves of . For the noisy image , we shall try to smooth the normal vectors . To avoid numerical problems at low gradients, a small constant is added in the calculation of the gradient magnitude, i.e.</p><p>is substituted by , turning the process into a convex one. Because the normal vectors can be discontinuous vector functions we use the TV norm to do the smoothing. Similar to <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, we add a fidelity term to balance the smoothing and edge capturing. To be more precise, we use a two-parameter method, one parameter controls the flow field smoothing and another parameter controls the surface fitting such that large deviation from their initial state will be penalized. The following minimization problem is solved to get a smoothed flow field (i.e., normal vectors): <ref type="bibr" target="#b5">(6)</ref> Presently, we are investigating several ways to select dynamically, but for all simulations given in this paper, the value of is fixed to a positive constant. At the end of this section, we give some advice on how to choose this constant.</p><p>Once the flow field is calculated, we want to find an image that matches this field. There are different ways to do this. In this work, we try to find a that solves the following minimization problem <ref type="bibr" target="#b6">(7)</ref> where is the smoothed normals obtained from (6). In the above, is the noise level in norm, and we assume it to be approximately known or that it can be estimated <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref>. For example, in <ref type="bibr" target="#b27">[28]</ref>, they proposed a statistical approach for blind estimation of noise variance. In 98% of the cases they evaluated, the relative estimation error was less than 0.2 with an average error of 0.06. In case the noise level is not known or the above estimation algorithms cannot be applied successfully, we just add a fidelity term to the minimization functional <ref type="bibr" target="#b6">(7)</ref> and drop the noise level constraint.</p><p>Assume that is the angle between and , it is clear that the functional <ref type="bibr" target="#b7">(8)</ref> is always nonnegative. Heuristically, is orthogonal to the level lines of , meaning that when ( <ref type="formula">8</ref>) is minimized, the function is constructed such that is constant along the integral curves of .</p><p>We shall use a Lagrange multiplier to deal with the noise constraint . The Lagrange functional is defined as (9) To find a minimizer for <ref type="bibr" target="#b6">(7)</ref>, we need to find the saddle points for . The optimality conditions for the saddle points are in on ( <ref type="formula">10</ref>) and ( <ref type="formula">11</ref>)</p><p>In <ref type="bibr" target="#b9">(10)</ref>, is the outwards unit normal vector on the boundary . It is not easy to find the minimizer for <ref type="bibr" target="#b5">(6)</ref>. We shall use ideas from <ref type="bibr" target="#b23">[24]</ref>. As is a unit vector, we use polar coordinate to represent it, i.e.</p><p>. It is known that <ref type="bibr" target="#b11">(12)</ref> (see the Appendix for the details of the calculations). Thereupon, ( <ref type="formula">6</ref>) becomes <ref type="bibr" target="#b12">(13)</ref> The optimality condition for for the above problem is <ref type="bibr" target="#b13">(14)</ref> Thereafter, we introduce an artificial time variable and note that is the steady state of the following equation:</p><p>One could solve directly from the above equation. One of the troubles is that can be multivalued. As an alternative, we note that (c.f. <ref type="bibr" target="#b23">[24]</ref>) and and with the notation , it follows from (15) that <ref type="bibr" target="#b15">(16)</ref> We know that , which gives us , so ( <ref type="formula">16</ref>) can be separated into <ref type="bibr" target="#b16">(17)</ref> and <ref type="bibr" target="#b17">(18)</ref> To find the values of and satisfying <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref>, we also introduce an artificial time variable and solve the following equation to steady state <ref type="bibr" target="#b18">(19)</ref> The value of also needs to be determined in such a way that the above equation has a steady state and the condition ( <ref type="formula">11</ref>) is fulfilled at the steady state. We use the noise level constraint ( <ref type="formula">11</ref>) and ( <ref type="formula">10</ref>) to obtain such a formula for . Using the same idea as in <ref type="bibr" target="#b6">[7]</ref>, we multiply <ref type="bibr" target="#b9">(10)</ref> by and integrate over to get (20) Using Green's theorem, we get the following formula for : <ref type="bibr" target="#b20">(21)</ref> In the numerical simulations, an explicit finite difference scheme is used to calculate . The value of at each time level is updated according <ref type="bibr" target="#b20">(21)</ref>, see (30). In order to update using the above formula, we need to know the noise level approximately. In case that the noise level is not known, we can just fix a constant value for by trial and error. If we use a bigger value for the noise level , the restored image will be smoother. If we use a smaller value for the noise level, the algorithm is adding less diffusion to the image. Accordingly, the restored image will have better edge preservation, but the amount of noise removed from the image is also less in such a case.</p><p>In our simulations, we do not have a dynamic updating formula for and this parameter was chosen by trial and error. By inspecting ( <ref type="formula">17</ref>) and ( <ref type="formula">18</ref>) we see that is not a good choice since the dominating term then are <ref type="bibr" target="#b21">(22)</ref> Solve <ref type="bibr" target="#b21">(22)</ref> to steady state will force and . In this way, and will be as noisy as their observations and no progress is made. On the other hand, if <ref type="bibr" target="#b22">(23)</ref> would be the dominating part. Both equations in <ref type="bibr" target="#b22">(23)</ref> reach steady state when and , meaning that and are very smooth. A consequence of the extremity constant and constant is that ( <ref type="formula">19</ref>) approaches the TV norm proposed in <ref type="bibr" target="#b6">[7]</ref> (see the Appendix for details). Depending on the amount of noise, we found to be a good choice. Advantages: The proposed system of second-order PDEs are capable to restore edges and discontinuities in a better way than fourth-order PDEs and avoid the explicit computation of unstable higher order derivatives. Advantages over the classical TV minimization are that our model can recover smooth subsurfaces and that it is more general (see the Appendix for details). An alternative approach for smoothing the flow field could be to use Gaussian filtering techniques directly on ( , ) to get ( , ). This approach roughly halve the computing time of our two-step algorithm since ( <ref type="formula">17</ref>) and ( <ref type="formula">18</ref>) in step one are replaced with Gaussian filtering. However, the major disadvantage of classical Gaussian filtering techniques is the uniform smoothing in all directions of the flow field and fine details are easily destroyed with these filters. Furthermore, solving ( <ref type="formula">17</ref>) and ( <ref type="formula">18</ref>) guarantee that at each iteration and this constraint is not necessarily satisfied everywhere if Gaussian filters are used to smooth the flow field.</p><p>Disadvantages: One of the drawbacks of the proposed method is the lack of a rigorous theory. We observe that our algorithm produces good results even though we still do not have any solid theoretical justification for this successful performance. Further, since we solve two second-order nonlinear PDEs sequentially, there may be a loss of efficiency compared with other second-order nonlinear PDE methods. For instance, the classical TV model is roughly twice as fast as the proposed model due to the performance of normal smoothing in the proposed model. Moreover, this is a two-parameter method and the parameter must be found by trial and error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. IMPLEMENTATION</head><p>We discretize the system ( <ref type="formula">17</ref>) and ( <ref type="formula">18</ref>) by finite differences and for simplicity we introduce and Details of how to discretize in space will follow the same scheme as for described in (29). The following semi-implicit scheme of <ref type="bibr" target="#b23">[24]</ref> is used to solve and :</p><formula xml:id="formula_1">(24) (25)</formula><p>To solve the previous algebraic system is used in <ref type="bibr" target="#b23">(24)</ref> to get <ref type="bibr" target="#b25">(26)</ref> The unknown is collected on the right hand side and an explicit formula is obtained for <ref type="bibr" target="#b17">(18)</ref> [shown in <ref type="bibr" target="#b26">(27)</ref>, at the bottom of the page] and ( <ref type="formula">17</ref>) is approximated by the same technique [shown in <ref type="bibr" target="#b27">(28)</ref>, at the bottom of the next page]. From ( <ref type="formula">27</ref>) and <ref type="bibr" target="#b27">(28)</ref>, it is easy to calculate that As soon as steady state is reached for ( <ref type="formula">27</ref>) and ( <ref type="formula">28</ref>), we fix to be the components of the unit normal vector. Let us use the notation and for backward and forward difference at a given pixel . The numerical approximation to ( <ref type="formula">19</ref>) and ( <ref type="formula">21</ref>) is shown in (29) at the bottom of the next page. Here, we have used the notation ( <ref type="formula">27</ref>) The evaluation of is done similarly as shown in (29). The action is applied to the terms and . If we hold during the iterations between (29) and (30), the updating of (29) and ( <ref type="formula">30</ref>) is exactly the original TV-smoothing algorithm of <ref type="bibr" target="#b6">[7]</ref>. This means that the TV smoothing is trying to force the normal vectors to be (0,0) and the method proposed here is trying to force the normal vectors to be closed to the smoothed normals. This is one of the important reasons that the proposed is able to preserve edges and still gives good results in smooth regions.</p><p>To evaluate , we need . In order to overcome this problem in the simulations, we use the standard trick to replace by where is a small number. Normally, we choose to be very small (for <ref type="bibr" target="#b27">(28)</ref> (29) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>example</head><p>) and the value of does not seem to influence the results much. The same trick is used for the calculation of . To summarize, our noise removal approach is done in the following two steps.</p><p>1) Choose a positive and take to be the initial values for ( , ), solve ( <ref type="formula">27</ref>) and ( <ref type="formula">28</ref>) to steady state. 2) Take as the initial value for and let ( , ) be the value of the smoothed normals. Solve ( <ref type="formula">29</ref>) and (30) to steady state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. NUMERICAL RESULTS</head><p>In this part, we present some of the results obtained with our system of coupled equations. First of all, we wish to compare our result with two related methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Both <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref> have their strengths and weakness and it will be shown that our new method does an overall better job than both of them on the set of examples tested. The classical TV model from <ref type="bibr" target="#b6">[7]</ref> is known to give good results for almost all kinds of images. The chief criticism is that smooth regions are transformed into piecewise constant regions. On the other hand, the TV method works almost perfectly for block images. To avoid the staircase effect Lysaker-Lundervold-Tai <ref type="bibr" target="#b10">[11]</ref> suggested a fourth-order PDE. By construction, this approach allows linear changes in the intensity value and is therefore well suited for processing images with smooth transitions like a human face. From a theoretical point of view <ref type="bibr" target="#b10">[11]</ref> will not fulfill the good property of the TV method along edges. For the evaluations, we have used images like Fig. <ref type="figure" target="#fig_0">1</ref>, Fig. <ref type="figure">4</ref>, Fig. <ref type="figure">6</ref>, and some others to show the robustness, strength, and weakness for the different algorithms concerned her.</p><p>Example 1: In this first test, the well-known Lena image is corrupted with noise. From the original and noisy image, we calculate the original and noisy normal vectors. We use the noisy observations as input to our algorithm and in this specific test we have used . For better visualization, we have only plotted a small portion of the flow field for the images in Fig. <ref type="figure" target="#fig_1">2</ref>. The rectangle in Fig. <ref type="figure" target="#fig_1">2(a)</ref> indicates the area we have plotted.</p><p>The processed unit vectors point in the wrong directions some places in Fig. <ref type="figure" target="#fig_1">2(d</ref>), but it is certainly an improvement compared with Fig. <ref type="figure" target="#fig_1">2(c</ref>) where the normals more or less have a random orientation. Together with <ref type="bibr" target="#b18">(19)</ref> and ( <ref type="formula">21</ref>), we use the smoothed normals to restore a new image for the noisy one. The result is compared with the TV method (i.e. and ) and the fourth-order smoother <ref type="bibr" target="#b10">[11]</ref>. We also visualize the difference between the input and output image. In an ideal case, the difference image should only contain noise as indicated in Fig. <ref type="figure" target="#fig_0">1(c</ref>).</p><p>From the restored images in Fig. <ref type="figure" target="#fig_2">3</ref>, it is clear that much of the noise is suppressed. As expected, the TV algorithm transforms smooth regions into piecewise constant regions (see Lena's cheek). By evaluating the image of the difference between the smoothed image and the noisy image, it is obvious that neither the fourth-order smoother or the TV method are as good as our new method.</p><p>Example 2: A blocky image which should favor the TV method is used in this second test. Note that some of the objects  are as small as 2 2 pixels and other as narrow as 1 10 pixels. It is a nontrivial case to smooth out noise and simultaneously maintain all edges for an image like this.</p><p>The amount of noise is increased and we fix during the normal processing. With this kind of synthesized images almost everywhere in . Due to this, we do not show the unit normal vectors but just evaluate the final result. The restored image obtained with our method is also compared with the two methods mentioned above.</p><p>We see that all methods are able to suppress much noise, but some ghosts are visible in the image restored by the fourth-order scheme (around the narrow object of 1 10 pixels). This is not  surprising since the fourth-order scheme does not allow discontinuous jumps in the same way as the other two methods do. From Fig. <ref type="figure">5</ref>(f) it is clear that the fourth-order scheme filters out some edges, and in some sense the same is also observed in Fig. <ref type="figure">5(d)</ref>.</p><p>Example 3: Here, we try our new method on an image composed of four different Brodatz textures as given in Fig. <ref type="figure">6(a)</ref>.</p><p>Processing texture images is generally a hard task since fine texture details often are filtered out. The texture in the lower left and upper right part of Fig. <ref type="figure">6</ref>(a) mostly contains high frequency information (i.e. very oscillating intensity values) and can easily be mixed up with noise. From Fig. <ref type="figure">7</ref>(b), we see that this is the part of the image with the poorest result, but the main quality is maintained. Both Fig. <ref type="figure">7(d</ref>) and Fig. <ref type="figure">7</ref>(f) reveal oversmoothing for some of the fine structures. Methods like <ref type="bibr" target="#b11">[12]</ref> may be better suited to deal with texture images, but this example shows the robustness of our new algorithm.</p><p>In Fig. <ref type="figure" target="#fig_5">8</ref>, we visualize two results using different values for . The purpose of this test is to show that our algorithm is robust with respect to this parameter. We use the image depicted in Fig. <ref type="figure">6</ref>(b) as our observation data, but for better visualization, we only plot a small part of the lower left corner. By choosing , we smooth the flow field too much and the final image depicted in Fig. <ref type="figure" target="#fig_5">8</ref>(e) misses some details. Using , the flow field resembles its initial state and the full potential of the algorithm is not exploited. However, these deviations are hardly noticeable when evaluating the images in full scale.</p><p>We will end this section by showing some more results from a texture image, a MR image, a landscape image, and a satellite image. The rest of this paper will only deal with results obtained with our new method.</p><p>Our next example uses an image containing both a human face and some textures. The challenge with this image is to maintain both texture details and smooth transitions in the human face during processing.</p><p>The background and human feature like a hand, shoulder, and face is restored in a proper way, but the difference image tells us that textures on the scarf is smoothed to much (see Fig. <ref type="figure" target="#fig_6">9</ref>).</p><p>An image of leaves on a tree is evaluated next (see Fig. <ref type="figure" target="#fig_7">10</ref>). Restoration algorithms may have troubles with this kind of images due to the lack of connection in the image. Observe that the leaves are not smeared together and this is an important quality. The only negative remark is that the wire (going left from the top of the pole) disappeared in some places. The same effect was observed for the TV method and the fourth-order smoother. The result is not reported here, but both of them reconstruct an image which is almost as good as the one given in Fig. <ref type="figure" target="#fig_7">10(c</ref>).</p><p>In our next example, an MR image is corrupted with noise, see Fig. <ref type="figure" target="#fig_8">11</ref>. We use an image of a human brain, zoomed so it is possible to see all the fine features in the tissues. We see that the restoration algorithm is able to maintain all important information in the image, and in the same time filter out noise. This means that the intensity value is more accurately computed inside each tissue region after processing.</p><p>The final example concerns a satellite image. The recovered image coincides with the true one almost everywhere (c.f. Fig. <ref type="figure" target="#fig_9">12</ref>).</p><p>We have also carried out a qualitative evaluation of the different schemes. In real applications, the exact noise level is seldom known. To simulate such a case, the value we used for is not the true noise level, but an approximation for the true noise level. Let denote the true noise level and denote the noise level we used for the algorithm. We investigate the performance of the schemes using two different images. For the texture image Fig. <ref type="figure">6</ref>(b), we challenge the schemes by using a poor estimate for the amount of noise when we deal with the noise constraint . For Fig. <ref type="figure">4</ref>(b), we use the estimate . In Table <ref type="table" target="#tab_0">I</ref>, the reduction ratio of the error measured in norm is reported in the second and fourth columns, and the improvement ratio of SNR is reported in the third and fifth column. From Table <ref type="table" target="#tab_0">I</ref>, we see that our method gives noticeable better results than the two others. We obtain higher SNR improvements and the reduction ratio of the error (compared with the true image) measured in -norm are significant higher for the set of examples tested. We want to emphasize that several statistical approach <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref> can be used to get much closer estimation of noise variance than that which we evaluated in Table <ref type="table" target="#tab_0">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>A variational method for filtering gray-scale images corrupted by additive noise is proposed in this paper. Our method considers two second-order nonlinear PDEs which are solved sequentially. The interpretation is simple; first we denoise the normals for the level sets of the image intensity function, and, thereafter, we try to find an image which fits the smoothed normals. With this approach, geometric information of the level contours are incorporated in our image processing model. If we reject the smooth normals obtained in the first step, the image processing step reduces to the original TV method.</p><p>Numerical experiments substantiate that our composed method holds three important qualities; it is superior in recovering sharp edges of an image, and, second, it enhances the recovery of smooth subsurfaces contained in the image. Third, we have shown that it is easy to control the amount of smoothing with our method. APPENDIX a) We give the details for the calculations for <ref type="bibr" target="#b11">(12)</ref>. Given and (31)</p><p>The gradient matrix and its norm of the vector-valued function are respectively defined by and (32)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let</head><p>, it is easy to see that [shown in (33), at the bottom of the page] b) We illuminate some details concerning the original TV-norm filter <ref type="bibr" target="#b6">[7]</ref> and our approach. The restoration model we propose here can be interpreted as the steady state solution of the nonlinear diffusion process where (34) An interesting observation is that this PDE reduces to the PDE in <ref type="bibr" target="#b6">[7]</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Lena image. (a) Original image. (b) Noisy image SNR 20. (c) Difference image.</figDesc><graphic coords="4,44.64,65.74,504.00,134.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. For better visualization, we have only plotted the normal vectors in = (30; 65) 2 (30;67) indicated in (a) by the bright rectangular . (b) Original normals. (c) Noisy normals. (d) Processed normals.and is defined discretely via</figDesc><graphic coords="5,121.20,66.08,347.00,295.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Results for the Lena image. (a) Our new method. (b) Difference image. (c) TV method. (d) Difference image. (e) Fourth-order method. (f) Difference image.</figDesc><graphic coords="6,122.70,66.14,347.00,433.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Blocky image. (a) Original image. (b) Noisy image SNR 8. (c) Difference image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Brodatz image for evaluation. (a) Original image. (b) Noisy image SNR 9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Robustness of . (a) True normals. (b) Normals with = 2. (c) Normals with = 10. (d) True image (e) Processed using (b) and (f) processed using (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Image with a human face and some textures. (a) Original image. (b) Noisy image SNR 20. (c) Our result. (d) Difference image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Image with a tree and leaves. (a) Original image. (b) Noisy image SNR 7. (c) Our result. (d) Difference image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. MR brain image. (a) Original image. (b) Noisy image SNR 20. (c) Our result. (d) Difference image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Results for a satellite image. (a) Original image. (b) Noisy image SNR 5. (c) Our result. (d) Difference image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I EVALUATION</head><label>I</label><figDesc>OF SNR AND L -NORM FOR EACH OF THE SCHEMES</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Norwegian Research Council under project number 135302/320, in part by IMAR under Contract ICA1-CT-2000-70022 with the European Commission, and in part by the NSF under Grant DMS 0312222. The associate editor coordinating the review of this manuscript and approving it for publication was Dr.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stanley</head><p>Osher received the M.S. and Ph.D. degrees from the Courant Institute, New York University.</p><p>He was with Brookhaven National Laboratory, University of California, Berkeley, and the State University of New York, Stony Brook, and he has been with the University of California, Los Angeles (UCLA), since 1976. He is the Director of Special Projects at the Institute for Pure and Applied Mathematics, UCLA. He is the coinventor of level set methods for computing moving fronts (8600 references on GOOGLE, ENO, and WENO) and other numerical methods for computing solutions to hyperbolic conservation laws and Hamilton-Jacobi equations, and total variation and other PDE-based image processing techniques. He has confounded three companies, based, in part, on his own research. His work has been written up numerous times in the scientific and international media, e.g., Science News, Die Zeit (1999). He is a highly cited researcher according to web-of-science and an Associate Editor of five major journals.</p><p>Dr. Osher has been a Fulbright and Alfred P. Sloan Fellow, he received the NASA Public Service Group Achievement Award, the Japan Society of Mechanical Engineers Computational Mechanics Award, and was an invited speaker at the International Congress of Mathematicians, and recently received the SIAM Pioneer Prize at the ICIAM conference last summer.</p><p>Xue-Cheng Tai received the Licenciate degree in 1989 and the Ph.D. degree in 1991 in applied mathematics from Jyvaskalya University, Finland. The subject of his Ph.D. dissertation was on inverse problems and parallel computing.</p><p>After holding several research positions in Europe, he was employed as an Associate Professor in 1994 at the University of Bergen, Bergen, Norway and as a Professor since 1997. He has also worked as a parttime Senior Scientist at the private company Rogaland Research. He is now a member of the Center for Mathematics for Applications in Oslo, Norway, and a member of the Center of Integrated Petroleum Research, Bergen, Norway. His research interests include Numerical PDE for image processing, multigrid and domain decomposition methods, iterative methods for linear and nonlinear PDE problems, and parallel computing. He has educated numerous M.S. and Ph.D. students and has published more than 60 scientific papers. He has been a Reviewer and Editor for several international journals.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Filtering noise from images with wavelet transforms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yansun</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Cromwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Res. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="288" to="295" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ideal spatial adaptation via wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometr</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="425" to="455" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adapting to unknown smoothness via wavelet shrinkage</title>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">432</biblScope>
			<biblScope unit="page" from="1200" to="1224" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image denoising: a nonlinear robust statistical approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Krim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans.Signal Processing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="3045" to="3054" />
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Block-median pyramidal transform: analysis and denoising applications</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Melnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shmulevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Astola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="364" to="372" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Woods</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990-07">July 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive smoothing respecting feature directions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="353" to="358" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Anisotropic Diffusion in Image Processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<editor>B. G. Teubner</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Stutgart, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Noise removal using fourthorder partial differential equation with applications to medical magnetic resonance images is space and time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lysaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lundervold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">C</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1579" to="1590" />
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image decomposition and restoration using total variation minimization and the H norm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Interdisciplinary J</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="370" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Multiscale Modeling and Simulation: A</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">High-order total image restoration</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marquina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mulet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="503" to="516" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fourth-order partial differential equation for noise removal</title>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaveh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1723" to="1730" />
			<date type="published" when="2000-10">Oct. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Traveling wave solutions of fourth order PDE&apos;s for image processing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. California</orgName>
		</respStmt>
	</monogr>
	<note>Tech. rep. (03-25</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Low Curvature image simplifiers: Global regularity of Ssmooth solutions and Laplacian limiting schemes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Greer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
		<respStmt>
			<orgName>Univ. California, Los Angeles</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Kenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langan</surname></persName>
		</author>
		<title level="m">A New Image Processing Primitive: Reconstructing Images From Modified Flow Fields</title>
		<meeting><address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
		<respStmt>
			<orgName>Univ. California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Geometric surface processing via normal maps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1012" to="1033" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Robot Vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The variational approach to shape from shading</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K P</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Graph. Image Process</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="174" to="208" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mesh regularization and adaptive smoothing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Belyaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bogaevski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput.-Aided Design</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="789" to="800" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dual/primal mesh optimization for polygonized implicit surfaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ohtake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Belyaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Solid Modeling</title>
		<meeting>ACM Solid Modeling<address><addrLine>Saarbrücken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">June 17-21, 2002</date>
			<biblScope unit="page" from="171" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Filling-in by joint interpolation of vector fields and gray levels</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ballaster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verdera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1200" to="1211" />
			<date type="published" when="2000-10">Oct. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Numerical methods for p-harmonic flows and applications to image processing</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2085" to="2104" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identification of discontinuous coefficient from elliptic problems using total varaition regularization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-C</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="881" to="904" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986-06">June 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Segmentation through variable-order surface fitting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="167" to="192" />
			<date type="published" when="1988-02">Feb. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The topic of his M.S. thesis was to develop algorithms to denoise MRI images via partial differential equations. He is currently pursuing the Ph.D. degree in applied mathematics at the University of Bergen. His research interests include constructions, denoising, and segmentation of medical images (MRI/PET). During the last few years, he has mainly focused on level set methods</title>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Jolion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Department of Scientific Computing</title>
		<meeting><address><addrLine>Bergen, Norway; Oslo, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-02">Feb. 1990. 2004</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="216" to="223" />
		</imprint>
		<respStmt>
			<orgName>Simula Research Laboratory AS</orgName>
		</respStmt>
	</monogr>
	<note>Marius Lysaker received the M.S. degree in applied mathematics in 2001 from the University of Bergen</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
