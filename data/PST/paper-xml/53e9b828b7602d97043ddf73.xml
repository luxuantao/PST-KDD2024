<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Honda Research Institute Europe</orgName>
								<address>
									<postCode>63073</postCode>
									<settlement>Offenbach</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B826538C6C03FF6E385DF50BE52B0A0D</idno>
					<idno type="DOI">10.1109/TSMCC.2008.919172</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pareto-Based Multiobjective Machine Learning:</p><p>An Overview and Case Studies Yaochu Jin, Senior Member, IEEE, and Bernhard Sendhoff, Senior Member, IEEE Abstract-Machine learning is inherently a multiobjective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can be mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multiobjective optimization methodology have gained increasing impetus, particularly due to the great success of multiobjective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multiobjective learning approaches are more powerful compared to learning algorithms with a scalar cost function in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. One common benefit of the different multiobjective learning approaches is that a deeper insight into the learning problem can be gained by analyzing the Pareto front composed of multiple Pareto-optimal solutions. This paper provides an overview of the existing research on multiobjective machine learning, focusing on supervised learning. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multiobjective ensemble generation are compared and discussed in detail. Finally, potentially interesting topics in multiobjective machine learning are suggested. Index Terms-Ensemble, evolutionary multiobjective optimization, generalization, machine learning, multiobjective learning, multiobjective optimization, neural networks, Pareto optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>M ACHINE learning is concerned with the development of computer algorithms and techniques that are able to learn, i.e., to improve automatically through experience <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Any machine learning method consists of two steps, i.e., selecting a candidate model, and then, estimating the parameters of the model using a learning algorithm and available data. Very often, model selection and parameter estimation are combined in an iterative process, and in many cases, model selection has been done only once intuitively and empirically. In other words, the user chooses a model empirically, and then, employs a learning algorithm to estimate the parameters of the model.</p><p>Machine learning algorithms can largely be divided into three categories. One large category is supervised learning, where the model should approximate the mapping between the input and output of the given data, typically known as regression or classification. Unsupervised learning belongs to the second category of learning algorithms. Data clustering is a typical unsupervised learning method, where a given set of data is to be assigned to different subsets (clusters) so that the data in each subset share some common trait (similarity) defined by a distance measure. The third category is reinforcement learning, which aims to find a policy for an agent to take actions that maximize the cumulated rewards in a given environment.</p><p>All learning algorithms perform model selection and parameter estimation based on one or multiple criteria. In supervised learning, the common criterion is an error function that reflects the approximation quality, whereas in clustering, the similarity between the elements in the same cluster (intercluster similarity) should be maximized and the similarity of the elements in different clusters (intracluster similarity) should be minimized. In reinforcement learning, the criterion is a value function that predicts the reward to perform a given action in a given state. Therefore, all learning problems can be considered as an optimization problem. Hereafter, we restrict our discussions mainly to supervised learning and data clustering, since little work has been reported on multicriterion reinforcement learning with few exceptions <ref type="bibr" target="#b2">[3]</ref>. In addition, we term any learning criterion an objective because we are going to discuss learning problems from the optimization point of view.</p><p>A categorization of the existing supervised learning algorithms from the optimization point of view is provided in Section II according to how many objectives are considered in the learning algorithms and whether a scalarized or Paretobased multiobjective optimization approach is adopted. A brief overview of representative research on Pareto-based multiobjective supervised and unsupervised learning is given in Sections III and Section IV, respectively. To illustrate the benefits of the Pareto-based approach to machine learning, a few illustrative examples are presented in the next sections. The experimental setup of the case studies, including the neural network model, the multiobjective evolutionary algorithm (MOEA), and three benchmark problems are outlined in Section V. Case studies on how to identify interpretable models from the achieved Pareto front, how to select models that are most likely to generalize on unseen data, and how to generate ensembles using the Paretobased approach are described in Section VI. A summary and outlook of the paper is provided in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SINGLE-AND MULTIOBJECTIVE LEARNING</head><p>We divide learning algorithms into three categories, namely, single-objective learning, scalarized multiobjective learning, and Pareto-based multiobjective learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Single-Objective Learning</head><p>By single-objective learning, we mean learning algorithms in which only one objective function is optimized. Take supervised learning as an example, a single-objective learning algorithm often minimizes the mean squared error (MSE) on the training data</p><formula xml:id="formula_0">f = 1 N N i=1 (y(i) -y d (i)) 2<label>(1)</label></formula><p>where y(i) and y d (i) are the model output and the desired output, respectively, and N is the number of data pairs in the training data. Several other error measures can also be used as the objective function.</p><p>The most often used data clustering algorithm is the k-means clustering algorithm, where the following objective function is minimized:</p><formula xml:id="formula_1">f = K j =1 x∈C j ||x -c j || 2<label>(2)</label></formula><p>where || • || is a chosen distance measure between a data point x and the center (c j ) of cluster C j , K is the number of clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scalarized Multiobjective Learning</head><p>Learning is inherently multiobjective. In supervised learning, memorizing the training data is not the only target. Several other objectives have often to be taken into consideration. In regression and classification, a learning model should not only have good approximation performance on the training data, but also on unseen data from the same problem. But this target cannot be achieved by minimizing the single objective in <ref type="bibr" target="#b0">(1)</ref> or any other similar error measures. In fact, only minimizing the approximation error on the training data can result in overfitting the training data, which means that the model is likely to perform poorly on unseen data. In other words, the model is not able to generalize to unseen data. To prevent the model from overfitting the training data, the complexity of the model must be controlled. Another common objective that often needs to be taken into account is the comprehensibility or interpretability of the learned model, which is particularly important when supervised learning is used for knowledge discovery from data. As suggested in <ref type="bibr" target="#b3">[4]</ref>, interpretability of machine learning models depends strongly on the complexity of the model, and in general, the lower the complexity, the easier it is to understand the model. In both cases, a second objective reflecting the complexity of the model must be considered too. To control the complexity, the two objectives can be aggregated into a scalar objective function</p><formula xml:id="formula_2">f = E + λΩ (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>where E is a common error function such as the one defined in <ref type="bibr" target="#b0">(1)</ref>, Ω is a measure for the model complexity, such as the number of free parameters in the model, and λ &gt; 0 is a positive hyperparameter to be defined by the user. In this way, the learning algorithm is able to optimize two objectives, though the objective function is still a scalar function.</p><p>The scalarized multiobjective learning approach has been widely adopted in machine learning, such as regularizing neural networks <ref type="bibr" target="#b4">[5]</ref>, creating interpretable fuzzy rules <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, and generating negatively correlated ensemble members <ref type="bibr" target="#b7">[8]</ref>. Unlike neural networks and fuzzy systems for regression and classification, where complexity control is not a must, some learning models, like support vector machines <ref type="bibr" target="#b8">[9]</ref>, sparse coding <ref type="bibr" target="#b9">[10]</ref>, or learning tasks, such as receiver operating characteristics (ROC) analysis <ref type="bibr" target="#b10">[11]</ref>, explicitly consider more than one objective, which naturally fall into the category of scalarized multiobjective learning.</p><p>Similar to supervised learning, multiple objectives can be considered in data clustering as well. On the one hand, it is well recognized that the objective function defined in ( <ref type="formula" target="#formula_1">2</ref>) is strongly biased toward spherically shaped clusters. For data with different types of cluster structures, other objective functions may be more appropriate <ref type="bibr" target="#b11">[12]</ref>. On the other hand, it is also suggested that stability, which reflects the variation in the clustering solutions under perturbations should be considered in developing clustering algorithms <ref type="bibr" target="#b12">[13]</ref>.</p><p>There are two main weaknesses if a scalarized objective function is used for multiobjective optimization. First, the determination of an appropriate hyperparameter λ that properly reflects the purpose of the user is not trivial. Second, only a single solution can be obtained, from which little insight into the problem can be gained. This is particularly important if the multiple objectives conflict with each other, and consequently, no single optimal solution exists that optimizes all the objectives simultaneously. This is particularly true for multiobjective learning, e.g., reducing the approximation error often leads to an increase of the complexity of the model. In addition to the aforementioned two drawbacks, it has been pointed out from the optimization point of view that a desired solution may not be achieved using a scalar objective function even if the hyperparameter is specified properly <ref type="bibr" target="#b13">[14]</ref>. Note, however, that this weakness can be addressed in part if the hyperparameter is changed dynamically during optimization <ref type="bibr" target="#b14">[15]</ref>.</p><p>An additional, potential advantage of the Pareto-based learning approach is that multiobjectivization may help the learning algorithm from getting out of local optima, thus improving the accuracy of the learning model. Some empirical evidence has been reported in <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b16">[17]</ref>. However, a rigorous proof of the favorable change to the learning curve by multiobjectivization remains to be shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Pareto-Based Multiobjective Learning</head><p>Using the Pareto approach to address multiple objectives in machine learning is actually a natural idea. However, this approach has not been adopted until a decade ago and has become popular only very recently. The reason is, in our opinion, that traditional learning algorithms, and most traditional optimization algorithms are inefficient in solving multiobjective problems using the Pareto-based approach. In a Pareto-based approach to multiobjective optimization, the objective function is no longer a scalar value, but a vector. As a consequence, a number of Pareto-optimal solutions should be achieved instead of one single solution.</p><p>Pareto-optimality is the most important concept in Paretobased multiobjective optimization. Consider the following mobjective minimization problem: min F (X),</p><formula xml:id="formula_4">F = {f 1 (X), f 2 (X), . . . , f m (X)}.</formula><p>A solution X is said to dominate a solution Y if ∀j = 1, 2, . . . , m, f j (X) ≤ f j (Y ), and there exists k ∈ {1, 2, . . . , m} such that f k (X) &lt; f k (Y ). Solution X is called Pareto-optimal if it is not dominated by any other feasible solutions. As previously mentioned, there often exists more than one Pareto-optimal solution if the objectives are conflicting with each other. The curve or surface composed of the Pareto-optimal solutions is known as the Pareto front. In practice, we often do not know where the global Pareto front of a real-world optimization problem lies, and therefore, nondominated solutions achieved by an MOEA are not necessarily Pareto-optimal. However, nondominated solutions achieved by multiobjective optimization algorithms are loosely called Pareto-optimal solutions.</p><p>Pareto-based multiobjective learning follows the Paretobased multiobjective optimization approach to handle learning problems. For example, the scalarized biobjective learning problem in (3) can be formulated as a Pareto-based multiobjective optimization as follows:</p><formula xml:id="formula_5">min {f 1 , f 2 } (4) f 1 = E (5) f 2 = Ω.<label>(6)</label></formula><p>The most popular error measure is the MSE defined in <ref type="bibr" target="#b0">(1)</ref>. The complexity of a neural network model can, among others, either be the sum of the squared weights</p><formula xml:id="formula_6">Ω = M i=1 w 2 i (7)</formula><p>or the sum of the absolute weights</p><formula xml:id="formula_7">Ω = M i=1 |w i | (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>where w i , i = 1, . . . , M is a weight in the neural model, and M is the number of weights in total. The aforementioned two complexity measures are often used for neural network regularization and ( <ref type="formula">7</ref>) is known as the Gaussian regularizer and (8) the Laplacian regularizer.</p><p>Comparing the scalarized multiobjective learning described by (3) and the Pareto-based multiobjective learning described by (4), we find that we no longer need to specify the hyperparameter in the Pareto-based multiobjective learning. On one hand, this spares the user the burden to determine the hyperparameter before learning, on the other hand, the user needs to pick out one or a number of solutions from the achieved Pareto-optimal solutions according to the user's preference after learning. One question may arise: Where is then the difference between the scalarized multiobjective learning and the Pareto-based multiobjective learning? As we will show in the next sections, Pareto-based multiobjective learning algorithms are able to achieve a number of Pareto-optimal solutions, from which the user is able to extract knowledge about the problem and make a better decision when choosing the final solution.</p><p>In the following sections, selected existing research on Paretobased supervised and unsupervised learning algorithms will be briefly reviewed. For an updated and more detailed account of the existing research on multiobjective learning, the reader is referred to <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MULTIOBJECTIVE SUPERVISED LEARNING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Earlier Ideas</head><p>The first ideas to formulate supervised learning as a Paretobased multiobjective optimization were reported in the mid of 1990s. One of the earliest work in which the neural learning problem was formulated as a multiobjective optimization problem was reported in <ref type="bibr" target="#b18">[19]</ref>, where two error measures (L 2 -norm and L ∞ -norm) and one complexity measure (the number of nonzero elements) of a Volterra polynomial basis function network and a Gaussian radial basis function network were minimized using the min-max approach</p><formula xml:id="formula_9">f 1 (W ) = ||y(W ) -y d (W )|| 2<label>(9)</label></formula><formula xml:id="formula_10">f 2 (W ) = ||y(W ) -y d (W )|| ∞ (<label>10</label></formula><formula xml:id="formula_11">)</formula><formula xml:id="formula_12">f 3 (W ) = C (11) F (W ) = min W {max{f 1 (W ), f 2 (W ), f 3 (W )}} (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>where C is the number of nonzero weights, f 1 (W ), f 2 (W ), f 3 (W ) are the normalized values of f 1 (W ), f 2 (W ), f 3 (W ), W is the weight matrix of the neural network. Unfortunately, a single-objective genetic algorithm has been employed to implement the learning process, and as a result, only one solution has been achieved. The weakness of the scalarized approach to handling competitive objectives in learning and the necessity to consider the tradeoff using the Pareto-based approach has been discussed in <ref type="bibr" target="#b19">[20]</ref>. An important step forward was made in <ref type="bibr" target="#b20">[21]</ref>, where the training of a multilayer perceptron network was formulated as a biobjective optimization problem. The MSE and the number of hidden nodes of the network were taken into account. A branch and bound algorithm was employed to solve the mixed integer multiobjective problem. Due to the limited ability of the branch-and-bound algorithm, the advantage of the Pareto-based approach to machine learning was not fully demonstrated in the paper.</p><p>With the increasing popularity of MOEAs <ref type="bibr" target="#b21">[22]</ref>, the idea of employing MOEAs to learning problems became more and more practical. Existing research on Pareto-based approaches to supervised learning can roughly be divided into three categories according to their motivations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Generalization Improvement</head><p>One major concern in supervised learning is to generate learning models that not only have good approximation performance on training data, but can also generalize on unseen data. To achieve this, several objectives in addition to the training error can be taken into account. Inspired from neural network regularization, the training error and the sum of the absolute weights were minimized using an -constraint-based multiobjective optimization method <ref type="bibr" target="#b16">[17]</ref>. The Tikhonov regularization term was used as a second objective for a parameter identification problem in <ref type="bibr" target="#b22">[23]</ref> and the biobjective problem was solved by a multiobjective real-coded evolutionary algorithm. Similar to <ref type="bibr" target="#b20">[21]</ref>, the training error and the number of hidden nodes of a feedforward neural network are minimized using a Pareto-based differential evolution algorithm <ref type="bibr" target="#b23">[24]</ref>. The influence of three different regularization terms on complexity minimization has been discussed in <ref type="bibr" target="#b24">[25]</ref> using an multiobjective optimization approach. Different to the conclusion drawn from gradient-based regularization algorithms, it is shown that the Gaussian regularizer is also able to efficiently reduce the network complexity like the Laplacian regularizer when an evolutionary method is used <ref type="bibr" target="#b25">[26]</ref>.</p><p>Another idea to improve the generalization performance of neural networks is to minimize different, potentially conflicting error measures <ref type="bibr" target="#b26">[27]</ref>, such as the Euclidian error, and the robust error, which can be defined by</p><formula xml:id="formula_14">E r = exp(λ| y -y d | p )<label>(13)</label></formula><p>where λ and p are two parameters to be defined. In <ref type="bibr" target="#b27">[28]</ref>, two different methods for determining nondominated solutions were investigated, one using a validation dataset rather than the training set, and the other using a boosting approach.</p><p>Cooperative coevolution of neural networks based on multiple objectives has been studied in <ref type="bibr" target="#b28">[29]</ref>. Two populations coevolve in the algorithm, the module (subnetwork) population and the network population. The module population consists again of a number of subpopulations, each of which evolves both the structure and weights of a subnetwork (a subcomponent of a neural network). The chromosome of the network population encodes which subcomponents should be picked out to construct the whole neural network. A steady-state genetic algorithm is used for the network population. For coevolutionary algorithms, it is not straightforward to determine the fitness value of the individuals in the module population. In <ref type="bibr" target="#b28">[29]</ref>, several criteria for evaluating the fitness of the modules are discussed. The first criterion is concerned with the performance of the modules, which can again be determined in different ways. For example, the performance of a module can be the mean fitness value of a number of best neural networks in which the model participates. Alternatively, the performance of a module can be determined by the average fitness change of the best neural networks when the module is replaced or removed. The second criterion is the number of neural networks the module is present in, which is to be maximized during the optimization. The third criterion is the complexity of the module, including the number of connections (NC), the number of nodes, and the sum of the absolute value of the weights. Two objectives are considered for the network population, namely, the performance and the fitness of each module.</p><p>In addition to feedforward neural networks, tradeoff between accuracy and complexity using the Pareto-based approach has also been considered for generation of radial-basis neural net-works <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, support vector machines <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref>, decision trees <ref type="bibr" target="#b34">[35]</ref>, and classifier systems <ref type="bibr" target="#b35">[36]</ref>. Interesting applications of Pareto-based multiobjective learning to face detection <ref type="bibr" target="#b36">[37]</ref>, feature extraction <ref type="bibr" target="#b37">[38]</ref>, robotics <ref type="bibr" target="#b38">[39]</ref>, and text retrieval <ref type="bibr" target="#b39">[40]</ref> have been reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Interpretability Enhancement in Rule Extraction</head><p>Extraction of logic or fuzzy rules from data or from trained neural networks is an important approach to knowledge discovery. One critical issue here is the interpretability, also known as understandability or transparency of the generated rules. Several aspects can be highly related to the interpretability of rules <ref type="bibr" target="#b40">[41]</ref>, such as the compactness (number of rules, number of premises) and the consistency of the rules. For fuzzy rules, the partition of the fuzzy subsets should be well distinguishable so that a meaningful term can be attached to the fuzzy subsets. Different aspects of interpretability have been coped with using the scalarized multiobjective optimization <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>.</p><p>The first idea to improve understandability of rule systems is to select a small subset from a large number of rules generated from data. A Pareto-based multiobjective genetic algorithm (MOGA) was used to generate fuzzy rules by trading off the classification error against the number of rules <ref type="bibr" target="#b41">[42]</ref>. Similar work has also been reported in <ref type="bibr" target="#b42">[43]</ref> and <ref type="bibr" target="#b43">[44]</ref>. A step further is to include a third objective that minimizes the rule length (number of premises) <ref type="bibr" target="#b44">[45]</ref>, or the number of selected input variables <ref type="bibr" target="#b45">[46]</ref>. To improve the distinguishability of the fuzzy partition, the maximum similarity between the fuzzy subsets has also been minimized in addition to accuracy and compactness <ref type="bibr" target="#b46">[47]</ref>. To further improve the distinguishability of the fuzzy partition, similar subsets are merged, singletons are removed, and overlapped subsets are separated in multiobjective optimization of fuzzy rules considering accuracy and compactness with application to both classification and regression problems <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>.</p><p>Several objectives have to be optimized in extracting logic rules from trained neural networks, such as coverage, i.e., the number of patterns correctly classified by a rule set, error, i.e., the number of the patterns that are misclassified, and compactness <ref type="bibr" target="#b49">[50]</ref>.</p><p>The main advantage of the Pareto-based approach to generating interpretable fuzzy rules is that the user is able to choose a preferred solution from a number of Pareto-optimal solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Diverse Ensemble Generation</head><p>An ensemble of learning models performs much better than a single learning model, if the members of the ensemble are sufficiently different <ref type="bibr" target="#b50">[51]</ref>. However, there is a tradeoff between accuracy and diversity and it is essential that the ensemble members are highly diverse and sufficiently accurate <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>. Previously, the diversity of the ensemble members has been promoted through the use of different data, different learning algorithms or different learning models <ref type="bibr" target="#b53">[54]</ref>. An alternative approach is to develop a learning algorithm that reduces the training error and minimizes the correlation among the outputs of the ensemble members. Traditionally, the approximation error and the output correlation between the ensemble members are summed up to a scalar objective function <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b54">[55]</ref>. In <ref type="bibr" target="#b51">[52]</ref>, the Pareto-based approach is adopted to generate diverse and accurate ensembles, where the following two objectives are minimized,</p><formula xml:id="formula_15">f 1 = 1 N N i=1 (y(i) -y d (i)) 2<label>(14)</label></formula><formula xml:id="formula_16">f 2 = N i=1 (y k (i) -y(i))   M j =k,j =1 (y j (i) -y(i))  <label>(15)</label></formula><p>where y k (i) is the output of the kth ensemble member, y(i) is the output of the ensemble for the ith training sample, N is the number of training samples, and M is the number of members in the ensemble. This research has been extended to a framework for evolving ensembles that is composed of three levels of evolution <ref type="bibr" target="#b55">[56]</ref>. On the first level, a mixture of learning models, such as multilayer perceptrons, radial basis function networks, and support vector machines are evolved. On the second level, different training datasets are used for evolving the hybrid ensembles produced on the first level. On the third level, all subsets of homogenous learning models of the hybrid ensembles generated on the second level are evolved separately to minimize training error and correlation between the ensemble members.</p><p>In each iteration, the current ensemble, which consists of each of the different types of models, is archived if it dominates the previous best ensemble based on training error and test error.</p><p>The ensemble in the archive serves as the final hybrid ensemble.</p><p>A different idea to take advantage of Pareto-based learning for ensemble generation has been presented in <ref type="bibr" target="#b56">[57]</ref>, where the training data is divided into two sets and the errors on the two datasets are used as two objectives for learning</p><formula xml:id="formula_17">f 1 = N 1 i=1 y(i) -y d 1 (i) 2<label>(16</label></formula><p>)</p><formula xml:id="formula_18">f 2 = N 2 i=1 y(i) -y d 2 (i) 2<label>(17)</label></formula><p>where y d j are the training data in dataset j, j = 1, 2, N 1 and N 2 are the size of the datasets. One should take care that the neural network model used should be sufficiently small in order not to overfit both datasets.</p><p>Another idea suggested for generating neural network ensembles is to include the complexity measure as the second objective <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> </p><formula xml:id="formula_19">f 1 = N i=1 (y(i) -y d (i)) 2<label>(18)</label></formula><formula xml:id="formula_20">f 2 = C (<label>19</label></formula><formula xml:id="formula_21">)</formula><p>where C is the NC in the neural network. In this way, the diversity of the networks is achieved in terms of different network structures, which is ensured by the fact that ensemble members always have different NC. Simulation results on both regression and classification problems show that the approach is effective in generating neural network ensembles. It should be noticed, however, that very simple Pareto-optimal neural networks will be generated whose error on the training data can be very large. These networks should not be included in the ensemble if models of high accuracy are targeted. One question that has not been answered in <ref type="bibr" target="#b24">[25]</ref> and <ref type="bibr" target="#b25">[26]</ref> is how to choose ensemble members from the nondominated solutions. We will come back to this issue again in the case studies. The method for multiobjective cooperative coevolution of the neural networks in <ref type="bibr" target="#b28">[29]</ref> has also been applied to generating neural network ensembles <ref type="bibr" target="#b57">[58]</ref>. In case of ensemble generation, one population evolves single neural networks and the other evolves neural network ensembles. For the population evolving single networks, objectives with respect to the performance of the single network, the performance on difficult patterns (measured, e.g., by the number of ensembles misclassifying it), and the average performance of the ensembles in which the network is present can be taken into account for evaluating the performance of the single networks. In addition, network complexity, ability to cooperate, and diversity are other objectives to consider. In addition to the correlation measure used in <ref type="bibr" target="#b51">[52]</ref>, functional diversity, which measures the average Euclidean distances among the outputs of two neural networks, mutual information between the output of two networks, and the Yule's Q statistics <ref type="bibr" target="#b58">[59]</ref>, which measures the correlation of the errors made by two models, are also considered. For the ensemble population, performance and ambiguity are two objectives to optimize. It has been shown that the generalization performance of the ensembles generated using the multiobjective approach is significantly better than that of the ensembles generated by classical approaches.</p><p>Pareto-based generation of ensembles for radial basis function networks <ref type="bibr" target="#b59">[60]</ref> and fuzzy rule systems <ref type="bibr" target="#b60">[61]</ref> have also been reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Miscellaneous</head><p>Much early work on Pareto-based multiobjective learning has been motivated by specific applications, where multiple objectives have to be considered even without thinking about generalization. For example, in generating the ROC curve for classifiers, both the true positive rate (TPR) and the false positive rate (FPR) are to be minimized. In <ref type="bibr" target="#b61">[62]</ref>, the Niched Pareto GA <ref type="bibr" target="#b62">[63]</ref> was employed to generate the ROC curves of neural network classifiers <ref type="bibr" target="#b61">[62]</ref>. It has been shown that better results can be obtained by using the Pareto-based approach compared to the traditional method for generating ROC curve usually by changing the threshold of the neural classifier after training. Notice that traditionally, ROC analysis is just a method for evaluating a given classifier, but in the Pareto-based approach, the classifiers on the ROC curve are different. Most recently, the generalization ability of neural classifiers using the Pareto-based approach to ROC curve generation has been studied in <ref type="bibr" target="#b63">[64]</ref>, and Pareto-based multiobjective multiclass ROC analysis has been investigated in <ref type="bibr" target="#b64">[65]</ref>.</p><p>Systems control is another area in which multiple objectives need to be satisfied. In <ref type="bibr" target="#b65">[66]</ref>, Pareto-based evolutionary programming was used to minimize the undershooting and overall tracking error of a neural-network-based controller. A number of Pareto-optimal solutions are obtained and the control performance of some typical Pareto-solutions is analyzed.</p><p>Supervised feature selection is one of the machine learning tasks where a tradeoff between the number of selected features and the performance of the learning model using the features must be considered. As a result, the Pareto-based multiobjective learning has been investigated <ref type="bibr" target="#b66">[67]</ref>- <ref type="bibr" target="#b68">[69]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. MULTIOBJECTIVE UNSUPERVISED LEARNING</head><p>In this section, we discuss existing research work on Paretobased multiobjective unsupervised learning, mainly multiobjective data clustering. In <ref type="bibr" target="#b69">[70]</ref>, four objectives are considered in Pareto-based evolutionary data clustering. The first objective is concerned with the cluster cohesiveness, which favors dense clusters, the second objective is to maximize the separateness between the clusters measured by their distance from the global centroid, the third objective is meant to reduce the number of clusters, and the fourth one minimizes the number of selected features. Rather than combining the objectives, a Pareto-based evolutionary algorithm has been employed to achieve multiple Pareto-optimal solutions. Through analyzing the individual Pareto-optimal solutions, significant features and an appropriate number of clusters can be identified.</p><p>The advantage of Pareto-based data clustering has been convincingly demonstrated in <ref type="bibr" target="#b70">[71]</ref>, where the number of clusters can be determined automatically by analyzing the Pareto front. In that paper, two objectives are minimized to reflect the compactness of clusters and the connectedness of data points. The cluster compactness is described by the overall deviation of a partitioning and the connectedness checks the degree to which data points in a neighborhood are assigned to the same cluster</p><formula xml:id="formula_22">f 1 = C k ∈C x i ∈C k ||x i -c k || 2 (<label>20</label></formula><formula xml:id="formula_23">)</formula><formula xml:id="formula_24">f 2 = N i=1 L j =1</formula><p>γ ij <ref type="bibr" target="#b20">(21)</ref> where</p><formula xml:id="formula_25">C = {C 1 , C 2 , . . . , C K } is a union of all clusters, c k is the center of cluster C k , k = 1, 2, . . . , K, x i is a data point assigned to cluster C k , K</formula><p>is the number of clusters, L is the number of data points in a predefined neighborhood, and γ ij is defined by</p><formula xml:id="formula_26">γ ij =    1 j , if x i and NN j (x i ) are not in the same cluster 0, otherwise<label>(22)</label></formula><p>where NN j (x i ) is the jth nearest neighbor of data point x i .</p><p>The Pareto-optimal solutions trading off between deviation and connectivity are plotted in such a way that the number of clusters contained in the Pareto-optimal solutions increases from left to right. It is argued that the overall deviation decreases with the increasing number of clusters and when the cluster number is larger than the "true" number of clusters, the gain in deviation minimization will be minor while the cost in connectivity increases rapidly. Thus, the Pareto-optimal solution that delivers the maximal gain in performance against the increase in the  number of clusters provides the correct number of clusters, as suggested in <ref type="bibr" target="#b71">[72]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CASE STUDIES: EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Neural Network Model</head><p>Feedforward neural networks with one hidden layer are used in the case studies. The hidden neurons are nonlinear and the output neurons are linear. The activation function used for the hidden neurons is as follows:</p><formula xml:id="formula_27">g(z) = x 1 + |x| . (<label>23</label></formula><formula xml:id="formula_28">)</formula><p>In the optimization, the maximum of hidden nodes is set to 10.</p><p>Weights are initialized between -0.2 and 0.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evolutionary Algorithms for Pareto-Based Learning 1) Coding of Neural Networks:</head><p>A connection matrix and a weight matrix are employed to describe the structure and the weights of the neural networks, see Fig. <ref type="figure" target="#fig_0">1</ref>. The connection matrix specifies the structure of the network, whereas the weight matrix determines the strength of each connection. Assuming that a neural network consists of M neurons in total, including the input and output neurons, then the size of the connection matrix is M × (M + 1), where an element in the last column indicates whether a neuron is connected to a bias value. In the connection matrix, if element c ij , i = 1, . . . , M, j = 1, . . . , M equals 1, it means that there is a connection between the ith and jth neuron and the signal flows from neuron j to neuron i. If j = M + 1, it indicates that there is a bias in the ith neuron. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates a connection matrix and the corresponding network structure. It can be seen from the figure that the network has two input neurons, two hidden neurons, and one output neuron. Besides, both hidden neurons have a bias.</p><p>2) Mutations of Structure and Weights: Evolutionary algorithms have widely been employed to optimize both the structure and parameters of neural networks, often combined with a gradient-based local search method <ref type="bibr" target="#b72">[73]</ref>. The framework for evolutionary multiobjective optimization of neural networks employed in our case studies is shown in Fig. <ref type="figure" target="#fig_2">3</ref>. In comparison to conventional evolutionary optimization, we note that only mutation operations are used in the framework for varying the structure and parameters of neural networks, which are specific to neural networks, including inserting a new neuron or deleting an existing neuron, adding or removing a connection between two neurons. A Gaussian mutation is applied to the weights</p><formula xml:id="formula_29">∆w ij = N (0, σ w )<label>(24)</label></formula><p>where w ij denotes the weight connecting neuron j and neuron i, σ w is the standard deviation of the Gaussian distribution.</p><p>3) Lifetime Learning: After mutation, lifetime learning using an improved version of the Rprop algorithm <ref type="bibr" target="#b73">[74]</ref> has been employed to fine tune the weights. After lifetime learning, the fitness of each individual regarding the approximation error (f 1 ) is updated. In addition, the weights modified during the lifetime learning are encoded back to the chromosome, which is known as the Lamarckian type of inheritance.</p><p>The Rprop learning algorithm <ref type="bibr" target="#b74">[75]</ref> is believed to be a fast and robust learning algorithm. In each iteration, the weights are modified in the following manner</p><formula xml:id="formula_30">∆w (t) ij = -sign ∂E (t) ∂w ij ∆ (t) ij (<label>25</label></formula><formula xml:id="formula_31">)</formula><p>where sign(•) is the sign function, ∆ (t) ij ≥ 0 is the step size, which is initialized to ∆ 0 for all weights. The step size for each weight is adjusted as</p><formula xml:id="formula_32">∆ (t) ij =              ξ + ∆ (t-1) ij , if ∂E (t-1) ∂w ij × ∂E (t) ∂w ij &gt; 0 ξ -∆ (t-1) ij , if ∂E (t-1) ∂w ij × ∂E (t) ∂w ij &lt; 0 ∆ (t-1) ij , otherwise<label>(26)</label></formula><p>where 0 &lt; ξ -&lt; 1 &lt; ξ + . To prevent the step sizes from becoming too large or too small, they are bounded by ∆ min ≤ ∆ ij ≤ ∆ max .</p><p>After the weights are updated, it is necessary to check if the partial derivative changes sign, which indicates that the previous step might be too large, and thus, a minimum has been missed. In this case, the previous weight change should be retracted</p><formula xml:id="formula_33">∆w (t) ij = -∆ (t-1) ij , if ∂E (t-1) ∂w ij × ∂E (t) ∂w ij &lt; 0. (<label>27</label></formula><formula xml:id="formula_34">)</formula><p>Recall that if the weight change is retracted in the tth iteration, the ∂E (t) /∂w ij should be set to 0.</p><p>In reference <ref type="bibr" target="#b73">[74]</ref>, it is argued that the condition for weight retraction in <ref type="bibr" target="#b26">(27)</ref> is not always reasonable. The weight change should be retracted only if the partial derivative changes sign and if the approximation error increases. Thus, the weight retraction condition in ( <ref type="formula" target="#formula_33">27</ref>) is modified as follows:</p><formula xml:id="formula_35">∆w (t) = -∆ (t-1) ij , if ∂E (t-1) ∂w ij × ∂E (t)</formula><p>∂w ij &lt; 0 and</p><formula xml:id="formula_36">E (t) &gt; E (t-1) . (<label>28</label></formula><formula xml:id="formula_37">)</formula><p>It has been shown on several benchmark problems that the modified Rprop (termed as Rprop + ) exhibits consistently better performance than the Rprop algorithm <ref type="bibr" target="#b73">[74]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Selection:</head><p>The most significant difference of multiobjective optimization to scalar optimization is the selection method. In our research, the selection method from NSGA-II <ref type="bibr" target="#b75">[76]</ref> is adopted, which consists of four major steps. First, the parent and offspring populations are combined. This implies that NSGA-II is an elitism. Second, the combined population is sorted according to the nondominance ranks. During the ranking, nondominated solutions in the combined population are assigned a rank 1, which belongs to the first nondominated front. These individuals are removed temporally from the population, and the nondominated individuals in the rest of the population are identified, which consists of the second nondominated front of the population and are assigned a rank 2. This procedure repeats until all individuals in the combined population are assigned with a rank from 1 to R, assuming that R nondominated fronts can be identified in total. Third, a crowding distance reflecting the crowdedness in the neighborhood of a particular solution is calculated. The crowding distance of solution i in the nondominated front j, (j = 1, . . . , R) is the distance between the two neighbors of solution s j i in the objective space where m is the number of objectives in the multiobjective optimization problem and solutions s j i-1 and s j i+1 are the two neighboring solutions of solution s j i . A large distance is assigned to the boundary solutions in each nondominated front. Here, the larger the crowding distance, the less crowded around the solution s j i it is. Fourth, a tournament selection that leverages between nondominated ranking and crowdedness is conducted. Given two randomly chosen individuals, the solution with the better (lower) rank wins the tournament. If the two solutions have the same rank, the one with the larger crowding distance wins. If the two solutions have the same rank and the same crowding distance, choose a winner randomly. This procedure continues until the required number of offspring is generated.</p><formula xml:id="formula_38">d j i = m k =1 |f k (s j i-1 ) -f k (s j i+1 )|<label>(29)</label></formula><p>The parameter settings used in the simulations are summarized in Table <ref type="table" target="#tab_0">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Benchmark Problems 1) Wisconsin Breast Cancer Data:</head><p>The Wisconsin breast cancer diagnosis problem in the University of California at Irvine (UCI) repository of machine learning database was collected by Dr. W. H. Wolberg at the University of Wisconsin-Madison Hospitalics <ref type="bibr" target="#b76">[77]</ref>. The benchmark problem contains 699 examples, each of which has nine inputs and two outputs. The inputs are: clump thickness (x 1 ), uniformity of cell size (x 2 ), uniformity of cell shape (x 3 ), marginal adhesion (x 4 ), single epithelial cell size (x 5 ), bare nuclei (x 6 ), bland chromatin (x 7 ), normal nucleoli (x 8 ), and mitosis (x 9 ). All inputs are normalized, to be more exact, x 1 , . . . , x 9 ∈ {0.1, 0.2, . . . , 0.8, 0.9, 1.0}. The two outputs are a complementary binary value, i.e., if the first output is 1, which means "benign," then the second output is 0. Otherwise, the first output is 0, which means "malignant," and the second output is 1. Therefore, only the first output is used.</p><p>2) Diabetes Data: The Pima Indians Diabetes Data consists of 768 data pairs with eight attributes normalized between 0 and 1 <ref type="bibr" target="#b76">[77]</ref>. The eight attributes are number of pregnant (x 1 ), plasma glucose concentration (x 2 ), blood pressure (x 3 ), triceps skin fold thickness (x 4 ), 2 h serum insulin (x 5 ), body mass index (x 6 ), diabetes pedigree function (x 7 ), and age (x 8 ). In this database, 268 instances are positive (output equals 1) and 500 instances are negative (output equals 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Iris Data:</head><p>The third dataset we looked at is the Iris data <ref type="bibr" target="#b76">[77]</ref>. The dataset contains three classes of 40 instances each, where each class refers to a type of Iris plant. The three classes are: Iris setosa (class 1, represented by -1), Iris versicolor (class 2, represented by 0), and Iris virginica (class 3, represented by 1). Four attributes are used to predict the Iris class, i.e., sepal length (x 1 ), sepal width (x 2 ), petal length (x 3 ), and petal width (x 4 ), all in centimeters. Among the three classes, class 1 is linearly separable from the other two classes, and classes 2 and 3 are not linearly separable from each other. To ease knowledge extraction, we reformulate the data with three outputs, where class 1 is represented by {1, 0, 0}, class 2 by {0, 1, 0}, and class 3 by {0, 0, 1}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CASE STUDIES: RESULTS</head><p>Based on the MOEA described in the previous section, we show in this section how one can benefit from Pareto-based multiobjective learning. We generate a number of Pareto-optimal neural network models that trade the accuracy on training data off against the network complexity. We show on the three benchmark problems how to identify interpretable neural networks from which understandable logic rules can be extracted, and networks that are most likely to generalize on unseen data, from the achieved Pareto-optimal solutions. Afterwards, we compare three methods for generating neural network ensembles using the Pareto-based multiobjective learning, which are suggested by Abbass <ref type="bibr" target="#b56">[57]</ref>, Chandra and Yao <ref type="bibr" target="#b51">[52]</ref>, and Jin et al. <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Identifying Interpretable Models</head><p>As suggested in <ref type="bibr" target="#b3">[4]</ref>, interpretability of neural networks is mainly determined by their complexity. The simpler a network, the easier it is to understand the knowledge embedded in the neural network. This is also true if we look at the definition of interpretability of fuzzy systems <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b40">[41]</ref>.</p><p>When we minimize both accuracy and complexity of the networks in a Pareto-based approach, we are able to achieve a number of Pareto-optimal solutions with a complexity ranging from very simple networks to highly complex ones. We argue that the simple Pareto-optimal neural networks on the Pareto front are actually the interpretable models from which understandable logic rules can be extracted. Before providing examples on the benchmark problems, we first briefly describe the rule extraction method we adopted in this case study, which is similar to the one used in <ref type="bibr" target="#b77">[78]</ref>. Consider a simple neural network with one single input, one hidden neuron, and one output neuron, refer to Fig. <ref type="figure" target="#fig_3">4</ref>. For binary classification problems, we usually assume that an instance is labeled as class 1 if the output is smaller than 0.5. Otherwise, it is labeled as class 2. To have more confidence in decision making, we can also define a stronger criterion, for instance: In the following, we will show how to derive rules from neural networks using the defined thresholds. Let the output of the hidden neuron be z, then a rule that defines class 1 should satisfy</p><formula xml:id="formula_39">w 3 z + w 4 ≥ 0.75. (<label>31</label></formula><formula xml:id="formula_40">)</formula><p>Then, we get</p><formula xml:id="formula_41">z ≥ (0.75 -w 4 ) w 3 , if w 3 &gt; 0 z ≤ (0.75 -w 4 ) w 3 , if w 3 &lt; 0.</formula><p>Consider the first case and define (0.75w 4 )/w 3 = θ 1 &gt; 0, we have</p><formula xml:id="formula_42">w 1 x + w 2 1 + |w 1 x + w 2 | ≥ θ 1 . (<label>32</label></formula><formula xml:id="formula_43">)</formula><p>Since θ 1 &gt; 0, w 1 x + w 2 must also be larger than zero to satisfy the conditions for class 1. Consequently,</p><formula xml:id="formula_44">w 1 x + w 2 1 + w 1 x + w 2 ≥ θ 1<label>(33)</label></formula><p>and</p><formula xml:id="formula_45">x ≥ θ 1 -w 2 (1 -θ 1 ) w 1 (1 -θ 1 ) , if w 1 (1 -θ 1 ) &gt; 0 (34) x ≤ θ 1 -w 2 (1 -θ 1 ) w 1 (1 -θ 1 ) , if w 1 (1 -θ 1 ) &lt; 0.<label>(35)</label></formula><p>Let</p><formula xml:id="formula_46">[θ 1 -w 2 (1 -θ 1 )]/[w 1 (1 -θ 1 )] = θ 2</formula><p>, either of the following two rules can be extracted that defines the condition for class 1:</p><formula xml:id="formula_47">If x ≥ θ 2 , then class 1, if w 1 (1 -θ 1 ) &gt; 0 If x ≤ θ 2 , then class 1, if w 1 (1 -θ 1 ) &lt; 0.</formula><p>Note, however, that it can happen that no rule can be extracted from the neural network. For instance, if ∀z, w 3 z + w 4 &lt; 0.75.</p><p>In this case, the neural network is not able to separate the two classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Wisconsin Breast Cancer Data:</head><p>For rule extraction, all available data are used for training the neural network. The Pareto-optimal solutions from a typical run are plotted in Fig. <ref type="figure" target="#fig_4">5</ref>.   As we will show later on, the simplest Pareto-optimal neural networks achieved from different runs are almost identical.</p><p>Let us now look at the simplest Pareto-optimal neural networks. The simplest neural network has three connections in total, in which no input is selected. In other words, the input of the neural network is constant, refer to Fig. <ref type="figure" target="#fig_5">6</ref>. Interestingly, this neural network learns exactly the mean output of the training data.</p><p>The second simplest network is presented in Fig. <ref type="figure" target="#fig_6">7</ref>, which has four connections. Of the nine input attributes, only x 2 (uniformity of cell sizes) is selected, which implies that x 2 might be the most important feature for determining whether an instance is benign or malignant. The MSE of the network is 0.051. From the network, the following two rules can be extracted using the previously described rule extraction method:</p><formula xml:id="formula_48">If x 2 ≤ 0.2, then benign If x 2 ≥ 0.4, then malignant.</formula><p>With these two simple rules, the correct classification rate is 97.0% on 602 instances with the rest 97 instances undetermined, recalling that the thresholds are set to 0.75 and 0.25 to make sure that the decision is confident enough. However, if we set the  The next simple Pareto-optimal neural network has five connections, in which both x 2 and x 6 are chosen as input features (see Fig. <ref type="figure" target="#fig_7">8</ref>). The MSE of the model is 0.029. From this neural network, the following two rules can be extracted: If 14 x 2 + 8.55 x 6 ≤ 5.81, then benign If 14 x 2 + 8.55 x 6 ≥ 7.55, then malignant.</p><p>Using these two rules, the correct classification rate is 97.2% on 680 instances with the rest 19 instances undetermined. If the threshold is set to 0.5, the following rule can be obtained with a correct classification rate of 96.4% on all instances: If 14 x 2 + 8.55 x 6 ≤ 6.45, then benign otherwise malignant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Diabetes Data:</head><p>The same empirical study is conducted on the diabetes data. The achieved Pareto front is shown in Fig <ref type="figure" target="#fig_8">9</ref>.</p><p>Same as the breast cancer data, the simplest Pareto-optimal solution contains three connections and learns the mean of the output value. The two simple Pareto solutions with at least one attribute chosen are plotted in Figs. <ref type="figure" target="#fig_9">10</ref> and<ref type="figure" target="#fig_10">11</ref>, respectively. The MSEs of the two simple network models are 0.17 and 0.16.  From the neural network with four connections (see Fig. <ref type="figure" target="#fig_9">10</ref>), the following two rules can be extracted:</p><formula xml:id="formula_49">If x 2 ≤ 0.83, then positive If x 2 ≥ 0.56, then negative.</formula><p>By applying the aforementioned two rules, we are able to make a decision on 413 instances with a correct classification rate of 85.4%. The rest 355 instances cannot be determined with these two rules.</p><p>If we set the threshold to 0.5, the following rule is obtained:</p><formula xml:id="formula_50">If x 2 ≤ 0.72, then positive otherwise negative. (<label>37</label></formula><formula xml:id="formula_51">)</formula><p>The correct classification rate using the aforementioned rule is 75.0% on all 768 instances. The following rules can be obtained for the neural network in Fig. <ref type="figure" target="#fig_10">11</ref>, when the threshold is set to 0.75 and 0.25: </p><formula xml:id="formula_52">If</formula><p>From the aforementioned rule, the correct classification rate on all 768 instances is 77.0%.</p><p>3) Iris Data: The Pareto front from the Iris data is presented in Fig. <ref type="figure" target="#fig_11">12</ref>, which consists of 20 solutions (two Pareto optimal solutions have the same MSE and complexity). Again, the simplest network with seven connections approximates the mean value of the output.</p><p>The two Pareto-optimal networks with eight connections are plotted in Figs. <ref type="figure" target="#fig_12">13</ref> and<ref type="figure" target="#fig_13">14</ref>, respectively. From the figures, we   notice that only one of the attribute (either x 3 or x 4 ) is chosen. From the network in Fig. <ref type="figure" target="#fig_12">13</ref>, the following rule can be extracted:</p><formula xml:id="formula_54">If x 3 ≤ 2.4, then Iris setosa. (<label>39</label></formula><formula xml:id="formula_55">)</formula><p>Similarly, the following rule can be extracted form the network in Fig. <ref type="figure" target="#fig_12">13</ref>:</p><formula xml:id="formula_56">If x 4 ≤ 0.80, then Iris setosa. (<label>40</label></formula><formula xml:id="formula_57">)</formula><p>It can be easily verified that both rules are able to separate Iris sesota from the other two classes correctly. The correct classification rate is 91.3% on all instances. Note that the classification rate is almost the same when the threshold is set to 0.5 on the Iris data.</p><p>From the three benchmark problems, we can conclude that by trading off accuracy against complexity, the Pareto-based multiobjective optimization algorithm is able to find the simplest structures that solve the problem best. Besides, the simple Pareto-optimal networks are able to capture the main knowledge embedded in the data so that interpretable logic rules can be extracted. Compared to other methods used in extracting rules from trained neural network <ref type="bibr" target="#b78">[79]</ref>, <ref type="bibr" target="#b79">[80]</ref>, the Pareto-based approach is very straightforward and efficient. Besides, the multiple interpretable yet Pareto-optimal solutions provide additional knowledge that can help the user understand the problem, as we have shown on the three benchmark problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Model Selection by Analyzing the Pareto Front</head><p>Model selection is a well-studied topic in machine learning <ref type="bibr" target="#b80">[81]</ref>, <ref type="bibr" target="#b81">[82]</ref>. If sufficient data are available, the best approach to model selection is to split the data into three subsets, where the first subset (training data) is for constructing models, the second one (validation data) is used to estimate prediction error for selecting a model, and the third one (test data) for accessing the generalization error of the selected model. In case of insufficient data, which is often the case in real-world applications, either analytical methods such as the informationtheoretic criteria <ref type="bibr" target="#b80">[81]</ref>, <ref type="bibr" target="#b81">[82]</ref>, e.g., the Akaike's information criterion (AIC) and the Bayesian information criterion (BIC), or resampling techniques like k-fold cross-validation <ref type="bibr" target="#b81">[82]</ref>, are used.</p><p>In this section, we show that the Pareto approach to handling the accuracy-complexity tradeoff provides an empirical, yet interesting alternative to selecting models that have good generalization on unseen data. The basic argument is that the complexity of the model should match that of the data to be learned and the ability of the learning algorithm. When the complexity of the model is overly large, learning becomes sensitive to stochastic influences, and results on unseen data will be unpredictable, i.e., overfitting can happen. Inspired by the work on determining the correct number of clusters in multiobjective data clustering <ref type="bibr" target="#b70">[71]</ref>, the appropriate complexity of the data can be determined by the normalized performance gain (NPG)</p><formula xml:id="formula_58">NPG = MSE j -MSE i C i -C j (<label>41</label></formula><formula xml:id="formula_59">)</formula><p>where MSE i , MSE j , and C i , C j are the MSE on training data, and the NC of the ith and jth Pareto optimal solutions. When the solutions are ranked in the order of increasing complexity, the following relationships hold:</p><formula xml:id="formula_60">C i+1 &gt; C i MSE i+1 ≤ MSE i .</formula><p>We hypothesize that if the model complexity is lower than that of the data, an increase in complexity will result in significant increase in performance (NPG). As the complexity continues to increase, the NPG decreases gradually to zero. At this point, the complexity of the model matches that of the data. Further increase in complexity will probably bring about further enhancement in performance on the training data, but with the increasing risk of overfitting the training data.   We first analyze the results on the breast cancer data. From Fig. <ref type="figure" target="#fig_19">19</ref>, we notice that the NPG decreases to 0 after the first peak in performance gain when the NC is between 12 and 14. Meanwhile, it can be seen from Fig. <ref type="figure" target="#fig_15">16</ref> that the learning performance on the training data from different runs begins to fluctuate when the NC is larger than 17. These two facts suggest that the appropriate complexity of the neural network for this problem is between 12 and 17. We can see from Fig. <ref type="figure" target="#fig_15">16</ref> that the error on the test data is well controlled when the complexity is in the suggested range.</p><p>Similar observations can be made on the diabetes data and the Iris data. For the diabetes data, the NPG first drops to 0 when the NC of the neural networks is around 10. In addition, a discrepancy between the two runs becomes large after the NC reaches 13. From these two observations, we conclude that the complexity of the neural network on the diabetes data should be around 8-10. For the same reasons, the NC of the neural network should be between 16 and 18 for the Iris data.</p><p>The proposed method for model selection is empirical and needs to be verified on more problems. For clarity, we only plot results from two independent runs in the aforementioned   analyses. The results of ten independent runs are plotted in Figs. <ref type="bibr">28-30.</ref> From these results, we can confirm that the generalization performance of the neural network is good when the learning performance on the training data is stable in different runs.</p><p>It is difficult to select one single model using our empirical method. Instead, it will be more reliable if multiple models of potentially good generalization performance are chosen to construct an ensemble. This topic will be discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Generating Diverse and Accurate Ensemble Members</head><p>In this section, we compare three Pareto-based multiobjective approaches to ensemble generation. The first approach is presented in Abbass <ref type="bibr" target="#b56">[57]</ref>, where the accuracies on two datasets serve as two objectives. The second one is described in Chandra and Yao <ref type="bibr" target="#b51">[52]</ref>, where a tradeoff between accuracy and diversity is taken into account to generate ensembles. The final approach studied in the section is suggested in Jin et al. <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, in which the accuracy and the NC of the neural network are adopted as two conflicting objectives. The experimental setup is the same as in the previous studies, except that in the Abbass' approach, the training data of the three benchmark problems are equally divided into two datasets so that the approximation errors on the two datasets can be computed as the two objectives.</p><p>Another issue, which has not been explicitly addressed in Abbass <ref type="bibr" target="#b56">[57]</ref>, is the lifetime learning under the context of multiobjective learning. Note that RProp is adopted as the lifetime learning algorithm, which works for single-objective learning only. This is not a problem in Chandra's as well as in Jin's approach in that the lifetime learning is applied to one of the objective only. However, when both objectives are approximation errors, multiobjective lifetime learning should be applied, which is not straightforward for gradient-based learning algorithms. In Jin et al. <ref type="bibr" target="#b82">[83]</ref>, it is suggested that the lifetime learning should be switched randomly between the two objectives to achieve diverse Pareto-optimal solutions. In this study, lifetime learning is switched between the two objectives at an equal probability. For comparison, simulations are also conducted where the lifetime learning is of single-objective nature, i.e., the RProp is applied on the combination of the two datasets.</p><p>The Pareto-optimal solutions from ten runs on the breast cancer data are plotted in Fig. <ref type="figure" target="#fig_22">22(a)</ref>, where the lifetime learning is switched between the two datasets, and Fig. <ref type="figure" target="#fig_22">22(b)</ref>, where the lifetime learning is applied on the combination of the two datasets. In the figures, the dots denote the results on the training data and the circles the results on test data. From these results, we can make the following observations. First, by switching the lifetime learning between the two datasets, more diverse solutions can be achieved. Second, good performance on the training data does not ensure good performance on the test data. As suggested in <ref type="bibr" target="#b52">[53]</ref>, ensemble members should be both accurate and diverse. In other words, ensembles whose members are of poor accuracy cannot perform well. This indicates that if the Pareto-optimal solutions are used as ensemble members, the quality of the ensemble will be poor. Third, lifetime learning on the combination of the data results in serious overfitting.</p><p>Very similar results are obtained for the diabetes data and the Iris data, which are plotted in Figs. <ref type="figure" target="#fig_23">23</ref> and<ref type="figure" target="#fig_24">24</ref>, respectively. Again, it is difficult to choose proper ensemble members from the Pareto-optimal solutions.</p><p>The simulation results using Chandra and Yao's approach for the three benchmark problems are presented in Figs. <ref type="figure" target="#fig_25">25,</ref><ref type="figure" target="#fig_26">26</ref>, and 27, respectively. Again, the results on the training and test data are denoted by dots and circles. From the figures, we find that the achieved Pareto-optimal network models tend to overfit the data regardless the diversity, particularly on the diabetes data and the Iris data.</p><p>Finally, we take a look at Jin et al.'s approach, which ensures the diversity of the ensemble members by generating neural networks with different complexities. The results are presented in Figs. 28, 29, and 30, respectively. From the figures, we can see that in all the three examples, the MSE on the test data is well constrained when the complexity of the neural network is appropriately low. As suggested in the previous section, the required complexity that matches the data can be estimated using the NPG. By choosing these networks as ensemble members, we are able to have a neural network ensemble whose members are both accurate and diverse. The diversity of the networks is guaranteed by the difference in the complexity of the neural networks.</p><p>Comparing the three Pareto-based approaches to ensemble generation, we conclude that it is not straightforward to choose ensemble members from the achieved Pareto-optimal solutions for constructing ensembles in Abbass' as well as in Chandra and Yao's approaches. To ensure good performance on unseen data of the ensemble, additional methods such as cross-validation must be employed. In contrast, it is rather easy to identify neural networks that can be used as ensemble members when Paretooptimal solutions are generated using Jin et al.' approach. Another important point is that in Abbass' and Chandra and Yao's approaches, the achieved solutions from the ten independent  runs are rather different along the whole Pareto front, which means that these two methods are quite sensitive to stochastic influences. Opposite to that, the results from the ten independent runs are quite stable in Jin et al.'s approach when the complexity is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. SUMMARY AND OUTLOOK</head><p>Pareto-based approach to machine learning provides us a new point of view for studying machine learning problems. By means of Pareto-based optimization, we are able to gain a deeper insight into different aspects of machine learning, and thus, develop new learning algorithms. The power of the Pareto-based approach is made more attractive due to the successful application of evolutionary algorithms to Pareto-based multiobjective optimization.</p><p>This paper provides an up-to-date yet not necessarily complete review of the existing research on Pareto-based multiobjective learning algorithms. We illustrate, on three benchmark problems, how we can address important topics in machine learning, such as generating interpretable models, model selection for generalization, and ensemble generation, using the Pareto-based multiobjective approach. We show that the simplest Pareto-optimal model without any input selected approximates the mean of the training data, while the simple Paretooptimal models with one or two most important features selected capture the essential knowledge in the data. In addition, we demonstrate empirically that by analyzing the Pareto-optimal solutions in terms of performance and complexity, and the learning performance w.r.t. model complexity in independent runs, we are able to choose models that are most likely to exhibit good performance on unseen data. Finally, we compare three Paretobased approaches to the generation of neural ensembles and indicate that the method by trading off accuracy and complexity can provide reliable results.</p><p>Many issues remain to be resolved and new areas could be opened up in the field of Pareto-based multiobjective machine learning. One interesting question is how the Pareto-based approach to machine learning influences the learning behavior, e.g., the property of the learning curve <ref type="bibr" target="#b83">[84]</ref>, <ref type="bibr" target="#b84">[85]</ref>. It has   been empirically disclosed in general optimization problems that the number of local optima can be reduced by converting multimodal single-objective problems into multiobjective ones <ref type="bibr" target="#b85">[86]</ref>, <ref type="bibr" target="#b86">[87]</ref>. If we are able to show that the same happens in   machine learning, it is then more convincing to argue that the Pareto-based multiobjective learning is able to improve learning performance.</p><p>Most topics discussed so far are mainly concerned with the bias-variance tradeoff in machine learning. Another important topic in machine learning, as well as in human memory systems, is the plasticity-stability tradeoff, which is also known as online learning <ref type="bibr" target="#b87">[88]</ref>, incremental learning <ref type="bibr" target="#b88">[89]</ref>, or catastrophic forgetting <ref type="bibr" target="#b89">[90]</ref>. A preliminary attempt has been made in <ref type="bibr" target="#b82">[83]</ref> to address catastrophic forgetting using the Pareto-based approach. It has been shown that the multiobjective approach is more promising in alleviating forgetting than its single-objective counterpart. The idea of Pareto-optimality can also be extended to the study on connectivity and complexity <ref type="bibr" target="#b90">[91]</ref>, <ref type="bibr" target="#b91">[92]</ref> of general networks, and to the research on structure and functionality of spiking neural networks <ref type="bibr" target="#b92">[93]</ref>, <ref type="bibr" target="#b93">[94]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Coding of the structure and parameters of neural networks using a connection matrix and a weight matrix.</figDesc><graphic coords="6,307.67,68.26,246.00,81.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example of a connection matrix and its corresponding neural network structure.</figDesc><graphic coords="6,307.67,205.21,246.00,89.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Framework for evolutionary multiobjective optimization of neural networks.</figDesc><graphic coords="7,40.44,68.25,246.00,167.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Typical simple network for extracting logic rules.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Typical Pareto-front obtained for the breast cancer data composed of 41 solutions.</figDesc><graphic coords="9,328.05,68.25,196.80,153.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Simplest Pareto-optimal network model for the breast cancer data, which exactly learns the mean of the training data.</figDesc><graphic coords="9,360.45,271.49,132.00,53.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Pareto-optimal network model with four connections for the breast cancer data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Pareto-optimal network model with five connections for the breast cancer data.</figDesc><graphic coords="10,71.65,68.26,192.00,76.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Typical Pareto-front obtained for the diabetes data composed of 37 solutions.</figDesc><graphic coords="10,71.65,197.10,192.00,149.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Pareto-optimal network model with four connections for the diabetes data.</figDesc><graphic coords="10,334.67,68.26,192.00,53.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Pareto-optimal network model with five connections for the diabetes data.</figDesc><graphic coords="10,352.67,174.35,156.00,66.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Typical Pareto-front obtained for the Iris data composed of 20 solutions.</figDesc><graphic coords="11,67.44,68.26,192.00,150.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Pareto-optimal network model with eight connections for the Iris data. In this model, x 3 is chosen as the input.</figDesc><graphic coords="11,73.44,272.27,180.00,107.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Pareto-optimal network model with eight connections for the Iris data. In this model, x 4 is chosen as the input.</figDesc><graphic coords="11,67.44,435.20,192.00,114.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Pareto-optimal network model with 13 connections for the Iris data. x 4 is chosen as the input.</figDesc><graphic coords="11,330.45,68.26,192.00,122.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Accuracy versus complexity of the Pareto-optimal solutions from two independent runs: breast cancer data. Dots denote training data and circles test data.</figDesc><graphic coords="12,71.65,68.26,192.00,150.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>We are now going to verify empirically the suggested method for model selection on the three benchmark problems. In this part of the simulations, available data are split into a training dataset and a test dataset. For the breast cancer data, 525 instances are used for training and 174 instances for test. The training set of the diabetes data contains 576 samples and the test set 192 samples. Finally, 120 instances are used for training and the rest 30 instances for test for the Iris data. The Pareto fronts generated from two independent runs on the three benchmark problems are presented in Figs. 16, 17, and 18, respectively. The dots denote the results on the training dataset, while the circles the results on test data. The NPG from the two</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Accuracy versus complexity of the Pareto-optimal solutions from two independent runs: diabetes data. Dots denote training data and circles test data.</figDesc><graphic coords="12,334.67,68.26,192.00,149.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Accuracy versus complexity of the Pareto-optimal solutions from two independent runs: Iris data. Dots denote training data and circles test data.</figDesc><graphic coords="12,334.67,267.66,192.00,149.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. NPG from two independent runs for the breast cancer data.</figDesc><graphic coords="13,101.50,68.29,386.80,159.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. NPG from two independent runs for the diabetes data.</figDesc><graphic coords="13,102.58,267.34,384.70,158.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 21 NPG</head><label>21</label><figDesc>Fig. 21 NPG from two independent runs for the Iris data.</figDesc><graphic coords="13,100.31,466.62,389.20,159.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 22 .</head><label>22</label><figDesc>Fig. 22. Achieved nondominated solutions using Abbass's approach: breast cancer data. (a) Lifetime learning is switched between two datasets. (b) Lifetime learning applied on the combination of the data.</figDesc><graphic coords="14,100.92,68.29,396.40,159.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Achieved nondominated solutions using Abbass's approach: diabetes data. (a) Lifetime learning is switched between two datasets. (b) Lifetime learning applied on the combination of the data.</figDesc><graphic coords="15,99.34,68.29,391.10,159.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. Achieved nondominated solutions using Abbass's approach: Iris data. (a) Lifetime learning is switched between two datasets. (b) Lifetime learning applied on the combination of the data.</figDesc><graphic coords="15,97.07,290.50,395.70,159.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. Achieved nondominated solutions using Chandra and Yao's approach: breast cancer data.</figDesc><graphic coords="16,59.65,68.26,216.00,170.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 26 .</head><label>26</label><figDesc>Fig. 26. Achieved nondominated solutions using Chandra and Yao's approach: diabetes data.</figDesc><graphic coords="16,71.65,297.41,192.00,155.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 27 .</head><label>27</label><figDesc>Fig. 27. Achieved nondominated solutions using Chandra and Yao's approach: Iris data.</figDesc><graphic coords="16,71.65,499.51,192.00,153.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig. 28 .</head><label>28</label><figDesc>Fig. 28. Achieved nondominated solutions using Jin et al.'s approach: breast cancer data.</figDesc><graphic coords="16,334.67,68.25,192.00,151.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig. 29 .</head><label>29</label><figDesc>Fig. 29. Achieved nondominated solutions using Jin et al.'s approach: diabetes data.</figDesc><graphic coords="16,334.67,279.65,192.00,148.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Fig. 30 .</head><label>30</label><figDesc>Fig. 30. Achieved nondominated solutions using Jin et al.'s approach: Iris data.</figDesc><graphic coords="16,334.67,487.92,192.00,147.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PARAMETER</head><label>I</label><figDesc>SETTINGS OF THE ALGORITHMS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>3.77 x 2 + 2.67 x 6 ≤ 4.54, then positive If 3.77 x 2 + 2.67 x 6 ≥ 3.46, then positive.With these two rules, the correct classification rate is 85.4% with the rest 308 instances undecided. If the threshold is set to 0.5, we then have the following rule:</figDesc><table><row><cell>If 3.77 x 2 + 2.67 x 6 ≤ 3.97,</cell><cell>then positive</cell></row><row><cell></cell><cell>otherwise negative.</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors are grateful to E. Körner for his kind support.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Yaochu Jin (M'98-SM'02) received the B.Sc., M.Sc., and Ph.D. degrees from Zhejiang University, Hangzhou, <ref type="bibr">China, in 1988</ref><ref type="bibr">China, in , 1991</ref><ref type="bibr">China, in , and 1996</ref>, respectively, all in automatic control, and the second Ph.D. degree in electrical and computer engineering from Ruhr-Universität Bochum, Bochum, Germany, in 2001.</p><p>In 1991, he joined the Electrical Engineering Department, Zhejiang University, where he became an Associate Professor in 1996. From 1996 to 1998, he was with the Institut für Neuroinformatik, Ruhr-Universität Bochum, first as a Visiting Researcher and then as a Research Associate. From 1998 to 1999, he was a Postdoctoral Associate with the Industrial Engineering Department, Rutgers, the State University of New Jersey, Piscataway. In 1999, he joined the Future Technology Research Division, Honda R&amp;D Europe, Offenbach/Main, Germany. Since 2003, he has been a Principal Scientist and a Project Leader at Honda Research Institute Europe, Offenbach. His current research interests include computational approaches to understanding evolution and learning in biology (computational biology), and evolutionary and learning approaches to complex systems design (computational intelligence). Bernhard Sendhoff (M'99-SM'05) received the Diploma and the Doctorate degree in physics from Ruhr-Universität Bochum, Bochum, Germany, in 1993 and 1998, respectively.</p><p>From 1998 to 1999, he was a Research Assistant at the Institute for Neuroinformatics. From 1999 to 2002, he was with Honda R&amp;D Europe GmbH, Offenbach/Main, Germany, where he has last been a Deputy Division Manager. He is currently the Chief Technology Officer of Honda Research Institute Europe GmbH, Offenbach, where he is also the Head of the Evolutionary and Learning Technology Group. He is also an Honorary Professor in the School of Computer Science, University of Birmingham, Birmingham, U.K. His current research interests include topics from systems biology and computational intelligence such as evolutionary system design and structure optimization of adaptive systems. He is the author or coauthor of more than 100 research papers published in journals and refereed conferences.</p><p>Dr. Sendhoff is a member of the Association for Computing Machinery, the European Neural Network Society, and the Deutsche Physikalische Gesellschaft (DPG). He is also a member of several advisory boards and scientific committees.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Alpaydin</surname></persName>
		</author>
		<title level="m">Introduction to Machine Learning</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<title level="m">Machine Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-criteria reinforcement learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zoltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kalmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="197" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evolutionary multi-objective optimization for simultaneous generation of signal-type and symbol-type representations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Körner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Evol. Multi-Criterion Optim</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>3rd Int. Conf. Evol. Multi-Criterion Optim<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3410</biblScope>
			<biblScope unit="page" from="752" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Regularization theory and neural network architectures</title>
		<author>
			<persName><forename type="first">F</forename><surname>Girosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="219" to="269" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fuzzy modeling of high-dimensional systems: Complexity reduction and interpretability improvement</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="212" to="221" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On generating FC 3 fuzzy rule systems from data using evolution strategies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Seelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="829" to="845" />
			<date type="published" when="1999-12">Dec. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ensemble learning via negative correlation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1399" to="1404" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Support vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse coding with an overcomplete basis set: A strategy employed by V1?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Olhausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3311" to="3325" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ROC graphs: Notes and practical considerations for data mining researchers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HP Labs</title>
		<imprint>
			<date type="published" when="2003-04">2003-4, 2003</date>
			<pubPlace>Palo Alto, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
	<note>HPL</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Model-based Gaussian and non-Gaussian clustering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Banfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="803" to="821" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multiobjective data clustering</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H C</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Topchy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="424" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A closer look at drawbacks of minimizing weighted sum of objectives for Pareto set generation in multicriteria optimization problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Struct. Optim</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="69" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic weighted aggregation for evolutionary multi-objective optimization: Why does it work and how?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Genetic Evol. Comput. Conf</title>
		<meeting>Genetic Evol. Comput. Conf<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1042" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Speeding up back-propagation using multi-objective evolutionary algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2705" to="2726" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving generalization of MLP with multi-objective optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Braga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saldanha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="189" to="194" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Multi-Objective Machine Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning with multi-objective criteria</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kadirkamanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inst. Electr. Eng. Conf. Artif. Neural Netw</title>
		<meeting>Inst. Electr. Eng. Conf. Artif. Neural Netw</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="53" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Harmonic competition: A self-organizing multiple criteria optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="652" to="668" />
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A novel multicriteria optimization algorithm for the structure determination of multilayer feedforward neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kottathra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Attikiouzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="135" to="147" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Multi-Objective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Wiley</publisher>
			<pubPlace>Chichester, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parameter identification with weightless regularization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Furukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Numer. Methods Eng</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="219" to="238" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A memetic Pareto approach to artificial neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Aust. Joint Conf</title>
		<meeting>14th Aust. Joint Conf</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evolutionary multi-objective approach to constructing neural network ensembles for regression</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Okabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Evolutionary Multi-Objective Optimization, C. Coello Coello</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="653" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural network regularization and ensembling using multi-objective evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Okabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr<address><addrLine>NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pareto multi-objective non-linear regression modelling to aid CAPM analogous forecasting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fieldsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw</title>
		<meeting>Int. Joint Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="388" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pareto evolutionary neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fieldsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="338" to="354" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multiobjective cooperative coevolution of artificial neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Garcia-Pedrajas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hervas-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Munoz-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1255" to="1274" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hierarchical rank density genetic algorithm for radial-basis function neural network design</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr. Evol. Comput</title>
		<meeting>Congr. Evol. Comput</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-objective structure selection for radial basis function networks based on genetic algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hatanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uosaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1095" to="1100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-objective programming in SVMs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Int. Conf. Mach. Learn</title>
		<meeting>20th Int. Conf. Mach. Learn<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-objective model selection for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Evolution Multi-Criterion Optimization Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3410</biblScope>
			<biblScope unit="page" from="534" to="546" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Support vector machines formulated as multi-objective linear programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICOTA</title>
		<meeting>ICOTA</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1171" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Structural risk minimization on decision trees using an evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Genetic Program</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>Eur. Conf. Genetic Program<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3003</biblScope>
			<biblScope unit="page" from="338" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">MOLeCS: Using multiobjective evolutionary algorithms for learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bernado-Manssilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garrell-Guii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMO</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>EMO<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">2001. 1993</date>
			<biblScope unit="page" from="696" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evolutionary multiobjective optimization of neural networks fore face detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Handmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="253" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evolving optimal feature extraction using multi-objective genetic programming: A methodology and preliminary study on edge detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Rockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Genetic Evol. Comput. Conf</title>
		<imprint>
			<biblScope unit="page" from="795" to="802" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Automatic generation of controllers for embodied legged organisms: A Pareto evolutionary multi-objective approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="394" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A multi-objective genetic algorithm for learning linguistic persistent quries in text retrieval environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Herrera-Viedma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multi-Objective Machine Learning</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="585" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Advanced Fuzzy Systems Design and Applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Physica Verlag</publisher>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Single-objective and twoobjective genetic algorithms for selecting linguistic rules for pattern recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Murata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Türksen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets Syst</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="135" to="150" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pareto-optimality in fuzzy modeling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gomez-Skarleta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ibanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Eur</title>
		<meeting>6th Eur</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="694" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient fuzzy modeling under multiple criteria by using genetic algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Furuhashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matsushima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tsutsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst., Man, Cybern</title>
		<meeting>IEEE Int. Conf. Syst., Man, Cybern</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="314" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Three-objective geneticsbased machine learning for linguistic rule extraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="109" to="133" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A structure identification method of submodels for hierarchical fuzzy modeling using the multiple objective genetic algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tachibana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Furuhashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="495" to="513" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Fuzzy modeling with multi-objective neuro-evolutionary algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Gomez-Skarmeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Roubos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babuska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst., Man, Cybern</title>
		<meeting>IEEE Int. Conf. Syst., Man, Cybern</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="253" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Agent-based evolutionary approach to interpretable rule-based knowledge extraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Man</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. C, Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="155" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-objective hierarchical genetic algorithm for interpretable fuzzy rule absed knowledge extraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Man</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy Sets Syst</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="149" to="186" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rule extraction from neural networks with Pareto optimization</title>
		<author>
			<persName><forename type="first">U</forename><surname>Markowska-Kaczmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wnuk-Liplnski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Soft Computing</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="450" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Neural network ensembles</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Salammon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="993" to="1101" />
			<date type="published" when="1990-10">Oct. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">DIVACE: Diverse and accurate ensemble learning algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Int. Conf. Intell. Data Eng</title>
		<meeting>5th Int. Conf. Intell. Data Eng</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="619" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Generating accurate and diverse members of a neural network ensemble</title>
		<author>
			<persName><forename type="first">D</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="535" to="541" />
			<date type="published" when="1996">1996</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Diversity creation methods: A survey and categorisation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Ensemble learning using decorrelated neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rosen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="373" to="384" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Evolving hybrid ensembles of learning machines for better generalisation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="686" to="700" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Pareto neuro-evolution: Constructing ensemble of neural networks using multi-objective optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abbass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr. Evol. Comput</title>
		<meeting>Congr. Evol. Comput</meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="2074" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">COVNET: A cooperative coevolutionary model for evolving artificial neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Garcia-Pedrajas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hervas-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Munoz-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="575" to="596" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="207" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multiobjective structure selection for RBF networks and its application to nonlinear system design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hatanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uosaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multi-Objective Machine Learning</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="491" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Evolutionary multi-objective optimization for generating an ensemble of fuzzy rule-based classifiers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. Genetic Evol. Comput. Conf. Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2723</biblScope>
			<biblScope unit="page" from="1077" to="1088" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multiobjective genetic optimization of diagnostic classifiers with implementations for generating receiver operating characteristic curves</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kupinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anastasio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="675" to="685" />
			<date type="published" when="1999-08">Aug. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Multiobjective optimization using the niched Pareto genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nafpliotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IlliGAL, Univ. Illinois at</title>
		<imprint>
			<biblScope unit="volume">93005</biblScope>
			<date type="published" when="1993">1993</date>
			<pubPlace>Urbana-Champaign, Urbana-Champaign</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Generalization improvement in multi-objective learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gräning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw</title>
		<meeting>Int. Joint Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="9893" to="9900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Multi-class ROC analysis from a multiobjective optimisation perspective</title>
		<author>
			<persName><forename type="first">R</forename><surname>Everson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fieldsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="918" to="927" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Design of a neural controller using multi-objective optimization for nonminimum phase systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Fuzzy Sets Syst</title>
		<meeting>IEEE Int. Conf. Fuzzy Sets Syst</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="533" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A multi-objective genetic algorithm for feature selection and granularity learning in fuzzyrule based classification systems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Del-Jesus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Villar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint 9th IFSA World Congr. 20th NAFIPS Int. Conf</title>
		<meeting>Joint 9th IFSA World Congr. 20th NAFIPS Int. Conf</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1253" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Selecting features in neurofuzzy modelling by multiobjective genetic algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Emmanouilidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Macintyre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw</title>
		<meeting>Int. Joint Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="749" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Feature seelction for ensembles: A hierarchical multi-objective genetic algorithm approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bortolozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Conf. Anal. Recognit</title>
		<meeting>7th Int. Conf. Anal. Recognit</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="676" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Evolutionary model selection in unsupervised learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Street</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Menczer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Data Anal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="531" to="556" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Exploiting the tradeoff-The benefits of multiple objectives in data clustering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Handl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Evolutionary Multi-Criterion Optimization Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3410</biblScope>
			<biblScope unit="page" from="547" to="560" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Estimating the number of clusters in a dataset via the gap statistics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="411" to="423" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Evolving artificial neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1999-09">Sep. 1999</date>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1423" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Empirical evaluation of the improved Rprop learning algorithm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hüsken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">C</biblScope>
			<biblScope unit="page" from="105" to="123" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A direct adaptive method for faster backpropgation learning: The RPROP algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Neural Netw</title>
		<meeting>IEEE Int. Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A fast elitist nondominated sorting genetic algorithm for multi-objective optimization: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Parallel Problem Solving Nat</title>
		<meeting>Parallel Problem Solving Nat</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">VI</biblScope>
			<biblScope unit="page" from="849" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">PROBEN1-A set of neural network benchmark problems and benchmarking rules</title>
		<author>
			<persName><forename type="first">L</forename><surname>Prechelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Karlsruhe, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Fakultät Inf., Univ. Karlsruhe</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Extracting rules from artificial neural networks with distributed representation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="505" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Extraction of symbolic rules from artificial neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kamruzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Islam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Eng., Comput. Technol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="271" to="277" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Generating concise and accurate classification rules for breast cancer disgnosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Setiono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="205" to="219" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Burnham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anderson</surname></persName>
		</author>
		<title level="m">Model Selection and Multimodel Inference</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Alleviating catastrophic forgetting via multiobjective learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw</title>
		<meeting>Int. Joint Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="6367" to="6374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A universal theorem on learning curves</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="166" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Parameter convergence and learning curves for neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="747" to="769" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Pareto optimality, GA-easiness and deception</title>
		<author>
			<persName><forename type="first">S</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rawlins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Genetic Algorithms</title>
		<meeting>Int. Conf. Genetic Algorithms</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="118" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Reducing local optima in singleobjective problems by multi-objectivization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Conf. Evol. Multi-Criterion Optim</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>1st Int. Conf. Evol. Multi-Criterion Optim<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993. 2001</date>
			<biblScope unit="page" from="269" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">On-line learning with minimal degradation in feedforward networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Angulo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Torras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="657" to="668" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Parameter incremental learning algorithm for neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Banta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1424" to="1438" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in simple networks: An analysis of the pseudo-rehearsal solution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Frean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Netw.: Comput. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="227" to="236" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Connectivity in real and evolved associative memories</title>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Calcraft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Davey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="153" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Classes of network connectivity and dynamics</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sporns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complexity</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="28" to="38" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Evolutionary multi-objective optimization of spiking neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Artif. Neural Netw. (ICANN) Part I</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>Int. Conf. Artif. Neural Netw. (ICANN) Part I<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4668</biblScope>
			<biblScope unit="page" from="370" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Pulsed Neural Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
