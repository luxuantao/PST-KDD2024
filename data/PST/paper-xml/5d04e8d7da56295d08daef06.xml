<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context Attentive Document Ranking and Query Suggestion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-06-05">5 Jun 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wasi</forename><forename type="middle">Uddin</forename><surname>Ahmad</surname></persName>
							<email>wasiahmad@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
							<email>kwchang.cs@ucla.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongning</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Virginia</orgName>
								<address>
									<settlement>Charlottesville</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Context Attentive Document Ranking and Query Suggestion</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-06-05">5 Jun 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:1906.02329v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Search tasks</term>
					<term>document ranking</term>
					<term>query suggestion</term>
					<term>neural IR models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a context-aware neural ranking model to exploit users' on-task search activities and enhance retrieval performance. In particular, a two-level hierarchical recurrent neural network is introduced to learn search context representation of individual queries, search tasks, and corresponding dependency structure by jointly optimizing two companion retrieval tasks: document ranking and query suggestion. To identify variable dependency structure between search context and users' ongoing search activities, attention at both levels of recurrent states are introduced. Extensive experiment comparisons against a rich set of baseline methods and an in-depth ablation analysis confirm the value of our proposed approach for modeling search context buried in search tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The scope and complexity of users' information need never get simpler <ref type="bibr" target="#b0">[1]</ref>. To fulfill a complex need, e.g., job hunting, users issue a series of queries, exam and click search results from multiple sites. Such search behavior is usually referred to as search tasks <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b48">49]</ref> or sessions, which are characterized by rich types of user-system interactions, implicit feedback, and temporal dependency among the search activities. Various studies have shown that exploring users' on-task search activities to enrich retrieval models is effective for improving retrieval performance, especially when users' intent is ambiguous. For example, through a large-scale analysis of search engine logs, Bennett et al. <ref type="bibr" target="#b3">[4]</ref> showed that a user's short-term search history becomes more important as the search session progresses. White et al. <ref type="bibr" target="#b50">[51]</ref> reported the use of users' on-task behavior yielded promising gains in retrieval performance in the Microsoft Bing search engine.</p><p>However, limited by the devised form of representation for search context, most existing solutions model users' on-task behavior in an ad-hoc manner. Typically, keywords or statistical features are extracted from previous clicks or queries <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b50">51]</ref>, or manually crafted rules are introduced to characterize the changes in a search sequence <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b52">53]</ref>. Those algorithms' exploration of contextual information is thus subjected by the capacity of their employed representation, which can hardly be exhaustive nor optimal for the retrieval tasks of interest. For example, keyword-based methods suffer from vocabulary gap, and statistical features become unreliable with sparse observations. Even if a rich set of contextual features can be provided beforehand, the dependency structure has to be imposed a priori, e.g., either to use the immediate one preceding query or all queries in a task to calculate the feature values. This cannot capture variable range dependency within a user's sequential search activities.</p><p>Moreover, during a search task users have to get involved in multiple retrieval tasks. For instance, to perform a search task, not only does a user need to respond to the system's returned search results (e.g., examine or click), but also to the suggested queries (e.g., accept or revise the suggestions). Arguably, when concurrently performing these retrieval tasks, users are motivated by the same underlying intent, and therefore their search activities are interrelated across the companion retrieval tasks. This dependency reveals fine-grained search context beyond the content of submitted search queries and clicked documents. For example, if a user skipped a top-ranked document, the suggestion for next query should be less related to such documents. Inspired by these scenarios, recent works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41]</ref> have proposed to jointly model multiple types of user search activities. These solutions focus mostly on using an auxiliary task to assist the target task with two objectives:</p><p>(1) leveraging large amount of cross-task data, and (2) benefiting from a regularization effect that leads to more useful representations. However, none of these multi-task retrieval solutions model the sequential dependency across different retrieval tasks. This inevitably limits their ability in exploiting information buried in a user's search sequence.</p><p>To address the aforementioned challenges in modeling users' ontask search behaviors, we present a context-aware neural retrieval solution, Context Attentive document-Ranking and query-Suggestion (CARS). Given a query and the user's past search activities (e.g., his/her issued queries and clicks) in the same search task, CARS encodes them into search context representations. Based on the learnt representations, CARS then predicts the ranking of documents for the given query and in turn suggests the next query. To encode search context, we employ a two-level hierarchical recurrent neural network. At the lower level, given queries and documents as a sequence of words, we encode them using bidirectional recurrent neural networks; and at the upper level, we introduce another layer of recurrent states on top of the embedding vectors of queries and documents to represent task-level search context. Each observed action of query reformulation or result click contributes to the update of task-level recurrent states, which thus serve as a learned summary of past search activities, providing relevant information for predicting document ranking and next query. To identify variable dependency structure between search context and ongoing user search activities, we apply attention mechanism at both levels of recurrent states. This endows CARS to model the development of users' search intent in the course of search tasks.</p><p>To learn search context representation and corresponding dependency structure, CARS jointly optimize for two companion retrieval tasks, i.e., document ranking and query suggestion. CARS models the relatedness between these two tasks via a regularized multi-task learning approach <ref type="bibr" target="#b9">[10]</ref>. We evaluate CARS on the AOL search log, the largest publicly available search engine log with both authentic user query and click information. We compared our model with a rich set of baseline algorithms (both classical and neural IR models), which model users on-task behavior differently for document ranking and query suggestion. Extensive experiment comparisons and significant improvements over the baselines confirm the value of modeling search context buried in search tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Context information embedded in a search task has shown to be useful for modeling user search intent <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26]</ref>. A rich body of research has explored different forms of context and search activities and built predictive models to improve retrieval performance. The related works can be roughly categorized as data-driven v.s., model-driven solutions for task-based retrieval.</p><p>Data-driven solutions focus on deriving contextual features from users' search activities to characterize their search intent. Shen et al. <ref type="bibr" target="#b42">[43]</ref> extract keywords from users' past queries and clicked documents in a search session to re-rank document for future queries. White et al. <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref> develop a rich set of statistical features to quantify context information from users' on-task search behavior. Xiang et al. <ref type="bibr" target="#b52">[53]</ref> craft a collection of rules to characterize the search context, e.g., specialization v.s., generalization, so as to extract features by the rules. As we discussed before, data-driven solutions are confined by their employed form of context representation, e.g., keywords or manually crafted rules, which is hardly generalizable or optimal with respect to different retrieval tasks.</p><p>Model-driven solutions build predictive models about users' search intent or future search behavior. Cao et al. <ref type="bibr" target="#b5">[6]</ref> model the development of users' search intent in search sessions with a variable length Hidden Markov Model, and utilize the inferred search intent for document ranking and query suggestion. Reinforcement learning is utilized to model user-system interactions in search tasks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">30]</ref>. Syntactic changes between consecutive queries and the relationship between query changes and retrieved documents, are modeled to improve retrieval results. However, the predefined model space (e.g., add/remove query terms) and state transition structure (e.g., first-order Markov chain) forbid this type of solutions from learning rich interaction between users and a system.</p><p>Encouraged by the recent success of neural network based retrieval solutions <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29]</ref>, various models have been developed to optimize session-based retrieval. Mitra et al. <ref type="bibr" target="#b31">[32]</ref> studies session context with a distributed representation of queries and reformulations and uses the learned embeddings to improve query prediction. <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b51">52]</ref> exploited hierarchical neural architectures to model a sequence of queries in the same search session.</p><p>Recently, Chen et al. <ref type="bibr" target="#b6">[7]</ref> propose a hierarchical attention based structure to capture session-and user-level search behavior. However, these neural models focus on learning search context representation from single retrieval tasks, e.g., document ranking or query suggestion, and therefore cannot utilize the reinforcement between different retrieval tasks. In addition, most solutions for search task based representation learning do not differentiate the influence from different actions in a sequence. For example, clicks from a nearly duplicated query to the current query discloses more information about a user's current focus than those not similar to the current query, although that nearly duplicated query might be submitted long time ago. Recognizing such variable length dependency is crucial for modeling the search context and thus inferring users' information need.</p><p>Multi-task learning has been explored in information retrieval studies <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41]</ref>. The basic idea is to use one learning task as regularization for another task. For example, Liu et al. <ref type="bibr" target="#b26">[27]</ref> proposed a multi-task deep neural approach to combine query classification and document ranking, and showed improvement on both tasks. Huang et al. <ref type="bibr" target="#b16">[17]</ref> coupled context-aware ranking and entity recommendation to enhance entity suggestion for web search. Similarly, Salehi et al. <ref type="bibr" target="#b40">[41]</ref> adopted semantic categorization of the query terms to improve query segmentation. From a different angle, Ahmad et al. <ref type="bibr" target="#b1">[2]</ref> proposed to train a document ranker and a query recommender jointly over a sequence of queries in a session. However, none of the existing multi-task solutions paid attention to the dependency structure embedded in a search task, which characterizes users' search intent. In this work, we explicitly model the dependency between users' in-session query and click sequence by learning context attentive representations, which mutually enhance document ranking and query suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A CONTEXT ATTENTIVE RANKING AND SUGGESTION MODEL 3.1 Problem Statement</head><p>In a search task, a user keeps formulating queries, examining and clicking search results until his/her information need is satisfied <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b48">49]</ref>. A user's search activities in the same task, e.g., query reformulation and result clicks, often exhibit strong inter-dependency, which provides rich context information for systems to improve their retrieval performance <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b50">51]</ref>. However, as the users' information need and behavior pattern vary significantly from task to task, modeling the search context and its use in specific retrieval problems is the key to unleash its vast potential.</p><p>Assuming a user submits a query "it masters ny 2018", a common interpretation of it could be that the user is looking for the latest IT master's degree programs in New York. However, if we knew that the user just followed a suggested query "software engineer ny" several queries before, it becomes evident that the user is actually looking for a software engineer position in New York, and he/she has a master's degree in IT. Hence, the search engine should promote job listings in the region that match the user's qualification and make more specific query suggestions (e.g., target at different industries). As the task progresses, if the user's next clicked results reflect his/her interest in healthcare industry, the system can further customize the search results and specialize its suggested queries (e.g., suggest names of particular companies in healthcare industry).  By inferring the user intent behind each query reformulation and result click regarding the context of his/her immediate interaction history, a search engine can rapidly improve its service quality as the search task progresses.</p><p>In this work, we propose a framework to explicitly model search context using representation learning to improve both document ranking and query suggestion in a search task. To the best of our knowledge, our proposed Context Attentive document Ranking and query Suggestion (CARS) model is of its first kind where both a user's query and click sequences from an ongoing search task are utilized to learn the search context representation and optimize two distinct retrieval tasks jointly.</p><p>In a nutshell, CARS maintains a two-level hierarchical recurrent neural network (RNN) structure for learning in-task search context representation. The system architecture of CARS is illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. At the lower level, RNN-based query and document encoders encapsulate information in a user's query formulation and click actions into continuous embedding vectors; and at the upper level, another set of RNN-based query-and document-session encoders take the embeddings of each search action as input and summarize past on-task search context on the fly. Then, the learned representations from both levels are utilized to rank documents under the current query and suggest the next query.</p><p>Before we zoom into the details of each component, we first specify the definitions of several important concepts and the notations. We represent a user's search history as a sequence of queries Q = {q 1 , q 2 , . . . , q N }, where each query q i is associated with a timestamp t i when the query is submitted and the corresponding list of returned documents, D i = {d i,1 , d i,2 , . . . , d i, M }. Each query q i is represented as the original text string that users submitted to the search engine, and Q is ordered according to query timestamp t i . Each returned document d i,m has two attributes: its text content and click timestamp c i,m (c i,m = 0, if it was not clicked). In general, user clicks serve as a good proxy of relevance feedback <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, and they serve as the training signals for our document ranker. In this work, we follow Wang et al. <ref type="bibr" target="#b48">[49]</ref>'s definition of search tasks: <ref type="bibr" target="#b23">[24]</ref>, which is usually defined by the inactive time between two consecutive search queries. Some past research assumes each search session can associate with only one particular information need, and thus they treat a session as a task <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">30]</ref>. This further introduces the compounding concepts of in-session task <ref type="bibr" target="#b25">[26]</ref> and across-session task <ref type="bibr" target="#b48">[49]</ref>. CARS can be readily applied to these different types of task (or session), as long as it follows our definition above. In this work, we will not differentiate between these different realizations of search tasks, but take it as the input of our algorithm. When no ambiguity is introduced, we will use the terminology "search task" and "search session" interchangeably in this paper. In addition, without further specification, we use W : and b : to represent a trainable weight matrix and vector, respectively as our model parameters.</p><formula xml:id="formula_0">Definition (Search Task) Given a user's search history Q, a search task T k is a maximum subset of queries in Q, such that all the queries in T k correspond to a particular information need. As a result, {T k } K k =1 is a set of disjoint partitions of a user's search history Q: ?j k, T j ? T k = ? and Q = k T k . A related concept in IR literature is search session</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Search Context Representations</head><p>CARS models users' search intent buried in search tasks by jointly learning from retrieval tasks of document ranking and query suggestion. Formally, we consider document ranking as learning a candidate document's relevance to a user's current query and search context, and query suggestion as learning the most likely query that follows the current query and search context. We treat queries and documents as variable length word sequences, and a search task as a sequence of queries and their result clicks. The key in both learning tasks is the representation of search actions and search context, and the dependency structure among them.</p><p>To this end, we employ hierarchical recurrent neural networks where the lower-level networks learn the query and document representations separately and the upper-level networks model the variable length dependency structure in the search context.</p><p>? Lower-level Query Document Embedding. The lower-level recurrent network creates a fixed-length vector to represent a variable length word sequence (e.g., query, document). CARS employs two networks with the same architecture to encode queries and documents separately, so as to capture their heterogeneity. In essence, given a sequence of T words (w 1 , . . . , w T ), the network first embeds the word w t into a l w -dimensional vector x t using a pre-trained word embedding <ref type="bibr" target="#b37">[38]</ref>. Then, a bidirectional recurrent neural network (BiLSTM) <ref type="bibr" target="#b41">[42]</ref> with an inner-attention mechanism <ref type="bibr" target="#b27">[28]</ref> is used to encode the word sequence into a fixed-length vector.</p><p>Specifically, an LSTM <ref type="bibr" target="#b14">[15]</ref> encodes an input sequence by sequentially updating a hidden state. At each step t, given an input word vector x t and the previous hidden state h t -1 , the hidden state is updated by h t = LST M(h t -1 , x t ). <ref type="foot" target="#foot_0">1</ref> To better capture information presented in a word sequence, we use a BiLSTM (one forward and one backward LSTM) to encode the sequence from both directions. The BiLSTM forms a sequence of T hidden representations,</p><formula xml:id="formula_1">H = [h 1 , . . . , h T ], H ? R 2l h ?T (1)</formula><p>by concatenating the hidden states generated by the two LSTM models, where l h is the dimension of the forward and backward LSTM hidden unit. To recognize the topical importance of each word in a given input sequence, e.g., focus of a query, we apply inner-attention to form a fixed-length sequence representation ? from the variable length sequence representation H ,</p><formula xml:id="formula_2">? = H? h , ? h = softmax W ? 1 tanh(W ? 2 H + b ? 1 ) + b ? 2 ,<label>(2)</label></formula><p>where ? h ? R T is the attention vector, tanh(?) is an element-wise tangent function on the input matrix, and W ? 1 ,W ? 2 , b ? 1 and b ? 2 are the parameters of a two-layer perceptron to estimate the attention vector. The attention vector assigns weight for each individual word in the sequence, such that informative words would play a more important role in the final sequence representation ? .</p><p>When no ambiguity is invoked, we will refer to q i and d i,m as the sequence representations learnt for the i-th query and the corresponding m-th candidate document.</p><p>? Upper-level Task Embedding. Within a search task, a user submits a sequence of queries, examines the returned documents, and clicks a few of them when found relevant. To encode the search context of an on-going task, we use a pair of recurrent neural networks that operate on top of the query and click representations learnt from the lower level networks, and refer to them as sessionquery encoder and session-click encoder respectively.</p><p>Query reformulation chain in a search task carries important contextual information about a user's search intent <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">30]</ref>. To represent search context in a query chain, we use an LSTM as the session-query encoder. This encoder takes a sequence of learned query representations till query q i as input and computes the corresponding recurrent states by s q i = LST M(s q i-1 , q i ), where s q i ? R l q is the session recurrent state at the i-th query and l q is the dimension of this LSTM's hidden unit.</p><p>A user's click sequence in a search task also contributes to its search context. But research shows that user clicks reflect their search intent from a different perspective than query reformulation chain does, and also these two types of feedback introduce distinct biases and variances in different retrieval tasks <ref type="bibr" target="#b22">[23]</ref>. We employ a separate task-level LSTM for the clicked documents, which we refer to as the session-click encoder. Assume documents {d c 1 , d c 2 , . . . d c N i } ? ? t =1,2, ...,i-1 D t are the clicked documents in the current search task T k before query q i is submitted (according to their click and query timestamps). The session-click encoder sequentially visits each clicked document and at the n-th clicked document d c n , the recurrent state of this LSTM is updated by</p><formula xml:id="formula_3">s c n = LST M(s c n-1 , d c n )</formula><p>, where s c n ? R l c and l c is the dimension of this LSTM's hidden unit.</p><p>Not all the clicked documents are equally useful to construct the search context <ref type="bibr" target="#b22">[23]</ref>, and they may depend on each other to collectively present a complete user information need. Hence, we employ the inner-attention used in Eq (2) over the learned click recurrent states to recognize the importance of each different clicked document and learn their composition in an ongoing search task.</p><p>? Context Attentive Representations. In recurrent neural networks, it is typical to use the last hidden state as a summary of the whole sequence. However, in the scenario of task-based retrieval, the immediate past search action is not necessarily the most important to model search context <ref type="bibr" target="#b3">[4]</ref>. But it is also difficult to pre-define the dependency structure. It is preferred to learn the dependency structure from a user's past interactions in the same task.</p><p>To this end, CARS learns to represent the search context till current query q i by applying attention <ref type="bibr" target="#b6">[7]</ref> over the whole search sequence, which accounts for the informativeness of each past search action regarding the search context and q i . To enhance search context representation, the session query recurrences are refined as follows:</p><formula xml:id="formula_4">s at t,q i = i-1 j=1 ? q j s q j , ? q j = exp(q ? i W e s q j ) i-1 k =1 exp(q ? i W e s q k ) ,<label>(3)</label></formula><p>where ? q j is the attention weight computed against the current query representation q i , session query recurrence s q j , and a learnt attention weight matrix W e . The attentive vector s at t,q i integrates the contribution of the previous in-task queries and guides the generation of current query q i .</p><p>Similarly, we use this attention mechanism between q i and click recurrence states [s c 1 , . . . , s c</p><p>N i ] to form s at t,c i , which represents the document content explored by the user previously in the same task before q i . To combine potentially complementary information from these two task-level summary vectors, we concatenate them to form our search context attentive representation, s at t i = [s at t,q i , s at t,c i ] and s at t i ? R l q +l c . It is then used in the document ranking and query suggestion tasks. 2 We should note that the attention applied over the past search activities recognizes their contributions in representing the search context up to the current search action, but not to a particular retrieval purpose, e.g., document ranking or query suggestion. We will discuss how to optimize these task-level representations with respect to specific retrieval tasks next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint Learning of Ranking and Suggestion</head><p>In the following, we describe how we optimize the model parameters to learn effective search context representations.</p><p>? Document Ranking. The goal of a document ranker is to rank the most relevant documents to the input query on top. As we do not have explicit relevance feedback from users, we use their clicks as relevance labels. To simplify the model, we appeal to the pointwise learning to rank scheme, where a ranker is designed to predict whether a document will be clicked under a given query. The documents are then ranked by the predicted click probabilities. In CARS, the click prediction for the m-th document under query 2 We compute individual attention and in turn attentive vector for the document ranking (? j,r ; s at t,r i ) and query suggestion (? j, s ; s at t,s i ) tasks.</p><p>q i is based on the document vector d i,m (see Section 3.2) and a composed vector u i generated by the current query vector q i and the search context attentive vector s at t i ,</p><formula xml:id="formula_5">u i = W u 1 s at t i + W u 2 q i + b u ,<label>(4)</label></formula><p>where W u 1 , W u 2 , b u are parameters of our ranker. Albeit user clicks are known to be biased <ref type="bibr" target="#b22">[23]</ref>, empirical studies also show promising results <ref type="bibr" target="#b17">[18]</ref>. We leave more advanced click modeling and learning to rank approaches as our future work.</p><p>Various models can be employed here to predict click based on these two vectors. Following <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">33]</ref>, we first create an extended matching vector to capture the similarity between d i,m and u i , as</p><formula xml:id="formula_6">[d i,m , u i , (d i,m -q i ), (d i,m ? q i )]</formula><p>where ? denotes element-wise multiplication. Then we feed this matching vector to a three-layer batch-normalized maxout network <ref type="bibr" target="#b11">[12]</ref> to predict the click probability P(c i,m |q i , d i,m , s at t i ), denoted as o i,m . ? Query Suggestion. The query suggestion component (a.k.a. recommender) takes current query and search context as input to predict the next query for a user as P(q i+1 |q i , s at t i ), which can be decomposed into a series of word-level predictions,</p><formula xml:id="formula_7">P(q i+1 |q i , s at t i ) = |q i +1 | t =1 P(w t |w 1:t -1 , q i , s at t i ).</formula><p>This can be readily estimated by the decoder in a sequence to sequence network <ref type="bibr" target="#b47">[48]</ref>.</p><p>We use the search context attentive vector to initialize the hidden state h dec 0 in the decoder by</p><formula xml:id="formula_8">h dec 0 = tanh(W h 0 s at t i + b h 0 ), where W h 0 ? R l h ?(l q +l c</formula><p>) and b h 0 ? R l h are the decoder parameters. The recurrence is computed by:</p><formula xml:id="formula_9">h dec t = LST M(h dec t -1 , w t -1 )</formula><p>, where w t -1 is the previously generated word. In standard use of an LSTM-based sequence decoder, the output sequence is generated by a recurrently computed latent state h dec t -1 and sampling the words accordingly. This, unfortunately, cannot carry over the search context in query word sequence generation, as the context is only used to initialize the decoder. To enhance the influence of search context in our query suggestion, we apply attention based on the search context s at t i and current query q i in the decoding process.</p><p>During a web search, users often reformulate their query by modifying a few words from their last query. For example, more than 39% users repeat at least one term from their immediate previous queries <ref type="bibr" target="#b19">[20]</ref> and an average of 62% terms in a query are retained from their previous queries <ref type="bibr" target="#b44">[45]</ref>. Motivated by this, we predict the t-th word in the next query q i+1 based on a constructed attention vector a i,t that encodes the query terms in the current query q i with respect to the latent state of decoder at the t-th generated word:</p><formula xml:id="formula_10">a i,t = |q i | k=1 ? q t k h enc k , where h enc k</formula><p>is the k-th column of H when encoding q i (defined in Eq (1)). The normalized attention weight ? q t k is learned using a bilinear function,</p><formula xml:id="formula_11">? q t k = exp((h dec t ) ? W ? q h enc k ) |q i | j=1 exp((h dec t ) ? W ? q h enc j ) ,<label>(5)</label></formula><p>where W ? q is the parameter matrix to be learned. We concatenate the attention vector a i,t for current query q i with h dec t , combine it with the search context vector s at t i by</p><formula xml:id="formula_12">? i,t = W ? 1 s at t i + W ? 2 [h dec t , c i,t ],<label>(6)</label></formula><p>and generate the next word w t in the suggested query q i+1 based on the following probability distribution over the vocabulary V ,</p><formula xml:id="formula_13">P(w t |w 1:t -1 , q i , s at t i ) = softmax(W ?en ? i,t + b ?en ),<label>(7)</label></formula><p>where W ?en ? R |V |?(l q +l c ) and b ?en ? R |V | are the corresponding decoder parameters. However, the search space for this decoding problem is exponentially large, as every combination of words in the vocabulary can be a candidate query. We follow the standard greedy decoding algorithm to generate the next query. Specifically, the best prefix w 1:t up to length t is chosen iteratively and extended by sampling the most probable word according to the distribution in Eq <ref type="bibr" target="#b6">(7)</ref>. The process ends when we obtain a well-formed query containing the unique end-of-query token.</p><p>? Optimizing the Representations via Multi-task Learning.</p><p>To better couple the document ranking and query suggestion tasks for learning the search context representations, we adopt the regularization based multi-task learning technique <ref type="bibr" target="#b9">[10]</ref> and decompose W u 1 (defined in Eq (4)) and W ? 1 (defined in Eq ( <ref type="formula" target="#formula_12">6</ref>)) parameter matrices into W u 1 = W shar e + W r ank and W ? 1 = W shar e + W r ecom , where W u 1 ? R l h ?(l q +l c ) and W ? 1 ? R l h ?(l q +l c ) . Here, W shar e is shared between the two tasks, while W r ank and W r ecom are kept private to the corresponding learning tasks. We choose to impose this structure to couple the two learning tasks, otherwise they would have full degree of freedom to over fit their own observations rather than collaboratively contribute to the shared search context representation learning. W shar e is thus expected to capture the homogeneity in the search context's effect in these two tasks, and W r ank and W r ecom are to capture task homogeneity from task data accordingly.</p><p>To estimate the model parameters in CARS, we minimize regularized negative log-likelihoods of the document ranking and query suggestion tasks,</p><formula xml:id="formula_14">L R1 + L R2 + 1 N N k =1 q i ?T k L ranker (q i ) + L recom. (q i ; q 1:i ) ,</formula><p>where N is the number of search tasks in the training set. L ranker (q i ) is the negative log-likelihood with respect to the predicted clicks under query q i :</p><formula xml:id="formula_15">L ranker (q i ) = - 1 m m I(c i,m &gt; 0) log o i,m + I(c i,m = 0) log(1 -o i,m ) ,</formula><p>where c i,m and o i,m represent the observed user clicks and predicted click probability for the m-th candidate document for query q i . L recom. is the negative log-likelihood of generating query i based on all previous queries and clicks in the task T k :</p><formula xml:id="formula_16">L recom. (q i ) = - |q i | t =1 log P(w t |w 1:t -1 , q 1:i-1 , d),</formula><p>where d ? {d j:k |c j:k = 1}, j ? {1, . . . , i -1} and k ? {1, . . . , m}.</p><p>To avoid overfitting and prevent the predicted word distributions being highly skewed, we apply two forms of regularization. First, we regularize the shared and private parameters W shar e , W r ank and W r ecom by </p><formula xml:id="formula_17">L R1 = ? 1 ?W shar e ? 2 + ? 2 (?W r ank ? 2 + ?W r ecom ? 2 ).</formula><formula xml:id="formula_18">L R2 = ? 3 w ?V P(w |q 1:i-1 , w 1:t -1 ) log P(w |q 1:i-1 , w 1:t -1 )</formula><p>as suggested in <ref type="bibr" target="#b1">[2]</ref> to smooth the predicted word distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Experimental Setups</head><p>We conduct experiments on the AOL search log data <ref type="bibr" target="#b36">[37]</ref>. Following <ref type="bibr" target="#b45">[46]</ref>, we use the first five weeks as background set, the next six weeks as training set, and the remaining two weeks are divided into half to construct validation and test sets. Note this setting is different from <ref type="bibr" target="#b1">[2]</ref> that randomly splits search log. The background set is used to generate candidate queries for later query suggestion evaluations. We removed all non-alphanumeric characters from the queries, applied a spelling checker and a word segmentation tool, and lower-cased all the query terms.</p><p>The AOL query log only contains clicked documents under each query and do not record other candidate documents returned to the users. Therefore, for a given query, <ref type="bibr" target="#b1">[2]</ref> aggregated a list of candidate documents, selected from the top documents ranked by BM25 <ref type="bibr" target="#b39">[40]</ref> and appended the recorded clicks in the list. However, in our preliminary experiments, we observed that many recorded clicks do not have lexical overlap concerning the queries. One possible reason is that we crawled the recorded clicks from the AOL search log in 2017 and many of the clicked documents' content updated since 2006 when the AOL log was recorded. In such a case, a data-driven model will exploit the differences in lexical overlapping to identify the clicked documents. To avoid such a bias in selecting candidate documents, we appeal to the "pseudolaebling" technique, which has been used in prior works <ref type="bibr" target="#b8">[9]</ref> to construct large-scale weekly supervised data to train neural IR models. We first collect the top 1,000 documents for each query retrieved by BM25 and then filtered out the queries, none of whose recorded clicks is in this set of documents. For the resulting queries, we sampled candidate documents from a fixed size window centered at the positions where BM25 ranks the recorded documents. Based on this strategy, we sampled 50 candidate documents per query in the test set, and 5 candidates per query for training and validation sets to speed up training and reduce memory requirements. Besides, following <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> we only used the document title as its content in our experiments.</p><p>We followed <ref type="bibr" target="#b23">[24]</ref> to segment user query logs into tasks. In each user's query sequence Q, we decided the boundaries between tasks based on the similarity between two consecutive queries. To this end, we first represented a query by averaging its query terms' pre-trained embedding vectors and computed the cosine similarity Table <ref type="table">2</ref>: Comparison between document ranking models. The paired t-test is conducted by comparing the best and second-best ranking models under each metric, and the test result is presented in bold-faced (p-value &lt; 0.05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>MAP MRR NDCG @1 @3 @10 Traditional IR-models BM25 <ref type="bibr" target="#b39">[40]</ref> 0.230 0.206 0.206 0.269 0.319 QL <ref type="bibr" target="#b38">[39]</ref> 0.195 0.166 0.166 0.213 0.276 FixInt <ref type="bibr" target="#b42">[43]</ref> 0.242 0.224 0.212 0.275 0.332 Single-task Learning DRMM <ref type="bibr" target="#b13">[14]</ref> 0.201 0.228 0.129 0.223 0.264 DSSM <ref type="bibr" target="#b17">[18]</ref> 0.283 0.307 0.188 0.231 0.341 CLSM <ref type="bibr" target="#b43">[44]</ref> 0.313 0.341 0.205 0.252 0.373 ARC-I <ref type="bibr" target="#b15">[16]</ref> 0.401 0.411 0.259 0.374 0.463 ARC-II <ref type="bibr" target="#b15">[16]</ref> 0.455 0.465 0.309 0.434 0.521 DUET <ref type="bibr" target="#b32">[33]</ref> 0.479 0.490 0.332 0.462 0.546 Match Tensor <ref type="bibr" target="#b18">[19]</ref> 0.481 0.501 0.345 0.472 0.555 Multi-task Learning M-NSRF <ref type="bibr" target="#b1">[2]</ref> 0.491 0.502 0.348 0.474 0.557 M-Match Tensor <ref type="bibr" target="#b1">[2]</ref> 0.505 0.518 0.368 0.491 0.567 CARS 0.531 0.542 0.391 0.517 0.596 between the resulting vectors. <ref type="foot" target="#foot_1">3</ref> We discarded the search tasks with less than two queries (no in-task search context). Statistics of our constructed experiment dataset are provided in Table <ref type="table" target="#tab_1">1</ref>.</p><p>? Evaluation metrics. We used Mean Average Precision (MAP), Mean Reciprocal Rank (MRR), and Normalized Discounted Cumulative Gain (NDCG) as our evaluation metrics for the document ranking task, where we treat the clicked documents as relevant.</p><p>For the query suggestion task, we evaluate a model's ability to discriminate and generate the next query. To test its discrimination ability, we follow <ref type="bibr" target="#b45">[46]</ref> and apply a testing model to rank a list of candidate queries that might follow an anchor query (the second last query of a task). We evaluate the rank of the recorded next query among the candidates using MRR. The candidate queries are selected as the most frequent queries (we consider at most 20 of them) following the anchor query in the background set. To examine its generation ability, a model is applied to generate the next query and evaluated against the true query based on F1 and BLEU scores <ref type="bibr" target="#b34">[35]</ref>. Both scores measure overlapping between the generated query term sequence and ground-truth sequence.</p><p>? Baselines. We compared CARS with both classical and neural ad-hoc retrieval models. We consider BM25 <ref type="bibr" target="#b39">[40]</ref>, Query likelihood based Language model (QL) <ref type="bibr" target="#b38">[39]</ref>, and a context-sensitive ranking model FixInt <ref type="bibr" target="#b42">[43]</ref>, as our classical IR baselines for document ranking. To compare CARS with neural ranking models, we selected the same set of models used in <ref type="bibr" target="#b1">[2]</ref>, and trained and evaluated them using their publicly available implementations. To examine CARS's performance in query suggestion, we compared with the sequence to sequence (Seq2seq) approach proposed in <ref type="bibr" target="#b2">[3]</ref>, an enhanced Seq2seq model with attention mechanism <ref type="bibr" target="#b30">[31]</ref>, session-based suggestion models HRED-qs <ref type="bibr" target="#b45">[46]</ref>, M-Match Tensor <ref type="bibr" target="#b1">[2]</ref> and M-NSRF <ref type="bibr" target="#b1">[2]</ref>. We used the public implementation of these query suggestion models. We carefully tuned the hyper-parameters for the baseline models. <ref type="foot" target="#foot_2">4</ref> For all the baselines, we tune the learning rate, dropout ratio, hidden dimension of the recurrent neural network units. For the models involving convolutional neural networks, we tuned the number of filters, and the filter sizes remained unchanged as reported in their original work.</p><p>? Experiment Setup. We kept the most frequent |V | = 80k words, and mapped all the others to an &lt;unk&gt; token. We trained CARS end-to-end using mini-batch SGD (with batch size 32) with Adam optimizer <ref type="bibr" target="#b24">[25]</ref>. To stabilize the learning process, we normalized the gradients if their L2 norm exceeds a threshold <ref type="bibr" target="#b35">[36]</ref>. In CARS, the number of hidden neurons in each of its encoders and decoders were selected from {64, 128, 256}. The initial learning rate and the dropout parameter <ref type="bibr" target="#b46">[47]</ref> were selected from {10 -3 , 10 -4 } and {0.1, 0.2, 0.3} based on its performance on validation set, respectively. We set the hyper-parameters ? 1 , ? 2 , and ? 3 to 10 -2 , 10 -4 , and 10 -1 after tuning on the validation set. We stopped training if the validation performance did not improve for 5 consecutive iterations. CARS generally stops after 20 epochs of training and each epoch takes 20 minutes on average on a TITAN XP GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Results</head><p>? Evaluation on document ranking. We report all models' document ranking performance in Table <ref type="table">2</ref>. As we can clearly observe CARS significantly outperformed all the traditional IR and neural IR baselines. Traditional ranking models only focus on keyword matching, which suffer seriously from vocabulary gap. We group the neural baselines into two groups, single-task learning and multitask learning models, where the latter can leverage information from the query suggestion task. All single-task neural ranking models only focus on per-query document matching. Although their learnt query document representations can greatly boosted retrieval performance in every single query, they cannot utilize any search context in a given search task, and therefore only provided sub-optimal search quality. Comparing with the baseline multi-task learning models, i.e., M-NSRF and M-Match Tensor, which model query formulation chain but not the associated click sequence, CARS complements search context by modeling the past clicks as well and enjoys clear benefit. Later we will perform detailed abalation analysis to decompose the gain into individual components of CARS for more in-depth performance analysis.</p><p>? Evaluation on query suggestion. We evaluate the models on two bases: a) identifying users' recorded next query from a list of candidate queries (i.e., discrimination ability), and b) generating users' next query (i.e., generation ability). The comparison results are reported in Table <ref type="table" target="#tab_2">3</ref>. CARS outperformed all the baselines with significant margins in both of its discrimination and generation abilities. Although a simple sequence to sequence model only considers consecutive query reformulations rather than the whole task, the attention mechanism still makes it the second best method (i.e., Seq2seq + Attn). This confirms the validity of our constructed local attentive vector (in Eq ( <ref type="formula" target="#formula_12">6</ref>)) for query suggestion. CARS improves on it by modeling the entire search task, especially the past click history. Compared with M-Match Tensor and M-NSRF, which model the whole query reformulation chain but still failed to perform in this evaluation, it shows the advantage of our learnt task-level context representation and its utility to the query suggestion task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Abalation Analysis and Discussions</head><p>We performed additional experiments by ablating CARS to analyze how and when each component of it adds benefit to the document ranking and query suggestion tasks. We provide the results of our ablation study in Table <ref type="table" target="#tab_3">4</ref> and discuss the significance of them next.</p><p>? Benefit of modeling search context. To understand the impact of modeling search context, we alternatively striped off the two components from the upper level task embedding layer of CARS (i.e., session-query and session-click encoders). First, we turned off the attention between consecutive queries defined in Eq (5) to concentrate on the impact of in-task search context modeling. It slightly affects the model's ranking performance, but generates considerable consequence on the query suggestion quality. This is consistent with our analysis in Table <ref type="table" target="#tab_2">3</ref> and again shows the importance of adjacent queries for query suggestion task. As presented in the second block of Table <ref type="table" target="#tab_3">4</ref>, without modeling the in-task queries and clicks, CARS loses 3% and 8.9% in NDCG@1; and in the meanwhile, it loses 30.7% and 0.8% in BLEU-1 (comparing to CARS w/o attention) respectively. This result clearly suggests that modeling in-task clicks is more important for the document ranking task and modeling the past queries is crucial for the query suggestion task.</p><p>? Multi-task learning v.s. single-task learning. We alternatively disabled the document ranker and query recommender components  in CARS and reported their performance in the third block of Table <ref type="table" target="#tab_3">4</ref>.</p><p>When the query recommender is disabled, the ranking performance of CARS dropped 3.1% in NDCG@1. This demonstrates the utility of supervision signals from the query recommender to the ranker. However, when the ranker is disabled, the query suggestion performance of CARS was not influenced (and it even became slightly better). We conjecture that since we already encode the clicked documents in the context attentive vector, information from user clicks can be utilized by the model. Therefore, adding training signals from ranker does not provide much additional new knowledge. On the other hand, by training CARS without document ranker, the recommender component can focus more on the query suggestion task, and this might introduce the performance variance.</p><p>? Effect of task length. To understand the impact of search context on tasks with different lengths, we performed experiments by splitting the test set into three groups:</p><p>(1) Short tasks (with 2 queries) -66.5% of the test set (2) Medium tasks (with 3-4 queries) -27.24% of the test set (3) Long tasks (with 5+ queries) -6.26% of the test set</p><p>As we filtered out queries that do not have any associated clicks when constructing the experiment dataset, we lost some longer tasks; otherwise our test data distribution is similar to <ref type="bibr" target="#b7">[8]</ref>. We report our findings on the models' document ranking and suggestion performance in Figure <ref type="figure" target="#fig_2">2</ref>. It is clear in Figure <ref type="figure" target="#fig_2">2a</ref> that modeling the past in-task clicks is essential for boosting the document ranking performance, especially in long search tasks. MAP dropped 6.9% and 5.6% in CARS when session-click encoder was turned off in long and short tasks respectively. However, we can also observe that CARS performed relatively worse in those longer tasks. We hypothesize that those longer tasks are intrinsically more difficult. To verify this, we included two best single-task learning baselines, DUET and Match Tensor, in Figure <ref type="figure" target="#fig_2">2b</ref>. And we also turned off query recommender component in CARS to make it focus only on the ranking task. We observed similar trend in those baseline models,  i.e., worse performance in longer tasks. In addition, we also found better improvement in the short tasks from CARS to the best baseline rankers than that in the long tasks, 9.3% v.s., 7.1%. This indicates modeling the immediate search context is more important. On the other hand, long tasks amplify the advantage of CARS in the query suggestion task. As we can find in Figure <ref type="figure" target="#fig_2">2c</ref>, the query suggestion performance measured by average BLUE score (arithmetic mean among BLUE 1 to 4) of CARS improved 41.4% from short tasks to long tasks. And compared with the best baseline query recommender that models query reformulation chain in a task, i.e., M-NSRF, better improvement was achieved with short tasks: 40.3% in short tasks v.s., 22.9% in long tasks. This further suggests CARS's advantageous sample complexity in learning search context. We also studied the effect of search context modeling with respect to tasks of different lengths in Figure <ref type="figure" target="#fig_2">2d</ref>. We turned off the attention between consecutive queries (in Eq (5)) to better illustrate the effect. Clearly, modeling past queries is more important for query suggestion than modeling past clicks; but when the tasks become longer, click history still helps boost the performance.</p><p>? Performance w.r.t. training data size. CARS models both document ranking and query suggestion tasks and consists of multiple encoders and decoders. As a result, it has more than 30 million parameters. <ref type="foot" target="#foot_4">5</ref> Despite its large number of parameters, CARS converges fairly fast, even with less data, as it effectively exploits training signals from two companion learning tasks. Figure <ref type="figure" target="#fig_3">3</ref> provides a detailed comparison of different models' sample complexity, where we only included the multi-task learning baselines as they are expected to be more effective with less training data. The fast improving performance of CARS in both tasks further proves the value of modeling search context and relatedness between the two retrieval tasks in exploiting information buried in users' search activities. ? Effect of modeling task progression. It is important to study how the modeled search context helps document ranking and query suggestion when a search task is progressing. We compare the performance of CARS with MNSRF and M-Match Tensor at individual query positions in the medium and long search tasks, and report our findings in Figure <ref type="figure" target="#fig_5">5</ref>. It is noticeable that both ranking and query suggestion performance improves steadily as a search task progresses, i.e., more search context becomes available for predicting the next click and query. Both compared baselines benefit from it, especially for document ranking, while CARS improves faster by better exploiting the context. One interesting finding is, when the search tasks get longer, the gain of CARS in query suggestion diminishes. As we can observe in Figure <ref type="figure" target="#fig_5">5b</ref> that the difference in query suggestion performance between MNSRF and CARS gets smaller from query position L4 to L7. By manually inspecting the test data, we find that users mostly keep submitting the same query when a task gets longer. Moreover, in unusually longer tasks (with more than 7 queries), the user queries are often very short (with only 1 or 2 terms). All the tested models can accurately repeat the previous query by exploiting the context via the attention mechanism.</p><p>? Analysis of learnt attention. We illustrate a qualitative example in Figure <ref type="figure" target="#fig_4">4</ref> and Table <ref type="table">5</ref> to demonstrate the effect of learnt context attention on the document ranking and query suggestion tasks. In Table <ref type="table">5</ref>, we highlighted the top two words with the highest self-attention weight in each query and document. Most of them accurately identify the topical focus on the text sequence in both queries and documents. This explains how the learnt representations of query and document help retrieval. In the meanwhile, Figure <ref type="figure" target="#fig_4">4</ref> discloses how the learnt search context representation is leveraged to predict Q3 (i.e., query suggestion) and rank documents for it. To rank the documents under Q3, the clicked documents of Q2 (? c 2,r = 0.91) impacts more than the other past clicks (? c 1,r = 0.09); but all the previous in-session queries play an approximately equal role (? q 2,r = 0.51 and ? q 1,r = 0.49). On the other hand, to predict Q3 for query suggestion, query Q2 (? q 2,s = 0.63) impacts more than Q1 (? q 1,s = 0.37), which is expected. And clicks in Q2 (? c 2,r = 0.87) contributes more than those in Q1 (? c 1,r = 0.13), which is also meaningful. These results shed light on the potential of using the learnt attention weights for an explanation, e.g., explaining why the documents are ordered in this way based on historical clicks. We leave this as our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORKS</head><p>In this work, we propose a context attentive neural retrieval model for modeling search context in search tasks. It models search context by explicitly utilizing previous queries and clicks from an on-going search task. A two-level hierarchical recurrent neural network is introduced to learn search context representations and corresponding dependency structure by jointly optimizing for two companion retrieval tasks, i.e., document ranking and query suggestion. Extensive experimentation demonstrates the effectiveness of the proposed search context modeling approach, especially the value of each introduced components to the tasks of document ranking and query suggestion.</p><p>Our work opens up many interesting future directions. First, our current solution independently models users' search tasks. As different users might have different and consistent search strategies and behavior patterns, modeling across-task relatedness, e.g., users' long-term search interest, becomes necessary. Second, our solution now passively waits for users' next query and click. It would be interesting to study it in an online fashion, e.g., reinforcement learning, where the algorithm projects a user's future search actions and optimizes its output accordingly. Last but not least, our solution is not limited to web search, but should be applied to any scenario where a user sequentially interacts with a system. We would like to explore its utility in a broader application area in future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System architecture of the Context Attentive document Ranking and query Suggestion (CARS) model. Our key novelty is to encode information in search actions and ontask search context into context-attentive representations to facilitate document ranking and query suggestion tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( a )</head><label>a</label><figDesc>Ablation on search context. (b) Comparing with baselines. (c) Evaluating generation ability. (d) Ablation on search context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison based on tasks with different lengths.</figDesc><graphic url="image-3.png" coords="8,46.94,201.71,120.12,99.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison on sample complexity among the multi-task learning models for (a) document ranking and (b) query suggestion tasks.</figDesc><graphic url="image-5.png" coords="8,311.10,82.62,120.13,94.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Attention weights (? j from Eq. (3)) over session encoder states at Q3 in the search task illustrated in Figure 5. The red and blue bars represent the attention weights for the ranking (? : j,r ) and suggestion (? : j,s ) tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ranking and suggestion performance comparison between MNSRF, M-Match Tensor, and CARS at different query position in medium (M2-M4) and long (L2-L7) search tasks. The number after "M" or "L" indicates the query index in a task.</figDesc><graphic url="image-9.png" coords="9,69.87,84.43,226.98,101.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Ranker Recommender Query Encoder Session-Query Encoder Session-Click Encoder initial state initial state ?.. Inner Attention Document Encoder</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>master's degree</cell><cell cols="2">hospital jobs</cell></row><row><cell>Context-Attentive</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Representation</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Clicked</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Documents</cell><cell></cell><cell></cell></row><row><cell>Context-Attentive</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Representation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Inner Attention</cell><cell cols="2">Inner Attention</cell><cell></cell><cell>Inner Attention</cell></row><row><cell>software engineer ny</cell><cell cols="2">it masters ny</cell><cell>2018</cell><cell>it position ny healthcare</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the constructed evaluation dataset based on AOL search log.</figDesc><table><row><cell>Dataset Split</cell><cell>Train</cell><cell>Validation</cell><cell>Test</cell></row><row><cell># Task</cell><cell>219,748</cell><cell>34,090</cell><cell>29,369</cell></row><row><cell># Query</cell><cell>566,967</cell><cell>88,021</cell><cell>76,159</cell></row><row><cell>Average Task Length</cell><cell>2.58</cell><cell>2.58</cell><cell>2.59</cell></row><row><cell>Average Query Length</cell><cell>2.86</cell><cell>2.85</cell><cell>2.90</cell></row><row><cell>Average Document Length</cell><cell>7.27</cell><cell>7.29</cell><cell>7.08</cell></row><row><cell>Average # Click per Query</cell><cell>1.08</cell><cell>1.08</cell><cell>1.11</cell></row><row><cell cols="3">And, we add the negative entropy regularization</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison between query suggestion models. Paired t-test is conducted by comparing the best and secondbest models under each metric, and the test result is presented in bold-faced (p-value &lt; 0.05).</figDesc><table><row><cell>Model</cell><cell>MRR</cell><cell>F1</cell><cell>1</cell><cell>2</cell><cell cols="2">BLEU</cell><cell>3</cell><cell>4</cell></row><row><cell cols="2">Single-task Learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Seq2seq</cell><cell cols="2">0.422 0.077</cell><cell>8.5</cell><cell cols="2">0.0</cell><cell cols="2">0.0</cell><cell>0.0</cell></row><row><cell>Seq2seq + Attn.</cell><cell cols="8">0.596 0.555 52.5 30.7 18.8 11.4</cell></row><row><cell>HRED-qs</cell><cell cols="7">0.576 0.522 48.8 26.3 15.3</cell><cell>9.2</cell></row><row><cell cols="2">Multi-task Learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">M-Match Tensor 0.551 0.458 41.5 20.6 11.5</cell><cell>7.0</cell></row><row><cell>M-NSRF</cell><cell cols="7">0.582 0.522 49.7 26.7 16.0</cell><cell>9.9</cell></row><row><cell>CARS</cell><cell cols="8">0.614 0.589 55.6 36.2 25.6 19.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Ablation study on CARS. * indicates that the attention in the query recommender (Eq (5)) was turned off to study the impact of search context precisely.</figDesc><table><row><cell>CARS Variant</cell><cell>@1</cell><cell>NDCG @3</cell><cell>@10</cell><cell cols="2">BLEU 1</cell><cell>2</cell></row><row><cell>CARS</cell><cell>0.391</cell><cell>0.517</cell><cell>0.596</cell><cell>55.6</cell><cell cols="2">36.2</cell></row><row><cell>CARS w/o Attn.</cell><cell cols="6">0.387  *  0.515  *  0.594  *  48.6  *  26.1  *</cell></row><row><cell cols="2">Ablation on search context</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">w/o Session Query 0.379</cell><cell>0.505</cell><cell cols="4">0.586 33.7  *  14.2  *</cell></row><row><cell>w/o Session Click</cell><cell>0.356</cell><cell>0.485</cell><cell cols="4">0.568 48.2  *  25.6  *</cell></row><row><cell cols="2">Ablation on joint learning</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">w/o Recommender 0.379</cell><cell>0.505</cell><cell>0.585</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>w/o Ranker</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>55.9</cell><cell cols="2">36.9</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We follow<ref type="bibr" target="#b14">[15]</ref> to use a shorthand in representing the LSTM cell, and the detailed update rules can be found in that paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>We used GloVe<ref type="bibr" target="#b37">[38]</ref> as the pre-trained word embeddings for this purpose, and used a cosine similarity threshold of 0.5 to segment the tasks.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We tune the hyper-parameters within a range centered around the value (with a window size of 3 or</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p><ref type="bibr" target="#b4">5)</ref> reported in the respective papers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>W ?e n in query decoder contains about 24 million parameters as the output vocabulary size |V | is 80,000.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Search, interrupted: understanding and predicting search task continuation</title>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th SIGIR</title>
		<meeting>the 35th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-Task Learning for Document Ranking and Query Suggestion</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Wasi Uddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling the impact of short-and long-term behavior on search personalization</title>
		<author>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>Paul N Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Borisyuk</surname></persName>
		</author>
		<author>
			<persName><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th SIGIR</title>
		<meeting>the 35th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Click Sequence Model for Web Search</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martijn</forename><surname>Wardenaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st SIGIR</title>
		<meeting>the 41st SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards context-aware search by learning a very large variable length hidden markov model from search logs</title>
		<author>
			<persName><forename type="first">Huanhuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th WWW</title>
		<meeting>the 18th WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Attentionbased Hierarchical Neural Query Suggestion</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honghui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st SIGIR</title>
		<meeting>the 41st SIGIR</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to attend, copy, and generate for session-based query suggestion</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fleury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CIKM</title>
		<meeting>the 2017 CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1747" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural Ranking Models with Weak Supervision</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th SIGIR</title>
		<meeting>the 40th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Regularized multi-task learning</title>
		<author>
			<persName><forename type="first">Theodoros</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th SIGKDD</title>
		<meeting>the 10th SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clickthrough-based translation models for web search: from word models to phrase models</title>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th CIKM</title>
		<meeting>the 19th CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1139" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ICML</title>
		<meeting>the 30th ICML</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Utilizing query change for session search</title>
		<author>
			<persName><forename type="first">Sicong</forename><surname>Dongyi Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th SIGIR</title>
		<meeting>the 36th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="453" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th CIKM</title>
		<meeting>the 25th CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving Entity Recommendation with Search Log and Multi-Task Learning</title>
		<author>
			<persName><forename type="first">Jizhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh IJCAI</title>
		<meeting>the Twenty-Seventh IJCAI</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4107" to="4114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd CIKM</title>
		<meeting>the 22nd CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hetunandan</forename><surname>Kamisetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Ringger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07795</idno>
		<title level="m">Match-Tensor: a Deep Relevance Model for Search</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning user reformulation behavior for query auto-completion</title>
		<author>
			<persName><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Yu</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pao-Yu</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pu-Jen</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th SIGIR</title>
		<meeting>the 37th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="445" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">RIN: Reformulation Inference Network for Context-Aware Query Suggestion</title>
		<author>
			<persName><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th CIKM</title>
		<meeting>the 27th CIKM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Accurately interpreting clickthrough data as implicit feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Granka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helene</forename><surname>Hembrooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geri</forename><surname>Gay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th SIGIR</title>
		<meeting>the 28th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Granka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helene</forename><surname>Hembrooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geri</forename><surname>Gay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Beyond the session timeout: automatic hierarchical segmentation of search topics in query logs</title>
		<author>
			<persName><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><forename type="middle">Lisa</forename><surname>Klinkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th CIKM</title>
		<meeting>the 17th CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="699" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluating the effectiveness of search task trails</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yalou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st WWW</title>
		<meeting>the 21st WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="489" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 NAACL</title>
		<meeting>the 2015 NAACL</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="912" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09090</idno>
		<title level="m">Learning natural language inference using bidirectional LSTM model and inner-attention</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A deep architecture for matching short texts</title>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1367" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Win-win search: Dual-agent stochastic game in session search</title>
		<author>
			<persName><forename type="first">Jiyun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sicong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th SIGIR</title>
		<meeting>the 37th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="587" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attention-based Neural Machine Translation</title>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on EMNLP</title>
		<meeting>the 2015 Conference on EMNLP</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Exploring session context using distributed representations of queries and reformulations</title>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th SIGIR</title>
		<meeting>the 38th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to Match using Local and Distributed Representations of Text for Web Search</title>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th WWW</title>
		<meeting>the 26th WWW</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Retrieve-and-read: Multi-task learning of information retrieval and reading comprehension</title>
		<author>
			<persName><forename type="first">Kyosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itsumi</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hisako</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junji</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th CIKM</title>
		<meeting>the 27th CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="647" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th ACL</title>
		<meeting>the 40th ACL</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ICML</title>
		<meeting>the 30th ICML</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A picture of search</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Pass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdur</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cayley</forename><surname>Torgeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In InfoScale</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A language modeling approach to information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W Bruce</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st SIGIR</title>
		<meeting>the 21st SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: BM25 and beyond</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multitask Learning for Query Segmentation in Job Search</title>
		<author>
			<persName><forename type="first">Bahar</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilson</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 SIGIR</title>
		<meeting>the 2018 SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="179" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuldip K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Context-sensitive information retrieval using implicit feedback</title>
		<author>
			<persName><forename type="first">Xuehua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th SIGIR</title>
		<meeting>the 28th SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A latent semantic model with convolutional-pooling structure for information retrieval</title>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gr?goire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd CIKM</title>
		<meeting>the 23rd CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A term-based methodology for query reformulation understanding</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Sloan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="145" to="165" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A hierarchical recurrent encoder-decoder for generative context-aware query suggestion</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th CIKM</title>
		<meeting>the 24th CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning to extract cross-session search tasks</title>
		<author>
			<persName><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd WWW</title>
		<meeting>the 22nd WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1353" to="1364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Predicting short-term interests using activity-based search context</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Ryen W White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th CIKM</title>
		<meeting>the 19th CIKM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1009" to="1018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Enhancing personalized search by mining and modeling task behavior</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ryen W White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongning</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd WWW</title>
		<meeting>the 22nd WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1411" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Query Suggestion with Feedback Memory Network</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 WWW</title>
		<meeting>the 2018 WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1563" to="1571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Context-aware ranking in web search</title>
		<author>
			<persName><forename type="first">Biao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd SIGIR</title>
		<meeting>the 33rd SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
