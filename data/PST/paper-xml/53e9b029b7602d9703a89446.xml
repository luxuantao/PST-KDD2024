<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Timing and causality in process algebra</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Luca</forename><surname>Aceto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Murphy'</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">&apos; School ofCognitive and Computing Science</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<postCode>BN1 9QH</postCode>
									<settlement>Brighton, England</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<addrLine>Fredrik Bajersvej 7E</addrLine>
									<postCode>DK-9220</postCode>
									<settlement>Aalborg 0</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<postCode>B15 2TT</postCode>
									<settlement>Birmingham</settlement>
									<country key="GB">England</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Timing and causality in process algebra</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5E7C51EA4B4F6B5534833FF4EF874A2A</idno>
					<note type="submission">Received December 20, 1993/February 23, 1995</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There has been considerable controversy in concurrency theory between the `interleaving' and `true concurrency' schools. The former school advocates associating a transition system with a process which captures concurrent execution via the interleaving of occurrences; the latter adopts more complex semantic structures to avoid reducing concurrency to interleaving.</p><p>In this paper we show that the two approaches are not irreconcilable. We define a timed process algebra where occurrences are associated with intervals of time, and give it a transition system semantics. This semantics has many of the advantages of the interleaving approach; the algebra admits an expansion theorem, and bisimulation semantics can be used as usual. Our transition systems, however, incorporate timing information, and this enables us to express concurrency: merely adding timing appropriately generalises transition systems to asynchronous transition systems, showing that time gives a link between true concurrency and interleaving. Moreover, we can provide a complete axiomatisation of bisimulation for our algebra; a result that is often problematic in a timed setting.</p><p>Another advantage of incorporating timing information into the calculus is that it allows a particularly simple definition of action refinement; this we present. The paper concludes with a comparison of the equivalence we present with those in the literature, and an example system specification in our formalism.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The process algebra community is divided between those who favour interleaving, and those who do not. The former school reduce a process like a. NIL 11 b. NIL to the choice between the alternative interleavings (a. b. NIL) + (b. a. NIL), enabling them to associate a labeled tree with a process, while the latter use more sophisticated semantic structures, such as partial orders, to distinguish between `true' concurrency and interleaving. These structures have the advantage of being more expressive than labeled trees, but the disadvantage of often being more complex and difficult to reason with.</p><p>The correct choice of semantic structure for concurrency becomes even more problematic when we move to timed process algebra. Many of the classic interleaving algebras, such as BPA <ref type="bibr" target="#b8">[9]</ref>, `theoretical' CSP <ref type="bibr" target="#b34">[35]</ref> or CCS <ref type="bibr" target="#b40">[41]</ref> have timed analogues ( <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> and <ref type="bibr" target="#b43">[44]</ref> respectively), and these inherit many of the features of the interleaved originals. However, timing adds a new element: in an untimed algebra, we would associate the traces &lt;a,b,c), &lt;a,c,b&gt; and &lt;c,a,b&gt; with the process (a. b. NIL) i1 c . NIL. If we add timing, writing a @ t for an a at time t, and assume that b happens 2 time-units after a, then merely generalising the traces above gives us &lt;a@0,b@2,c@0&gt;, &lt;a@0,c@0,b @2&gt; and &lt;c@0,a@0,b@2&gt; Many authors <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b43">44]</ref> argue that the first trace, &lt;a @0, b @2, c @ 0&gt;, is inconsist- ent or ill-timed, since the trace order does not reflect the order given by time; they claim that we cannot observe a c at time 0 after observing a b at time 2. This position allows them to reduce the allowed traces in their timed models, but at a considerable cost: expansion theorems, which are often a great aid in manipulating expressions, establishing normal forms etc., rarely follow in this setting, as Godskesen and Larsen <ref type="bibr" target="#b28">[29]</ref> point out. Moreover, considerable trouble needs to be taken in the semantics of the calculus to ensure that such ill-timed traces do not arise, with the result that it is often possible to write processes which do not allow time to pass. This is well known in the timed process algebra community; cf. <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b54">55]</ref>.</p><p>Here we will argue that it is not necessary to ban ill-timed traces provided they are well-caused. There is no causal connection between b and c in the process (a. b . NIL) c . NIL, SO we claim that it is unreasonable for c to influence the presence or absence of b in a semantic structure. Thus we will allow ill-timed traces, provided they come about through parallelism.</p><p>This novel approach has a number of advantages; firstly it allows us to keep many of the advantages of the classic interleaving approach, such as the existence of an expansion theorem. Secondly, it allows us to capture concurrency information purely through timing, so that we can record the difference between interleaving and concurrency without using a semantic structure more complex than a labeled tree. Finally it allows us to define a timed process algebra that is both physically realistic (our calculus will suffer from no pathological processes such as those which do not allow time to pass or those which do an infinite number of actions in a finite time) and fairly expressive.</p><p>We will proceed thus: firstly we define the process algebra CIPA (for `closed interval process algebra') that will be our main object of study. This is a subalgebra of the second author's IPA introduced in <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref>. An operational semantics is given to the algebra cIPA which allows us to associate an action-timed transition system with a process. This semantics has several novel features:</p><p>• we have urgent actions: things happen as soon as they can. This allows us to reason compositionally about timing properties;</p><p>• we introduce local clocks to record the evolution of different parts of a distributed state. This, together with our treatment of synchronisation (which ensures that process synchronisation implies clocks synchronisation), allows us to treat parallelism smoothly.</p><p>A congruence is then defined over the action-timed transition systems given by the operational semantics, and is axiomatised. We prove that it remains a congruence under a definition of semantic action refinement. These results rely on a careful analysis of timing information.</p><p>The paper concludes with a comparison of our notion of equivalence with others in the literature, and an example of the use of cIPA. We aim to show the usefulness of timed process algebra not just as specification calculi for timed systems, but also as possessing inherent semantic advantages over untimed calculi. Timing, for instance, increases the expressiveness of the calculus without going beyond an interleaving setting. It also simplifies the definition of action refinement, as we show.</p><p>An extended abstract of the matter presented here appears in <ref type="bibr" target="#b3">[4]</ref>, while a slightly expanded account of this material can be found in <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A timed process algebra</head><p>In this section we define a timed process algebra, giving its syntax, investigating its timing properties, and presenting an operational semantics. We show that our semantics captures concurrency information in a natural way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Syntax</head><p>We will use a syntax derived from both CSP <ref type="bibr" target="#b34">[35]</ref> and CCS <ref type="bibr" target="#b40">[41]</ref>, assuming as given some set of actions, A, with r (which_ will be used for internal actions of a process) not in A. We also assume a bijection : A -A (giving the complementary action of a), extend -such that x = z for all x E Au A, and write ACT for Au A. We will use a, b, c, d, etc. to range over ACT, and write + for the positive reals. We assume a countably infinte set of process variables PVAR, and will use X, Y to range over it. The syntax of CIPA is then defined by P ::= a.P I WAITt.P I P+ P I P\C I NIL IF 11 P I X I REC X.P with a ranging over ACT, t e O, X E PVVAR and C 9 A. We assume the usual notions of free and bound variables in terms with REC as the binding construct. We shall write P [Q/X ] for the term obtained by replacing each free occurrence of the variable X in P with the term Q. (The interested reader is referred to, for example, <ref type="bibr" target="#b51">[52]</ref> for standard material on substitution, free variables, etc.).</p><p>In what follows, we shall restrict ourselves to considering only closed CIPA terms in which recursions are time-guarded. A recursive process REC X. P is time-guarded if each free occurrence of the variable X in P is within the scope of an action-prefixing or WAIT t-prefixing operation.</p><p>The set of all closed, time-guarded processes generated by this syntax over a fixed set of actions A, and a set of process variables P VAR will be written CIPA. The operators are intended to have the following informal meaning: a.P An action a e Acr followed by the process P.</p><p>WAIT t. P A process that can do nothing but wait for time t and then become P.</p><p>P + Q This is the choice between P and Q; P + Q can perform either an action from P, in which case it behaves like the rest of P, or one from Q, in which case the remainder of Q follows.</p><p>P \ C This restriction operator allows us to force some of P's actions not to occur; all of the actions in the set C are prohibited.</p><p>NIL This is the empty processs which does nothing.</p><p>P 11 Q This is parallel composition. Each process is allowed to proceed asynchronously, with synchronisations between a and a sometimes being possible; see subsection 2.6 for details.</p><p>REC X . P This denotes a distinguished solution of the equation X = P.</p><p>We will often omit the terminal NIL, writing for instance a.b for a.(b.NIL).</p><p>Moreover, we assume that . binds more strongly than + or fi, so that a. b + c should be read as the process (a.b.NIL) + c. NIL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Duration and nonatomicity</head><p>Consider the process a.b. In any realistic system there must be a delay between a and b. Clearly we have two alternatives:</p><p>• either to imbue operators with delay, so that a and b are atomic and time passes `between' them (cf. the derived prefixing operation a `+ P in timed CSP <ref type="bibr" target="#b18">[19]</ref>; this denotes a program that performs an instantaneous a action and then delays for t time units before behaving like P);</p><p>• or to view actions as compound happenings having duration.</p><p>We shall take the latter course, giving a function d : A -&gt; 118 + which assigns durations to actions. The duration A(a) for any a a A will be assumed to be nonzero and, for technical convenience, constant over all occurrences of a. We extend A to ACT by defining A(a) = A (a).</p><p>Our approach of giving durations to actions is novel but not entirely new; Lamport assumes nonatomicity <ref type="bibr" target="#b37">[38]</ref> in his discussions of distributed systems, as do Best and Koutny <ref type="bibr" target="#b11">[12]</ref> when discussing priority. Related process algebraic work with explicit starts and finishes is due to Hennessy and the first author <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33]</ref>, while the second author <ref type="bibr" target="#b46">[47]</ref> treats a partial order model with duration. van Glabbeek (in his definition of ST-bisimulation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref>), Gorrieri <ref type="bibr" target="#b29">[30]</ref>, and especially Vogler <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b53">54]</ref> consider durational information is necessary in the consideration of action refinement and hence in properly structuring the descriptions of systems, a view we concur with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Urgency and timing properties</head><p>A key notion in CIPA is that of urgency; an action happens as soon as possible. Thus if a has duration ir, the Pin a. P will definitely start executing exactly 3.141 ... units of time after a has started. Note that the issue of urgency is different from that of liveness. The term `maximal liveness', which intuitively should mean things happening as quickly as possible, is in fact used in much of the literature to mean r actions happening as quickly as possible. In the absence of duration information, this can cause effects, such as the a in T.a happening immediately, which are not present in cIPA. As illustration, consider (a.b 11 a)\ {a}; in CIPA the b will happen at time A (a) after the process has begun, not immediately. We take the view that there is no reason for hidden actions to lose their durations.</p><p>The urgency of CIPA allows us to define compositionally the set of all times a recursion-free process without restriction can last (cf. Sect. 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Action-timed transition systems</head><p>We shall present the operational semantics of CIPA in the usual SOS style <ref type="bibr" target="#b48">[49]</ref>, associating a rooted transition system (or process graph) (S, E, -+, so ) with a cIPA process. This transition system represents the possible steps in executing P. so S will be the set of reachable configurations of P, E a set of actions, -+ an evolution or transition relation (which indicates which action is associated with a given state change), and so a S the starting configuration. In what follows, p will range over</p><formula xml:id="formula_0">ACT U {T}.</formula><p>Timed process algebra usually assumes the existence of an observer's clock. This is a conceptual clock which accompanies an observer of the system, and is used to time-stamp observations; its presence does not necessarily constitute a global clocks assumption. Indeed, we shall show in this paper how to give an operational semantics for CIPA in which different parallel sub-processes have an independent local clock which they use to time-stamp observations.</p><p>To introduce time-stamps, we need to generalise the rules of operational semantics slightly. A conventional untimed transition rule takes the form</p><formula xml:id="formula_1">(i a I) u " u'</formula><p>indicating that if every configuration s, can evolve by u i to s; then u can evolve by p to u'. We want to capture both the timing of an action (p @ t, read 'p occurs at time t') and its duration (S), so we shall write timed transition rules in the form Si "" r a" "-^ s; (i a I) u?`^u' a Definition 1. An action-timed transition system or Arrs is a tuple G = (S, E, -&gt;, s o ) consisting of a set of configurations S, a set of timed, durationful events E c (ACT U {T}) x (R' u {0}) x R' (together with a duration map A: ACT -&gt; lle ), a relation -&gt; : S x E x S and an initial configuration so . We usually write s u rather than <ref type="bibr">(s, (p, t, 6)</ref>, u) a -+, and require that T is the only action whose duration can vary s ' u and s' ' ' u' implies (S = S' v µ = r).</p><p>For the sake of convenience, we shall only consider ATTSS with the following properties:</p><p>lack of cycles Let -&gt;* be the reflexive and transitive closure of -*. Then we require: s u implies u/-s.</p><p>reachability All states mentioned are reachable from the initial configuration, and all events label some transition: s e S implies so -&gt;* s, and e e E implies 3s, u e S such that s u.</p><p>Note that the ATTSS we consider are root unwound in the sense of [24, Chap. 3], i.e. they have no incoming edges at the root:</p><p>-i(sso).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Configurations</head><p>Consider the general timed transition rule of the last section. In keeping with the idea of urgency, we want P to begin as soon as a has ended in a. P, i.e. at time A(a) assuming that a.P started at time 0. However, if configurations are just process fragments, we have no convenient syntactic means of knowing the time of occurrence of an action. Thus we define the set '(cIPA) of configurations as follows:</p><formula xml:id="formula_2">s::= Ptls+slslisIS\C.</formula><p>The idea is that Pt is the process P started at time t; we conventionally identify P with P 0. (Note that, with this convention, we can regard cIPA as a sublanguage of '(cIPA)-indeed we have identified cIPA with a subset of the set of generators of €(cIPA).) The configuration (Pt) II (F' t') is P with local clock at t in parallel with P' whose local clock reads t'. This use of local clocks enables us to treat the simultaneous execution of actions in parallel processes smoothly. It is important to emphasise here that our local clocks are conceptual; they are an aid in recording distributed state, rather than a precise model of an implementation.</p><p>For the sake of simplicity, we shall follow the example of <ref type="bibr" target="#b16">[17]</ref> and consider configurations in canonical form with respect to the operators _t. In particular, it will be assumed that the operators _ t distribute over nondeterministic choice, restriction and parallel composition. Formally, let -denote the least congruence over these operators which satisfies the following axioms:</p><formula xml:id="formula_3">(P+Q)t-Pt+Qt, (P\C) t -(Pt)\C, (P II Q) t=(Pt)II(Qt)-</formula><p>Applying these axioms as rewrite rules from left to right, it is easy to see that for each s E ,9(cIPA) there exists a canonical term generated by the grammar s ::= NILt I (a.P)t I (WAITt'.P)t I (RECX.P)t I s+ s I s\C I s 11 s such that s is always = to a canonical term. In what follows, 4(cIPA) will always be considered modulo Notice, incidentally, that there are some configurations that do not correspond to processes in any recognisable sense; (a 2) + (b 3), for instance, is not an implementable choice. Such configurations are needed for semantic reasons, (allowing us to show completeness, for instance) and should not be thought as corresponding to (the state of) a process which offers such a choice.</p><p>We shall write transition rules between configurations, a typical example being s a@=, s , h which means that starting from the configuration s, the configuration s' is reachable by the action µ happening at time t with duration S.</p><p>Definition 2 (Internal transition relation) In a given ATTS, (S, E, -b, so ), we say that there is an internal transition from s a S to u a S, written s u, iff there is a sequence</p><formula xml:id="formula_4">oft-transitions s i b `'^ • • • u.</formula><p>Note that we do not associate a duration with internal transitions. The reason for this choice is essentially technical. The notion of behavioural equivalence we shall impose on CIPA processes will, to a certain extent, abstract from their internal evolution, and all the information about the changes in the local clocks of processes which occur in the transition s . u will be recorded in the target configuration u, where it can be used to associate the apppropriate time-stamp with the next observable action.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Arrs semantics</head><p>In this subsection, we shall define the ATTS associated with a CIPA expression; see displays 1 and 2. Our timed semantics will be rather different from the usual ones in the literature <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b50">51]</ref> in that we do not explicitly allow time to pass. Rather, we merely say when actions happen. This means that processes will not be able to refuse to let time pass. Moreover, our association of a nonzero duration with each action means that we cannot build Zeno mechines-machines that do more than a finite number of actions in a finite interval of time. These two features mean that all processes in our calculus will be physically realistic in the sense of <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>A few comments on the rules in displays 1 and 2 are now in order. First primitive happenings; the rule AcT. Actions fire as soon as they are ready, passing control to their suffixes once their duration is over.</p><p>Waits (rule WAIT) just wait the specified time with at transition, passing control to their suffixes at the end of their wait. We want to think of WAIT t. P as being a timed version of CCS's r. P rather than timed CSP's wait t; P. This is because we think the timing of choices is important; we want to make a distinction between a choice followed by a wait and a wait followed by a choice, i.e. between (WAIT 2. P + WAIT 2. Q) and WAIT 2. (P + Q) .  Display 2. The timed operational semantics of parallelism This is just the timed version of the distinction between i.P + T.Q and T.(P + Q). Intuitively, our WAIT t prefixing represents busy waiting, which we interpret as waiting by performing internal computations: this can change the state of a process. In contrast, most algebras, such as Hennessy and Regan's <ref type="bibr" target="#b33">[34]</ref> and Wang Yi's <ref type="bibr" target="#b54">[55]</ref>, interpret the passage of time as idling. As a consequence they do not allow `the passage of time to decide a choice', and hence have an equality between wait-thenchoice and choice-then-wait situations, which means that the moment of choice cannot be clearly distinguished.)</p><p>The rule for restriction is RES: restriction just stops the restricted actions from happening; Ts can always proceed since C 9 A, and TOA.</p><p>The rules for parallelism are PAL, PAR and SYNC. The idea of a configuration Pt 11 Q t' is that t and t' are the local clocks at P and Q. Notice that the two clocks never interact during the execution of P Q, except during synchronisation, so they are genuinely local. Notice too that synchronisation is only allowed provided the local clocks of the synchronising actions match exactly (rule SYNC).</p><p>This is an abstraction of the clock synchronisation that happens in many protocols as a result of synchronisation <ref type="bibr" target="#b5">[6]</ref>; our clocks are not supposed to model all of the features of physical clocks in actual implementations, so abstracting away from the details of clock synchronisation is not unreasonable.</p><p>It is worth noting that our assignment of clocks to each parallel process is rather close to Matthern's notion of vector time <ref type="bibr" target="#b38">[39]</ref> in which setting a comprehensive account of Lamport's clock synchronisation procedure can be given <ref type="bibr" target="#b37">[38]</ref>. Thus while the strictness of our synchronisation requirements does not match a naive account of real synchronisations, it is, we suggest, not an unreasonable abstraction, as well as having excellent technical properties.</p><p>The choice of allowing synchronisation only if the local clocks of the synchronising processes match exactly, however, is not without consequences. Consider the process (a.b b.c)\{b}. In the presence of rule SYNC, this process will perform an a-action at time 0 and then deadlock, because b @ d (a) and b@ 0 cannot synchronise. The point here is that achieving synchronisation is a responsibility of the implementer of a system, not an automatic right; one has to insert waits in processes to make sure that the desired synchronisations take place. It is this feature of low-level implementations (rather than higher-level descriptions of them) that we model here.</p><p>To end this section, we prove a property of processes in our calculus that implies that processes can only perform a finite number of transitions in a finite interval of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 3 For every CIPA process P and non-negative real number t, the meaning of P up to time t (as the unwinding of an ATTS) is finite.</head><p>Proof. (Sketch.) Let it(P, t) denote the synchronization tree for P cut at time t, i.e. n(P, t) consists of all the sequences of transitions from P 0 whose action times are &lt;_ t. We sketch the proof that n(P, t) is finite, thus establishing non-Zenoness: see <ref type="bibr" target="#b45">[46]</ref> for more details. The proof proceeds by contradiction: assume that n(P, t) is infinite. Since the transition system for any term is finitely branching (by a simple induction), using Konig's lemma it follows that n(P, t) has an infinite path P O" so"'h^ `^ s l • • • where for all i, t. &lt; t.</p><p>Since any term can have only a finite number of durations and waits in its syntax, there is an upper bound on the number of different t,s occurring in the above sequence. Thus there is a clock time t' occurring infinitely often in it. However, this is not possible: let M be the size of parallelism in P, i.e. the number of syntactic occurrences of 11 in P. At time t, since all recursions are time-guarded, P could only have unwound at most a finite number of times, N(t) say. There are then at most (M + 1)N(`) clocks in ir(P, t). A contradiction follows. q 3 The meanings of processes The rules of the last section allow us to associate an ATrs with a configuration of a CIPA process. Here we identify the meaning of a process P as the ATTS generated by the configuration P0, and present a suitable notion of equivalence over such transition systems. This equivalence is shown, through an analysis of its interaction with timing information, to be a congruence. This analysis is then extended, showing how timing captures concurrency information. Isomorphic process graphs, i.e. process graphs that differ only in the name of their nodes, will be identified. With this convention, it is easy to see that, for every restriction free CIPA process P,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QPJI = [NIL] if dur(P) = {0} if 0 E dur(P)</head><p>(where dur(P) is the set of times P can last: see Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Rooted branching bisimulation</head><p>We want to define a notion of equivalence over ATTSS that will tell us when two CIPA processes should be regarded as equal. The notion we pick should reflect our interest in the precise timing of choices discussed above, and thus should respect the branching structure of processes. Given this preoccupation, we shall pick the notion of branching bisimulation introduced by van Glabbeek and Weijland <ref type="bibr" target="#b26">[27]</ref>. This equivalence is stronger than weak bisimulation, and accurately captures branching structure. Definition 5 A timed branching bisimulation from an ATTs G = (S, E, -, so ) to</p><formula xml:id="formula_5">another H = (S', E', -', ^) is a symmetric relation R: (S x S') u (S' x S) such that (i)</formula><p>The roots are related; so R so.</p><p>(ii) If two configurations are related and an observable timed transition with a given duration is possible from one of them, then it is possible from the other with the same time and duration: if we have s R u and s^,`-s', then exactly one of the following applies p = r.In this case we require that either s' R u or u u' -^`' -P u",for some u', u" such that s R u' and s' R u". p = a. Here we require that u = u' ° @ ` ' u"for some u', u" such that s R u' and s'Ru".</p><p>If there is a timed branching bisimulation between G and H, we say that G and H are branching bisimilar. If R is a branching bisimulation and additionally it only relates root nodes to root nodes, we will call it `rooted'. Since `rooted branching bisimulation' is a somewhat cumbersome term, we will abbreviate such relations by Ras's. We write R: G : H to indicate that G and H are rooted branching bisimilar, and that this fact is witnessed by the relation R; the R is sometimes dropped. Finally, two CIPA processes P and Q are rooted branching bisimilar if f P11 and I{QD are.</p><p>The reader will have noticed that, in the definition of timed branching bisimulation, we abstract from the duration and start time of internal transitions. This is in agreement with Definition 2. However, as previously remarked, the duration of internal transitions is not simply forgotten. In fact, internal transitions change the local clocks in a configuration, and so their duration may influence the start time of observable transitions and hence bisimilarity: in the definition of bisimulation we are only allowed to match observable actions which have the same start time. We return to this point in Subsection 3.2.</p><p>Examples. To provide some intuition, we give the meanings of some processes, and present some equations between processes which do and do not hold relative to Rsa. As usual, we write P = Q for IPJ z QQI.</p><p>Interleaving Consider a 11 b. This generates the traditional diamond with paths and</p><formula xml:id="formula_6">(a II b) 0 b b&gt; ^' (a 0) 1 1 (NIL 2.1(b))(NIL 4 (a)) II (NIL d (b))</formula><p>In contrast, Note that both processes are somehow semantically sequential (in that the parallelism in both is hidden, and both are equivalence to sequential processes). This shows that, in general, RBB is even finer than strong bisimulation over semantically finite sequential processes, which is not surprising given the role played by timing information in clpA. Another similar example is (a.c.b 11 WAITd(a).c)\{c} and (a.d.b 11 WAITd(a).d)\{d}; two processes which are only equated by our theory if d(c) = A(d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Law 1</head><p>The usual equations P + P = P and P + NIL = P hold for our notion of equivalence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NonLaw</head><p>It is interesting that one of the r laws in <ref type="bibr" target="#b26">[27]</ref> immediately generalises to our setting. For instance, the restriction example above generalises to a. WAITt.b a.b. We also have WAITt.a * WAITt.a + a since the latter can begin a earlier than the former.</p><p>Note, however, that a. WAIT t .: a as the only behaviour that can be observed of both processes is that they can execute action a at time 0 with duration A (a).</p><p>Law 2 There are some nontrivial relationships between processes with is, e.g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a.WAITt.WAIT t'.P = a.WAIT(t + t').P</head><p>Indeed, it is easy to see that a. WAIT t : a. WAIT t' and WAIT t WAIT t ' for all t, t' e W. Moreover, we have that a. (WAIT t fi b) a. b.</p><p>Note that it is only with the introduction of a x-ignoring equivalence that we have this result: we do not have additivity of waits in the raw operational semantics or even up to strong bisimulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Compositionality and timing</head><p>We will now show that rooted branching bisimulation is a congruence, and discuss the timing-dependence of our results. Definition 6 Let maxtime(s) denote the largest clock time t occurring in s, and for each t &gt;_ 0, s 7 ` denote the configuration obtained by adding t to each clock time occurring in s, i.e. -T ` is the unique homomorphism satisfying NILt'/`=NIL(t'+t) (a.P)t'&gt;'` = (a.P)(t' + t) (WAITt".P)t'7` = (WAIT t".P)(t' + t) <ref type="bibr">(</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RECX.P)t'T` = (RECX.P)(t' + t).</head><p>Lemma 7 For all s E cf(cIPA) and t e l, the following statements hold: (i) s ` s' implies s 1,1 " t s' T (ii) s ` '` a `'^ s l implies s '`^` s' for some s' a 9(cIPA) and t' a lR + such that s 1 =s'i` and t 1 =t'+t;</p><p>(iii) maxtime(s `) = t + maxtime(s).</p><p>We can now tackle the compositionality of RBB:</p><formula xml:id="formula_7">Theorem 8 Rooted branching bisimulation is compositional; QP1 : [Q]1 implies fPOR]^[QOR]J</formula><p>for e a { +, 11 }. Furthermore, for any t a O and a e ACT, E[a.P F{a.Q]j, fWAITt.P] ti fWAITt.Q]J and fP\Cj ,: I{Q\C]1.</p><p>Proof This is an extension to CIPA of van Glabbeek and Weijland's for BPA <ref type="bibr" target="#b26">[27]</ref>.</p><p>The only cases which depart slightly from the standard proof are those for action and WAIT t prefixing. To show that : is preserved by these operations, we prove that if R: [Q], then the symmetric closure of the relations Rp1e = {(a.P0, a.Q0)} u{(sl7 4(°) . 52, A(a) )IS1RSy } Rwait = {(WAITt.PO,WAITt.Q0)}U{(S I /%S 2 7`)I s 1 Rs2} are rooted branching bisimulations between the relevant process graphs. This can be easily verified using <ref type="bibr">Lemma 7.</ref> q</p><p>We shall now define the set of all times a cIPA process can last, denoted by dur(P) a yo (118 + u{0}), (Here gi (X) is the set of finite subsets of X.) Definition 9 For every CIPA process P and nonnegative real number t, t a dur(P) iff there exists s e W (cIPA) such that P0 -&gt;* s and maxtime(s) = t. We now present a further time uniformity result: that if we restrict ourselves to restriction-and recursion-free CIPA processes, the set dur(P) can be defined compositionally as follows:</p><formula xml:id="formula_8">dur(NIL) = {0} .</formula><p>dur(a . P) = { t' + z1(a)t' E dur(P)}. dUr(WAIT t.P) = {t' + t I t' a dur(P)} .</p><formula xml:id="formula_9">dur(P + Q) = dur(P) if dur(Q) = {0}, dur(Q)</formula><p>if dur(P) = {0}, dur(P)udur(Q) otherwise.</p><formula xml:id="formula_10">dur(P fi Q) = {max(t, t') It a dur(P), t' a dur(Q)} .</formula><p>The existence of this function means that the restriction and recursion-free sublanguage of cIPA has compositional timing properties: we can reason about the timing of a CIPA process given knowledge of those of its subcomponents and how they are combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Time uniformity</head><p>The reals are often problematic in computer science because they admit unrealisable features: the function that takes value a at the rationals and b at the irrationals, for instance, does not correspond to the timed execution of a process we can build.</p><p>In the last subsection we showed that our semantics is uniformly parameterised by the reals; Lemma 7 states that we can add t to all the clocks in any configuration, and the effect will just be to shift all of the transitions from that configuration forward t in time. Thus our semantics varies smoothly rather than pathologically with time.</p><p>Here we examine another facet of the interaction of timing and behaviour -how : varies as the duration function is changed. Clearly, the identifications made by the congruence x depend on the particular choice of A. For instance, an equality like</p><formula xml:id="formula_11">(a.b II a) \a : WAITt.b holds if d (a) = t.</formula><p>If for all a, A(a) = S for some S &gt; 0, we recover some of the identifications of an untimed equivalence from : ; here, for instance, we have</p><formula xml:id="formula_12">(a.b II d)\a (c.b II j)\c</formula><p>However, the presence of timing information still allows us to make distinctions which are not made by untimed equivalences. For example, we would still differentiate the processes (a.b 11 ã)\a and (a.a.b 1) ã.ã)\a, which are identified by all the untimed equivalences which abstract from the internal evolution of processes we are aware of.</p><p>We shall now show that, if we restrict ourselves to constant duration functions, .. does not depend on the choice of duration for the actions over WAIT t-free processes.</p><p>In the statement of the following result, we shall write : b for the rooted branching bisimulation over WAIT t-free processes induced by the duration function which assigns duration b to each action. The details of the proof of the following result may be found in <ref type="bibr" target="#b4">[5]</ref>.</p><p>Proposition 10. For all WAIT t -free cIPA processes P and Q, and positive reals S and</p><p>(5',P ,:</p><formula xml:id="formula_13">:b Q iff P &amp;b , Q.</formula><p>Thus, all of the s: a s coincide, and it is this equivalence that should be thought of as the untimed version of . (In fact, our results carry over with little modification to processes with (suitably translated) WAIT (5s, so the presence of Ts does not alter the results of this section.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ill-timed paths</head><p>Suppose that we have the following path in an ATTS, G:</p><formula xml:id="formula_14">S Al S r It2 2 z) S rr</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="31">d2</head><p>Since our actions are urgent,-they happen as quickly as they can, -we expect µ2 to have started immediately after p, has ended, and so we have</p><formula xml:id="formula_15">t o =t l + ch i .</formula><p>Any path which does not obey this property will be called ill-timed; note that ill-timed paths include those that have gaps in their time (t2 &gt; t l + S 1 ) and those that run backwards in time (t2 &lt; t l + 8 1 ).</p><p>Before we analyse how ill-timed paths occur, we need a little more notation. We will introduce the nonnegative integer clks(s) for a configuration s, which will be the maximum number of local clocks of parallel processes which can be initially active in s. Next, an important lemma on the clocks in configurations;</p><p>Lemma 12 (The clocks Lemma) Suppose that s L t s' in {P] for some process P.</p><p>Then there is a clock in s reading t and t + 6 in s'.</p><p>Proof. By induction over the rules in Displays 1 and 2 given above. q</p><p>Our next proposition shows that ill-timed paths precisely arise through concurrency.</p><p>Proposition 13. Suppose that P is a cIPA process without restriction. Then there is a configuration s in QP] with clks(s) &gt; 1 if and only if QPj contains an ill-timed path.</p><p>Proof. We first prove the `if' direction of the statement. Suppose that P0 -&gt;* s and s '"@`'^ s''`2 b `2 , s" is ill-timed. Then, by the clocks lemma, there are clocks in s and s' reading t l and t2 respectively. But t l + 6 0 t2, hence, by the clocks lemma, s' has at least one clock reading t l + (5 and one reading t 2 . However, inspection of the only clock introduction rules (PAL and PAR) shows that we can only introduce a clock with the same time as an extant one. So s must have a clock reading t l and one reading t2 . But the subprocesses with both of these clocks are each capable of transitions, namely µ l and µ2 respectively, so clks(s) &gt; 1.</p><p>In the other direction, suppose that clks(s) &gt; 1 for some sin [Ph. Let P0 -&gt;*s be the shortest sequence of transitions leading to a configuration s with elks(s) &gt; 1. A simple induction on the length of this derivation shows that all clocks in s must read the same value t. As clks(s) &gt; 1, a structural induction on s now shows that s 'Ut@t s' 1 '`z b @` 0 s 1^ for some actions 11,µ2 and configurations s; and s l . This is g, z the required ill-timed path. q</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Independency in Arms</head><p>The concept of independency has been proposed by several authors, notably Bednarczyk <ref type="bibr" target="#b9">[10]</ref>, and Mazurkiewicz <ref type="bibr" target="#b39">[40]</ref> as capturing concurrency information in a natural way. The idea is to give a relation i over events, interpreting a i fi as `a and fi are independent', i.e. could take place in parallel. We have a similar notion closely related to ill-timedness; suppose in an ATTS s "' 61 0s l °u and t2 &lt;t 1 +b l , µ'@t1 then the occurrence of µ t in the transition s a ^ -^ s l must be independent from that of µ2 in s l '`2 4`) u since it began before the other terminated. Thus, in particular, the path s µz _ tz, ul P _ , ) u should also be possible, for some u l ; this is called the diamond property by Bednarczyk, and motivates the following. Definition 14. Suppose that G = (S, E, -+, s o ) is an ATTS. Then we say that G is well-caused if all ill-timed paths are due to concurrency, i.e. iff we can commute all independent actions s " `@`'&gt; sl "Z ^-^ u and t2 :A tl + 61 implies 3s' a S.s '`Z @ si Al ) U.</p><p>2 For a cIPA process all time happens `during' a transition, so there are no gaps in time; this is just urgency (and the reason we have 0 rather than &lt; above). Hence we define the following.</p><p>Definition 15. Suppose that G = (S, E, --^,so ) is an ATTS. Then we say that G is timeful iff the following conditions are all met.</p><p>(i) Its starting transitions all begin at time 0: s o " -u t = 0.</p><p>(ii) While the process is running, something (perhaps a t) is happening all the time: s implies that for 0 &lt;_ t &lt;_ (t' + b') there exists a y such that s0 -+ ... " a )s"-+ s and te[t",t"+6].</p><p>Proposition 16. If P is a CIPA process, then {PJ1 is a timeful, well-caused, finite ATTS.</p><p>Proof. Timefulness can be easily seen to hold. In order to prove that the wellcaused property holds, it is sufficient to show that for all s e c'(cIPA), s µ ' -d`'' S1 µ ? 52 u and t2 } tl + 61 implies 3s1 c S.s "2 ^`^ S1 "' ^`-'^ U.</p><p>bi 2</p><p>An induction on the proof of the transition s "' ) s l suffices. q</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Action refinement</head><p>Action refinement, -the operation of replacing an action by a process, -has recently been the object of much interest in concurrency theory. Here we show that our durationful actions allow a particularly simple definition of action refinement: in a sense, this is to be expected, as associated intervals with actions means that we are not trying to refine instantaneous actions, and hence can expect a more straightforward development. The technical machinery we present was inspired by <ref type="bibr" target="#b27">[28]</ref> and <ref type="bibr" target="#b23">[24,</ref><ref type="bibr">Sect. 3.6</ref>]. We shall, following <ref type="bibr" target="#b29">[30]</ref>, think of action refinement as a tool for structuring the meanings of processes; a high-level description of a complete process can be given, then further detail can be exposed by action refinement. Thus our notion of action refinement will be a semantic one. Definition 17 A process P is a valid refinement of an action a, written P refines a, (every execution of) the process lasts the same time as the action: dur(P) = {d (a)}. This is rather a strict notion of refinement; we even forbid processes that are always quicker than an action from being valid refinements of it. We do this partly for technical reasons, and partly to emphasise that speed-up is not always desirable; there are protocols which work at some speeds and fail at faster rates <ref type="bibr" target="#b5">[6]</ref>. Note that we do not allow for refinement of actions by CIPA processes which are rooted branching bisimilar to NIL (since A(a) &gt; 0 for all a, and such processes have {0} for their dur). Finally, notice that, following <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b27">28]</ref>, internal actions are not refined.</p><p>Definition 18 (Semantic substitution) Let F: ACT -&gt; CIPA be a mapping from actions to CIPA processes with the property that F(a) = P implies P refines a.</p><p>Then, we call F a semantic substitution, and for a ATTS G we define the refined graph F(G) as follows: for every edge s s' in G, take a copy F(a), of [F(a) ,' `I. Identify s with the root node of F(a), and s' with the end nodes of F(a); , and remove the edges " a )S.</p><p>Example. Consider the process a. b 11 c. The meaning of this process as a process graph is depicted in Fig. <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now suppose that A(b) = A(a) + A(c) and consider the mapping F : A -&gt; CIPA</head><p>which maps b to a.c, and acts like the identity on all the other actions. This is clearly a well-defined semantic substitution: the result of applying it to the process graph above is shown in Fig. <ref type="figure">2</ref>.</p><p>Note that this process graph is indeed the result of the semantic substitution of a graph, namely [a. c &gt;' A (a) J , for the arcs corresponding to occurrences of action b in the original process graph.</p><p>b@0(a) a@O t c@0 c@0 _____________Jco b@i(a) a@0 Fig. <ref type="figure">1</ref>.</p><p>c@2A(a) a@0(a) a@O c@0 c@0 c@0 c@20(a) a@I(a) a@O Fig. <ref type="figure">2</ref>.</p><p>The reader will have noticed that the process graph obtained by applying the semantic substitution F to a timeful, well-caused ATTS is timeful, but not necessarily well-caused. (Indeed, the above process graph provides an example of this phenomenon.) Hence, well-caused high-level descriptions of processes may turn out not to be well-caused when further details about their computations are unveiled by means of semantic substitutions. This is only to be expected because the definition of semantic substitution we use preserves the noninterference property of atomic actions, i.e. actions have no intermediate state for other activities <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>Our aim is to show that RBB is a congruence of semantic substitution. To do this, we need to see how to define a rooted branching bisimulation between refined process graphs. Definition 19. Suppose that G, H are ATTss and that R is a RBB witnessing G H. Suppose further that we refine both G and H using some semantic substitution F. We define the refined RBB F(R) as the smallest relation satisfying the conditions (i) R F(R).</p><p>(ii) If s ° a ` s' and u °®I ^ u' are edges in G and H respectively, s.t. s R u and s'R u', and both edges are replaced by copies F(a) <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and F(a)2 of {F(a) `jj respectively, then nodes from F(a) 1 and F(a)2 are related by F(R) they are copies of the same node in [F(a)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 20 If R: G H is a RBB between process graphs G and H, and F is a semantic substitution, then F(R) is a branching bisimulation between F(G) and F(H).</head><p>Proof. We check that F(R) is indeed a RBB by an analysis of the cases in Definition 5:</p><p>(i) The root nodes of F(G) and F(H) are related by F(R). It is easy to see that F(R) only relates root nodes to root nodes, as this holds of R.</p><p>(ii) Assume that F(R) relates s to u, and there is an edge s s' in F(G). Then there are two cases:</p><p>(1) The nodes s and u originate from G and H. Then s R u, and we find either µ = r and s -r s' was already an edge in G, or G has an edge s -"". `-&gt; s" and s " s' is a copy of an initial edge from QF(a) In the first case, either s' R u and hence s' F(R) u or there is a path in H u .u 1 u' s.t. s R u l and s' R u'. This path also exists in F(H) by definition, so s F(R) u l and s' F(R) u' as required. In the second case there must be a corresponding path u u l a ,, `^ u" in H s.t. s R u l and s" R u". Then, in F(H) we find a path u Su l "b `-^ u' s.t. sF(R)u l and s'F(R)u'.</p><p>(2) The nodes s and u originate from related copies F(a), and F(a); of some substituted graph E[F(a)T `]. Then s' s' is an edge in F(a); and s and u are copies of the same node in f F(a) i `]. So there is an edge u u' in F(a); where u' is a copy of the same node in QF(a), `] that s' is a copy of, and s' F(R) u'.</p><p>(iii) The case of an edge in R(H) follows symmetrically. q</p><p>In the remainder of this paper, we shall confine ourselves to dealing with recursion-free processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">An algebraic characterization of</head><p>The purpose of this section is to axiomatize the congruence relation '&amp; defined in Sect. 3 over the language cIPA. Given the fundamental role played by configurations in defining the semantics of cIPA processes, we shall provide a complete axiomatization of ,: over the set of configurations cf(cIPA). The key to the axiomatization presented in this section is the realization that the interpretation of processes given by an action-timed transition system is just an ordinary labeled transition system over a set of actions. The only difference being that the actions are structured, as they carry information on the timing of their occurrence and their duration.</p><p>Following van Glabbeek and Weijland <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, there is a standard way of axiomatizing rooted branching bisimulation-like relations over ordinary, finite, acyclic labeled transition systems. The application of their method to cIPA involves the reduction of terms to (some syntactic notation for) trees over the set of actions into consideration. However, in our ATTS semantics processes evolve by performing events in E and these are not in the signature for configurations, so this method is not directly applicable to the language '(cIPA). In order to apply van Glabbeek and Weijland's algebraic characterization to provide an axiomatization for over c9(cIPA), we thus need to extend the language (cIPA) to tf(cIPA), where ( '(cIPA) is built as cf(cIPA) with the additional formation rule: a e E and s a 1fff(cIPA) a: S E 99(CIPA).</p><p>Thus the signature of the language c (cIPA) has been extended by allowing prefixing operators of the form a : -, for a E. The language (cIPA) thus allows one to prefix timed, durationful events to configurations and this is what will be needed to define a suitable notation for trees. The extended set of configurations 9cf(cIPA) inherits the structural congruence from its sublanguage 'W(CIPA), and in what follows c8'(cIPA) will always be considered modulo -. We shall use s, u, w, s', ... to range over 49cf (cIPA) and a, p to range over E. The operational semantics for (cIPA) is obtained by extending the rules in Displays 1 and 2 with the axiom</p><formula xml:id="formula_16">PRE (p, t,a):S µ a t ) S</formula><p>It is easy to see that can be conservatively extended to the language ^f(cIPA) and that the following proposition (proved in <ref type="bibr" target="#b4">[5]</ref>) holds: Proposition 21 .:s is a congruence over i8 '(cIPA).</p><p>In order to give a complete axiomatization for RBB over ew(cIPA) (and, consequently, over CIPA), it will be sufficient to devise a set of axioms which allow us to reduce terms in W(cIPA) to (an obvious notion of) sumforms and which are together with (R1)-( <ref type="formula">R6</ref>) and (Iwr), are used to reduce configurations to finite E-labeled trees.</p><p>We can now state the promised completeness theorem (proved in <ref type="bibr" target="#b4">[5]</ref>):</p><p>Theorem 22 For all s, u E SW(CIPA), s ,: u iff s =, u. In particular, for all CIPA processes P, Q, P :</p><formula xml:id="formula_17">Q iff P0 =w Q 0.</formula><p>Other authors, notably Ferrari et al. <ref type="bibr" target="#b20">[21]</ref>, have noted that expansion theorems often hold in the noninterleaving setting when the algebraic structure of transitions is taken into account; here we have shown that timing and duration are sufficient provided that we express the relationship between configurations rather than processes. Our account (Irrr) is a straightforward adaptation of Milner's interleaving law to our setting. Indeed, we could treat a different notion of synchronisation merely by presenting the appropriate operational rule and modifying (Irrr); this would, for instance, allow us to axiomatise the loose notion of timed synchronisation latterly proposed in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31]</ref>. It should be noted, however [op cit.], that neither RBB nor indeed the notion of equivalence those authors present are congruences of parallel composition, so such changes to our definitions, although useful for comparing performance based and causality based equivalences, do not lead to theories of processes with pleasant algebraic properties. 6 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arrss and other models of concurrency</head><p>In this section we first give a broad overview of the relationship between the work reported here and salient other models in the literature. We then, to make a precise connection, relate our equivalence -&amp; for a class of concrete processes to several other noninterleaving equivalences proposed in the literature. To reinforce our claim that timing information captures independency, we show how a class of well-behaved ATTSS can be translated into the asynchronous transition systems of Bednarczyk.</p><p>It is possible to classify noninterleaving behavioural theories for process algebras by means of the information they use to distinguish parallel processes from purely sequential ones. To begin with, we indicate some of the main notions in the process-algebraic literature and their relationship to our own, making no claim of completeness. As an aid to this discussion, we shall make use of the standard example in the literature, namely the processes P = a 11 b and Q = a. b + b. a.</p><p>• Boudol et al. <ref type="bibr" target="#b13">[14]</ref> argue for the use of distribution information to distinguish parallelism from sequential nondeterminism. The processes P and Q are distinguished in this approach because there are two locations in P and only one in Q. • Hennessy and the first author <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33]</ref> use abstract duration information to distinguish parallel processes from sequential ones. In this approach, P is distinguished from Q since it can start b before a has ended whereas Q cannot. • Darondeau and Degano <ref type="bibr" target="#b16">[17]</ref> use information about the causal structure of processes to distinguish P (which has no causal structure) from Q (where a causes b or b causes a).</p><p>Our position is rather complex in this classification; using timing and duration enables us to discover which states are independent. Thus our ATTSS, like various `true concurrency' versions of transition systems <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b49">50]</ref>, incorporate independency information, as we have shown. To generate these transition systems, we have used the notion of local time, which is clearly related to that of location. Notice, incidentally, that both the location and causal approaches use annotated tree structures, as do we. We are clearly seeing the renaissance of tree-based approaches to concurrency semantics, as workers discover how to abandon the structures of pure interleaving without leaving the convenience of trees. Indeed this is the essence of our complete axiomatisation: we lift an untimed result to our setting. Many more such liftings are possible-for instance, we could use the efficient algorithm for deciding branching bisimulation of <ref type="bibr" target="#b31">[32]</ref> in our setting.</p><p>In the timed process algebra literature, apart from all the aforementioned references, we should like to mention <ref type="bibr" target="#b22">[23]</ref> as an example to work in which ideas developed in the theory of true concurrency have been put to good use in the specification of timing properties of processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">RBB over concrete processes</head><p>The class of concrete processes (i.e. processes without internal transitions <ref type="bibr" target="#b6">[7]</ref>) built from the operators NIL, action-prefixing, choice and parallelism (without synchronization) is a particularly well-behaved one; it is already known that causal bisimulation equivalence <ref type="bibr" target="#b16">[17]</ref>, t-observational equivalence <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33]</ref>, ST-bisimulation equivalence <ref type="bibr" target="#b23">[24]</ref> and location equivalence <ref type="bibr" target="#b13">[14]</ref> coincide for these processes.</p><p>Here we show that these equivalences also coincide with :. (Note that, over concrete processes, ,: is just standard strong bisimulation equivalence over the associated ATTSS.)</p><p>In view of the results in <ref type="bibr" target="#b0">[1]</ref>, it is sufficient to show that .: shares the same finite axiomatization of the above-mentioned congruences over concrete processes. To carry out this programme, it is necessary to extend the language for concrete processes with Bergstra and Klop's left-merge operator <ref type="bibr" target="#b10">[11]</ref>. The syntax of concrete cIPA is then defined by P ::=a.P I P+P I NIL I Pu1P I P(LP and its associated set of concrete configurations is defined as follows:</p><p>s ::= Pt I s+s I sIIsls^s.</p><p>The reader will have no trouble in convincing himself/herself that a suitable notion of canonical term can be easily defined over concrete configurations by assuming that the operators _t distribute over the left-merge operator, as well as choice and parallel composition. (See Sect. 2.5 for details.)</p><p>The operational semantics of concrete CIPA is obtained by adding the following rule to rules Acr, CL, CR, PAL and PAR in Displays 1 and 2:</p><formula xml:id="formula_18">S i ,` -' s' LEFT L 1 a a , S1l S2 3 ) si 11s2</formula><p>We will now show that the axioms that completely axiomatize causal bisimulation equivalence, location equivalence, t-observational equivalence and Proof A straightforward adaptation of the proof of Theorem 4.2.2 in <ref type="bibr" target="#b42">[43]</ref>. The proof makes an essential use of the following version of the so-called simplification lemma, a result first proved in <ref type="bibr" target="#b15">[16]</ref> for distributed bisimulation equivalence and subsequently adapted to strong bisimulation in [43, Lemma 4.2.1]; st II s s2 II s implies s 1 s: s2 . q</p><p>We can now prove the promised decomposition result DEC.</p><p>Proposition 26 For all concrete CIPA processes P, P', Q, Q' and t e</p><p>Pt1IP'O&amp;Qt1IQ'0 implies PQ and P'Q'.</p><p>Proof. The claim is easily seen to hold if any of the processes P, P', Q, Q' is equivalent to NIL. Assume then that P, P', Q, Q' are not equivalent to NIL. By Proposition 25, there exist unique parallel factorizations for P t, P' 0, Q t and Q' 0. Let us assume that these are given by Pt:siII...IIsk, P'0:slII • IIsh, Qt , ^wlll...11wm, Q'0 w l ll...11wp, By the proviso of the proposition, substitutivity and Proposition 25, we have that, modulo : , { s l , ... s sk, S b ... , $h } = { w 1, ... , wnt, w l f ... , wn }</p><p>It is now easy to see that none of the prime factors for P t, s" is equivalent to any of the wj's. In fact, any initial transition from s; will start at time t &gt; 0, whilst all the transitions from w; will start at time 0. Moreover, as P * NIL, P as at least one transition, and so does each s;. Similarly, none of the prime factors for Q t is equivalent to any of the s;'s. This implies that {si, ... , sk } and {wi, ... , w`", } are identical parallel factorizations, and so are {s 1 , ... , .s} and {w 1 , ... , w,}. By substitutivity, we then have that Pt r: Qt and P'O : Q' 0.</p><p>To complete the proof, we are thus left to show that Pt t: Q t implies P0 .: Q 0. However, this is easily seen to hold using Lemma 7. q</p><p>We now have enough technical machinery to prove the completeness result for concrete CIPA. The proof of this result relies, as usual, on the isolation of suitable normal forms for processes. These take the form Y_ a,.Pi IIIi, iCI where I is a finite index set, and Pi , P; are themselves normal forms.</p><p>Theorem 27 For all concrete cIPA processes P, Q, P -Q iff P .:; Q.</p><p>Proof. The `only if' implication (soundness) is just Proposition 23. To prove the `if' implication (completeness), we proceed by induction on the combined size of P and Q. By standard normalization results for concrete processes, such as Lemma 1.3.5 in <ref type="bibr" target="#b15">[16]</ref>, we can safely restrict ourselves to proving completeness for normal forms.</p><p>Assume then that P = E ir a; .P, 1 P; JEJ Q = Q. We will now show that Q + P = Q. The claim will then follow by symmetry and transitivity.</p><p>To prove Q + P = Q, it is sufficient to show that for each summand a,.P; ^ P; of P, Q+a;.Pj Pi_Q.</p><p>To see that this is indeed the case, note that P0 a^ , P, 4(a1) 11 P; 0. As P there exists j a J such that Q 0 6a Q; 4(b) II Q; 0, P; d (a; ) 11 P0 Q; d (b; ) 11 Q; 0, and a, = b;. By Proposition 26 and induction, we now have that P ; = Q; and P; = Q. The claim now follows immediately by substitutivity and equations</p><formula xml:id="formula_19">(A1)-(A4). q</formula><p>As an immediate corollary of this result, we now have that:</p><p>Corollary 28 For concrete processes, coincides with causal bisimulation equiva- lence <ref type="bibr" target="#b16">[17]</ref>, ST-bisimulation equivalence <ref type="bibr" target="#b23">[24]</ref>, t-observational equivalence [2, 33] and location equivalence <ref type="bibr" target="#b13">[14]</ref>.</p><p>Proof. By the results in <ref type="bibr" target="#b0">[1]</ref> and Theorem 27, : shares the same finite axiomatization of the above-mentioned congruences over concrete processes. El</p><p>It is worth noting that, by the above result, : does not depend on the choice of duration function over concrete processes, regardless of whether the duration function is constant or not. Proposition 10 thus holds in a sharpened version over concrete processes.</p><p>Further comparison is slightly hindered by our decision to use branching bisimulation rather than ordinary strong bisimulation; this makes it harder to extract the features of our equivalence that are due to timing, and those that arise through our sensitive treatment of branching structure. However, we can state that for processes with internal transitions and an appropriate choice of duration function, .: distinguishes more purely sequential processes than strong bisimulation equivalence (see the restriction example in Sect. 3.1) and, afortiori, than all of the noninterleaving equivalences we are aware of. Moreover, it is incomparable with location equivalence. In fact, regardless of the duration of actions a and b, it would identify the processes Conversely, consider the processes P = (a. b 11 S. c)\ {b} and Q = a. NIL. Then P : Q, whilst P and Q are distinguished by causal bisimulation equivalence, location equivalence and ST-bisimulation equivalence. El</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Translating Arms into ATSs</head><p>We now turn to the matter of the information that timing gives us, showing that it alone allows us to deduce the causal structure of transitions. We do this by presenting a relation pa defined over Arrss which captures which transitions are independent, noting en passant that timing information, like the annotated transitions of <ref type="bibr" target="#b19">[20]</ref>, is also sufficient for an analysis of causality. We show in detail that pa does indeed allow us to define an asynchronous transition system from a suitably well-behaved ATTS.</p><p>To begin the account of how timing information captures the idea of independency, we recall the formal definition of the asynchronous transition systems (or ATSs) of <ref type="bibr" target="#b9">[10]</ref>: Definition 30 A finite rooted asynchronous transition system Q is a tuple (Q, T, -, qo , i) where • (Q, T, =., qo ) is a rooted transition system with Q and T finite sets, and root qo ; • i c T x T is a symmetric, irreflexive relation satisfying the diamond property <ref type="bibr" target="#b9">[10]</ref>: forward stability This says that if we have two independent actions possible next, then that is as a result of parallelism, so after taking one the other must still be possible: s 4 u and s -u" and e i e' together imply 3s' such that u _+ s' and u' 4s'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>lack of cycles</head><p>This is essentially the same property as was required for ATTSS in Definition 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>reachability</head><p>Likewise.</p><p>We are now ready to translate an ATTS into an ATS. Suppose S = (S, E, -&gt;, s o ) is a well-caused, timeful ATTS. The events e e E are nonunique in the sense that we can have s 4 s' and u 4 u' without s = u and s' = u'. Moreover, even if s = u, we do not necessarily have s' = u'. Thus consider the structure S' = (S, E', -&gt;, so ) where E' = -+, -^ c S x E x S is the set of transitions in S, and s '"'e' °'^'s' iff s -s' and u = s and u' = s'.</p><p>Immediately we have that S' is a rooted transition system, which is deterministic, acyclic and satisfies the reachability property.</p><p>Our next task is to define a suitable notion of independence over this transition system. Clearly, if e' = (s, e, s'), f' = (s', f u') and there exists an ill-timed path s s' 4 u' in S, then e' and f' should be independent. But this relation is not symmetric, for two reasons; firstly the commuted path (which we know exists as S is well-caused) s (s, I u) , u (u, e, u ' , u, may (fortuitously) not be ill-timed, and secondly, the `events' (s, e, s') and (u, e, u') are different, while we want them to be the same in the generated ATS. Our solution is to quotient E' by a suitable congruence: Definition 31 Define for S' the relation K c E' x E' as e' c f' iff e' = (s, e, s'), f' = (s', f, u') and there exists an ill-timed path s _ + s' 4 u' in S. Suppose s (s, f u)) u (" e, U , u' is the diamond guaranteed by well-causedness or vice versa.</p><p>Extend K and define A c E' x E' by saying (s, f, u)x(u, e, u'), (s, f, u)2(s', f, u') and (s, e, s')2(u, e, u') whenever this happens, and write A* for the reflexive and transitive closure of A. Proof. That A* is an ER is trivial. To show that pa is an independence relation, first note that e" K f" implies -i (e" A* f ") and e" A* f " implies -i (e" K f"), as a simple geometrical argument reveals. Thus pa is irreflexive. Symmetry then follows from the definition of K. q Definition 33 The asynchronous transition system associated with S, written 61l(S), is defined as (S, E'/2*, -*',5O ,&gt;&lt;), where -&gt; is defined as (s, e', s') e if and only if (s, e", s') E -&gt; and e' = [e"]/1*.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 34</head><p>If S is an ATTS, then a/I (S) is an ATS.</p><p>Proof. We have to verify: (i) That pa is a symmetric, irreflexive relation; this is just Proposition 32. (ii) The diamond property. This follows as the generating ATTS is well-caused. (iii) Unambiguity. This follows by construction of E'. (iv) Forward stability. By the definition of pa, if two actions are independent, then a diamond exists between them. (v) Lack of cycles and reachability. Again, clearly true by construction. q</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">An example</head><p>As an extended example of the use of CIPA, we present the specification of a remote data-gathering unit in the calculus. This arose through a collaboration of the second author with Patrick Peglar of Delta T Devices Ltd., and thus is a (simplification of a) real industrial example rather than one contrived just for presentation purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">The problem</head><p>The purpose of a data-gatherer is to take measurements at prespecified times. In usual applications, a number of sensors are attached to a data-gatherer. Each sensor must be turned on at some given time before the measurement it takes can be made (typically so that thermocouples have time to stabilise). The sensor then takes a measurement and hands the data back to the data-gatherer. Sensors are often cheap and unsophisticated devices, without internal clocks or buffering, so the data-gatherer must ensure that the sensor is turned on at the right time, and that it is ready to receive the data when it is ready. Thus a sensor can be specified as def SENSOR = WAIT ti. STARTI. WAIT ti.READI.WRITE1</p><p>which is to say that it is a device that waits some constant user-defined time t, until it is turned on by a START! action. After being turned on by this action, it waits time ti before taking a measurement, which it then WRITES.</p><p>The data-gatherer, then, will be responsible for doing a START! with the correct t, which will ensure that the sensor does a READI when required. It must also be ready ti + A(READ1) units of time after finishing the SrART1 to do a WRITE1, allowing the sensor to transfer data back to it. Finally, it PROCESSes the data.</p><p>The design of the data-gatherer is only nontrivial when more than one sensor is considered, so suppose we also have del SENSOR2 = WAIT t2. START2. WAIT t? . READ2. WRITE2.</p><p>(In a real application, the requirement is recurrent; we have to make a series of measurements at each sensor, rather than just one. However, our design will extend smoothly to this setting, so we avoid the use of recursion to keep the complexity of the design down.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Timing analysis</head><p>Suppose that the two measurements READ1 and READ2 have deadlines d, and d2 respectively, i.e. READi must happen at t = d; . Clearly, then we must have the deadline equation</p><formula xml:id="formula_20">d, = ti + d (STARTi) + ti</formula><p>in order for the deadlines to be met. Now, clearly the design of the data-gatherer will depend on the specific deadlines. For instance, WRITEi starts at time d, + d (READi), so if the intervals</p><formula xml:id="formula_21">[dl + 4(READ1),d1 + d(READI) + d(WRITEI)] and [d2 + A (READ2), d2 + 4(READ2) + d (WRITE2)]</formula><p>overlap, then a purely sequential implementation is not possible, as the datagatherer will need to do both a WRITEI and a WRITE2 simultaneously. Similarly, if we need to turn on both sensors simultaneously, we will end up needing a parallel implementation. Suppose, then, for the moment, that the intervals above do not overlap, and neither do [t1, t1 + d (STARTI)] and [t2, t2 + A(START2)] (which is eminently reasonable, as the START actions are usually of very short duration).</p><p>Then we can implement the data-gather in a sequential fashion (which is useful, as the resources for a parallel implementation are often not available). For convenience, suppose also that d, &lt;d 2 .</p><p>The data-gatherer waits until it needs to start the sensor with the smallest value of t; , 2 say, switches that on, waits until it must start 1, switches that on, waits for the first bit of data, collects that, waits for the second, gets that, and then processes the data. A simple bit of arithmetic (and the use of dur) reveals that correct functioning depends on the behaviour shown in Display 5.</p><p>The ? occurs because we do not know where warming up the second sensor occurs relative to taking the first measurement. This is a scheduling issue that depends on the relationship between the d, and the times STARTS happen. But the time between being activated and taking a measurement is a fixed (presumably physical) property of each sensor; call it warm; . Immediately the urgency of READS gives warm, = A(STARTi) + tŵ hich fixes ti. Together with the deadline equation, it also fixes the order of the Display 5. The timing constraints on the Data-Gatherer. (Implicitly assuming that t 2 + A(START2) &lt;t 1 , which follows as the intervals [t 1 , t 1 + A(START2)] were assumed not to overlap in time. Note that START actions typically have very small durations.) which fixes t, as d; is given. Finally, suppose that the warms are such that 0 &lt;t2 &lt;t1 &lt;dl &lt;d2.</p><p>This will allow us to give a sequential implementation to the data-gatherer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Implementation</head><p>In this section we give the promised implementation: In practice it would be helpful to make r 1 as short and r2 as long as possible, by selecting sensors with appropriate warms, so that we can shut (much of) the data-gatherer down, and save power, between the STARTS and the READS.</p><p>Our description of this, sequential version of the system, is then Thus far, the example has demonstrated a feature of the CIPA synchronisation discipline; often we write a process including WAIT t for some unspecified t, as we did with the SENSORis and t;s, and then fix the value of t so that some desired synchronisation can happen. In the above, we have also derived assumptions necessary on timing constraints to allow a sequential implementation. This practice corresponds well with informal design procedures in real-time systems, where delays are often inserted to allow some desired rendez-vous' and timing properties exploited in an implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Correctness</head><p>The correctness of the implementation (at least as far as it is captured by cIPA) can be demonstrated by showing that it is equivalent to a process which does a READi at d; for each i, and then, suitably later, PROCESSes the data. However, our implementation is predicated on a set of timing assumptions that allow a sequential implementation, and these must be built into our specification.</p><p>The first read must begin at time d 1 , and the second at d2 , which happens after d 1 , so we have where r4 = A (WRITE2).</p><p>1 Our use of WAIT t with t undefined means that we are implicitly working with a design calculus with i rather than WAIT t prefixes which is compiled down to full CIPA syntax by fixing the duration of WAITS; the least syntactic overhead comes if we view this as we have above, rather than making the design calculus explicit.</p><p>It is then routine, if rather tedious, to show that Proposition 35 The implementation is equivalent to the specification; SPEC SYSTEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Further work</head><p>We conclude the paper with a discussion of some extensions to the work presented here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Inference systems for regular processes</head><p>In Sect. 5, we presented a complete axiomatization of rooted branching bisimulation for recursion-free processes. It would be interesting to extend this result to the regular fragment of CIPA following van Glabbeekis results in <ref type="bibr" target="#b24">[25]</ref>. Note, however, that our processes are acyclic. This implies that processes generated by the regular fragment of cIPA may be infinite state. We expect that techniques from <ref type="bibr" target="#b2">[3]</ref> can be adapted to solve this technical problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Passive actions</head><p>Urgency is a crucial property in CIPA; without it, many of our proofs would not be valid. However, it is quite constraining, especially given our choice of synchronisation rule. One way of allowing more freedom in the timing of actions without losing all hope of a tractable calculus is to add lazy actions; a.P, unlike a.P, waits to be triggered from a synchronisation <ref type="bibr" target="#b45">[46]</ref>. Lazy actions like a allow us to keep our synchronisation rule while allowing idling; a.NIL can synchronise with the a in b.a.NIL, whereas a.NIL cannot.</p><p>Lazy actions also add expressive power to the calculus via their interaction with choice; a. NIL + b.NIL is rather like the CSP external choice between a and b, for instance.</p><p>It would be interesting to try to extend our results for cIPA to a calculus with both lazy and eager actions, some progress in this direction being reported in <ref type="bibr" target="#b45">[46]</ref>. Operationally, lazy actions can be dealt with smoothly by means of the rule LACT (t = t).</p><p>(a.P) t a j -j P(t' + d(a))</p><p>The extension of our results on complete axiomatizations to a setting with lazy actions is, however, much more involved. We are currently working on a complete axiomatization of strong bisimulation over the resulting calculus using a variation on the integration construct of Baeten and Bergstra <ref type="bibr" target="#b7">[8]</ref>. We plan to report on this work elsewhere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Other operators</head><p>An industrial strength timed specification formalism would need a much larger set of operators than we have provided in CIPA. Most of these would be derived, but there is a crucial class of operations,-timeouts,-that cannot be coded in cIPA.</p><p>The introductions of timeouts, such as those provided in timed CSP <ref type="bibr" target="#b17">[18]</ref>, would be a useful extension to cIPA; the correct intuition, however, is somewhat unclear: how should local clocks interact with timeouts? The right balance between generality and tractability is not clear to us here. Another example of the kind of extra operator that might be useful in CIPA is the interrupt. To give some idea of one possible way to proceed, we define the semantics of an interrupt P +A Q. Our intuition is that P + Q behaves like P if Q cannot make a visible move: once it can, P is allowed to finish any current action, but then must allow Q to do its visible action, which forcibly terminates P. Thus the semantics only allows P to evolve if Q does not want to do a visible action sufficiently early. Furthermore, a deadlocked P does not prevent Q from evolving, and Q can always do a silent action.</p><p>We impose a clock distribution property analogous to those of Section 2.5: (P *i Q) t -(P t) ^i' (Q t). The semantics of + can then be defined over configurations (see <ref type="bibr">Display 6)</ref>.</p><p>The interrupt operator Ea has the minimum necessary to be considered as an extension to cIra: it has a well-defined semantics and preserves RBB. However, it interacts rather badly with action refinement (as refinement can allow an interrupt to happen earlier), so we did not choose to add it to the core calculus.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>ACT</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition 4 .</head><label>4</label><figDesc>We will write API for the process graph G = (S, E, --*, s o ) generated by a cIPA process P starting at time 0 from the rules in displays 1 and 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a)) II (b 0) a bj (NIL A (a)) II (NIL A (b))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a.b + b.a)0 bA(a) b@4(a) NIL (A (a) + d(b)) and (a.b + b.a)0 -r aA(b) ° a°) NIL (d(a) + d(b)) clearly indicating the use of local clocks in differentiating between these two processes. Restriction Consider P = (a.b 11 ã)\{a} and Q = (c.b 11 c)\{c}. Then it is easy to see that P '&amp; WAIT d (a). b and Q ;: WAIT d (c) . b and so P .:s Q if 4(a) = 4(c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition 11 .</head><label>11</label><figDesc>Define by structural induction on the (the canonical form of) configurations, s, the collection of times clocks in s read, rds(s) and the number of clocks in s, clks(s): rds(NIL t) = &lt;t&gt; clks(NIL t) = 0 rds((a.P)t) = &lt;t&gt; clks((a.P)t) = 1 rds((WAITt'.P)t) = &lt;t&gt; clks((WAITt'.P)t) = 1 rds((REcX.P)t) = &lt;t&gt; clks((R.EcX.P)t) = 1 rds(s + s') = rds(s).rds(s') rds(s 11 s') = rds(s).rds(s') rds(s\C) = rds(s) where . is concatenation of sequences. clks(s + s') = max(clks(s), clks(s')) clks(s 11 s') = clks(s) + clks(s') clks(s\C) = clks(s)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>P</head><label></label><figDesc>= (a.a.c jj b.d.d)\{Q} and Q = (a.a.d jj b.Q.c)\{a} which are distinguished by location equivalence. Thus we have: Proposition 29 For full CCS, .: is, in general, incomparable with the weak versions of causal bisimulation equivalence, location equivalence and ST-bisimulation equivalence. Proof. Consider P = (a.b ã)\{a} and Q = (c.b 11 c)\{c}. Then, if d(a) d(c), we have that P * Q. On the other hand, P and Q are related by causal bisimulation equivalence, location equivalence and ST-bisimulation equivalence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>s 4 u 4 s' and e i f implies 3u' e Q such that s 4 u' 4s'.We will, as usual, confine attention to ATSs satisfying the following conditions: unambiguity This property essentially says that the same transition cannot take us to different places: s o u and s 4 u' implies u= u' .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>clef DATA GATHERER = WAIT t2 . START2. WAIT rl . START 1. WAIT r2. WRITE1 . WAIT r3. WRITE2. PROCESS, where r1 = tl -t2 -4(START2), r2 = ti + A(READ1) and r3 = (d2 + A(READ2)) -(d l + A(READ1) + A(WRITEI)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>II SENSOR1 11 SENSOR2)\ {STARTi, WRITEi} .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>WAIT d1 . READ 1) II (WAIT d2. READ2. WAIT r4. PROCESS),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Proposition 32 The relation A* is an equivalence relation, and pd defined over2*-equivalence classes by [e'] pa [ f'] iff 3e" e [e'], f" e [ f'] such that e" x f" is a symmetric and irreflexive relation.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. The second author would like to thank Gian Luigi Ferrari for a most stimulating visit to Pisa where this work was first presented. Both authors would like to thank Roberto Gorrieri, Matthew Hennessy and Vladimiro Sassone for helpful remarks.</p><p>The second author was partly funded by a Royal Society European Research Fellowship at the GMD Bonn, and partly by an SERC Postdoctoral Research Fellowship.</p><p>Both authors would like to thank the referees for their constructive comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In view of the above axiom, we shall abbreviate all timed, durationful r-actions to r.</p><p>(So that the axiomatisation we give is two-sorted.) The equivalence relation over E generated by TAU axiom will be denoted by</p><p>The interplay between the equational theory of actions and that for processes is stated by the following substitutivity rule: SUB a /3 and s = u implies a : s = /3: u.</p><p>We shall write, for s, u extended configurations, s =, u if the equality s = u can be derived using equational logic from the equations in Display 3 and the rule SUB.</p><p>A few comments on the axioms in Display 3 are now in order. Axioms (A1)-(A4) and (H) are all that is needed to completely axiomatize rooted branching bisimulation over E-labeled finite trees <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. Axioms (S1)-(S3) are the structural axioms over the set of generators of c'(cIPA) and 1c'(cIPA). These axioms, ST-bisimulation equivalence over concrete CIPA (see <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">Fig. 3]</ref>) are also sound and complete for :. For ease of reference, the set of equations we will consider is listed in Display 4.</p><p>Let _ denote the least congruence over concrete cIPA processes which satisfies the equations in Display 4.</p><p>Proposition 23 For all concrete CIPA processes P, Q, P -Q implies P x Q.</p><p>In the proof of completeness of = with respect to .: over concrete processes, we will follow the lines of similar results in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16]</ref>, and will make a fundamental use of the following key decomposition property: for t&gt; 0 DEC Pt II P' 0 .: Q t II Q'O implies P : Q and P' " Q'.</p><p>An elegant proof of statement DEC can be given by adapting the unique factorisation result presented in <ref type="bibr" target="#b42">[43,</ref><ref type="bibr">Theorem 4.2.2]</ref> to our setting. This we now present, referring the reader to <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref> for more details and intuition on unique factorization results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 24</head><p>Let s be a concrete configuration. Then s is said to be:</p><p>• irreducible ifs : s l II s2 implies s l NIL or s2 NIL;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• prime if s is irreducible and s * NIL.</head><p>For each concrete configuration s, a parallel factorization for s modulo : is given by a set {s 1i ... ,Sk }, k &gt;_ 0, of primes such that </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Relating distributed, temporal and causal observations of simple processes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Aceto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fund. Inf</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="369" to="397" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards action refinement in process algebra</title>
		<author>
			<persName><forename type="first">L</forename><surname>Aceto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="204" to="269" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A complete axiomatization of timed bisimulation for a class of timed regular behaviours</title>
		<author>
			<persName><forename type="first">L</forename><surname>Aceto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jeffrey</surname></persName>
		</author>
		<idno>4/94</idno>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<date type="published" when="1994-03">March 1994</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science, University of Sussex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>To appear in</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the Ill-Timed but Well-Caused</title>
		<author>
			<persName><forename type="first">L</forename><surname>Aceto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CONCUR. Proc. Hildesheim</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Best</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">715</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Timing and Causality in Process Algebra</title>
		<author>
			<persName><forename type="first">L</forename><surname>Aceto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>University of Sussex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report 9</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Axford</surname></persName>
		</author>
		<title level="m">Concurrent Programming: Fundamental Techniques for Real-Time and Parallel Software Design</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Global renaming operators in concrete process algebra</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baeten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="245" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Real time process algebra</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baeten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Form. Asp. of Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="142" to="188" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Process algebra. (Cambridge Tracts in Theoret</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baeten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weijland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="1990">1990</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Categories of asynchronous systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bednarczyk</surname></persName>
		</author>
		<idno>Number 3/87</idno>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Sussex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fixed point semantics in process algebras</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-W</forename><surname>Klop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Report Number IW</title>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<date type="published" when="1982">1982</date>
			<pubPlace>Mathematisch Centrum. Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Petri net semantics of priority systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koutny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="175" to="215" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Atomic actions (note)</title>
		<author>
			<persName><forename type="first">G</forename><surname>Boudol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. EATCS</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="136" to="144" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Observing localities</title>
		<author>
			<persName><forename type="first">G</forename><surname>Boudol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Castellani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kiehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="31" to="62" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Atomic actions in concurrent systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jalotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed Computing Systems. Proc. 5th Internat. Conf</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="184" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed bisimulations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Castellani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="887" to="911" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Causal trees</title>
		<author>
			<persName><forename type="first">P</forename><surname>Darondeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Degano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata, Languages and Programming. Proc</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Rovan</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">372</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An introduction to timed CSP</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
		<idno>Number 75</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>Oxford University Computer Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A bried history of timed CSP</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
		<idno>Number 96</idno>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Oxford University Computer Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Partial Ordering Semantics for CCS</title>
		<author>
			<persName><forename type="first">P</forename><surname>Degano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>De Nicola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="223" to="262" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Parametric laws for concurrency. Manuscript, Dipartimento di Informatica</title>
		<author>
			<persName><forename type="first">G-L</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gorrieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Montanari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>University di Pisa</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Observing Time-Complexity of Concurrent Programs. Manuscript</title>
		<author>
			<persName><forename type="first">G-L</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Montanari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>Dipartimento di Informatica, University di Pisa</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A constraint-oriented real-time process calculus</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th Internat. Conf. Formal Description Techniques</title>
		<meeting>of the 5th Internat. Conf. Formal Description Techniques<address><addrLine>North-Holland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="363" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Comparative concurrency semantics and refinement of actions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Glabbeek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Vrije Universiteit to Amsterdam</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A complete axiomatization for branching bisimulation congruence of finite-state behaviours</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Glabbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Foundations of Computer Science Proc. Gdansk</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Borzyszkowski</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">711</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Petri net models for algebraic theories of concurrency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Glabbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vaandrager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PARLE II Parallel Languages. Proc</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Bakker</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">259</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Branching time and abstraction in bisimulation semantics (extended abstract)</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Glabbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weijland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing. Proc. 613-618</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Ritter</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989. 1991</date>
		</imprint>
	</monogr>
	<note>Full version available as Report CS-R9120</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Refinement in branching time semantics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Glabbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weijland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Report CS-R</title>
		<imprint>
			<biblScope unit="volume">8922</biblScope>
			<date type="published" when="1989">1989</date>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>CWI</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Real-time calculi and expansion theorems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Godskesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th Conference on Foundations of Software Technology and Theoretical Computer Science</title>
		<title level="s">Lecture Notes in Comput. Sci</title>
		<meeting>12th Conference on Foundations of Software Technology and Theoretical Computer Science</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Refinement, atomicity and transactions for process description languages</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gorrieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Dipartimento di Informatica, University di Pisa</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Towards performance evaluation in process algebra</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gorrieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roccetti</surname></persName>
		</author>
		<idno>93-27</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. AMAST &apos;93</title>
		<title level="s">Lecture Notes in Comput. Sci</title>
		<meeting>AMAST &apos;93</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
		<respStmt>
			<orgName>Dipartimento di Matematica, University di Bologna</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An efficient algorithm for branching bisimulation and stuttering equivalence</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Groote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vaandrager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata, Languages and Programming. Proc</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">443</biblScope>
			<biblScope unit="page" from="626" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Axiomatising Finite Concurrent Processes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A temporal process algebra</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Regan</surname></persName>
		</author>
		<idno>2/90</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Sussex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Communicating sequential processes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hoare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. series on Comput. Sci</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Timed Process Algebra # Time x Process Algebra</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jeffrey</surname></persName>
		</author>
		<idno>Number 79</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Programming Methodology Group, Chalmers University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Relating computation and time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goswami</surname></persName>
		</author>
		<idno>RR 138</idno>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Warwick</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On interprocess communication. Part I: Basic formalism</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="85" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Virtual Time and Global States of Distributed Systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mattern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Algorithms. Proc</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Cosnard</surname></persName>
		</editor>
		<meeting><address><addrLine>North-Holland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Traces, histories, graphs: Instances of a process monoid</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mazurkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Foundations of Computer Science. Proc</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">176</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Communciation and concurrency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Milner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. series on Comput. Sci</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Prentice-Hall International</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unique decomposition of processes (note)</title>
		<author>
			<persName><forename type="first">R</forename><surname>Milner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Scie</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="357" to="363" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Axioms for concurrency</title>
		<author>
			<persName><forename type="first">F</forename><surname>Moller</surname></persName>
		</author>
		<idno>CST-59-89</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A temporal calculus of communicating systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tofts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CONCUR. Proc. Amsterdam</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Baeten</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990">1993. 1990</date>
			<biblScope unit="volume">459</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Timed Process Algebra, Petri Nets, and Event Refinement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Refinement. Proc</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Morris</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Arbeitspapiere der GMD 680, Gesellschaft fur Mathematik and Dataverarbeitung, St. Augustin, 1992. Presented at MFPS &apos;92 and submitted to Theoret</title>
		<author>
			<persName><forename type="first">D</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci</title>
		<imprint/>
	</monogr>
	<note>Intervals and actions in a timed process algebra</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Real-timed concurrent refineable behaviours</title>
		<author>
			<persName><forename type="first">D</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal Techniques in Real Time and Fault Tolerant Systems Proc. Nijmegen</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Vytopil</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">571</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The algebra of timed processes ATP: Theory and application</title>
		<author>
			<persName><forename type="first">X</forename><surname>Nicollin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sifakis</surname></persName>
		</author>
		<idno>RT-C26</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Laboratorie de Genie Informatique de Grenoble</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A structural approach to operational semantics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Plotkin</surname></persName>
		</author>
		<idno>DAIMI-FN- 19</idno>
		<imprint>
			<date type="published" when="1981">1981</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, Arhus University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A classification of models for concurrency</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sassone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Winskel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CONCUR. Proc. Hildesheim</title>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Best</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993. 1993</date>
			<biblScope unit="volume">715</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An operational semantics for timed CSP</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. and Comput</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Substitution revisted</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stoughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="317" to="325" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Failures Semantics based on Interval Semiwords is a congruence for Refinement</title>
		<author>
			<persName><forename type="first">W</forename><surname>Vogler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="139" to="162" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Moduler Construction and Partial Order Semantics fo Petri Nets</title>
		<author>
			<persName><forename type="first">W</forename><surname>Vogler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lect. Notes Comput. Sci.</title>
		<imprint>
			<biblScope unit="volume">625</biblScope>
			<date type="published" when="1993">1993</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<author>
			<persName><forename type="first">Wang</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCS + Time = an Interleaving Model for Real Time Systems. In Automata</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">510</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
