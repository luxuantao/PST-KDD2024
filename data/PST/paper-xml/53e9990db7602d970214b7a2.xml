<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Measuring the Dynamic Behaviour of AspectJ Programs *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bruno</forename><surname>Dufour</surname></persName>
							<email>bdufou1@cs.mcgill.ca</email>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Goard</surname></persName>
							<email>cgoard@cs.mcgill.ca</email>
						</author>
						<author>
							<persName><forename type="first">Laurie</forename><surname>Hendren</surname></persName>
							<email>hendren@cs.mcgill.ca</email>
						</author>
						<author>
							<persName><forename type="first">Ganesh</forename><surname>Sittampalam</surname></persName>
							<email>ganesh@comlab.ox.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Clark</forename><surname>Verbrugge</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Oege de Moor Oxford University Computing Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Oxford University Computing Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Measuring the Dynamic Behaviour of AspectJ Programs *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3AA79BCCEA44673A4FC6A07F65F95A80</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.3.3 [Programming Languages]: Language Constructs and Features; D.2.8 [Software Engineering]: Metrics Experimentation</term>
					<term>Languages</term>
					<term>Measurement</term>
					<term>Performance Aspect-oriented Programming</term>
					<term>AspectJ</term>
					<term>Dynamic Metrics</term>
					<term>Program Analysis</term>
					<term>Java</term>
					<term>Optimization</term>
					<term>Performance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes and implements a rigorous method for studying the dynamic behaviour of AspectJ programs. As part of this methodology several new metrics specific to AspectJ programs are proposed and tools for collecting the relevant metrics are presented. The major tools consist of: (1) a modified version of the AspectJ compiler that tags bytecode instructions with an indication of the cause of their generation, such as a particular feature of AspectJ; and (2) a modified version of the *J dynamic metrics collection tool which is composed of a JVMPI-based trace generator and an analyzer which propagates tags and computes the proposed metrics. This dynamic propagation is essential, and thus this paper contributes not only new metrics, but also non-trivial ways of computing them.</p><p>We furthermore present a set of benchmarks that exercise a wide range of AspectJ's features, and the metrics that we measured on these benchmarks. The results provide guidance to AspectJ users on how to avoid efficiency pitfalls, to AspectJ implementors on promising areas for future optimization, and to tool builders on ways to understand the runtime behaviour of AspectJ.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Aspect-oriented programming <ref type="bibr" target="#b17">[17]</ref> is a new technique for modularizing a program. An aspect is a feature that "cross-cuts" the traditional abstraction boundaries of classes and methods; the most common examples of aspects are ones used for tracing or logging the execution of an existing program, but aspect-oriented design techniques have also been used successfully for more closely coupled functionality improvements, such as connection pooling.</p><p>The most popular implementation of these ideas is AspectJ <ref type="bibr" target="#b16">[16]</ref>, an extension of Java. The textbook by Laddad <ref type="bibr" target="#b19">[19]</ref> provides a nice introduction, both to the language and its potential applications. AspectJ started out as a pioneering research effort, but has quickly reached a level of maturity where it is on the verge of being used for production programming, and we therefore believe that the time is right for the research community to pay more attention to the performance of AspectJ programs.</p><p>The conceptual model behind AspectJ execution is one in which aspects dynamically "observe" the execution of a base Java program. At certain points during this execution, known as join points and specified (in aspects) by pointcuts, an aspect inserts or substitutes its own code, known as advice. Of course, this conceptual model would be extremely expensive to implement literally; instead, AspectJ is implemented as a compiler which statically weaves advice code into the base code. In many cases, whether or not advice would apply at runtime (in the conceptual model) is statically determinable, and so this can be done without introducing runtime overhead. However, it is not always possible to decide this at compile time, and so a runtime test has to be inserted, particularly when the more complex features of pointcuts are being used. However, it is a stated goal of the AspectJ compiler to minimize these overheads; indeed, the AspectJ FAQ <ref type="bibr" target="#b35">[35]</ref> states: "We aim for the performance of our implementation of AspectJ to be on par with the same functionality handcoded in Java. Anything significantly less should be considered a bug."</p><p>It appears to be generally believed in the AspectJ community that the compiler does not introduce overheads, and indeed we have confirmed that in many situations it is the case that equivalent Java and AspectJ programs have essentially the same performance. However, we have also identified a number of examples in which the AspectJ compiler does impose a significant overhead, contradicting this belief.</p><p>The FAQ goes on to say: "There is currently no benchmark suite for AOP lan-guages in general or for AspectJ in particular. It is probably too early to develop such a suite because As-pectJ needs more maturation of the language and the coding styles first. Coding styles really drive the development of the benchmark suites since they suggest what is important to measure."</p><p>We contend that the development of a benchmark set which shows good as well as bad uses of AspectJ language features will help to inform the development both of the AspectJ language and compiler, and of coding styles; and that it is better to view the situation as a two-way process where benchmarking both drives and is driven by such development. The overheads that we have found using our benchmark set confirm this.</p><p>In detail, the contributions of this paper are as follows:</p><p>• We provide a new set of dynamic metrics and tools for measuring the performance of AspectJ programs and attributing elements of this performance between the original Java code, the introduced aspect code and the compilation overhead of individual AspectJ language features.</p><p>• We have collected the first benchmark set of AspectJ programs, from a variety of public sources. Despite the growing popularity of AspectJ, it has proved rather difficult to find publicly available programs. We hope that it will form the basis of a generally accepted suite of benchmarks and we welcome further contributions from the AspectJ community.</p><p>• We explain the "conventional wisdom" that the AspectJ compiler introduces no runtime overhead, by showing a series of benchmarks in which this overhead is indeed negligible.</p><p>• We show that in other benchmarks, there is a significant overhead. We identify the language features and patterns of usage that lead to this overhead.</p><p>• Using the Dava decompiler <ref type="bibr" target="#b25">[25]</ref> from the Soot toolkit <ref type="bibr" target="#b32">[32]</ref>, we investigate the output of the AspectJ compiler where our tools pinpointed a significant performance impact, and demonstrate various ways in which improvements could be made. This measure-identify-decompile-fix cycle is very economic in the AspectJ situation, where a new language paradigm calls for novel analyses and optimizations: it would be immensely labour-intensive to obtain the same results through direct experiments with different versions of the compiler.</p><p>These contributions will be of benefit to three groups of people:</p><p>• AspectJ users: Our results provide guidance on which As-pectJ idioms are cheap to use and which impose a performance penalty. For example, we found that directions for advice placement (before/after/around) can have a significant impact on performance, and our experiments explain why.</p><p>• AspectJ compiler implementors: We identify areas in which compilers could be improved, for example by using more sophisticated static analyses to eliminate runtime checks for pointcut matching. Some of these suggestions are very easy to implement, and indeed we report one such optimization which we applied in a modified version of the compiler.</p><p>• AspectJ tool developers: The power of AspectJ makes it very easy to write a seemingly innocuous piece of advice that turns out to have dramatic consequences for performance.</p><p>Our results point the way towards interactive tools that warn the programmer of such situations, and help to remedy the problem when it arises.</p><p>The remainder of this paper is structured as follows. In Section 2 we provide a brief overview of the AspectJ language, and in Section 3 we provide an overview of the statistics we collect for our set of benchmarks.</p><p>In Section 4 we give the full details of our toolset, which consists of a modified version of the AspectJ compiler <ref type="bibr" target="#b3">[3]</ref> that "tags" bytecode instructions according to their provenance (the base Java program, aspect code, or compiler overhead from particular language features), along with a modified version of the *J metric tool <ref type="bibr">[8]</ref> which collects statistics for each of these tags. The tagging is performed both statically and dynamically to allow some tags to be context-dependent; this is vital since in some cases code that is compiler overhead may make calls that should also be attributed to this overhead, but in other cases it may call aspect code that should also be attributed correctly. Developing this tag "propagation" scheme has been a major part of our work.</p><p>The benchmarks themselves are presented in Section 5. We split them into two categories: those that do not demonstrate significant compiler overhead and those that do. In the case of the latter category, we investigate the reasons for this overhead in detail and suggest possible improvements.</p><p>While we believe this is the first systematic study of the dynamic behaviour of AspectJ, there is naturally a wealth of related work on collecting dynamic metrics. We discuss these, and also existing efforts to improve the runtime behaviour of AspectJ programs, in Section 6. Finally we discuss our conclusions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A BRIEF INTRODUCTION TO ASPECTJ</head><p>AspectJ is an extension of Java; it provides novel features for modularization, in particular when adding new functionality to an existing "base program". The novel features can be classified into two groups. The first group allows one to influence the dynamic behaviour of the base program by injecting new code when certain events occur in its execution. We discuss these dynamic features in Section 2.1. The second group of features allows one to statically add new members to classes. These features are reviewed in Section 2.2. This introductory section only covers the very basics, and readers who are new to AspectJ may wish to consult one of the textbooks <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b19">19]</ref> for a more comprehensive introduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Join points, pointcut and advice</head><p>When adding tracing functionality to an existing program, it is often undesirable to modify the program itself: the implementation of tracing is scattered over the design, and hence it obscures the existing code, and it is difficult to maintain itself. It would be preferable if we could describe the execution events that we wish to trace, and the action to take upon each such event. AspectJ allows us to do this by specifying such execution events. The events are called join points, the pattern that specifies a set of join points is called a pointcut and the additional code that gets run is called advice. The join points that can be be selected via pointcuts can be thought of as nodes in the dynamic call tree of the program. Besides nodes for method calls, this call tree also includes nodes for the execution of a method body, exception handlers, and so on.</p><p>To illustrate these abstract definitions, let us examine a tiny example, shown in Figure <ref type="figure">1</ref>. It consists of a base program (the class Example) and an aspect (named ExampleAspect). The base program consists of two methods called foo and bar. The purpose of the aspect is to signal any calls that are made to bar within the dynamic scope of foo. In terms of the call tree, this means that we are interested in bar nodes that occur below a call to foo. In the aspect, this is expressed as follows. It says that before entering any join point selected by the pointcut the message "foo -&gt; bar" should be displayed on the standard output. The pointcut itself consists of two parts: it says we want a call to bar, and furthermore we must be dynamically within the control flow (cflow) of foo.</p><p>While the matching of join points to pointcuts is conceptually a dynamic process that happens entirely at runtime, the AspectJ compiler shifts a lot of the work to compile-time. In the above example, it will identify the calls to bar in the program text, effectively matching the first part of the pointcut. The second part of the pointcut (involving cflow) is however matched dynamically, and to this end some extra code is inserted, which checks whether we are in the dynamic scope of foo. To make that check, it is in turn necessary to do a little administration at each call to foo. As we shall discuss in more detail later, the AspectJ compiler mimics the call stack by recording each entry to foo, and each exit.</p><p>There is some terminology to ease discussion of these issues. The place in a program text that gives rise to a particular join point at runtime is called a shadow. As we have just explained, the compiler matches pointcuts against such shadows, possibly leaving a dynamic residue for the tests that could not be resolved completely. The process of producing combined code for the base program and its aspects is called weaving.</p><p>Our own understanding of join points and advice was mostly shaped by <ref type="bibr" target="#b33">[33]</ref>, which gives a definitional interpreter for join points and advice. Our discussion of the weaving process has been greatly influenced by <ref type="bibr" target="#b23">[23]</ref>, which explains it in terms of partial evaluation of the interpreter in <ref type="bibr" target="#b33">[33]</ref>. The definitive account of the way the AspectJ compiler works can be found in <ref type="bibr" target="#b14">[14]</ref>.</p><p>We shall introduce further features relating to join points and advice as we discuss specific benchmarks later on in this paper. In particular, we shall examine different placements of advice (after and around) in addition to before.</p><p>Finally, we should remark that the example in this section does not require the use of cflow. AspectJ has another kind of pointcut, namely withincode that would be preferable to use for such a simple application, because it is more efficient. One aim of the present paper is to elucidate such issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Intertype declarations</head><p>While advice is a powerful mechanism to modularize designs where the traditional abstractions of Java fail, it is not always enough on its own. Sometimes it is necessary to make a static change to an existing class, for example to add a new method. AspectJ allows such intertype declarations. For example, the aspect in Figure <ref type="figure">1</ref> could enhance the Example class with a new method called goo by including the line public void Example.goo() { System.out.println("goo"); foo(); } Client code of Example (introduced by the aspect) can now refer to goo in the same way as it references foo or bar.</p><p>Similar ideas can be found in other extensions to Java, in particular MultiJava <ref type="bibr" target="#b5">[5]</ref> and RMJ <ref type="bibr" target="#b26">[26]</ref>. These designs are in fact more disciplined than AspectJ, and they allow for modular type checking, which AspectJ does not; furthermore they include multimethods, a feature that AspectJ lacks at present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MEASUREMENTS AND DYNAMIC METRICS</head><p>In order to study the dynamic behaviour of AspectJ, it was necessary to develop a methodology to collect measurements and dynamic metrics for AspectJ programs. Our approach uses the following three kinds of measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Execution Time</head><p>The most coarse-grained measurement is the execution time of a program, which we use as a first-order measurement of the overheads incurred by using aspects. In particular, we compare the execution time of an AspectJ version of a program and an equivalent Java program. All execution times in this paper were collected on an Athlon MP 1.66 GHz machine with 2 Gbyte of memory. All profiling data used to compute the dynamic metrics was collected on an Intel Pentium 4 1.80 GHz machine with 512 Mbyte of memory. Both machines use Sun's Java™ 2 Runtime Environment, Standard Edition (build 1.4.0-b92<ref type="foot" target="#foot_0">1</ref> ) on Debian Linux.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Java-based dynamic metrics</head><p>As well as execution time, one would also like more specific measurements of the dynamic behaviour of both the Java and As-pectJ versions of benchmarks. Since both Java and AspectJ programs are compiled to Java bytecode, it was possible, using *J <ref type="bibr">[8]</ref>, an existing tool, to measure relevant dynamic metrics. The *J tool collects a wide variety of metrics, and we have found several metrics to be useful in our evaluation of AspectJ benchmarks.</p><p>For example, the base metrics can be used to measure: (1) the total number of bytecode instructions executed, a VM-neutral measure of execution time; (2) the total number of distinct bytecodes loaded and executed, which gives a measurement of total and live program size; and (3) the total number of bytes allocated, which measures how memory hungry the benchmarks are. We can also use more detailed metrics to measure specific behaviours. For example, we can look at the density of important (expensive) operations such as virtual method invocations, field read/writes and object allocations. Specific examples of these metrics are given in the discussion of our benchmarks in Section 5.</p><p>It is often useful to differentiate between application code and library code, especially in the case of AspectJ programs. We define application code as the set of class files that are directly generated by the AspectJ compiler. In addition to generating "WHOLE PRO-GRAM" versions of the metrics, *J is also able to generate "APPLI-CATION ONLY" versions of them by only taking into consideration the contributions made by the application code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Dead Code and Code Coverage</head><p>In our study of AspectJ benchmarks we found that the AspectJ compiler sometimes includes code that is never executed; in particular, methods that are never called. Since the entire class must be loaded, this causes unnecessary time to be spent in class loading and verification.</p><p>Thus, we found that it was useful to add two new metrics to our standard Java metrics. The dead code metric measures the number of bytecode instructions that are loaded, but never executed. The code coverage metric is computed as the ratio of live code over loaded code. Thus, a program that loads 10,000 bytecodes and has 2,000 dead bytecodes, has a code coverage of 0.80, that is (10,000 -2,000)/10,000. It should be noted that the dead code metric is also dynamic and is reporting the code dead for a particular execution of the program. It may be the case that a different execution would touch different parts of the code. Also, in some cases, the dead code may never execute in any given run, but is a necessary consequence of support for incremental compilation and weaving, since a change to the base program might cause the code to become required and we would not want to have to recompile the aspect in that case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">AspectJ-specific dynamic metrics</head><p>Although the previous two kinds (execution time and Java-based dynamic metrics) of measurements give a good overall idea of overheads incurred by the use of AspectJ, they do not help identify the cause of such overheads, nor do they expose any behaviours that are specific to AspectJ programs. In order to study these it was necessary to define new metrics and extend existing tools in nontrivial ways to compute them. These extensions are described in more detail in Section 4, but mainly consist of associating a tag to every executed bytecode instruction indicating its purpose. In the following subsections we describe the new metrics that were designed specifically for analyzing AspectJ programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Tag Mix</head><p>The tag mix metric partitions all executed bytecode instructions into 29 different bins, where each bin corresponds to a specific purpose. Bins are reported as a percentage of total executed instructions. This breakdown of executed bytecodes is useful in determining which particular features of AspectJ are used in a benchmark.</p><p>Individual tags can be grouped into categories according to the AspectJ language feature that they relate to. We define 10 categories of tags, 9 of which correspond to overhead code introduced by the AspectJ compiler. A detailed list of tags and categories is given in Appendix I, and example measurements of these tags are given in Section 5. A short description of all categories, along with their most important tags, is presented next.</p><p>Readers who are unfamiliar with AspectJ may wish to skim this section first time through, and then return to it after seeing some example programs in Section 5.</p><p>General tags. This category contains tags which are associated with user-defined code. For analysis purposes, we distinguish between regular code and advice code. The BASE CODE bin represents all executed instructions that correspond to the base program (regular Java), whereas the ASPECT CODE bin corresponds to code that was executed as part of the aspect. This includes all non-overhead instructions corresponding to the body of an advice and all non-overhead instructions in code called from the body. It also includes all non-overhead instructions in methods introduced by intertype declarations.</p><p>In making the distinction between base program and aspect, we err on the side of underestimating the effect of aspects, for example by making all instructions due to callbacks from native methods contribute to the BASE CODE bin.</p><p>Advice-related tags. This category contains tags that are common to before, after and around advice. The ADVICE EXECUTE tag identifies overhead associated with executing an advice body. The ADVICE ARG SETUP tag identifies overhead associated with exposing parameters to the advice body. The ADVICE TEST tag is associated with dynamic guards inserted by the compiler in cases where it could not determine whether a particular advice body should always be executed for a given join point.</p><p>Tags specific to around advice. Unlike before and after, around advice replaces existing code with the advice body. The original code can still be invoked through the special proceed() statement, though implementation of this feature implies additional overhead. The AROUND PROCEED tag identifies instructions which are inserted to make a call to proceed() from within an advice body. Under some circumstances, it is possible that the call to proceed() is not implemented using the inlining strategy, but implemented using a more general technique, a closure. We therefore define the tag AROUND CALLBACK which serves the same purpose as AROUND PROCEED, but which additionally identifies the tagged instructions as part of the closure implementation. The CLOSURE INIT tag is used to identify instructions which initialize the closure objects that are created.</p><p>Tags specific to after advice. There are two distinct kinds of overhead that are associated with the use of after advice. As with around advice, exposing the return value of a method to the advice body requires support from the compiler, leading to the addition of some overhead code. Also, because after advice must execute regardless of whether the method terminated normally or not, the compiler adds exception handlers to the original code in order to address this issue. The AFTER RETURNING EXPOSURE and AFTER THROWING HANDLER tags are associated with these two situations, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intertype declaration tags. Intertype declarations in AspectJ</head><p>can lead to several forms of overhead being introduced: additional method invocations, accessor methods for introduced fields, variable initialization, etc. Several tags are defined to identify each kind of overhead.</p><p>perthis and pertarget-specific tags. Normally aspects are singletons; however, they can also be defined on a per-object basis. This category contains instructions which are used to manipulate aspect instances when there are multiple instantiations rather than a single one.</p><p>Cflow-specific tags. Because cflow pointcuts and percflow aspects (as with perthis and pertarget, percflow is defined on a perobject basis) require some knowledge of the dynamic control flow of the application, the compiler inserts overhead code in order to create and maintain a representation of this information. There are two tags, CFLOW ENTRY and CFLOW EXIT, to identify instructions which keep this data structure updated.</p><p>Exception softening tags. This category contains a single tag, EXCEPTION SOFTENER, which identifies instructions which are used to wrap instances of checked exceptions into an unchecked org.aspectj.SoftException instance.</p><p>Tags specific to privileged aspects. Privileged aspects have access to private methods and fields of classes. The compiler makes it possible by adding public wrappers to the appropriate classes. This category contains tags that identify instructions which are part of the inserted wrapper methods.</p><p>Miscellaneous aspect tags. This category contains two kinds of tags. The first kind of tag, CLINIT, is associated with instructions which are found in static initializers of aspect classes. The second kind, INLINE ACCESS METHOD, identifies the overhead involved in calling a method defined on an aspect when there is a static dispatch method.</p><p>An important benefit of our tool set is that it is easy to extend the set of bins, thus giving fine-grained information to language designers and compiler writers about the code emanating from new language features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Aspect Overhead</head><p>Once every executed bytecode has been tagged appropriately, it is possible to compute the percentage of executed instructions which fall into the "overhead" category. We define overhead as all instructions executions which do not fall within the "general" tag category (BASE CODE or ASPECT CODE). This closely corresponds to the instruction executions that would not be found in a hand-woven implementation of the same application.</p><p>The aspect overhead metric can also be expressed as the product of two other ratios. The overhead to advice ratio indicates the relative amount of overhead per introduced advice. It is measured as the number of executed overhead bytecode instructions divided by the number of executed advice instructions. The advice to total ratio measures the proportion of the executed code that belongs to advice bodies, and is computed as the number of executed advice instructions divided by the total number of executed instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">AspectJ Runtime</head><p>In order to truly measure the proportion of the code that can be attributed to the use of AspectJ, it is necessary to keep track of the calling context. The AspectJ runtime library metric measures the percentage of the code that is executed as part of the AspectJ library, or on its behalf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Advice Execution</head><p>In many cases, the AspectJ compiler can statically determine if a piece of advice should be executed at all join points corresponding to a given join point shadow. In these cases, no dynamic test is required to determine if the advice code should be executed or not. There are cases for which static analysis cannot determine the applicability of the advice. For example, the if pointcut contains a boolean expression which is evaluated to determine join point membership; this expression may contain references to dynamic values, and so it may not be statically determinable whether it evaluates to true or false. The cflow pointcut also generally results in a dynamic test.</p><p>The advice execution metric reports on the outcome of those checks, categorizing them into three bins, those that always succeed, those that always fail, and those that sometimes succeed and sometimes fail. Clearly those checks that sometimes succeed and sometimes fail are needed. However, those checks that always succeed or always fail (in one particular run) are potential places where a stronger static analysis might be able to eliminate the check, thus eliminating unnecessary overhead and improving performance. Of course it may be the case that some checks that are measured as always going one way actually could go the other way in a different run of the program, so it is not necessarily the case that all of those which are identified could really be removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">Hot Shadows</head><p>Recall that a shadow is the static location in a program text that gives rise to a particular join point at runtime. The hot shadows metric measures the percentage of all shadows that account for 90% of the total advice body invocations. This gives an indication of whether runtime advice execution is mostly concentrated on a few shadows, or whether it is thinly spread; this metric thus helps us to understand whether we might obtain a performance gain by concentrating on just a few locations (and for example inlining advice bodies at those locations). Note that if there are overlapping pointcuts, it is possible for one shadow to invoke multiple advice bodies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">TOOLS FOR COLLECTING DYNAMIC METRICS</head><p>An overview of the tools that we use for collecting the dynamic metrics is given in Figure <ref type="figure">2</ref>. The darker shaded boxes correspond to new tools, and the more lightly shaded boxes correspond to components of existing tools that we modified.</p><p>Our main tools implement the two important components of our approach: (1) a static tagger, which tags bytecode instructions with tags corresponding to their associated purpose; and (2) a dynamic analyzer, which propagates the bytecode tags across method calls, according to the context of the call, and computes the dynamic metrics.</p><p>In addition to these main tools we have also developed two utilities. The Retagger utility allows us to modify the tags by hand interactively, so that we can experiment with new tagging approaches. The TagReader utility allows us to print a textual representation of the tagged bytecode so that we can check its correctness and view the details of which bytecode instructions are tagged.</p><p>In the following subsections we first provide an illustrative example, showing examples of static tagging and tag propagation (Section 4.1). We then provide more specific details on the implementation of the two main components of our approach, the static tagger, based on the AspectJ 1.1.1<ref type="foot" target="#foot_1">2</ref> compiler (Section 4.2), and the dynamic metric analyzer, based on *J (Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">An example</head><p>To demonstrate our approach to static tagging and dynamic propagation, consider the small AspectJ program in Figure <ref type="figure">1</ref>. The advice declared in ExampleAspect should execute before every call to bar() (selected by the first call pointcut) for which there is a call to foo() somewhere in the call stack (selected by the cflow pointcut).</p><p>The listing in Figure <ref type="figure" target="#fig_0">3</ref> shows the bytecode instructions for each of the methods in Example.class, with the added instruction tags that were produced by our static tagger. Each line of bytecode corresponding to instructions introduced by the AspectJ compiler is annotated with the tag associated with it. Many bytecodes do not have a tag and these bytecodes will be assigned a tag during the  Instructions 18-21 in both methods are advice execution overhead, tagged ADVICE ARG SETUP and ADVICE EXECUTE. The distinction is made between these two tags because they propagate differently. Instruction 18 is a call to the aspectOf() method, which acquires the aspect instance. All of the untagged instructions in as-pectOf() will inherit the tag of instruction 18 (ADVICE ARG SET- UP), as they also represent the same kind of overhead. Instruction 21, however, calls the advice body, which is not overhead, and so its tag is not propagated by the analyzer. Instead, the ASPECT CODE tag is propagated to the advice body method.</p><p>Instructions 28-38 (CFLOW ENTRY) and 44-62 (CFLOW EXIT) manage the representation of the call stack, required by the cflow pointcut. This call stack representation is described in more detail in Section 5.3.2. Before each call to foo(), a value is pushed onto the CFlowStack corresponding to the relevant cflow pointcut. On returning from that call, either normally or by thrown exception, the CFlowStack is popped. Both of these tags, CFLOW ENTRY and CFLOW EXIT, propagate to the called methods since the push() and pop() methods represent the same kinds of overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Static Tagging: annotating class files using a modified AspectJ compiler</head><p>The AspectJ compiler, since version 1.1, operates in two stages. The first is a compilation stage, using the Java compiler from the Eclipse project, which produces class files with special attributes. These attributes contain information for the second stage, where aspects are woven into the bytecode of a base program.</p><p>We have modified the bytecode weaver of version 1.1.1 of the AspectJ compiler to annotate the classes it produces. A first set of annotations assigns tags to certain bytecode instructions. These tags aim at identifying the role of the instruction in the generated code, such as dynamically guarding a given piece of advice, invoking an advice body, etc. The tag annotations are focused on studying the use of the different language features that AspectJ supports; 27 out of the 29 possible tags represent overhead instructions (the other two are for base and aspect code respectively).</p><p>A second set of annotations identify the join point shadows into which instructions have been inserted during weaving. Each added instruction is tagged with a shadow ID corresponding to a single join point shadow. For example, the single advice declaration listed in Figure <ref type="figure">1</ref> results in instructions being added to multiple join point shadows in the base program. These added instructions have shadow ID tags as shown in Figure <ref type="figure" target="#fig_0">3</ref>. The three join point shadows, each corresponding to a method call, have IDs 12, 13, and 17. The weaver additionally stores a table mapping each shadow ID to its shadow kind (e.g., method-call) and its signature (e.g., void Example.bar() for shadow 12 in the example.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Tagging during weaving</head><p>In the AspectJ compiler, the major changes made to the classes being woven into are performed by two kinds of munger. The first is the type munger, which is responsible for changing the type structure of the program and implements intertype declarations. The second is the shadow munger, which is responsible for manipulating join point shadows, implementing, for example, the weaving in of advice. Consider the simple case of the before advice declared in the example in Figure <ref type="figure">1</ref>. During the weaving stage this advice is represented by a shadow munger which operates on shadows for which a subset of associated join points are selected by the advice's pointcut. The body of the advice is compiled as a method on the aspect class during the compilation stage; the shadow munger inserts into the shadow the instructions necessary for calling this advice body method, and, if necessary, test instructions to determine at runtime if a join point matches the pointcut.</p><p>Our modified AspectJ weaver tags all the instructions according to their purpose. The first set of new instructions created by the weaver expose arguments to the advice and acquire the aspect instance. We add as attributes to each generated instruction object the ADVICE ARG SETUP tag. Then the advice execution instruction is created, which is an invoke to the advice body method. We tag this ADVICE EXECUTE in the same way. Finally, if it hasn't been statically determined that this advice should always execute at this shadow, test instructions are generated, which we tag as AD-VICE TEST. This newly generated instruction list is then inserted into the shadow, which is a range of instructions in a method in the base program.</p><p>Our examples so far have demonstrated some of the most common tags. However, the AspectJ weaver introduces new instructions into the base program to implement many other features, both as a result of static cross-cutting and dynamic cross-cutting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Pretagging</head><p>Not all of the instructions we wish to annotate during the weaving stage are generated during the weaving stage. Existing instructions in aspect classes, generated during the front-end AspectJ compilation, may also represent overhead. The front-end compiler could be modified to tag these instructions as they are generated, in the same manner that instructions are tagged during weaving, however, since AspectJ supports the weaving of binary aspects for which the source may be unavailable, it is desirable to instead perform all tagging during the weaving stage. Therefore, at the beginning of this stage, we search for existing overhead instructions within aspect classes and tag them. Since the AspectJ compiler automatically generates names for advice bodies and other methods on the aspect class, this is accomplished by searching for bytecode patterns in methods whose names match the naming conventions. An example case is that of an around advice body. The body of this around advice is implemented as a method on the aspect class. For this method, we isolate the instructions implementing the proceed() call, and tag them appropriately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Generating attributed class files</head><p>After all tagging and weaving has been performed on all classes, and as classes are being written, our modified AspectJ compiler converts the tag attributes on the instruction objects into a code attribute for each method which is stored in the generated class files. For those instructions with explicit tags we use that tag value, and for instructions without tags a placeholder tag is assigned, namely NO TAG. This will be replaced by a proper tag during the dynamic analysis phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Dynamic metric analysis with tag propagation using *J</head><p>*J is a framework designed to perform dynamic analyses of Java programs. While it was primarily designed for computing dynamic metrics, it can be easily extended to include various other kinds of analyses. The *J framework uses a trace collection agent which is based on the Java Virtual Machine Profiler Interface (JVMPI). This agent receives execution events from a regular Java Virtual Machine (JVM) and encodes the information in the form of an event trace. This trace can then be processed by the analyzer, which internally consists of a sequence of operations organized as a pipeline structure. Each analysis in the pipeline receives events from the trace sequentially. *J provides a number of default analyses in its library, many of which provide services to subsequent analyses in the pipeline. It also includes a full set of general-purpose dynamic metric computation modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Modifications to the *J analyzer:</head><p>Static tagging identifies bytecode that is added to support As-pectJ constructs. Because only the application classes are compiled with the modified AspectJ compiler, using only the static instruction tags in an analysis results in a significant underestimate of the overhead code. For example, it is possible for parts of the Java standard library to be called in AspectJ overhead code as well as from the original application. It is thus necessary to propagate the statically-assigned tags dynamically based on the control flow of the application in order to obtain a correct measurement of overhead.</p><p>Several additions were made to *J in order to make it recognize and use the bytecode tags. The *J class file reader was extended to enable reading of the encoded information, and association of tags with each loaded bytecode instruction. For untagged bytecodes, a default tag value, NO TAG, serves as a placeholder.</p><p>The most significant addition to *J consists of the tag propagation analysis. This analysis is responsible for dynamically assigning tags to executed bytecodes by pushing tags along invocation edges in the dynamic call graph of the application. For example, in Figure <ref type="figure">1</ref>, the invokestatic bytecode at offset 18 in main(String[]) has a static ADVICE ARG SETUP tag. This instruction invokes the aspectOf() method on the ExampleAspect aspect class. At runtime, the ADVICE ARG SETUP tag will be propagated to all bytecodes in the aspectOf() method, and all bytecodes in methods that it calls, etc. If an instruction has no static tag, and no tag has been propagated to it, it is assigned the default tag, BASE CODE. This guarantees that all bytecodes executed during "normal" control flow receive a dynamic tag every time they are executed.</p><p>The exception to this is when program code is entered from places the *J agent cannot observe. This can happen in the case of callbacks from JNI code, or the execution of the class loader, for example. In the cases described, where this task is especially difficult, we always opt for the conservative solution, ensuring that our analysis will never overestimate the overhead.</p><p>The meaning associated with some tags precludes their propagation. For example, the ADVICE EXECUTE tag is used for calls to methods corresponding to advice code; the call (and subsequent return statement) are overhead, but the body of the advice is not and should be tagged ASPECT CODE. In this and similar cases, particular tags trigger propagation of different tags. Therefore, we define a propagation table. This table provides a mapping from each tag to another tag which is to be used in its stead when propagating. Most tags are propagated as themselves; the exceptions are listed in Table <ref type="table" target="#tab_2">1</ref> The propagation algorithm is further complicated by tags which are to be propagated to bytecode instructions which already possess a tag. In such cases, it is sometimes necessary to allow the new tag to temporarily override the previous one. While tags identifying overhead code should not be overridden, it must be possible to override the tags which correspond to base or aspect code. This is best illustrated by a simple example. An instance of an aspect can be accessed via the static method aspectOf() on the aspect class. This call can originate from within user-defined code, as well as from within the code inserted by the weaver to implement advice execution. In order to support the first case, the method is statically tagged ASPECT CODE. In the second case, the invoke is tagged ADVICE ARG SETUP (as illustrated in Figure <ref type="figure" target="#fig_0">3</ref>), which we wish to propagate to the method. To correctly handle all similar situations, it is necessary that instances of the ASPECT CODE and BASE CODE tags can temporarily be overridden by other tags during analysis. Note that in order to support the first case, an instruction tagged BASE CODE must not be allowed to override a statically assigned ASPECT CODE tag. In cases where it would, an ASPECT CODE tag is propagated instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Collecting the AspectJ-specific metrics</head><p>The entire tag propagation scheme is implemented as a separate *J analysis, so that subsequent AspectJ-specific analyses can be implemented independently and easily.</p><p>Since each bytecode execution now has an associated dynamically computed tag, it is a simple addition to the *J analyzer to collect the tag mix metric, which counts the number of bytecodes executed for each tag. We can also apportion other existing metrics, such as allocation counts, between the different tags.</p><p>In addition, the analyzer also tracks all dynamic guards on advice, and for each such guard computes whether the guard always succeeds, always fails, or sometimes succeeds. A count of the number of times each guard is executed is also maintained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">BENCHMARKS</head><p>In this section we provide the results and analysis for eight benchmarks which span a wide variety of uses of AspectJ. Although As-pectJ is becoming quite popular there is no existing AspectJ benchmark set, thus our first challenge was to collect benchmarks that were representative of many different applications of AspectJ. All of our benchmarks were collected from public sources on the web, and can be obtained from http://www.sable.mcgill.ca/ benchmarks/. We believe that providing an interesting and diverse benchmark set is an important contribution in itself.</p><p>Four of our benchmarks have equivalent Java versions, while the other four are too large and/or complex to easily produce Java equivalents. The benchmarks with Java versions are particularly valuable because we can compare runtime overheads shown by direct timing comparisons with overheads shown by our dynamic metric analysis; the timings tell us where there is observable overhead, and the metric analysis helps us understand the reasons for that overhead.</p><p>When analyzing the benchmarks we did not know what to expect a priori. The general belief in the AspectJ community seems to be that overheads are low. Thus, an important part of our study was to find out if and why this is true. The first four benchmarks, presented in Section 5.2, are examples where we found low overall overheads. However, somewhat to our surprise we found three benchmarks which had extremely high overheads, and for those benchmarks we have made a detailed examination of the source of the overheads, as presented in Section 5.3. Finally, we investigated one benchmark for which the aspect is intended to improve performance. We discuss it in Section 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Data</head><p>Table <ref type="table" target="#tab_3">2</ref> gives an overview of the key data for all eight benchmarks. Each heading of related rows contains references to those sections of the paper that discuss the relevant metrics in detail.</p><p>At the top of the table we give the metrics that measure program size. Note that six of the benchmarks are quite large, and are composed of between 24 and 252 application classes (classes that are not part of the standard Java library). Two benchmarks, Bean and Figure are smaller, but have been selected to illustrate some standard uses of AspectJ. Also, note that as with all Java programs, the size of the programs, when the Java libraries are included, are very large, even for the small applications.</p><p>The region of the table labelled "EXECUTION TIME MEA-SUREMENTS" gives measurements for execution time, including both real execution times and metrics. For real execution times we consider three different configurations of the Java VM (Java HotSpot™ Client VM (build 1.4.0-b92, mixed mode)). In the first configuration we use the default mode which enables the client VM. For this configuration we also provide the amount of time spent in the JIT compiler, and total GC time. Since the ajc compiler's code generation strategy assumes a VM with a JIT that inlines, we also provide the performance for the client VM when inlining is disabled. Finally, in order to see performance of the bytecode directly, without the effect of JIT compilation, we provide the time for the interpreter configuration.</p><p>Another important aspect of performance is space usage. In the section of the chart labelled "EXECUTION SPACE MEASURE-MENTS", a key metric is the Object Allocation Density which measures the number of objects allocated per 1000 bytecode instructions executed (kilobytecode or kbc). If the allocation density is high, then it is important to examine the "ASPECTJ TAG MIX FOR ALLOCATIONS" section at the bottom of the table to determine if significant space is used for AspectJ overhead.</p><p>In the section labelled "ASPECTJ METRICS SUMMARIZING OVERHEAD" we provide those measurements that summarize overheads. Benchmarks with high AspectJ Overhead are those most likely to have performance problems.</p><p>The sections for "ASPECTJ TAG MIX" provide a more detailed breakdown of the overheads, first considering all instructions, and then the tag mix for allocations only.</p><p>Finally, in the section labelled "ASPECTJ METRICS FOR SHAD-OWS", we give two metrics. The first one refers to the hot shadow metric as defined in Section 3.3.5. The second one, called "Shadow Guards Runtime Const.", is computed using the advice execution metrics defined in Section 3.3.4, and is simply the percentage of all shadow guards that always evaluate to true or always evaluate to false (i.e., those guards that are runtime constants and perhaps could be optimized away using a compiler analysis).</p><p>A detailed individual analysis of all benchmarks is given in the next three subsections. For each benchmark we give the source of the benchmark, a brief description of the aspects involved, and a discussion of our performance measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmarks with low runtime overhead</head><p>In this section we present four benchmarks which seem to confirm the general opinion that AspectJ programs have low overhead when compared to equivalent hand-woven Java programs.</p><p>As shown in the bold entries in The overall conclusion is that total overhead is not a problem when: (1) each advice body represents a large amount of work, so the overhead per advice application is low; (2) the application spends most of its time in the Java library, which usually does not have advice applied to it; (3) the application spends very little time in the part of the code which has advice applied to it (so even if the overhead per advice instruction is high, the overall overhead is low); or (4) there is some noticeable overhead in the code produced by ajc, but a good inlining JIT compiler removes the overhead. In the following sections we expand upon these conclusions and examine each of the low-overhead benchmarks in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">DCM</head><p>One important use of AspectJ is to provide a convenient way of instrumenting a base Java program. In this case the base program doesn't change, but aspects are used to inject instrumentation code to measure some sort of dynamic behaviour. Hassoun, Johnson and Counsell have suggested a new dynamic coupling metric (DCM) <ref type="bibr" target="#b12">[12]</ref> and a validation of that metric using AspectJ <ref type="bibr" target="#b13">[13]</ref>. We have implemented a more efficient version of their aspects (using a hash table with one entry per class, instead of one entry per object) which computes their proposed dynamic coupling metric. The aspects use around and after advice. The basic idea is that each constructor call and each method call is instrumented so as to increment a time step counter and to compute a dynamic coupling metric as a function of the value of the metric at the previous time step, the number of currently live objects, and the static coupling metric values. Computing this function is quite expensive as it requires iterating through the entries in a hash table, where there is one entry for each class in the application.</p><p>Since this aspect can be applied to any program, we applied it to a reasonably large Java benchmark, Certrevsim, which is a discrete event simulator used to simulate the performance of various certificate revocation schemes <ref type="bibr" target="#b1">[1]</ref>. This seemed to be a suitable benchmark because it has non-trivial uses of objects and it computes something useful.</p><p>The performance measurements for the DCM aspects applied to the Certrevsim program are given in the column labelled "DCM" in Table <ref type="table" target="#tab_3">2</ref>. As shown by the bold entry, the AspectJ Overhead is only 4.92%. Furthermore, as expected, the ASPECTJ TAG MIX metrics shows that over 93% of the instructions executed are in the aspect code. This is completely reasonable, since the advice bodies are very expensive, and they involve calls to relatively expensive hash table routines in the Java library.</p><p>A more detailed analysis does show that the overhead when looking at just the application code (Aspect Overhead (app)) is higher, at 16.98%. Furthermore, in the TAG MIX metrics for allocations, 19% of all allocations are due to AROUND CONVERSION. These overheads do not matter for this particular benchmark, but for a benchmark with smaller advice bodies, it could be a problem, and may be worth further investigation and possible improvements to the compiler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">ProdLine</head><p>Intertype declarations in AspectJ allow one to define new fields, constructors and methods for existing Java classes. Lopez-Herrejon and Batory use this idea to experiment with using AspectJ to implement product lines, where a product line is a family of related software applications <ref type="bibr" target="#b22">[22]</ref>. Their application experiments with a product line for related graph algorithms. This application is in-teresting because it heavily uses intertype declarations. The base program is effectively just a collection of empty classes (for example Edge, Vertex and Graph) and various aspects that use intertype declarations to insert fields, constructors and methods into those classes (for example, Directed, Undirected, DFS), plus some uses of advice to splice in some method calls. The underlying implementations of the graph data structures and algorithms make heavy use of the LinkedList implementation in the standard Java library. We used the original benchmark as provided by the authors, but added our own module to generate random graphs, and run larger tests suitable for timing.</p><p>The performance numbers are given in the column labelled "Prod-Line" in Table <ref type="table" target="#tab_3">2</ref>. The overall AspectJ overhead is very low at 0.73% and almost all of the overhead comes from the intertype tags. However, note that the AspectJ overhead for the application only is much higher at 11.25%. This indicates the benchmark spends a majority of its time in the Java library. Also, a potentially important overhead is found in the ASPECTJ TAG MIX for allocations. It appears that the heavy use of intertype constructors in this benchmark leads to considerable space overhead, with about 40% of the total space used due to objects allocated in the pre and post processing of constructors that have been introduced using intertype declarations. This may be another area where a better compilation strategy can avoid some of that overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Tetris</head><p>Graphical, interactive applications pose difficulties for analysis in that they both require human intervention and may have large variations in execution time thereby. However, they certainly form a large class of applications, and the performance and overhead of aspects in such a context is quite relevant in terms of program response times, or the cost of background computations.</p><p>We have analyzed an AspectJ version of the arcade game Tetris, available on the web <ref type="bibr" target="#b9">[9]</ref>. In order to get reproducible results, we have modified the program to use a seeded random number generator, and to (non-interactively) replay a previously-recorded interactive session. The code to accomplish this naturally changes the program; however, the core program logic is unaltered, and the use of aspects remains the same as the original program.</p><p>Aspects in this situation were used to augment the base game with new functionality. A number of aspects were applied, though most of them apply to situations that did not happen or which happened only a few times during our sample game play. The remaining aspects (NEW BLOCKS and NEXT BLOCK in <ref type="bibr" target="#b9">[9]</ref>) are applied to code that is exercised every few game moves, roughly in (a reduced) proportion to the number of game events, or sequences of active code execution.</p><p>Overall aspect overhead in Tetris is low, accounting for less than 1% of executed bytecodes (see the "Tetris" column in Table <ref type="table" target="#tab_3">2</ref>). This is further demonstrated by the limited use of aspects with respect to the overall program-advice constitutes only 2% of the program.</p><p>In fact, the WHOLE PROGRAM metrics are dominated by costs external to the application (startup, GUI library code). This can be seen in the relative size (Instructions Loaded) of the application versus the whole program, but is also apparent in the APPLICATION ONLY version of the aspect metrics. Overhead rises to 7.84%, and is now greater than the cost of the aspect code itself (overhead to advice ratio is 1.09).</p><p>Program design in this case limits any apparent overhead. Variations in Java library/startup design may change the relative weight of application code, and thus the visibility of this overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Bean</head><p>This is example is taken from the AspectJ primer on the website aspectj.org. <ref type="foot" target="#foot_2">3</ref> Once again, we modified it slightly to increase the running time. It starts with a class named Point for representing pairs of x and y coordinates, and it adds the functionality of Java beans with bound properties to this class.</p><p>In order to do so, it injects a new private field into the Point class; this new field has type PropertyChangeSupport; all the associated methods are added as well, and the Point class is declared to be an implementation of Serializable. All these additions are accomplished via the static features of AspectJ. Furthermore, it also fires a property changer whenever either the x or y coordinate is changed. This additional functionality is achieved with a pointcut and around advice, for each of x and y separately.</p><p>For comparison, we wove the AspectJ version by hand to obtain a pure Java program. Both the AspectJ and the pure Java program were compiled with the JIT inliner turned on and off. The results for these versions are shown in the "Bean" column of Table <ref type="table" target="#tab_3">2</ref>.</p><p>From the tag mix, it is apparent that this benchmark spends most of its time in aspect code, which consists of library calls introduced via intertype declarations, but there is also some around advice.</p><p>The overhead in terms of bytecodes executed is quite significant (14.24%). This is reflected in the execution time when run through the interpreter. However, it appears that the JIT compiler is able to eliminate most of the overhead. Without inlining turned on, there is still a discernible price in execution time of about 7%. With inlining, the JIT compiler completely eliminates the cost of the overhead instructions inserted by the AspectJ compiler.</p><p>In the context of this small benchmark, these numbers appear to justify an assumption of the AspectJ implementors, stated in <ref type="bibr" target="#b14">[14]</ref>, that the inliner eliminates most overhead of intertype declarations, and also of advice declarations where there is no dynamic residue of pointcut matching. It is however notoriously difficult to predict the effect of inlining strategies, so further benchmarking is necessary to justify the assumption in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Benchmarks with high overheads</head><p>Contrary to the belief that there are no significant overheads for AspectJ we did find extremely large overheads in three benchmarks. In this section we present these benchmarks, examine where the overheads come from and suggest some solutions for both the programmer (what to avoid using in AspectJ) and for compiler writers (what can be improved and some ideas on how to make those improvements).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">NullCheck</head><p>Users of AspectJ have found many different kinds of applications for aspects. One potential use, as outlined in a short online article by Asberry, is to use aspects to enforce coding standards <ref type="bibr" target="#b2">[2]</ref>. He suggests several applications, one of them being an aspect to detect when methods return null. According to Asberry, the justification for this aspect is that sometimes programmers use the "on error condition, return null from method" anti-pattern. This is considered to be bad coding style, since throwing a meaningful exception would be much preferable. He suggests the following pointcut and around advice to detect all occurrences of returning null from a method. Since this is another case of an aspect that can be applied to any Java program, we applied it to the same Java benchmark, Certrevsim, that we used for the DCM example in Section 5.2.1. Our first experiment was to analyze the dynamic behaviour of the original Certrevsim benchmark and compare it with the same benchmark, but with the suggested null check aspect applied to it. Results given in Table <ref type="table" target="#tab_8">3</ref> in the column labelled "Orig. AspectJ". The results were very surprising, as the original Java benchmark runs in 1.49 seconds, but the AspectJ benchmark runs in 33.13 seconds, a 19-fold slowdown. This was completely unexpected, because according to the description of the aspect, the only new useful code being inserted is a check of the return value of all non-void methods. <ref type="foot" target="#foot_3">4</ref> To verify that such checks should not account for such a slowdown we hand-wove the checks into the original program, and the dynamic measurements for this version are given in the last column of Table <ref type="table" target="#tab_8">3</ref>, labelled "Hand-woven Java". The runtime for this handwoven version is 1.78 seconds, which is only 19% slower than the benchmark without the checks. Thus, there is a huge gap between the performance of the AspectJ program (1856% slower) and the hand-woven program (19% slower). The hand-woven version does of course not admit the collection of the AspectJ metrics, and therefore that part of the table has been omitted in the relevant column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>// First</head><p>Our metrics indicate the source of the problem. First, there is a lot of around overhead -this is to be expected. However, AROUND CONVERSION should be significant only when non-object types have to be boxed (and unboxed) upon invocation of the around advice body. Here we did not expect that to happen, as we only wish to process method results that are objects in the first place. However, the around advice was being applied to all method calls returning values (including methods returning scalar types such as integers) instead of just those that returned values with some Object type (i.e., any type that is Object or a subclass of Object). <ref type="foot" target="#foot_4">5</ref> Of course, looking back to the pointcut methodsThatReturnObjects, we can see that it does apply to all methods with non-void return type. Thus, we fixed the pointcut designator to be the following. This fixed pointcut matches only those method calls which return Object types, as intended, and the dynamic measurements of applying this fixed pointcut to the simulator benchmark are given in Table <ref type="table" target="#tab_8">3</ref>, in the column labelled "Fixed AspectJ". Note that the runtime is still much larger than expected, 10.69 seconds, or about 6 times slower than the handwoven Java program.</p><p>The WHOLE PROGRAM dynamic metrics give us some insight into this large performance difference. The fixed AspectJ version executes 1938 million instructions, whereas the hand-woven Java Orig.  When we look at the APPLICATION ONLY dynamic metrics we see that the hand-woven Java benchmark loaded only 22 application classes (2421 instructions), whereas the fixed AspectJ version loaded 138 classes (8510 instructions), another source of overhead for the class loader and JIT compiler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fixed</head><p>By looking at the ASPECTJ TAG MIX metrics we can see there is a large amount of overhead, mostly attributed to the tags AD-VICE ARG SETUP, AROUND CALLBACK, AROUND PROCEED and CLOSURE INIT. Furthermore, by concentrating on the ASPECTJ TAG MIX FOR ALLOCATIONS ONLY metrics, it is clear that the around advice tags ADVICE ARG SETUP and AROUND PROCEED account for almost 100% of the allocations in the program. Given that all overhead was coming from around advice, we decompiled the class files and studied the code generated by the AspectJ compiler to implement the around advice. We found that, in this case, closures are created to handle the around advice. By studying the code produced we estimated that each method call with around advice has an overhead of 2 invokespecial calls, 5 invokestatic calls, 2 invokevirtual calls, 2 array allocations, 3 object allocations, 3 field read/write instructions, 4 cast/instanceof instructions, plus numerous simple load and store instructions. Clearly this use of closures is a very heavy-weight solution, using many expensive bytecode instructions and considerable memory allocation, and it certainly accounts for the increase in runtime.</p><p>In order to understand why closures were being used to implement the around advice for such a simple case, we studied the AspectJ compiler and found that there are two strategies for implementing around advice, one uses closures and the other uses an inlining strategy. By default the compiler will try to inline; however there are two situations in which closures will be used: (1) the compiler flag -XnoInline has been set; or <ref type="bibr" target="#b2">(2)</ref> the around body has around advice which applies to it. For our benchmark, the body of the around advice contains several method calls returning Object types (namely the string operations in the argument of println), so situation (2) applies and thus the AspectJ compiler selects the closure strategy for all method calls which have this kind of around advice applied.</p><p>To study the performance of the inlining strategy, we changed the pointcut designator to eliminate those method calls that were in our aspect code as follows. The dynamic measurements of this version are given in Table <ref type="table" target="#tab_8">3</ref> in the column labelled "Pruned AspectJ". Clearly the inlining strategy for around advice is much more efficient than the closure strategy. However, it is somewhat alarming that such a minor change to the pointcut specification has such a large impact on the performance of the program. From the programmer's point of view, the !within clause should not be necessary, but clearly it does have a very important impact on the ultimate performance. Furthermore, there is still a significant amount of overhead when we compare the hand-woven Java version (column labelled "Hand-woven Java") to the equivalent AspectJ version (column labelled "Pruned AspectJ").</p><p>In terms of runtime performance, the hand-woven Java version executes in 1.78 seconds whereas the Pruned AspectJ version executes in 1.89 seconds, which is 6% slower. This overhead is also reflected in the number of instructions executed, 963 million for the Java version versus 1313 million for the AspectJ version. According to the ASPECTJ TAG MIX metrics, most of the overhead is due to ADVICE ARG SETUP (16.13%) and AROUND PROCEED (6.64%).</p><p>Furthermore, the Pruned AspectJ program loads more application classes (48 vs. 22), because the AspectJ version must load many classes from the AspectJ runtime library, and the aspect class itself. The AspectJ version has more instructions (7660 vs. 2421), which is due to code from the AspectJ runtime library, the inlining of multiple copies of advice, and the fact that the inlining strategy introduces many overhead instructions, as demonstrated by the ASPECTJ TAG MIX metrics.</p><p>Finally, the Pruned AspectJ version has significantly more dead code (4872 vs 1042). The dead code comes from three sources: (1) methods in the AspectJ runtime library that are loaded, but never run, (2) the code in the never-taken branch of the advice which is inlined in many places, and (3) the presence of methods generated by the AspectJ compiler which are never needed (for example, a method to deal with advice as closures is generated even if closures are not used). We believe AspectJ generates these dead methods for reasons of incremental compilation.</p><p>After studying the null check aspect further, one can notice that the pruned version can be further improved by using after returning advice instead of around advice, as follows. The measurements for this final version are given in the column labelled "Best AspectJ". As indicated by the ASPECTJ TAG MIX metrics, the overhead due to around in the Pruned version (0.95% for AROUND CONVERSION and 6.64% for AROUND PROCEED) is replaced by a smaller overhead due to after after returning (2.29% for AFTER RETURNING EXPOSURE).</p><p>There are some important observations to be made with this benchmark. First, even though the pointcut in this example was very simple, it shows that it is very easy for a programmer to define a pointcut that applies to more places than absolutely necessary. Further, the decision of the AspectJ compiler to use closures or inlining for around advice can have a huge impact on runtime, due to the general, but heavy-weight, strategy used for closures. Programmers may unwittingly trigger the use of closures if they forget, or don't realize, the importance of avoiding pointcuts that apply in the aspect body. The inlining strategy for around advice is much more efficient than the closure-based strategy, but it can still lead to significant overheads, particularly if applied to method calls that execute frequently. Thus, we feel that this example shows that it would be worthwhile to further improve the approach to generating code for around advice. Finally, programmers should be aware of situations where after advice could be used instead of around advice, since the overheads for after advice are lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Figure</head><p>The Figure benchmark illustrates the use of aspect-oriented programming in a figure editor <ref type="bibr" target="#b15">[15]</ref>. Here we have selected just one aspect from that example, namely to update the display whenever one of the figure elements has been altered.</p><p>There is an interface called FigureElement, and all shapes that the editor support implement that interface, for example the Point and Line classes. To capture any alterations to figure elements, we define a named pointcut: The first use of call captures the moveBy operations on any of the implementations of FigureElement; the other disjuncts deal with alterations to individual classes. Now when do we want to update the display? Clearly whenever a move has occurred, but not when the move is part of a more complex operation that is itself a move. Furthermore we only want to update the display when the relevant move has been successfully completed, not when it throws an exception. These considerations lead <ref type="bibr" target="#b15">[15]</ref> to declare the following pointcut and advice: after() returning: move() &amp;&amp; !cflowbelow(move()) { Display.needsRepaint(); }</p><p>The primitive cflowbelow checks that there is a move somewhere strictly below the top of the call stack. One might argue that it is not necessary to use this primitive: it would be possible to explicitly write out all the composite operations. In that case, however, the pointcut depends on intimate implementation detail, and is not robust to changes in that detail.</p><p>In the present paper, the purpose of the Figure benchmark is to examine the cost of using cflowbelow. We have thus disabled the other aspects introduced in <ref type="bibr" target="#b15">[15]</ref>, using only the core figure editor and the above advice. The core program is only a skeleton, and it does no interesting computation on its own. It is therefore to be expected that there is a very high overhead as a proportion of the total computation time. This expectation is confirmed by the first column of Table <ref type="table" target="#tab_12">4</ref>: the slowdown is about a factor of 32 compared to an equivalent, hand-coded version (where all the necessary calls to needsRepaint are inserted by hand into the core).</p><p>To understand this huge performance penalty, it is worthwhile to examine the numbers in more detail. It appears that there is a great deal of allocation, as indicated by the EXECUTION SPACE MEASUREMENTS. Furthermore the tag mix reveals that the relevant overheads lie in the administration of CFLOW ENTRY and CFLOW EXIT, as well as ADVICE TEST. The dynamic tests for cflowbelow are thus at the root of the problem. However, from the last row in our table we can conclude that all the dynamic tests are in fact runtime constants -so there is likely to be a significant saving possible.</p><p>As described in <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b14">14]</ref>, the AspectJ compiler generates code to maintain a stack to keep track of each cflow(P) pointcut. When a join point that matches P is encountered, a new entry is pushed onto the stack; and when such a join point terminates, the stack is popped. We examined the generated code using the Dava decompiler to gain further insight.</p><p>In this example, the entries of the stack are zero length arrays of Object. In general these arrays are used to store variable bindings. A pointcut can bind variables through a number of primitives such as args(x), which assigns the value of a join point parameter to x. If the pointcut P in cflow(P) binds variables, we need to keep track of them in the stack. In this benchmark program, the arrays have zero length because there are no arguments to bind.</p><p>Such a stack of zero length arrays could be more efficiently implemented using a counter; and the only check we need to make is that the argument of cflow does not have variable binders in it. This optimization was implemented by modifying the AspectJ compiler, and the results are displayed in the second column of Table <ref type="table" target="#tab_12">4</ref>. The results are a lot better, but there are still significant overheads. The slowdown compared to the hand-woven version is a factor of 15.44.</p><p>The overheads of this counter-based implementation are due to the fact that it is necessary to maintain a counter for each cflow in each thread. To this end the implementation keeps a mapping from threads to counters: upon each push, pop or is-empty operation, one first needs to retrieve the relevant counter for the current thread.</p><p>To improve upon this bookkeeping, note that the thread can be assumed to be the same throughout a method body. It is therefore possible to retrieve the relevant counter once when the first cflow operation is done, store it in a final local variable, and then use the same counter throughout the method. To measure the impact of this optimization, we decompiled the output of our modified compiler, and applied the transformation by hand. The results are displayed in the third column of Table <ref type="table" target="#tab_12">4</ref>: the slowdown has now been brought down to a factor of 3.78.</p><p>Of course for this very simple benchmark, we know that there is only a single thread, and thus the thread-counter mapping is wholly unnecessary. The result of eliminating it from our code (again by editing the decompiled source) is shown in the penultimate column of Table <ref type="table" target="#tab_12">4</ref>. It further reduces the slowdown to a factor of 1.31. It would not be too difficult to implement this optimization, with a conservative whole-program analysis to determine whether the application is single-threaded.</p><p>In <ref type="bibr" target="#b30">[30]</ref>, it is argued that by building an accurate call graph that accounts for advice as well as ordinary method calls, one may often completely eliminate the dynamic tests for cflow. That paper makes a lot of simplifying assumptions, however, and in fact the language under consideration is a simple aspect-oriented variant of Pascal. We expect, however, that the same techniques can be applied in the more general setting of Java, and we are working towards an implementation using the Soot analysis framework <ref type="bibr" target="#b29">[29]</ref>, which would truly be on a par with the hand-woven version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">LoD</head><p>A very interesting application of AspectJ for checking the Law of Demeter was proposed by Lieberherr, Lorenz and Wu <ref type="bibr" target="#b20">[20]</ref> and the code to accompany the paper is also available <ref type="bibr" target="#b21">[21]</ref>. In the paper they suggest two checkers, one for object form and another for class form. We have used the object form checker as our benchmark. The basic idea is that a program has correct Law of Demeter object form when an object can only send messages to: itself, its arguments, its instance variables, a locally-constructed object or a returned object from a message sent to itself. To achieve this check Lieberherr et al. have written a concise, but advanced collection of aspects which includes relatively complex pointcuts, and the use of percflow, pertarget and cflow.</p><p>The basic idea behind the checking code is that each calling context is associated with a hash table (through the use of percflow) and all valid (preferred) objects for that context are inserted into the hash table for that context. Then, at each method call, the checker verifies that the method call uses only preferred objects, otherwise it is a violation of the Law of Demeter object form.</p><p>In order to generate an interesting application of the checker, we applied it to the same simulator base code as used in Sections 5.3.1 and 5.2.1. We slightly modified the Law of Demeter code so that each error would be reported only once (in the original code an error was reported once for each dynamic instance of the error, which led to large, difficult to read, output files). After applying the Law of Demeter checker code (AspectJ code) to the simulator code base (Java code), and executing the resulting woven code, the following three object form violations were reported. At first glance one might expect that the AspectJ overhead for this benchmark should be small in relation to the amount of work done in each advice body (which includes inserting and testing for membership in hash tables). However, as shown in Table <ref type="table" target="#tab_14">5</ref> this was not the case. As demonstrated by the column labelled "Orig.", the original benchmark code has about 96% overhead, which is entirely unexpected. By examining the ASPECTJ TAG MIX metrics it is immediately obvious that cflow is the problem, with 96% of the instructions and over 99% of the object allocations coming from CFLOW ENTRY and CFLOW EXIT. The effect of all these allocations has a huge impact on execution time, with garbage collection taking 72.42 seconds, out of a total of 96.91 seconds.</p><p>In order to examine this problem in more depth, we created a second version of the benchmark using our modified ajc which implements cflow with counters instead of stacks ("Counters" column in Table <ref type="table" target="#tab_14">5</ref>). As we saw in the Figure benchmark, the counters do improve performance substantially, reducing total running time Orig.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Counters</head><p>Opt We examined the benchmark and found that cflow is used in two places, first in the definition of a pointcut, and second in a percflow clause. The pointcut definition is as follows. Note that the definition of the scope() pointcut contains a cflow and then scope() is used within the definition of many other pointcuts. By examining the decompiled output of ajc we determined that at least 13 cflow stacks are created for the same cflow, presumably due to the inlining of the scope() pointcut inside the other pointcuts. Since all 13 stacks are updated on method entry and exit of some key methods, this leads to enormous overheads. Since the states of all of these stacks are the same, there is clearly room for improvement in the ajc code generation strategy, and further work will be needed to avoid the creation of unneeded duplicate stacks.</p><p>To show that most of the overhead is due to this use of cflow and not the percflow, we created a version of the benchmark that eliminated the cflow clause in the definition of the scope() pointcut. This is safe for our benchmark because we know for our case it is not needed. The performance measurements for this version are given in the column labelled "No cflow", and it is clear that we have removed the majority of the cflow overheads.</p><p>Clearly programmers like to include cflow pointcuts for ease of specification and for safety, so it seems important to work on efficient implementations for them. By eliminating the multiple copies of stacks, and applying the efficient counter schemes presented in the previous section, it should be possible to greatly reduce the overheads due to cflow.</p><p>Even after dealing with the cflow overheads, there still remains  First, there are some significant overheads for ADVICE ARG SET- UP (5.47%) and ADVICE TEST (2.24%). These overheads are larger than normal because the pertarget advice leads to extra code to be generated that checks if the aspect instance corresponding to the target already exists, and to allocate a new aspect instance if one does not exist. Also, the space requirements for percflow and pertarget are significant. The BASE CODE only accounts for 2.64% of the total allocations, whereas the percflow accounts for 44.69% (shown in the bin for CFLOW ENTRY), and the pertarget accounts for 25.71% (shown in the bin for ADVICE ARG SETUP, since this is where new aspect instances are created in the case of pertarget aspects). We expect that at least some of these space overheads could be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Benchmark for performance improvement</head><p>The final benchmark in our set is somewhat different from the others in that the aspects used for this benchmark were intended to improve upon the performance of an existing Java program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">*J Pool</head><p>This benchmark is drawn from our own tool set, namely the *J tool itself. The *J analyzer reads events one-by-one from a trace file (as described in Section 4.3). Each time it reads a new event, a new object is allocated to hold this event; since there are potentially millions of events in a trace file this places significant stress on the memory manager. However, it is a property of the implementation that for any given trace file, no more than the last two events will ever be in use at any one time, which makes manual memory management of these objects possible (by reusing previously allocated ones that are guaranteed to no longer be in use, rather than allocating new ones).</p><p>This optimization is implemented by maintaining two pools of events, each pool containing one object of each of the various possible event type. At any one moment, one pool is "active" and the other is "inactive"; each time a new event would have been allocated, the appropriate type of event from the active pool is reused instead, and the active and inactive pools are swapped over. This guarantees that the last two events are always allocated from different pools, which ensures that events in use can never collide with each other.</p><p>We wrote this optimization as a piece of around advice; in the original program a single method (newEvent) is used to allocate new event objects, so this advice simply replaces calls to newEvent with code to reuse an object from the appropriate pool as described above. Of course, this could be implemented relatively simply by just replacing the body of newEvent, but this would make it harder to disable the optimization easily if required. Multiple trace files can be read simultaneously by creating multiple objects of the appropriate class; therefore the advice is implemented in a pertarget aspect, to ensure that different pools are used for each trace file (the current implementation actually reads just one file at a time, so the aspect could be implemented without using pertarget, but this would be rather more fragile).</p><p>The results of this optimization are detailed in Table <ref type="table" target="#tab_16">6</ref>. The first column, "Aspect" shows it implemented as a pertarget aspect as described above; the second column ("Hand-woven") is for a manual implementation. Finally the third column ("No pooling") shows the unoptimized version for comparison. In each case, the *J analyzer was run on a trace generated from a short run of a program to calculate the Fast Fourier Transform. <ref type="foot" target="#foot_5">6</ref>We have provided comparisons of running time with the unoptimized version; these show that introducing the aspect provides a speedup of about 23%. In fact, there is some overhead from weaving, since the version that applies pooling directly shows a speedup of about 52%. The amount of memory allocated drops by nearly a factor of 2, and the number of garbage collections and the total time spent garbage collection go down significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>Most work on dynamic metrics has focused on either addressing a specific optimization problem such as memory use (e.g., <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b31">31]</ref>), or more generally (and voluminously) on software engineering quality or complexity measures (e.g., <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b36">36]</ref>). More re-   <ref type="bibr">[8]</ref>, along with a description of our overall approach.</p><p>The performance of AspectJ programs has also been discussed and investigated in the literature, and typically it is assumed or demonstrated to some degree that aspects do not impose unreasonable overhead. Kiczales et al.'s overview paper of AspectJ <ref type="bibr" target="#b16">[16]</ref> for instance makes the pronouncement that (with respect to before/after advice) "...there should generally be no observable performance overhead from these additional method calls." Method calls inserted into code to support advice testing are assumed to be simple and strict enough that the Just-In-Time compiler in most Java Virtual Machine implementations will be able to inline the method call, and thus reduce any overhead to insignificance. The AspectJ FAQ reinforces that perception, claiming that most constructions have little overhead, which "could be optimized away by modern VM's." <ref type="bibr" target="#b35">[35]</ref> (section 7.3).</p><p>There are a few studies that actually measured the performance impact of using aspects. Pace and Campo, for instance, analyzed regular and aspect-oriented versions of a temperature control benchmark <ref type="bibr" target="#b6">[6]</ref>. Although they found one style of implementation to be over 3 times slower than the original, a different aspect-oriented approach had only about 1% runtime overhead. They attribute the former to the internal use of reflection, and conclude that the impact may depend on the problem under consideration. A more recent and larger study was done by Hilsdale and Hugunin <ref type="bibr" target="#b14">[14]</ref>, examining both runtime and compile-time performance issues. A naive implementation is shown to have quite poor performance (for a logging implementation they get a 2900% overhead versus a handcoded implementation), but they improve that to an "unlikely to be noticeable" 22% runtime overhead for an optimized version. Again they attribute the former very poor performance largely to the use of reflection.</p><p>In the context of middleware, Zhang and Jacobsen <ref type="bibr" target="#b37">[37]</ref> demonstrate that an aspect version of a CORBA/ORB benchmark has negligible runtime overhead. They argue that an AspectJ implementation should have no overhead since it is just specifying the same code in different ways (in the aspect versus in the program). In their case, however, an aspect-oriented approach significantly simplified the program design (overall code reduction of 9%, fewer methods per class on average, etc), so they are actually comparing an optimized design to an unoptimized design. The fact that the optimized design only achieves the same speed as the unoptimized is an argument that a significant overhead may well be present.</p><p>In their analysis, Zhang and Jacobsen also give data for a number of software engineering complexity metrics, and use that data to show that the aspect-oriented approach is quantitatively simpler. Complexity is also considered by Zhao, who proposes a specific complexity metric suite for aspect oriented programming <ref type="bibr" target="#b38">[38]</ref>. We are focusing on performance and execution time costs, rather then complexity.</p><p>Clearly particularities of the implementation of aspects have a large impact on the overhead. Sereni and de Moor describe a better implementation of pointcut designators as well as a compiler flow analysis that can reduce the overhead by eliminating many instances of runtime matching <ref type="bibr" target="#b30">[30]</ref>. That paper is mostly a theoretical study, dealing with a small toy language, and wholly without performance experiments. The results presented here suggest that such optimization techniques may be quite important in practice.</p><p>Performance analyses have also been done on dynamic weaving approaches where an aspect is applied to a running program. Dynamic weaving generally aims to enhance capabilities, allowing for instant "hot fixes" to be applied to running code <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28]</ref>. <ref type="bibr">Popovici et al.</ref> show an aspect-aware Java Virtual Machine that imposes relatively little overhead when aspects are inactive (1.5%-8% slowdown over a regular JVM), though that increases dramatically for active join points (1.3×-5× slower than a statically-woven version).</p><p>Finally, more generic profiling methods have been applied to As-pectJ programs. Hall's CPPROFJ <ref type="bibr" target="#b11">[11]</ref> for instance, does call-path profiling of both pure Java and (limited) AspectJ programs, allowing the runtime cost of various method execution sequences to be determined. CPPROFJ is sampling-based and is naturally much more coarse-grained than our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>We have presented a tool set and a systematic method for analyzing the dynamic behaviour of AspectJ programs. The main technical contributions are the definition of new metrics, as well as a novel method of computing these metrics. In particular the idea of compile-time tags that are dynamically propagated allows us to accurately attribute costs to specific language features. As discussed in Section 4, the overall system for collecting our data is complex-modifications to *J and ajc were non-trivial, and this system constitutes a contribution by itself. One of the more interesting and difficult components of the system is the propagation strategy, which has to be carefully designed in order to attribute data correctly. The general paradigm could be transferred to similar situations, for example when compiling ML to Java bytecode <ref type="bibr" target="#b4">[4]</ref>. The same ideas could be integrated in a compiler that weaves the instrumentation with the generated code, instead of using a tool like JVMPI, which was the route taken in this paper.</p><p>Our benchmark set provides the first collection of programs suit-able for discussing performance of AspectJ. The benchmarks we have chosen provide a good cross section of different uses of the language. We are continuing to extend the collection, in particular using some of the examples from <ref type="bibr" target="#b19">[19]</ref>. One small difficulty consists of programs that make use of reflection: at present our propagation tools are unable to cope with reflective calls, and wrongly attribute the cost of such calls to the base program, never to the aspect. This does not invalidate our measurements of overheads, only the numbers for BASE CODE and ASPECT CODE.</p><p>The conventional wisdom that AspectJ does not introduce overheads seems to be explained by typical aspect usage. First, advice generally applies to user code, yet typical Java programs spend most of their time in library calls. As a percentage of the total execution time, the cost of advice is therefore insignificant in such applications. The Tetris benchmark illustrates this phenomenon. Some of our benchmarks (in particular DCM) show the opposite behaviour, where the advice is so expensive that the overheads of applying it are dwarfed. Finally, intertype declarations have very little overheads, except when it concerns the introduction of new constructors. This is demonstrated by Bean and ProdLine respectively.</p><p>Contrary to popular belief, we did however also find significant overheads. This has led to the following guidelines for AspectJ usage, as well as promising areas for future compiler research:</p><p>Loose pointcuts. It is easy to write a pointcut that matches too many join points. Even when some of the dynamic tests fail, such loose specification can introduce significant overheads. It is particularly important to avoid around advice that can apply to itself, as this forces the introduction of closures. This was illustrated in the first two versions of the Nullcheck benchmark. Sometimes it is however not possible to tighten pointcuts to avoid this situation, so a more careful consideration of the use of closures is a fruitful topic for future research.</p><p>Advice that is too generic. When using the very generic form of around, this causes a significant amount of boxing and unboxing to convert arguments to the right form.</p><p>Unwarranted use of around. Because of the above, it is generally preferable to eschew around in favour of after returning when possible. The most striking example we found of this phenomenon occurred in the final version of the Nullcheck benchmark. In fact, that improvement was not noticed by a number of seasoned AspectJ users to whom we showed the original code, so this is an instance where our methods give new insights.</p><p>Cflow. It is tempting to write pointcuts using cflow, but often this introduces significant overheads. This was illustrated by three separate benchmarks, namely Nullcheck, Figure and LoD. Where possible, it is better to use withincode in lieu of cflow, but this is arguably less robust with respect to refactoring. Because it is not always possible to eliminate cflow, we investigated various ways of improving its implementation:</p><p>• When there is no argument binding, the current use of stacks in ajc can be replaced by counters. We have in fact implemented this optimization in ajc, and found it to be highly effective. • The use of such counters is still somewhat expensive due to the fact that we have to maintain one for each thread. If the application is known to be single-threaded, significant savings are possible, as there is no need to maintain a mapping between threads and counters.</p><p>• A whole-program analysis based on the call graph can eliminate all runtime overheads of cflow. An initial study in this direction, for a very small toy language, was undertaken in <ref type="bibr" target="#b30">[30]</ref>.</p><p>Pertarget. The use of per clauses to control aspect creation carries a non-negligible overhead, as demonstrated by the *J Pool benchmark. It might be possible to devise a static analysis which detects that only one instance will be created in a particular application.</p><p>For all programmers with an interest in aspect-orientation, it is important to understand the implications of using aspects on the behaviour of their programs. The tools we have presented are an important step towards this goal, but perhaps even more important is the construction of a representative set of benchmarks that is accepted by the whole community. We hope that the benchmarks presented here provide a starting point, and that others will join us in extending and improving it.</p><p>ASPECT CODE: This tag represents the default for any instruction that is executed from an aspect, regardless of where it was originally defined. It is propagated, so that, for example, the body of a method call from advice will receive the ASPECT CODE tag.</p><p>NO TAG: This is a special tag inserted by the compiler which is meant to be overwritten by a propagated tag during analysis. An instruction with this tag is to be interpreted equivalently to an instruction with no tag at all. It is a necessary consequence of the way tags are encoded in a code attribute. Instructions in library classes, which have not been explicitly tagged, are also assumed to have NO TAG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tags to support intertype declarations</head><p>INTERMETHOD: An intertype method declaration results in the body of the new method being compiled into a method on the aspect class, and a dispatch method being added to the target class. The instructions in this dispatch method have this tag.</p><p>INTERFIELDGET, INTERFIELDSET: Some intertype field declarations result in accessor methods being woven into the target class. The instructions in these accessor methods have these tags.</p><p>INTERFIELDINIT: Intertype field declarations result in initialization code being woven into either the target class's constructor, or its static initializer. These instructions invoke initialization methods on the aspect to handle variable initialization. This initialization code has this tag.</p><p>INTERCONSTRUCTOR PRE, INTERCONSTRUCTOR POST: If an aspect has an intertype constructor declaration two methods are created on the aspect: a preInterConstructor method and a postInter-Constructor method. A new constructor method is added to the class, and it invokes both of these methods. The instructions that load these methods' arguments and invoke these methods have these tags.</p><p>INTERCONSTRUCTOR CONVERSION: This represents overhead involved in calling methods on org.aspectj.runtime.internal.Conversions from within a constructor added by an intertype constructor declaration.</p><p>Tags applying to all kinds of advice (before, after and around) ADVICE EXECUTE: This tag represents the overhead associated with executing the method implementing a piece of advice. Advice bodies are compiled as methods in the aspect class. When an aspect with advice is woven into a base class, an invoke instruction for the advice method is added to the relevant join point shadows. ADVICE ARG SETUP: This tag represents the overhead associated with acquiring an aspect instance at a join point at which advice is to be executed, and exposing arguments to the advice body. At least one instruction of this kind will precede an advice execution instruction.</p><p>ADVICE TEST: When it cannot be statically determined whether an advice body should be executed at all join points corresponding to the join point shadow at which the advice invocation instructions have been added, then those invocation instructions are wrapped in a test. The instructions corresponding to this test have this tag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tags applying to around advice only</head><p>AROUND CONVERSION: This represents the conversion of arguments and return values related to a proceed() call within around advice. This conversion is done by making calls to methods on org.aspectj.runtime.internal.Conversions, which convert between primitive types and objects. AROUND CALLBACK, AROUND PROCEED: Both of these tags represent an overhead involved in making a proceed() call from within around advice. One of these tags, AROUND CALLBACK, is specific to the run method on closure classes. CLOSURE INIT: Advice advice may result in the creation of closure classes. When it does,the instructions in the constructors of these classes have this tag.</p><p>Tags applying to after advice only AFTER RETURNING EXPOSURE: This tag represents the overhead involved in exposing the value returned at a join point to the body of a piece of after advice. AFTER THROWING HANDLER: In order to support after and after throwing advice, exception handling code is inserted which catches any exception, executes any pertinent advice, and then rethrows the original exception. The instructions responsible for this have this tag.</p><p>Tags to support the cflow pointcuts and percflow aspects CFLOW ENTRY, CFLOW EXIT: The cflow and cflowbelow pointcuts require that a representation of the call stack be managed during the execution of the program. At every relevant join point shadow, this representation must be updated. Instructions for doing so receive one of these tags. An aspect that is declared with percflow or percflowbelow clause will also lead to instructions with this tag.</p><p>Tags to support perthis and pertarget aspects PEROBJECT ENTRY: By default, aspect instances are singletons. They can however be associated on a per-object basis, either with the execution or target objects at join points selected by a given pointcut. The instructions inserted at join point shadows matched by the pointcut to manage these instances have this tag. PEROBJECT GET, PEROBJECT SET: These accessor methods are added to a class to acquire instances of an aspect that is declared pertarget or perthis.</p><p>Tag for exception softening due to declare soft EXCEPTION SOFTENER: This tag represents the overhead involved in softening exceptions. The declare soft declaration in an aspect results in exceptions of a given type, thrown from within join points selected by a given pointcut, being wrapped in the unchecked org.aspectj.SoftException, which is then thrown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tags to handle privileged aspects</head><p>PRIV METHOD, PRIV FIELD GET, PRIV FIELD SET: In order to support privileged aspects, public wrapper methods for the class's private methods, and public accessor methods for the class's private fields, are inserted during weaving. The instructions in these new methods have these tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Miscellaneous aspect tags</head><p>CLINIT: The instructions in the static initializer of the aspect class have this tag. The static initializer may setup the default singleton instance of the aspect or setup the cflow stack, if necessary. Instructions woven into the static initializer of a base program class, such as for initializing the static join point information, also have this tag. INLINE ACCESS METHOD: This tag represents the overhead involved in calling a method defined on an aspect when there is a static dispatch method. The instructions of the static dispatch method have this tag.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Tagged class file for example AspectJ program</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>pointcut methodsThatReturnObjects(): call(Object+ *.*(..));</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>pointcut methodsThatReturnObjects(): call(Object+ *.*(..)) &amp;&amp; !within(lib.aspects.codingstandards.*);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>pointcut move(): call(void FigureElement.moveBy(int, int)) || call(void Point.setX(int)) || call(void Point.setY(int)) || call(void Line.setP1(Point)) || call(void Line.setP2(Point));</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>public pointcut scope(): !within(lawOfDemeter..*) &amp;&amp; !cflow(withincode(* lawOfDemeter..*(..))) ; public pointcut StaticInitialization(): scope() &amp;&amp; staticinitialization(*); public pointcut MethodCallSite(): scope() &amp;&amp; call(* *(..)); // ... followed by many other uses of scope()</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Standard JVM Figure 2: Overview of Metric Collection Tools</head><label></label><figDesc></figDesc><table><row><cell></cell><cell cols="2">AspectJ source programs</cell></row><row><cell cols="2">Modified AspectJ Compiler</cell><cell></cell></row><row><cell></cell><cell cols="2">Front-end</cell></row><row><cell></cell><cell cols="2">class files with AspectJ attributes</cell></row><row><cell></cell><cell cols="2">Tagging bytecode</cell></row><row><cell></cell><cell cols="2">weaver</cell></row><row><cell>Retagger</cell><cell cols="2">.class files with tags in attributes</cell><cell>TagReader</cell></row><row><cell></cell><cell cols="2">JVMPI Interface</cell><cell>textual representation of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tagged class file</cell></row><row><cell></cell><cell></cell><cell>JVMPI Events</cell></row><row><cell cols="2">*J Dynamic Metric Tool</cell><cell></cell></row><row><cell></cell><cell cols="2">JVMPI Agent</cell></row><row><cell></cell><cell></cell><cell>trace file</cell></row><row><cell></cell><cell cols="2">Metric Analyzer with</cell></row><row><cell></cell><cell cols="2">tag propagator</cell></row><row><cell cols="2">standard dynamic metrics</cell><cell cols="2">AspectJ-specific dynamic metrics</cell></row><row><cell>CFLOW ENTER 13</cell><cell>28: bipush 0</cell><cell></cell></row><row><cell>CFLOW ENTER 13</cell><cell cols="2">30: anewarray Object[]</cell></row><row><cell>CFLOW ENTER 13</cell><cell>33: astore 3</cell><cell></cell></row><row><cell>CFLOW ENTER 13</cell><cell cols="3">34: getstatic CFlowStack ExampleAspect.ajc$cflowStack$0</cell></row><row><cell>CFLOW ENTER 13</cell><cell>37: aload 3</cell><cell></cell></row><row><cell>CFLOW ENTER 13</cell><cell cols="3">38: invokevirtual void CFlowStack.push(Object[])</cell></row><row><cell></cell><cell cols="2">41: invokevirtual void Example.foo()</cell></row><row><cell>CFLOW EXIT 13</cell><cell>44: goto → 24</cell><cell></cell></row><row><cell>CFLOW EXIT 13</cell><cell>47: astore 4</cell><cell></cell></row><row><cell>CFLOW EXIT 13</cell><cell cols="3">49: getstatic CFlowStack ExampleAspect.ajc$cflowStack$0</cell></row><row><cell>CFLOW EXIT 13</cell><cell cols="2">52: invokevirtual void CFlowStack.pop()</cell></row><row><cell>CFLOW EXIT 13</cell><cell>55: aload 4</cell><cell></cell></row><row><cell>CFLOW EXIT 13</cell><cell>57: athrow</cell><cell></cell></row><row><cell>CFLOW EXIT 13</cell><cell>58: nop</cell><cell></cell></row><row><cell>CFLOW EXIT 13</cell><cell cols="3">59: getstatic CFlowStack ExampleAspect.ajc$cflowStack$0</cell></row><row><cell>CFLOW EXIT 13</cell><cell cols="2">62: invokevirtual void CFlowStack.pop()</cell></row><row><cell></cell><cell>65: nop</cell><cell></cell></row><row><cell></cell><cell>66: return</cell><cell></cell></row><row><cell></cell><cell>public void foo()</cell><cell></cell></row><row><cell></cell><cell cols="2">0: getstatic PrintStream System.out</cell></row><row><cell></cell><cell>3: ldc "foo"</cell><cell></cell></row><row><cell></cell><cell cols="2">5: invokevirtual void PrintStream.println(String)</cell></row><row><cell></cell><cell>8: aload 0</cell><cell></cell></row><row><cell>ADVICE TEST 17</cell><cell cols="3">9: getstatic CFlowStack ExampleAspect.ajc$cflowStack$0</cell></row><row><cell>ADVICE TEST 17</cell><cell cols="2">12: invokevirtual boolean CFlowStack.isValid()</cell></row><row><cell>ADVICE TEST 17</cell><cell>15: ifeq → 24</cell><cell></cell></row><row><cell>ADVICE ARG SETUP 17</cell><cell cols="3">18: invokestatic ExampleAspect ExampleAspect.aspectOf()</cell></row><row><cell>ADVICE EXECUTE 17</cell><cell cols="3">21: invokevirtual void ExampleAspect.ajc$before$ExampleAspect$148()</cell></row><row><cell></cell><cell cols="2">24: invokevirtual void Example.bar()</cell></row><row><cell></cell><cell>27: return</cell><cell></cell></row><row><cell></cell><cell>public void bar()</cell><cell></cell></row><row><cell></cell><cell cols="2">0: getstatic PrintStream System.out</cell></row><row><cell></cell><cell>3: ldc "bar"</cell><cell></cell></row><row><cell></cell><cell cols="2">5: invokevirtual void PrintStream.println(String)</cell></row><row><cell></cell><cell>8: return</cell><cell></cell></row></table><note><p>Tag Shadow public Example() 0: aload 0 1: invokespecial Object() 4: return public static void main(String[] args) 0: new Example 3: dup 4: invokespecial Example() 7: astore 1 8: aload 1 ADVICE TEST 12 9: getstatic CFlowStack ExampleAspect.ajc$cflowStack$0 ADVICE TEST 12 12: invokevirtual boolean CFlowStack.isValid() ADVICE TEST 12 15: ifeq → 24 ADVICE ARG SETUP 12 18: invokestatic ExampleAspect ExampleAspect.aspectOf() ADVICE EXECUTE 12 21: invokevirtual void ExampleAspect.ajc$before$ExampleAspect$148() 24: invokevirtual void Example.bar() 27: aload 1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Dynamic Propagation TableThe INTERMETHOD and INLINE ACCESS METHOD tags, like AD-</figDesc><table><row><cell>.</cell><cell></cell></row><row><cell>Current</cell><cell>Propagated</cell></row><row><cell>ADVICE EXECUTE</cell><cell>ASPECT CODE</cell></row><row><cell>INTERMETHOD</cell><cell>ASPECT CODE</cell></row><row><cell cols="2">INLINE ACCESS METHOD ASPECT CODE</cell></row><row><cell>AROUND CALLBACK</cell><cell>BASE CODE or ASPECT CODE</cell></row><row><cell>AROUND PROCEED</cell><cell>BASE CODE or ASPECT CODE</cell></row></table><note><p>VICE EXECUTE, both identify call sites which invoke user-defined aspect code, and thus have the same propagation behaviour. The AROUND CALLBACK and AROUND PROCEED tags identify call sites which implement the proceed() construct, and can propagate either the BASE CODE or the ASPECT CODE tag depending on the calling context at the advised join point. Keeping track of the depth of nested aspect code is thus necessary to determine the context of proceed() calls.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>, the first four benchmarks</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TAG MIX FOR ALLOCATIONS ONLY (WHOLE PROG.) (%) (</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">§3.3.1, appendix)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BASE CODE</cell><cell>0.38</cell><cell>0.57</cell><cell>95.52</cell><cell>3.74</cell><cell>19.25</cell><cell>0.02</cell><cell>0.03</cell><cell>100.00</cell></row><row><cell>ASPECT CODE</cell><cell>26.25</cell><cell>53.54</cell><cell>3.70</cell><cell>92.69</cell><cell></cell><cell></cell><cell>0.27</cell><cell></cell></row><row><cell>AspectJ Overhead (total)</cell><cell>73.38</cell><cell>45.88</cell><cell>0.78</cell><cell>3.56</cell><cell>80.75</cell><cell>99.98</cell><cell>99.70</cell><cell>0.003</cell></row><row><cell>INTERFIELDINIT</cell><cell></cell><cell></cell><cell></cell><cell>3.56</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>INTERCONSTRUCTOR PRE</cell><cell></cell><cell>18.72</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>INTERCONSTRUCTOR POST</cell><cell></cell><cell>21.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>INTERCONSTRUCTOR CONVERSION</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADVICE ARG SETUP</cell><cell>54.39</cell><cell>4.07</cell><cell>0.59</cell><cell></cell><cell>53.85</cell><cell></cell><cell>0.27</cell><cell></cell></row><row><cell>AROUND CONVERSION</cell><cell>18.98</cell><cell></cell><cell>0.09</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>AROUND PROCEED</cell><cell></cell><cell>2.03</cell><cell>0.09</cell><cell></cell><cell>26.90</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CFLOW ENTRY</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>99.98</cell><cell>99.42</cell><cell></cell></row><row><cell>PEROBJECT ENTRY</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.009</cell><cell>0.003</cell></row><row><cell>CLINIT</cell><cell>0.005</cell><cell>0.001</cell><cell>0.02</cell><cell></cell><cell></cell><cell></cell><cell>0.002</cell><cell></cell></row><row><cell cols="5">ASPECTJ METRICS FOR SHADOWS (WHOLE PROGRAM) (%) ( §3.3.5,  §3.3.4)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Hot Shadows (for 90%)</cell><cell>3.12</cell><cell>33.33</cell><cell cols="2">4.17 100.00</cell><cell cols="2">2.94 100.00</cell><cell>27.43</cell><cell>66.67</cell></row><row><cell>Shadow Guards Runtime Const.(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Benchmark Measurementseither show a low amount of total overhead as computed by our metrics (DCM, ProdLine and Tetris), or show little or no slowdown when compared to an equivalent Java program (Bean).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>primitive pointcut matches all calls, // second avoids those with void return type.</figDesc><table><row><cell>pointcut methodsThatReturnObjects(): call(* *.*(..)) &amp;&amp; !call(void *.*(..));</cell></row><row><cell>Object around(): methodsThatReturnObjects()</cell></row><row><cell>{ Object lRetVal = proceed();</cell></row><row><cell>if (lRetVal == null)</cell></row><row><cell>{ System.err.println( "Detected null return value after calling " +</cell></row><row><cell>thisJoinPoint.getSignature().toShortString() + " in file " +</cell></row><row><cell>thisJoinPoint.getSourceLocation().getFileName() + " at line " +</cell></row><row><cell>thisJoinPoint.getSourceLocation().getLine());</cell></row><row><cell>}</cell></row><row><cell>return lRetVal; }</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 : Nullcheck metrics version</head><label>3</label><figDesc>executes only 963 million instructions. However, most surprising is that even the fixed AspectJ benchmark allocates 1529 million bytes, whereas the original Java version only allocated 2 million bytes. This is a huge increase in memory consumption, considering the aspect body itself is very simple, the check against null never succeeds in this benchmark, and thus the aspect body does not explicitly allocate any objects at all.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>METRICS FOR SHADOWS (WHOLE PROGRAM) (%)</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">. Counters Single Thread Hand-woven</cell></row><row><cell cols="2">PROGRAM SIZE (APPLICATION ONLY)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classes Loaded</cell><cell>12</cell><cell>10</cell><cell>10</cell><cell>8</cell><cell>6</cell></row><row><cell>Instructions Loaded</cell><cell>616</cell><cell>645</cell><cell>642</cell><cell>347</cell><cell>189</cell></row><row><cell>Instructions Dead</cell><cell>233</cell><cell>246</cell><cell>270</cell><cell>89</cell><cell>25</cell></row><row><cell>Code Coverage (%)</cell><cell>62</cell><cell>62</cell><cell>58</cell><cell>74</cell><cell>87</cell></row><row><cell cols="2">PROGRAM SIZE WITH JAVA LIBRARIES (WHOLE PROGRAM)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classes Loaded</cell><cell>295</cell><cell>293</cell><cell>293</cell><cell>291</cell><cell>284</cell></row><row><cell>Instructions Loaded</cell><cell>74922</cell><cell>74951</cell><cell>74948</cell><cell>74653</cell><cell>73325</cell></row><row><cell cols="2">EXECUTION TIME MEASUREMENTS (WHOLE PROGRAM)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell># instr. (million bytecodes)</cell><cell>1623</cell><cell>495</cell><cell>299</cell><cell>229</cell><cell>114</cell></row><row><cell>Total time -client (sec)</cell><cell>8.90</cell><cell>4.23</cell><cell>1.03</cell><cell>0.36</cell><cell>0.27</cell></row><row><cell>JIT time -client (sec)</cell><cell>0.05</cell><cell>0.04</cell><cell>0.04</cell><cell>0.03</cell><cell>0.03</cell></row><row><cell>GC time -client (sec)</cell><cell>0.14</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Slowdown vs. handcoded(×)</cell><cell>32.53</cell><cell>15.44</cell><cell>3.78</cell><cell>1.31</cell><cell>1.00</cell></row><row><cell>Time -client noinline (sec)</cell><cell>10.07</cell><cell>4.46</cell><cell>1.18</cell><cell>0.48</cell><cell>0.44</cell></row><row><cell>Slowdown vs. handcoded (×)</cell><cell>23.01</cell><cell>10.20</cell><cell>2.69</cell><cell>1.11</cell><cell>1.00</cell></row><row><cell>Time -interpreter (sec)</cell><cell>44.76</cell><cell>13.38</cell><cell>5.44</cell><cell>3.51</cell><cell>2.12</cell></row><row><cell>Slowdown vs. handcoded (×)</cell><cell>21.11</cell><cell>6.31</cell><cell>2.57</cell><cell>1.66</cell><cell>1.00</cell></row><row><cell cols="2">EXECUTION SPACE MEASUREMENTS (WHOLE PROGRAM)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Mem. Alloc. (million bytes)</cell><cell>374</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Obj. Allocation Density (per kbc)</cell><cell>9.86</cell><cell>0.01</cell><cell>0.02</cell><cell>0.03</cell><cell>0.06</cell></row><row><cell>#Garbage Collections</cell><cell>488</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">ASPECTJ METRICS SUMMARIZING OVERHEAD</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>AspectJ Overhead % (whole)</cell><cell>92.54</cell><cell>75.55</cell><cell></cell><cell></cell><cell></cell></row><row><cell>#overhead/#advice (whole)</cell><cell>125.17</cell><cell>31.17</cell><cell></cell><cell></cell><cell></cell></row><row><cell>#advice/#total (whole)</cell><cell>0.01</cell><cell>0.02</cell><cell></cell><cell></cell><cell></cell></row><row><cell>AspectJ Runtime Lib % (whole)</cell><cell>85.27</cell><cell>40.40</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ASPECTJ TAG MIX FOR ALL INSTRUCTIONS (WHOLE PROG.) (%)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BASE CODE</cell><cell>6.72</cell><cell>22.02</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASPECT CODE</cell><cell>0.74</cell><cell>2.42</cell><cell></cell><cell></cell><cell></cell></row><row><cell>AspectJ Overhead (total)</cell><cell>92.54</cell><cell>75.55</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADVICE EXECUTE</cell><cell>0.25</cell><cell>0.81</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADVICE ARG SETUP</cell><cell>0.62</cell><cell>2.02</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADVICE TEST</cell><cell>10.84</cell><cell>33.94</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CFLOW ENTRY</cell><cell>36.97</cell><cell>25.86</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CFLOW EXIT</cell><cell>43.87</cell><cell>12.93</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PEROBJECT ENTRY</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CLINIT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>INLINE ACCESS METHOD</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ASPECTJ TAG MIX FOR ALLOCATIONS ONLY (WHOLE PROG.) (%)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BASE CODE</cell><cell>0.02</cell><cell>99.78</cell><cell></cell><cell></cell><cell></cell></row><row><cell>AspectJ Overhead (total)</cell><cell>99.98</cell><cell>0.22</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CFLOW ENTRY</cell><cell>99.98</cell><cell>0.09</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CLINIT</cell><cell></cell><cell>0.12</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASPECTJ Shadow Guards Runtime Const.(%)</cell><cell>100.00</cell><cell>100.00</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 4 : Figure Benchmark Measurements to</head><label>4</label><figDesc><ref type="bibr" target="#b9">9</ref>.38 seconds and garbage collection time to 0.34 seconds. However, there remains over 75% overhead due to CFLOW ENTRY and CFLOW EXIT, which is still higher than expected.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 5 : Law of Demeter Benchmark Measurements about</head><label>5</label><figDesc>16% overhead which is due mostly to the percflow and pertarget aspects. The pertarget overhead shows up in two ways.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 6 : *J Pool Benchmark Measurements lated</head><label>6</label><figDesc>work on analyzing programs through metrics is given in</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Flaws in the implementation of the JVMPI interface in more recent versions of Sun's JRE caused the collected data to be incomplete, and precluded their use in this study. Using a more recent release of Sun's JRE (build 1.4.2-b28) does result in significantly faster running times for some benchmarks, but such improvements do not contradict the observations made in this paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>At the time of this writing, version 1.2 of the AspectJ compiler has been recently released. Preliminary experiments show that it does not significantly affect the present discussion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>An earlier version on that webpage was flawed; we are using the revision suggested in an early draft of this paper and also on the aspectj-dev list by Gregor Kiczales on January14, 2004.   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>It turns out that the Certrevsim benchmark is well written and does not return null from methods, so the check against null never succeeds. Thus, the runtime overhead is simply the check against null and a branch.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p><ref type="bibr" target="#b5">5</ref> This could also be observed using the Eclipse plugin for AspectJ.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>In order to reproduce the memory constraints imposed by a larger input, the total heap size is limited to 52 Mbytes for this benchmark.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We will be making a public release of the *J tool so that others can collect our Java-based metrics for their own programs. To benefit from these tools, one also needs a compiler that assigns static tags; for now we are using a modified version of the standard As-pectJ compiler ajc. Inspired by the results of the present paper, we have begun the implementation of an optimizing AspectJ compiler based on Soot <ref type="bibr" target="#b29">[29]</ref>, and this compiler includes that tagging scheme.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work was supported, in part, by NSERC, FQRNT and EP-SRC.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix I: Tags</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Tags</head><p>BASE CODE: This tag represents instructions that are not interpreted as AspectJ overhead or are not part of an advice body. They represent the base program that exists before weaving.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Certificate revocations performance simulation project</title>
		<author>
			<persName><forename type="first">André</forename><surname>Arnes</surname></persName>
		</author>
		<ptr target="http://www.pvv.ntnu.no/˜andrearn/certrev/sim.html" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Aspect oriented programming (AOP): Using AspectJ to implement and enforce coding standards</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Dale</forename><surname>Asberry</surname></persName>
		</author>
		<ptr target="http://www.daleasberry.com/newsletters/200210/20021002.shtml" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Aspectj</forename><surname>Eclipse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Home</forename></persName>
		</author>
		<ptr target="http://eclipse.org/aspectj/" />
		<title level="m">The AspectJ home page</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Compiling standard ML to Java bytecodes</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">rd ACM SIGPLAN conference on Functional Programming</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">MultiJava: Design, implementation and evaluation of a Java-compatible language supporting modular open classes and symmetric multiple dispatch</title>
		<author>
			<persName><forename type="first">Curtis</forename><surname>Clifton</surname></persName>
		</author>
		<idno>01-10</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Ames, Iowa</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Iowa State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Analyzing the role of aspects in software design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Andrés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Díaz</forename><surname>Pace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><forename type="middle">R</forename><surname>Campo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="66" to="73" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A study of the allocation behavior of the SPECjvm98 Java benchmarks</title>
		<author>
			<persName><forename type="first">Sylvia</forename><surname>Dieckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urs</forename><surname>Hölzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECOOP 1999</title>
		<meeting>ECOOP 1999</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1628</biblScope>
			<biblScope unit="page" from="92" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic metrics for Java</title>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Dufour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karel</forename><surname>Driesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurie</forename><surname>Hendren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Verbrugge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGPLAN conference on Object-oriented programing, systems, languages, and applications</title>
		<meeting>the 18th ACM SIGPLAN conference on Object-oriented programing, systems, languages, and applications</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="149" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Gustav</forename><surname>Evertsson</surname></persName>
		</author>
		<ptr target="http://www.guzzzt.com/coding/aspecttetris.shtml" />
		<title level="m">Tetris in AspectJ</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Mastering AspectJ: Aspect-Oriented Programming in Java</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">D</forename><surname>Gradecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lesiecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CPPROFJ: aspect-capable call path profiling of multi-threaded Java applications</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE Conference on Automated Software Engineering (ASE&apos;02)</title>
		<meeting>the 17th IEEE Conference on Automated Software Engineering (ASE&apos;02)</meeting>
		<imprint>
			<date type="published" when="2002-11">November 2002</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A dynamic runtime coupling metric for meta-level architectures</title>
		<author>
			<persName><forename type="first">Youssef</forename><surname>Hassoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Counsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th European Conference on Software Maintenace and Reengineering, page</title>
		<meeting>the 8th European Conference on Software Maintenace and Reengineering, page</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2004-03">March 2004</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Emprical validation of a dynamic coupling metric</title>
		<author>
			<persName><forename type="first">Youssef</forename><surname>Hassoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Counsell</surname></persName>
		</author>
		<idno>BBKCS-04-03</idno>
		<imprint>
			<date type="published" when="2004-03">March 2004</date>
			<pubPlace>Birbeck College London</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Advice weaving in AspectJ</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hilsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Hugunin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Aspect-oriented Software Development</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Lieberherr</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Getting started with AspectJ</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hilsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Hugunin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mik</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Palm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Griswold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="59" to="65" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An overview of AspectJ</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hilsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Hugunin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mik</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Palm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">G</forename><surname>Griswold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Object-oriented Programming</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Lindskov</forename><surname>Knudsen</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2072</biblScope>
			<biblScope unit="page" from="327" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Aspect-oriented programming</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Menhdekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Marc</forename><surname>Loingtier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Object-oriented Programming</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1241</biblScope>
			<biblScope unit="page" from="220" to="242" />
		</imprint>
	</monogr>
	<note>Mehmet Aksit and Satoshi Matsuoka</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Aspect-oriented programming with</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kiselev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AspectJ. SAMS</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Ramnivas</forename><surname>Laddad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AspectJ in Action. Manning</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A case for statically executable advice: checking the law of Demeter with AspectJ</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Lieberherr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">H</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on Aspect-oriented software development</title>
		<meeting>the 2nd international conference on Aspect-oriented software development</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="40" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A case for statically executable advice: Checking the law of demeter with AspectJ</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Lieberherr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">H</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Wu</surname></persName>
		</author>
		<ptr target="http://www.ccs.neu.edu/home/lorenz/papers/aosd2003lod/" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Using AspectJ to implement product-lines: A case study</title>
		<author>
			<persName><forename type="first">E</forename><surname>Roberto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Lopez-Herrejon</surname></persName>
		</author>
		<author>
			<persName><surname>Batory</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002-09">September 2002</date>
		</imprint>
		<respStmt>
			<orgName>University of Texis at Austin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A compilation and optimization model for aspect-oriented programs</title>
		<author>
			<persName><forename type="first">Hidehiko</forename><surname>Masuhara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dutchyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compiler Construction</title>
		<title level="s">Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2622</biblScope>
			<biblScope unit="page" from="46" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Software assessment using metrics: A comparison across large C++ and Java systems</title>
		<author>
			<persName><forename type="first">Jean</forename><surname>Mayrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Franois</forename><surname>Patenaude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ettore</forename><surname>Merlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Dagenais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Laguë</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="117" to="141" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Decompiling Java bytecode: Problems, traps and pitfalls</title>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Miecznikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurie</forename><surname>Hendren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compiler Construction, 11th International Conference</title>
		<imprint>
			<date type="published" when="2002-04">April 2002</date>
			<biblScope unit="volume">2304</biblScope>
			<biblScope unit="page" from="111" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relaxed MultiJava: Balancing extensibility and modular typechecking</title>
		<author>
			<persName><forename type="first">Todd</forename><surname>Millstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Reay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA 2003</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="224" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Just-in-time aspects: efficient dynamic weaving for Java</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on Aspect-oriented software development</title>
		<meeting>the 2nd international conference on Aspect-oriented software development</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="100" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dynamic weaving for aspect-oriented programming</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international conference on Aspect-oriented software development</title>
		<meeting>the 1st international conference on Aspect-oriented software development</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="141" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Soot: a Java optimization framework</title>
		<imprint>
			<date type="published" when="1998">1998-2003</date>
		</imprint>
		<respStmt>
			<orgName>McGill University Sable Research Group</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Static analysis of aspects</title>
		<author>
			<persName><forename type="first">Damien</forename><surname>Sereni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oege</forename><surname>De Moor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Aspect-Oriented Software Development (AOSD)</title>
		<meeting>the 2nd International Conference on Aspect-Oriented Software Development (AOSD)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="30" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Characterizing the memory behavior of Java workloads: a structured view and opportunities for optimizations</title>
		<author>
			<persName><forename type="first">Yefim</forename><surname>Shuf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><forename type="middle">J</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaswinder Pal</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems</title>
		<meeting>the 2001 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="194" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Optimizing Java bytecode using the Soot framework: Is it feasible?</title>
		<author>
			<persName><forename type="first">Raja</forename><surname>Vallée-Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etienne</forename><surname>Gagnon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurie</forename><forename type="middle">J</forename><surname>Hendren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrice</forename><surname>Pominville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Sundaresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compiler Construction, 9th International Conference (CC 2000)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="18" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A semantics for advice and dynamic join points in aspect-oriented programming</title>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Wand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dutchyn</surname></persName>
		</author>
		<idno>TR #02-06</idno>
	</analytic>
	<monogr>
		<title level="m">Foundations of Aspect-Oriented Languages (FOAL)</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
		<respStmt>
			<orgName>Iowa State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Workshop at AOSD 2002</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Object-oriented metrics -a survey</title>
		<author>
			<persName><forename type="first">D</forename><surname>Michalis Xenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stavrinoudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zikouli</surname></persName>
		</author>
		<author>
			<persName><surname>Christodoulakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the FESMA 2000, Federation of European Software Measurement Associations</title>
		<meeting>the FESMA 2000, Federation of European Software Measurement Associations</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Frequently asked questions about AspectJ, revision 1.8</title>
		<ptr target="http://dev.eclipse.org/viewcvs/indextech.cgi/aspectj-home/doc/faq.html" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Xerox Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic metrics for object oriented designs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sherif</surname></persName>
		</author>
		<author>
			<persName><surname>Yacoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Symposium on Software Metrics</title>
		<meeting>the 6th International Symposium on Software Metrics</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Quantifying aspects in middleware platforms</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Arno</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on Aspect-oriented software development</title>
		<meeting>the 2nd international conference on Aspect-oriented software development</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="130" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Towards a metrics suite for aspect-oriented software</title>
		<author>
			<persName><forename type="first">Jianjun</forename><surname>Zhao</surname></persName>
		</author>
		<idno>SE-136-25</idno>
		<ptr target="http://citeseer.nj.nec.com/zhao02towards.html" />
		<imprint>
			<date type="published" when="2002-03">March 2002</date>
			<publisher>Information Processing Society of Japan</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
