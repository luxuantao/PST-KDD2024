<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Note on the Alternating Direction Method of Multipliers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Deren</forename><surname>Han</surname></persName>
							<email>handeren@njnu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xiaoming</forename><surname>Yuan</surname></persName>
							<email>xmyuan@hkbu.edu.hk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical Science</orgName>
								<orgName type="laboratory">Key Laboratory for NSLSCS of Jiangsu Province</orgName>
								<orgName type="institution">Nanjing Normal University</orgName>
								<address>
									<postCode>210046</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Note on the Alternating Direction Method of Multipliers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E49B20E33AD06D00C5E8356638CE79BD</idno>
					<idno type="DOI">10.1007/s10957-012-0003-z</idno>
					<note type="submission">Received: 15 March 2011 / Accepted: 26 January 2012</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the linearly constrained separable convex programming, whose objective function is separable into m individual convex functions without coupled variables. The alternating direction method of multipliers has been well studied in the literature for the special case m = 2, while it remains open whether its convergence can be extended to the general case m ≥ 3. This note shows the global convergence of this extension when the involved functions are further assumed to be strongly convex.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The alternating direction method of multipliers (ADMM) was presented originally in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, and it has been well studied in the literature. The earlier literature of ADMM focused on convex programming and variational inequalities (see, e.g., <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>), and it has recently found lots of efficient applications in a broad spectrum of areas (see, e.g., <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>). In particular, we refer to <ref type="bibr" target="#b17">[18]</ref> for a review of the applications of ADMM in the areas of distributed optimization and statistical learning. In <ref type="bibr" target="#b17">[18]</ref>, ADMM was commented as a simple algorithm that is "at least comparable to very specialized algorithms (even in the serial setting), and in most cases, the simple ADMM algorithm will be efficient enough to be useful". This note discusses the application of ADMM for linearly constrained separable convex programming, whose objective function is separable into m individual convex functions without coupled variables. In the literature, the convergence of ADMM was established only for the special case m = 2, while the convergence of the natural extension to the general case m ≥ 3 is still open under the convex assumption. We show that the global convergence of the extension of ADMM for m ≥ 3 is valid if the involved functions are further assumed to be strongly convex. This result does not answer the open problem regarding the convergence of the extension of ADMM under the convex assumption, but it makes further progress towards this objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section, we summarize some basic concepts and their properties for the convenience of further discussions.</p><p>Let • p denote the standard definition of the p -norm, and particularly, let • := • 2 denote the Euclidean norm. For any positive definite matrix M, we denote • M as the M-norm. If M is the product of a positive parameter β and the identity matrix I , i.e., M = βI , we use the simpler notation:</p><formula xml:id="formula_0">• M = • β . Let θ : R n →]-∞, +∞].</formula><p>If the domain of θ denoted by dom θ := {x ∈ R n , θ(x) &lt; +∞} is not empty, θ is said to be proper. If for any x ∈ R n and y ∈ R n , we always have</p><formula xml:id="formula_1">f tx + (1 -t)y ≤ tf (x) + (1 -t)f (y), ∀t ∈ [0, 1],</formula><p>then we say that f is convex. Furthermore, f is said to be strongly convex with the modulus μ &gt; 0 iff</p><formula xml:id="formula_2">f tx + (1 -t)y ≤ tf (x) + (1 -t)f (y) - 1 2 μt (1 -t) x -y 2 , ∀t ∈ [0, 1].</formula><p>A set-valued operator T defined on R n is said to be monotone iff</p><formula xml:id="formula_3">u -u , w -w ≥ 0, ∀w ∈ T u, ∀w ∈ T u ;</formula><p>and it is called a strongly monotone operator with the modulus μ &gt; 0 iff</p><formula xml:id="formula_4">u -u , w -w ≥ μ u -u 2 , ∀w ∈ T u, ∀w ∈ T u .</formula><p>Let Γ 0 (R n ) denote the set of lower semicontinuous proper convex functions from R n to ]-∞, +∞]. For any θ ∈ Γ 0 (R n ), the subdifferential of θ is the set-valued operator defined by</p><formula xml:id="formula_5">∂θ : x → ξ ∈ R n | y -x, ξ + θ(x) ≤ θ(y), ∀y ∈ dom θ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Motivation</head><p>In this section, we delineate the motivation. To present ADMM, let us first consider the following linearly constrained convex programming problem with a separable objective function</p><formula xml:id="formula_6">min θ 1 (x 1 ) + θ 2 (x 2 ) | A 1 x 1 + A 2 x 2 = b, x 1 ∈ X 1 , x 2 ∈ X 2 , (<label>1</label></formula><formula xml:id="formula_7">)</formula><p>where θ i : R n i → R is a closed, proper and convex function (not necessarily smooth); A i ∈ R l×n i ; X i ⊆ R n i is a closed, convex and nonempty set; and b ∈ R l is a given vector. The iterative scheme of ADMM in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> is as follows</p><formula xml:id="formula_8">⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ x k+1 1 := Argmin θ 1 (x 1 ) -λ k , A 1 x 1 + β 2 A 1 x 1 + A 2 x k 2 -b 2 | x 1 ∈ X 1 ; x k+1 2 := Argmin θ 2 (x 2 ) -λ k , A 2 x 2 + β 2 A 1 x k+1 1 + A 2 x 2 -b 2 | x 2 ∈ X 2 ; λ k+1 = λ k -β(A 1 x k+1 1 + A 2 x k+1 2 -b),<label>(2)</label></formula><p>where λ k is a Lagrange multiplier associated with the linear constraint and β &gt; 0 is the penalty parameter for the violation of the linear constraint. It is obvious that the iterative scheme of ADMM makes it possible to exploit the properties of θ i 's individually, and for many applications the resulting subproblems of ADMM are often simple enough to have closed-form solutions or can be solved efficiently up to a high precision; see, e.g., <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>.</p><p>Motivated by the wide applications (see, e.g., <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref>), it is interesting to consider the extension of (1), where the objective function is separable into m (m ≥ 3) blocks without coupled variables</p><formula xml:id="formula_9">min m i=1 θ i (x i ) m i=1 A i x i = b, x i ∈ X i , i = 1, 2, . . . , m ,<label>(3)</label></formula><p>where for each i, θ i : R n i → R is a closed, proper and convex function (but not necessarily smooth);</p><formula xml:id="formula_10">A i ∈ R l×n i ; X i ⊆ R n i is a closed, convex and nonempty set; b ∈ R l ; and n 1 + n 2 + • • • + n m = n.</formula><p>For solving (3), one may argue that the ADMM ( <ref type="formula" target="#formula_8">2</ref>) is applicable whenever we divide all the function components θ i 's into two groups and the subvectors x i 's are grouped accordingly. By doing so, however, the objective functions of some of the resulting subproblems may consist of more than one function components θ i 's, and this makes such a subproblem difficult. As emphasized in <ref type="bibr" target="#b17">[18]</ref>, the philosophy of ADMM is a "decomposition-coordination procedure in which the solutions to small local subproblems are coordinated to find a solution to a large global problem". Thus, it is obvious that the resulting subproblems need to be as simple as possible in order to maintain the efficiency of ADMM, and this purpose is basically achieved by exploiting the properties of θ i 's individually in the procedure of subproblem-solving. Therefore, for solving (3) with m ≥ 3, we do not recommend to apply the original ADMM (2) directly. Nevertheless, motivated by the philosophy of ADMM, the easiest idea for solving (3) is to extend the ADMM (2) and this yields the following iterative scheme</p><formula xml:id="formula_11">⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ x k+1 1 ∈ arg min x 1 ∈X 1 θ 1 (x 1 ) -λ k , A 1 x 1 + β 2 A 1 x 1 + m j =2 A j x k j -b 2 , . . . x k+1 i ∈ arg min x i ∈X i θ i (x i ) -λ k , A i x i + β 2 i-1 j =1 A j x k+1 j + A i x i + m j =i+1 A j x k j -b 2 , . . . x k+1 m ∈ arg min x m ∈X m θ m (x m ) -λ k , A m x m + β 2 m-1 j =1 A j x k+1 j + A m x m -b 2 , λ k+1 = λ k -β( m i=1 A i x k+1 i -b). (<label>4</label></formula><formula xml:id="formula_12">)</formula><p>Even though its efficiency has been verified empirically by some recent applications (see, e.g., <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref>), the convergence of the extended ADMM (4) for m ≥ 3 is still open in the literature. Recently, the lack of convergence of (4) has inspired some efforts in the prediction-correction fashion for solving (3), whose main idea is to generate the new iterate via correcting the output of (4) via some correction steps, see e.g. <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. As shown in these articles, the direct extension of ADMM (4) still performs the best numerically. Therefore, the open problem regarding the convergence of ( <ref type="formula" target="#formula_11">4</ref>) falls into the interests of researchers and it deserves further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Convergence</head><p>In this section, we prove the convergence of the extended ADMM (4) for solving <ref type="bibr" target="#b2">(3)</ref> with the strongly convex assumption on θ i 's. First, since all θ i 's in (3) are assumed to be strongly convex functions, by invoking the first-order necessary and sufficient condition for convex programming, we easily see that the problem (3) under consideration is characterized by the following variational inequality (VI): Find u * ∈ U and</p><formula xml:id="formula_13">ξ * i ∈ ∂θ i (x * i ) such that u -u * , Q u * ≥ 0, ∀u ∈ U,<label>(5)</label></formula><p>where</p><formula xml:id="formula_14">u * := ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ x * 1 x * 2 . . . x * m λ * ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ , Q u * := ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ξ * 1 -A T 1 λ * ξ * 2 -A T 2 λ * . . . ξ * m -A T m λ * m i=1 A i x * i -b ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ and U := m i=1 X i × R l . (<label>6</label></formula><formula xml:id="formula_15">)</formula><p>Here, ∂θ i is the subdifferential operator of the strongly convex function θ i (x i ), and it is strongly monotone (see <ref type="bibr" target="#b24">[25]</ref>). We denote the VI ( <ref type="formula" target="#formula_13">5</ref>)-( <ref type="formula" target="#formula_14">6</ref>) by MVI(Q, U), and the solution set of the VI ( <ref type="formula" target="#formula_13">5</ref>)-( <ref type="formula" target="#formula_14">6</ref>) is denoted by U * .</p><p>We assume that each θ i in (3) be strongly convex with the modulus μ i . Then, the subdifferential operator ∂θ i is strongly monotone with the modulus μ i . Since ∂θ i (x i ) is strongly monotone, the VI ( <ref type="formula" target="#formula_13">5</ref>)-( <ref type="formula" target="#formula_14">6</ref>) is solvable and the solution set U * is nonempty (In fact, x * i is unique due to strong convexity of θ i ); see, e.g., <ref type="bibr" target="#b25">[26]</ref>. Then, we propose an easily implementable stopping criterion for executing (4):</p><formula xml:id="formula_16">max 1≤i≤m max A i x k i -A i x k+1 i , m i=1 A i x k i -b ≤ ,<label>(7)</label></formula><p>and its rationale can be seen in the following lemma.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 4.1 If</head><formula xml:id="formula_17">m i=1 A i x k i -b = 0 and A i x k i = A i x k+1 i (i = 1, . . . , m), then (x k+1 1 , . . . , x k+1 m , λ k+1 ) is a solution of MVI(U, Q). Proof The assumptions m i=1 A i x k i -b = 0 and A i x k i = A i x k+1 i (i = 1, . . . , m) im- ply that m i=1 A i x k+1 i = b,<label>(8)</label></formula><p>which, together with the definition of λ k+1 , means that λ k+1 = λ k . On the other hand, by invoking the first-order optimality condition for the x k+1 i related subproblem in (4), we have that</p><formula xml:id="formula_18">x i -x k+1 i , ξ k+1 i -A T i λ k -β i j =1 A j x k+1 j + m j =i+1 A j x k j -b ≥ 0, ∀x i ∈ X i ,<label>(9)</label></formula><p>where ξ k+1 i ∈ ∂θ i (x k+1 i ). Thus, it follows from (8), <ref type="bibr" target="#b8">(9)</ref> </p><formula xml:id="formula_19">and A i x k i = A i x k+1 i that x i -x k+1 i , ξ k+1 i -A T i λ k+1 ≥ 0, ∀x i ∈ X i , i = 1, . . . , m,</formula><p>and we have the conclusion that</p><formula xml:id="formula_20">m i=1 (A i x k i -b) = 0 A i x k i = A i x k+1 i , i = 1, . . . , m ⇒ ⎧ ⎨ ⎩ x i -x k+1 i , ξ k+1 i -A T i λ k+1 ≥ 0, ∀x i ∈ X i , i = 1, . . . , m, m i=1 A i x k+1 i = b.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thus, (x k+1</head><p>1 , x k+1 2 , . . . , x k+1 m , λ k+1 ) is a solution of MVI(U, Q).</p><p>Lemma 4.1 indicates that the iterate (x k+1 1 , . . . , x k+1 m , λ k+1 ) is a solution of MVI(U, Q) when the inequality (7) holds with = 0. Some techniques of establishing the error bounds in <ref type="bibr" target="#b25">[26]</ref> can help us analyze how precisely the iterate satisfies the optimality conditions when the proposed stopping criterion is satisfied with a tolerance &gt; 0; and how to measure the accuracy of approaching the optimal objective function. Now, we show the convergence of (4), starting with the following lemma which proves an important inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 4.2 Let (x *</head><p>1 , x * 2 , . . . , x * m ) be the solution of the problem (3) and λ * be a corresponding Lagrange multiplier associated with the linear constraint. Then, the sequence {(x k 1 , x k 2 , . . . , x k m , λ k )} generated by (4) satisfies</p><formula xml:id="formula_21">λ k -λ * , m i=1 A i x k+1 i -b ≥ m i=1 μ i x k+1 i -x * i 2 + β m i=1 A i x k+1 i -b 2 + β m i=1 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x k+1 j . (<label>10</label></formula><formula xml:id="formula_22">)</formula><p>Proof Recall <ref type="bibr" target="#b8">(9)</ref>. By setting x i := x * i in ( <ref type="formula" target="#formula_18">9</ref>), we obtain that</p><formula xml:id="formula_23">x * i -x k+1 i , ξ k+1 i -A T i λ k -β i j =1 A j x k+1 j + m j =i+1 A j x k j -b ≥ 0. (<label>11</label></formula><formula xml:id="formula_24">)</formula><p>On the other hand, setting x i := x k+1 i in ( <ref type="formula" target="#formula_13">5</ref>)-( <ref type="formula" target="#formula_14">6</ref>), we have that</p><formula xml:id="formula_25">x k+1 i -x * i , ξ * i -A T i λ * ≥ 0. (<label>12</label></formula><formula xml:id="formula_26">)</formula><p>Adding ( <ref type="formula" target="#formula_23">11</ref>) and ( <ref type="formula" target="#formula_25">12</ref>), we get</p><formula xml:id="formula_27">x k+1 i -x * i , ξ * i -ξ k+1 i -A T i λ * -λ k -βA T i i j =1 A j x k+1 j + m j =i+1 A j x k j -b ≥ 0.</formula><p>With re-arrangement of the above inequality, we derive that</p><formula xml:id="formula_28">A i x k+1 i -x * i , λ k -λ * ≥ x k+1 i -x * i , ξ k+1 i -ξ * i + β A i x k+1 i -x * i , i j =1 A j x k+1 j + m j =i+1 A j x k j -b ≥ μ i x k+1 i -x * i 2 + β A i x k+1 i -x * i , i j =1 A j x k+1 j + m j =i+1 A j x k j -b ,</formula><p>where the second inequality follows from the strong monotonicity of the subdifferential mapping ∂θ i (with the modulus μ i ). Then, summing the above inequality over all i = 1, 2, . . . , m and using the equality</p><formula xml:id="formula_29">m i=1 A i x * i = b,</formula><formula xml:id="formula_30">and i j =1 A j x k+1 j + m j =i+1 A j x k j -b = m j =1 A j x k+1 j -b + m j =i+1 A j x k j -x k+1 j ,</formula><p>we have that</p><formula xml:id="formula_31">λ k -λ * , m i=1 A i x k+1 i -b ≥ m i=1 μ i x k+1 i -x * i 2 + β m i=1 A i x k+1 i -b 2 + β m i=1 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x k+1 j ,</formula><p>which completes the proof.</p><p>Hereafter, we define an auxiliary block-diagonal matrix</p><formula xml:id="formula_32">M M = ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ β(m -1)A T 1 A 1 0 • • • 0 0 0 β(m -1)A T 2 A 2 • • • 0 0 . . . . . . . . . . . . . . . 0 0 • • • β(m -1)A T m A m 0 0 0 • • • 0 β -1 I ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠</formula><p>, where I denotes the identity matrix in R l×l . Evidently, M is a positive semidefinite matrix. For notational convenience, we denote</p><formula xml:id="formula_33">u 2 M := β(m -1) A 1 x 1 2 + A 2 x 2 2 + • • • + A m x m 2 + λ 2 β -1 .</formula><p>Our next step towards the convergence is to find a lower bound of the quantity u ku * Mu k+1u * M , which measures the progress made by the new iterate u k+1 . With the result of Lemma 4.2, we achieve this goal in the following lemma. </p><formula xml:id="formula_34">u k+1 -u * 2 M ≤ u k -u * 2 M -2 m i=1 μ i x k+1 i -x * i 2 -β m i=1 A i x k+1 i -b 2 + 3(m -1)β m i=1 A i x k+1 i -A i x * i 2 . (<label>13</label></formula><formula xml:id="formula_35">)</formula><p>Proof It follows from the last equality in (4) and that</p><formula xml:id="formula_36">λ k+1 -λ * 2 β -1 = λ k -λ * -β m i=1 A i x k+1 i -b 2 β -1 = λ k -λ * 2 β -1 -2 λ k -λ * , m i=1 A i x k+1 i -b + β m i=1 A i x k+1 i -b 2 ≤ λ k -λ * 2 β -1 -2 m i=1 μ i x k+1 i -x * i 2 -β m i=1 A i x k+1 i -b 2 -2β m i=1 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x k+1 j . (<label>14</label></formula><formula xml:id="formula_37">)</formula><p>On the other hand, for any i, we have that</p><formula xml:id="formula_38">-2 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x k+1 j = -2 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x * j + 2 A i x k+1 i -A i x * i , m j =i+1 A j x k+1 j -A j x * j ≤ 2 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x * j + 2 A i x k+1 i -A i x * i , m j =i+1 A j x k+1 j -A j x * j ≤ 2(m -i) A i x k+1 i -A i x * i 2 + m j =i+1 A j x k+1 j -A j x * j 2 + m j =i+1 A j x k j -A j x * j 2 , (<label>15</label></formula><formula xml:id="formula_39">)</formula><p>where the last inequality follows from the fact that for any two vectors a and b, we</p><formula xml:id="formula_40">2 a, b ≤ a 2 + b 2 . Since m i=1 m j =i+1 A j x k+1 j -A j x * j 2 = m i=1 (i -1) A i x k+1 i -A i x * i 2 and m i=1 m j =i+1 A j x k j -A j x * j 2 = m i=1 (i -1) A i x k i -A i x * i 2 ,</formula><p>summing up <ref type="bibr" target="#b14">(15)</ref> for all i's, we obtain</p><formula xml:id="formula_41">-2 m i=1 A i x k+1 i -A i x * i , m j =i+1 A j x k j -A j x k+1 j ≤ m i=1 2(m -i) A i x k+1 i -A i x * i 2 + m i=1 (i -1) A i x k+1 i -A i x * i 2 + m i=1 (i -1) A i x k i -A i x * i 2 ≤ m i=1 (2m -i -1) A i x k+1 i -A i x * i 2 + m i=1 (i -1) A i x k i -A i x * i 2 ≤ 2(m -1) m i=1 A i x k+1 i -A i x * i 2 + (m -1) m i=1 A i x k i -A i x * i 2 . (<label>16</label></formula><formula xml:id="formula_42">)</formula><p>Combining ( <ref type="formula" target="#formula_36">14</ref>) and ( <ref type="formula" target="#formula_41">16</ref>), we have</p><formula xml:id="formula_43">λ k+1 -λ * 2 β -1 + (m -1)β m i=1 A i x k+1 i -x * i 2 ≤ λ k -λ * 2 β -1 + (m -1)β m i=1 A i x k i -x * i 2 -2 m i=1 μ i x k+1 i -x * i 2 -β m i=1 A i x k+1 i -b 2 + 3(m -1)β m i=1 A i x k+1 i -A i x * i 2 .</formula><p>This completes the proof.</p><p>With Lemmas 4.2 and 4.3, we are now ready to establish the convergence of extended ADMM (4) for solving (3) with strongly convex θ i 's. Theorem 4.1 Let θ i 's in (3) be strongly convex with the modulus μ i 's. For any</p><formula xml:id="formula_44">0 &lt; β &lt; min 1≤i≤m 2μ i 3(m -1) A i 2 ,</formula><p>the sequence {u k } generated by the extended ADMM (4) converges to a solution of MVI(U, Q).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof Since</head><formula xml:id="formula_45">A i x k+1 i -A i x * i 2 ≤ A i 2 x k+1 i -x * i 2 ,</formula><p>it follows from ( <ref type="formula" target="#formula_34">13</ref>) that</p><formula xml:id="formula_46">u k+1 -u * 2 M ≤ u k -u * 2 M - m i=1 c i x k+1 i -x * i 2 -β m i=1 A i x k+1 i -b 2 , (<label>17</label></formula><formula xml:id="formula_47">)</formula><p>where</p><formula xml:id="formula_48">c i := 2μ i -3(m -1)β A i 2 &gt; 0.</formula><p>Consequently,</p><formula xml:id="formula_49">u k+1 -u * 2 M ≤ u k -u * 2 M ≤ • • • ≤ u 0 -u * 2 M &lt; +∞,<label>(18)</label></formula><p>which means that the generated sequence {u k } is bounded. Furthermore, it follows from (17) that </p><formula xml:id="formula_50">)<label>19</label></formula><p>Since it is bounded, the sequence {λ k } has at least one cluster point, say λ. Let {λ k j } be the corresponding subsequence that converges to λ. Taking limit along this subsequence in ( <ref type="formula" target="#formula_18">9</ref>) and ( <ref type="formula" target="#formula_50">19</ref>), we obtain ξ * i ∈ ∂θ i (x * ),</p><p>x ix * i , ξ * i -A T λ ≥ 0, ∀x i ∈ X i , and m i=1 A i x * ib = 0, which mean that λ is an optimal Lagrange multiplier. Since λ * is arbitrary, we can set λ * = λ in <ref type="bibr" target="#b17">(18)</ref> and conclude that the whole generated sequence converges. This completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This note presents a theoretical result on the extension of the well known alternating direction method of multipliers (ADMM) for solving linearly constrained separable convex programming, whose objective function is separable into m (m ≥ 3) individual functions without coupled variables. We show that the convergence of this extension is valid provided that the objective function is further assumed to be strongly convex. This result makes a progress towards the open problem regarding the convergence of the extension of ADMM under only convex assumption on the objective function.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Lemma 4 . 3</head><label>43</label><figDesc>Let u * = (x * 1 , . . . , x * m , λ * ) be a solution of MVI(U, Q) and the sequence {u k = (x k 1 , . . . , x k m , λ k )} be generated by the extended ADMM (4). Then, we have</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>u k -u * 2 M -u k+1 -u * 2 M</head><label>22</label><figDesc>i = 0, for all i = 1, . . . , m,</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The research was supported by the National Natural Science Foundation of China (NSFC) grants 11071122, 11171159, Doctoral Found of Ministry of Education of China 20103207110002, and the Hong Kong General Research Grant: HKBU203311.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A dual algorithm for the solution of nonlinear variational problems via finite element approximations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gabay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mercier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Math. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="17" to="40" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Augmented Lagrangian Methods: Applications to the Numerical Solution of Boundary-Value Problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gabay</surname></persName>
		</author>
		<editor>Fortin, M., Glowinski, R.</editor>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="299" to="331" />
			<pubPlace>North-Holland; Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>Applications of the method of multipliers to variational inequalities</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A proximal-based decomposition method for convex minimization problems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="81" to="101" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="293" to="318" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Application of the alternating directions method of multipliers to separable convex programming problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Optim. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="93" to="111" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A new inexact alternating direction method for monotone variational inequalities</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="103" to="118" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A variable-penalty alternating directions method for convex optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kontogiorgis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="29" to="53" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Applications of a splitting algorithm to decomposition in convex programming and variational inequalities</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control Optim</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="119" to="138" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Alternating direction method for image inpainting in wavelet domain</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="807" to="826" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Matrix completion via alternating direction method</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA J. Anal</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="227" to="245" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Applications of Lagrangian-based alternating direction methods and connections to split Bregman</title>
		<author>
			<persName><forename type="first">E</forename><surname>Esser</surname></persName>
		</author>
		<idno>09-31</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">UCLA CAM Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Solving large-scale least squares covariance matrix problems by alternating direction methods</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="136" to="152" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Solving constrained total-variation problems via alternating direction methods</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2710" to="2736" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A modified alternating direction method for convex quadratically constrained quadratic semidefinite programs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="1210" to="1220" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recovering low-rank and sparse components of matrices from incomplete and noisy observations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Alternating direction algorithms for 1 problems in compressive sensing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="250" to="278" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sparse and low-rank matrix decomposition via alternating direction method</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac. J. Optim</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Faund. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Structured linear algebra problems in adaptive optics imaging</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bardsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Knepper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Comput. Math</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="103" to="117" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Proximal decomposition via alternating linearization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Kiwiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruszczyński</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="668" to="689" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deblurring Poissonian images by split Bregman techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Steidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tebuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="193" to="199" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust alignment by sparse and low-rank decomposition for linearly correlated images</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Alternating direction method with Gaussian back substitution for separable convex programming</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Alternating directions based contraction method for generally separable linearly constrained convex programming problems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<title level="m">Convex Analysis</title>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Finite-Dimensional Variational Inequalities and Complementarity Problems, vols. I and II</title>
		<author>
			<persName><forename type="first">F</forename><surname>Facchinei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
