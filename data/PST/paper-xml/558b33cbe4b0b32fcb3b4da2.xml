<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linear stereo matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Leonardo</forename><surname>De-Maeztu</surname></persName>
							<email>leonardo.demaeztu@unavarra.es</email>
							<affiliation key="aff0">
								<orgName type="institution">Public University of Navarre</orgName>
								<address>
									<settlement>Pamplona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefano</forename><surname>Mattoccia</surname></persName>
							<email>stefano.mattoccia@unibo.it</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Bologna Bologna</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arantxa</forename><surname>Villanueva</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Public University of Navarre</orgName>
								<address>
									<settlement>Pamplona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rafael</forename><surname>Cabeza</surname></persName>
							<email>rcabeza@unavarra.es</email>
							<affiliation key="aff0">
								<orgName type="institution">Public University of Navarre</orgName>
								<address>
									<settlement>Pamplona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Linear stereo matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EA1EC7B1D4AC85EC498E1DA9EE442903</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent local stereo matching algorithms based on an adaptive-weight strategy achieve accuracy similar to global approaches. One of the major problems of these algorithms is that they are computationally expensive and this complexity increases proportionally to the window size. This paper proposes a novel cost aggregation step with complexity independent of the window size (i.e. O( <ref type="formula">1</ref>)) that outperforms state-of-the-art O(1) methods. Moreover, compared to other O(1) approaches, our method does not rely on integral histograms enabling aggregation using colour images instead of grayscale ones. Finally, to improve the results of the proposed algorithm a disparity refinement pipeline is also proposed. The overall algorithm produces results comparable to those of state-of-the-art stereo matching algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Dense stereo matching algorithms aim at determining correspondences in two or more images of the same scene taken from different viewpoints. This topic was exhaustively reviewed in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b18">[19]</ref>. According to both, most stereo algorithms can be categorized in two major classes: local methods and global methods. Local approaches use information within a finite region around the pixel whose disparity is being computed. Global approaches incorporate explicit smoothness assumptions and determine all disparities simultaneously by applying energy minimization techniques.</p><p>Traditional local stereo matching algorithms are typically faster than global approaches and have a lower memory footprint. However, they also have reduced accuracy compared to global state-of-the-art algorithms. Recent local algorithms based on adaptive-weight <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22]</ref> produce similar results to those obtained using global optimization techniques. Unfortunately, the computational complexity of this type of local algorithms is high, and is quadratically related to the window size used to aggregate the matching costs. Recently, two similar solutions have been proposed that render the computation complexity independent of the size of the aggregation window <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> (also referred as O(1) complexity). However, the proposed methods have some limitations (i.e. aggregation can only be performed using grayscale images) and they have significantly reduced accuracy compared to state-of-the-art adaptive-weight methods arising from the asymmetric nature of the aggregation strategy (i.e. only the reference image information is used for aggregating costs).</p><p>This paper proposes a novel O(1) costs aggregation strategy that thanks to its symmetric nature outperforms stateof-the-art O(1) costs aggregation methods. Moreover, compared to previous O(1) solutions, our proposal relies on a completely different approach that allows to aggregate costs using colour input stereo pairs (previous O(1) solutions aggregate costs using grayscale images because of memory footprint limitations). The symmetric and colour-based O(1) aggregation strategy proposed not only outperforms state-of-the-art O(1) algorithms, but it also produces results comparable to non-O(1) adaptive-weight stereo matching <ref type="bibr" target="#b21">[22]</ref>. Thanks to the O(1) nature of our algorithm, when the size of the input stereo pair grows, our method enables a dramatic improvement in execution time compared to adaptive-weight stereo matching. Finally, we also propose a pipeline that combines two disparity refinement techniques, that allows to obtain results comparable to top-performing stereo matching algorithms.</p><p>The rest of this paper is organized as follows. In Section 2, we review state-of-the-art O(1) cost aggregation strategies and other non-O(1) methods based on the adaptiveweight strategy. In Section 3 we present our novel constant time aggregation strategy and in Section 4 the overall algorithm proposed in this paper is described. We report experimental results in Section 5 and we draw conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this Section we split the review of state-of-theart stereo matching algorithms in non-O(1) and O(1) approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Non-O(1) cost aggregation strategies based on adaptive-weights</head><p>Traditional local stereo matching algorithms produce less accurate results compared to global ones. This gap has been reduced <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> by recent local stereo algorithms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21]</ref>. Even if the idea of aggregating costs using adapting weights for each pixel had been studied in several publications <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14]</ref>, it was in <ref type="bibr" target="#b21">[22]</ref> where Yoon and Kweon proposed the adaptive-weight aggregation method which clearly outperformed previous local stereo matching algorithms. It consists in aggregating costs over a fixed-size window (35 × 35 in <ref type="bibr" target="#b21">[22]</ref>), where each pixel adds its cost to the total cost of the window with a different weight. The weight encodes the likelihood that each pixel q belongs to the same object than the central pixel of the window p. The pixel weight depends on two values: the colour difference and the distance between this pixel and the central pixel of the window. The weight is higher for pixels of a colour similar to the central one as well as for pixels closer to the central one. The colour difference (∆c pq ) is computed as the Euclidean distance between the values in the CIELab colour space of pixel p and pixel q. The distance (∆g pq ) is computed as the spatial Euclidean distance between pixel p and pixel q. Two constants, γ c and γ p , respectively, are used to modulate the relative relevance of ∆c pq and ∆g pq . The weight, w, assigned to the cost of pixel q when the disparity of pixel p is being computed is expressed as</p><formula xml:id="formula_0">w(p, q) = exp ( - ( ∆c pq γ c + ∆g pq γ p ))<label>(1)</label></formula><p>During the aggregation step, the weights computed for the pixels in the reference window and the pixels in the target window are combined (symmetric aggregation). Then the dissimilarity within a square window, E, between the pixels p and p d can be expressed as</p><formula xml:id="formula_1">E(p, p d ) = ∑ qϵNp,q d ϵNp d w(p, q)w(p d , q d )e(q, q d ) ∑ qϵNp,q d ϵNp d w(p, q)w(p d , q d )<label>(2)</label></formula><p>where p d and q d are the corresponding pixels in the target image when the pixels p and q in the reference image have a disparity value of d, N p and N p d are the aggregation windows, and e(q, q d ) represents the pixel-based raw matching cost of q and q d . One of the main disadvantages of adaptive-weight aggregation is that it is computationally expensive. Moreover, as it was mentioned in Section 1, computation time is quadratically related to the window size. Several authors have proposed faster local methods inspired by the adaptiveweight algorithm. Gong et al. <ref type="bibr" target="#b1">[2]</ref> proposed two modifications to the original adaptive-weight algorithm. First, they only use the weight term obtained using the target image.</p><p>Second, a two-pass 1D algorithm is implemented instead of using a 2D square window for aggregation. Richardt et al. <ref type="bibr" target="#b15">[16]</ref> recently proposed a new real-time local stereo algorithm based on the adaptive-weight method. They use a dual-cross-bilateral grid for costs aggregation, an extension of the bilateral grid used to speedup bilateral filtering <ref type="bibr" target="#b11">[12]</ref>. However, the results of both algorithms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref> are less accurate than those of the adaptive-weight algorithm <ref type="bibr" target="#b21">[22]</ref>. Fast Bilateral Stereo <ref type="bibr" target="#b10">[11]</ref> is an algorithm that combines the efficiency of integral images, deployed by traditional correlative approaches, with an adapting-weight strategy applied on a block basis. Compared to the original adaptive-weight algorithm, the execution time is significantly reduced with comparable results.</p><p>All the techniques described in the previous paragraph are faster than the adaptive-weight algorithm. However, the execution time of these techniques still depends on the aggregation window size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">O(1) cost aggregation strategies</head><p>Ju and Kang <ref type="bibr" target="#b6">[7]</ref> propose an alternative O(1) implementation of adaptive-weight aggregation. They use integral histograms to render the computation time independent of the size of the aggregation window using an approach inspired by Porikli's O(1) technique <ref type="bibr" target="#b12">[13]</ref>. Ju and Kang <ref type="bibr" target="#b6">[7]</ref> define the integral histogram H d (I,I) (p x , p y , i) for the difference image with disparity d between the grayscale versions of reference image I and target image I as</p><formula xml:id="formula_2">H d (I,I) (p x , p y , i) = H d (I,I) (p x -1, p y , i) + H d (I,I) (p x , p y -1, i) -H d (I,I) (p x -1, p y -1, i) + I(p x , p y ) -I(p x -d, p y )<label>(3)</label></formula><p>where the point p is represented by its coordinates p x and p y . i represents all the possible bins of the integral histogram.</p><p>To obtain not only a constant time algorithm but also a faster algorithm than the original adaptive-weight algorithm, Ju and Kang <ref type="bibr" target="#b6">[7]</ref> perform some simplifications. First, only the weights in the reference image are used. Second, grayscale input images are used for costs aggregation instead of colour ones due to memory footprint constraints <ref type="bibr" target="#b6">[7]</ref>. Finally, spatial filtering is performed separately from the colour filtering. According to the definition of the integral histogram and the simplifications previously mentioned, the constant time aggregation <ref type="bibr" target="#b6">[7]</ref> can be expressed as</p><formula xml:id="formula_3">E(p, p d ) = ∑ N -1 i=0 w(p, i)H d (I,I) (p, i) ∑ N -1 i=0 w(p, i) (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where N is the number of bins of the histogram and w(p, i) is the resulting weight of comparing the value of the pixel p and the value of the bin i. It can be observed in (4) that aggregation is performed using the values of the histogram instead of the input stereo pair. This is the reason why the computation complexity of the algorithm is independent of the window size. Recently, Zhang et al. <ref type="bibr" target="#b22">[23]</ref> proposed a new structure, the joint integral histogram (JIH) , that accelerates weighted filtering and adaptive-weight stereo matching. Apart from this new structure, the proposed algorithm is similar to the previously described O(1) algorithm <ref type="bibr" target="#b6">[7]</ref>. Finally, we report that in parallel to our activity, Rhemann et al. <ref type="bibr" target="#b14">[15]</ref> developed an asymmetric aggregation strategy based on a similar linear model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed linear stereo aggregation step</head><p>In this Section we describe our O(1) aggregation step that, differently by other O(1) approaches does not rely on the Porikli's method <ref type="bibr" target="#b12">[13]</ref>. For stereo matching algorithms, it is desirable that the edges of the input stereo pair of images are preserved during costs aggregation, as it is made in the adaptive-weight algorithms, where pixels with different colour values are aggregated with a low weight <ref type="bibr" target="#b0">(1)</ref>. Local linear models have been proven useful in image filtering <ref type="bibr" target="#b3">[4]</ref>, image matting <ref type="bibr" target="#b8">[9]</ref>, image super-resolution <ref type="bibr" target="#b23">[24]</ref>, and haze removal <ref type="bibr" target="#b2">[3]</ref>. In these models, each pixel p of the output image O is supposed to be linearly related to the same pixel p of the input image I in a window N q centered at the pixel q</p><formula xml:id="formula_5">O p = a q I p + b q , ∀pϵN q , (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where a q and b q are constant parameters in each window N q . This linear relationship ensures the conservation of edges between the input and the output image <ref type="bibr" target="#b3">[4]</ref>. To model this behavior, in our linear stereo algorithm, the aggregated cost E is linearly related to the input stereo pair composed of the reference image I and the target image I as</p><formula xml:id="formula_7">E(p, p d ) = a q [ I(p) T I(p d ) T ] + b q (6)</formula><p>where I(p) and I(p d ) are intensity values if the algorithm is being applied to grayscale images or RGB components if the algorithm is being applied to colour images, a q is a 2×1 or a 6×1 vector (depending on whether the input stereo pair contains grayscale or colour information, respectively) and E(p, p d ) and b q are scalars.</p><p>Minimizing the difference between the input and the output of the linear model, the coefficients of the model are determined. According to <ref type="bibr" target="#b3">[4]</ref> the parameters can be expressed as</p><formula xml:id="formula_8">a q = (Σ q + ϵU) -1   1 |N | ∑ pϵNq [ I(p)I(p d ) ] e(p, p d ) -µ q e q  <label>(7)</label></formula><p>b q = e q -a T q µ q (8)</p><p>where Σ q is the 2 × 2 or 6 × 6 covariance matrix of the</p><formula xml:id="formula_9">[ I(p)I(p d ) ]</formula><p>vector in N q and U is a 2 × 2 or 6 × 6 identity matrix. µ q is the 2 × 1 or 6 × 1 mean vector of the</p><formula xml:id="formula_10">[ I(p)I(p d ) ]</formula><p>vector in N q . e q is the mean of e in N q . |N | is the number of pixels in N q . ϵ is a regularization parameter preventing a q from being too large. ϵ has a similar effect to σ c in the adaptive-weight algorithm <ref type="bibr" target="#b21">[22]</ref>. The larger the ϵ value, the stronger the filtering effect on edges.</p><p>After applying this linear model to the entire input stereo pair, a pixel p is involved in all the windows N q that contain p. In other words, the aggregated cost of each pixel is modeled by |N | different a q and b q values. Once computed all the a q and b q values, we average them within N q . After this final modification, the proposed stereo linear model can be expressed as</p><formula xml:id="formula_11">E(p, p d ) = 1 |N | ∑ q∋pϵNq (a q [ I(p) T I(p d ) T ] + b q ) = a p [ I(p) T I(p d ) T ] + b p (9)</formula><p>The behavior of the proposed aggregation algorithm can be explained using Equations <ref type="bibr" target="#b6">(7)</ref> and <ref type="bibr" target="#b7">(8)</ref>. In fact, in highly textured regions, the value of the a q parameter is close to 1 and b q tends to 0 (i.e. no filtering is performed). In low texture regions, a q = 0 and b q = e q (i.e. our linear model computes a simple square window averaging).</p><p>As it was previously mentioned in this paper, Equation (9) used for costs aggregation, was inspired by guided filtering <ref type="bibr" target="#b3">[4]</ref>. Similarly, as pointed out in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b21">22]</ref>, the idea behind the adaptive-weight aggregation strategy <ref type="bibr" target="#b21">[22]</ref> was related to bilateral filtering <ref type="bibr" target="#b19">[20]</ref>. In fact, our proposal and the adaptive-weight technique aim to average costs only in regions with similar colours.</p><p>It is worth noting that all the window-based computations described in this Section can be computed in constant time by means of the integral image method <ref type="bibr" target="#b0">[1]</ref>. As a consequence, the computation time of the linear stereo aggregation stage is independent of the size of the window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Stereo matching algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Disparity computation and disparity selection</head><p>In Section 3 a novel O(1) costs aggregation step for stereo matching was proposed. According to <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b18">[19]</ref>  For what concerns costs computation (a), two different measures are deployed in this paper: Absolute Difference (AD) and Hierarchical Mutual Information (HMI) <ref type="bibr" target="#b4">[5]</ref>. In the case of colour images, AD is expressed as</p><formula xml:id="formula_12">e(q, q d ) = ∑ cϵ{r,g,b} |I c (q) -I c (q d )| (<label>10</label></formula><formula xml:id="formula_13">)</formula><p>where I is the intensity value of pixel p in the reference image and I is the intensity value of pixel p d in the target image. HMI is a matching measure defined from the entropy of two images (their information content). It is a more robust measure against radiometric distortion that AD <ref type="bibr" target="#b4">[5]</ref>. The reader can find a detailed description of HMI in <ref type="bibr" target="#b4">[5]</ref>.</p><p>For what concerns disparity optimization (c), we use the simple winner-takes-all strategy (WTA). We obtain subpixel accuracy by fitting a parabola to the direct neighbors of the best disparity found <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Disparity refinement</head><p>In this paper, as depicted in Figure <ref type="figure" target="#fig_0">1</ref>, we also propose a novel combination of two existing disparity refinement techniques <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b9">[10]</ref>. The combination of these two techniques allows us to remove large errors and to enforce local consistency in the disparity results.</p><p>The intensity consistent (IC) disparity selection technique proposed in <ref type="bibr" target="#b4">[5]</ref> (Section 2.5.2), relies on segmentation and is particularly effective to solve the problem of propagation of disparities from textured foregrounds to untextured backgrounds as well as to assign disparities to large untextured regions, one of the major problems of local stereo matching algorithms.</p><p>The locally consistent (LC) disparity selection technique <ref type="bibr" target="#b9">[10]</ref>, by enforcing local consistency between neighboring points, has proven to be effective in recovering wrong disparity assignments in uniform regions as well near depth discontinuities. Nevertheless, this technique is unable to recover from large erroneous areas (i.e. the erroneous patches typically caused by homogeneous regions in the stereo pair). Therefore, we propose a disparity refinement pipeline in which the resulting disparity maps of linear stereo are refined with method <ref type="bibr" target="#b4">[5]</ref> to solve large erroneous areas, and then refined enforcing local consistency by means of <ref type="bibr" target="#b9">[10]</ref>.</p><p>A detailed description of these two disparity refinement techniques can be found in <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Accuracy comparison</head><p>In this Subsection we evaluate the performance of our proposal and the performance of constant time O(1) stereo matching <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> and adaptive-weight stereo matching <ref type="bibr" target="#b21">[22]</ref> according to the metric used in the Middlebury ranking <ref type="bibr" target="#b17">[18]</ref> and in <ref type="bibr" target="#b16">[17]</ref>. For the three algorithms we use our own C implementation. The parameters of the three algorithms are chosen according to an optimization process aiming at obtaining the minimum average percentage of erroneous pixels in the tested stereo dataset. In this Section we perform three different tests. The first uses colour stereo pairs for costs computation and grayscale stereo pairs for costs aggregation (the reason of this choice if the aforementioned intrinsic limitation of the constant time algorithms proposed by <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>, which due to memory limitations cannot be executed on colour images). In this case, the three algorithms are referred as G-LinearS, G-ConsT and G-AdaptW. The second test evaluates the performance of linear stereo and adaptive-weight with simple pre and post-processing techniques on colour stereo pairs (both for costs computation and costs aggregation). In this test, algorithms are referred as LinearS and AdaptW (we do not evaluate ConstT in this experiment because, as it was previously mentioned, it cannot be executed on colour images due to a very large memory footprint). Finally we perform a third test in which the algorithms in the second test are refined with the IC and LC techniques described in Subsection 4.2. Those algorithms are referred as P-LinearS and P-AdaptW.</p><p>The Middlebury stereo evaluation website ( <ref type="bibr" target="#b17">[18]</ref>) provides a standard way to evaluate the accuracy of the reconstruction by the percentage of bad pixels in the computation of four disparity maps using four stereo pairs named Tsukuba, Venus, Teddy and Cones (see Figure <ref type="figure" target="#fig_3">3</ref>). In fact, it is the implicit benchmark for stereo matching algorithms, as most papers evaluate their results according to these four stereo pairs.   We have evaluated constant time O(1) stereo matching according to the Middlebury benchmark and compared it with linear stereo and adaptive-weight. For a fair comparison, we use the same experimental setup used in the papers <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>: no pre or post-processing is implemented, colour stereo pairs are used for costs computation (AD matching metric), grayscale stereo pairs are used in the aggregation stage since the computation of the constant time algorithm using colour images requires a very large amount of memory that is not available in today's computers <ref type="bibr" target="#b6">[7]</ref>. The optimal set of parameter values used in this test is 35×35 aggregation window with γ p = 10 and γ c = 20 for G-AdaptW, 35 × 35 aggregation window with γ c = 9 for G-ConsT and ϵ = 10 -2.75 and r = 10 for G-LinearS. Under these circumstances, the results of G-ConsT <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>, G-AdaptW <ref type="bibr" target="#b21">[22]</ref> and the proposed G-LinearS are reported in Table <ref type="table" target="#tab_0">1</ref>. Table <ref type="table" target="#tab_0">1</ref> reports that G-AdaptW and G-LinearS outperform on the whole dataset G-ConsT. This can be explained observing that the constant time algorithm computes weights asymmetrically deploying only the reference image. On the other end, linear stereo and adaptive-weight deploy the reference and the target image. Table <ref type="table" target="#tab_0">1</ref> also reports that the performance of linear stereo performance is not as good as adaptive-weight on grayscale images with AD. Although the overall performance of G-AdaptW is better than G-LinearS, our proposal outperforms G-AdaptW in 6 out of 12 cases.</p><p>In Figure <ref type="figure" target="#fig_2">2a</ref>, the execution time of G-AdaptW, G-LinearS and G-ConsT on the Teddy stereo pair is represented versus the window size. Execution time measurements were performed on a Intel Core 2 6420 processor using only one core. It can be observed that the proposed G-LinearS algorithm is much faster than G-AdaptW and also it outperforms G-ConstT in terms of execution time. As proposed in <ref type="bibr" target="#b22">[23]</ref>, G-ConsT could be speeded up by quantizing the grayscale levels used for aggregation. However, according to the results presented in <ref type="bibr" target="#b22">[23]</ref>, the accuracy of the algorithm would further decrease, being a much less accurate algorithm than G-AdaptW or G-LinearS.</p><p>In order to provide a more detailed comparison of linear stereo and adaptive-weight, we evaluate their performance according to the Middlebury benchmark using colour images both for costs computation and costs aggregation. Experimentally we found that for both algorithms preprocessing the input images with a 5 × 5 bilateral filter <ref type="bibr" target="#b19">[20]</ref> with parameters σ c = 10 and σ s = 10 only for costs aggregation provides optimal results. Moreover we postprocess the resulting disparity maps of both algorithms applying cross-checking, a 3 × 3 median filtering to the resulting disparity maps and eliminating constant disparity blobs smaller than 80 pixels. The disparities in these invalidated areas are filled in with the content of the first noninvalidated pixel to the left or to the right (according to the nature of the occlusion). For both algorithms we use the optimal set of parameters empirically found, 35 × 35 aggregation window with γ p = 26 and γ c = 6 for AdaptW and ϵ = 10 -4 and r = 9 for LinearS. HMI with σ = 1 is implemented for costs computation, as it produces better results than AD. Table <ref type="table" target="#tab_1">2</ref> reports the experimental results for linear stereo (LinearS) and adaptive-weight (AdaptW) according to this setup. The resulting disparity maps are shown in Figure <ref type="figure" target="#fig_4">4</ref>.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows that AdaptW produces slightly better results than LinearS. However, we can observe more significant differences on the discontinuity regions of Venus and Teddy. Despite this small difference, it is worth noting that the complexity of the costs aggregation step of linear stereo is independent of the window size. According to Figure <ref type="figure" target="#fig_2">2b</ref> LinearS outperforms AdaptW in terms of execution time. Moreover, this advantage grows when the size of the support is increased.</p><p>To test the effectiveness of the disparity refinement technique proposed in Section 4.2, we perform a third experiment with LinearS and AdaptW implemented as described previously in this paper, deploying the disparity refinement step. These algorithms are referred as P-LinearS and P-AdaptW. For IC, the parameter values proposed in <ref type="bibr" target="#b4">[5]</ref> are used. For LC, the chosen values are a 39 × 39 window with γ s = 22, γ c = 23, γ m = 5 and T = 60 for P-LinearS and a 39 × 39 window with γ s = 13, γ c = 35, γ m = 8 and T = 50 for P-AdaptW. The results of these algorithms can be found in Table <ref type="table" target="#tab_1">2</ref>. The resulting disparity maps are reported in Figure <ref type="figure" target="#fig_6">5</ref>. Comparing the non refined (LinearS and AdaptW) and the refined (P-LinearS and P-AdaptW) versions of the algorithms, the results are notably improved showing that the disparity refinement pipeline is very effective. The disparity refinement pipeline is more ef-fective for the LinearS algorithm, since we can observe that the results of P-LinearS and P-AdaptW are very similar (P-LinearS even outperforms P-AdaptW in 5 out of 12 results).</p><p>Observing the overall results, the proposed P-LinearS method has results comparable to state-of-the-art algorithms according to the Middlebury ranking <ref type="bibr" target="#b17">[18]</ref> <ref type="foot" target="#foot_0">1</ref> . The complete proposed pipeline is composed of a local stereo matching algorithm whose execution time is independent of the size of the window (15 seconds for Tsukuba and 94 seconds for Teddy) and a disparity refinement step based on the intensity consistent technique (IC) <ref type="bibr" target="#b4">[5]</ref> (which runs in 10 second on Tsukuba and 30 seconds on Teddy) and the locally consistent technique (LC) <ref type="bibr" target="#b9">[10]</ref> (which takes 8 seconds for Tsukuba and 20 seconds for Teddy). Execution time has been measured in our own implementation of both methods. However, both techniques as well as the proposed linear cost aggregation method could be implemented much more efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Scalability</head><p>The time measurements described in the previous Subsection are associated to the execution of algorithms using the Middlebury stereo pairs. The most time consuming stereo pairs in the Middlebury dataset are Teddy and Cones (450×375 resolution and 60 possible disparities). However, these two stereo pairs were obtained downsampling the original 1800×1500 images (240 disparities). Although the Middlebury benchmark uses relatively low resolution images, images of larger size are already quite common nowadays. When the resolution of the input stereo pairs is increased, the size of the aggregation window must be increased accordingly using the same scale factor. As a consequence, the use of O(1) aggregation techniques becomes even more advantageous. In Figure <ref type="figure" target="#fig_7">6</ref>, it can be observed how the execution time ratio of AdaptW and LinearS increases as the resolution of the input stereo pair is increased. For a resolution of 1800×1500 pixels and 240 disparity levels, LinearS is around 50 times faster than AdaptW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we propose a new O(1) costs aggregation method based on a linear model. Compared to existing O(1) methods, our proposal does not rely on the Porikli's method <ref type="bibr" target="#b12">[13]</ref>. To our knowledge, it is the first O(1) costs aggregation method which relies on a symmetric strategy. Moreover, unlike previous O(1) algorithms, aggregation based on colour images can be performed with a reasonable computational cost. Thanks to these two improvements (symmetric and colour-based aggregation) our linear stereo algorithm clearly outperforms previous O(1) stereo algorithms    in terms of accuracy of the results. Not only our algorithm outperforms previous O(1) solutions, but experimental results show that the proposed method produces accurate dis-parity maps comparable to those of adaptive-weight aggregation. However, compared to the adaptive-weight aggregation approach, our proposal has a computational complexity independent of the size of the window.</p><p>In this paper we have also proposed a disparity refinement strategy based on a combination of two already existing techniques. Each one of the techniques aim at solving common problems that arise in local stereo algorithms. The combination of these techniques provides, according to the Middlebury ranking, a notable improvement in accuracy of the resulting disparity maps. In fact, the overall proposed algorithm provides disparity maps comparable to state-ofthe-art algorithms.</p><p>Finally, it has been proven that the O(1) nature of the algorithm makes it highly scalable for future applications using higher resolution stereo pairs. According to our tests, for high resolution images, our algorithm is around 50 times faster than adaptive-weight based stereo matching.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Structure of the proposed linear stereo algorithm and the disparity refinement pipeline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Execution time of the studied algorithms on the Teddy stereo pair using: (a) grayscale images and (b) colour images for aggregation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Left image of each one of the Middlebury datasets. (a) "Tsukuba" images. (b) "Venus" images. (c) "Teddy" images. (d) "Cones" images.</figDesc><graphic coords="7,307.08,256.99,83.86,69.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Disparity maps computed by LinearS (upper row) and AdaptW (lower row). (a) "Tsukuba" images. (b) "Venus" images. (c) "Teddy" images. (d) "Cones" images.</figDesc><graphic coords="7,307.08,472.06,83.86,69.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Disparity maps computed by P-LinearS (upper row) and P-AdaptW (lower row). (a) "Tsukuba" images. (b) "Venus" images. (c) "Teddy" images. (d) "Cones" images.</figDesc><graphic coords="7,307.08,545.61,83.86,69.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Execution time ratio of AdaptW and LinearS versus the sampling factor of the Teddy stereo pair (original resolution 1800×1500 pixels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison of aggregation methods using colour images for costs computation and grayscale images for costs aggregation and no pre or post-processing.</figDesc><table><row><cell>Average</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison of aggregation methods using colour images for costs computation and costs aggregation, pre and postprocessing.</figDesc><table><row><cell>Average</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>February</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_1"><p>rd 2011 our P-LinearS algorithm classifies in position number 15 in the Middlebury ranking.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Summed-area tables for texture mapping</title>
		<author>
			<persName><forename type="first">F</forename><surname>Crow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Special Interest Group on Graphics</title>
		<meeting>Special Interest Group on Graphics</meeting>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="217" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A performance study on different cost aggregation approaches used in realtime stereo matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="296" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Single image haze removal using dark channel prior</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Workshop Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1956" to="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Guided image filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stereo processing by semiglobal matching and mutual information</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hirschmüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local stereo matching using geodesic support weights</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl Conf. on Image Processing</title>
		<meeting>IEEE Intl Conf. on Image essing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2093" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Constant time stereo matching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Image Processing Conf</title>
		<imprint>
			<date type="published" when="2005">2009. 1, 2, 3, 4, 5</date>
			<biblScope unit="page" from="13" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust matching by partial correlation</title>
		<author>
			<persName><forename type="first">R.-D</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf</title>
		<meeting>British Machine Vision Conf</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="651" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A closed-form solution to natural image matting</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="242" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A locally global approach to stereo correspondence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop on 3D Digital Imaging and Modelling</title>
		<meeting>IEEE Int. Workshop on 3D Digital Imaging and Modelling</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Accurate and efficient cost aggregation strategy for stereo correspondence based on approximated joint bilateral filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gambini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="371" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A fast approximation of the bilateral filter using a signal processing approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="52" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Constant time o(1) bilateral filtering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detection of binocular disparities</title>
		<author>
			<persName><forename type="first">K</forename><surname>Prazdny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="93" to="99" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast cost-volume filtering for visual correspondence and beyond</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dodgson. Real-time spatiotemporal stereo matching using the dual-cross-bilateral grid</title>
		<author>
			<persName><forename type="first">C</forename><surname>Richardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. Computer Vision</title>
		<imprint>
			<publisher>Springer Berling / Heidelberg</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6313</biblScope>
			<biblScope unit="page" from="510" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A taxonomy and evaluation of dense two-frame stereo correspondence algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="7" to="42" />
			<date type="published" when="2002">2002. 1, 3, 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Middlebury stereo evaluation -version 2</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<ptr target="http://vision.middlebury.edu/stereo/eval.2" />
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Computer vision: algorithms and applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010. 1, 2, 3</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl Conf. on Computer Vision</title>
		<meeting>IEEE Intl Conf. on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Classification and evaluation of cost aggregation methods for stereo correspondence</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Stefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Addimanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptive support-weight approach for correspondence search</title>
		<author>
			<persName><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="650" to="656" />
			<date type="published" when="2005">2006. 1, 2, 3, 4, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint integral histograms and its application in stereo matching</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lafruit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lauwereins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intl Conf. Image Processing</title>
		<meeting>IEEE Intl Conf. Image essing</meeting>
		<imprint>
			<date type="published" when="2006">2010. 1, 3, 4, 5, 6</date>
			<biblScope unit="page" from="817" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-sensor super resolution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Applications of Computer Vision</title>
		<meeting>IEEE Workshop Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="27" to="31" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
