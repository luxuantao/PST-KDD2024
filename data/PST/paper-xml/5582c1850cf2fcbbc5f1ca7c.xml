<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A4015B3DDF9183E5212575B37C1100EE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Silicon Retina with Correlation-Based, Velocitv-Tuned Pixels Tobias Delbriick</p><p>Abstract-I report the first functional two-dimensional silicon retina that computes a complete set of local direction-selective outputs. The chip motion computation uses unidirectional delay lines as tuned filters for moving edges. Photoreceptors detect local changes in image intensity, and the outputs from these photoreceptors are coupled into the delay line, where they propagate with a particular speed in one direction. If the velocity of the moving edges matches that of the delay line, then the signal on the delay line is reinforced. The output of each pixel is the power in the delay line signal, computed within each pixel. This power computation provides the essential nonlinearity for velocity-selectivity. The delay line architecture differs from the usual painvise correlation models in that motion information is aggregated over an extended spatiotemporal range. As a result, the detectors are sensitive to motion over a wide range of spatial frequencies.</p><p>I have designed and tested functional one-and two-dimensional silicon retinas with direction-selective, velocity-tuned pixels. A velocity-selective detector requires only a single delay element and nonlinearity for each tuned velocity, and is sensitive to both light and dark contrasts. The use of adaptive photoreceptors and compact circuits makes for a well-conditioned input signal and small circuit offsets, resulting in robust operation. All circuits work in subthreshold, resulting in low power consumption. Pixels with three hexagonal directions of motion selectivity are approximately (225 pm)' area in a 2-pm CMOS technology, and consume less than 5 pW of power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. ANALOG HARDWARE MOTION COMPUTATION</head><p>N this introduction, I place the new chip in the 'context I of previous approaches to analog-hardware visual motion computation. Essentially, there are two approaches: Those that use spatiotemporal image gradients, and those that use spatiotemporal image correlation. Hardware systems that utilize each approach has been previously built. This chip reported here falls into the second category.</p><p>Tanner and Mead built the first analog two-dimensional optical-flow chip [35], <ref type="bibr" target="#b36">[36]</ref>, <ref type="bibr">[30]</ref>. The Tanner chip computes a single motion vector for the global two-dimensional optical flow, using a gradient-based scheme (for references, see [28]).</p><p>The motion vector is computed cooperatively by a network of circuits, each circuit using local spatiotemporal derivative information. The circuits reach a consensus on the global image motion vector, using the overall constraint that the total derivative of the image intensity is zero. This constraint allows The two-dimensional direction-selective chip built by Benson and Delbriick <ref type="bibr" target="#b4">[5]</ref> performs a different and much simpler computation that is based on biological studies. The pixel outputs respond selectively to local rightward motion, and the motion computation is feedforward, rather than cooperative. The architecture is based on the idea of null-inhibition direction selectivity, developed by Barlow and Levick [4] to explain the direction selective responses found in rabbit retinas. In a null-inhibition model, the pixel output is inhibited by edges coming from the null-direction. In the preferred direction, the pixel output in response to an edge is not inhibited, because the inhibition arrives after the excitation.</p><p>I distinguish the value-encoded global velocity-vector output of the Tanner chip, from the place-encoded, directionselective, velocity-tuned outputs of the Benson-Delbriick chip. The computations are qualitatively different, because one encodes the pattern velocity as a vector with magnitude and direction, and the other encodes the motion of features by the location of active outputs. The Tanner chip does a higher-level computation, integrating spatiotemporal image information from the entire moving image in a cooperative calculation, whereas the Benson-Delbriick chip simply responds selectively to rightward versus leftward motion.</p><p>The operation of the Tanner chip is not robust, perhaps because of the demands of the mathematically sophisticated motion algorithm it implements. High-contrast images, with sharp edges, are required if the chip is to produce a directionselective output, and the precision of the velocity measurement is poor. The reason for this nonideal performance is the combination of inherent susceptibility of gradient-based schemes to temporal and spatial noise, low-sensitivity receptors, and large circuits with poor offset characteristics. The strongest signals are derived from places in the image with sharp gradients and high contrasts, but gradient-based schemes require images with smoothly varying contrast if they are to obtain reliable estimates of spatial and temporal derivatives. The performance of the chip is compromised severely by these conflicting requirements.</p><p>The operation of the Benson-Delbriick chip is robust in comparison with that of the Tanner chip, because the Benson-Delbriick chip, unlike the Tanner chip, responds correctly to real input scenes of moderate contrast. There are several reasons for this performance difference. The algorithm is much simpler, the circuits are more compact and hence less offset prone, and a well-conditioned input is generated by the 1045-9227/93$03.00 0 1993 IEEE use of adaptive photoreceptors. However, this comparison is arguable pointless, given the major differences in computation performed by the two chips.</p><p>The null-inhibition architecture has the advantage of a large degree of direction-selectivity and hence, inherently robust operation. The disadvantage is that it is difficult to produce a response-versus-speed tuning that is other than a simple lowpass determined by the pixel spacing, so construction of a set of detectors tuned to different speeds is not straightforward. Moreover, this architecture does not deal with the aperture problem, and, in fact, knows nothing of global motion constraints.</p><p>The chip described here has place-encoded outputs that encode information about components of local edge motion along the detector directions, like the Benson-Delbruck chip. It is also like the Benson-Delbriick chip in that the motion computation does not deal with solving the aperture problem. It is like the Tanner chip in that the computation integrates information over an extended spatiotemporal region. Our chip is the first functional analog device that computes a full set of local direction-selective outputs in two dimensions. It is also the first reported chip that uses correlation-based analog computation to produce direction-selective, velocitytuned outputs. (Reference [22] reports a correlation-based one-dimensional motion circuit that correlates digital pulses, produced by image intensity changes, in analog time.) The remainder of this paper is organized as follows.</p><formula xml:id="formula_0">I</formula><p>Section I1 is a heuristic description of correlation motion detectors, and of the delay line motion architecture in one and two dimensions. Section I11 describes a mathematical model of the circuit operation in the time and frequency domains, and investigates the model to understand the limiting behavior, and the differences between the new model and previous pairwise correlation detectors. Section IV is a description of the circuits used in the chip. Section V is about qualitative and semiquantitative measurements on the two-dimensional motion chip, and quantitative measurement on the onedimensional chip. Section VI and Section VI1 conclude the paper with a short discussion of future direction of this work and a summary of the results.</p><p>[321.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">CORRELATION-BASED MOTION DETECTORS</head><p>The simplest correlation-based motion detector is shown in Fig. <ref type="figure">l(a)</ref>. A pair of spatially separated, feature-detecting cells feed into a nonlinearity that detects coincidence of the two inputs. One of the inputs to the nonlinearity is delayed. When the motion is matched to the detector spatial separation and delay, the output becomes large. The nonlinearity, although often formulated as a multiplicative operation, can be any </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Extension of the Simple Correlation Detector</head><p>My motion architecture extends the pairwise correlation model in Fig. <ref type="figure">l(a)</ref>, by using a unidirectional delay line as a tuned filter for a particular velocity, as shown in Fig. <ref type="figure">l(b)</ref>. The input to the delay line comes from photoreceptors that respond to local intensity change. The photoreceptor outputs are coupled capacitively into the delay line. The delay line is composed of low-pass filters. An edge passing over a photoreceptor creates a traveling signal in the delay line that spreads and decays with time. If the velocity of the edge is matched to that of the delay line, the successive inputs to the delay line pile up in synchrony. If the input velocity is not matched to the delay line velocity, the successive inputs arrive in asynchrony and do not pile up.</p><p>It is well known that the time-averaged output of a linear system cannot be direction or speed dependent. In a linear system, we can alter the time order of the input without changing the time-averaged output, because the response to a sum of inputs is the same as the sum of the responses to each input individually. Hence, the average signal on our delay line is not velocity selective. The amplitude of the signal clearly is velocity selective. Measuring amplitude is a nonlinear operation. We can use any nonlinearity that measures some metric of the amplitude of the delay line signal, and the result will be direction and speed selective. On my chip, I use a compact circuit that computes an approximate squaring function of the delay line signal. Hence, the nonlinearity approximately measures the filter output power.</p><p>The nonlinear operation is an even function of its input, so the delay line activities caused by edges of light and dark contrasts are both detected. A single nonlinearity, and a single delay line, are sufficient to compute as direction-selective, velocity-tuned response for either sign of image contrast.</p><p>The delay line architecture is robust against noise, because a particular output integrates information from an extended spatiotemporal range of the moving image. This feature is shared with the human visual system 1311.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Two-Dimensional Architecture</head><p>In the two-dimensional chip, I use a hexagonal architecture that encodes any possible direction of motion using three directions (Fig. <ref type="figure" target="#fig_3">2</ref>). Each pixel computes the response to three principal directions of motion. Since the three directions are nonorthogonal, any direction can be represented by weighted combinations of the three nonnegative outputs. This basis set may be familiar from the representation of color space by a set of three primary colors. In an orthogonal architecture, we would need four principal directions, each with nonnegative output, to represent an arbitrary direction of motion, or, equivalently, two bidirectional outputs.</p><p>Each pixel contains a single photoreceptor, three delay elements, and three output nonlinearities. The three outputs are scanned out and are displayed on a monitor as three different colors, through use of a scanning frame, as described in <ref type="bibr">[29]</ref>. The Reichardt detector uses differencing of complementary directions to reduce common-mode responses. In the twodimensional motion chip, I use an analogous scheme to increase the contrast between the three channels of output that is computed serially by the video driver circuits. This linear differencing operation does not do any additional information processing, so I will not discuss it further.</p><p>The aperture problem arises in any two-dimensional motion computation. A local edge-based measurement can measure only the component of edge motion orthogonal to an edge, and cannot measure motion along the edge. Another and more general way of stating this fact is that local measurements constrain the estimate of the actual pattern movement. An array of detectors measures a set of motion vectors, each member of which is consistent with the movement of the pattern as a whole. The different detectors, however, may disagree in their assumptions about the component of motion along their local edges. The global motion vector is the vector that most closely agrees with the set of constraints imposed by the local measurements. The Tanner chip ingeniously solves the constraint problem in a cooperative manner.</p><p>The delay line motion architecture does no global computation to reconcile local measurements, so the best that it can do, in principle, is the computation of the local motion vectors. In the present architecture, these quantities are computed such that they are consistent with the observed motion, but there is no built-in assumption that the measured motion is only orthogonal to the edge. The nonintuitive feature is that the motion that is consistent with the observed set of outputs may not be orthogonal to the edges. The reason is that a detector is sensitive to only spatiotemporal correlation along its preferred direction. An edge moving at a speed S in a direction oblique to the preferred direction, with angle 0, causes apparent motion along the preferred direction with speed S/cos 0 (Fig. <ref type="figure" target="#fig_4">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">THEORETICAL ANALYSIS OF MOTION CIRCUIT</head><p>To understand the properties of our model, and to derive results that can be verified experimentally, we shall analyze the one-dimensional motion circuit in both the time and frequency domains. The time-domain analysis is more intuitive. The frequency-domain analysis is more useful for comparison with measurement, and for understanding the response of the system to variations in stimulus parameters, such as velocity and spatial frequency. The nonlinearity is a simple feedforward operation done on the delay line signal, so our analysis will concentrate on the linear delay line. Some of the symbols used in this section are shown in Fig. <ref type="figure" target="#fig_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Time-Domain Analysis</head><p>We shall compute the delay line response to a single moving bright edge. To do this calculation, we compute the transfer function from photoreceptor to delay line, and the transfer function of an n-stage delay line. Combining these two transfer functions, we obtain the complete transfer function between the input and the delay line output n stages later. Using the transfer function, we compute the step response. The response to a moving edge is a sum over the temporally shifted step responses produced by the edge at successive receptors.</p><p>The photoreceptor outputs are coupled capacitively into the follower-integrator delay line section. Hence, the transfer function from receptor to delay line is the single high-pass filter  <ref type="figure" target="#fig_12">9</ref>). The delay line-a chain of n first-order, buffered, low-pass filters-has the transfer function:</p><p>We obtain the transfer function from photoreceptor input 0 to delay line output n by multiplying Hn and Hi,. By computing the inverse Laplace transform, we find that the time response at the nth delay line tap to a bright intensity step at the first</p><formula xml:id="formula_1">photoreceptor at time t = 0 is r,(t) = ; (<label>(3)</label></formula><p>for t &gt; 0. For n = 0, this function is a step-increase from 0 to 1, followed by a decaying exponential. For n = 1, this function is an initially linear increase from 0, followed by the same decaying exponential. In general, (3) represents a wave packet that travels along the delay line, one stage per time. r. Asymptotic analysis shows that as n grows large, the response approaches a Gaussian shape with constant area.</p><p>The width of the Gaussian broadens as fi, and the height decreases as 1 / 6 . Note that the stimulus is a step-input at the photoreceptor that is high-pass filtered by the capacitive coupling to the delay line.</p><p>A motion stimulus causes a succession of inputs to the delay line, where the time delay AT between excitation of successive stages is</p><formula xml:id="formula_2">L A T = - S (<label>4</label></formula><formula xml:id="formula_3">)</formula><p>where L is the spatial separation between detectors, and S is the velocity of the moving pattern. Since the delay line is a linear system, the response to a moving bright edge is the superposition of the responses to the edge passing over all the contributing inputs. We define R,(t) to be the delay line response at tap n, in response to a moving bright edge that passes over the first input at time t = 0. It is easy to compute is shown in (b) and (d). In (a) and @), the edge travels at the natural speed of the delay line. In (c) and (d), the edge travels at one-half the speed of the delay line. When the bar motion is matched to the delay line speed, the successive inputs pile up, in response either to the bright or the dark edge. The nonlinearity rectifies B, (t), so both edge contrast appear as a positive output.</p><p>When the motion is not matched, the successive inputs arrive in asynchrony with the delay line signal, and the resulting output is smaller.</p><p>.</p><formula xml:id="formula_4">.. n R,(t) = ~( t -( n -k)AT) .</formula><p>(</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) k=O</head><p>We have assumed that either the delay line or the motion starts at tap 0. Fig. <ref type="figure">4</ref>(a) and (c), show a graphical representation of the linear delay line response to a bright bar moving over the delay line at the optimum velocity and at one half of the optimum velocity. The bright edge causes positive activity, and the dark edge causes negative activity. Both signs of edgecontrast information travel along the delay line with a fixed speed and direction, though the activity has opposite polarity for the two edges. When the edge motion is matched to the speed of the delay line, the activity on the delay line piles up maximally. We can see how, in this linear system, the integrated response is unaffected by the stimulus velocity, even though the activity has larger peak magnitude when the motion is matched to the delay line speed. The longer the motion continues, the larger the peak activity. Saturating nonlinearities eventually limit the response of the delay line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Antibump Output Nonlinearity</head><p>The antibump output-nonlinearity-circuit used in the motion chips computes the function ( <ref type="formula">6</ref>)</p><formula xml:id="formula_5">Ib 1 + sech2x N ( x ) =</formula><p>where Ib is the bias current, x is the input voltage in units of approximately ( 2 k T / q ~) M 70 mV, and w M 20 is a geometrical layout parameter <ref type="bibr">[ l l</ref> ] . The output is a current. The shape of this function is shown in Fig. <ref type="figure" target="#fig_7">5</ref>. The output is parabolic for small input, and saturates at the adjustable bias current. The width of the valley region in subthreshold is determined by layout geometry. The valley width can be increased by using an above-threshold bias current.</p><p>The output from the motion circuit is the nonlinearity (6) applied to the signal on the delay line. In response to the moving edge signal R,(t) on the delay line, the velocity-tuned outputs are N ( R , ( t ) ) . Fig. <ref type="figure">4</ref>(c) and (d) show the response to the same moving bright bar after the nonlinearity is applied. We can see how the nonlinearity makes both the peak and integrated responses strongly velocity selective, and also how the even characteristic of the nonlinearity results in equivalent detection of both bright and dark edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Frequency-Domain Analysis</head><p>In the frequency domain, the stimulus is a one-dimensional sinusoidal variation in contrast, with wavelength X and velocity S (Fig. <ref type="figure" target="#fig_8">6</ref>). If the velocity is constant, then each input to the motion array is a simple sinusoidal function of time with the same temporal frequency</p><formula xml:id="formula_6">27rs x w = -<label>(7)</label></formula><p>at each input. The signal at a particular tap of the delay line is a sum over all the contributing inputs. Each input is first phase shifted by the spatial separation, and then phase shifted again by the filtering in the low pass delay line stages. The delay line signal is a pure sinusoidal function of time, with the same temporal frequency at each tap, multiplied by the transfer function for that tap.</p><p>The pattem phase shift of the input signal between each pixel, due to the pixel spacing and the sinusoidal spatial variation of image contrast, is</p><p>27r L X q = -. Each stage of the delay line is separated by a low-pass filter, with transfer function</p><formula xml:id="formula_8">I i w r + 1 (<label>9</label></formula><formula xml:id="formula_9">)</formula><p>Each input is a single high-pass filter, with transfer function i w r i w r + I '</p><p>We obtain the complete transfer function for tap n by summing the inputs from taps 0 though n, resulting in where we have factored out the high-pass filter common to each stage. The summation in (11) is a geometric series, SO we can write the transfer function explicitly for an arbitrary number of stages:</p><formula xml:id="formula_10">, n l l</formula><p>This expression represents a phasor that rotates about the complex origin at a frequency w. The physically measurable part of the expression is the projection of (12) onto any axis in the complex plane, and is much more complicated than is (12).</p><p>The average signal on the delay line in response to a sinusoidal input pattern is zero, regardless of the velocity. The length of the phasor, however, is strongly direction and velocity selective. To obtain a response that is tuned for velocity requires a nonlinear operation that measures the length-on some metric-of the phasor. The delay line signal is fed into the antibump nonlinearity, which computes a squaring operation for small input signals. In explicit mathematical form, the time-dependent velocity-tuned output is O,(t,w) = N(IH,(w)eiwtI)</p><p>where N is the antibump nonlinearity in (6). Hence, the operation in ( <ref type="formula">13</ref>) is proportional to the squared absolute transfer function, for low-contrast stimuli.</p><p>We can learn about the behavior of the system by studying the amplitude of the linear transfer function (12)-that is, the length of the phasor. We shall examine the case of a seveninput system. In Fig. <ref type="figure" target="#fig_9">7</ref>, I have plotted the phasor at the seventh tap, HG(w), in response to the motion of a sinusoidal pattern in the preferred and null directions. The speed of the motion, in each case, is near the optimum speed for the preferred direction. Each phasor is shown as a number of adjoining line segments; each of these components is the contribution of one pixel input to the complete phasor.</p><p>When the grating moves in the preferred direction at the optimum speed, the phasor is as long as it can be, given an input pattern of a given amplitude and wavelength, because the components all point in nearly the same direction. They all point in the same direction because, for each input, the total pattern-phase-shift and the total low-pass-filtering-phase-shift match. There is also an overall rotation of the entire phasor, due to the high-pass filtering at each input to the delay line.</p><p>In contrast, when the pattern moves in the null direction, the phasors sum destructively, and the resultant phasor curls up on itself. The complete phasor is short, no matter how many inputs are combined, because the components always approximately cancel one another. The length of the phasor, as a function of the speed of the motion, has wiggles, corresponding to the periodic behavior of the destructive cancellation. (These wiggles can be seen in the experimental data shown in Fig. <ref type="figure" target="#fig_7">15</ref> and Fig. <ref type="figure" target="#fig_17">17.</ref>)</p><p>Many of the correlation-based direction-selective models in the literature correspond to a two-input ( n = 1) version of this system. Hence, it is interesting to compare the case of a two-input system with a system that is effectively infinitely long. We shall first derive the mathematical behavior for each system, and then contrast the two systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I ) Long System:</head><p>The explicit form of the transfer function for an infinite number of stages is given by (12) with n + 00:</p><p>(Note that this transfer function includes the high-pass input to the delay-line.) By examining the behavior of the n-dependent term in the numerator of (12), we can determine that this limiting form is accurate as long as the following condition holds: n &gt; ( $ ) 2 <ref type="bibr">(15)</ref> This restriction seems severe, but examination of the measured tuning curves shows that, in practice, there are only scale differences in the responses after the first few taps. We shall examine the behavior of ( <ref type="formula">14</ref>) to understand how it is affected by spatial wavelength.</p><p>Since the numerator of ( <ref type="formula">14</ref>) is 1, we can find the maximum value of the response by minimizing the absolute value of the denominator. This simple computation reveals that the maximum value of IHoo(w)l occurs at </p><formula xml:id="formula_11">2 (1-cosp) W m a x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>27~</head><p>TI-sincp For long wavelengths, p = 2.rrL/X is small, and we find the peak tuning occurs at the frequency corresponding to the speed which is reassuring, since this optimum speed corresponds with the intuitive idea that optimum motion is motion matched to the delay-line speed. The optimum speed is invariant with wavelength, for wavelengths longer than a few pixel spacings. This result is also surprising, because correlation models do not generally display this invariance. We can see how this behavior comes about by examining the limiting case of a long wavelength. As we increase the wavelength A, we decrease the pattern phase shift p between pixels. (The pattern phase shift is the phase shift of the input, between adjacent pixels, just due to the wavelength of the pattern). The response maximum does not move, because the decrease in p is compensated by a decrease in low-pass phase lag due to decreased frequency w in the low-pass filter.</p><p>The first-order, low-pass phase lag cannot become greater than 90". Eventually, as we decrease wavelength, pattern phase shift decreases faster than does the low-pass phase lag. To compensate, the pattern must move faster to obtain an increased phase lag from the low-pass filter. Hence, the shorter the wavelength, the higher the optimum speed. In fact, when X = 2L, the optimum velocity approaches infinity. This limit corresponds to the Nyquist sampling criterion-the spatial frequency pattern is sampled twice per cycle by the array. The trend toward higher optimum speed with shorter wavelength is visible in the experimentally measured velocity tuning curves in Fig. <ref type="figure" target="#fig_17">17</ref>.</p><p>At the optimum velocity, in the limit X &gt;&gt; L, the squared magnitude of the transfer function takes the value</p><formula xml:id="formula_12">lK"w)l;max =<label>(20)</label></formula><p>Hence, the squared magnitude of the response at the optimum speed goes as the square of the wavelength, independent of the optimum speed. At low speeds, w &lt;&lt; 117, and the squared magnitude of the transfer function is given by Hence, for low speeds, the squared magnitude of the response is proportional to the square of the speed and invariant to wavelength. (The apparently conflicting results in (19), (20) and (21) are actually not conflicting, because the assumption that leads to (21) breaks down at S, , . ) 2) Two-Input System: As stated earlier, the two-input system is similar to existing correlation-based direction-selective detectors. Let us now consider the behavior of a two-input system in the same way we just did for the effectively-infinite delay line system. For two inputs, (12) becomes We will form a particular instantiation of the painvise We can think of this detector as the difference between two time-averaged painvise detectors, like the one shown in Fig. <ref type="figure">l</ref>(a), with opposite direction selectivities. The commonmode terms have canceled. The tuning is separable into a temporal and a spatial product. Hence, we can immediately deduce that the optimum response occurs at a particular temporal frequency, and not at a particular velocity. The painvise detector is not a velocity-selective filter, but rather is a temporal-frequency-selective filter whose response is modulated by the geometrical interference term sin cp, familiar from the fly literature (see, for example, [7]) We can find the optimum temporal frequency w, , for the two-input system in the same way that we found S,,</p><p>for the infinite delay line. Independent of wavelength, the maximum of (23) occurs at the temporal frequency in Fig. <ref type="figure" target="#fig_17">17</ref>. Table I lists these theoretical results. In summary, the delay line architecture differs from the painvise detectors in that it is sensitive to stimuli with low as well as high spatial frequencies. The pairwise detector, because of the locality of the computation, cannot be very selective for w, ,</p><p>= &amp; I T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(24)</head><p>For low speeds, the temporal frequency is small compared with 117, and we compute the response (23) as approximately motion of patterns with long wavelengths. The delay-line detector, in contrast, aggregates information over a spatial range corresponding to an arbitrarily-long wavelength, and hence can retain direction and speed selectivity even for longwavelength patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IH1(w)l2 -IH1(-w)I2 = 4 ( ~r ) ~s i n c p . (25)</head><p>Hence, the response to slow motion depends on the wavelength through the sin9 term, and is cubic in the speed.</p><p>Fig. <ref type="figure" target="#fig_11">8</ref> compares the theoretical transfer function amplitudes for the two-input system and the long system cases. Note that in this figure, we compare IH, I with IH11, rather than with the Reichardt detector in (23). In the two-input system, the optimum speed is proportional to wavelength (in accordance with (24)), but the amplitude of the response at the optimum speed is relatively variant to wavelength. In the long system, the optimum speed and the low-speed response are invariant to wavelength, but the amplitude of the response at the' optimum speed is proportional to wavelength. We can also see these characteristics in the measured tuning curves shown</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Iv. THE MOTION CIRCUIT</head><p>The circuit for a single stage of the motion circuit is shown in Fig. <ref type="figure" target="#fig_12">9</ref>. The output from an adaptive, high-gain, logarithmic photoreceptor circuit is coupled capacitively into a delay line state. The delay line consists of a line of buffered, firstorder, low-pass filters, implemented on the chips with follower integrators. The output nonlinearity is implemented with an antibump circuit.</p><p>The adaptive photoreceptor is essential for the robust operation of the circuit, because it provides well-conditioned input to the delay line over a wide range of lighting conditions. The receptor circuit has been reported previously <ref type="bibr">[lo]</ref>, of the photoreceptor circuit goes as follows. The input leg of the receptor, consisting of the phototransistor and the sourcefollower feedback transistor, forms a signal voltage that is logarithmic in the intensity. The feedback circuit amplifies the logarithmic signal, and centers the operating point of the output signal around the history of the The timeaveraged output signal is stored on the feedback capacitor and serves as the reference around which the response is computed. The pair of diode-connected transistors act as a resistor-like adaptive element with monotonic I -V characteristic. The use of adaptation makes for a receptor with simultaneous high sensitivity and wide dynamic range.</p><p>The output from the adaptive photoreceptor connects to the input of a source follower amplifier that buffers the output of the receptor. Different directions of selectivity use separate buffers that share the common photoreceptor input. The source follower isolates different directions in the case of a motion network with more than a single direction of selectivity. A separate source-follower is used for each direction. The sourcefollower output can follow a decreasing input signal only as fast as the bias current can discharge the output. It can follow increasing signals at an arbitrary rate, determined by the input voltage. By biasing the follower strongly (i.e., turning up Va), we ensure that the source-follower output can follow accurately both increasing and decreasing outputs from the photoreceptor.</p><p>The follower-integrator uses a simple five-transistor transconductance amplifier [30]. These simple transconductance amplifiers suffer from systematic offset of several millivolts, due to Early-effect drain conductance in the differential pair and in the current mirror. Over a 25-stage delay line, the offset can be more than 100 mV. Since we compute the output of the pixel relative to a fixed reference voltage Kef that is the input to the first stage of the delay line, this offset is important. we set Vref near Vdd, so that the differential pair and the current mirror are both balanced. The speed of the delay line, and hence of the velocity tuning, is set by the bias T of the transconductance amplifier. The voltage on the delay line connects to the input of an antibump circuit <ref type="bibr">[ll]</ref>. The other input to the antibump circuit connects to the reference voltage Vref. If any activity on the delay line pushes the voltage away from Vref, either in the positive (bright-edge) or in the negative (dark-edge) direction, the output current becomes larger, thus computing the power-like measurement of the linear delay line signal. Details of the antibump circuit operation are given in [ll]. In brief, the antibump circuit works because the center leg of the circuit, consisting of the series-connected transistors marked with Q in Fig. <ref type="figure" target="#fig_12">9</ref>, turns off when the differential input voltage is sufficiently large, forcing the bias current to flow through the outer legs of the circuit.</p><p>The delay line architecture for this circuit was inspired by an earlier architecture for sound synthesis of visual images <ref type="bibr">[30]</ref>. The SeeHear chip sees an image, through use of onchip photodetectors, and converts the image into an auditory equivalent of the visual image. This SeeHear chip used the same scheme of photodetector signals coupling into linear delay lines. The delay lines serve to synthesize the interaurel delay cues that drive the auditory-localization system in the brain.</p><p>The layout for one pixel from the two-dimensional motion chip is shown in Fig. <ref type="figure" target="#fig_13">10</ref>. Most of the pixel area is covered with wire and capacitance, rather than with transistor. The amount of interpixel wiring is minimal compared with the amount of wire used for routing bias signals into the pixel or routing outputs from the pixel. The architecture is efficient, because these input and output signals are essential and occupy most of the pixel area. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>In this section, I present experimental results from a twodimensional motion chip with the hexagonal architecture, and from a one-dimensional motion chip with two opposing delay lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Results from Two-Dimensional Motion Circuit</head><p>Fig. <ref type="figure" target="#fig_14">11</ref> shows the real-time scanned output from the twodimensional motion circuit in response to two moving patterns. Part (a) shows the response to a drifting square-wave grating. The buildup of activity away from the edge of the array in part (a) of the figure is evident as an increasing saturation of the color of the output. The longer the motion is visible to the array, the larger the response. Part (b) shows the response of the chip to a rotating spiral pattern that produces the illusion of expansive optical flow. The chip computes a pseudolocal flow field. Motion that is not in a principal direction appears as a combination of the colors corresponding to the principal directions.</p><p>This chip consists of a 26 by 26 hexagonally arranged array of pixels. The power consumption of the core of the chip (all the analog computation done by the pixels) is' 1.5 mW (dark) to 8 mW(light), depending on the brightness of the illumination, and hence on the raw pixel photocurrent.</p><p>Hence, the power consumption of the analog computation, independent of photocurrent, is 1.5 mW, or 2.2 pW/pixel. About 80% of this power is supplied to the antibump circuit, which I run at above-threshold bias to widen the transfer characteristic. The rest of the chip-consisting of the scanning frame, the clock driver, and the on-chip video amplifiers [29]-uses another 26 mW. The size of each pixel is 224 by 225 pm; the entire chip fits on a 6.8by 6.9-mm die and is fabricated in a 2-pm, double poly, n-well process available through MOSIS, the DARPA fabrication service <ref type="bibr" target="#b8">[9]</ref>.</p><p>Fig. <ref type="figure" target="#fig_3">12</ref> shows the directional tuning for the pixels in the two-dimensional chip. These plots show the average angular tuning for each of the directions represented by a pixel, for three different movement speeds. The responses are plotted in polar coordinates, and the distance from the origin is the magnitude of the average response. For speeds at or higher than the optimum velocity, the relative values of three outputs unambiguously determine the direction of the normal component of edge velocity. However, for speeds lower than the optimum, motion of a grating in a direction oblique to the detector orientation excites a detector more than motion at the same speed along the detector, resulting in responses with two peaks. This characteristic is an aspect of the aperture effect, since the delay-line detectors correlate image information along only the detector orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Quantitative Results from a One-Dimensional Motion Circuit</head><p>I collected quantitative data primarily from a onedimensional version of the motion circuit with two directions of selectivity. Fig. <ref type="figure" target="#fig_4">13</ref> shows the response from two taps of the one-dimensional circuit in response to a moving sinusoidal pattern. The buildup of direction selectivity is evident in the difference between the response of the early and late taps. A systematic asymmetry is evident in the lack of frequency doubling, except for the largest response. I am not certain of the origin of the asymmetry, although I suspect either the source-follower buffer or the photoreceptor. Fig. <ref type="figure" target="#fig_2">14</ref> shows velocity-tuning curves for a number of taps from the same one-dimensional motion circuit, in response to the same moving pattern. The velocity tuning becomes sharper and more direction selective for later taps, although it appears that the tuping begins to approach a limiting form after about tap 15. The tuning curves shown in Fig. <ref type="figure" target="#fig_2">14</ref> are measurements of the peak-to-peak output voltage from the circuit. The theoretical form of this measurement can be computed from <ref type="bibr" target="#b12">(13)</ref>, plus the transfer function of the logarithmic currentsense amplifier used in the scanning frame <ref type="bibr">[29]</ref>. In Fig. <ref type="figure" target="#fig_7">15</ref>, I show fits to the data in Fig. <ref type="figure" target="#fig_2">14</ref>. Only the tap number was varied among the theoretical curves; all other parameters (wavelength, spatial frequency, time constant, antibump circuit parameters, logarithmic current-sense amplifier parameters) were kept constant. The quality of the fits is remarkable, considering that the input to the system was from a grating pattern printed on a piece of paper.</p><p>A number of nonlinearities have been ignored in the analysis. The effect of saturating nonlinearities can be seen in The velocity tuning for a number of taps of a one-dimensional motion circuit. Plotted are the peak-to-peak outputs from the logarithmic current-sense amplifier fed from the antibump nonlinearity at each tap. The tap number is shown next to each curve. The gain of the logarithmic sense amplifier is approximately 100 mV per decade of current. Circuit offsets are visible as an inversion of the exoected order between tam 6 and 9.</p><p>Fig. <ref type="figure" target="#fig_3">12</ref>. Directional-tuning of pixel in two-dimensional chip, for different stimulus speeds. stimulus is sinusoidal grating pattern with wavelength approximately 10 pixel spacings. Each polar plot shows the response, measured as average video output voltage, of the three outputs from a pixel near the center of the chip. Each curve is labeled with an arrow showing the orientation of the delay line. I normalized each polar curve to the same maximum to adjust for monitor brightness corrections in the video circuits. The scatter in the points shows the noise in the 2 second averages. The solid curves are Bezier curves fitted by eye to the data points. The stimuli in (a), (b), and (c) differ only in grating speed. In (a) the grating moves at the optimum speed, in (b), at half optimum speed, and in (c), at twice optimum speed. In (b), the apparent motion effect from Fig. <ref type="figure" target="#fig_4">3</ref> is evident as doubly peaked responses that are roughly perpendicukdr to orientation of delay line. In (c), the response does not display the same doubly-peaked effect, because oblique motion is faster than orthogonal motion, so oblique motion excites pixel less than does true motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Velocity (arb, -pixeUs)</head><p>Fig. <ref type="figure" target="#fig_7">15</ref>. Effects of saturating nonlinearities on motion-circuit response. The data in the top curve were collected with the use of high-contrast ( ~5 0 % ) grating; those in the lower curve were collected with the use of a low-contrast ( d 0 ' K ) grating. Fig. <ref type="figure" target="#fig_0">16</ref>, which compares the velocity tuning for low-and highcontrast grating patterns. The high-contrast grating pattern saturates the differential inputs in the follower integrators or in the antibump nonlinearity, causing a shift of the peak response toward a lower velocity, and a widening of the peak. Fig. <ref type="figure" target="#fig_17">17</ref> shows the velocity tuning of several taps of the network for different wavelength stimuli. For the late taps, the peak response occurs at a constant speed, relatively invariant to wavelength. For tap 1, the optimum velocity is a strong function of wavelength. For all the taps, the primary effect of varying the wavelength of the stimulus is a simple scaling of the amplitude of the response with wavelength. The speed of the optimum response shifts toward higher speeds as the wavelength is decreased. All these effects are consistent with the theoretical analysis presented earlier. The scaling of tap 1 response amplitude with wavelength, however, is inconsistent. I think that this result is due to a defocused image, which decreases the effective modulation depth of the image more for shorter wavelengths, and hence results in a smaller response for shorter wavelength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>The inspiration for the spatiotemporal integration properties of the chip's motion architecture came from psychophysical observations of human motion perception [31]. I am aware that cortex is far more complex than my simple model. The important thing to point out, however, is that the robust functioning of the chip is at least partially due to the spatiotemporal aggregation, while I now of at least three other attempts to build functional analog correlation detectors that have only marginal performance. The spatiotemporal aggregation in the chip also has the consequence that it allows the computation to see motion over a wide range of spatial frequencies, a s opposed to the short spatial scales that a pairwise detector is capable of discriminating. A given combination of the three pixel outputs can correspond to a range of possible pattern velocities of the actual scene. This characteristic is an expression of the aperture effect, and is true for any local motion detector. The three spatiotemporal correlations computed in each pixel are valid computations in the sense that the information they report is consistent with a possible motion of a one-dimensional pattern. It can turn out that the output is not consistent with a motion orthogonal to the edge, as seen in Fig. <ref type="figure" target="#fig_3">12(b</ref>). However, there is absolutely no reason why motion must be orthogonal to an edge. At first sight, the apparent-motion effect suggests why cortical direction-selective cells are orientation tuned to edges orthogonal to the preferred direction, and why fly motion-sensitive cells are sensitive to the temporal frequency more than to image speed <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref>. The argument goes that, in cortext, the orientation tuning removes the ambiguity about edge motion by ensuring that the computation measures only those motion components that are orthogonal to the edge. The same argument may be made in flies [19], <ref type="bibr" target="#b39">[39]</ref>. However, I believe that it is not settled whether these arguments are computationally valid or only opportunistically based on particular aspects of experimental observations. The receptive field of the delay line motion detector resembles a simplified Adelson-Bergen spatiotemporal energy model <ref type="bibr">[l]</ref>. Different spatial locations in the receptive field have different time delays to get to the output of the detector. The spatial receptive field is a long, skinny, rectangle starting at the location of the pixel and extending back along the delay line. The antibump output nonlinearity is similar to the squaring nonlinearity used in the Adelson-Bergen detectors. My detectors share receptive field with each other, through the common shared signal on the delay line.</p><p>One approach to performing full computation on the image motion is to plaster the input space with tuning curves. In cortex, there are spatial-and temporal-frequency tuned neurons with many different tuning curves <ref type="bibr" target="#b2">[3]</ref>. The ensemble of broadly tuned, imprecise responses, that covers the whole space of inputs, can be combined to form a precise estimate of optical flow <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b37">[37]</ref>. In comparison with some models of cortical motion computation, the number of velocity tunings in my motion chip is tiny-only three curves are used to cover the entire space of inputs. Models of cortex often plaster the space with dozens or hundreds of different tuning curves. Can we build systems with even tens of tuning curves? Not on one chip! This approach would require a number of motion chips because of the large number of required tuning curves. The problem of integrating multiple massively parallel analog chips is now being addressed <ref type="bibr">[26]</ref>.</p><p>It would be good to automatically adjust the tuning of the motion detector to match the input image, in analogy with other adaptive sensory processing like the automatic gain control used in photoreceptors. This strategy would use the available dynamic range more fully, and the adaptation state itself would give information about the image motion. Biological studies suggest that animals with cortex do not tdjust the tuning curves, while insects do. (However, people nave not looked very hard in cortex for short-time-scale adaptive behaviors.) The fly visual system has only a few tens of visual output neurons. These direction-selective, velocitytuned neurons, which integrate information from the entire visual field, adjust their tuning curves in response to the scene velocity <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr">[25]</ref>, <ref type="bibr">[34]</ref>, <ref type="bibr" target="#b38">[38]</ref>. The adjustment takes the form of a variable time constant that is shorter for higher image velocities or temporal frequencies (which it is-velocity [34] or frequency <ref type="bibr" target="#b5">[6]</ref>-is under contention). This scheme is attractive from a chip designer's point of view, because it potentialy allows a single velocity-tuned unit to cover a large dynamic range and still retain high sensitivity, in a manner analogous to the adaptive photoreceptor circuits used in our pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. SUMMARY</head><p>I have described the first functional two-dimensional analog VLSI implementation of a motion detector based on the 35year-old Hassenstein-Reichardt correlation detector. The delay line extension to the usual pairwise correlation model has the novel functional property that it integrates information over an extended spatiotemporal region. The functionality of this chip is part of an accumulating body of evidence that we will eventually build complete, functional, neuromorphic visual systems.</p><p>ACKNOWLEDGMENT I wish to tha: k the anonymous reviewers for constructive comments, Carver Mead, Martin Egelhaaf, Shih-Chii Liu, Buster Boahen, Misha Mahowald, Humbert Suarez, Rahul Sarpeshkar, and Rod Goodman for valuable discussion, and Lyn DuprC for style editing. I also thank the MOSIS fabrication service for making this type of exploratory chip design possible. The inspiration to build a correlating detector array came from Werner Reichardt's work on the fly visual system, and from Nicola Franceschini's work on recording responses to optical stimulation of single pairs of ommatidial receptors. The idea of extending the correlation model to more than a pairwise correlation was inspiied by a talk given by Ken </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Manuscript received July 16 ,</head><label>16</label><figDesc>1992; revised August 31, 1992. This work was supported in part by the Office of Naval Research under Grant NAV N00014-89-J-1675 and by the California Competitive Technologies Program. The author is with the California Institute of Technology, Pasadena, CA 91125. IEEE Log Number 9207195. the chip to solve the aperture problem, which arises because a local measurement cannot detect motion along an edge [28].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>omit discussion of other analog motion chops that have been fabricated only as one-dimensional circuits [22], [23]. For the most part these architectures cannot be fabricated practically in a two-dimensional architecture, because they are not parsimonious with wire. I also omit discussion of analog change-detecting circuits [8], [ 131, digital motion circuits [2], and discrete-component correlation-detector systems [ 161,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Correlation-motion-detectors. (a) Pairwise correlation detector. Nondirectional feature-detecting cells feed into an output nonlinear element that measures coincidence between the spatiotemporally separated inputs. The exact nature of the nonlinearity is not important, as long as it is expansive. (h) Extended correlation detector. Nondirectional cells (P) couple activity into a unidirectional delay line with delay T per stage. The delay line signal ( D , ) is large when the image motion is matched to the delay line speed. The expansive output nonlinearities ( N ) compute a velocity selective signal M, that is monotonic in the magnitude of the delay line signal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Photoreceptor DelayFig. 2. Two-dimensional architecture of the motion chip. Pixels are arranged in a hexagonal array. Each pixel contains a single photoreceptor, three delay elements, and three output nonlinearities. The delay lines run in the three principal directions shown by the arrows in the delay elements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Apparent motion and wavelength effects. A grating pattern with wavelength A, moving at speed S and angle 8 over motion detector with preferred direction to the right causes an apparent motion along the array at the increased speed S/cos 8. The apparent wavelength seen by the array is also increased to A/cos 8. The "apparent" motion can equally well be caused by true motion to the right at velocity S/cos 8 of edges that are oriented at angle 8; there is no way, in principle, that the local measurement can distinguish them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>the Laplace transform variable and 7 is the time constant of each first-order section [30]. (It may be helpful to refer to the circuit diagram in Fig.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4 Fig. 4 .</head><label>44</label><figDesc>Fig. 4. Theoretical response of delay line to moving bar for two velocities. A bright bar of width 6 pixels, traveling to the right over the delay line, passes over the first tap at time t = 0. The mathematical form of the delay line response to the moving bar at the nth tap is B,(t) = R, ( t ) -R n ( t -( 6 / S ) ) ,where R is the response to a single bright edge, computed in the text as (5), and S is the speed in pixels/time. Each trace shows the response at a particular tap as a function of time. Tap number is shown to right of trace. The linear delay line signals E , (t) are shown in (a) and (c), and the result of passing the linear delay line signal through the antibump nonlinearity (Fig.5), NIB, ( t ) ] ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The antibump output nonlinearity (6). The input is a differential voltage 2 shown in natural input units, and the output is a current, shown here normalized to 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Sinusoidal grating pattern moving over motion array. The grating moves at speed S. Pixel locations are shown as arrows. The pattem has wavelength A, and the pixel spacing is L. The temporal frequency at each pixel is U . The pattern phase shift between pixels is 'p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Phasor summation properties for a seven-stage system. H c ( 2 a a / X ) is plotted on the complex plane. The symbols are defined in Fig. 6. The contributions of individual taps are shown as component line segments; taps 1 and 7 are labeled. The optimum velocity is near L / r = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Theoretical plots of the magnitude of the transfer function for (a) two-stage system, compared with (b) infinite delay line, for various wavelength pairwise detectors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Circuitry for a single stage of motion circuit. An adaptive photoreceptor, with a contrast-sensitive gain of about 1 V/decade, feeds into a source-follower buffer, whose output couples capacitively into the follower integrator. The velocity-selective output current is computed by the antibump expansive-nonlinearity circuit. When the delay line signal is pushed away from its equilibrium point (Vref) by activity on the delay line, the output current increases, because the center leg of the antibump circuit is turned off. For additional directions of selectivity, only the Buffer, Delay element, and Antibump nonlinearity must be duplicated-all directions share the same photoreceptor input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Layout of pixel of two-dimensional motion circuit with hexagonal architecture. Pixel has one photoreceptor, three follower integrators, and three antibump nonlinearities. Lines indicate circuit components. Keys: F = follower, N = antibump nonlinearity, C = capacitor, B = buffer, P = phototransistor, R = photoreceptor. Scale bar shows dimensions. This pixel is arranged in the hexagonal architecture shown in Fig. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Color photographs showing the video output of the two-dimensional motion chip to motion (a) of a square-wave grating pattern in a single principal direction (arrow), and (b) of a rotating spiral pattern that produces illusory expansive optical flow (arrows). The output of the chip encode motion downward as blue, motion upward and to the right as red, and motion upward and to the left as green. Encoding of intermediate directions is evident as mixing of the primary colors. The dynamic nature of the output of the chip makes direct photography difficult, so we produced these pictures by videotaping the output from the color monitor, and then photographing the freeze-framed screen of the videotape monitor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 13 . 5 '</head><label>135</label><figDesc>Fig.13. Measured response from two taps of a one-dimensional motion circuit with both directions of sensitivity (see upper left). The stimulus is a moving low-contrast grating pattern. The motion network had a total of 21 taps. I simultaneously recorded tap 2 in one direction and tap 18 in the other direction (numbering starts at zero, as in the text), and I plot the output voltage from the logarithmic current-sense amplifier. The grating initially moved in the tap 2 preferred direction and in the tap 18 null direction; it then changed direction. After a slight latency, the response from tap 18 became much larger than that of tap 2. The lack of frequency doubling, except in the largest signals (arrows), arises from a systematic offset of unknown origin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Velocity tuning with theoretical fits. Each plot shows measured velocity-tuning data as squares, with theoretical fits as solid curves. Response plotted is the peak-to-peak output voltage from a logarithmic current-sense amplifier that senses the antibump output current. Theoretical curves are derived from (14), plus the transfer function for the sense amplifier. The tap number is shown at the top of each curve and corresponds to the numbering used in the theory. Note the vertical scale-the response grows with tap number, as in Fig. 14. Arrows point out wiggles in null direction response that are fitted by theory. All parameters in the model are identical for each theoretical curve, except for the tap number.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Effect of changing the stimulus wavelength. Each plot shows the measured output of a particular tap of the one-dimensional motion chip as a function of the stimulus velocity, in response to a moving sinusoidal grating pattern. In each graph, four plots are shown, one for each wavelength of the stimulus. The number on each plot show the wavelength, in pixels, of the grating.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Nakayama at the Society of Neuroscience Annual meeting in Phoenix, AZ in 1989.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I DELAY-LINE DETECTOR. SYMBOLS ARE DEFINED IN FIG. 6 COMPARISON BETWEEN PAIRWISE REICHARDT-TYPE DETECTOR AND Pairwise detector: Delay-line detector:</head><label>I</label><figDesc></figDesc><table><row><cell></cell><cell>Iff1(u)12 -I H 1 ( -W ) I 2</cell><cell cols="2">l Hco12</cell></row><row><cell>Location of optimum</cell><cell>d = d</cell><cell cols="2">s = 4 for(X &gt;&gt; L )</cell></row><row><cell>response</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Low-speed response</cell><cell>( ~7 ) ~ siny</cell><cell>(+)'(for</cell><cell>x &gt;&gt; L )</cell></row><row><cell>Response at</cell><cell></cell><cell></cell><cell></cell></row><row><cell>optimum speed</cell><cell>o( sin9</cell><cell>cx (+)"for</cell><cell></cell></row></table><note><p>X &gt;&gt; L )</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spatiotemporal energy models for the perception of motion</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="284" to="299" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Video compression makes big gains</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ruetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Auld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<biblScope unit="page" from="16" to="19" />
			<date type="published" when="1991-10">Oct. 1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spatial-and temporal-frequency selectivity as a basis for velocity preference in cat striate cortex neurons</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Neuroscience</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="101" to="113" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The mechanism of directionally selective units in the rabbit&apos;s retina</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Levick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="447" to="504" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Direction-selective silicon retina that uses null inhibition</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Delbriick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<meeting><address><addrLine>San Meteo, C A Morgan Kaufman</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Temporal modulation of luminance adapts time constant of fly movement detectors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Egelhaaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="209" to="215" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Elementary movement detectors in an insect visual system</title>
		<author>
			<persName><forename type="first">E</forename><surname>Buchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="85" to="101" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image-motion detection using analog VLSI</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A T</forename><surname>Salama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Solid State Circuits</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="93" to="96" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MOSIS-the ARPA silicon broker</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lewicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. from the Second Caltech Conj VZSI</title>
		<meeting>from the Second Caltech Conj VZSI<address><addrLine>Pasadena CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="29" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><surname>Io</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">I 11 T. Delbriick, &quot;&apos;Bump&apos; circuits for computing similarity and dissimilarity of analog voltages</title>
		<author>
			<persName><forename type="first">T</forename><surname>Delbriick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems I</title>
		<title level="s">Proc. Int. Joint Con&amp; Neural Networks</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>An electronic photoreceptor sensitive to small changes in intensity</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Investigations of analog VLSI visual transduction and motion processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Delbriick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ph.D. dissertation Department of Computation and Neural Systems</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Pasadena CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Time-derivative adaptive silicon photoreceptor array</title>
		<author>
			<persName><forename type="first">T</forename><surname>Delbriick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Mead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">1541</biblScope>
			<biblScope unit="page" from="92" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Functional properties of the H1-neurone in the third optic ganglion of the blowfly, Phaenicia</title>
		<author>
			<persName><forename type="first">H</forename><surname>Eckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Comp. PhysioL</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page">1151</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic response properties of movement detectors: theoretical analysis and electrophysiological investigation in the visual system of the fly</title>
		<author>
			<persName><forename type="first">M</forename><surname>Egelhaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Reichardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="69" to="87" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Real-time visuomotor control: from flies to robots</title>
		<author>
			<persName><forename type="first">N</forename><surname>Franceschini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pichon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blanes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Fifth Int. Conj Advanced Robotics</title>
		<meeting><address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-06">June 1991. 1991</date>
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A model for the estimate of local image velocity by cells in the visual cortex</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Grzywacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Royal Soc. Lond</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="page" from="129" to="161" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Systemtheoretische analyse der &amp;it-, reihenfolgen-und vorzeichenauswertung bei der Bewegungsperzeption des Riisselkafers Chlorophanus</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hassenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Reichardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Z. Naturforch</title>
		<imprint>
			<biblScope unit="volume">l l b</biblScope>
			<biblScope unit="page" from="513" to="524" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Directional tuning curves, elementary movement detectors, and the estimation of the direction of visual movement</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Van Hateran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="603" to="614" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Monokulare und binoculare Bewegungsauswertung in der Lobula plate der Fliege (Monocular and binocular computation of motion in the lobula plate of the fly)</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hausen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Gustav Fischer Verlag</publisher>
			<biblScope unit="page" from="49" to="70" />
			<pubPlace>Stuttgart</pubPlace>
		</imprint>
	</monogr>
	<note>in Verh. Dtsch. 2001. Ges</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optical flow using spatiotemporal features</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="279" to="302" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A delay line based motion detection chip</title>
		<author>
			<persName><forename type="first">T</forename><surname>Horiuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lazzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Lippman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Moody</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Touretzky</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufman</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="406" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Computing motion using analog VLSI Chips: an experimental comparison among different approaches</title>
		<author>
			<persName><forename type="first">T</forename><surname>Horiuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bishofberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lazzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comp. vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="203" to="216" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural model of stereoacuity and depth interpolation based on a distributed representation of stereo disparity</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Lehky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosc</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="29" to="39" />
			<date type="published" when="1980">1990. 1991. 1991. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Afterimage-like effects in the motion-sensitive neuron Hl</title>
		<author>
			<persName><forename type="first">T</forename><surname>Maddess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. Lond</title>
		<imprint>
			<biblScope unit="volume">228</biblScope>
			<biblScope unit="page" from="433" to="459" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mahowald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI Analogs of Neuronal Visual Processing: A Synthesis of Form and Function</title>
		<meeting><address><addrLine>Pasadena, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Silicon retina with adaptive photoreceptors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mahowald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIEISPSE Symp. Electronic Science and Technology: From Neurons to Chips</title>
		<meeting>SPIEISPSE Symp. Electronic Science and Technology: From Neurons to Chips</meeting>
		<imprint>
			<date type="published" when="1991-04">Apr. 1991</date>
			<biblScope unit="volume">1473</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Vision</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>W. H. Freeman &amp; Co</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scanners for visualizing activity of analog VLSI circuitrv</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Delbriick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analoa Interrated Circuits and Sianal Processina</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Mead</surname></persName>
		</author>
		<title level="m">Analoa VLSI and Neural Systems</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison--Wesley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Temporal and spatial characteristics of the upper displacement limit for motion in random dots</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="293" to="299" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visual guidance of a mobile robot equipped with a network of self-motion sensors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pichon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blanes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Franceschini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluation of optical motion information by movement detectors</title>
		<author>
			<persName><forename type="first">W</forename><surname>Reichardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Physiol</title>
		<imprint>
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="page" from="533" to="547" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adaptation of transient responses of a movement-sensitive neuron in the visual system of the blowfly Calliphora erythrocephala</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>De Ruyter Van Steveninick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Zaagman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A K</forename><surname>Mastebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="223" to="236" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An Integrated Analog Optical Motion Sensor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Ii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Kung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI Signal Processing</title>
		<imprint>
			<publisher>New York IEEE Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="59" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName><surname>Spie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1195</biblScope>
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Integrated Optical Motion Detection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Tanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ph.D. dissertation California Inst. of Tech., Dept. of Computer Science</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<pubPlace>Pasadena, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Recurrent eye tracking network using a distributed representation of image motion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Lisberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="380" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adaptive strategies in fly vision: on their image-processing qualities</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Zaagman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A K</forename><surname>Mastebroek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Van Steveninck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="900" to="906" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">On the directional sensitivity of motion detectors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tobias Delbriick was born on March</title>
		<imprint>
			<date type="published" when="1960">1990. 1960</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="177" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">He is interested in the use of biologically inspired analog VLSI technology for artificial vision</title>
	</analytic>
	<monogr>
		<title level="m">He received the B.A. degree in physics and applied mathematics from the University of California at San Diego. in 1983 and the Ph.D. degree from the Department of Computation and Neural Systems</title>
		<meeting><address><addrLine>Pasadena, CA</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Carver Mead&apos;s Laboratory ; California Institute of Technology, Pasadena</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
