<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Output Feedback Control of Markov Jump Linear Systems in Continuous-Time</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>De Farias</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mechanical and Environmental En-gineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>93106</postCode>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Geromel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mechanical and Environmental En-gineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>93106</postCode>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">B R</forename><surname>Do Val</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mechanical and Environmental En-gineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>93106</postCode>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">O</forename><forename type="middle">L V</forename><surname>Costa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mechanical and Environmental En-gineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>93106</postCode>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Output Feedback Control of Markov Jump Linear Systems in Continuous-Time</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8DC26894E4FFCE600ADA35379B626568</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Jump parameter systems</term>
					<term>and control</term>
					<term>and filtering</term>
					<term>linear matrix inequalities</term>
					<term>output feedback</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper addresses the dynamic output feedback control problem of continuous-time Markovian jump linear systems. The fundamental point in the analysis is an LMI characterization, comprising all dynamical compensators that stabilize the closed-loop system in the mean square sense. The and -norm control problems are studied, and the and filtering problems are solved as a by product.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>There have been several examples showing the importance of dynamic systems subject to abrupt variations in their structures. This is in part due to the fact that very often dynamic systems are inherently vulnerable to component failures or repairs, sudden environmental disturbances, changing subsystem interconnections, abrupt variations of the operating point of a nonlinear plant, etc. Markovian jump linear systems (MJLS) comprise an important class of stochastic dynamic systems which can, in several situations, model the above problems. The theory of stability, optimal control and H1 -control, as well as some important applications of such systems, can be found in several papers in the current literature, for instance, in <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, and <ref type="bibr" target="#b15">[16]</ref>.</p><p>Continuous-time LQ control problems for MJLS have been studied in the current literature usually under the assumption of perfect information of the jump variable of the system as well as of the state variable. By using standard arguments on dynamic programming it has been shown that this formulation leads to a set of coupled differential Riccati equations (CDRE) for the solution of the problem <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Taking the limit as time goes to infinity we have, under some appropriate conditions, that the CDRE tends to coupled algebraic Riccati equations (CARE), and numerical methods have been designed for solving it in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b15">[16]</ref>. The state feedback H1 -control problem has also been analyzed, and generalized coupled algebraic Riccati equations have been derived for this problem in <ref type="bibr" target="#b5">[6]</ref>. The LQG control problem with no direct knowledge of the state variable, but assuming that the jump variable is available, was addressed in <ref type="bibr" target="#b10">[11]</ref> (named JLQG) and in <ref type="bibr" target="#b11">[12]</ref>. In <ref type="bibr" target="#b10">[11]</ref> it was shown that the separation principle holds for the optimal control problem, leading to a sample path dependent optimal state estimator (the Kalman filter) combined with the CDRE obtained for the state feedback LQ control problem. As pointed out in <ref type="bibr" target="#b10">[11]</ref>, this optimal solution is not satisfactory since the filter portion of the controller for the optimal infinite time horizon JLQG is not invariant, which makes any asymptotic and stability analysis unfeasible.</p><p>In this paper the output feedback control of continuous-time MJLS with perfect measurement of the Markov state is revisited under a convex programming approach. The H2 and the H1 -norm control problems are solved employing dynamic compensators that can change structure when a jump of the Markov state occurs. The formulation provides a suitable framework for implementations when compared with the optimal stochastic filter. Convex analysis has shown to be a powerful tool to derive numerical algorithms for several important control problems, for instance, H 2 guaranteed cost control for uncertain systems, H 1 -control problems, and mixed H 2 /H 1 -control problems and has been widely studied in the international literature (see, for instance, <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b2">[3]</ref>). For the state feedback MJLS case, convex analysis had been previously considered in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b15">[16]</ref>. In <ref type="bibr" target="#b3">[4]</ref> the state-feedback H 2 -control problem of continuous-time MJLS was defined and a convex programming approach was used to study it. It was shown that the existence of a solution to the convex programming problem is completely equivalent to the existence of a mean square stabilizing solution to CARE, and one solution can be recovered from the other, showing the equivalence between these two formulations.</p><p>As in <ref type="bibr" target="#b10">[11]</ref> we assume in this paper that the jump variable is perfectly observable to the controller but not the state variable, which is observed only through an output variable. The first important problem we consider in this paper is to find necessary and sufficient conditions for the existence of output feedback dynamic controllers, dependent on the jump variable, such that the closed loop system is stable in the mean square sense. It is proven that the necessary and sufficient conditions can be written in terms of an LMI problem, providing thus a parametrization for all mean square stabilizing compensators in terms of the elements of a convex set.</p><p>Having obtained this result we can move on to the control problems, and we write the output feedback H 2 -norm and H 1 -norm control problems of continuous-time MJLS in terms of LMI optimization problems. The optimal solution of the LMI optimization problem leads to a closed-loop controller which stabilizes the system in the mean square sense.</p><p>As a byproduct of the output feedback control problems, we can also consider the H2 and H1 filtering problems for the continuous-time MJLS. The LMI optimization problems, as before, provide mean square stabilizing controllers for the error estimator equation.</p><p>Last, but not least, it is important to emphasize that, besides providing important theoretical results for the H 2 and H 1 -norm con- trol problems of continuous-time MJLS, the convex approach naturally leads to powerful numerical methods, as illustrated by an example of a multiple mode VTOL helicopter.</p><p>Section II presents the notation to be employed, as well as some basic results concerning stability in the mean square sense. The definition of the H 2 and the H 1 norms for continuous-time MJLS are also presented, and the connection between the H 2 -norm and the observability and controllability gramians is made. Section III shows that the existence of a compensator that stabilizes in the mean square sense an output feedback continuous-time MJLS is equivalent to a convex set described in terms of LMI's not being empty, and we show how to obtain a compensator with this property from an element of this convex set. Section IV considers, respectively, the H 2 and the H 1 -control problem for the output feedback system via LMI optimization problems, and Section V analyzes the corresponding filtering problems. The proofs for the control and filtering problems can be deduced from the Theorem 3.1, and they are omitted. The paper is concluded in Section VI with an application and some final remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM FORMULATION AND BASIC RESULTS</head><p>A Markov jump linear system (MJLS) is described as follows. Let S = f1; 1 1 1 ; N g be an index set, and consider the collections of real matrices:</p><formula xml:id="formula_0">A = (A 1 ; 1 1 1 ; A N ), dim(A i ) = n 2 n; E = (E 1 ; 1 1 1 ; E N ), dim(E i ) = n 2 m; C 1 = (C 11 ; 1 1 1 ; C 1N ), 0018-9286/00$10.00 © 2000 IEEE dim(C1i) = p 2 n; C2 = (C21; 1 1 1 ; C2N ), dim(C2i) = q 2 n; and D 2 = (D 21 ; 1 1 1 ; D 2N ), dim(D 2i ) = q 2 m; i = 1; 1 1 1 ; N.</formula><p>Let us consider a continuous-time homogeneous Markov chain, 2 = ft ; t 0g having S as state space and 3 = [ij; i 2 S; j 2 S] as the transition rate matrix. The probability distribution of the Markov chain at the initial time is given by = ( 1 ; 1 1 1 ; N ) in such a way that P (0 = i) = i.</p><p>Consider a fundamental probability space (; F ; fF t g; P ). We denote by L m 2 the Hilbert space formed by the stochastic processes z = fzt; t 0g such that, for each t 0, zt is a second order real valued m-dimensional random variable, F t -measurable and The MJLS is the stochastic system G 0 :</p><formula xml:id="formula_1">_x t = A( t )x t + E( t )w t zt = C1(t)xt yt = C2(t)xt + D2(t)wt; t 0 w 2 L m</formula><p>2 ; E(jx 0 j 2 ) &lt; 1; 0 .</p><p>(1) Thus, whenever t = i 2 S , one has that A( t ) = A i ; E( t ) = E i , C1(t) = C1i, C2(t) = C2i, and D2(t) = D2i. The processes x = fx t ; t 0g, z = fz t ; t 0g, and y = fy t ; t 0g are, respectively, the state, the output, and the measured output for system G0 . We assume that the process w = fwt; t 0g 2 L m 2 . The definition below generalizes of the concept of stable systems for stochastic systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.1:</head><p>We say that model G0 with w 0, is mean square</p><formula xml:id="formula_2">stable (MSS) if E jx t j 2 ! 0; as t ! 1</formula><p>for any initial condition x 0 and initial distribution for 0 .</p><p>The following proposition connects the main results on stochastic stability for MJLS. They can be derived from <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b12">[13]</ref>. are feasible for some P = (P1; 1 1 1 ; PN ) with dim(Pi) = n 2 n, P i &gt; 0 for all i = 1; 1 1 1 ; N.</p><p>c) (Coupled Lyapunov Equations) For any given U = (U1; 1 1 1 ; UN ) with dim(Ui) = n 2 n, Ui &gt; 0, there exists a unique P = (P 1 ; 1 1 1 ; P N ); P i &gt; 0 8 i satisfying A 0</p><formula xml:id="formula_3">i P i + P i A i + N j=1 ij P j + U i = 0; i= 1; 1 1 1 ; N: (3)</formula><p>If we set Ui 0, the uniqueness stated also holds for Pi 0;</p><formula xml:id="formula_4">i = 1; 1 1 1 ; N. Proposition 2.2: If G 0 is MSS, for every w = fw t ; t 0g 2 L m 2 ,</formula><p>we have that x = fx t ; t 0g 2 L n 2 for any initial condition x 0 and initial distribution for 0.</p><p>The proof of Proposition 2.2 is omitted. The next definition is a generalization of the H 2 -norm from continuous-time deterministic systems to the stochastic Markovian jump case. where z s; i represents the output fz t ; t 0g when: a) the input is given by w = fwt; t 0g, wt = es(t), (t) the unitary impulse, and e s the r-dimensional unitary vector formed by 1 at the sth position and zero elsewhere;</p><p>b) x0 = 0 and 0 = i.</p><p>For the deterministic case (N = 1) the above definition reduces to the usual H2-norm. The following proposition states that the H2-norm defined above can be calculated as the solution of the coupled observability and controllability gramians, a result that mirrors its deterministic counterpart. Suppose that G 0 is MSS and consider</p><formula xml:id="formula_5">A 0 i W i +W i A i + N j=1 ij W j +C 0 1i C 1i = 0; i= 1; 1 1 1 ; N (4)</formula><p>and AiVi + ViA 0 i + N j=1 jiVj + iEiE 0 i = 0; i= 1; 1 1 1 ; N (5) with W i 0 and V i 0; i = 1; 1 1 1 ; N the unique solution of these equations.</p><p>Proposition 2.3 <ref type="bibr" target="#b3">[4]</ref>: Indeed, for W and P satisfying ( <ref type="formula">4</ref>) and ( <ref type="formula">6</ref>), respectively, we have that P i &gt; W i 0; i = 1; 1 1 1 ; N and the consequence is that </p><formula xml:id="formula_6">kG0k 2 2 = N i=1 i Tr(E 0 i WiEi) = N i=1 Tr(C 1i V i C 0 1i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. STOCHASTIC STABILITY</head><p>We shall address the problem of finding all dynamic compensators G c as defined in the beginning of Section IV such that the system G coupled with Gc becomes stochastically stable. To this end, we apply Proposition 2.1 to get the following conditions:</p><formula xml:id="formula_7">Ã0 i P i + P i Ãi + N j=1 ij P j &lt; 0; i= 1; 1 1 1 ; N (7)</formula><p>where Ãi ; i = 1; 1 1 1 ; N are given by Ãi</p><formula xml:id="formula_8">= A i B i C ci BciC2i Aci<label>(8)</label></formula><p>i = 1; 1 1 1 ; N, and P i &gt; 0; i = 1; 1 1 1 ; N.</p><p>Let diag(1) indicate a block diagonal matrix whose entries are given by (1). We are ready to present the following theorem. </p><formula xml:id="formula_9">A i Y i + Y i A 0 i + B i F i + F 0 i B 0 i + ii Y i R i (Y ) R 0 i (Y ) S i (Y ) &lt; 0 (9) A 0 i X i + X i A i + L i C 2i + C 0 2i L 0 i + N j=1 ij X j &lt; 0 (10)</formula><p>Yi I I X i &gt; 0 <ref type="bibr" target="#b10">(11)</ref> with</p><formula xml:id="formula_10">R i (Y ) = p 1i Y i 111 (i01)i ; Y i (i+1)i Y i 111 p N i Y i S i (Y ) = 0diag(Y 1 ; 11 1; Y i01 ; Y i+1 ; 11 1; Y N )<label>(12)</label></formula><p>i = 1; 1 11; N, has a feasible solution X i = X 0 i , Y i = Y 0 i , L i , and F i .</p><p>Proof: For the necessity, let us consider the following partition for Pi:</p><formula xml:id="formula_11">P i = P 1i P 2i P 0 2i P3i :<label>(13)</label></formula><p>We shall assume, with no loss of generality, that P2i is nonsingular.</p><p>Defining the matrices Y i = P 1i 0 P 2i P 01 3i P 0 2i 01 &gt; 0</p><formula xml:id="formula_12">(14) Ti = Y i I Y i 0<label>(15)</label></formula><formula xml:id="formula_13">J i = I 0 0 0P 01 3i P 0 2i<label>(16)</label></formula><p>and multiplying <ref type="bibr" target="#b6">(7)</ref> to the left by T 0 i J 0 </p><formula xml:id="formula_14">F i = 0C ci P 01 3i P 0 2i Y i L i = P 2i B ci M i = A 0 i + P 1i A i Y i + P 1i B i F i + L i C 2i Y i 0 P2iAciP 01 3i P 0 2i Yi + N j=1 ij P1jP2jP 01 3i P 0 2i Yi: (19)</formula><p>Besides, the conditions Pi &gt; 0; i = 1; 111 ; N are equivalent to T 0 i J 0 i PiJiTi = Yi I I P 1i &gt; 0:</p><p>(20) it follows that ( <ref type="formula">9</ref>)-( <ref type="formula">11</ref>) hold for Y = i X i 1i , F i = F i and Li = Li; i = 1; 1 11; N.</p><note type="other">Since</note><p>For the sufficiency part, let us suppose that X i = X 0 i , Y i = Y 0 i , F i and L i , i = 1; 11 1; N are feasible solutions of ( <ref type="formula">9</ref>)-( <ref type="formula">11</ref>). Then if we set for each i</p><formula xml:id="formula_15">A ci = X i 0 Y 01 i 01 A 0 i + X i A i Y i + X i B i F i (<label>22</label></formula><formula xml:id="formula_16">)</formula><formula xml:id="formula_17">+ L i C 2i Y i + N j=1 ij Y 01 j Y i Y 01 i (23) B ci = Y 01 i 0 X i 01 L i<label>(24)</label></formula><p>Cci = FiY 01 i (25)</p><formula xml:id="formula_18">P i = X i Y 01 i 0 X i Y 01 i 0 Xi Xi 0 Y 01 i &gt; 0<label>(26)</label></formula><formula xml:id="formula_19">T i = Yi I Y i 0<label>(27)</label></formula><p>it follows that (28) shown at the bottom of this page, holds and hence ( <ref type="formula">7</ref>) is verified. One important aspect refers to the parameterization of the compensators. Notice that Theorem 3.1 selects a particular parametrization, but it also establishes the relations which are satisfied by any compensator Gc that stabilizes the closed-loop system in the stochastic sense. One can always pick the trivial solution P 2i = 0P 3i = Y 01 i 0 X i and M i = 0, yielding the compensator adopted in (22), (24), and (25).</p><p>The H2 and H1-norm problems are not affected by the particular parametrization of G c , and the trivial solution in terms of the choice made in Theorem 3.1 will be adopted throughout the paper. Consequently, the matrices Pi's assume the particular structure in (26).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. THE CONTROL PROBLEM</head><p>Let B = (B 1 ; 111 ; B N ), dim(B i ) = n 2 r and D 1 = (D1i; 111; DNi), dim(D1i) = p 2 r, for each i = 1; 111 ; N; be  t 0 w 2 L m 2 ; E(jx 0 j 2 ) &lt; 1; 0 :</p><formula xml:id="formula_20">A i Y i + Y i A 0 i + B i F i + F 0 i B 0 i M 0 i M i A 0 i P 1i + P 1i A i + L i C 2i + C 0 2i L 0 i + N j=1 ij Y i Y 01</formula><formula xml:id="formula_21">A i Y i + Y i A 0 i + B i F i + F 0 i B 0 i + N j=1 ij Y i Y 01 j Y i 0 0 A 0 i Xi + XiAi + LiC2i + C 0 2i L 0 i + N j=1 ijXi &lt; 0<label>(</label></formula><p>For the synthesis of the control action u t , we introduce a dynamical compensator of the form</p><formula xml:id="formula_22">G c : _ vt = Ac(t)vt + Bc(t)yt u t = C c ( t )v t ; t 0</formula><p>where we consider Ac = (Ac1; 111; AcN ), dim(Aci) = n2n; Bc = (B c1 ; 111 ; B cN ), dim(B ci ) = n 2 q; and C c = (C c1 ; 1 11; C cN ), dim(C ci ) = p 2 n. The H 2 -control problem is to find a compen- sator Gc (Ac; Bc; Cc) such that the norm kGk2 of the closed-loop system is minimized. Similarly, the H 1 -control problem is to find (A c ; B c ; C c ) such that the norm kGk 1 of the closed-loop system is smaller than .   </p><formula xml:id="formula_23">A 0 i X i + X i A i + L i C 2i + C 0 2i L 0 i + C 0 1i C 1i + N j=1 ij X j &lt; 0;</formula><p>i= 1; 111; N:</p><formula xml:id="formula_24">(35)</formula><p>The corresponding parameters of G c are</p><formula xml:id="formula_25">C ci = F i Y 01 i Bci = Y 01 i 0 Xi 01 Li A ci = Y 01 i 0 X i 01 M i Y 01 i (<label>36</label></formula><formula xml:id="formula_26">)</formula><p>where</p><formula xml:id="formula_27">M i = 0A 0 i 0 X i A i Y i 0 X i B i F i 0 L i C 2i Y i 0 C 0 1i (C 1i Y i + D 1i F i ) 0 N j=1 ij Y 01 j Y i : B. H 1 -Control</formula><p>Let us turn our attention to the H 1 -control problem with output observations. The H1 constraints in Proposition 2.4, written here as </p><formula xml:id="formula_28">C ci = F i Y 01 i Bci = Y 01 i 0 Xi 01 Li A ci = Y 01 i 0 X i 01 M i Y 01 i<label>(40)</label></formula><p>where</p><formula xml:id="formula_29">M i = 0A 0 i 0 X i A i Y i 0 X i B i F i 0 L i C 2i Y i 0 C 0 1i (C1iYi + D1iFi) 0 02 (XiEi + LiD2i)E 0 i 0 N j=1 ij Y 01 j Yi: V.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE FILTERING PROBLEM</head><p>Consider A c = (A c1 ; 11 1; A cN ), dim(A ci ) = n 2 n; B c = (B c1 ; 1 11; B cN ), dim(B ci ) = n 2 q; and C c = (C c1 ; 111 ; C cN ), dim(Cci) = p 2 n; and let the output filter be of form</p><formula xml:id="formula_30">G f : _ v t = A c ( t )v t + B c ( t )y t ẑt = C c ( t )v t ; t 0:</formula><p>The H2-filtering problem is to find G f (Ac; Bc; Cc) such that the H 2 -norm of system G e is minimized, where G e stands for a system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yi</head><formula xml:id="formula_31">I E i I X i XiEi + LiD2i E 0 i E 0 i X i + D 0 2i L 0 i Z i &gt; 0; AiYi + YiA 0 i + BiFi + F 0 i B 0 i + iiYi YiC 0 1i + F 0 i D 0 1i Ri(Y ) C1iYi + D1iFi 0I 0 R 0 i (Y ) 0 S i (Y ) &lt; 0 (34) A 0 i X i + X i A i + L i C 2i + C 0 2i L 0 i + C 0 1i C 1i + N j=1 ij X j X i E i + L i D 2i E 0 i X i + D 0 2i L 0 i 0 2 I &lt; 0 (38) Y i I I X i &gt; 0; AiYi + YiA 0 i + BiFi + F 0 i B 0 i + iiYi + 02 EiE 0 i (C1iYi + D1iFi) 0 Ri(Y ) C1iYi + D1iFi 0I 0 R 0 i (Y ) 0 S i (Y ) &lt; 0 (39)</formula><p>obtained from the connection of G0 and G f with output et = zt 0 ẑt.</p><p>Similarly, the H 1 -filtering problem is to find (A c ; B c ; C c ) such that for some &gt; 0, kG e k 1 &lt; .</p><p>The augmented MJLS made up by system G0 and the filter G f can be written as</p><formula xml:id="formula_32">Ãi = A i 0 B ci C 2i A ci ; Ẽi = E i B ci D 2i</formula><p>Ci = [C 1i 0C ci ] ; i= 1; 111 ; N:</p><p>(41)</p><p>If we compare the above parameters with those of the output feedback control problem (32), we verify that the problem here is a particular case of that one, with B i = 0 and D 1i = 0I. Therefore, we can find the H2 and H1 filters in terms of LMI's in a straightforward manner, from the corresponding control results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. H2-Filtering</head><p>Notice that a particular filter structure is imposed by G f , which comprises all linear n-dimensional filters that can vary on time only when the 2 state jumps. The Kalman filter for MJLS <ref type="bibr" target="#b10">[11]</ref>, also aims at the minimum mean square error but it is intrinsically a time variant filter and no steady state solution can be found, in contrast with the case of linear systems embedded in additive Gaussian noise. </p><p>subject to (35) and </p><formula xml:id="formula_34">X i X i E i + L i D 2i E 0 i X i + D 0 2i L 0 i Z i &gt; 0<label>(</label></formula><p>One should be aware of the duality between the filter problem above and the H2 state feedback control as it appears for instance in <ref type="bibr" target="#b15">[16]</ref>. Another correspondence between these problems was also indicated in <ref type="bibr" target="#b13">[14]</ref>, considering the change of variables Ai = A 0 i , C2i = B 0 i , L i = F 0 i , C 1i = E 0 i , E i = C 0 1i , D 2i = D 0 1i , and 3 = 3 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. H1-Filtering</head><p>Similarly to the H2-filtering problem, one can observe that the solution of the H 1 -filtering problem formulated above can be expressed by a reduction from the H 1 -norm problem of output feedback control. </p><formula xml:id="formula_36">C ci = F i Y 01 i = C 1i B ci = Y 01 i 0 X i 01 L i = 0X 01 i L i A ci = Y 01 i 0 X i 01 M i Y 01 i = A i 0 B ci C 2i : VI. APPLICATION</formula><p>We applied the H2 and H1-norm control techniques to a VTOL helicopter model presented in <ref type="bibr" target="#b14">[15]</ref>. The dynamics can be written as _x = A( t )x + B( t )u + Ew z = C1x + D1u y = C 2 x + D 2 w where t indicates the airspeed and the state variables are the horizontal velocity (x 1 ), the vertical velocity (x 2 ), the pitch rate (x 3 ), and the pitch angle (x4). The initial distributions we adopt are (0.3333, 0.3333, 0.3333), (0.6, 0.3, 0.1) and (0.6, 0.1, 0.3), the corresponding stationary distributions for each case. We solved the control problems of minimizing the H 2 and H 1 norms, and the results can be seen in Table <ref type="table">II</ref>.</p><p>The advantage of using Markov jump systems can be clearly seen. In this example, a refined description of the airspeed is included in the model, if we compare with that used in guaranteed control <ref type="bibr" target="#b8">[9]</ref>. For instance, one would only be able to impose that the parameters a32, a34, and b 2i lie in a certain convex set, without knowing how they would change with time. Taking into account the information on how the airspeed can vary, we can provide less restrictive conditions for stability, leading to controllers with better performance. One should notice that in the guaranteed cost approach, the system must be stable for all values of a32, a34, and b2i in the convex set in consideration, whereas in the stochastic stability framework, stability of all operation modes is not even required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nonlinear Repetitive Control</head><p>Jayati Ghosh and Brad Paden </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Periodic signals commonly occur in robotics, servo mechanisms, and other similar tracking scenarios, either in form of reference inputs or disturbances. In linear time-invariant plants, repetitive control builds on the well-known internal model principle <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref> to provide exact asymptotic output tracking of periodic inputs. The internal model principle states that the output of a plant can be made to asymptotically track a class of reference commands without a steady-state error if the generator for the reference signal is included in the stable closed-loop system. If a periodic input signal has a finite Fourier series, then a finite number of internal models (one for each harmonic) can be used to produce asymptotic tracking. Likewise, if the periodic input has an infinite Fourier series, an infinite number of controller models (i.e., j!-axis poles) are required for exact tracking. Fortunately, a simple delay line can be used to produce an infinite number of poles, but the system dynamics are, nonetheless, infinite dimensional. Such periodic tracking problems are surprisingly common. For example, every computer disk drive uses some type of linear repetitive control to compensate for repeatable runout in the disk bearings. Other applications of significant economic value include eccentricity compensation in rolling mills, noncircular machining of pistons and camshafts, AFM control, and optical turning.</p><p>The innovation of repetitive control was motivated by a power supply regulation problem and is due to Inoue et al. <ref type="bibr" target="#b3">[4]</ref>. Early progress was made in papers by Nakano, Iwai, Omata, and Hara <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, culminating in a seminal paper on the stability of linear infinite-dimensional repetitive controllers <ref type="bibr" target="#b6">[7]</ref>. Repetitive control theory became more accessible with the appealing discrete-time formulation of Tomizuka et al. <ref type="bibr" target="#b7">[8]</ref>; the discrete-time formulation was developed further to cover robustness analysis <ref type="bibr" target="#b8">[9]</ref>. Disturbance rejection is a particularly important problem in repetitive control, and this has been addressed in the context of the discrete-time formulation for disk-drive shock disturbance rejection <ref type="bibr" target="#b9">[10]</ref>. The discrete-time formulation also allows segments of a periodic reference input to be selected for exact tracking, thus saving computer memory <ref type="bibr" target="#b10">[11]</ref>. The repetitive control theory community joined forces with the multivariable control community beginning with the work of Ledwich and Bolton <ref type="bibr" target="#b11">[12]</ref>. Further research on linear repetitive control design is due to Güvenc <ref type="bibr" target="#b12">[13]</ref> where sensitivity minimization at discrete points is used to design a repetitive controller. Roh and Chung</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 2 . 1 :</head><label>21</label><figDesc>The assertions below are equivalent. a) System G 0 is MSS. b) The linear inequalities A 0 i P i + P i A i + N j=1 ij P j &lt; 0; i= 1; 1 1 1 ; N (2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Definition 2 . 2 :</head><label>22</label><figDesc>We define the H 2 -norm of an MSS system G 0 as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Remark 2 . 1 :</head><label>21</label><figDesc>A very interesting property obtained from Proposition 2.1-d) is the increasing behavior for the solutions Pi &gt; 0 of A 0 i Pi + PiAi + N j=1 ij Pj + C 0 1i C1i &lt; 0; i= 1; 1 1 1 ; N: (6)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 .</head><label>2</label><figDesc>(E 0i PiEi). In other words, feasible solutions of the above linear matrix inequalities provide upper bounds to the H 2 -norm. Besides, we can find P i arbitrarily close to W i , and the H2-norm can be found by the following optimization problem:s.t. A 0 i P i + P i A i + N j=1 ij P j + C 0 1i C 1i &lt; 0; i= 1; 1 1 1 ; N:If the model G0 is MSS and w 2 L m 2 , then from Proposition 2.2 we have that z 2 L p 2 . The next definition is a generalization of the H 1 -norm for MJLS's.Definition 2.3: The H1-norm of an MSS system G0 , kG0k1 is the smallest &gt; 0, such that kzk 2 &lt; kwk 2 holds for all w 2 L m Propostition 2.4<ref type="bibr" target="#b5">[6]</ref>: If P = (P 1 ; 1 1 1 ; P N ); P i &gt; 0 satisfies N; then kG0 k1 &lt; .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 3 . 1 :</head><label>31</label><figDesc>There exist Pi &gt; 0, Aci, Bci; and Cci; i = 1; 111 ; N such that (7) holds if</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>i</head><label></label><figDesc>and to the right by JiTi we get that performing the indicated calculations, yields (18), shown at the bottom of this page, where</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Ãi , Ẽi ; and Ci are given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>that (30) ensures stochastic stability for the closed-loop system of approaching solutions to the problem of minimizing The next theorem casts solution terms of LMI's; the proof is omitted, since it is immediate from Theorem 3.1, (29)-(31) and Remark 2.1. Theorem 4.1: The H 2 output feedback control problem is solved by the following LMI problem: 34), as shown at the bottom of this page, and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Ã0 i P i + P i Ãi + C0 i Ci + 02 P i Bi B0 i P i + N j=1 ij P j &lt; 0 (37) i = 1; 111 ; N, can be rephrased in LMI form.Theorem 4.2: The H 1 constraints (37) are equivalent to (38) and (39), shown at the bottom of this page. The corresponding compensatorG c is given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Theorem 5 . 1 :</head><label>51</label><figDesc>The H2-filtering problem can be written as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>43) i = 1; 111 ; N; and the filter parameters are C ci = C 1i Bci = 01 Li ci = A B C ; i= 1; 11 1; N:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Lemma 5 . 1 :</head><label>51</label><figDesc>Each feasible H1-norm filter is parameterized by the LMI's in (38), and the filter G f is given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>The parameters are given by A( t ) = 00:0366 0:0271 0:0188 00:4555 0:0482 01:01 0:0024 04:0208 0:1002 a32(t) 00:707 a34(t)We modeled the behavior of t as a Markov chain with three different states, corresponding to airspeeds of 135 (nominal value), 60, and 170 knots. The values of parameters a32, a34, and b32 are shown in TableI. Three different transition matrices are considered</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Abstract-</head><label></label><figDesc>Repetitive controllers are generally applied to reject periodic disturbances and to track periodic reference signals with a known period. Their design is based on The Internal Model Principle, proposed by Francis and Wonham. This paper describes a new finite-dimensional SISO repetitive controller for two different classes of nonlinear plants. Simulation results show asymptotic tracking of the periodic reference signal by the proposed repetitive controller in closed loop up to the th harmonic frequency. A proof of robustness of the repetitive control system to small nonlinearities, like actuator nonlinearities, is provided. Index Terms-Internal model principle, nonlinear, tracking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript received September 1, 1998; revised July 21, 1999. Recommended by Associate Editor, T. Katayama. This work was supported in part by Fundação de Amparo à Pesquisa do Estado de São Paulo, FAPESP and Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq.</figDesc><table /><note><p><p><p>D. P. de Farias, J. C. Geromel, and J. B. R. do Val are with LAC-DT, School of Electrical and Computer Engineering, UNICAMP, 13081-970, Campinas, SP, Brazil.</p>O. L. V. Costa is with the Department of Electronic Engineering, USP, 05508-000, São Paulo, SP, Brazil.</p>Publisher Item Identifier S 0018-9286(00)04062-9.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>= C 1 ( t )x t + D 1 ( t )u t y t = C 2 ( t )x t + D 2 ( t )w t;</figDesc><table /><note><p>28) set of matrices associated to the sets A; C1; C2; E; D2 to form the controlled stochastic system G: _ xt = A(t)xt + E(t)wt + B(t)ut z t</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommended by Associate Editor, J. Si. This work was supported in part by the National Science Foundation under Grant CMS-9800294.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Continuous-time regulation of a class of econometric models</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Blair</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Sworder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="341" to="346" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Feron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Balakrishnan</surname></persName>
		</author>
		<title level="m">Linear Matrix Inequalities in System and Control Theory</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Colaneri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Geromel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Locatelli</surname></persName>
		</author>
		<title level="m">Control Theory and Design-An RH /RH Viewpoint</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Continuous-time state-feedback H -control of Markovian jump linear systems via convex analysis</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L V</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B R</forename><surname>Val</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Geromel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1999</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>De</surname></persName>
		</author>
		<title level="m">Otimização e controle de sistemas com parâmetros sujeitos a saltos markovianos</title>
		<imprint>
			<publisher>UNICAMP</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note type="report_type">M.Sc. thesis</note>
	<note>in Portuguese</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">H control for linear systems with Markovian jumping parameters</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Fragoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Theory Advanced Technol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="457" to="466" />
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Solutions for the linear quadratic control problem of Markov jump linear systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B R</forename><surname>Val</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Geromel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L V</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optimization Theory Appl</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Lyapunov for optimal control of jump linear systems steady state</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gajic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Borno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1971" to="1975" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On a convex parameter space method for linear control design of uncertain systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Geromel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bernussou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L D</forename><surname>Peres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Contr. Opt</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="381" to="402" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Controllability, stabilizability, and continuous-time Markovian jump linear quadratic control</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Chizeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="777" to="788" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Jump linear quadratic Gaussian control in continuous time</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1884" to="1892" />
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Output feedback for a class of linear systems with jump parameters</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mariton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bertrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="898" to="900" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Almost sure and moments stability of jump linear systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mariton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Contr. Lett</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="393" to="397" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Jump Linear Systems in Automatic Control</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Marcel Dekker</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Identification and optimization of aircraft dynamics</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Narendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Aircraft</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="193" to="199" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">LMI optimization for nonstandard Riccati equations arising in stochastic control</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1666" to="1671" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
