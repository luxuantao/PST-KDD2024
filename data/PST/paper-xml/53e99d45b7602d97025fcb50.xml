<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Privacy in Electronic Commerce and the Economics of Immediate Gratification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Alessandro</forename><surname>Acquisti</surname></persName>
							<email>acquisti@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Heinz III School of Public Policy and Management</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><surname>John</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Heinz III School of Public Policy and Management</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Privacy in Electronic Commerce and the Economics of Immediate Gratification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C632B3E9CAC6AB45BC39D69561F70659</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>J.4 [Social and Behavioral Sciences]: Economics; K.4.1 [Public Policy Issues]: Privacy Economics</term>
					<term>Security</term>
					<term>Human Factors Privacy</term>
					<term>Electronic Commerce</term>
					<term>Immediate Gratification</term>
					<term>Hyperbolic Discounting</term>
					<term>Self-Control Problems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dichotomies between privacy attitudes and behavior have been noted in the literature but not yet fully explained. We apply lessons from the research on behavioral economics to understand the individual decision making process with respect to privacy in electronic commerce. We show that it is unrealistic to expect individual rationality in this context. Models of self-control problems and immediate gratification offer more realistic descriptions of the decision process and are more consistent with currently available data. In particular, we show why individuals who may genuinely want to protect their privacy might not do so because of psychological distortions well documented in the behavioral literature; we show that these distortions may affect not only 'naïve' individuals but also 'sophisticated' ones; and we prove that this may occur also when individuals perceive the risks from not protecting their privacy as significant.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Commission study reported in 2000 that sixty-seven percent of consumers were "very concerned" about the privacy of the personal information provided on-line <ref type="bibr" target="#b11">[11]</ref>. More recently, a February 2002 Harris Interactive survey found that the three biggest consumer concerns in the area of on-line personal information security were: companies trading personal data without permission, the consequences of insecure transactions, and theft of personal data <ref type="bibr" target="#b19">[19]</ref>. According to a Jupiter Research study in 2002, "$24.5 billion in on-line sales will be lost by 2006 -up from $5.5 billion in 2001. Online retail sales would be approximately twenty-four percent higher in 2006 if consumers' fears about privacy and security were addressed effectively" <ref type="bibr" target="#b21">[21]</ref>. Although the media hype has somewhat diminished, risks and costs have notas evidenced by the increasing volumes of electronic spam and identity theft <ref type="bibr" target="#b16">[16]</ref>.</p><p>Surveys in this field, however, as well as experiments and anecdotal evidence, have also painted a different picture. <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b21">21]</ref> have found evidence that even privacy concerned individuals are willing to trade-off privacy for convenience, or bargain the release of very personal information in exchange for relatively small rewards. The failure of several on-line services aimed at providing anonymity for Internet users <ref type="bibr" target="#b6">[6]</ref> offers additional indirect evidence of the reluctance by most individuals to spend any effort in protecting their personal information.</p><p>The dichotomy between privacy attitudes and behavior has been highlighted in the literature. Preliminary interpretations of this phenomenon have been provided <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b40">40]</ref>. Still missing are: an explanation grounded in economic or psychological theories; an empirical validation of the proposed explanation; and, of course, the answer to the most recurring question: should people bother at all about privacy?</p><p>In this paper we focus on the first question: we formally analyze the individual decision making process with respect to privacy and its possible shortcomings. We focus on individual (mis)conceptions about their handling of risks they face when revealing private information. We do not address the issue of whether people should actually protect themselves. We will comment on that in Section 5, where we will also discuss strategies to empirically validate our theory.</p><p>We apply lessons from behavioral economics. Traditional economics postulates that people are forward-looking and bayesian updaters: they take into account how current behavior will influence their future well-being and preferences. For example, <ref type="bibr" target="#b5">[5]</ref> study rational models of addiction. This approach can be compared to those who see in the decision not to protect one's privacy a rational choice given the (supposedly) low risks at stake. However, developments in the area of behavioral economics have highlighted various forms of psychological inconsistencies (self-control problems, hyperbolic discounting, present-biases, etc.) that clash with the fully rational view of the economic agent. In this paper we draw from these developments to reach the following conclusions:</p><p>• We show that it is unlikely that individuals can act rationally in the economic sense when facing privacy sensitive decisions.</p><p>• We show that alternative models of personal behavior and time-inconsistent preferences are compatible with the dichotomy between attitudes and behavior and can better match current data. For example, they can explain the results presented by <ref type="bibr" target="#b36">[36]</ref> at the ACM EC '01 conference. In their experiment, self-proclaimed privacy advocates were found to be willing to reveal varying amounts of personal information in exchange for small rewards.</p><p>• In particular, we show that individuals may have a tendency to under-protect themselves against the privacy risks they perceive, and over-provide personal information even when wary of (perceived) risks involved.</p><p>• We show that the magnitude of the perceived costs of privacy under certain conditions will not act as deterrent against behavior the individual admits is risky.</p><p>• We show, following similar studies in the economics of immediate gratification <ref type="bibr" target="#b31">[31]</ref>, that even 'sophisticated' individuals may under certain conditions become 'privacy myopic.'</p><p>Our conclusion is that simply providing more information and awareness in a self-regulative environment is not sufficient to protect individual privacy. Improved technologies, by lowering costs of adoption and protection, certainly can help. However, more fundamental human behavioral responses must also be addressed if privacy ought to be protected.</p><p>In the next section we propose a model of rational agents facing privacy sensitive decisions. In Section 3 we show the difficulties that hinder any model of privacy decision making based on full rationality. In Section 4 we show how behavioral models based on immediate gratification bias can better explain the attitudes-behavior dichotomy and match available data. In Section 5 we summarize and discuss our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A MODEL OF RATIONALITY IN PRIVACY DECISION MAKING</head><p>Some have used the dichotomy between privacy attitudes and behavior to claim that individuals are acting rationally when it comes to privacy. Under this view, individuals may accept small rewards for giving away information because they expect future damages to be even smaller (when discounted over time and with their probability of occurrence).</p><p>Here we want to investigate what underlying assumptions about personal behavior would support the hypothesis of full rationality in privacy decision making.</p><p>Since <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b29">29]</ref> economists have been interested in privacy, but only recently formal models have started appearing <ref type="bibr" target="#b3">[3,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b40">40]</ref>. While these studies focus on market interactions between one agent and other parties, here we are interested in formalizing the decision process of the single individual. We want to see if individuals can be economically rational (forward-lookers, bayesian updaters, utility maximizers, and so on) when it comes to protect their own personal information.</p><p>The concept of privacy, once intended as the right to be left alone <ref type="bibr" target="#b41">[41]</ref>, has transformed as our society has become more information oriented. In an information society the self is expressed, defined, and affected through and by information and information technology. The boundaries between private and public become blurred. Privacy has therefore become more a class of multifaceted interests than a single, unambiguous concept. Hence its value may be discussed (if not ascertained) only once its context has also been specified. This most often requires the study of a network of relations between a subject, certain information (related to the subject), other parties (that may have various linkages of interest or association with that information or that subject), and the context in which such linkages take place.</p><p>To understand how a rational agent could navigate through those complex relations, in Equation 1 we abstract the decision process of an idealized rational economic agent who is facing privacy trade-offs when completing a certain transaction.</p><formula xml:id="formula_0">max d Ut = δ vE (a) , p d (a) + γ vE (t) , p d (t) -c d t (1)</formula><p>In Equation <ref type="formula">1</ref>, δ and γ are unspecified functional forms that describe weighted relations between expected payoffs from a set of events v and the associated probabilities of occurrence of those events p. More precisely, the utility U of completing a transaction t (the transaction being any action -not necessarily a monetary operation -possibly involving exposure of personal information) is equal to some function of the expected payoff vE (a) from maintaining (or not) certain information private during that transaction, and the probability of maintaining [or not maintaining] that information private when using technology d, p d (a) [1 -p d (a)]; plus some function of the expected payoff vE (t) from completing (or non completing) the transaction (possibly revealing personal information), and the probability of completing [or not completing] that transaction with a certain technology d, p d (t) [1 -p d (t)]; minus the cost of using the technology t: c d t . <ref type="foot" target="#foot_0">1</ref>The technology d may or may not be privacy enhancing. Since the payoffs in Equation 1 can be either positive or negative, Equation 1 embodies the duality implicit in privacy issues: there are both costs and benefits gained from revealing or from protecting personal information, and the costs and benefits from completing a transaction, vE (t), might be distinct from the costs and benefits from keeping the associated information private, vE (a). For instance, revealing one's identity to an on-line bookstore may earn a discount. Viceversa, it may also cost a larger bill, because of price discrimination. Protecting one's financial privacy by not divulging credit card information on-line may protect against future losses and hassles related to identity theft. But it may make one's on-line shopping experience more cumbersome, and therefore more expensive.</p><p>The functional parameters δ and γ embody the variable weights and attitudes an individual may have towards keeping her information private (for example, her privacy sensitivity, or her belief that privacy is a right whose respect should be enforced by the government) and completing certain transactions. Note that vE and p could refer to sets of payoffs and the associated probabilities of occurrence. The payoffs are themselves only expected because, regardless of the probability that the transaction is completed or the information remains private, they may depend on other sets of events and their associated probabilities. vE() and p d (), in other words, can be read as multi-variate parameters inside which are hidden several other variables, expectations, and functions because of the complexity of the privacy network described above.</p><p>Over time, the probability of keeping certain information private, for instance, will not only depend on the chosen technology d but also on the efforts by other parties to appropriate that information. These efforts may be function, among other things, of the expected value of that information to those parties. The probability of keeping information private will also depend on the environment in which the transaction is taking place. Similarly, the expected benefit from keeping information private will also be a collection over time of probability distributions dependent on several parameters. Imagine that the probability of keeping your financial transactions private is very high when you use a bank in Bermuda: still, the expected value from keeping your financial information confidential will depend on a number of other factors.</p><p>A rational agent would, in theory, choose the technology d that maximizes her expected payoff in Equation <ref type="formula">1</ref>. Maybe she would choose to complete the transaction under the protection of a privacy enhancing technology. Maybe she would complete the transaction without protection. Maybe she would not complete the transaction at all (d = 0). For example, the agent may consider the costs and benefits of sending an email through an anonymous MIX-net system <ref type="bibr" target="#b8">[8]</ref> and compare those to the costs and benefits of sending that email through a conventional, non-anonymous channel. The magnitudes of the parameters in Equation 1 will change with the chosen technology. MIX-net systems may decrease the expected losses from privacy intrusions. Nonanonymous email systems may promise comparably higher reliability and (possibly) reduced costs of operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RATIONALITY AND PSYCHOLOGICAL DISTORTIONS IN PRIVACY</head><p>Equation 1 is a comprehensive (while intentionally generic) road-map for navigation across privacy trade-offs that no human agent would be actually able to use.</p><p>We hinted to some difficulties as we noted that several layers of complexities are hidden inside concepts such as the "expected value of maintaining certain information private," and the "probability" of succeeding doing so. More precisely, an agent will face three problems when comparing the tradeoffs implicit in Equation <ref type="formula">1</ref>: incomplete information about all parameters; bounded power to process all available information; no deviation from the rational path towards utilitymaximization. Those three problems are precisely the same issues real people have to deal with on an everyday basis as they face privacy-sensitive decisions. We discuss each problem in detail.</p><p>1. Incomplete information. What information has the individual access to as she prepares to take privacy sensitive decisions? For instance, is she aware of privacy invasions and the associated risks? What is her knowledge of the existence and characteristics of protective technologies?</p><p>Economic transactions are often characterized by incomplete or asymmetric information. Different parties involved may not have the same amount of information about the transaction and may be uncertain about some important aspects of it <ref type="bibr" target="#b4">[4]</ref>. Incomplete information will affect almost all parameters in Equation 1, and in particular the estimation of costs and benefits. Costs and benefits associated with privacy protection and privacy intrusions are both monetary and immaterial. Monetary costs may for instance include adoption costs (which are probably fixed) and usage costs (which are variable) of protective technologies -if the individual decides to protect herself. Or they may include the financial costs associated to identity theft, if the individual's information turns out not to have been adequately protected. Immaterial costs may include learning costs of a protective technology, switching costs between different applications, or social stigma when using anonymizing technologies, and many others. Likewise, the benefits from protecting (or not protecting) personal information may also be easy to quantify in monetary terms (the discount you receive for revealing personal data) or be intangible (the feeling of protection when you send encrypted emails).</p><p>It is difficult for an individual to estimate all these values. Through information technology, privacy invasions can be ubiquitous and invisible. Many of the payoffs associated with privacy protection or intrusion may be discovered or ascertained only ex post through actual experience. Consider, for instance, the difficulties in using privacy and encrypting technologies described in <ref type="bibr" target="#b43">[43]</ref>.</p><p>In addition, the calculations implicit in Equation 1 depend on incomplete information about the probability distribution of future events. Some of those distributions may be predicted after comparable data -for example, the probability that a certain credit card transaction will result in fraud today could be calculated using existing statistics. The probability distributions of other events may be very difficult to estimate because the environment is too dynamicfor example, the probability of being subject to identity theft 5 years in the future because of certain data you are releasing now. And the distributions of some other events may be almost completely subjective -for example, the probability that a new and practical form of attack on a currently secure cryptosystem will expose all of your encrypted personal communications a few years from now.</p><p>This leads to a related problem: bounded rationality.</p><p>2. Bounded rationality. Is the individual able to calculate all the parameters relevant to her choice? Or is she limited by bounded rationality?</p><p>In our context, bounded rationality refers to the inability to calculate and compare the magnitudes of payoffs associated with various strategies the individual may choose in privacy-sensitive situations. It also refers to the inability to process all the stochastic information related to risks and probabilities of events leading to privacy costs and benefits.</p><p>In traditional economic theory, the agent is assumed to have both rationality and unbounded 'computational' power to process information. But human agents are unable to process all information in their hands and draw accurate conclusions from it <ref type="bibr" target="#b34">[34]</ref>. In the scenario we consider, once an individual provides personal information to other parties, she literally loses control of that information. That loss of control propagates through other parties and persists for unpredictable spans of time. Being in a position of information asymmetry with respect to the party with whom she is transacting, decisions must be based on stochastic assessments, and the magnitudes of the factors that may affect the individual become very difficult to aggregate, calculate, and compare. <ref type="foot" target="#foot_1">2</ref> Bounded rationality will affect the calculation of the parameters in Equation <ref type="formula">1</ref>, and in particular δ, γ, vE(), and pt(). The cognitive costs involved in trying to calculate the best strategy could therefore be so high that the individual may just resort to simple heuristics.</p><p>3. Psychological distortions. Eventually, even if an individual had access to complete information and could appropriately compute it, she still may find it difficult to follow the rational strategy presented in Equation <ref type="formula">1</ref>. A vast body of economic and psychological literature has by now confirmed the impact of several forms of psychological distortions on individual decision making. Privacy seems to be a case study encompassing many of those distortions: hyperbolic discounting, under insurance, self-control problems, immediate gratification, and others. The traditional dichotomy between attitude and behavior, observed in several aspects of human psychology and studied in the social psychology literature since <ref type="bibr" target="#b24">[24]</ref> and <ref type="bibr" target="#b13">[13]</ref>, may also appear in the privacy space because of these distortions.</p><p>For example, individuals have a tendency to discount 'hyperbolically' future costs or benefits <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b27">27]</ref>. In economics, hyperbolic discounting implies inconsistency of personal preferences over time -future events may be discounted at different discount rates than near-term events. Hyperbolic discounting may affect privacy decisions, for instance when we heavily discount the (low) probability of (high) future risks such as identity theft. <ref type="foot" target="#foot_2">3</ref> Related to hyperbolic discounting is the tendency to underinsure oneself against certain risks <ref type="bibr" target="#b22">[22]</ref>.</p><p>In general, individuals may put constraints on future behavior that limit their own achievement of maximum utility: people may genuinely want to protect themselves, but because of self-control bias, they will not actually take those steps, and opt for immediate gratification instead. "People tend to underappreciate the effects of changes in their states, and hence falsely project their current preferences over consumption onto their future preferences. Far more than suggesting merely that people mispredict future tastes, this projection bias posits a systematic pattern in these mispredictions which can lead to systematic errors in dynamicchoice environments" [25, p. 2].</p><p>In addition, individuals suffer from optimism bias <ref type="bibr" target="#b42">[42]</ref>, the misperception that one's risks are lower than those of other individuals under similar conditions. Optimism bias may lead us to believe that we will not be subject to privacy intrusions.</p><p>Individuals encounter difficulties when dealing with cumulative risks. <ref type="bibr" target="#b35">[35]</ref>, for instance, shows that while young smokers appreciate the long term risks of smoking, they do not fully realize the cumulative relation between the low risks of each additional cigarette and the slow building up of a serious danger. Difficulties with dealing with cumulative risks apply to privacy, because our personal information, once released, can remain available over long periods of time. And since it can be correlated to other data, the 'anonymity sets' <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b14">14]</ref> in which we wish to remain hidden get smaller. As a result, the whole risk associated with revealing different pieces of personal information is more than the sum of the individual risks associated with each piece of data.</p><p>Also, it is easier to deal with actions and effects that are closer to us in time. Actions and effects that are in the distant future are difficult to focus on given our limited foresight perspective. As the foresight changes, so does behavior, even when preferences remain the same <ref type="bibr" target="#b20">[20]</ref>. This phenomenon may also affects privacy decisions, since the costs of privacy protection may be immediate, but the rewards may be invisible (absence of intrusions) and spread over future periods of time.</p><p>To summarize: whenever we face privacy sensitive decisions, we hardly have all data necessary for an informed choice. But even if we had, we would be likely unable to process it. And even if we could process it, we may still end behaving against our own better judgment. In what follows, we present a model of privacy attitudes and behavior based on some of these findings, and in particular on the plight of immediate gratification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PRIVACY AND THE ECONOMICS OF IMMEDIATE GRATIFICATION</head><p>The problem of immediate gratification (which is related to the concepts of time inconsistency, hyperbolic discounting, and self-control bias) is so described by O'Donoghue and Rabin <ref type="bibr">[27, p. 4]</ref>: "A person's relative preference for wellbeing at an earlier date over a later date gets stronger as the earlier date gets closer. [...] [P]eople have self-control problems caused by a tendency to pursue immediate gratification in a way that their 'long-run selves' do not appreciate." For example, if you were given only two alternatives, on Monday you may claim you will prefer working 5 hours on Saturday to 5 hours and half on Sunday. But as Saturday comes, you will be more likely to prefer postponing work until Sunday.</p><p>This simple observation has rather important consequences in economic theory, where time-consistency of preferences is the dominant model. Consider first the traditional model of utility that agents derive from consumption: the model states that utility discounts exponentially over time:</p><formula xml:id="formula_1">Ut = T τ =t δ τ uτ<label>(2)</label></formula><p>In Equation <ref type="formula" target="#formula_1">2</ref>, the cumulative utility U at time t is the discounted sum of all utilities from time t (the present) until time T (the future). δ is the discount factor, with a value between 0 and 1. A value of 0 would imply that the individual discounts so heavily that the utility from future periods is worth zero today. A value of 1 would imply that the individual is so patient she does not discount future utilities. The discount factor is used in economics to capture the fact that having (say) one dollar one year from now is valuable, but not as much as having that dollar now. In Equation <ref type="formula" target="#formula_1">2</ref>, if all uτ were constant -for instance, 10 -and δ was 0.9, then at time t = 0 (that is, now ) u0 would be worth 10, but u1 would be worth 9.</p><p>Modifying the traditional model of utility discounting, <ref type="bibr" target="#b23">[23]</ref> and then <ref type="bibr" target="#b31">[31]</ref> have proposed a model which takes into account possible time-inconsistency of preferences. Consider Equation <ref type="formula" target="#formula_2">3</ref>:</p><formula xml:id="formula_2">Ut(ut, ut+1, ..., uT ) = δ t ut + β T τ =t+1 δ τ uτ<label>(3)</label></formula><p>Assume that δ, β ∈ [0, 1]. δ is the discount factor for intertemporal utility as in Equation <ref type="formula" target="#formula_1">2</ref>. β is the parameter that captures an individual's tendency to gratify herself immediately (a form of time-inconsistent preferences). When β is 1, the model maps the traditional time-consistent utility model, and Equation 3 is identical to Equation <ref type="formula" target="#formula_1">2</ref>. But when β is zero, the individual does not care for anything but today. In fact, any β smaller than 1 represents self-control bias.</p><p>The experimental literature has convincingly proved that human beings tend to have self-control problems even when they claim otherwise: we tend to avoid and postpone undesirable activities even when this will imply more effort tomorrow; and we tend to over-engage in pleasant activities even though this may cause suffering or reduced utility in the future.</p><p>This analytical framework can be applied to the study of privacy attitudes and behavior. Protecting your privacy sometimes means protecting yourself from a clear and present hassle (telemarketers, or people peeping through your window and seeing how you live -see <ref type="bibr" target="#b33">[33]</ref>); but sometimes it represents something akin to getting an insurance against future and only uncertain risks. In surveys completed at time t = 0, subjects asked about their attitude towards privacy risks may mentally consider some costs of protecting themselves at a later time t = s and compare those to the avoided costs of privacy intrusions in an even more distant future t = s + n. Their alternatives at survey time 0 are represented in Equation <ref type="formula">4</ref>.</p><formula xml:id="formula_3">min wrt x DU0 = β[(E(cs,p)δ s x) + (E(cs+n,i)δ s+n (1 -x))] (4)</formula><p>x is a dummy variable that can take values 0 or 1. It represents the individual's choice -which costs the individual opts to face: the expected cost of protecting herself at time s, E(cs,p) (in which case x = 1), or the expected costs of being subject to privacy intrusions at a later time s + n, E(cs+n,i).</p><p>The individual is trying to minimize the disutility DU of these costs with respect to x. Because she discounts the two future events with the same discount factor (although at different times), for certain values of the parameters the individual may conclude that paying to protect herself is worthy. In particular, this will happen when:</p><formula xml:id="formula_4">E(cs,p)δ s &lt; E(cs+n,i)δ s+n<label>(5)</label></formula><p>Now, consider what happens as the moment t = s comes. Now a real price should be paid in order to enjoy some form of protection (say, starting to encrypt all of your emails to protect yourself from future intrusions). Now the individual will perceive a different picture:</p><formula xml:id="formula_5">min wrt x DUs = E(cs,p)x + βE(cn,i)δ n (1 -x)<label>(6)</label></formula><p>Note that nothing has changed in the equation (certainly not the individual's perceived risks) except time. If β (the parameter indicating the degree of self-control problems) is less than one, chances are that the individual now will actually choose not to protect herself. This will in fact happen when:</p><formula xml:id="formula_6">E(cs,p) &gt; βE(cn,i)δ n<label>(7)</label></formula><p>Note that Disequalities 5 and 7 may be simultaneously met for certain β &lt; 1. At survey time the individual honestly claimed she wanted to protect herself in principlethat is, some time in the future. But as she is asked to make an effort to protect herself right now, she chooses to run the risk of privacy intrusion.</p><p>Similar mathematical arguments can be made for the comparison between immediate costs with immediate benefits (subscribing to a 'no-call' list to stop telemarketers from harassing you at dinner), and immediate costs with only future expected rewards (insuring yourself against identity theft, or protecting yourself from frauds by never using your credit card on-line), particularly when expected future rewards (or avoided risks) are also intangible: the immaterial consequences of living (or not) in a dossier society, or the chilling effects (or lack thereof) of being under surveillance.</p><p>The reader will have noticed that we have focused on perceived (expected) costs E(c), rather than real costs. We do not know the real costs and we do not claim that the individual does. But we are able to show that under certain conditions even costs perceived as very high (as during periods of intense privacy debate) will be ignored.</p><p>We can provide some fictional numerical examples to make the analysis more concrete. We present some scenarios inspired by the calculations in <ref type="bibr" target="#b31">[31]</ref>.</p><p>Imagine an economy with just 4 periods (Table <ref type="table" target="#tab_0">1</ref>). Each individual can enroll in a supermarket's loyalty program by revealing personal information. If she does so, the individual gets a discount of 2 during the period of enrollment, only to pay one unit each time thereafter because of price discrimination based on the information she revealed (we make no attempt at calibrating the realism of this obviously abstract example; the point we are focusing on is how time inconsistencies may affect individual behavior given the expected costs and benefits of certain actions). <ref type="foot" target="#foot_4">4</ref> Depending on which period the individual chooses for 'selling' her data, we have the undiscounted payoffs represented in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Imagine that the individual is contemplating these options and discounting them according to Equation <ref type="formula" target="#formula_2">3</ref>. Suppose that δ = 1 for all types of individuals (this means that for simplicity we do not consider intertemporal discounting) but β = 1/2 for time-inconsistent individuals and β = 1 for everybody else. The time-consistent individual will choose to join the program at the very last period and rip off a benefit of 2-1=1. The individual with immediate gratification problems, for whom β = 1/2, will instead perceive the benefits from joining now or in period 3 as equivalent (0.5), and will join the program now, thus actually making herself worse off.</p><p>[31] also suggest that, in addition to the distinction between time-consistent individuals and individuals with timeinconsistent preferences, we should also distinguish timeinconsistent individuals who are naïve from those who are sophisticated. Naïve time-inconsistent individuals are not aware of their self-control problems -for example, they are those who always plan to start a diet next week. Sophisticated time-inconsistent individuals suffer of immediate gratification bias, but are at least aware of their inconsistencies. People in this category choose their behavior today correctly estimating their future time-inconsistent behavior. Now consider how this difference affects decisions in another scenario, represented in Table <ref type="table" target="#tab_1">2</ref>. An individual is considering the adoption of a certain privacy enhancing technology. It will cost her some money both to protect herself and not to protect herself. If she decides to protect herself, the cost will be the amount she pays -for example -for some technology that shields her personal information. If she decides not to protect herself, the cost will be the expected consequences of privacy intrusions.</p><p>We assume that both these aggregate costs increase over time, although because of separate dynamics. As time goes by, more and more information about the individual has been revealed, and it becomes more costly to be protected against privacy intrusions. At the same time, however, intrusions become more frequent and dangerous.</p><p>In period 1, the individual may protect herself by spending 5, or she may choose to face a risk of privacy intrusion the following period, expected to cost 7. In the second period, assuming that no intrusion has yet taken place, she may once again protect herself by spending a little more, 6; or she may choose to face a risk of privacy intrusion the next (third) period, expected to cost 9. In the third period she could protect herself for 8 or face an expected cost of 15 in the following last period.</p><p>Here too we make no attempt at calibrating the values in Table <ref type="table" target="#tab_1">2</ref>. Again, we focus on the different behavior driven by heterogeneity in time-consistency and sophistication versus naïvete. We assume that β = 1 for individuals with no self control problems and β = 1/2 for everybody else. We assume for simplicity that δ = 1 for all.</p><p>The time-consistent individuals will obviously choose to protect themselves as soon as possible.</p><p>In the first period, naïve time-inconsistent individuals will compare the costs of protecting themselves then or face a privacy intrusion in the second period. Because 5 &gt; 7 * (1/2), they will prefer to wait until the following period to protect themselves. But in the second period they will be comparing 6 &gt; 9 * (1/2) -and so they will postpone their protection again. They will keep on doing so, facing higher and higher risks. Eventually, they will risk to incur the highest perceived costs of privacy intrusions (note again that we are simply assuming that individuals believe there are privacy risks and that they increase over time; we will come back to this concept later on).</p><p>Time-inconsistent but sophisticated individuals, on the other side, will adopt a protective technology in period 2 and pay 6. By period 2, in fact, they will (correctly) realize that if they wait till period 3 (which they are tempted to do, because 6 &gt; 9 * (1/2)), their self-control bias will lead them to postpone adopting the technology once more (because 8 &gt; 15 * (1/2)). Therefore they predict they would incur the expected cost 15 * (1/2), which is larger than 6the cost of protecting oneself in period 2. In period 1, however, they correctly predict that they will not wait to protect themselves further than period 2. So they wait till period 2, because 5 &gt; 6 * (1/2), at which time they will adopt a protective technology (see also <ref type="bibr" target="#b31">[31]</ref>).</p><p>To summarize, time-inconsistent people tend not to fully appreciate future risks and, if naïve, also their inability to deal with them. This happens even if they are aware of those risks and they are aware that those risks are increasing. As we learnt from the second scenario, time inconsistency can lead individuals to accept higher and higher risks. Individuals may tend to downplay the fact that single actions present low risks, but their repetition forms a huge liability: it is a deceiving aspect of privacy that its value is truly appreciated only after privacy itself is lost. This dynamics captures the essence of privacy and the so-called anonymity sets <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b14">14]</ref>, where each bit of information we reveal can be linked to others, so that the whole is more than the sum of the parts.</p><p>In addition, <ref type="bibr" target="#b31">[31]</ref> show that when costs are immediate, time-inconsistent individuals tend to procrastinate; when benefits are immediate, they tend to preoperate. In our context things are even more interesting because all privacy decisions involve at the same time costs and benefits. So we opt against using eCash <ref type="bibr" target="#b9">[9]</ref> in order to save us the costs of switching from credit cards. But we accept the risk that our credit card number on the Internet could be used ma- liciously. And we give away our personal information to supermarkets in order to gain immediate discounts -which will likely turn into price discrimination in due time <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b26">26]</ref>.</p><p>We have shown in the second scenario above how sophisticated but time-inconsistent individuals may choose to protect their information only in period 2. Sophisticated people with self-control problems may be at a loss, sometimes even when compared to naïve people with time inconsistency problems (how many privacy advocates do use privacy enhancing technologies all the time?). The reasoning is that sophisticated people are aware of their self-control problems, and rather than ignoring them, they incorporate them into their decision process. This may decrease their own incentive to behave in the optimal way now. Sophisticated privacy advocates might realize that protecting themselves from any possible privacy intrusion is unrealistic, and so they may start misbehaving now (and may get used to that, a form of coherent arbitrariness). This is consistent with the results by <ref type="bibr" target="#b36">[36]</ref> presented at the ACM EC '01 conference. <ref type="bibr" target="#b36">[36]</ref> found that privacy advocates were also willing to reveal personal information in exchange for monetary rewards.</p><p>It is also interesting to note that these inconsistencies are not caused by ignorance of existing risks or confusion about available technologies. Individuals in the abstract scenarios we described are aware of their perceived risks and costs. However, under certain conditions, the magnitude of those liabilities is almost irrelevant. The individual will take very slowly increasing risks, which become steps towards huge liabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION</head><p>Applying models of self-control bias and immediate gratification to the study of privacy decision making may offer a new perspective on the ongoing privacy debate. We have shown that a model of rational privacy behavior is unrealistic, while models based on psychological distortions offer a more accurate depiction of the decision process. We have shown why individuals who genuinely would like to protect their privacy may not do so because of psychological distortions well documented in the behavioral economics literature. We have highlighted that these distortions may affect not only naïve individuals but also sophisticated ones. Surprisingly, we have also found that these inconsistencies may occur when individuals perceive the risks from not protecting their privacy as significant.</p><p>Additional uncertainties, risk aversion, and varying attitudes towards losses and gains may be confounding elements in our analysis. Empirical validation is necessary to calibrate the effects of different factors.</p><p>An empirical analysis may start with the comparison of available data on the adoption rate of privacy technologies that offer immediate refuge from minor but pressing privacy concerns (for example, 'do not call' marketing lists), with data on the adoption of privacy technologies that offer less obviously perceivable protection from more dangerous but also less visible privacy risks (for example, identity theft insurances). However, only an experimental approach over different periods of time in a controlled environment may allow us to disentangle the influence of several factors. Surveys alone cannot suffice, since we have shown why survey-time attitudes will rarely match decision-time actions. An experimental verification is part of our ongoing research agenda.</p><p>The psychological distortions we have discussed may be considered in the ongoing debate on how to deal with the privacy problem: industry self-regulation, users' self protection (through technology or other strategies), or government's intervention. The conclusions we have reached suggest that individuals may not be trusted to make decisions in their best interests when it comes to privacy. This does not mean that privacy technologies are ineffective. On the contrary, our results, by aiming at offering a more realistic model of user-behavior, could be of help to technologists in their design of privacy enhancing tools. However, our results also imply that technology alone or awareness alone may not address the heart of the privacy problem. Improved technologies (with lower costs of adoption and protection) and more information about risks and opportunities certainly can help. However, more fundamental human behavioral mechanisms must also be addressed. Self-regulation, even in presence of complete information and awareness, may not be trusted to work for the same reasons. A combination of technology, awareness, and regulative policies -calibrated to generate and enforce liabilities and incentives for the appropriate parties -may be needed for privacy-related welfare increase (as in other areas of an economy: see on a related analysis <ref type="bibr" target="#b25">[25]</ref>).</p><p>Observing that people do not want to pay for privacy or do not care about privacy, therefore, is only a half truth. People may not be able to act as economically rational agents when it comes to personal privacy. And the question whether "do consumers care?" is a different question from "does privacy matter?" Whether from an economic standpoint privacy ought to be protected or not, is still an open question. It is a question that involves defining specific contexts in which the concept of privacy is being invoked. But the value of privacy eventually goes beyond the realms of economic reasoning and cost benefit analysis, and ends up relating to one's views on society and freedom. Still, even from a purely economic perspective, anecdotal evidence suggest that the costs of privacy (from spam to identity theft, lost sales, intrusions, and the like <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b26">26]</ref>) are high and increasing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>(Fictional)  expected payoffs from joining loyalty program.</figDesc><table><row><cell></cell><cell cols="4">Period 1 Period 2 Period 3 Period 4</cell></row><row><cell>Benefits from selling period 1</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Costs from selling period 1</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Benefits from selling period 2</cell><cell>0</cell><cell>2</cell><cell>0</cell><cell>0</cell></row><row><cell>Costs from selling period 2</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell></row><row><cell>Benefits from selling period 3</cell><cell>0</cell><cell>0</cell><cell>2</cell><cell>0</cell></row><row><cell>Costs from selling period 3</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>(Fictional) costs of protecting privacy and expected costs of privacy intrusions over time.</figDesc><table><row><cell></cell><cell cols="4">Period 1 Period 2 Period 3 Period 4</cell></row><row><cell>Protection costs</cell><cell>5</cell><cell>6</cell><cell>8</cell><cell>.</cell></row><row><cell>Expected intrusion costs</cell><cell>.</cell><cell>7</cell><cell>9</cell><cell>15</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>See also<ref type="bibr" target="#b1">[1]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The negative utility coming from future potential misuses of somebody's personal information could be a random shock whose probability and scope are extremely variable. For example, a small and apparently innocuous piece of information might become a crucial asset or a dangerous liability in the right</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>context.<ref type="bibr" target="#b3">3</ref> A more rigorous description and application of hyperbolic discounting is provided</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>in Section 4.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>One may claim that loyalty cards keep on providing benefits over time. Here we make the simplifying assumption that such benefits are not larger than the future costs incurred after having revealed one's tastes. We also assume that the economy ends in period 4 for all individuals, regardless of when they chose to join the loyalty program.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGMENTS</head><p>The author gratefully acknowledges Carnegie Mellon University's Berkman Development Fund, that partially supported this research. The author also wishes to thank Jens Grossklags, Charis Kaskiris, and three anonymous referees for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the economics of anonymity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Acquisti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dingledine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Financial Cryptography -FC &apos;03</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2742</biblScope>
			<biblScope unit="page" from="84" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Losses, gains, and hyperbolic discounting: An experimental approach to information security attitudes and behavior</title>
		<author>
			<persName><forename type="first">A</forename><surname>Acquisti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grossklags</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Annual Workshop on Economics and Information Security -WEIS &apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Conditioning prices on purchase history</title>
		<author>
			<persName><forename type="first">A</forename><surname>Acquisti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Varian</surname></persName>
		</author>
		<ptr target="http://www.heinz.cmu.edu/~acquisti/papers/privacy.pdf" />
	</analytic>
	<monogr>
		<title level="m">European Economic Association Conference</title>
		<meeting><address><addrLine>Venice, IT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-08">2001. August 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The market for &apos;lemons:&apos; quality uncertainty and the market mechanism</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Akerlof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="488" to="500" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A theory of rational addiction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Political Economy</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="675" to="700" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Understanding the privacy space</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Brunk</surname></persName>
		</author>
		<ptr target="http://firstmonday.org/issues/issue7_10/brunk/index.html" />
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On the optimality of privacy in sequential contracting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Calzolari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Gremaq, University of Toulouse</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Untraceable electronic mail, return addresses, and digital pseudonyms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="88" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Blind signatures for untraceable payments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology -Crypto &apos;82</title>
		<imprint>
			<publisher>Plenum Press</publisher>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="199" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Personalization versus privacy: An empirical examination of the online consumer&apos;s dilemma</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Forhtcoming</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Privacy online: Fair information practices in the electronic marketplace</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Commission</surname></persName>
		</author>
		<ptr target="http://www.ftc.gov/reports/privacy2000/privacy2000.pdf" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Identity fraud expected to triple by</title>
		<ptr target="http://www.cbai.org/Newsletter/December2001/identity_fraud_de2001.htm" />
		<imprint>
			<date type="published" when="2001">2005. 2001</date>
			<publisher>Community Banker Association of Indiana</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Professional attitudes and actual behavior</title>
		<author>
			<persName><forename type="first">S</forename><surname>Corey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="271" to="280" />
			<date type="published" when="1937">1937</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards measuring anonymity</title>
		<author>
			<persName><forename type="first">C</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Claessens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Preneel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Privacy Enhancing Technologies -PET &apos;02</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Syverson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Dingledine</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page">2482</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="http://www.ebusinessforum.com/index.asp?doc_id=1785&amp;layout=rich_story" />
		<title level="m">The great online privacy debate</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Identity theft heads the ftc&apos;s top 10 consumer fraud complaints of</title>
		<ptr target="http://www.ftc.gov/opa/2002/01/idtheft.htm" />
	</analytic>
	<monogr>
		<title level="m">Federal Trade Commission</title>
		<imprint>
			<date type="published" when="2001">2001. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Privacy, consumers, and costs -How the lack of privacy costs consumers and why business studies of privacy costs are biased and incomplete</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gellman</surname></persName>
		</author>
		<ptr target="http://www.epic.org/reports/dmfprivacy.html" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online information privacy: Measuring the cost-benefit trade-off</title>
		<author>
			<persName><forename type="first">I.-H</forename><surname>Harn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P L</forename><surname>Png</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd International Conference on Information Systems</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">First major post-9.11 privacy survey finds consumers demanding companies do more to protect privacy; public wants company privacy policies to be independently verified</title>
		<author>
			<persName><forename type="first">Harris</forename><surname>Interactive</surname></persName>
		</author>
		<ptr target="http://www.harrisinteractive.com/news/allnewsbydate.asp?NewsID=429" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Smoking today and stopping tomorrow: A limited foresight perspective</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jehiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lilico</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Department of Economics, UCLA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Seventy percent of US consumers worry about online privacy, but few take protective action</title>
		<ptr target="http://www.jmm.com/xp/jmm/press/2002/pr_060302.xml" />
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Jupiter Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Causes of underinsurance against natural disasters</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kunreuther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geneva Papers on Risk and Insurance</title>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Laibson</surname></persName>
		</author>
		<title level="m">Essays on hyperbolic discounting. MIT, Department of Economics</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attitudes versus actions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lapiere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Forces</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="230" to="237" />
			<date type="published" when="1934">1934</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Projection bias in predicting future utility</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lowenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>O'donoghue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University, Cornell University, and University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Privacy, economics, and price discrimination on the Internet</title>
		<author>
			<persName><forename type="first">A</forename><surname>Odlyzko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Electronic Commerce</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Choice and procrastination</title>
		<author>
			<persName><forename type="first">T</forename><surname>O'donoghue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quartely Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="121" to="160" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>The page referenced in the text refers to the 2000 working paper version</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An economic theory of privacy</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Regulation</title>
		<imprint>
			<date type="published" when="1978">May-June:19-26, 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The economics of privacy</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="405" to="409" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Nowhere to turn: Victims speak out on identity theft</title>
		<ptr target="http://www.privacyrights.org/ar/idtheft2000.htm" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Privacy Rights Clearinghouse</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The economics of immediate gratification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>O'donoghue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards an information theoretic metric for anonymity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Serjantov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Danezis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Privacy Enhancing Technologies -PET &apos;02</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Syverson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Dingledine</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2482</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Paying for privacy: Consumers and infrastructures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shostack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Annual Workshop on Economics and Information Security -WEIS &apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Models of bounded rationality</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">What does it mean to know a cumulative risk? Adolescents&apos; perceptions of short-term and long-term consequences of smoking</title>
		<author>
			<persName><forename type="first">P</forename><surname>Slovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="259" to="266" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">E-privacy in 2nd generation e-commerce: Privacy preferences versus actual behavior</title>
		<author>
			<persName><forename type="first">S</forename><surname>Spiekermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grossklags</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Berendt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Electronic Commerce (EC &apos;01)</title>
		<meeting>the ACM Conference on Electronic Commerce (EC &apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="38" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An introduction to privacy in economics and politics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Stigler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Legal Studies</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="623" to="644" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The paradoxical value of privacy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Syverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Annual Workshop on Economics and Information Security -WEIS &apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Private demands and demands for privacy: Dynamic pricing and the market for customer information</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Taylor</surname></persName>
		</author>
		<idno>02-02</idno>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Department of Economics, Duke University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Duke Economics Working Paper</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Vila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Greenstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molnar</surname></persName>
		</author>
		<title level="m">Why we can&apos;t be bothered to read privacy policies: Models of privacy economics as a lemons market. In 2nd Annual Workshop on Economics and Information Security -WEIS &apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The right to privacy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brandeis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Law Review</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="193" to="220" />
			<date type="published" when="1890">1890</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Optimistic biases about personal risks</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1232" to="1233" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Why Johnny can&apos;t encrypt: A usability evaluation of PGP 5.0</title>
		<author>
			<persName><forename type="first">A</forename><surname>Whitten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
