<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Privacy-Robustness-Utility Trilemma in Distributed Learning</title>
				<funder ref="#_gVr3MbY #_nvhEHE9">
					<orgName type="full">SNSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-05-29">29 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Youssef</forename><surname>Allouah</surname></persName>
							<email>&lt;youssef.allouah@epfl.ch&gt;.</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Ecole Polytechnique F?d?rale de Lausanne (EPFL)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Ecole Polytechnique F?d?rale de Lausanne (EPFL)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rachid</forename><surname>Guerraoui</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Ecole Polytechnique F?d?rale de Lausanne (EPFL)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nirupam</forename><surname>Gupta</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Ecole Polytechnique F?d?rale de Lausanne (EPFL)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rafa?l</forename><surname>Pinot</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Ecole Polytechnique F?d?rale de Lausanne (EPFL)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Stephan</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Ecole Polytechnique F?d?rale de Lausanne (EPFL)</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On the Privacy-Robustness-Utility Trilemma in Distributed Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-29">29 May 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2302.04787v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Although privacy and robustness have been extensively studied independently in distributed ML, their synthesis remains poorly understood. We present the first tight analysis of the error incurred by any algorithm ensuring robustness against a fraction of adversarial machines, as well as differential privacy (DP) for honest machines' data against any other curious entity. Our analysis exhibits a fundamental trade-off between privacy, robustness, and utility. To prove our lower bound, we consider the case of mean estimation, subject to distributed DP and robustness constraints, and devise reductions to centralized estimation of one-way marginals. We prove our matching upper bound by presenting a new distributed ML algorithm using a high-dimensional robust aggregation rule. The latter amortizes the dependence on the dimension in the error (caused by adversarial workers and DP), while being agnostic to the statistical properties of the data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Distributed machine learning (ML) has been playing a pivotal role in a wide range of applications <ref type="bibr" target="#b19">(Dean et al., 2012;</ref><ref type="bibr" target="#b0">Abadi et al., 2016)</ref>, due to an unprecedented growth in the complexity of ML models and the volume of data being used for training purposes. Distributed ML breaks a complex ML task into sub-tasks that are performed in a collaborative fashion. In the standard server-based architecture, n machines (a.k.a., workers) collaboratively train a global model on their datasets, with the help of a coordinator (the server). This is typically achieved through a distributed implementation of the renowned stochastic gradient descent (SGD) algorithm <ref type="bibr" target="#b10">(Bertsekas &amp; Tsitsiklis, 2015)</ref>. In distributed SGD (or DSGD), the server maintains a model which is updated iteratively by averaging gradients of the loss function associated with the model, computed by the different workers upon sampling random points from their local datasets. DSGD is particularly useful in cases where the data held by the workers is too sensitive to be shared, e.g., medical data collected by several hospitals <ref type="bibr" target="#b63">(Sheller et al., 2020)</ref>.</p><p>Privacy. Although DSGD inherently ensures privacy of the workers' data to an extent, by not sharing it explicitly, information leakage can still be significant. When the ML model maintained at the server is publicly released, it may be exposed to membership inference <ref type="bibr" target="#b64">(Shokri et al., 2016)</ref> or model inversion attacks <ref type="bibr" target="#b29">(Fredrikson et al., 2015;</ref><ref type="bibr" target="#b35">Hitaj et al., 2017;</ref><ref type="bibr" target="#b53">Melis et al., 2019)</ref> by external entities. Furthermore, upon observing the gradients and transient models during the learning procedure, curious machines (be they workers or the server itself) can infer sensitive information about the datasets held locally by the machines, or even reconstruct data points in certain scenarios <ref type="bibr" target="#b57">(Phong et al., 2017;</ref><ref type="bibr">Wang et al., 2019b;</ref><ref type="bibr">Zhu et al., 2019;</ref><ref type="bibr" target="#b78">Zhao et al., 2020)</ref>.</p><p>Robustness. In real-world distributed systems, it is arguably inevitable to encounter faulty workers that may deviate from their prescribed algorithm. This may result from hardware and software bugs, data corruption, network latency, or malicious adversaries controlling a subset of workers. To cover all such possible scenarios, it is common to assume that a fraction of the machines can be adversarial<ref type="foot" target="#foot_0">1</ref> and arbitrarily deviate from their algorithms. In the context of DSGD, adversarial workers may send incorrect gradients <ref type="bibr" target="#b28">(Feng et al., 2015;</ref><ref type="bibr" target="#b69">Su &amp; Vaidya, 2016)</ref> to the server and critically influence the learning procedure, as shown in <ref type="bibr" target="#b8">(Baruch et al., 2019;</ref><ref type="bibr" target="#b75">Xie et al., 2019)</ref>.</p><p>Integrating privacy and robustness. With the growing concerns and legal obligations regarding the processing of public data in AI-driven technologies <ref type="bibr">(EU, 2016)</ref>, privacy and robustness issues question the very applicability of ML in critical public domain services, such as healthcare or banking. It is thus natural to seek distributed ML methods that simultaneously ensure privacy and robustness. In fact, these aspects have separately received significant attention in the past. On the one hand, the standard statistical privacy requirement of (?, ?)-differential privacy ((?, ?)-DP) has been studied to a great extent in the context of distributed ML <ref type="bibr" target="#b17">(Choudhury et al., 2019;</ref><ref type="bibr" target="#b38">Hu et al., 2020;</ref><ref type="bibr" target="#b56">Noble et al., 2022)</ref>. On the other hand, numerous provably robust adaptations of DSGD have been proposed <ref type="bibr" target="#b11">(Blanchard et al., 2017;</ref><ref type="bibr" target="#b74">Xie et al., 2018;</ref><ref type="bibr" target="#b76">Yin et al., 2018;</ref><ref type="bibr" target="#b34">Gupta et al., 2021;</ref><ref type="bibr" target="#b27">Farhadkhani et al., 2022</ref>). Yet, the synthesis of privacy and robustness remains highly understudied in distributed ML. The few works on this topic, such as <ref type="bibr" target="#b32">(Guerraoui et al., 2021;</ref><ref type="bibr">Zhu &amp; Ling, 2022;</ref><ref type="bibr" target="#b73">Xiang &amp; Su, 2022;</ref><ref type="bibr" target="#b52">Ma et al., 2022)</ref>, only focus on per-step privacy, and provide loose upper bounds on the learning error. On the other hand, the guarantees presented in <ref type="bibr" target="#b15">(Cheu et al., 2021;</ref><ref type="bibr" target="#b1">Acharya et al., 2021)</ref> only apply to discrete distribution estimation subject to non-interactive local DP <ref type="bibr" target="#b43">(Kasiviswanathan et al., 2011)</ref>, a restricted case of distributed ML where each worker holds a single data point and can be queried only once.</p><p>An orthogonal line of work studied the case where the server is assumed not to be curious, i.e., data only needs to be protected against the public release of the model <ref type="bibr" target="#b23">(Dwork &amp; Lei, 2009;</ref><ref type="bibr">Liu et al., 2021b;</ref><ref type="bibr">Hopkins et al., 2022a;</ref><ref type="bibr" target="#b49">Liu et al., 2022)</ref>. In this setting, it was recently shown that privacy and robustness are mutually beneficial <ref type="bibr" target="#b31">(Georgiev &amp; Hopkins, 2022;</ref><ref type="bibr">Hopkins et al., 2022b)</ref>. However, the assumption of a non-curious server may not be viable, especially in applications such as healthcare and finance, where sovereignty of data must be protected at every stage of the learning procedure <ref type="bibr">(Lowy et al., 2023)</ref>. In this paper, we focus on the setting where the server itself may be curious, and we show that privacy and robustness are actually at odds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Contributions</head><p>We precisely characterize the privacy-robustness-utility trilemma in distributed learning. Specifically, we present the first tight analysis of the error incurred by any distributed ML algorithm that simultaneously ensures (i) robustness against a minority of adversarial workers, and (ii) differential privacy (DP) of each worker's data against curious entities including other workers and the server. In short, we show that, in addition to the usual separate costs of privacy and robustness, the learning accuracy necessarily degrades due to their interplay.</p><p>Main results. We consider a system of n workers up to f of which (of unknown identity) may be adversarial, and the remainder are honest. The server is assumed honest-butcurious <ref type="bibr" target="#b12">(Bonawitz et al., 2016)</ref>. Each honest worker holds a dataset comprising m points. The goal of the server is to learn a model, parameterized by a d-dimensional vector, incurring minimum loss over the collective dataset of the honest workers. We denote by G the heterogeneity <ref type="bibr">(Karim-ireddy et al., 2020;</ref><ref type="bibr">2022)</ref> between the honest datasets.</p><p>We show that a distributed learning algorithm that is robust to f adversarial workers, while ensuring (?, ?)-DP of each honest worker's data against the server (and other curious workers) incurs a training error in</p><formula xml:id="formula_0">? d ? 2 nm 2 + f n ? 1 ? 2 m 2 + f n ? G 2 , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where ? ignores the logarithmic terms.</p><p>The first and the third terms in (1) are the respective errors due to privacy and robustness separately. Importantly, the second term represents the additional cost of satisfying privacy and robustness simultaneously. We then present a new distributed ML algorithm, SAFE-DSHB<ref type="foot" target="#foot_1">2</ref> , which we prove yields a matching upper bound (up to a logarithmic factor) for the class of smooth and strongly convex loss functions, while ensuring both privacy and robustness. We also obtain an upper bound for smooth non-convex learning problems.</p><p>The key to proving the tightness of this trade-off is the robust high-dimension aggregation rule we introduce, namely SMEA<ref type="foot" target="#foot_2">3</ref> . As an important consequence of our result, we observe that the privacy-robustness trade-off (second term) is dominated by the privacy cost alone (first term) when the dimension d is larger than the number of adversarial workers f . This observation however does not mean that the tradeoff is not significant, but rather that it can be adequately controlled when using SMEA. This would not have been possible otherwise with the use of existing aggregation rules such as coordinate-wise or geometric median, for which the upper bound has an additional dimension factor in the privacy-robustness trade-off.</p><p>Independent contributions. As a byproduct of our analysis, we obtain several results that are of independent interest to both the robust distributed ML and the privacy communities. Indeed, our upper bound is tight for strongly convex losses, even when removing the privacy constraints. This is mainly due to the use of momentum in SAFE-DSHB (see Section 1.2 below) which allows obtaining an excess error that is independent of the variance of local stochastic gradients. This improves over the state-of-the-art analysis on robust distributed learning with strongly convex losses <ref type="bibr" target="#b18">(Data &amp; Diggavi, 2021)</ref>, which induces a suboptimal excess error. Besides, our analysis features a tighter dependence on heterogeneity in the excess error. Our lower bound on the cost of privacy (without robustness) also improves over the state-of-the-art <ref type="bibr">(Lowy &amp; Razaviyayn, 2023)</ref> as we make no assumptions on the interactivity of the algorithm and impose weaker conditions on the DP parameter ? (see Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Overview of Proof Techniques</head><p>Lower bound. We prove our lower bound by reducing distributed mean estimation to centralized estimation of oneway marginals (i.e. row-wise averages). We distinguish cases depending on the presence of adversarial workers. In each case, we start with a distributed algorithm A whose interactions with each worker are (?, ?)-DP, and then construct a centralized algorithm M using A. Depending on the case, we then use either the advanced composition theorem <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref> or an indistinguishability argument on the honest identities to relate the DP and utility guarantees of M to those of A. We conclude by applying lower bounds on centralized private estimation of one-way marginals <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref> to M.</p><p>Upper bound. To prove our matching upper bound, we present SAFE-DSHB, a privacy-preserving robust adaptation of DSGD. Our algorithm incorporates Polyak's momentum <ref type="bibr" target="#b58">(Polyak, 1964)</ref> and a Gaussian mechanism <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref> at the worker level, as well as SMEA, our robust aggregation rule at the server level. We identify a key property that, if satisfied by an aggregation rule, mitigates the curse of dimensionality that could impact the Gaussian mechanism. This property, called (f, ?)-robust averaging, requires the squared distance between the aggregate and the average of honest vectors to be bounded by ? times the spectral norm of the empirical covariance matrix of the honest vectors. Our aggregation rule, SMEA, satisfies (f, ?)-robust averaging for ? = O( f /n), while being agnostic to the statistical properties of honest inputs. Another critical element of our analysis is the tuning of the momentum coefficients to control the trade-off between the deviation from the true gradient and the reduction of the drift between honest workers' momentums. We achieve this through a novel Lyapunov function (a.k.a. potential function in optimization literature <ref type="bibr" target="#b62">(Schmidt et al., 2017)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Prior Work</head><p>Only a handful of works addressed the interplay between DP and robustness in distributed ML. It was conjectured that ensuring both these requirements is impractical, in the sense that it would require the batch size to grow with the model dimension <ref type="bibr" target="#b32">(Guerraoui et al., 2021)</ref>. However, the underlying analysis relied upon the criterion of (?, f )-Byzantine resilience <ref type="bibr" target="#b11">(Blanchard et al., 2017)</ref>, which has been recently shown to be a restrictive sufficient condition <ref type="bibr" target="#b41">(Karimireddy et al., 2021)</ref>. Subsequent works <ref type="bibr">(Zhu &amp; Ling, 2022;</ref><ref type="bibr" target="#b73">Xiang &amp; Su, 2022;</ref><ref type="bibr" target="#b52">Ma et al., 2022)</ref> augmented the RSA learning algorithm <ref type="bibr" target="#b45">(Li et al., 2019)</ref> with the sign-flipping or sign-Gaussian privacy mechanisms. However, these works only focus on per-step DP, and the presented upper bounds on the error of the proposed algorithms are loose.</p><p>Another line of work targeted the specific learning problem of discrete distribution estimation subject to non-interactive local DP <ref type="bibr" target="#b22">(Duchi et al., 2013)</ref> and robustness constraints. The bounds for this problem <ref type="bibr" target="#b15">(Cheu et al., 2021;</ref><ref type="bibr" target="#b1">Acharya et al., 2021)</ref> are comparable to ours in the particular scenario where each worker holds a single data point and the algorithm is non-interactive (can query each worker once). Although a recent paper <ref type="bibr" target="#b16">(Chhor &amp; Sentenac, 2023)</ref> considered a more general case where workers hold a batch of data points, the algorithm was still assumed non-interactive, and the data distribution identical for all the workers. It was also shown recently <ref type="bibr" target="#b46">(Li et al., 2022)</ref> that local DP and robustness are disentangled when the adversarial workers corrupt the data before randomization only, which however need not be the case in general. The aforementioned works being tailored to non-interactive local DP, it is not clear how to extend their results to the general distributed ML setting.</p><p>Significant attention was given to robust mean estimation under DP <ref type="bibr" target="#b23">(Dwork &amp; Lei, 2009;</ref><ref type="bibr">Liu et al., 2021b;</ref><ref type="bibr">Hopkins et al., 2022a;</ref><ref type="bibr" target="#b49">Liu et al., 2022)</ref>. However, as we pointed out, the corresponding results do not readily apply to our setting, as they would require the server to be non-curious. Moreover, robust mean estimation <ref type="bibr" target="#b21">(Diakonikolas et al., 2019;</ref><ref type="bibr" target="#b7">Ashtiani &amp; Liaw, 2022;</ref><ref type="bibr" target="#b49">Liu et al., 2022)</ref> typically assumes the honest inputs to be identically distributed, which need not be the case in a general distributed setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Paper Outline</head><p>Section 2 defines the problem and recalls some useful concepts. Sections 3 and 4 present our lower bound and the analysis of SAFE-DSHB. Section 5 presents SMEA and derives our matching upper bound. Section 6 discusses future work. We defer full proofs to appendices A-D, and experimental evaluation to Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Statement</head><p>We consider the classical server-based architecture comprising n workers w 1 , . . . , w n , and a central server. The workers hold local datasets D 1 , . . . , D n , each composed of m data points from an input space X , i.e., D i := {x</p><formula xml:id="formula_2">(i) 1 , . . . , x<label>(i)</label></formula><p>m } ? X m . For a given parameter vector ? ? R d , a data point x ? X has a real-valued loss function ?(?; x). The empirical loss function for each worker w i is defined by</p><formula xml:id="formula_3">L(?; D i ) := 1 m x?Di ?(?; x).</formula><p>The goal of the server is to compute an optimal parameter vector ? * minimizing the global empirical loss function L(?; D 1 , . . . , D n ) defined to be</p><formula xml:id="formula_4">L(?; D 1 , . . . , D n ) := 1 n n i=1 L(?; D i ).</formula><p>We assume that each loss L(?; D i ) is differentiable, and that L is lower bounded, i.e., inf ??R d L(?; D 1 , . . . , D n ) is finite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Robustness</head><p>We consider a setting where at most f out of n workers may be adversarial. Such workers may send arbitrary messages to the server, and need not follow the prescribed protocol. The identity of adversarial workers is a priori unknown to the server. Let H ? {1, . . . , n}, with |H| = n -f . We define</p><formula xml:id="formula_5">L H (?) := L(?; D i , i ? H) := 1 |H| i?H L(?; D i ).</formula><p>If H represents the indices of honest workers, the function L H is referred to as the global honest loss. An algorithm is deemed robust to adversarial workers if it enables the server to compute a minimum of the global honest loss <ref type="bibr" target="#b33">(Gupta &amp; Vaidya, 2020)</ref>. Formally, we define robustness as follows.</p><p>Definition 2.1 ((f, ?)-robust). A distributed algorithm is said to be (f, ?)-robust if it outputs a parameter ? such that</p><formula xml:id="formula_6">E L H ( ?) -L * ? ?,</formula><p>where L * := inf ??R d L H (?), and the expectation is taken over the randomness of the algorithm.</p><p>In other words, an algorithm A is said to be (f, ?)-robust if, in every execution of A, the server outputs a ?-approximate minimizer of the honest loss, despite the presence of up to f adversarial workers. Note that (f, ?)-robustness is in general impossible for any ? when f ? n 2 <ref type="bibr">(Liu et al., 2021a)</ref>. Thus, throughout the paper, we assume that f &lt; n 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Differential Privacy</head><p>Each honest worker w i , i ? H, aims to protect the privacy of their dataset D i against all other entities, i.e., the server and the other workers. To define our privacy requirement formally, we recall below the definition of item-level differential privacy (DP) <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref>, where two datasets are said to be adjacent if they differ by one item.</p><formula xml:id="formula_7">Definition 2.2 ((?, ?)-DP). Let ? ? 0, ? ? [0, 1]. A random- ized algorithm M : X m ? Y satisfies (?, ?)-DP if for any adjacent datasets D, D ? ? X m and subset S ? Y, we have P[M(D) ? S] ? e ? ? P [M(D ? ) ? S] + ?.<label>(2)</label></formula><p>We consider the server to be honest-but-curious, i.e., it follows the prescribed algorithm correctly, but may try to infer sensitive information about the workers' datasets. Thus, the workers must enforce privacy locally at their end.</p><p>We assume that the server can only query the dataset of a worker w i through a dedicated communication channel, and that there is no direct communication between the workers. Hence, for privacy in this context, we require the communications between the server and each honest worker to satisfy the criterion of DP in (2). In our context, we formalize this property below, inspired from <ref type="bibr" target="#b65">(Smith et al., 2017)</ref>.</p><formula xml:id="formula_8">Definition 2.3 ((?, ?)-distributed DP). Let ? ? 0, ? ? [0, 1]. Consider a randomized distributed algorithm A : X m?n ? Y.</formula><p>Let Z i be a function that outputs the transcript of communications between the server and worker w i during the execution of A. Algorithm A is said to satisfy (?, ?)distributed DP if for all i ? H, Z i satisfies (?, ?)-DP with respect to the dataset held by worker w i .</p><p>The above criterion of distributed DP reduces to local DP <ref type="bibr" target="#b43">(Kasiviswanathan et al., 2011;</ref><ref type="bibr" target="#b22">Duchi et al., 2013)</ref> when each local dataset comprises a single item (i.e., m = 1).</p><p>Moreover, an algorithm satisfying (?, ?)-distributed DP may be fully interactive, i.e., the queries made to the workers by the server may share arbitrary dependence <ref type="bibr" target="#b43">(Kasiviswanathan et al., 2011)</ref>. Hereafter, a distributed algorithm satisfying (?, ?)-distributed DP is simply said to be (?, ?)-DP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Assumptions</head><p>Our results are derived under standard assumptions. First, we recall that data heterogeneity can be modeled following the assumption below <ref type="bibr" target="#b40">(Karimireddy et al., 2020;</ref><ref type="bibr">2022)</ref>. Assumption 2.1 (Bounded heterogeneity). There exists G &lt; ? such that for all ? ? R d ,</p><formula xml:id="formula_9">1 |H| i?H ??L(?; D i ) -?L H (?)? 2 ? G 2 .</formula><p>To present the convergence guarantees of SAFE-DSHB, we make the following standard assumption on the variance of stochastic gradients <ref type="bibr" target="#b13">(Bottou et al., 2018)</ref>. Assumption 2.2 (Bounded variance). There exists ? &lt; ? such that for each honest worker w i , i ? H, and all ? ? R d ,</p><formula xml:id="formula_10">1 m x?Di ?? ? ?(?; x) -?L(?; D i )? 2 ? ? 2 .</formula><p>Additionally, we also assume the point-wise gradients to be bounded, as usually done when analyzing differentially private ML algorithms to circumvent the complications due to clipping <ref type="bibr" target="#b3">(Agarwal et al., 2018;</ref><ref type="bibr" target="#b56">Noble et al., 2022)</ref>. Assumption 2.3 (Bounded gradient). There exists C &lt; ? such that for all ? ? R d , i ? H, and x ? D i , ???(?; x)? ? C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Lower Bound</head><p>We now prove our lower bound on the error incurred by a (f, ?)-robust distributed algorithm, when ensuring (?, ?)-DP.</p><p>The main result is given in Theorem 3.1, whose full proof is deferred to Appendix A.5. To give insights about the proof, we detail three separate cases in sections 3.1, 3.2 and 3.3 where we respectively study f = 0, f ? 1 but no privacy is enforced, and the adversarial setting f ? 1 with privacy. <ref type="table"></ref>and<ref type="table">?, ? ? (0, 1</ref>). Consider arbitrary datasets D 1 , . . . , D n ? X m such that Assumption 2.1 is satisfied with G ? 1. Let A : X m?n ? R d be an (?, ?)-DP distributed algorithm. Assume that ? ? 1/4 2n ln (m + 1), and that 2 -m 1-? ? n? ? 1/8m 1+? for some ? ? (0, 1).</p><formula xml:id="formula_11">Theorem 3.1. Let X = R d , ? = ??? 2 , n ? 3, 0 ? f &lt; n/2, m ? 1,</formula><formula xml:id="formula_12">For any ? ? f +1 100(n-f ) , if A is (f, ?)-robust, then ? = ? d ? 2 nm 2 + f n ? 1 ? 2 m 2 + f n ? G 2 .</formula><p>Comparison with prior work. Our lower bound generalizes that of the non-adversarial centralized case. Specifically, specializing our lower bound to the case n = 1 yields the bound ? d ? 2 m 2 , which corresponds to the lower bound from centralized private ERM (Theorem V.5, Bassily et al. ( <ref type="formula">2014</ref>)) <ref type="foot" target="#foot_3">4</ref> . Second, we improve over a result from the non-adversarial private distributed learning literature (Theorem D.3, <ref type="bibr">Lowy &amp; Razaviyayn (2023)</ref>), where a similar lower bound is shown. While we consider distributed algorithm A as a black-box verifying (?, ?)-DP (as per Definition 2.3), the mentioned work imposes additional structure on A by assuming it to be round-based and to satisfy compositionality, which essentially abstracts the class of roundbased algorithms whose DP guarantees can be computed from advanced composition. Moreover, as the number of data points per worker m is typically greater than the number of workers n, our condition <ref type="bibr">(Lowy &amp; Razaviyayn, 2023)</ref>.</p><formula xml:id="formula_13">? = O( 1 / ? n log m) is arguably weaker than ? = O( 1 /m) in</formula><p>Discussion on assumptions. The assumptions on ?, ?, ? are only needed to use the lower bound from <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref>, which additionally features the log (1/?) factor. One could use the same proof technique as in <ref type="bibr" target="#b9">(Bassily et al., 2014)</ref> and remove these assumptions, at the expense of loosening the bound, e.g. an additional log m factor in the denominator of the first term appears.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Case I: Non-adversarial Setting</head><p>In this particular case, we assume all the workers to be honest, i.e., f = 0. However, the algorithm satisfies (?, ?)distributed DP. We show the following result.</p><formula xml:id="formula_14">Proposition 3.1. Let n, m ? 1, and ?, ? ? (0, 1). Con- sider X = {? 1 ? d } d and ? = ??? 2 . Consider an arbitrary (?, ?)-DP distributed algorithm A : X m?n ? R d . Assume</formula><p>that ? ? 1/4 2n ln (m + 1) and that 2 -m 1-? ? n? ? 1/8m 1+? for some ? ? (0, 1). For any ? ? 1/100, if A is (0, ?)-robust, then we must have</p><formula xml:id="formula_15">? = ? d ? 2 nm 2 .</formula><p>Sketch of proof. We consider the quadratic loss function. We derive a centralized DP algorithm M from A, and then reduce to private estimation of one-way marginals <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref>. Algorithm M runs A on n copies of the same dataset D ? X m . Thus, M inherits the error guarantee ? from A on estimating the average of D, but with a weaker (? n , ? n )-DP guarantee, due to the composition of n adaptive (?, ?)-DP queries (since A can query each of the n copies of D up to (?, ?)-DP budget). Using the centralized DP lower bound from <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref>, we have ? = ?(d log (1/? n )/? 2 n m 2 ). We bound ? n and ? n via advanced composition <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref> as follows:</p><formula xml:id="formula_16">? n = O(? n log (1/? ? )) (provided that ? is small enough) and ? n ? n? + ? ? ,</formula><p>where ? ? is carefully chosen to ensure that log (1/? n )/ log (1/? ? ) = ?(1) (provided ? is small enough). Substituting the above values of ? n and ? n in the above lower bound on ? proves the proposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Case II: No Privacy</head><p>Finally, we adapt the lower bound from robust distributed ML <ref type="bibr" target="#b42">(Karimireddy et al., 2022)</ref> to our robustness definition (Definition 2.1) in Proposition 3.2 below.</p><formula xml:id="formula_17">Proposition 3.2. Let Assumption 2.1 hold. Let n ? 1, 1 ? f &lt; n/2, and ? = 16f (n-2f ) (n-f ) 2 . Consider X = {? G ? ?d } d and ? = ??? 2 . If a distributed algorithm is (f, ?)-robust, then ? = ? f n ? G 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Case III: Adversarial Setting</head><p>We now state, in Proposition 3.3 below, the part of our bound where privacy and robustness are coupled.</p><formula xml:id="formula_18">Proposition 3.3. Let n ? 3, 1 ? f &lt; n/2, m ? 1, ?, ? ? (0, 1), and ? = 16f (n-2f ) (n-f ) 2 . Consider X = {? 1 ? d } d ? {? 1 ? ?d } d and ? = ??? 2 . Consider any (?, ?)- DP distributed algorithm A : X m?n ? R d . Assume that 2 -o(m) ? ? ? 1/m 1+?(1) . For any ? ? f +1 100(n-f ) , if A is (f, ?)-robust, then we must have ? = ? f + 1 n -f ? log (1/?) ? 2 m 2 .</formula><p>Sketch of proof. We consider the quadratic loss function, and reduce to the case d = 1 with a careful choice of datasets. We derive a centralized DP algorithm M from A, and then reduce to private estimation of one-way marginals <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref>. Algorithm M runs A on input dataset D ? X m together with the remaining n -1 datasets crafted as follows: f 'adversarial' datasets are filled with -1, while n -f -1 'honest' datasets are filled with +1. This ensures that, in all cases, M estimates the average of D better than at least an f -sized minority of datasets. Therefore, as A guarantees error ? on estimating the average of every group of n -f datasets' averages (by Definition 2.1), we can bound the error of estimating the average of D by ? = ?( n-f f +1 ?). We conclude by applying the aforementioned DP lower bound to M, which is (?, ?)-DP and ensures error ? in estimating the average of D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Our Algorithm: SAFE-DSHB</head><p>We prove in this section that our lower bound is tight. Specifically, we present a new distributed algorithm, SAFE-DSHB, which yields a matching upper bound. Upon describing SAFE-DSHB in Section 4.1, we analyze its privacy in Section 4.2 and convergence guarantees in Section 4.3 for smooth strongly convex and non-convex loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Description of SAFE-DSHB</head><p>Similar to DSGD, SAFE-DSHB is an iterative algorithm where the server initiates each iteration (or step) t ? 0 by broadcasting its current model parameter vector ? t to all the workers. The initial parameter vector ? 0 is chosen arbitrarily by the server. Upon receiving ? t from the server, each honest worker w i samples a mini-batch S (i) t of b ? m data points randomly from its local dataset D i without replacement. Then, w i computes the gradients ??(? t ; x) for all x ? S (i) t , clips each of them using a threshold value C and averages the clipped gradients to obtain a gradient estimate g (i)</p><p>t . Specifically,</p><formula xml:id="formula_19">g (i) t = 1 b x?S (i) t ??(? t ; x) ? min 1, C ???(? t ; x)? .</formula><p>To protect the privacy of its data, w i then obfuscates g</p><formula xml:id="formula_20">(i) t</formula><p>with Gaussian noise to obtain g(i) t , i.e.,</p><formula xml:id="formula_21">g(i) t = g (i) t + ? (i) t ; ? (i) t ? N 0, ? 2 DP I d ,</formula><p>where I d denotes the identity matrix of dimension d ? d, and N 0, ? 2 DP I d denotes a d-dimensional Gaussian distribution with mean 0 and covariance ? 2 DP I d . Finally, w i uses this noisy gradient to update its local Polyak's momentum <ref type="bibr" target="#b58">(Polyak, 1964)</ref> denoted by m (i) t , which is then sent to the server. Specifically, for t ? 1,</p><formula xml:id="formula_22">m (i) t = ? t-1 m (i) t-1 + (1 -? t-1 )g (i) t ,</formula><p>Algorithm 1 SAFE-DSHB Initialization: Initial model ? 0 , initial momentum m (i) 0 = 0 for each honest worker w i , robust aggregation F , DP noise ? DP , batch size b, clipping threshold C, learning rates {? t }, momentum coefficients {? t }, and total number of steps T .</p><p>1: for t = 0 . . . T -1 do 2:</p><p>Server broadcasts ? t to all workers.</p><p>3:</p><p>for every honest worker w i , i ? H, in parallel do 4:</p><p>Sample a mini-batch S (i)</p><p>t of size b at random from D i without replacement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Clip and average the mini-batch gradients:</p><formula xml:id="formula_23">g (i) t = 1 b x?S (i) t Clip (??(? t ; x); C) ,</formula><p>where Clip(g; C) := g ? min {1, C/ ?g?}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Add noise to the mini-batch average gradient:</p><formula xml:id="formula_24">g(i) t = g (i) t + ? (i) t ; ? (i) t ? N (0, ? 2 DP I d ). 7: Send m (i) t = ? t-1 m (i) t-1 + (1 -? t-1 )g (i)</formula><p>t .</p><p>8:</p><p>end for 9:</p><p>Server aggregates: R t = F (m</p><formula xml:id="formula_25">(1) t , . . . , m<label>(n)</label></formula><p>t ).</p><p>10:</p><p>Server updates the model: ? t+1 = ? t -? t R t . 11: end for 12: return ? uniformly sampled from {? 0 , . . . , ? T -1 }.</p><p>where m (i) 0 = 0 by convention, and ? t ? [0, 1] is referred to as the momentum coefficient. Recall that if worker w i is adversarial, then it may send an arbitrary value for its momentum m (i) t . Upon receiving the local momentums from all the workers, the server aggregates them using F to obtain R t = F (m (1) t , . . . , m (n) t ). Finally, the server updates the model ? t to</p><formula xml:id="formula_26">? t+1 = ? t -? t R t</formula><p>where ? t ? 0 is the learning rate at step t. The above procedure is repeated for a total of T steps, after which the server outputs ? which is sampled uniformly from the set {? 0 , . . . , ? T -1 }. The complete learning procedure is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Privacy of SAFE-DSHB</head><p>We present below the DP guarantee of SAFE-DSHB. To state closed-form expressions, we will assume that the batch size b is sufficiently small compared to m the number of data points per worker. This assumption is only made for pedagogical reasons, but is not necessary for the privacy analysis to hold. In particular, the expressions that result from removing this assumption are difficult to read and interpret <ref type="bibr">(Wang et al., 2019a)</ref>. We defer the full DP analysis without this assumption to Appendix C. Theorem 4.1. Consider Algorithm 1. Let ? &gt; 0, ? ? (0, 1) be such that ? ? log (1/?). There exists a constant k &gt; 0 such that, for a sufficiently small batch size b, when</p><formula xml:id="formula_27">? DP ? k ? 2C b max {1, b ? T log (1/?) m? }, Algorithm 1 is (?, ?)-DP.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Convergence of SAFE-DSHB</head><p>To present the convergence of SAFE-DSHB we first introduce below a criterion, namely (f, ?)-robust averaging, for an aggregation rule F that proves crucial in our analysis.</p><p>Definition 4.1. Let n ? 1, 0 ? f &lt; n/2 and ? ? 0. An aggregation rule F is said to be (f, ?)-robust averaging if for any vectors x 1 , . . . , x n ? R d , and any set S ? {1, . . . , n} of size n -f , the output</p><formula xml:id="formula_28">x = F (x 1 , . . . , x n ) satisfies ?x -x S ? 2 ? ? ? ? max 1 |S| i?S (x i -x S )(x i -x S ) ? ,</formula><p>where x S := 1 |S| i?S x i and ? max denotes the maximum eigenvalue. We refer to ? as the robustness coefficient of F .</p><p>Comparison to prior work. Our robustness criterion is stronger than existing ones: (f, ?)-robustness <ref type="bibr" target="#b5">(Allouah et al., 2023)</ref>, (f, ?)-resilience <ref type="bibr" target="#b27">(Farhadkhani et al., 2022)</ref> and (c, ? max )-ARAgg <ref type="bibr" target="#b42">(Karimireddy et al., 2022)</ref>. The last two works bound the error with the diameter of honest inputs, i.e., maximum squared pairwise distance. The latter is greater than the empirical variance (bound used in (f, ?)-robustness <ref type="bibr" target="#b5">(Allouah et al., 2023)</ref>), which itself is greater than the maximum eigenvalue of the empirical covariance (that we use) in high-dimensional spaces (i.e., d &gt; 1). In fact, the tight analysis of aggregation functions (e.g., trimmed mean, Krum) conducted in <ref type="bibr" target="#b5">(Allouah et al., 2023)</ref> through the lens of (f, ?)-robustness directly implies our (f, ? ? )-robust averaging criterion, with ? ? ? d ? ?. However, aggregation rules that are optimal w.r.t. (f, ?)robustness <ref type="bibr" target="#b5">(Allouah et al., 2023)</ref> may be suboptimal in our context, as we need to suppress the dimension dependence of ? for our tight bounds.</p><p>Tighter heterogeneity metric. We introduce a new metric G cov for quantifying the heterogeneity between the local gradients of honest workers' loss functions, which is arguably tighter than G defined in Section 3.2. Specifically,</p><formula xml:id="formula_29">G 2 cov := sup ??R d sup ?v??1 1 |H| i?H ?v, ?L(?; D i ) -?L H (?)? 2 .</formula><p>Note that G 2 cov above represents an upper bound on the spectral norm of the empirical covariance of honest gradients, which is smaller than their empirical variance G 2 . Moreover, if the gradients have a well-conditioned empirical covariance, then G cov has weaker dependence on d.</p><p>We state our convergence result below in Theorem 4.2. Essentially, we analyze the convergence of SAFE-DSHB with an (f, ?)-robust averaging aggregation F , under assumptions 2.2 and 2.3, for smooth strongly convex and non-convex loss functions. We use the following notation: <ref type="table">480, a 3 = 5760,</ref> and<ref type="table">a 4 = 270.</ref> (3) Theorem 4.2. Suppose that assumptions 2.2 and 2.3 hold true, and that L H is L-smooth. Let F satisfy the condition of (f, ?)-robust averaging. We let</p><formula xml:id="formula_30">L * = inf ??R d L H (?), L 0 = L H (? 0 ) -L * , a 1 = 240, a 2 =</formula><formula xml:id="formula_31">? 2 = ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP 1 + d n -f , where ? 2 b = 2(1-b m ) ? 2 b .</formula><p>Consider Algorithm 1 with T ? 1, the learning rates ? t and momentum coefficients ? t specified below. We prove that the following holds, where the expectation E [?] is over the randomness of the algorithm. 1. Strongly convex: Assume that L H is ?-strongly convex.</p><p>If</p><formula xml:id="formula_32">? t = 10 ?(t+a1 L ? ) and ? t = 1 -24L? t then E [L H (? T ) -L * ] ? 4a 1 ?G 2 cov ? + 2a 2 1 L? 2 ? 2 T + 2a 2 1 L 2 L 0 ? 2 T 2 . 2. Non-convex: If ? = min 1 24L , ? a4L0 2? ? a3LT</formula><p>and</p><formula xml:id="formula_33">? t = 1 -24L? then E ??L H ( ?)? 2 ? a 2 ?G 2 cov + ? a 3 a 4 LL 0 ? ? T + a 4 LL 0 T .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sketch of proof.</head><p>We show that at each step t, the descent L H (? t+1 ) -L H (? t ) can be bounded from above. Doing so is however non-trivial, as one needs to consider two conflicting effects: (i) the drift between honest momentums, and (ii) the deviation between the average honest momentum and the true gradient. To control this trade-off, we use increasing momentum coefficients and decreasing learning rates, and introduce an adapted Lyapunov function V t . Ignoring the constants, the function can be written as follows:</p><formula xml:id="formula_34">V t := (t + K) 2 ? E L H (? t ) -L * + 1 L ? t + ? L ? t ,</formula><p>where ? t := ?m t -?L H (? t )? 2 represents the deviation of the momentum from the true gradient,</p><formula xml:id="formula_35">? t := ? max 1 |H| i?H (m (i) t -m t )(m (i)</formula><p>t -m t ) ? represents the drift between the honest momentums, and K := L ? denotes the condition number of L H . Remark 4.3. Our strongly convex upper bound also holds true for the larger class of smooth ?-PL functions <ref type="bibr" target="#b39">(Karimi et al., 2016)</ref>, which includes some non-convex functions.</p><p>On the Privacy-Robustness-Utility Trilemma in Distributed Learning Comparison to prior work. Our convergence rate in O 1 T for strongly convex losses is optimal in the nonadversarial and privacy-free setting <ref type="bibr" target="#b2">(Agarwal et al., 2009)</ref>. We improve over the state-of-the-art strongly convex analysis <ref type="bibr" target="#b18">(Data &amp; Diggavi, 2021)</ref>, without privacy, which features a suboptimal excess term proportional to the stochastic noise ? 2 . Essentially, we remove this dependency on ? 2 thanks to the use of momentum, although our convergence rate is in O 1</p><p>T instead of being exponential as in <ref type="bibr" target="#b18">(Data &amp; Diggavi, 2021)</ref>. In fact, making ? 2 vanish at a rate 1 T is crucial in our setting, as the DP noise ? 2 DP scales with T (Theorem 4.1). We also improve over the state-of-the-art non-convex analysis <ref type="bibr" target="#b27">(Farhadkhani et al., 2022)</ref>. Namely, our analysis features a tighter characterization of the data heterogeneity G cov , instead of the traditional heterogeneity metric G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Tight Upper Bound</head><p>We present a new aggregation rule named SMEA (Smallest Maximum Eigenvalue Averaging) in Section 5.1, and show that it yields a tight upper bound in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Robust Aggregation: SMEA</head><p>Consider a set of n vectors x 1 , . . . , x n . Let S * be an arbitrary subset of [n] of size n -f with the smallest empirical maximum eigenvalue, i.e.,</p><formula xml:id="formula_36">S * ? argmin S?[n] |S|=n-f ? max 1 |S| i?S (x i -x S )(x i -x S ) ? .</formula><p>SMEA outputs the average of the inputs in S * , i.e.,</p><formula xml:id="formula_37">SMEA(x 1 , . . . , x n ) := 1 |S * | i?S * x i .</formula><p>Note that SMEA draws inspiration from the minimum diameter averaging method <ref type="bibr" target="#b25">(El Mhamdi et al., 2018)</ref>, which itself is reminiscent of the minimal volume ellipsoid method <ref type="bibr" target="#b61">(Rousseeuw, 1985)</ref>. We show that our aggregation rule satisfies the criterion of (f, ?)-robust averaging.</p><formula xml:id="formula_38">Proposition 5.1. Let f &lt; n/2. SMEA is (f, ?)-robust averaging with ? = 4f n -f 1 + f n -2f 2 .</formula><p>Proposition 5.1 implies that, when n ? (2 + ?)f for some constant ? &gt; 0, SMEA satisfies (f, ?)-robust averaging with ? = O( f /n). Importantly, SMEA satisfies this highdimensional robustness property while being agnostic to the statistical properties of the valid inputs, knowledge of which is key in designing efficient robust estimators <ref type="bibr" target="#b20">(Diakonikolas et al., 2017;</ref><ref type="bibr" target="#b67">Steinhardt et al., 2018)</ref> </p><formula xml:id="formula_39">(see Appendix B.2).</formula><p>Computational complexity. However, as SMEA involves computing the maximum eigenvalue of d-dimensional symmetric matrices, which is in O d 3 , the worst-case computational complexity of SMEA is O n f ? d 3 , which is exponential in f . This shortcoming of our method should be addressed in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Upper Bound</head><p>Upon combining the results in theorems 4.1, 4.2, Proposition 5.1, and ignoring the vanishing terms in T , we obtain Corollary 5.1 that quantifies the privacy-robustness-utility trade-off of SAFE-DSHB using the SMEA aggregation rule.</p><p>Corollary 5.1. Consider Algorithm 1 with aggregation F = SMEA, under the strongly convex setting of Theorem 4.2. Suppose that assumptions 2.1, 2.2, 2.3 hold, and that n ? (2 + ?)f , for some absolute constant ? &gt; 0.</p><formula xml:id="formula_40">Let ? &gt; 0, ? ? (0, 1) be such that ? ? log (1/?). Then, there exists a constant k &gt; 0 such that, if ? DP = k ? 2C /b max {1, b ? T log (1/?) /?m}, then Algorithm 1 is (?, ?)- DP and (f, ?)-robust where ? = O d log (1/?) ? 2 nm 2 + f n ? log (1/?) ? 2 m 2 + f n G 2 .</formula><p>Tightness. Our upper bound is tight, in the sense that it matches the lower bound, up to the logarithmic factor log (1/?) in the first term. We believe that it is not possible to improve upon our upper bound in general, but rather that it may be possible to improve our lower bound in Proposition 3.1, by including the factor log (1/?). This could be done, for example, by assuming the stronger R?nyi DP property <ref type="bibr" target="#b54">(Mironov, 2017)</ref>, satisfied by the Gaussian mechanism, instead of relying on the advanced composition theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>Applying machine learning in sensitive public domains requires algorithms that protect data privacy, while being robust to faults and adversarial behaviors. We present the first tight analysis of the error incurred by any distributed ML algorithm ensuring robustness to adversarial workers and differential privacy for honest machines' data against any other curious entity. Our algorithm SAFE-DSHB yields a tight upper bound for the class of smooth strongly convex problems, up to a logarithmic factor. Proving a tighter lower bound on the privacy cost, featuring the usual log (1/?) factor, is an appealing goal. Proving similar bounds for the non-strongly convex class is also of interest. Also, in Appendix E, we conduct small-scale experiments showing encouraging results using our aggregation rule SMEA (as well as other aggregation rules). Yet, while SMEA is simple and agnostic to the statistical properties of honest data, it has a high computational complexity. Deploying it on larger scale systems goes through designing variants with lower complexity, and this is also an interesting research direction. composing (?, ?)-DP across n adaptive queries. Thanks to the advanced composition theorem <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref>, we obtain that, for any ? ? ? (0, 1),</p><formula xml:id="formula_41">? n = ? 2n ln (1/? ? ) + n?(e ? -1), ? n = n? + ? ? .<label>(4)</label></formula><p>As ? ? (0, 1), we have e ? -1 ? 2? and thus</p><formula xml:id="formula_42">? n ? ? 2n ln (1/? ? ) + 2n? 2 . (<label>5</label></formula><formula xml:id="formula_43">)</formula><p>We now set ? ? as follows:</p><formula xml:id="formula_44">? ? = 1 (m + 1) 1+? ? (0, 1). (<label>6</label></formula><formula xml:id="formula_45">)</formula><p>We verify below the privacy conditions on M of Lemma A.1. We first prove that ln (1/? ? ) ? [n? 2 , 1/16n? 2 ), and then that</p><formula xml:id="formula_46">? n ? 4? n ln (1/? ? ) &lt; 1.</formula><p>Bound on ln (1/? ? ): Since we assume ? ? 1/4 2n ln (m + 1) (with m ? 1), we have</p><formula xml:id="formula_47">n? 2 ? 1/16 ? 1/16n? 2 .</formula><p>On the other hand, as m ? 1, it follows from the expression (6</p><formula xml:id="formula_48">) of ? ? that 1/? ? ? 2 and ln (1/? ? ) ? 1/4 ? n? 2 .</formula><p>Also, since ? ? 1/4 2n ln (m + 1) we have ln (m + 1) ? 1/32n? 2 , and thus (because ? ? (0, 1)) we have</p><formula xml:id="formula_49">ln (1/? ? ) = (1 + ?) ln (m + 1) &lt; 2 ln (m + 1) ? 1/16n? 2 . This proves that ln (1/? ? ) ? [n? 2 , 1/16n? 2 ).<label>(7)</label></formula><p>Bound on ? n : Thanks to (7), we have ln (1/? ? ) ? n? 2 . Thus, by taking square roots we have ?</p><formula xml:id="formula_50">? n ? ln (1/? ? ).</formula><p>Therefore, n? 2 ? ? n ln (1/? ? ). Then, using the bound on ? n in (5), we obtain</p><formula xml:id="formula_51">? n ? ? 2n ln (1/? ? ) + 2n? 2 ? ? 2n ln (1/? ? ) + 2? n ln (1/? ? ) ? 4? n ln (1/? ? ).</formula><p>On the other hand, since we showed in (7) that ln (1/? ? ) &lt; 1/16n? 2 , we have 4? n ln (1/? ? ) &lt; 1. This proves that</p><formula xml:id="formula_52">? n ? 4? n ln (1/? ? ) &lt; 1.<label>(8)</label></formula><p>From ( <ref type="formula" target="#formula_52">8</ref>), we have ? n ? (0, 1). From (4), we have ? n = n? + ? ? . Thus, by assumption on ? and ( <ref type="formula" target="#formula_44">6</ref>), the parameter</p><formula xml:id="formula_53">? n satisfies both ? n ? n? ? 2 -m 1-? = 2 -o(m) and ? n = n? + ? ? ? 1/8m 1+? + 1/(m + 1) 1+? = 1/m 1+?(1) .</formula><p>Utility guarantees of M. We now analyze the utility guarantees of M, inherited from A.</p><p>Let D ? X m be an arbitrary set of m points from the specified space</p><formula xml:id="formula_54">X = ?1/ ? d d . Recall that A is assumed (0, ?)-robust. By Definition 2.1, for any D 1 , . . . , D n ? X m , the output ? = A(D 1 , . . . , D n ) verifies ? ? E L( ?; D 1 , . . . , D n ) -inf ??R d L(?; D 1 , . . . , D n ) ,<label>(9)</label></formula><p>In this particular case, since D 1 , . . . , D n = D and ?(?; x) := ?? -x? 2 , we have for all ? ? R d ,</p><formula xml:id="formula_55">L(?; D 1 , . . . , D n ) = 1 nm n i=1 x?Di ?? -x? 2 = 1 m x?D ?? -x? 2 = L(?; D). (<label>10</label></formula><formula xml:id="formula_56">)</formula><p>We can rewrite the above upon applying the bias-variance decomposition: for any x 1 , . . . , x n we have</p><formula xml:id="formula_57">1 n n i=1 ?x i -x? 2 = 1 n n i=1 ?x i ? 2 -?x? 2 where x = 1 n n i=1 x i . Thus, denoting D := 1 m x?D x, we can rewrite (10) as L(?; D 1 , . . . , D n ) = L(?; D) = ? -D 2 + 1 m x?D D -x 2 . (<label>11</label></formula><formula xml:id="formula_58">)</formula><p>This loss is minimized at ? = D, and the minimum value</p><formula xml:id="formula_59">L * := 1 m x?D D -x 2 .</formula><p>Thus, substituting the expression of L from ( <ref type="formula" target="#formula_57">11</ref>) in ( <ref type="formula" target="#formula_54">9</ref>), we obtain that</p><formula xml:id="formula_60">? ? E L( ?; D) -L * = E ? -D 2 .</formula><p>Note that by construction of M, we have M(D) = A(D, . . . , D) = ?. Thus, from above we obtain that</p><formula xml:id="formula_61">? ? E M(D) -D 2 .</formula><p>Thus, as</p><formula xml:id="formula_62">??? 1 ? ? d ???</formula><p>, by taking square roots above, applying Jensen's inequality and multiplying by d, we obtain that</p><formula xml:id="formula_63">d ? ? ? d E M(D) -D 2 ? d E M(D) -D ? ? d E M(D) -D 1 = E ? d ? M(D) - ? d ? D 1 . (12) Recall that X = {?1/ ? d} d . As in Theorem 5.2 of (Steinke &amp; Ullman, 2016), we define a mechanism M ? : {?1} d?m ? [?1] d as follows: on input D ? ? {?1} d?m let D = D ? / ? d ? X m , return ? d ? M(D) truncated to [?1] d . Thus, by (12), mechanism M ? verifies for all D ? ? {?1} d?m that d ? ? ? E M ? (D) -D ? 1 .<label>(13)</label></formula><p>Invoking Lemma A.1. Note that M ? , similar to M, is also (? n , ? n )-DP by the argument of post-processing. Recall that we have shown earlier that ? n , ? n satisfy the conditions of Lemma A.1. Since ? ? 1/100, we also have ? ? ? 1/10. Therefore, upon applying Lemma A.1 to M ? , in conjunction with (13), we deduce that</p><formula xml:id="formula_64">m = ? d log (1/? n ) ? n ? ? .</formula><p>By rearranging terms above and taking squares, we obtain that</p><formula xml:id="formula_65">? = ? d log (1/? n ) ? 2 n m 2 . (<label>14</label></formula><formula xml:id="formula_66">)</formula><p>Recall that we have already shown in ( <ref type="formula" target="#formula_52">8</ref>) and ( <ref type="formula" target="#formula_41">4</ref>), respectively, that ? n ? 4? n ln (1/? ? ) and ? n = n? + ? ? , where ? ? = 1/(m + 1) 1+? (defined in ( <ref type="formula" target="#formula_44">6</ref>)). Therefore, ( <ref type="formula" target="#formula_65">14</ref>) yields</p><formula xml:id="formula_67">? = ? d log (1/(n? + ? ? )) ? 2 nm 2 log (1/? ? ) . (<label>15</label></formula><formula xml:id="formula_68">)</formula><p>As ln(1 + x) ? x, substituting ? ? from (6), and using the assumption that ? ? 1/8nm 1+? , ? ? (0, 1), m ? 1, we obtain that</p><formula xml:id="formula_69">ln (1/(n? + ? ? )) ln (1/? ? ) = ln (1/? ? (1 + n?/? ? )) ln (1/? ? ) = 1 + ln (1/(1 + n?/? ? )) ln (1/? ? ) = 1 - ln (1 + n?/? ? ) ln (1/? ? ) ? 1 - n? ? ? ln (1/? ? ) = 1 - n?(m + 1) ?+1 (1 + ?) ln (m + 1) ? 1 - (m + 1) ?+1 8(1 + ?)m 1+? ln (m + 1) ? 1 - (2m) ?+1 8(1 + ?)m 1+? ln (m + 1) = 1 - 2 ?+1 8(1 + ?) ln (m + 1) ? 1 - 4 8 ln (m + 1) ? 1 - 1 2 ln (2)</formula><p>= ?(1).</p><p>Finally, substituting from above in Equation ( <ref type="formula" target="#formula_67">15</ref>) proves the desired result, i.e.,</p><formula xml:id="formula_70">? = ? d ? 2 nm 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Case II: No Privacy</head><p>We prove below the lower bound due to robustness stated in Proposition 3.2.</p><formula xml:id="formula_71">Proposition 3.2. Let Assumption 2.1 hold. Let n ? 1, 1 ? f &lt; n/2, and ? = 16f (n-2f ) (n-f ) 2 . Consider X = {? G ? ?d } d and ? = ??? 2 . If a distributed algorithm is (f, ?)-robust, then ? = ? f n ? G 2 .</formula><p>Proof. The proof is similar to that of Theorem III <ref type="bibr" target="#b42">(Karimireddy et al., 2022)</ref>.</p><formula xml:id="formula_72">Let n ? 1, 1 ? f &lt; n/2, ? = 16f (n-2f ) (n-f ) 2 , and G &gt; 0. Consider X = {? G ? ?d } d and ? = ??? 2 . Let Assumption 2.1 hold. Assume that algorithm A is (f, ?)-robust. Denote by x = G ? ?d ? 1 ? R d</formula><p>, where 1 ? R d is the vector of ones. Consider the following datasets D 1 = . . . = D n-f = {x} m (i.e. all rows are x) and D n-f +1 = . . . = D n = {-x} m (i.e. all rows are -x). Consider the two situations of honest identities</p><formula xml:id="formula_73">H 1 = {1, . . . , n -f } and H 2 = {f + 1, . . . , n}.</formula><p>We first show that the loss functions L(? ; D 1 ), . . . , L(? ; D n ) (defined using ? in Section 2) satisfy Assumption 2.1 in both situations. This is straightforward in situation H 1 since honest losses are identical. In situation H 2 , we have for all ? ? R d ,</p><formula xml:id="formula_74">?L H2 (?) = 1 n -f i?H2 ?L(?; D i ) = n -2f n -f 2(? -x) + f n -f 2(? + x) = 2 ? - n -3f n -f x .</formula><p>Observe that, as n &gt; 2f , the intersection H 1 ? H 2 = {f + 1, . . . , n -f } is non-empty. Therefore, thanks to the choice of x, we now show that Assumption 2.1 holds, as for all ? ? R d we have</p><formula xml:id="formula_75">1 |H 2 | i?H2 ??L(?; D i ) -?L H2 (?)? 2 = |H 1 ? H 2 | n -f ??L(?; D f +1 ) -?L H2 (?)? 2 + |H 2 \ H 1 | n -f ??L(?; D n ) -?L H2 (?)? 2 = n -2f n -f 2(? -x) -2(? - n -3f n -f x) 2 + f n -f 2(? + x) -2(? - n -3f n -f x) 2 = 4(n -2f ) n -f -2f n -f x 2 + 4f n -f 2(n -2f ) n -f x 2 = 16f (n -2f ) (n -f ) 2 ?x? 2 = ? ?x? 2 = G 2 . Now, denote L * ,H1 := inf R d L H1 and L * ,H2 := inf R d L H2 . Since learning algorithm A is (f, ?)-robust, it outputs ? such that E L H1 ( ?) -L * ,H1 ? ? and E L H2 ( ?) -L * ,H2 ? ?.</formula><p>Note that situations H 1 and H 2 are indistinguishable to algorithm A because it ignores the honest identities, and thus ? is the same in both situations.</p><p>Recall that the expression of loss L H1 is</p><formula xml:id="formula_76">L H1 = 1 |H 1 | i?H1 L(?; D i ) = 1 |H 1 | i?H1 ?? -x? 2 = ?? -x? 2 .</formula><p>Therefore, the loss is minimized at ? = x and we have L * ,H1 = L H1 (x) = 0. Thus, we have</p><formula xml:id="formula_77">E L H1 ( ?) -L * ,H1 = E ? -x 2 .</formula><p>On the other hand, after some algebraic manipulations, the expression of loss L H2 is</p><formula xml:id="formula_78">L H2 (?) = 1 |H 2 | i?H2 L(?; D i ) = |H 1 ? H 2 | n -f ? ?? -x? 2 + |H 2 \ H 1 | n -f ? ?? + x? 2 = n -2f n -f ? (??? 2 + ?x? 2 -2 ??, x?) + f n -f ? (??? 2 + ?x? 2 + 2 ??, x?) = ? - n -3f n -f x 2 + ? ?x? 2 .</formula><p>Therefore, the loss is minimized at ? = n-3f n-f x and we have L * ,H2 = ? ?x? 2 . Thus, we obtain</p><formula xml:id="formula_79">E L H2 ( ?) -L * ,H2 = E ? - n -3f n -f x 2 .</formula><p>Recall that ? = 16f (n-2f ) (n-f ) 2 . Therefore, invoking Jensen's inequality, we have</p><formula xml:id="formula_80">? ? max E L H1 ( ?) -L * ,H1 , E L H2 ( ?) -L * ,H2 ? 1 2 E L H1 ( ?) -L * ,H1 + E L H2 ( ?) -L * ,H2 = 1 2 ? -x 2 + ? - n -3f n -f x 2 ? 1 4 2f n -f x 2 = f n -f 2 G 2 ? = 1 16 ? f n -2f G 2 . (<label>16</label></formula><formula xml:id="formula_81">)</formula><p>Since n -2f ? n, we obtain ? ? 1 16 ? f n G 2 , which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Case III: Adversarial Setting</head><p>We show below the lower bound from Proposition 3.3 due to the privacy-robustness tradeoff. <ref type="formula" target="#formula_0">1</ref>) and (f, ?)-robustness.</p><formula xml:id="formula_82">Proposition 3.3. Let n ? 3, 1 ? f &lt; n/2, m ? 1, ?, ? ? (0, 1), and ? = 16f (n-2f ) (n-f ) 2 . Consider X = {? 1 ? d } d ? {? 1 ? ?d } d and ? = ??? 2 . Consider any (?, ?)-DP distributed algorithm A : X m?n ? R d . Assume that 2 -o(m) ? ? ? 1/m 1+?(1) . For any ? ? f +1 100(n-f ) , if A is (f, ?)-robust, then we must have ? = ? f + 1 n -f ? log (1/?) ? 2 m 2 . Proof. Let n ? 3, 1 ? f &lt; n/2, m ? 1, d ? 1, ?, ? ? (0, 1), ? = 16f (n-2f ) (n-f ) 2 , and ? ? f +1 100(n-f ) . Consider X = {?1/ ? d} d ? {?1/ ? ?d} d and ? = ??? 2 . We consider a distributed algorithm A : X m?n ? R d that satisfies (?, ?)-distributed DP where 2 -o(m) ? ? ? 1/m 1+?(</formula><p>We consider the following datasets. Let 1 denote the vector of ones in R d . For i ? {2, . . . , n -f }, we set</p><formula xml:id="formula_83">D i = D + := {+ 1 ? d ? 1} m , i.e., all rows are + 1 ? d ? 1 ? R d . For i ? {n -f + 1, . . . , n} we set D i = D -:= {- 1 ? d ? 1} m , i.e., all rows are -1 ? d ? 1 ? R d .</formula><p>Finally, we fix D 1 ? X m to be an arbitrary dataset with every element having identical coordinates. That is, for arbitrary ? 1,1 , . . . , ? 1,m ? {?1}, we set</p><formula xml:id="formula_84">D 1 = ? 1,1 ? d ? 1, . . . , ? 1,m ? d ? 1 .</formula><p>Proof outline. We consider the centralized algorithm M : X m ? R d which takes as input dataset D 1 ? X m and executes A(D 1 , D 2 , . . . , D n ), where the datasets D 2 , . . . , D n are fixed above. We first derive the DP and utility guarantees M inherits from A, which satisfies (?, ?)-distributed DP (see Definition 2.3) and (f, ?)-robustness, and then conclude the proof by applying the centralized lower bound Lemma A.1 to M.</p><p>Privacy guarantees of M. We first state the privacy guarantees of M inherited from A.</p><p>As per Definition 2.3, since A is (?, ?)-DP, all communications with worker w 1 (whose dataset is D 1 ) are (?, ?)-DP. It follows directly that M is (?, ?)-DP by post-processing.</p><p>Utility guarantees of M. We now analyze the utility guarantees of M inherited from A.</p><formula xml:id="formula_85">Since A is (f, ?)-robust (Definition 2.1), the output ? = M(D 1 ) = A(D 1 , . . . , D n ) verifies ? ? E L H ( ?) -L * ,<label>(17)</label></formula><p>for any set of honest identities H ? {1, . . . , n}, |H| = n -f , where we denote</p><formula xml:id="formula_86">L * := inf R L H .</formula><p>Reduction to one-dimensional space: We now show that we can simply consider d = 1, without loss of generality.</p><p>For this, we develop the RHS of ( <ref type="formula" target="#formula_85">17</ref>). We have for any ? ? R d and H ? {1, . . . , n}, |H| = n -f :</p><formula xml:id="formula_87">L H (?) = 1 |H| i?H 1 m x?Di ?? -x? 2 . (<label>18</label></formula><formula xml:id="formula_88">)</formula><p>The above function is minimized at ? * H := 1 |H| i?H D i the average of one-way marginals</p><formula xml:id="formula_89">D i := 1 m x?Di x. Therefore, the minimum of L H is L * ,H := L H (? * H ).</formula><p>Recall the following bias-variance decomposition: for any x 1 , . . . , x n ? R d we have</p><formula xml:id="formula_90">1 n n i=1 ?x i -x? 2 = 1 n n i=1 ?x i ? 2 -?x? 2</formula><p>, where we denoted x := 1 n n i=1 x i . Therefore, recalling (18) and</p><formula xml:id="formula_91">? * H = 1 |H| i?H D i , we have L H (?) -L * ,H = L H (?) -L H ( 1 |H| i?H D i ) = ? - 1 |H| i?H D i 2 . (<label>19</label></formula><formula xml:id="formula_92">)</formula><p>Recall our setting of datasets in the beginning of the proof: in particular, for every i ? {1, . . . , n}, each element of dataset D i has identical coordinates. Thus, there is</p><formula xml:id="formula_93">? i ? [?1] such that D i = ?i ? d ? 1. Plugging this in (19) yields: L H (?) -L * ,H = ? - 1 |H| i?H D i 2 = ? - 1 ? d ? |H| i?H ? i 1 2 = d k=1 ? k - 1 ? d ? |H| i?H ? i 2 = 1 d d k=1 ? d ? ? k - 1 |H| i?H ? i 2 , (<label>20</label></formula><formula xml:id="formula_94">)</formula><p>where ? k denotes the k-th coordinate of ? ? R d . Upon applying (17) and then Jensen's inequality, we obtain</p><formula xml:id="formula_95">? ? E L H ( ?) -L * ,H = 1 d d k=1 E ? ? ? d ? ?k - 1 |H| i?H ? i 2 ? ? ? E ? ? 1 d d k=1 ? d ? ?k - 1 |H| i?H ? i 2 ? ? = E ? ? d k=1 ?k ? d - 1 |H| i?H ? i 2 ? ? .<label>(21)</label></formula><p>Therefore, everything happens as if d = 1. That is, data universe X = {?1}, and datasets</p><formula xml:id="formula_96">D + = {+1} m , D -= {-1} m , and D 1 = {? 1,1 , . . . , ? 1,m } being arbitrary in X m . Indeed, denote ? := d k=1 ?k ? d ? R. Recall that, now that d = 1, each ? i ? [?1] is such that D i = ? i .</formula><p>In this one-dimensional setting of datasets, we develop the RHS of (21), by using the aforementioned bias-variance decomposition backwards:</p><formula xml:id="formula_97">? ? E ? ? ? - 1 |H| i?H ? i 2 ? ? = E 1 |H| i?H 1 m x?Di ? -x 2 -E ? ? 1 |H| i?H 1 m x?Di x - 1 |H| i?H D i 2 ? ? = E L H ( ?) -L * ,H .</formula><p>Thus, (17) holds with loss ? being the one-dimensional quadratic loss and mechanism M returning ? instead of ?.</p><p>Since ? is a function of ? without access to D 1 , M is also (?, ?)-DP by post-processing. Throughout the remainder of the proof, we set d = 1 without loss of generality.</p><p>We consider below the RHS of ( <ref type="formula" target="#formula_85">17</ref>). We have for any ? ? R:</p><formula xml:id="formula_98">L H (?) = 1 |H| i?H 1 m x?Di |? -x| 2 . (<label>22</label></formula><formula xml:id="formula_99">)</formula><p>The above function is minimized at ? * H := 1 |H| i?H D i the average of one-way marginals</p><formula xml:id="formula_100">D i := 1 m x?Di x.</formula><p>Next, following (30), we consider two possible cases of honest identities, a priori indistinguishable to the algorithm. In the first case, we consider the set of honest identities H to be H 1 = {1, . . . , n -f }. In the second case, we consider the set of honest identities H to be H 2 := {1} ? {f + 2, . . . , n}. As |H| = n -f , upon invoking Definition 2.1 in both the cases, we obtain a upper bound on</p><formula xml:id="formula_101">E | ? -D 1 | 2 in terms of ?.</formula><p>First case: Consider H to be H 1 = {1, . . . , n -f }. Recall that D i = D + for all i ? {2, . . . , n -f }. By (22), we have for all ? ? R:</p><formula xml:id="formula_102">L H1 (?) = 1 |H 1 | i?H1 1 m x?Di |? -x| 2 = 1 |H 1 | 1 m x?D1 |? -x| 2 + |H 1 | -1 |H 1 | 1 m x?D+ |? -x| 2 = 1 n -f 1 m x?D1 |? -x| 2 + (1 - 1 n -f ) ? -D + 2 ? 1 n -f ? -D 1 2 + (1 - 1 n -f ) ? -D + 2 . (Jensen's inequality)</formula><p>Thus, from above we obtain that</p><formula xml:id="formula_103">E L H1 ( ?) ? 1 n -f E | ? -D 1 | 2 + (1 - 1 n -f ) E | ? -D + | 2 . (<label>23</label></formula><formula xml:id="formula_104">)</formula><p>Now, recall the following bias-variance decomposition: for any x 1 , . . . , x n ? R we have</p><formula xml:id="formula_105">1 n n i=1 |x i -x| 2 = 1 n n i=1 |x i | 2 -|x| 2 where x := 1 n n i=1 x i . Thus, from (22) we obtain that ? * H1 = 1 |H1| i?H1 D i . Thus, as |x| 2 = 1 for all x ? X , we have L * ,H1 = L H1 (? * H1 ) = 1 m |H 1 | i?H1 x?Di ? * H1 -x 2 = 1 m |H 1 | i?H1 x?Di |x| 2 -? * H1 2 = 1 -? * H1 2 = 1 - 1 |H 1 | i?H1 D i 2 = 1 - 1 n -f D 1 + (1 - 1 n -f )D + 2 = 1 - 1 n -f D 1 + 1 - 1 n -f 2 = 1 - 1 (n -f ) 2 D 1 + n -f -1 2 . Note that, as D 1 ? X m = {?1} m , we have D 1 ? [?1]. Also, since f &lt; n/2 and n ? 3, we have n -f -2 ? 0. Therefore, D 1 + n -f -1 2 ? |n -f -2| 2 .</formula><p>Substituting this in the above, we obtain that</p><formula xml:id="formula_106">L * ,H1 = 1 - 1 (n -f ) 2 D 1 + n -f -1 2 ? 1 - 1 (n -f ) 2 |n -f -2| 2 = 1 -1 - 2 n -f 2 = 2 n -f (2 - 2 n -f ) = 4 n -f (1 - 1 n -f ) ? 4 n -f ? 4(f + 1) n -f . (<label>24</label></formula><formula xml:id="formula_107">)</formula><p>Substituting from ( <ref type="formula" target="#formula_103">23</ref>) and ( <ref type="formula" target="#formula_106">24</ref>) in ( <ref type="formula" target="#formula_85">17</ref>) we obtain that</p><formula xml:id="formula_108">? + 4(f + 1) n -f ? ? + L * ,H1 ? E L H1 ( ?) ? 1 n -f E | ? -D 1 | 2 + (1 - 1 n -f ) E | ? -D + | 2 . (<label>25</label></formula><formula xml:id="formula_109">)</formula><p>Second case: Consider H to be H 2 = {1} ? {f + 2, . . . , n}. Recall that D i = D -for all i ? {n -f + 1, . . . , n}. By ( <ref type="formula" target="#formula_98">22</ref>), we have for all ? ? R:</p><formula xml:id="formula_110">L H2 (?) = 1 |H 2 | i?H2 1 m x?Di |? -x| 2 = 1 |H 2 | 1 m x?D1 |? -x| 2 + |H 2 | -1 -f |H 2 | 1 m x?D+ |? -x| 2 + f |H 2 | 1 m x?D- |? -x| 2 = 1 n -f 1 m x?D1 |? -x| 2 + n -2f -1 n -f ? -D + 2 + f n -f ? -D - 2 ? 1 n -f 1 m x?D1 |? -x| 2 + f n -f ? -D - 2 (n ? 2f + 1) ? 1 n -f ? -D 1 2 + f n -f ? -D - 2 . (Jensen's inequality)</formula><p>Substituting ? = ?, and taking expectation yields</p><formula xml:id="formula_111">E L H2 ( ?) ? 1 n -f E | ? -D 1 | 2 + f n -f E | ? -D -| 2 . (<label>26</label></formula><formula xml:id="formula_112">)</formula><p>Now, recall the following bias-variance decomposition: for any x 1 , . . . , x n ? R we have</p><formula xml:id="formula_113">1 n n i=1 |x i -x| 2 = 1 n n i=1 |x i | 2 -|x| 2</formula><p>, where we denoted x := 1 n n i=1 x i . Using this in ( <ref type="formula" target="#formula_98">22</ref>), and that ?x ? X , |x| 2 = 1, we get</p><formula xml:id="formula_114">L * ,H2 = L H2 (? * H2 ) = 1 m |H 2 | i?H2 x?Di ? * H2 -x 2 = 1 m |H 2 | i?H2 x?Di |x| 2 -? * H2 2 = 1 -? * H2 2 = 1 - 1 |H 2 | i?H2 D i 2 = 1 - 1 n -f D 1 + n -2f -1 n -f D + + f n -f D - 2 = 1 - 1 n -f D 1 + n -2f -1 n -f - f n -f 2 = 1 -1 + 1 n -f D 1 - 2f + 1 n -f 2 = 1 -1 - 1 n -f D 1 + 2f + 1 n -f 1 + 1 + 1 n -f D 1 - 2f + 1 n -f = 2f + 1 -D 1 n -f 2 - 2f + 1 -D 1 n -f . Note that, as D 1 ? X m = {?1} m , we have D 1 ? [?1]</formula><p>. This, together with n ? 2f + 1, implies that both the terms in the product above are non-negative. Moreover, as D 1 ? -1, the first term can be bounded by</p><formula xml:id="formula_115">2f + 1 -D 1 n -f ? 2(f + 1) n -f .</formula><p>Similarly, as D 1 ? 1, the second term can be bounded by</p><formula xml:id="formula_116">2 - 2f + 1 -D 1 n -f ? 2 - 2f n -f ? 2.</formula><p>Consequently, we have</p><formula xml:id="formula_117">L * ,H2 ? 4(f + 1) n -f . (<label>27</label></formula><formula xml:id="formula_118">)</formula><p>Invoking ( <ref type="formula" target="#formula_85">17</ref>) with the set of honest identities H 2 , and using the bounds shown in ( <ref type="formula" target="#formula_111">26</ref>), ( <ref type="formula" target="#formula_117">27</ref>) yields:</p><formula xml:id="formula_119">? + 4(f + 1) n -f ? ? + L * ,H2 ? E L H2 ( ?) ? 1 n -f E | ? -D 1 | 2 + f n -f E | ? -D -| 2 . (<label>28</label></formula><formula xml:id="formula_120">)</formula><p>Final step: We deduce from ( <ref type="formula" target="#formula_108">25</ref>), ( <ref type="formula" target="#formula_119">28</ref>) that</p><formula xml:id="formula_121">? + 4(f + 1) n -f ? max 1 n -f E | ? -D 1 | 2 + (1 - 1 n -f ) E | ? -D + | 2 , 1 n -f E | ? -D 1 | 2 + f n -f E | ? -D -| 2 = 1 n -f E | ? -D 1 | 2 + max (1 - 1 n -f ) E | ? -D + | 2 , f n -f E | ? -D -| 2 ? 1 n -f E | ? -D 1 | 2 + f n -f max E | ? -D + | 2 , E | ? -D -| 2 , (<label>29</label></formula><formula xml:id="formula_122">)</formula><p>where the last inequality is due to f &lt; n 2 , which implies that 1-</p><formula xml:id="formula_123">1 n-f ? f n-f . Besides, observe that, as D 1 ? X m = {?1} m , we have D 1 ? [?1]. Recall that D + = +1 and D -= -1. Thus, it holds that E | ? -D 1 | 2 ? max (E | ? -D + | 2 , E | ? -D -| 2 ).<label>(30)</label></formula><p>Indeed, since</p><formula xml:id="formula_124">D 1 ? [?1], we can write D 1 = ? ? (+1) + (1 -?) ? (-1) for some ? ? [0, 1]. Thus, using</formula><p>Jensen's inequality and then taking expectations, we have</p><formula xml:id="formula_125">E | ? -D 1 | 2 ? ? E | ? -1| 2 + (1 -?) E | ? + 1| 2 ? max (E | ? -1| 2 , E | ? + 1| 2 ).</formula><p>Using (30) in (29), we obtain, for every D 1 ? X m , that</p><formula xml:id="formula_126">? + 4(f + 1) n -f ? f + 1 n -f E | ? -D 1 | 2 . (<label>31</label></formula><formula xml:id="formula_127">)</formula><p>Before concluding, recall that 1 ? f ? n 2 , thus applying Proposition 3.2 with G = 1 yields</p><formula xml:id="formula_128">? = ? f n = ? f + 1 n -f . (<label>32</label></formula><formula xml:id="formula_129">)</formula><p>Indeed, since the data universe considered in the proof includes {? 1 ? ?d } d , we can apply Proposition 3.2. Plugging this back in (31), we have for every</p><formula xml:id="formula_130">D 1 ? X m that ? = ? f + 1 n -f E | ? -D 1 | 2 .</formula><p>Invoking Lemma A.1. Hence, since ? ? f +1 100(n-f ) , we can proceed in the same way as in the proof of Proposition 3.1 to leverage Lemma A.1 (with d = 1) for showing</p><formula xml:id="formula_131">n -f f + 1 ? = ? log (1/?) ? 2 m 2 .</formula><p>We finally conclude the desired result by rearranging terms and ignoring absolute constants:</p><formula xml:id="formula_132">? = ? f + 1 n -f ? log (1/?) ? 2 m 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5. Final Lower Bound</head><p>We prove below the final lower bound stated in Theorem 3.1.</p><formula xml:id="formula_133">Theorem 3.1. Let X = R d , ? = ??? 2 , n ? 3, 0 ? f &lt; n/2, m ? 1,</formula><p>and ?, ? ? (0, 1). Consider arbitrary datasets D 1 , . . . , D n ? X m such that Assumption 2.1 is satisfied with G ? 1. Let A : X m?n ? R d be an (?, ?)-DP distributed algorithm. Assume that ? ? 1/4 2n ln (m + 1), and that 2 -m 1-? ? n? ? 1/8m 1+? for some ? ? (0, 1). For any</p><formula xml:id="formula_134">? ? f +1 100(n-f ) , if A is (f, ?)-robust, then ? = ? d ? 2 nm 2 + f n ? 1 ? 2 m 2 + f n ? G 2 .</formula><p>Proof. The proof consists in showing that the setting we consider in the above theorem allows us to merge the lower bounds from propositions 3.1, 3.3, and 3.2. First, we remark that the case f = 0 corresponds to simply showing that ? = ? d ? 2 nm 2 , which follows immediately from Proposition 3.1 directly (see Step 1 below for verifying the applicability of the proposition). In the remainder of the proof, we will assume f &gt; 0 and ? &gt; 0. Let H denote the set of honest nodes of size n -f .</p><p>Step 1: To derive the first term in ? d ? 2 nm 2 , we remark that all the conditions of Proposition 3.1 on ?, ?, ?, n, m hold under the assumptions stated in the theorem. Consider D 1 , . . . , D n ? {?1/ ? 8d} d?m ? X m . Note that in this case, we have</p><formula xml:id="formula_135">1 |H| i?H ??L(?; D i ) -?L H (?)? 2 ? 1 ? G 2 .</formula><p>Hence, D 1 , . . . , D n is a valid collection of datasets with regard to the theorem statement. Since A is assumed to be (f, ?)-robust, it guarantees an error less than or equal to ? on the honest global loss L(?; D i , i ? H). Using the proof technique of Proposition 3.1, we can show that (as</p><formula xml:id="formula_136">f &lt; n/2 and |H| = n -f ? n) ? = ? d ? 2 |H| m 2 = ? d ? 2 nm 2 . (<label>33</label></formula><formula xml:id="formula_137">)</formula><p>Step 2: To derive the second term in ?( f n ? 1 ? 2 m 2 ), we remark that all conditions of Proposition 3.3 on ?, ?, ?, n, f, m, and A are verified. Note also that, similar to Step 1, the datasets considered in the proof Proposition 3.2, scaled by a constant, are also valid instances with regard to the theorem statement. Using the proof technique of Proposition 3.2 we can show that (since 0 &lt; f &lt; n/2, we have</p><formula xml:id="formula_138">f + 1 ? f and n -f ? n) ? = ? f + 1 n -f ? log (1/?) ? 2 m 2 = ? f n ? 1 ? 2 m 2 , (<label>34</label></formula><formula xml:id="formula_139">)</formula><p>where we ignore the logarithmic term in ?(?).</p><p>Step 3: To obtain the third term in ? f n ? G 2 , we first remark that Assumption 2.1 holds, as well as all the conditions in Proposition 3.2 on n, f, m and A. As the input domain in Proposition 3.2 is a subset of X , using the proof technique of Proposition 3.2 we can show that</p><formula xml:id="formula_140">? = ? f n ? G 2 . (<label>35</label></formula><formula xml:id="formula_141">)</formula><p>Final step: Combining (33), (34), and (35) proves the theorem, i.e., we obtain that</p><formula xml:id="formula_142">? = ? max d ? 2 nm 2 , f n ? 1 ? 2 m 2 , f n ? G 2 = ? d ? 2 nm 2 + f n ? 1 ? 2 m 2 + f n ? G 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Robustness Analysis</head><p>In this section, we prove all our claims related to (f, ?)-robustness and SMEA. In Section B.1, we analyze SMEA. In Section B.2, we discuss Filter <ref type="bibr" target="#b20">(Diakonikolas et al., 2017;</ref><ref type="bibr" target="#b67">Steinhardt et al., 2018)</ref>, a related algorithm.</p><p>We first recall the definition of our robustness criterion:</p><p>Definition 4.1. Let n ? 1, 0 ? f &lt; n/2 and ? ? 0. An aggregation rule F is said to be (f, ?)-robust averaging if for any vectors x 1 , . . . , x n ? R d , and any set S ? {1, . . . , n} of size n -f , the output</p><formula xml:id="formula_143">x = F (x 1 , . . . , x n ) satisfies ?x -x S ? 2 ? ? ? ? max 1 |S| i?S (x i -x S )(x i -x S ) ? ,</formula><p>where x S := 1 |S| i?S x i and ? max denotes the maximum eigenvalue. We refer to ? as the robustness coefficient of F .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Smallest Maximum Eigenvalue Averaging (SMEA)</head><p>Given a set of n vectors x 1 , . . . , x n ? R d , the SMEA algorithm first searches for a set S * of cardinality n -f with the smallest empirical maximum eigenvalue, i.e.,</p><formula xml:id="formula_144">S * ? argmin S?{1,..., n |S|=n-f } ? max 1 |S| i?S (x i -x S )(x i -x S ) ? . (<label>36</label></formula><formula xml:id="formula_145">)</formula><p>Then the algorithm outputs the average of the inputs in set S * :</p><formula xml:id="formula_146">SMEA(x 1 , . . . , x n ) := 1 |S * | i?S * x i . (<label>37</label></formula><formula xml:id="formula_147">) Proposition 5.1. Let f &lt; n/2. SMEA is (f, ?)-robust averaging with ? = 4f n -f 1 + f n -2f 2 .</formula><p>Proof. Let n ? 1 and 0 ? f &lt; n/2. Fix a set S ? {1, . . . , n} such that |S| = n -f . Recall the definition of S * in (36). Denote by x S * the output of SMEA defined in (37):</p><formula xml:id="formula_148">x S * := 1 |S * | i?S * x i .<label>(38)</label></formula><p>From (38), we have</p><formula xml:id="formula_149">?x S * -x S ? 2 = 1 n -f i?S * x i - 1 n -f i?S x i 2 = 1 n -f i?S * \S x i - 1 n -f i?S\S * x i 2 = 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) + |S * \ S| n -f (x S * -x S ) 2 = 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) 2 + |S * \ S| 2 (n -f ) 2 ?x S * -x S ? 2 + 2 |S * \ S| n -f x S * -x S , 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) . However, notice that 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) = 1 n -f i?S * \S x i - 1 n -f i?S\S * x i - |S * \ S| n -f (x S * -x S ) = 1 n -f i?S * x i - 1 n -f i?S x i - |S * \ S| n -f (x S * -x S ) = 1 - |S * \ S| n -f (x S * -x S ).</formula><p>This implies that</p><formula xml:id="formula_150">?x S * -x S ? 2 = 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) 2 + |S * \ S| 2 (n -f ) 2 + 2 |S * \ S| n -f 1 - |S * \ S| n -f ?x S * -x S ? 2 = 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) 2 + 1 -1 - |S * \ S| n -f 2 ?x S * -x S ? 2</formula><p>By rearranging the terms, applying Jensen's inequality, and using the fact that sup ?v??1 |?v, x?| = ?x?, we obtain</p><formula xml:id="formula_151">1 - |S * \ S| n -f 2 ?x S * -x S ? 2 = 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) 2 = sup ?v??1 v, 1 n -f i?S * \S (x i -x S * ) - 1 n -f i?S\S * (x i -x S ) 2 = sup ?v??1 1 n -f i?S * \S ?v, x i -x S * ? - 1 n -f i?S\S * ?v, x i -x S ? 2 ? |S * \ S| + |S \ S * | (n -f ) 2 sup ?v??1 ? ? i?S * \S |?v, x i -x S * ?| 2 + i?S\S * |?v, x i -x S ?| 2 ? ? ? |S * \ S| + |S \ S * | (n -f ) 2 ? ? sup ?v??1 i?S * \S |?v, x i -x S * ?| 2 + sup ?v??1 i?S\S * |?v, x i -x S ?| 2 ? ? ? 2f (n -f ) 2 ? ? sup ?v??1 i?S * \S |?v, x i -x S * ?| 2 + sup ?v??1 i?S\S * |?v, x i -x S ?| 2 ? ? ,<label>(39)</label></formula><p>where the last inequality is due to the fact that</p><formula xml:id="formula_152">|S * | = |S| = n -f , as we must have |S \ S * | = |S * \ S| = |S ? S * | -|S| ? n -(n -f ) = f. (<label>40</label></formula><formula xml:id="formula_153">)</formula><p>The first term on the RHS of (39) can be bounded by construction of S * , and using the fact that sup ?v??1 ?v, M v? = ? max (M ):</p><formula xml:id="formula_154">sup ?v??1 i?S * \S |?v, x i -x S * ?| 2 ? sup ?v??1 i?S * |?v, x i -x S * ?| 2 = sup ?v??1 v, i?S * (x i -x S * )(x i -x S * ) ? v = ? max i?S * (x i -x S * )(x i -x S * ) ? ? ? max i?S (x i -x S )(x i -x S ) ? .</formula><p>The second term on the RHS of (39) can be bounded similarly:</p><formula xml:id="formula_155">sup ?v??1 i?S\S * |?v, x i -x S ?| 2 ? sup ?v??1 i?S |?v, x i -x S ?| 2 = ? max i?S (x i -x S )(x i -x S ) ? .</formula><p>Plugging these two bounds back in (39), we obtain</p><formula xml:id="formula_156">1 - |S * \ S| n -f 2 ?x S * -x S ? 2 ? 4f n -f 1 n -f ? max i?S (x i -x S )(x i -x S ) ? .</formula><p>Finally, since |S * \ S| ? f (see ( <ref type="formula" target="#formula_152">40</ref>)), we have 1</p><formula xml:id="formula_157">-|S * \S| n-f 2 ? 1 -f n-f 2 = n-2f n-f<label>2</label></formula><p>. We can therefore obtain</p><formula xml:id="formula_158">?x S * -x S ? 2 ? 4f (n -f ) (n -2f ) 2 ? ? max 1 |S| i?S (x i -x S )(x i -x S ) ? .</formula><p>The proof concludes by noticing that 4f</p><formula xml:id="formula_159">(n-f ) (n-2f ) 2 = 4f n-f 1 + f n-2f 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Filter Algorithm</head><p>In this section, we present the Filter algorithm <ref type="bibr" target="#b20">(Diakonikolas et al., 2017;</ref><ref type="bibr" target="#b66">Steinhardt, 2018)</ref> in Algorithm 2 and discuss its robustness properties, stated in Proposition B.1, in the distributed ML context we consider. Recall that Filter was also used in <ref type="bibr" target="#b18">(Data &amp; Diggavi, 2021)</ref>.</p><p>Algorithm 2 Filter algorithm <ref type="bibr" target="#b20">(Diakonikolas et al., 2017;</ref><ref type="bibr" target="#b66">Steinhardt, 2018</ref>) Compute weight</p><formula xml:id="formula_160">Input: vectors x 1 , . . . , x n ? R d , spectral norm bound ? 2 0 , constant factor ? &gt; 0. 1: Initialize c 1 , . . . , c n = 1, ?c = +?.</formula><formula xml:id="formula_161">? i = ?v c , x i -?c ? 2 . 10: Update c i ? c i (1 -? i /? max )</formula><p>, where ? max = max 1?i?n ? i .</p><p>11:</p><p>end if 12: end while In Proposition B.1, we recall the robustness guarantees of the Filter procedure (Algorithm 2). The proposition is followed by a discussion further below.</p><formula xml:id="formula_162">Proposition B.1. Let n ? 1, 0 ? f &lt; n/2, x 1 , . . . , x n ? R n , and S ? [n], |S| = n -f . Denote x S := 1 |S| i?S x i . Set the parameters ? 2 0 ? ? max 1 |S| i?S (x i -x S )(x i -x S ) ? and ? = 2n(n -f )/(n -2f ) 2 .</formula><p>Then, the output x of the Filter procedure (Algorithm 2) with parameters ? 2 0 and ? satisfies</p><formula xml:id="formula_163">? x -x S ? 2 ? ? ? ? 2 0 , with ? = 4f n (n-2f ) 2 + 2f n-f = 6f n-2f 1 + f n-2f .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Privacy Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Preliminaries</head><p>We first recall definitions and useful lemmas on Differential Privacy (DP) and R?nyi Differential Privacy (RDP), including the privacy amplification by subsampling (without replacement) results for RDP. Definition C.1 (R?nyi Differential Privacy, <ref type="bibr" target="#b54">(Mironov, 2017)</ref>). Let ? &gt; 1 and ? &gt; 0. A randomized algorithm M is (?, ?)-RDP if for any adjacent datasets D, D ? ? X m it holds that</p><formula xml:id="formula_164">D ? (M(D)||M(D ? )) ? ?, where D ? (M(D)||M(D ? )) := 1 ?-1 log E ??M(D ? ) M(D)(?) M(D ? )(?) ?</formula><p>is the R?nyi divergence of order ?.</p><p>Lemma C.1 (RDP Adpative Composition, <ref type="bibr" target="#b54">(Mironov, 2017)</ref>). If M 1 that takes the dataset as input is (?, ? 1 )-RDP, and M 2 that takes the dataset and the output of M 1 as input is (?, ? 2 )-RDP, then their composition is (?, ? 1 + ? 2 )-RDP.</p><p>Lemma C.2 (RDP to DP conversion, <ref type="bibr" target="#b54">(Mironov, 2017)</ref>). <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref>). The ? 2 -sensitivity of a function g :</p><formula xml:id="formula_165">If M is (?, ?)-RDP, then M is (? + log (1/?) ?-1 , ?)-DP for all ? ? (0, 1). Definition C.2 (? 2 -sensitivity,</formula><formula xml:id="formula_166">X m ? R d is ?(g) := sup D,D ? adjacent ?g(D) -g(D ? )? .</formula><p>Lemma C.3 (RDP for Gaussian Mechanisms, <ref type="bibr" target="#b54">(Mironov, 2017)</ref>).</p><formula xml:id="formula_167">If g : X m ? R d has ? 2 -sensitivity smaller than ?, then the Gaussian mechanism G ?,g = g + N (0, ? 2 I d ) is (?, ? 2 2? 2 ?)-RDP. Definition C.3 (Subsampling Mechanism). Consider a dataset D ? X m , a constant b ? [m]</formula><p>, and define r := b /m. The procedure subsample r : X m ? X b selects b points at random and without replacement from D. Lemma C.4 (RDP for Subsampled Mechanisms, <ref type="bibr">(Wang et al., 2019a)</ref>). Let ? ? N, ? ? 2, and r ? (0, 1) the sampling parameter</p><formula xml:id="formula_168">. If M is (?, ?(?))-RDP, then M ? subsample r is (?, ? ? (?))-RDP, with ? ? (?) = 1 ? -1 log 1 + r 2 ? 2 min 4(e ?(2) -1), e ?(2) min {2, (e ?(?) -1) 2 } + ? j=3</formula><p>r j ? j e (j-1)?(j) min {2, (e ?(?) -1) j } .</p><p>(41)</p><p>Lemma C.5 (Real-valued RDP for Subsampled Mechanisms). Let ? ? R, ? &gt; 1, and r ? (0, 1) the sampling parameter. If</p><formula xml:id="formula_169">M is (?, ?(?))-RDP, then M ? subsample r is (?, ? ?? (?))-RDP, with ? ?? (?) = (1 -? + ???) ??? -1 ? -1 ? ? (???) + (? -???) ??? -1 ? -1 ? ? (???),</formula><p>where ? ? is defined in Equation (41).</p><p>Proof. The result follows immediately from Corollary 10 and Remark 7 in <ref type="bibr">(Wang et al., 2019a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Proof of Theorem 4.1 and Theorem C.1</head><p>We state below the DP guarantees without approximation:</p><formula xml:id="formula_170">Theorem C.1. Let ? ? (0, 1). Algorithm 1 is (? * , ?)-DP with ? * = inf ?&gt;1 T ? 1 (?) + log (1/?) ? -1 ,</formula><p>where for every ? &gt; 1, Proof. To derive the above DP guarantees, we first track the privacy loss for a single iteration of Algorithm 1 using RDP.</p><formula xml:id="formula_171">? ? ? ? ? ? ? ? 1 (?) := (1 -? + ???) ???-1 ?-1 ? ? (???) + (? -???) ???-1 ?-1 ? ? (???), ? ? (?) := 1 ?-1 log 1 + r 2 ? 2 min 4(e ?(2) -1), 2e ?(2) + 2 ? j=3 r j ? j e (j-1)?(j) , ?(?) := 2C b 2 ? 2? 2 DP . ? t g(i) t ? t+1<label>(</label></formula><p>Then we apply adaptive composition to track the end-to-end privacy loss of the algorithm. Finally, we optimize over the privacy loss for several levels of RDP to compute the noise parameter needed for DP.</p><p>Single-iteration privacy. First, we analyze a single fixed iteration t ? {0, . . . , T -1} of Algorithm 1. To do so, we divide the analysis into two steps, i.e.</p><p>Step I and Step II, as shown in Figure <ref type="figure" target="#fig_1">1</ref>.</p><p>Step (I): This step corresponds to lines 2-6 in Algorithm 1. Recall that our definition of DP for a distribution algorithm (given in Definition 2.3) requires that the transcript of communications of each worker satisfies (centralized) (?, ?)-DP with respect to their own data. Thus, since the workers only send their local momentum to the server, we show that for any i ? H computing g(i) t from D i and ? t is RDP for any ? &gt; 1. Let i ? H, ? &gt; 1 and r = b /m. First, we show that ? := 2C b is an upper bound of the ? 2 -sensitivity of the mini-batch (clipped) averaging. To see this, consider two adjacent training sets D i , Di , the mini-batch average (after clipping) g </p><formula xml:id="formula_172">(i) t computed on mini-batch S (i) t ? D i ,</formula><formula xml:id="formula_173">g (i) t - g(i) t = 1 b x?S (i) t Clip (??(? t , x); C) - 1 b x? S(i) t Clip (??(? t , x); C) = 1 b Clip (??(? t , x * ); C) - 1 b Clip (??(? t , x * ); C) ? 1 b ?Clip (??(? t , x * ); C)? + 1 b ?Clip (??(? t , x * ); C)? ? 2C b .</formula><p>Thanks to the above, the sensitivity of computing the gradient g Furthermore, by Lemma C.5, for every j ? H, the corresponding mechanism M j taking the dataset D j and ? t as input and returning g(j)</p><formula xml:id="formula_174">t is (?, ? 1 (?))-RDP with ? 1 (?) := (1 -? + ???) ??? -1 ? -1 ? ? (???) + (? -???) ??? -1 ? -1 ? ? (???).<label>(42)</label></formula><p>Where</p><formula xml:id="formula_175">? ? (?) = 1 ? -1 log 1 + r 2 ? 2 min 4(e ?(2) -1), e ?(2) min {2, (e ?(?) -1) 2 } + ? j=3</formula><p>r j ? j e (j-1)?(j) min {2, (e ?(?) -1) j } , and ?(?</p><formula xml:id="formula_176">) := ?? 2 2? 2 DP = 2C b 2 ? 2? 2 DP . Furthermore, since ?(?) = +?, we get ? ? (?) = 1 ? -1 log 1 + r 2 ? 2 min 4(e ?(2) -1), 2e ?(2) + 2 ? j=3</formula><p>r j ? j e (j-1)?(j) .</p><p>(43)</p><p>Step (II): This step consists in computing the local momentums from the noisy gradients, and then aggregating the momentums and updating the model accordingly. As this process does not have direct access to the datasets D i , i ? H, it should be considered as a post-processing operation for Step (I). As RDP is preserved by post-processing <ref type="bibr" target="#b54">(Mironov, 2017)</ref>, we conclude that a single iteration of Algorithm 1 is (?, ? 1 (?))-RDP with respect to each worker's data for any ? &gt; 1, with ? 1 (?) as defined above.</p><p>End-to-end privacy. We can now compute the end-to-end DP of our algorithm. First, invoking Lemma C.1 and the per-iteration RDP guarantee of Algorithm 1, we obtain that Algorithm 1 is (?, T ? 1 (?))-RDP towards the server, for any ? &gt; 1. Next, by Lemma C.2, we deduce that Algorithm 1 is (? * (?), ?)-DP towards the server for every ? ? (0, 1), ? &gt; 1, with</p><formula xml:id="formula_177">? * (?) := T ? 1 (?) + log (1/?) ? -1 .</formula><p>This implies that, for any ? ? (0, 1), Algorithm 1 is (? * , ?)-DP with</p><formula xml:id="formula_178">? * := inf ?&gt;1 ? * (?) = inf ?&gt;1 T ? 1 (?) + log (1/?) ? -1 .</formula><p>The above concludes the proof.</p><p>We now prove the (closed-form) approximate DP guarantees of SAFE-DSHB in Theorem 4.1, as a corollary of Theorem C.1. Theorem 4.1. Consider Algorithm 1. Let ? &gt; 0, ? ? (0, 1) be such that ? ? log (1/?). There exists a constant k &gt; 0 such that, for a sufficiently small batch size b, when</p><formula xml:id="formula_179">? DP ? k ? 2C b max {1, b ? T log (1/?) m? }, Algorithm 1 is (?, ?)-DP.</formula><p>Proof. Suppose that b m is sufficiently small. Let ? &gt; 0 and ? ? (0, 1) be such that ? ? log (1/?). Finally consider ?, ? * (?), ? 1 (?), ? ? (?), and ?(?) as defined in the statement and the proof of Theorem C.1. Below, we show that there exists k &gt; 0 such that, when</p><formula xml:id="formula_180">? DP ? k ? 2C /b max {1, b</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>T log (1/?) /m?}, Algorithm 1 ensures (?, ?)-DP towards an honest-butcurious server. First note that, when ? DP ? 2C /b, we have</p><formula xml:id="formula_181">?(2) = ? 2 ? 2 DP = ( 2C /b) 2 ? 2 DP ? 1.</formula><p>Since h := x ? 1</p><p>x (e x -1) is non-decreasing on (0, +?), this also implies that 1 ?(2) (e ?(2) -1) = h(?(2)) ? h(1) = e -1 ? 2. As a result, we have min 4(e ?(2) -1), 2e ?(2) ? 4(e ?(2) -1) ? 8 ?(2).</p><p>(44)</p><p>Recall that</p><formula xml:id="formula_182">? ? (?) = 1 ? -1 log 1 + r 2 ? 2 min 4(e ?(2) -1), 2e ?(2) + 2 ? j=3 r j ? j e (j-1)?(j) .<label>(45)</label></formula><p>Therefore, since we assume that b m is sufficiently small (r ? 1), the dominating term inside the logarithm is the term in r 2 . Using log (1 + x) ? x, there exists a constant k ? such that</p><formula xml:id="formula_183">? ? (?) ? 1 ? -1 ? ? r 2 ? 2 min 4(e ?(2) -1), 2e ?(2) + 2 ? j=3 r j ? j e (j-1)?(j) ? ? ? k ? ? -1 r 2 ? 2 min 4(e ?(2) -1), 2e ?(2) = k ? ? -1 O r 2 ?(? -1) min 4(e ?(2) -1), 2e ?(2) .</formula><p>Hence substituting from (44), we get</p><formula xml:id="formula_184">? ? (?) ? 8k ? r 2 ??(2) = 8k ? r 2 ? 2 ? 2 DP ?.</formula><p>This directly implies that</p><formula xml:id="formula_185">? 1 (?) = (1 -? + ???) ??? -1 ? -1 ? ? (???) + (? -???) ??? -1 ? -1 ? ? (???) ? 8k ? r 2 ? 2 ? 2 DP (1 -? + ???) ??? -1 ? -1 ??? + (? -???) ??? -1 ? -1 ??? .<label>(46)</label></formula><p>Now, recall that ? -1 ? ??? ? ? and ? ? ??? ? ? + 1. We will prove that ? 1 (?) ? 32k ? r 2 ? 2 ? 2 DP by distinguishing two cases:</p><p>Case ? ? (1, 2): Since ? &gt; 1, we have ??? ? 1 and therefore ?-??? /?-1 ? 1. We therefore have from Equation ( <ref type="formula" target="#formula_185">46</ref>)</p><formula xml:id="formula_186">? 1 (?) ? 8k ? r 2 ? 2 ? 2 DP (1 -? + ???) ??? -1 ? -1 ??? + (? -???) ??? -1 ? -1 ??? ? 8k ? r 2 ? 2 ? 2 DP (1 -? + ???) ?1 ??? -1 ? -1 ?1 ??? + (??? -1) ?? ??? ? 8k ? r 2 ? 2 ? 2 DP ??? + ? ??? ? (i) 8k ? r 2 ? 2 ? 2 DP ? + 2? = 24k ? r 2 ? 2 ? 2 DP ?,</formula><p>where (i) is due to ??? ? 2 because ? &lt; 2.</p><p>Case ? ? [2, +?):</p><p>Since ? ? 2, we have both ??? ? ??? ? ? + 1 ? 2? and ??? -1 ? ??? -1 ? 2(? -1). Therefore, we have from Equation ( <ref type="formula" target="#formula_185">46</ref>) that</p><formula xml:id="formula_187">? 1 (?) ? 8k ? r 2 ? 2 ? 2 DP (1 -? + ???) ??? -1 ? -1 ??? + (? -???) ??? -1 ? -1 ??? ? 8k ? r 2 ? 2 ? 2 DP (1 -? + ???)4? + (? -???)4? = 32k ? r 2 ? 2 ? 2 DP .</formula><p>We have now proved for every ? &gt; 1 that ? 1 (?) ? 32k ? r 2 ? 2 ? 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DP</head><p>. This implies that</p><formula xml:id="formula_188">? * = inf ?&gt;1 T ? 1 (?) + log (1/?) ? -1 ? inf ?&gt;1 32k ? r 2 ? 2 ? 2 DP ?T + log (1/?) ? -1 .</formula><p>The above (convex) optimization problem is solved for ? = ? * := 1 + ? DP log (1/?) 32k ? r 2 ? 2 T . Remark that the constraint ? &gt; 1 is satisfied at ? * . Additionally, the objective at ? = ? * is equal to</p><formula xml:id="formula_189">32k ? r 2 ? 2 ? 2 DP ? * T + log (1/?) ? * -1 = 32k ? r 2 ? 2 ? 2 DP T + 2r? 32k ? T log (1/?) ? DP .</formula><p>Therefore, using the assumption</p><formula xml:id="formula_190">? ? log (1/?), when ? DP ? 6C ? 32k ? T log (1/?) m? = 3r? ? 32k ? T log (1/?) ? , we have ? * ? 32k ? r 2 ? 2 ? 2 DP T + 2r? 32k ? T log (1/?) ? DP ? ? 2 9 log (1/?) + 2 /3 ? ? ( 1 /9 + 2 /3)? ? ?.</formula><p>Recall that to derive this last inequality, we overall needed</p><formula xml:id="formula_191">? DP ? 2C /b = ? and ? DP ? 6C ? 32k ? T log (1/?) m? = 3r? ? 32k ? T log (1/?) ?</formula><p>. Therefore, by choosing k := max {1, 3</p><formula xml:id="formula_192">? 32k ? }, we can now conclude that, when ? DP ? k ? 2C /b max {1, b ? T log (1/?) /m?}, Algorithm 1 is (?, ?)-DP.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Upper Bounds D.1. Proof Outline</head><p>Our analysis of SAFE-DSHB (Algorithm 1), inspired from <ref type="bibr" target="#b27">(Farhadkhani et al., 2022)</ref>, consists of three elements: (i) Momentum drift (Lemma D.1), (ii) Momentum deviation (Lemma D.2), and (iii) Descent bound (Lemma D.3). We combine these elements to obtain the final convergence result stated in Theorem 4.2, and the matching upper bound stated in Corollary 5.1.</p><p>Notation. Recall that for each step t, for each honest worker w i ,</p><formula xml:id="formula_193">m (i) t = ? t-1 m (i) t-1 + (1 -? t-1 )g (i) t ,<label>(47)</label></formula><formula xml:id="formula_194">g(i) t = g (i) t + ? (i) t ; ? (i) t ? N (0, ? 2 DP I d ),<label>(48)</label></formula><p>where we initialize m</p><formula xml:id="formula_195">(i) 0 = 0.</formula><p>As we analyze Algorithm 1 with aggregation F , we denote</p><formula xml:id="formula_196">R t := F m (1) t , . . . , m (n) t , (<label>49</label></formula><formula xml:id="formula_197">)</formula><formula xml:id="formula_198">? t+1 = ? t -? t R t . (<label>50</label></formula><formula xml:id="formula_199">)</formula><p>Throughout, we denote the loss function over dataset D i by L i = L(? ; D i ). Also, we denote by P t the history from steps 0 to t. Specifically, P t := ? 0 , . . . , ? t ; m</p><formula xml:id="formula_200">(i) 1 , . . . , m (i) t-1 ; i ? [n] .</formula><p>By convention, P 1 = {? 0 }. We denote by E t [?] and E [?] the conditional expectation E [? P t ] and the total expectation, respectively. Thus,</p><formula xml:id="formula_201">E [?] = E 1 [? ? ? E T [?]].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.1. MOMENTUM DRIFT</head><p>Along the trajectory ? 0 , . . . , ? t , the honest workers' local momentums may drift away from each other. The drift has three distinct sources: (i) noise injected by the DP mechanism, (ii) gradient dissimilarity induced by data heterogeneity, and (iii) stochasticity of the mini-batch gradients. The aforementioned drift of local momentums can be exploited by the Byzantine adversaries to maliciously bias the aggregation output.</p><p>In this section, we will control the growth of the drift ? t between momentums, which we define as</p><formula xml:id="formula_202">? t := ? max 1 |H| i?H (m (i) t -m t )(m (i) t -m t ) ? ,<label>(51)</label></formula><p>where ? max denotes the maximum eigenvalue, and</p><formula xml:id="formula_203">m t := 1 |H| i?H m (i)</formula><p>t denotes the average honest momentum. We show in Lemma D.1 below that the growth of the drift ? t of the momentums can be controlled by tuning the momentum coefficient ? t . The full proof can be found in Appendix D.5.2. Lemma D.1. Suppose that assumptions 2.2 and 2.3 hold. Consider Algorithm 1. For every t ? {0, . . . , T -1}, we have</p><formula xml:id="formula_204">E [? t+1 ] ? ? t E [? t ] + 2(1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + (1 -? t )G 2 cov ,</formula><p>where</p><formula xml:id="formula_205">m t := 1 |H| i?H m (i) t , ? 2 b := 2(1 -b m ) ? 2 b , and G 2 cov := sup ??R d sup ?v??1 1 |H| i?H ?v, ?L i (?) -?L H (?)? 2 .</formula><p>The dimension factor d due to DP noise is divided by n -f , which would not have been possible without leveraging the Gaussian nature of the noise. This dependence will prove crucial to match our lower bound. To leverage Gaussianity, we use a concentration argument on the empirical covariance matrix of Gaussian random variables, stated in Lemma D.6.</p><p>The remaining term G 2 cov of the upper bound is only due to data heterogeneity. An important distinction from <ref type="bibr" target="#b42">(Karimireddy et al., 2022)</ref> is that G 2 cov is a tighter bound on heterogeneity, compared to G 2 the bound on the average squared distance from Assumption 2.1. This is because the drift ? t is not an average squared distance, but rather a bound on average squared distances of every projection on the unit ball. Controlling this quantity requires a covering argument (stated in Lemma D.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.2. MOMENTUM DEVIATION</head><p>Next, we study the momentum deviation; i.e., the distance between the average honest momentum m t and the true gradient ?L H (? t ) in an arbitrary step t. Specifically, we define momentum deviation to be ? t := m t -?L H (? t ) .</p><p>(52) Also, we introduce the error between the aggregate R t and m</p><formula xml:id="formula_206">t := 1 |H| i?H m (i)</formula><p>t the average momentum of honest workers for the case. Specifically, when defining the error</p><formula xml:id="formula_207">? t := R t -m t ,<label>(53)</label></formula><p>we get the following bound on the momentum deviation in Lemma D.2, proof of which can be found in Appendix D.5.3.</p><p>Lemma D.2. Suppose that assumptions 2.2 and 2.3 hold and that L H is L-smooth. Consider Algorithm 1. For all t ? {0, . . . , T -1}, we have</p><formula xml:id="formula_208">E ?? t+1 ? 2 ? ? 2 t (1 + ? t L)(1 + 4? t L) E ?? t ? 2 + 4? t L(1 + ? t L)? 2 t E ??L H (? t )? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + 2? t L(1 + ? t L)? 2 t E ?? t ? 2 ,</formula><p>where</p><formula xml:id="formula_209">? 2 DP := 2 1 -b m ? 2 b + d ? ? 2 DP .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.3. DESCENT BOUND</head><p>Finally, we bound the progress made at each learning step in minimizing the loss L H using Algorithm 1. From ( <ref type="formula" target="#formula_198">50</ref>) and ( <ref type="formula" target="#formula_196">49</ref>), we obtain that, for each step t,</p><formula xml:id="formula_210">? t+1 = ? t -? t R t = ? t -? t m t -? t (R t -m t ),</formula><p>Furthermore, by ( <ref type="formula" target="#formula_207">53</ref>), R t -m t = ? t . Thus, for all t,</p><formula xml:id="formula_211">? t+1 = ? t -? t m t -? t ? t . (<label>54</label></formula><formula xml:id="formula_212">)</formula><p>This means that Algorithm 1 can actually be treated as distributed SGD with a momentum term that is subject to perturbation proportional to ? t at each step t. This perspective leads us to Lemma D.3, proof of which can be found in Appendix D.5.4.</p><formula xml:id="formula_213">Lemma D.3. Assume that L H is L-smooth. Consider Algorithm 1. For any t ? [T ],</formula><p>we have</p><formula xml:id="formula_214">E L H (? t+1 ) -L H (? t ) ? - ? t 2 (1 -4? t L) E ??L H (? t )? 2 + ? t (1 + 2? t L) E ?? t ? 2 + ? t (1 + ? t L) E ?? t ? 2 .</formula><p>Putting all of the previous lemmas together, we prove Theorem 4.2 in Section D.2. We then prove Corollary 5.1 in Section D.3, and its non-convex version in Corollary D.1 in Section D.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Proof of Theorem 4.2</head><p>We recall the theorem statement below for convenience. Recall that Theorem 4.2. Suppose that assumptions 2.2 and 2.3 hold true, and that L H is L-smooth. Let F satisfy the condition of (f, ?)-robust averaging. We let</p><formula xml:id="formula_215">L * = inf ? ?R d L H (?), L 0 = L H (? 0 ) -L * , a 1 = 240, a 2 =</formula><formula xml:id="formula_216">? 2 = ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP 1 + d n -f , where ? 2 b = 2(1 -b m ) ? 2 b .</formula><p>Consider Algorithm 1 with T ? 1, the learning rates ? t and momentum coefficients ? t specified below. We prove that the following holds, where the expectation E [?] is over the randomness of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Strongly convex</head><formula xml:id="formula_217">: Assume that L H is ?-strongly convex. If ? t = 10 ?(t+a1 L ? ) and ? t = 1 -24L? t then E [L H (? T ) -L * ] ? 4a 1 ?G 2 cov ? + 2a 2 1 L? 2 ? 2 T + 2a 2 1 L 2 L 0 ? 2 T 2 . 2. Non-convex: If ? = min 1 24L , ? a4L0 2? ? a3LT</formula><p>and</p><formula xml:id="formula_218">? t = 1 -24L? then E ??L H ( ?)? 2 ? a 2 ?G 2 cov + ? a 3 a 4 LL 0 ? ? T + a 4 LL 0 T .</formula><p>We prove Theorem 4.2 in the strongly convex case in Section D.2.1, and in the non-convex case in Section D.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.1. STRONGLY CONVEX CASE</head><p>Proof. Let Assumption 2.2 hold and assume that L H is L-smooth and ?-strongly convex, and that F is a (f, ?)-robust averaging aggregation rule. Let t ? {0, . . . , T -1}. We set the learning rate and momentum schedules to be</p><formula xml:id="formula_219">? t = 10 ?(t + a 1 L ? ) , ? t = 1 -24L? t , (<label>55</label></formula><formula xml:id="formula_220">)</formula><p>where a 1 := 240. Note that we have</p><formula xml:id="formula_221">? t ? ? 0 = 10 ?240 L ? = 1 24L . (<label>56</label></formula><formula xml:id="formula_222">)</formula><p>To obtain convergence result we define the Lyapunov function to be</p><formula xml:id="formula_223">V t := t + a 1 L ? 2 E L H (? t ) -L * + z 1 L ?? t ? 2 + ? ? z 2 L ? t ,<label>(57)</label></formula><p>where a 1 = 240, z 1 = 1 16 , and z 2 = 2. Throughout the proof, we denote t := t + a 1 L ? . Therefore, we have ? t = 10 ? t . Consider also the auxiliary sequence W t defined as</p><formula xml:id="formula_224">W t := E L H (? t ) -L * + z 1 L ?? t ? 2 + ? ? z 2 L ? t .<label>(58)</label></formula><p>Therefore, we have</p><formula xml:id="formula_225">V t+1 -V t = ( t + 1) 2 W t+1 -t2 W t = ( t + 1) 2 W t+1 -( t2 + 2 t + 1)W t + (2 t + 1)W t = ( t + 1) 2 (W t+1 -W t ) + (2 t + 1)W t . (<label>59</label></formula><formula xml:id="formula_226">)</formula><p>We now bound the quantity W t+1 -W t below.</p><p>Invoking Lemma D.1. Upon substituting from Lemma D.1, we obtain</p><formula xml:id="formula_227">E ? ? z 2 L ? t+1 -? ? z 2 L ? t ? ? ? z 2 L ? t E [? t ] + 2? ? z 2 L (1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + ? ? z 2 L (1 -? t )G 2 cov -? ? z 2 L E [? t ] . (<label>60</label></formula><formula xml:id="formula_228">)</formula><p>Invoking Lemma D.2. Upon substituting from Lemma D.2, we obtain</p><formula xml:id="formula_229">E z 1 L ?? t+1 ? 2 - z 1 L ?? t ? 2 ? z 1 L ? 2 t c t E ?? t ? 2 + 4z 1 ? t (1 + ? t L)? 2 t E ??L H (? t )? 2 + z 1 L (1 -? t ) 2 ? 2 DP n -f + 2z 1 ? t (1 + ? t L)? 2 t E ?? t ? 2 - z 1 L E ?? t ? 2 , (<label>61</label></formula><formula xml:id="formula_230">)</formula><p>where we introduced the following quantity for simplicity</p><formula xml:id="formula_231">c t = (1 + ? t L) (1 + 4? t L) = 1 + 5? t L + 4? 2 t L 2 . (<label>62</label></formula><formula xml:id="formula_232">)</formula><p>Invoking Lemma D.3. Substituting from Lemma D.3, we obtain</p><formula xml:id="formula_233">E L H (? t+1 ) -L H (? t ) ? - ? t 2 (1 -4? t L) E ??L H (? t )? 2 + ? t (1 + 2? t L) E ?? t ? 2 + ? t (1 + ? t L) E ?? t ? 2 . (<label>63</label></formula><formula xml:id="formula_234">)</formula><p>Substituting from ( <ref type="formula" target="#formula_227">60</ref>), ( <ref type="formula" target="#formula_229">61</ref>) and ( <ref type="formula" target="#formula_233">63</ref>) in ( <ref type="formula" target="#formula_224">58</ref>), we obtain</p><formula xml:id="formula_235">W t+1 -W t = E L H (? t+1 ) -L H (? t ) + E z 1 L ?? t+1 ? 2 - z 1 L ?? t ? 2 + E ? ? z 2 L ? t+1 -? ? z 2 L ? t - ? t 2 (1 -4? t L) E ??L H (? t )? 2 + ? t (1 + 2? t L) E ?? t ? 2 + ? t (1 + ? t L) E ?? t ? 2 + z 1 L ? 2 t c t E ?? t ? 2 + 4z 1 ? t (1 + ? t L)? 2 t E ??L H (? t )? 2 + z 1 L (1 -? t ) 2 ? 2 DP n -f + 2z 1 ? t (1 + ? t L)? 2 t E ?? t ? 2 - z 1 L E ?? t ? 2 + ? ? z 2 L ? t E [? t ] + 2? ? z 2 L (1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) ? ? z 2 L (1 -? t )G 2 cov -? ? z 2 L E [? t ] .<label>(64)</label></formula><p>Upon rearranging the R.H.S. in (64) we obtain that</p><formula xml:id="formula_236">W t+1 -W t ? - ? t 2 (1 -4? t L) -8z 1 (1 + ? t L)? 2 t E ??L H (? t )? 2 + z 1 L (1 -? t ) 2 ? 2 DP n -f -z 1 ? t - 1 z 1 (1 + 2? t L) - 1 ? t L ? 2 t c t + 1 ? t L E ?? t ? 2 + ? t 1 + ? t L + 2z 1 (1 + ? t L)? 2 t E ?? t ? 2 -? ? z 2 L (1 -? t ) E [? t ] + 2? ? z 2 L (1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + ? ? z 2 L (1 -? t )G 2 cov . (<label>65</label></formula><formula xml:id="formula_237">)</formula><p>Since we assume F to be (f, ?)-robust averaging, we can bound E ?? t ? 2 as follows. Starting from the definition of ? t , we have</p><formula xml:id="formula_238">?? t ? 2 = ?R t -m t ? 2 = F (m (1) t , . . . , m (n) t ) -m t 2 ? ? ? ? max 1 |H| i?H (m (i) t -m t )(m (i) t -m t ) ? = ? ? ? t .</formula><p>Then taking total expectations above gives the bound</p><formula xml:id="formula_239">E ?? t ? 2 ? ? ? E [? t ] .</formula><p>Using the bound above in Equation ( <ref type="formula" target="#formula_236">65</ref>), and then rearranging terms, yields</p><formula xml:id="formula_240">W t+1 -W t ? - ? t 2 (1 -4? t L) -8z 1 (1 + ? t L)? 2 t E ??L H (? t )? 2 + z 1 L (1 -? t ) 2 ? 2 DP n -f -z 1 ? t - 1 z 1 (1 + 2? t L) - 1 ? t L ? 2 t c t + 1 ? t L E ?? t ? 2 + ?? t 1 + ? t L + 2z 1 (1 + ? t L)? 2 t E [? t ] -? ? z 2 L (1 -? t ) E [? t ] + 2? ? z 2 L (1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + ? ? z 2 L (1 -? t )G 2 cov = - ? t 2 (1 -4? t L) -8z 1 (1 + ? t L)? 2 t E ??L H (? t )? 2 + z 1 L (1 -? t ) 2 ? 2 DP n -f -z 1 ? t - 1 z 1 (1 + 2? t L) - 1 ? t L ? 2 t c t + 1 ? t L E ?? t ? 2 -?z 2 ? t 1 ? t L (1 -? t ) - 1 z 2 1 + ? t L + 2z 1 (1 + ? t L)? 2 t E [? t ] + 2? ? z 2 L (1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + ? ? z 2 L (1 -? t )G 2 cov .</formula><p>For simplicity, we define</p><formula xml:id="formula_241">A := 1 2 (1 -4? t L) -8z 1 (1 + ? t L)? 2 t ,<label>(66)</label></formula><formula xml:id="formula_242">B := - 1 z 1 (1 + 2? t L) - 1 ? t L ? 2 t c t + 1 ? t L ,<label>(67)</label></formula><p>and</p><formula xml:id="formula_243">C := 1 ? t L (1 -? t ) - 1 z 2 1 + ? t L + 2z 1 (1 + ? t L)? 2 t ,<label>(68)</label></formula><p>Denote also</p><formula xml:id="formula_244">? 2 := ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP (1 + d n -f</formula><p>) .</p><p>Recall that, as z 1 = 1 16 and z 2 = 2, and ? 2 DP = ? 2 b + d? 2 DP , we have</p><formula xml:id="formula_245">? 2 ? z 1 ? 2 DP n -f + 2? ? z 2 ? 2 b + 36? 2 DP (1 + d n -f</formula><p>) .</p><p>Thus, substituting the above variables, we obtain</p><formula xml:id="formula_246">W t+1 -W t ? -A? t E ??L H (? t )? 2 -z 1 B? t E ?? t ? 2 -? ? z 2 C? t E [? t ] + 1 L (1 -? t ) 2 ? 2 + ? ? z 2 L (1 -? t )G 2 cov . (<label>69</label></formula><formula xml:id="formula_247">)</formula><p>We now analyze below the terms A, B and C on the RHS of (69).</p><p>Term A. Recall from (56) that ? t ? 1 24L . Upon using this in (66), and the facts that z 1 = 1 16 and ? 2 t ? 1, we obtain that</p><formula xml:id="formula_248">A ? 1 2 (1 -4? t L) -8z 1 (1 + ? t L) ? 1 2 (1 -4 ? 1 24 ) - 8 16 (1 + 1 24 ) ? 1 10 . (<label>70</label></formula><formula xml:id="formula_249">)</formula><p>Term B. Substituting c t from (62) in ( <ref type="formula" target="#formula_242">67</ref>) we obtain that</p><formula xml:id="formula_250">B = - 1 z 1 (1 + 2? t L) - 1 ? t L ? 2 t 1 + 5? t L + 4? 2 t L 2 + 1 ? t L = 1 ? t L 1 -? 2 - 1 z 1 1 + 2? t L + 5z 1 ? 2 t + 4z 1 ? 2 t ? t L .</formula><p>Using the facts that ? t ? 1 and ? t ? 1 24L , and then substituting z 1 = 1 16 we obtain</p><formula xml:id="formula_251">B ? 1 ? t L (1 -? 2 t ) -16 1 + 2 24 + 5 16 + 4 24 ? 16 ? 1 ? t L (1 -? 2 t ) -23 ? 1 ? t L (1 -? t ) -23 = 1.<label>(71)</label></formula><p>where the last equality follows from the fact that 1 -? t = 24? t L.</p><p>Term C. Substituting z 1 = 1 16 , z 2 = 2 in (68), and then using the facts that ? t ? 1 and ? t ? 1 24L , we obtain</p><formula xml:id="formula_252">C = 1 ? t L (1 -? t ) - 1 2 1 + ? t L + (2 ? 16)(1 + ? t L)? 2 t ? 1 ? t L (1 -? t ) - 1 2 1 + 1 24 + 32(1 + 1 24 ) ? 1 ? t L (1 -? t ) -18 = 6,<label>(72)</label></formula><p>where the last equality follows from the fact that 1 -? t = 24? t L.</p><p>Combining terms A, B, and C. Finally, substituting from ( <ref type="formula" target="#formula_248">70</ref>), (71), and ( <ref type="formula" target="#formula_252">72</ref>) in ( <ref type="formula" target="#formula_246">69</ref>) (and recalling that z 2 = 2) we obtain that</p><formula xml:id="formula_253">W t+1 -W t ? - ? t 10 E ??L H (? t )? 2 -z 1 ? t E ?? t ? 2 -6?z 2 ? t E [? t ] + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov .<label>(73)</label></formula><p>Since L H is ?-strongly convex, we have <ref type="bibr" target="#b39">(Karimi et al., 2016)</ref> for</p><formula xml:id="formula_254">any ? ? R d that ??L H (?)? 2 ? 2?(L(?) -L * ).<label>(74)</label></formula><p>Plugging ( <ref type="formula" target="#formula_254">74</ref>) in ( <ref type="formula" target="#formula_253">73</ref>) above, and then recalling that L ? ?, yields</p><formula xml:id="formula_255">W t+1 -W t ? - ?? t 5 E [L H (? t ) -L * ] -z 1 ? t E ?? t ? 2 -6?z 2 ? t E [? t ] + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov ? - ?? t 5 E L H (? t ) -L * + z 1 ? ?? t ? 2 + ? ? z 2 ? ? t + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov ? - ?? t 5 E L H (? t ) -L * + z 1 L ?? t ? 2 + ? ? z 2 L ? t + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov = - ?? t 5 W t + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov .</formula><p>Upon plugging the above bound back in Equation ( <ref type="formula" target="#formula_225">59</ref>), rearranging terms and substituting 1 -? t = 24L? t , we obtain</p><formula xml:id="formula_256">V t+1 -V t ? ( t + 1) 2 - ?? t 5 W t + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov + (2 t + 1)W t = -( t + 1) 2 ?? t 5 -(2 t + 1) W t + ( t + 1) 2 L (24L? t ) 2 ? 2 + ? ? 2( t + 1) 2 L (24L? t )G 2 cov .</formula><p>Recall however that ? t = 10</p><formula xml:id="formula_257">? t as t = t + a 1 L ? .</formula><p>Recall that we denote a 1 = 24 ? 10 = 240. Substituting ? t above yields</p><formula xml:id="formula_258">V t+1 -V t ? ( t + 1) 2 - ?? t 5 W t + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov + (2 t + 1)W t = -2 ( t + 1) 2 t -(2 t + 1) W t + a 2 1 L ( t + 1) 2 ? 2 t2 ? 2 + 2a 1 ? ? ( t + 1) 2 ? t G 2 cov .</formula><p>Observe that 2 ( t+1) 2 t ? 2( t + 1) &gt; 2 t + 1, implying that the first term above is negative:</p><formula xml:id="formula_259">V t+1 -V t ? a 2 1 L ( t + 1) 2 ? 2 t2 ? 2 + 2a 1 ? ? ( t + 1) 2 ? t G 2 cov .</formula><p>Plugging the above bound back in Equation ( <ref type="formula">75</ref>), rearranging terms, and then recalling that a 1</p><formula xml:id="formula_260">L ? ? 0, yields E [L H (? t+1 ) -L * ] ? 4a 1 ? ?G 2 cov + 2a 2 1 L? 2 ? 2 (t + 1 + a 1 L ? ) + 2a 1 L 2 (L H (? 0 ) -L * ) ? 2 (t + 1 + a 1 L ? ) 2 ? 4a 1 ? ?G 2 cov + 2a 2 1 L? 2 ? 2 (t + 1) + 2a 1 L 2 (L H (? 0 ) -L * ) ? 2 (t + 1) 2 .</formula><p>Specializing the inequality above for t = T -1 and denoting L 0 := L H (? 0 ) -L * proves the theorem:</p><formula xml:id="formula_261">E [L H (? T ) -L * ] ? 4a 1 ? ?G 2 cov + 2a 2 1 L? 2 ? 2 T + 2a 2 1 L 2 L 0 ? 2 T 2 .</formula><p>Remark D.1. In the proof of the strongly convex case of Theorem 4.2 above, we do not need the function L H to be ?-strongly convex. In fact, it is sufficient for L H to satisfy the ?-PL inequality stated in ( <ref type="formula" target="#formula_254">74</ref>). Accordingly, our results not only apply to smooth ?-strongly convex functions, but more generally to the class of smooth ?-PL functions, which may be non-convex <ref type="bibr" target="#b39">(Karimi et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.2. NON-CONVEX CASE</head><p>Proof. Let Assumption 2.2 hold and assume L H is L-smooth, and that F is a (f, ?)-robust averaging aggregation rule. Let t ? {0, . . . , T -1}. We set the learning rate and momentum to constant as follows:</p><formula xml:id="formula_262">? t = ? := min 1 24L , ? a 4 L 0 2? ? a 3 LT , ? t = ? := 1 -24L?,<label>(76)</label></formula><p>where a 1 := 240. Note that we have</p><formula xml:id="formula_263">? t = ? ? 1 24L .<label>(77)</label></formula><p>To obtain the convergence result we define the Lyapunov function to be</p><formula xml:id="formula_264">V t := E L H (? t ) -L * + z 1 L ?? t ? 2 + ? ? z 2 L ? t ,<label>(78)</label></formula><p>where z 1 = 1 16 , and z 2 = 2. Note that V t corresponds to the sequence W t defined in Equation ( <ref type="formula" target="#formula_224">58</ref>), and analyzed in Appendix D.2.1 under the assumption that ? t ? 1 24L . Since the latter holds by Equation (77), we directly apply the bound obtained in Equation ( <ref type="formula" target="#formula_253">73</ref>):</p><formula xml:id="formula_265">V t+1 -V t ? - ? t 10 E ??L H (? t )? 2 -z 1 ? t E ?? t ? 2 -6?z 2 ? t E [? t ] + 1 L (1 -? t ) 2 ? 2 + ? ? 2 L (1 -? t )G 2 cov .</formula><p>In turn, substituting ? t = ?, ? t = ? and bounding the second and third terms on the RHS by zero, this implies that</p><formula xml:id="formula_266">V t+1 -V t ? - ? 10 E ??L H (? t )? 2 + 1 L (1 -?) 2 ? 2 + ? ? 2 L (1 -?)G 2 cov .</formula><p>By rearranging terms and then averaging over t ? {0, . . . , T -1}, we obtain</p><formula xml:id="formula_267">1 T T -1 t=0 E ??L H (? t )? 2 ? 10 ?T T -1 t=0 (V t -V t+1 ) + 10 ?L (1 -?) 2 ? 2 + ? ? 20 ?L (1 -?)G 2 cov .</formula><p>We now substitute ? = 1 -24?L. Denoting a 3 = 10 ? 24 2 = 5760, a 2 = 20 ? 24 = 480, we obtain</p><formula xml:id="formula_268">1 T T -1 t=0 E ??L H (? t )? 2 ? 10 ?T T -1 t=0 (V t -V t+1 ) + (10 ? 24 2 ) ?L (?L) 2 ? 2 + ? ? (20 ? 24) ?L (?L)G 2 cov = 10 ?T (V 0 -V T ) + a 3 ?L? 2 + a 2 ?G 2 cov .<label>(79)</label></formula><p>We now bound V 0 -V T . First recall that V T ? 0 as a sum of non-negative terms (see ( <ref type="formula" target="#formula_264">78</ref>)). Therefore, we have</p><formula xml:id="formula_269">V 0 -V T ? V 0 = L H (? 0 ) -L * + z 1 L ?? 0 ? 2 + z 2 L ? 0 . By definition of m t = 1 |H| i?H m (i) t</formula><p>and the initializations m</p><formula xml:id="formula_270">(i) 0 = 0 for all i ? H, we have ? 0 = ? max 1 |H| i?H (m (i) 0 -m 0 )(m (i)</formula><p>0 -m 0 ) ? = 0. Therefore, we have</p><formula xml:id="formula_271">V 0 = L H (? 0 ) -L * + z 1 L ?? 0 ? 2 .</formula><p>Moreover, by definition of ? t in (52), we obtain that <ref type="bibr" target="#b55">(Nesterov et al., 2018)</ref>, Theorem 2.1.5).</p><formula xml:id="formula_272">?? 0 ? 2 = ?m 0 -?L (? 0 )? 2 = ??L H (? 0 )? 2 . Recall that L H is L-smooth. Thus, ??L H (? 0 )? 2 ? 2L(L H (? 0 ) -L * ) (see</formula><p>Therefore, substituting z 1 = 1 16 , we have</p><formula xml:id="formula_273">V 0 -V T ? V 0 ? L H (? 0 ) -L * + 2L 16L (L H (? 0 ) -L * ) = 9 8 (L H (? 0 ) -L * ).</formula><p>By plugging this bound back in (79), and denoting a 4 := 24 ? 10 ? ( 9 8 ) = 270 and L 0 := L H (? 0 ) -L * , we obtain</p><formula xml:id="formula_274">1 T T -1 t=0 E ??L H (? t )? 2 ? 10 ? ( 9 8 ) ?T (L H (? 0 ) -L * ) + a 3 ?L? 2 + a 2 ?G 2 cov = a 4 L 0 24?T + a 3 ?L? 2 + a 2 ?G 2 cov .<label>(80)</label></formula><p>Recall that by definition</p><formula xml:id="formula_275">? = min 1 24L , ? a 4 L 0 2? ? a 3 LT ,</formula><p>and thus</p><formula xml:id="formula_276">1 ? = max 24L, 2 ? a4L0 ? ? a 3 LT ? 24L + 2 ? a4L0 ?</formula><p>? a 3 LT . Therefore, we have</p><formula xml:id="formula_277">a 4 L 0 24?T ? a 4 L 0 24T 24L + 2 ? a 4 L 0 ? a 3 LT = a 4 LL 0 T + ? a 3 a 4 LL 0 ? 12 ? T .</formula><p>Upon using the above, and that ? ?</p><formula xml:id="formula_278">? a4L0 2? ?</formula><p>a3LT , in (80), we obtain that</p><formula xml:id="formula_279">1 T T -1 t=0 E ??L H (? t )? 2 ? a 4 LL 0 T + ? a 3 a 4 LL 0 ? 12 ? T + ? a 3 a 4 LL 0 ? 2 ? T + a 2 ?G 2 cov ? a 2 ?G 2 cov + ? a 3 a 4 LL 0 ? ? T + a 4 LL 0 T .</formula><p>Finally, recall from Algorithm 1 that ? is chosen randomly from the set of parameter vectors ? 0 , . . . , ? T -1 . Thus,</p><formula xml:id="formula_280">E ?L H ? 2 = 1 T T -1 t=0 E ??L H (? t )? 2 .</formula><p>Substituting this above proves the theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Proof of Corollary 5.1</head><p>We now state the proof of Corollary 5.1 below. Corollary 5.1. Consider Algorithm 1 with aggregation F = SMEA, under the strongly convex setting of Theorem 4.2. Suppose that assumptions 2.1, 2.2, 2.3 hold, and that n ? (2 + ?)f , for some absolute constant ? &gt; 0. Let ? &gt; 0, ? ? (0, 1) be such that ? ? log (1/?). Then, there exists a constant k &gt; 0 such that, if</p><formula xml:id="formula_281">? DP = k ? 2C /b max {1, b ? T log (1/?) /?m}, then Algorithm 1 is (?, ?)-DP and (f, ?)-robust where ? = O d log (1/?) ? 2 nm 2 + f n ? log (1/?) ? 2 m 2 + f n G 2 .</formula><p>Proof. Assume that L H is L-smooth and ?-strongly convex. Consider Algorithm 1 with aggregation F = SMEA, learning rate ? t = 10 ?(t+a1 L ? ) , and momentum coefficient ? t = 1 -24L? t . By Theorem 4.1, the condition on ? DP ensures that Algorithm 1 is (?, ?)-DP. In the remaining, we prove that Algorithm 1 is (f, ?)-robust as stated in the corollary.</p><p>First, note that, by Proposition 5.1, SMEA is (f, ?)-robust averaging with ? = 4f n-f (1 + f n-2f ) 2 . In fact, as we assume n ? (2 + ?)f where ? &gt; 0 is an absolute constant, we have</p><formula xml:id="formula_282">? ? 4f n -f (1 + 1 ? ) 2 = O( f n -f ).<label>(81)</label></formula><p>Therefore, thanks to Theorem 4.2, we have</p><formula xml:id="formula_283">E [L H (? T ) -L * ] ? 4a 1 ?G 2 cov ? + 2a 2 1 L? 2 ? 2 T + 2a 2 1 L 2 L 0 ? 2 T 2 , (<label>82</label></formula><formula xml:id="formula_284">)</formula><p>where the constant a 1 is defined as in (3), and</p><formula xml:id="formula_285">? 2 := ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP (1 + d n -f ) , ? 2 b := 2(1 - b m ) ? 2 b .</formula><p>We now analyze independently the terms of ( <ref type="formula" target="#formula_283">82</ref>) that depend on T , i.e. the last two terms on the RHS of (82). Recall that, asymptotically in T , the condition on ? DP implies</p><formula xml:id="formula_286">? DP = k ? 2C b max {1, b ? T log (1/?) /m?} = O C T log (1/?) m? . (<label>83</label></formula><formula xml:id="formula_287">) Term 2a 2 1 L? 2 ? 2 T .</formula><p>Recalling the expression of ? 2 , and using ( <ref type="formula" target="#formula_286">83</ref>) and ( <ref type="formula" target="#formula_282">81</ref>) and the facts that ? 2 b is independent of T and f &lt; n -f , we obtain</p><formula xml:id="formula_288">? 2 = ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP (1 + d n -f ) = O d? 2 DP n -f + f n -f ? ? 2 DP (1 + d n -f ) = O d? 2 DP n -f + f n -f ? ? 2 DP = O C 2 d T log (1/?) m 2 (n -f )? 2 + f n -f ? C 2 T log (1/?) m 2 ? 2 .</formula><p>As a result, we obtain</p><formula xml:id="formula_289">2a 2 1 L? 2 ? 2 T = O C 2 d log (1/?) m 2 (n -f )? 2 + f n -f ? C 2 log (1/?) m 2 ? 2 . (<label>84</label></formula><formula xml:id="formula_290">) Term 2a 2 1 L 2 L0 ? 2 T 2 .</formula><p>This term is independent of ? DP and vanishes with T . Going back to (82), and ignoring terms vanishing in T , and using (81), we obtain</p><formula xml:id="formula_291">E [L H (? T ) -L * ] = O C 2 d log (1/?) m 2 (n -f )? 2 + f n -f C 2 log (1/?) m 2 ? 2 + f n -f G 2 cov .</formula><p>Finally, note that G 2 cov ? G 2 . Indeed, using the definition of G 2 cov and Assumption 2.1, together with Cauchy-Schwartz, we have</p><formula xml:id="formula_292">G 2 cov = sup ??R d sup ?v??1 1 |H| i?H ?v, ?L i (?) -?L H (?)? 2 ? sup ??R d 1 |H| i?H ??L i (?) -?L H (?)? 2 ? G 2 .</formula><p>Using the fact above in the last inequality, together with the fact that n -f ? n 2 (as n &gt; 2f ), we conclude</p><formula xml:id="formula_293">E [L H (? T ) -L * ] = O C 2 d log (1/?) m 2 n? 2 + f n C 2 log (1/?) m 2 ? 2 + f n G 2 .</formula><p>Ignoring the constant C above concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. Proof of Corollary D.1</head><p>We now state the robustness and DP guarantees of SAFE-DSHB with SMEA in the non-convex case in Corollary D.1 below.</p><p>Corollary D.1. Consider Algorithm 1 with aggregation F = SMEA, under the non-convex setting of Theorem 4.2. Suppose that assumptions 2.1, 2.2, 2.3 hold, that L H is L-smooth, and that n ? (2 + ?)f , for some absolute constant ? &gt; 0. Let ? &gt; 0, ? ? (0, 1) be such that ? ? log (1/?). Then, there exists a constant k &gt; 0 such that, if</p><formula xml:id="formula_294">? DP = k ? 2C /b max {1, b ? T log (1/?) /?m}, then Algorithm 1 is (?, ?)-DP and (f, ?)-robust, where ? = O d log (1/?) ? ? nm + f n ? log (1/?) ?m + f n G 2 .</formula><p>Proof. Assume that L H is L-smooth. Consider Algorithm 1 with aggregation F = SMEA, learning rate</p><formula xml:id="formula_295">? t = ? = min 1 24L , ? a4L0 2? ?</formula><p>a3LT , and momentum coefficient ? t = ? = 1 -24L?. By Theorem 4.1, the condition on ? DP ensures that Algorithm 1 is (?, ?)-DP. In the remaining, we prove that Algorithm 1 is (f, ?)-robust as stated in the corollary.</p><p>First, note that, by Proposition 5.1, SMEA is (f, ?)-robust averaging with ? = 4f n-f (1 + f n-2f ) 2 . In fact, as we assume n ? (2 + ?)f where ? &gt; 0 is an absolute constant, we have</p><formula xml:id="formula_296">? ? 4f n -f (1 + 1 ? ) 2 = O( f n -f ).<label>(85)</label></formula><p>Therefore, thanks to Theorem 4.2, we have</p><formula xml:id="formula_297">E ??L H ( ?)? 2 ? a 2 ?G 2 cov + ? a 3 a 4 LL 0 ? ? T + a 4 LL 0 T ,<label>(86)</label></formula><p>where the constants a 1 , a 2 , a 3 , a 4 are defined as in (3), and</p><formula xml:id="formula_298">? 2 := ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP (1 + d n -f ) , ? 2 b := 2(1 - b m ) ? 2 b .</formula><p>We now analyze independently the terms of (82) that depend on T , i.e. the last two terms on the RHS of (82). Recall that, asymptotically in T , the condition on ? DP implies</p><formula xml:id="formula_299">? DP = k ? 2C b max {1, b ? T log (1/?) /m?} = O C T log (1/?) m? . (<label>87</label></formula><formula xml:id="formula_300">)</formula><formula xml:id="formula_301">Term ? a3a4LL0? ? T</formula><p>. Recalling the expression of ? 2 , and using ( <ref type="formula" target="#formula_286">83</ref>) and ( <ref type="formula" target="#formula_282">81</ref>) and the facts that ? 2 b is independent of T and f &lt; n -f , we obtain</p><formula xml:id="formula_302">? 2 = ? 2 b + d? 2 DP n -f + 4? ? 2 b + 36? 2 DP (1 + d n -f ) = O d? 2 DP n -f + f n -f ? ? 2 DP (1 + d n -f ) = O d? 2 DP n -f + f n -f ? ? 2 DP = O C 2 d T log (1/?) m 2 (n -f )? 2 + f n -f ? C 2 T log (1/?) m 2 ? 2 . Therefore, using ? x + y ? ? x + ? y, we obtain ? = O C d T log (1/?) m ? n -f ? + f n -f ? C T log (1/?) m? .</formula><p>As a result, we obtain</p><formula xml:id="formula_303">? a 3 a 4 LL 0 ? ? T = O C d log (1/?) m ? n -f ? + f n -f ? C log (1/?) m? .<label>(88) Term a4LL0</label></formula><p>T . This term is independent of ? DP and vanishes with T .</p><p>Going back to (86), ignoring terms vanishing in T , and using (85), we obtain</p><formula xml:id="formula_304">E ??L H ( ?)? 2 = O C d log (1/?) m ? n -f ? + f n -f ? C log (1/?) m? + f n -f G 2 cov .</formula><p>Finally, note that G 2 cov ? G 2 . Indeed, using the definition of G 2 cov and Assumption 2.1, together with Cauchy-Schwartz, we have</p><formula xml:id="formula_305">G 2 cov = sup ??R d sup ?v??1 1 |H| i?H ?v, ?L i (?) -?L H (?)? 2 ? sup ??R d 1 |H| i?H ??L i (?) -?L H (?)? 2 ? G 2 .</formula><p>Using the fact above in the last inequality, together with the fact that n -f ? n 2 (as n &gt; 2f ), we conclude</p><formula xml:id="formula_306">E ??L H ( ?)? 2 = O C d log (1/?) m ? n? + f n ? C log (1/?) m? + f n G 2 .</formula><p>Ignoring the constant C above concludes the proof.</p><p>Discussion. We conjecture that the non-convex upper bound can be improved as observed recently in the centralized DP setting using other variance reduction techniques <ref type="bibr" target="#b6">(Arora et al., 2022)</ref>. Nevertheless, both in the centralized and distributed settings, it remains an open question to derive tight lower bounds for non-convex problems. Proof. Let M ? R d?d be a random real symmetric matrix and g : R ? R a increasing function.</p><p>The proof follows the construction of (Section 5.2, <ref type="bibr" target="#b70">(Vershynin, 2010)</ref>). Recall from standard covering net results <ref type="bibr" target="#b70">(Vershynin, 2010)</ref> that we can construct N 1/4 a finite 1/4-net of the unit ball, i.e., for any vector v in the unit ball, there exists u v ? N 1/4 such that ?u v -v? ? 1/4. Moreover, we have the bound N 1/4 ? (1 + 2/(1/4)) d = 9 d . Denote by ?M ? := sup ?v??1 ?M v? the operator norm of M . By recalling that M is symmetric, we obtain for any v in the unit ball</p><formula xml:id="formula_307">|?v, M v? -?u v , M u v ?| = |?v + u v , M (v -u v )?| ? ?v + u v ? ?M (v -u v )? ? (?v? + ?u v ?) ?M (v -u v )? ? 2 ?M (v -u v )? ? 2 ?M ? ?v -u v ? ? 2 ?M ? /4 = ?M ? /2.</formula><p>Therefore, we have ?v, M v? -?u v , M u v ? ? ?M ? /2, and ?v, M v? -?M ? /2 ? ?u v , M u v ? ? sup u?N 1/4 ?u, M u?.</p><p>Recall that since M is symmetric, its operator norm coincides with its maximum eigenvalue: ?M ? = sup ?v??1 ?v, M v?.</p><p>We therefore deduce that sup Upon taking expectations and applying union bound, we finally conclude</p><formula xml:id="formula_308">E sup ?v??1 g(?v, M v?) ? E sup v?N 1/4 g(2 ?v, M v?) ? N 1/4 ? sup v?N 1/4 E [g(2 ?v, M v?)] ? 9 d ? sup ?v??1 E [g(2 ?v, M v?)] .</formula><p>Lemma D.5. Suppose assumptions 2.2 and 2.3 hold. For any t ? {0, . . . , T -1} and i ? H, we have</p><formula xml:id="formula_309">E g(i) t -?L i (? t ) 2 ? 2 1 - b m ? 2 b + d ? ? 2 DP .</formula><p>Proof. Suppose assumptions 2.2 and 2.3 hold. Let i ? H and t ? {0, . . . , T -1}.</p><p>First recall from (48) that, since</p><formula xml:id="formula_310">g(i) t = g (i) t + ? (i) t , ? (i) t i.i.d.</formula><p>? N (0, ? 2 DP I d ), we have</p><formula xml:id="formula_311">E ? (i) t g(i) t -g (i) t 2 = E ? (i) t 2 = d ? ? 2 DP .</formula><p>Next, we have</p><formula xml:id="formula_312">g(i) t -?L i (? t ) 2 = g(i) t -g (i) t + g (i) t -?L i (? t ) 2 = g(i) t -g (i) t 2 + g (i) t -?L i (? t ) 2 + 2 g(i) t -g (i) t , g<label>(i)</label></formula><p>t -?L i (? t ) .</p><p>Now taking expectation on the randomness of ? (i)</p><p>t (independent of all other random variables), and since E ?</p><formula xml:id="formula_313">(i) t = 0, we get E ? (i) t g(i) t -?L i (? t ) 2 = E ? (i) t g(i) t -g (i) t 2 + g (i) t -?L i (? t ) 2 + 2 E ? (i) t g(i) t -g (i) t =E ? (i) t =0 , g (i) t -?L i (? t ) = E ? (i) t g(i) t -g (i) t 2 + g (i) t -?L i (? t ) 2 .</formula><p>Upon taking total expectation, we obtain</p><formula xml:id="formula_314">E g(i) t -?L i (? t ) 2 = E g(i) t -g (i) t 2 + E g (i) t -?L i (? t ) 2 = E g (i) t -?L i (? t ) 2 + d ? ? 2 DP .<label>(89)</label></formula><p>First observe that when m = 1, as b ? [m], we must have b = m. Thus, the gradient is deterministic, i.e., g</p><p>t = ?L i (? t ). Thus, the first term in the equation above is zero, and the claimed bound holds.</p><p>Else, when m ? 2, recall that from Assumption 2.2, we have <ref type="bibr" target="#b59">(Rice, 2006)</ref>, the variance reduction due to subsampling without replacement gives</p><formula xml:id="formula_316">E x?U (Di) ?? ? ?(? t ; x) -?L i (? t )? 2 ? ? 2 . From</formula><formula xml:id="formula_317">E g (i) t -?L i (? t ) 2 ? 1 - b -1 m -1 ? 2 b .</formula><p>Plugging this bound back in Equation ( <ref type="formula" target="#formula_314">89</ref>) yields</p><formula xml:id="formula_318">E g(i) t -?L i (? t ) 2 ? 1 - b -1 m -1 ? 2 b + d ? ? 2 DP .</formula><p>By observing, as m ? 2, that 1</p><formula xml:id="formula_319">-b-1 m-1 = m-b m-1 = m m-1 ? m-b m = (1 + 1 m-1 )(1 -b m ) ? 2(1 -b m )</formula><p>, we obtain the final result:</p><formula xml:id="formula_320">E g(i) t -?L i (? t ) 2 ? 2 1 - b m ? 2 b + d ? ? 2 DP .</formula><p>Lemma D.6. Let ? DP ? 0 and d, n ? 1. Consider ? (1) , . . . , ? (n) to be i.i.d. random variables drawn from the Gaussian distribution N (0, ? 2 DP I d ). We have</p><formula xml:id="formula_321">E sup ?v??1 1 n n i=1 v, ? (i) 2 ? 36? 2 DP 1 + d n .</formula><p>Proof. Let ? DP ? 0 and d, n ? 1. Consider ? (1) , . . . , ? (n) to be i.i.d. random variables drawn from the Gaussian distribution N (0, ? 2 DP I d ). If ? DP = 0, then ? (i) = 0 almost surely for every i ? [n], and the remainder of the proof holds with ? DP = 0. Else, we assume ? DP &gt; 0 in the remaining.</p><p>Thus, the law of the random variable ? (i) /? DP is N (0, I d ) for every i ? [n]. Thus, for every vector of the unit ball v, the random variable v, ? (i) /? DP is sub-Gaussian with variance proxy equal to 1 (see (Chapter 1, <ref type="bibr" target="#b60">(Rigollet &amp; H?tter, 2015)</ref>)). Therefore, for every i ? [n] and every vector v of the unit ball, applying (Theorem 2.1.1, (Pauwels, 2020)), we have</p><formula xml:id="formula_322">E exp v, ? (i) /? DP 2 /8 ? 2.</formula><p>As a result, by the independence of ? (i) 's, we obtain</p><formula xml:id="formula_323">sup ?v??1 E exp 1 8? 2 DP n i=1 v, ? (i) 2 = sup ?v??1 n i=1 E exp v, ? (i) /? DP 2 /8 ? 2 n .</formula><p>Now, observe that we can write n i=1 v, ? (i) 2 as the quadratic form ?v, M v?, where M := n i=1 ? (i) ? ? (i) ? is a random real symmetric matrix. Thus, applying Lemma D.4 with the increasing function g = exp ( 1 16? 2 DP ? ?), we have</p><formula xml:id="formula_324">E sup ?v??1 exp 1 16? 2 DP n i=1 v, ? (i) 2 = E sup ?v??1 g(?v, M v?) ? 9 d ? sup ?v??1 E [g(2 ?v, M v?)] = 9 d ? sup ?v??1 E exp 1 8? 2 DP n i=1 v, ? (i) 2 ? 9 d ? 2 n .</formula><p>We can now use this inequality to bound the term of interest. We apply Jensen's inequality thanks to exp being convex, and we also interchange exp and sup thanks to the former being increasing:</p><formula xml:id="formula_325">exp 1 16? 2 DP E sup ?v??1 n i=1 v, ? (i) 2 ? E exp 1 16? 2 DP sup ?v??1 n i=1 v, ? (i) 2 = E sup ?v??1 exp 1 16? 2 DP n i=1 v, ? (i) 2 ? 9 d ? 2 n .</formula><p>Upon applying ln and multiplying by 16? 2 DP /n, we obtain</p><formula xml:id="formula_326">E sup ?v??1 1 n n i=1 v, ? (i) 2 ? 16 ? 2 DP n (d ln 9 + n ln 2)? 2 ? 36 ? 2 DP n (d + n) = 36? 2 DP 1 + d n .</formula><p>The above concludes the proof D.5.2. PROOF OF LEMMA D.1</p><p>Lemma D.1. Suppose that assumptions 2.2 and 2.3 hold. Consider Algorithm 1. For every t ? {0, . . . , T -1}, we have</p><formula xml:id="formula_327">E [? t+1 ] ? ? t E [? t ] + 2(1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + (1 -? t )G 2 cov ,</formula><p>where</p><formula xml:id="formula_328">m t := 1 |H| i?H m (i) t , ? 2 b := 2(1 -b m ) ? 2 b , and G 2 cov := sup ??R d sup ?v??1 1 |H| i?H ?v, ?L i (?) -?L H (?)? 2 .</formula><p>Proof. Let t ? {0, . . . , T -1}. Suppose that Assumption 2.2 holds. Recall that the alternate definition of maximum eigenvalue implies, following the definition of ? t in Equation ( <ref type="formula" target="#formula_202">51</ref>), that</p><formula xml:id="formula_329">? t = ? max 1 |H| i?H (m (i) t -m t )(m (i) t -m t ) ? = sup ?v??1 1 |H| i?H v, m (i) t -m t 2 .</formula><p>We will use the latter expression above for ? t throughout this lemma.</p><p>For every i ? H, by definition of m (i) t , given in Equation ( <ref type="formula" target="#formula_193">47</ref>), we have</p><formula xml:id="formula_330">m (i) t+1 = ? t m (i) t + (1 -? t )g (i)</formula><p>t+1 .</p><p>We also denote m</p><formula xml:id="formula_331">t := 1 |H| i?H m (i) t and g t+1 := 1 |H| i?H g(i)</formula><p>t+1 . Therefore, we have m t+1 = ? t m t + (1 -? t ) g t+1 . As a result, we can write for every i ? H</p><formula xml:id="formula_332">m (i) t+1 -m t+1 = ? t (m (i) t -m t ) + (1 -? t )(g (i) t+1 -g t+1 ) = ? t (m (i) t -m t ) + (1 -? t )(?L i (? t+1 ) -?L H (? t+1 )) + (1 -? t )(g (i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 )).</formula><p>By projecting the above expression on an arbitrary vector v and then taking squares, we obtain v, m</p><formula xml:id="formula_333">(i) t+1 -m t+1 2 = ? t v, m (i) t -m t + (1 -? t ) ?v, ?L i (? t+1 ) -?L H (? t+1 )? + (1 -? t ) v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 = ? 2 t v, m (i) t -m t 2 + (1 -? t ) 2 ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 + (1 -? t ) 2 v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 + 2? t (1 -? t ) v, m (i) t -m t ?v, ?L i (? t+1 ) -?L H (? t+1 )? + 2? t (1 -? t ) v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) + 2? t (1 -? t ) ?v, ?L i (? t+1 ) -?L H (? t+1 )? v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) .</formula><p>Upon averaging over i ? H, taking the supremum over the unit ball, and then total expectations, we get</p><formula xml:id="formula_334">E sup ?v??1 1 |H| i?H v, m (i) t+1 -m t+1 2 = ? 2 t E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + (1 -? t ) 2 E sup ?v??1 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 + (1 -? t ) 2 E sup ?v??1 1 |H| i?H v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 + 2? t (1 -? t ) E sup ?v??1 1 |H| i?H v, m (i) t -m t ?v, ?L i (? t+1 ) -?L H (? t+1 )? + 2? t (1 -? t ) E sup ?v??1 1 |H| i?H v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) + 2? t (1 -? t ) E sup ?v??1 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) .<label>(90)</label></formula><p>We now show that the last two terms on the RHS of Equation ( <ref type="formula" target="#formula_334">90</ref>) are non-positive. We show it for the first one, as the second one can be shown to be non-positive in the same way.</p><p>First, note that we can write the inner expression as a quadratic form. Precisely, we have for any vector v and any i ? H that</p><formula xml:id="formula_335">2 i?H v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) = ?v, M v? ,</formula><p>where we have introduced the</p><formula xml:id="formula_336">d ? d matrix M := N + N ? , such that N := i?H (m (i) t -m t )(g (i) t+1 -?L i (? t+1 ) - g t+1 + ?L H (? t+1 )) ? .</formula><p>By observing that M is symmetric, we can apply Lemma D.4 with g being the identity mapping:</p><formula xml:id="formula_337">E sup ?v??1 2 i?H v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) = E sup ?v??1 ?v, M v? ? 9 d ? sup ?v??1 E [2 ?v, M v?] .<label>(91)</label></formula><p>However, the last term is zero by the total law of expectation. Indeed, recall that stochastic gradients are unbiased (Assumption 2.2) and that ? t+1 and m (i)</p><p>t are deterministic when given history P t+1 . This gives</p><formula xml:id="formula_338">E [?v, M v?] = E 2 i?H v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) = E E t+1 2 i?H v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) = E ? ? ?2 i?H v, m (i) t -m t v, E t+1 g(i) t+1 -?L i (? t+1 ) =0 -E t+1 g t+1 -?L H (? t+1 ) =0 ? ? ? = 0.</formula><p>Moreover, going back to Equation ( <ref type="formula" target="#formula_337">91</ref>), we obtain</p><formula xml:id="formula_339">E sup ?v??1 2 i?H v, m (i) t -m t v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) ? 9 d ? sup ?v??1 E [2 ?v, M v?] = 0.</formula><p>As mentioned previously, we can prove in the same way that</p><formula xml:id="formula_340">E sup ?v??1 2 i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) ? 0.</formula><p>Plugging the two previous bounds back in Equation ( <ref type="formula" target="#formula_334">90</ref>), we have thus proved that</p><formula xml:id="formula_341">E sup ?v??1 1 |H| i?H v, m (i) t+1 -m t+1 2 = ? 2 t E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + (1 -? t ) 2 E sup ?v??1 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 + (1 -? t ) 2 E sup ?v??1 1 |H| i?H v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 + 2? t (1 -? t ) E sup ?v??1 1 |H| i?H v, m (i) t -m t ?v, ?L i (? t+1 ) -?L H (? t+1 )? .<label>(92)</label></formula><p>We now bound the two last terms on the RHS of Equation ( <ref type="formula" target="#formula_341">92</ref>).</p><p>First, by using the fact that 2ab ? a 2 + b 2 , we have for any vector v that</p><formula xml:id="formula_342">2 |H| i?H v, m (i) t -m t ?v, ?L i (? t+1 ) -?L H (? t+1 )? ? 1 |H| i?H v, m (i) t -m t 2 + ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 = 1 |H| i?H v, m (i) t -m t 2 + 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 . (<label>93</label></formula><formula xml:id="formula_343">)</formula><p>Taking the supremum over the unit ball and then total expectations yields</p><formula xml:id="formula_344">2 E sup ?v??1 1 |H| i?H v, m (i) t -m t ?v, ?L i (? t+1 ) -?L H (? t+1 )? ? E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + E sup ?v??1 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 . (94) Second, recall that g(i) t+1 = g (i) t+1 + ? (i) t+1 , where ? (i) t+1 ? N (0, ? 2 DP I d ). Denote ? t+1 := 1 |H| i?H ? (i)</formula><p>t+1 . Therefore, by applying Jensen's inequality, we have</p><formula xml:id="formula_345">E sup ?v??1 1 |H| i?H v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 = E sup ?v??1 1 |H| i?H v, g (i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) + ? (i) t+1 -? t+1 2 ? 2 E sup ?v??1 1 |H| i?H v, g (i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 + v, ? (i) t+1 -? t+1<label>2</label></formula><p>Now, recall the following bias-variance decomposition: for any x 1 , . . . , x n ? R we have</p><formula xml:id="formula_346">1 n n i=1 (x i -x) 2 = 1 n n i=1 x 2 i - x 2 ? n i=1 x 2</formula><p>i , where we denoted x := 1 n n i=1 x i . Applying this fact above yields</p><formula xml:id="formula_347">E sup ?v??1 1 |H| i?H v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 ? 2 E sup ?v??1 1 |H| i?H v, g (i) t+1 -?L i (? t+1 ) 2 + v, ? (i) t+1 2 ? 2 E 1 |H| i?H g (i) t+1 -?L i (? t+1 ) 2 + 2 E sup ?v??1 1 |H| i?H v, ? (i) t+1 2 ,<label>(95)</label></formula><p>where the last inequality is due to the Cauchy-Schwartz inequality. Recall that, by Assumption 2.2 and Lemma D.5 applied with zero privacy noise, we have for every i ? H that E g</p><formula xml:id="formula_348">(i) t+1 -?L i (? t+1 ) 2 ? 2(1 -b m ) ? 2 b =: ? 2 b . Therefore, upon averaging over i ? H, we have E 1 |H| i?H g (i) t+1 -?L i (? t+1 ) 2 ? ? 2 b .<label>(96)</label></formula><p>We now bound the remaining (last) term on the RHS of Equation (95). By applying Lemma D.6 to the random variables (?</p><formula xml:id="formula_349">(i) t+1 ) i?H which are drawn i.i.d. from N (0, ? 2 DP I d ), we obtain E sup ?v??1 1 |H| i?H v, ? (i) t+1 2 ? 36? 2 DP 1 + d n -f . (<label>97</label></formula><formula xml:id="formula_350">)</formula><p>Plugging the bounds obtained in Equations ( <ref type="formula" target="#formula_348">96</ref>) and ( <ref type="formula" target="#formula_349">97</ref>) back in Equation ( <ref type="formula" target="#formula_347">95</ref>), we get</p><formula xml:id="formula_351">E sup ?v??1 1 |H| i?H v, g(i) t+1 -?L i (? t+1 ) -g t+1 + ?L H (? t+1 ) 2 ? 2 ? 2 b + 36? 2 DP (1 + d n -f ) .<label>(98)</label></formula><p>We can now use the above bound of Equation ( <ref type="formula" target="#formula_351">98</ref>) and that of Equation ( <ref type="formula">94</ref>) to bound the RHS of Equation ( <ref type="formula" target="#formula_341">92</ref>), which yields</p><formula xml:id="formula_352">E sup ?v??1 1 |H| i?H v, m (i) t+1 -m t+1 2 ? ? 2 t E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + (1 -? t ) 2 E sup ?v??1 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 + 2(1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + ? t (1 -? t ) E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 .</formula><p>By rearranging terms, and noticing that</p><formula xml:id="formula_353">? 2 t + ? t (1 -? t ) = ? t and (1 -? t ) 2 + ? t (1 -? t ) = 1 -? t , we obtain E sup ?v??1 1 |H| i?H v, m (i) t+1 -m t+1 2 ? ? t E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + (1 -? t ) E sup ?v??1 1 |H| i?H ?v, ?L i (? t+1 ) -?L H (? t+1 )? 2 + 2(1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) . Denote G 2 cov := sup ??R d sup ?v??1 1 |H| i?H ?v, ?L i (?) -?L H (?)? 2 . Then, the above bound implies E sup ?v??1 1 |H| i?H v, m (i) t+1 -m t+1 2 ? ? t E sup ?v??1 1 |H| i?H v, m (i) t -m t 2 + 2(1 -? t ) 2 ? 2 b + 36? 2 DP (1 + d n -f ) + (1 -? t )G 2 cov .</formula><p>The above inequality concludes the proof. </p><formula xml:id="formula_354">E ?? t+1 ? 2 ? ? 2 t (1 + ? t L)(1 + 4? t L) E ?? t ? 2 + 4? t L(1 + ? t L)? 2 t E ??L H (? t )? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + 2? t L(1 + ? t L)? 2 t E ?? t ? 2 , where ? 2 DP := 2 1 -b m ? 2 b + d ? ? 2 DP .</formula><p>Proof. Let t ? {0, . . . , T -1}. Suppose that assumptions 2.2 and 2.3 hold and that L H is L-smooth.</p><p>Recall from (52) that</p><formula xml:id="formula_355">? t+1 := m t+1 -?L H ? t+1 . Denote g t := 1 |H| i?H g(i) t .</formula><p>Substituting from (47) and recalling that m</p><formula xml:id="formula_356">t = 1 |H| i?H m (i) t , we obtain ? t+1 = ? t m t + (1 -? t ) g t+1 -?L H ? t+1 .</formula><p>Upon adding and subtracting ? t ?L H (? t ) and ? t ?L H (? t+1 ) on the R.H.S. above we obtain that</p><formula xml:id="formula_357">? t+1 = ? t m t -? t ?L H (? t ) + (1 -? t ) g t+1 -?L H ? t+1 + ? t ?L H (? t+1 ) + ? t ?L H (? t ) -? t ?L H (? t+1 ) = ? t (m t -?L H (? t )) + (1 -? t ) g t+1 -(1 -? t )?L H ? t+1 + ? t ?L H (? t ) -?L H (? t+1 ) .</formula><p>As m t -?L H (? t ) = ? t (by ( <ref type="formula">52</ref>)), from above we obtain that</p><formula xml:id="formula_358">? t+1 = ? t ? t + (1 -? t ) g t+1 -?L H ? t+1 + ? t ?L H (? t ) -?L H (? t+1 ) .</formula><p>Therefore,</p><formula xml:id="formula_359">?? t+1 ? 2 =? 2 t ?? t ? 2 + (1 -? t ) 2 g t+1 -?L H ? t+1 2 + ? 2 t ?L H (? t ) -?L H (? t+1 ) 2 + 2? t (1 -? t ) ? t , g t+1 -?L H ? t+1 + 2? 2 t ? t , ?L H (? t ) -?L H (? t+1 ) + 2? t (1 -? t ) g t+1 -?L H ? t+1 , ?L H (? t ) -?L H (? t+1 ) .</formula><p>By taking conditional expectation E t+1 [?] on both sides, and recalling that ? t , ? t+1 and ? t are deterministic values when the history P t+1 is given, we obtain that</p><formula xml:id="formula_360">E t+1 ?? t+1 ? 2 =? 2 t ?? t ? 2 + (1 -? t ) 2 E t+1 g t+1 -?L H ? t+1 2 + ? 2 t ?L H (? t ) -?L H (? t+1 ) 2 + 2? t (1 -? t ) ? t , E t+1 g t+1 -?L H ? t+1 + 2? 2 t ? t , ?L H (? t ) -?L H (? t+1 ) + 2? t (1 -? t ) E t+1 g t+1 -?L H ? t+1 , ?L H (? t ) -?L H (? t+1 ) .</formula><p>Recall that g t+1 :=</p><formula xml:id="formula_361">1 (n-f ) j?H g(i)</formula><p>t+1 . Thus, as we ignore clipping by Assumption 2.3, we have E t+1 g t+1 = ?L H (? t+1 ). Using this above we obtain that</p><formula xml:id="formula_362">E t+1 ?? t+1 ? 2 =? 2 t ?? t ? 2 + (1 -? t ) 2 E t+1 g t+1 -?L H ? t+1 2 + ? 2 t ?L H (? t ) -?L H (? t+1 ) 2 + 2? 2 t ? t , ?L H (? t ) -?L H (? t+1 ) . Now, denote ? 2 DP := 2 1 -b m ? 2 b + d ? ? 2 DP .</formula><p>By assumptions 2.2 and 2.3, we can invoke Lemma D.5 which implies, together with the fact that g</p><formula xml:id="formula_363">(j) t+1 's for j ? H are independent, that E t+1 g t+1 -?L H ? t+1 2 ? ? 2 DP n-f . Thus, E t+1 ?? t+1 ? 2 ? ? 2 t ?? t ? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + ? 2 t ?L H (? t ) -?L H (? t+1 ) 2 + 2? 2 t ? t , ?L H (? t ) -?L H (? t+1 ) . By the Cauchy-Schwartz inequality, ? t , ?L H (? t ) -?L H (? t+1 ) ? ?? t ? ?L H (? t ) -?L H (? t+1 ) . Since L H is L-smooth, we have ?L H (? t ) -?L H (? t+1 ) ? L ? t+1 -? t . Recall from (50) that ? t+1 = ? t -? t R t . Thus, ?L H (? t ) -?L H (? t+1 ) ? ? t L ?R t ?.</formula><p>Using this above we obtain that</p><formula xml:id="formula_364">E t+1 ?? t+1 ? 2 ? ? 2 t ?? t ? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + ? 2 t ? 2 t L 2 ?R t ? 2 + 2? t ? 2 t L ?? t ? ?R t ? .</formula><p>As 2ab ? a 2 + b 2 , from above we obtain that</p><formula xml:id="formula_365">E t+1 ?? t+1 ? 2 ? ? 2 t ?? t ? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + ? 2 t ? 2 t L 2 ?R t ? 2 + ? t L? 2 t ?? t ? 2 + ?R t ? 2 = (1 + ? t L)? 2 t ?? t ? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + ? t L(1 + ? t L)? 2 t ?R t ? 2 . (<label>99</label></formula><formula xml:id="formula_366">)</formula><p>By definition of ? t in (53), we have R t = ? t + m t . Thus, owing to the triangle inequality and the fact that 2ab</p><formula xml:id="formula_367">? a 2 + b 2 , we have ?R t ? 2 ? 2 ?? t ? 2 + 2 ?m t ? 2 . Similarly, by definition of ? t in (52), we have ?m t ? 2 ? 2 ?? t ? 2 + 2 ??L H (? t )? 2 . Thus, ?R t ? 2 ? 2 ?? t ? 2 + 4 ?? t ? 2 + 4 ??L H (? t )? 2 .</formula><p>Using this in (99) we obtain that This concludes the proof.</p><formula xml:id="formula_368">E t+1 ?? t+1 ? 2 ? (1 + ? t L)? 2 t ?? t ? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + 2? t L(1 + ? t L)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experimental Evaluation</head><p>In Section E.1, we present our experimental setup. In Section E.2, we report our empirical results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Experimental Setup</head><p>In our experiments, we test the performance of SAFE-DSHB using SMEA and Filter <ref type="bibr" target="#b20">(Diakonikolas et al., 2017;</ref><ref type="bibr" target="#b18">Data &amp; Diggavi, 2021)</ref> in the server-based architecture and in three privacy regimes.</p><p>Dataset, model architecture, and hyperparameters. We train a logistic regression model of d = 69 parameters on the academic Phishing<ref type="foot" target="#foot_5">5</ref> dataset. We employ the binary cross entropy (bce) loss as well as L2-regularization of parameter ? = 10 -4 , making the underlying learning problem strongly convex. We train the model using a fixed learning rate ? = 1 over a total of T = 400 learning steps. We set the clipping threshold C = 1 and the batch size b = 25. We run all algorithms, except DSGD, with momentum ? = 0.99.</p><p>Distributed setup, and privacy accounting. We consider a server-based architecture composed of n = 7 workers, among which f = 3 are adversarial. The honest workers inject a privacy noise ? DP = 2C b ? ? NM to their gradients, where ? NM is referred to as the noise multiplier. We consider three privacy regimes in our experiments; namely low privacy where ? NM = 1, moderate privacy where ? NM = 2, and high privacy where ? NM = 3. In order to estimate the privacy budgets achieved at the end of the learning, we use Opacus <ref type="bibr" target="#b77">(Yousefpour et al., 2021)</ref>, a DP library for deep learning in PyTorch <ref type="bibr">(Paszke et al., 2019)</ref>. Using Opacus, the aggregate privacy budgets after T = 400 steps of learning are (?, ?) = (1.14, 10 -4 ) in the low privacy regime, (?, ?) = (0.32, 10 -4 ) in the moderate privacy regime, and (?, ?) = (0.19, 10 -4 ) in the high privacy regime.</p><p>Evaluation details and reproducibility. As a benchmark, we compare the performance of SAFE-DSHB against the DP-DSGD algorithm, i.e., the private version of the adversary-free DSGD. We test SAFE-DSHB using SMEA and Filter. These algorithms are obtained by running Algorithm 1 while replacing the aggregation method F with the robust algorithm in question, namely SMEA and Filter. Note that we run Filter with spectral norm bound ? 2 0 = 0 (see Section B.2) because it provides the best empirical results, and it cannot be set to its theoretical value since the values of data heterogeneity G 2 and stochastic gradient noise ? 2 are unknown. We run each experiment with five seeds from 1 to 5 for reproducibility. The code we use to launch the different experiments will be made available.</p><p>Adversarial attacks. In our experiments, the adversarial workers execute four state-of-the-art attacks from the robust distributed ML literature, namely A Little is Enough (ALIE) <ref type="bibr" target="#b8">(Baruch et al., 2019)</ref>, Fall of Empires (FOE) <ref type="bibr" target="#b75">(Xie et al., 2019)</ref>, Sign-flipping (SF) (Allen- <ref type="bibr" target="#b4">Zhu et al., 2020)</ref>, and Label-flipping (LF) (Allen- <ref type="bibr" target="#b4">Zhu et al., 2020)</ref>. The first three attacks rely on the same attack primitive that we explain below, while LF is executed differently. Let b t be the attack vector in step t and ? ? 0 a fixed real number. In every step t, the adversarial workers send to the server the gradient B t = g t + ? t b t , where g t is an estimation of the true gradient at step t. Experimentally, we set g t = 1</p><p>|H| i?H g (i)</p><p>t .</p><p>? ALIE: In this attack, b t = ? t , where ? t is coordinate-wise standard deviation of g t . In our experiments on ALIE, ? t is chosen through an extensive grid search. Essentially, in each step t, we choose the value that results in the worst adversarial vector, i.e, the vector for which the distance to g t is the largest.</p><p>? FOE: In this attack, b t = -g t . All adversarial workers thus send (1 -? t )g t in step t. Similar to ALIE, ? t for FoE is also estimated through grid searching.</p><p>? SF: In this attack, b t = -g t , and ? t = 2. All adversarial workers thus send B t = b t = -g t in step t.</p><p>? LF: Every adversarial worker computes its gradient on flipped labels. Since the labels l for Phishing are in {0, 1}, the adversarial workers flip the labels by computing l ? = 1 -l on the batch, where l ? is the flipped/modified label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. Experimental Results</head><p>We present our results in the low privacy regime in Figures <ref type="figure" target="#fig_7">2</ref> and<ref type="figure" target="#fig_8">3</ref>, in the mid privacy regime in Figures <ref type="figure" target="#fig_9">4</ref> and<ref type="figure" target="#fig_4">5</ref>, and finally in the high privacy regime in Figures <ref type="figure" target="#fig_11">6</ref> and<ref type="figure" target="#fig_12">7</ref>. We then comment on the results below.       </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>i (x i -?c )(x i -?c )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. (I): Subsampling + Gaussian mechanism, (II): Post-processing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>t</head><label></label><figDesc>when given a batch of b point S (i) t is upper bounded by ? = 2C b . Accordingly, invoking Lemma C.3, the Gaussian mechanism used in Line 6 of Algorithm 1 is (?, ?? 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>480, a 3 = 5760, and a 4 = 270.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>D. 5 .</head><label>5</label><figDesc>Proof of Supporting Lemmas Before proving Lemmas D.1 to D.3 in Sections D.5.2 to D.5.4 respectively, we first show some additional technical lemmas in Section D.5.1 below. D.5.1. TECHNICAL LEMMAS Lemma D.4. Let M ? R d?d be a random real symmetric matrix and g : R ? R an increasing function. It holds that E sup ?v??1 g(?v, M v?) ? 9 d ? sup ?v??1 E [g(2 ?v, M v?)] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Test accuracy on Phishing with f = 3 adversarial workers among n = 7 workers, with ? = 0.99. The adversarial workers execute the LF (row 1, left), SF (row 1, right), ALIE (row 2, left), and FOE (row 2, right) attacks. Privacy budget after T = 400 steps is (?, ?) = (1.14, 10 -4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Training loss on Phishing with f = 3 adversarial workers among n = 7 workers, with ? = 0.99. The adversarial workers execute the LF (row 1, left), SF (row 1, right), ALIE (row 2, left), and FOE (row 2, right) attacks. Privacy budget after T = 400 steps is (?, ?) = (1.14, 10 -4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Test accuracy on Phishing with f = 3 adversarial workers among n = 7 workers, with ? = 0.99. The adversarial workers execute the LF (row 1, left), SF (row 1, right), ALIE (row 2, left), and FOE (row 2, right) attacks. Privacy budget after T = 400 steps is (?, ?) = (0.32, 10 -4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 .</head><label>5</label><figDesc>Figure5. Training loss on Phishing with f = 3 adversarial workers among n = 7 workers, with ? = 0.99. The adversarial workers execute the LF (row 1, left), SF (row 1, right), ALIE (row 2, left), and FOE (row 2, right) attacks. Privacy budget after T = 400 steps is (?, ?) = (0.32, 10 -4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Test accuracy on Phishing with f = 3 adversarial workers among n = 7 workers, with ? = 0.99. The adversarial workers execute the LF (row 1, left), SF (row 1, right), ALIE (row 2, left), and FOE (row 2, right) attacks. Privacy budget after T = 400 steps is (?, ?) = (0.19, 10 -4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Training loss on Phishing with f = 3 adversarial workers among n = 7 workers, with ? = 0.99. The adversarial workers execute the LF (row 1, left), SF (row 1, right), ALIE (row 2, left), and FOE (row 2, right) attacks. Privacy budget after T = 400 steps is (?, ?) = (0.19, 10 -4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Zhu, L., Liu, Z., and Han, S. Deep leakage from gradients. In Wallach, H., Larochelle, H., Beygelzimer, A., d Alch?-Buc, F., Fox, E., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 32, pp. 14774-14784. Curran Associates, Inc., 2019.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Lemma D.2. Suppose that assumptions 2.2 and 2.3 hold and that L H is L-smooth. Consider Algorithm 1. For all t ? {0, . . . , T -1}, we have</figDesc><table><row><cell>D.5.3. PROOF OF LEMMA D.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>? 2 t ?? t ? 2 + 2 ?? t ? 2 + 2 ??L H (? t )? 2 .By rearranging the terms on the R.H.S., we getE t+1 ?? t+1 ?The proof concludes upon taking total expectation on both sides. D.5.4. PROOF OF LEMMA D.3 Lemma D.3. Assume that L H is L-smooth. Consider Algorithm 1. For any t ? [T ], we haveE L H (? t+1 ) -L H (? t ) ? -? t 2 (1 -4? t L) E ??L H (? t )? 2 + ? t (1 + 2? t L) E ?? t ? 2 + ? t (1 + ? t L) E ?? t ? 2 .Proof. Let t ? {0, . . . , T -1}. Assuming L H is L-smooth, we have (see<ref type="bibr" target="#b13">(Bottou et al., 2018)</ref>)L H (? t+1 ) -L H (? t ) ? ? t+1 -? t , ?L H (? t ) + L 2 ? t+1 -? t 2 .Substituting from (54), i.e., ? t+1 = ? t -? t m t -? t ? t , we obtain thatL H (? t+1 ) -L H (? t ) ? -? t ?m t , ?L H (? t )? -? t ?? t , ?L H (? t )? + ? 2 -? t ?m t -?L H (? t ) + ?L H (? t ), ?L H (? t )? -? t ?? t , ?L H (? t )? + ? 2By Definition (52), m t -?L H (? t ) = ? t . Thus, from above we obtainL H (? t+1 ) -L H (? t ) ? -? t ??L H (? t )? 2 -? t ?? t , ?L H (? t )? -? t ?? t , ?L H (? t )? + 1 2 ? 2 t L ? m t + ? t ? 2 . (100)Now, we consider the last three terms on the R.H.S. separately. Using Cauchy-Schwartz inequality, and the fact that 2ab ? 1 c a 2 + cb 2 for any c &gt; 0, we obtain that (by substituting c = 2)2 |?? t , ?L H (? t )?| ? 2 ?? t ? ??L H (? t )? ? ?L H (? t )?| ? 2 ?? t ? ??L H (? t )? ?Finally, using triangle inequality and the fact that 2ab ? a 2 + b 2 we have? m t + ? t ? 2 ? 2 ?m t ? 2 + 2 ?? t ? 2 = 2 m t -?L H (? t+1 ) + ?L H (? t ) H (? t+1 ) -L H (? t ) ? -? t ??L H (? t )? ??L H (? t )? 2 + 2 ?? t ? 2 .Upon rearranging the terms in the R.H.S., we obtain thatL H (? t+1 ) -L H (? t ) ? -? t 2 (1 -4? t L) ??L H (? t )? 2 + ? t (1 + 2? t L) ?? t ? 2 + ? t (1 + ? t L) ?? t ? 2 .</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t</cell><cell>L 2</cell><cell>? m t + ? t ?</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t</cell><cell>L 2</cell><cell>? m t + ? t ? 2 .</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2 1</cell><cell cols="3">?? t ? 2 +</cell><cell>1 2</cell><cell>??L H (? t )? 2 .</cell><cell>(101)</cell></row><row><cell>Similarly,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">2 |?? t , 2 1</cell><cell cols="3">?? t ? 2 +</cell><cell>1 2</cell><cell>??L H (? t )? 2 .</cell><cell>(102)</cell></row><row><cell></cell><cell></cell><cell>2 +</cell><cell>1 2</cell><cell>? t 2 ?? t ? 2 +</cell><cell>1 2</cell><cell cols="4">??L H (? t )? 2 +</cell><cell>1 2</cell><cell>? t 2 ?? t ? 2 +</cell><cell>1 2</cell><cell>??L H (? t )? 2</cell></row><row><cell>+</cell><cell>1 2</cell><cell cols="2">? 2 t L 4 ?? t ? 2 + 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p><p><p><p><p><p>2 ?? 2 t (1 + ? t L) (1 + 4? t L) ?? t ? 2 + 4? t L(1 + ? t L)? 2 t ??L H (? t )? 2 + (1 -? t ) 2 ? 2 DP (n -f ) + 2? t L(1 + ? t L)? 2 t ?? t ? 2 . 2 = 2 + 2 ?? t ? 2 ? 4 ?? t ? 2 + 4 ??L H (? t )? 2 + 2 ?? t ? 2 . [since m t -?L H (? t ) = ? t ]</p>(103)</p>Substituting from (</p>101</p>), (</p>102</p>) and (</p>103</p>) in (100) we obtain that L</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Sometimes called "Byzantine" in the parlance of distributed computing<ref type="bibr" target="#b44">(Lamport et al., 1982)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Safe Distributed Stochastic Heavy Ball method, inspired from the optimization literature<ref type="bibr" target="#b30">(Gadat et al., 2018)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Smallest Maximum Eigenvalue Averaging.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Notice that the loss function in<ref type="bibr" target="#b9">(Bassily et al., 2014)</ref> is not divided by the number of samples m.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J.,  Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019.Pauwels, E. Lecture notes: Statistics, optimization and algorithms in high dimension, 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>https://www.csie.ntu.edu.tw/ ?cjlin/libsvmtools/datasets/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>On the Privacy-Robustness-Utility Trilemma in Distributed Learning Low Privacy Regime (? NM = 1).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>On the Privacy-Robustness-Utility Trilemma in Distributed Learning High Privacy Regime (? NM = 3).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported in part by <rs type="funder">SNSF</rs> grants <rs type="grantNumber">200021 200477</rs> and <rs type="grantNumber">200021 182542</rs>, and an <rs type="grantName">EPFL-Ecocloud postdoctoral grant</rs>. The authors are thankful to the anonymous reviewers for their constructive comments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gVr3MbY">
					<idno type="grant-number">200021 200477</idno>
				</org>
				<org type="funding" xml:id="_nvhEHE9">
					<idno type="grant-number">200021 182542</idno>
					<orgName type="grant-name">EPFL-Ecocloud postdoctoral grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organization of the Appendix</head><p>Appendix A contains the proof of our lower bounds. Appendix B contains proofs of claims related to (f, ?)-robust averaging and SMEA. Appendix C contains the privacy analysis of SAFE-DSHB. Appendix D contains the convergence analysis of SAFE-DSHB. Appendix E contains the experimental setup and results of our empirical evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Lower Bounds</head><p>In Section A.1, we recall lower bounds on centralized private algorithms. We then extend these results to distributed private algorithms. We start by the lower bound due to privacy alone in Section A.2. Next, we show the lower bound due to robustness alone in Section A.3. We then show the lower bound due to the privacy-robustness tradeoff in Section A.4. Finally, we merge the previous results to show the final lower bound in Section A.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Lower Bounds in Centralized DP</head><p>We recall lower bounds <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref> on the error incurred by centralized differentially private mechanisms for estimating d-dimensional one-way marginals; i.e., the average of rows of a dataset. Recall that Steinke &amp; Ullman prove a sharper bound (by factor log (1/?)) than Bassily et al., whose work is based on lower bounds using fingerprinting codes <ref type="bibr" target="#b14">(Bun et al., 2014)</ref>. We recall below the main lower bound from <ref type="bibr" target="#b68">(Steinke &amp; Ullman, 2016)</ref>. 1) and that ? ? 2 -o(m) . Let D ? X m and D denote the average of records of D. For any ? ? 1/10 such that for every D ? X m , E M(D) -D 1 ? d?, we have:</p><p>Observe in Lemma A.1 that the lower bound assumption ? ? 1/m 1+?(1) is slightly more restrictive than the folklore assumption ? = o(1/m) <ref type="bibr" target="#b24">(Dwork et al., 2014)</ref>. The latter ensures that (?, ?)-DP precludes some intuitively non-private algorithms, e.g., when ? ? 1/m, the algorithm that returns ?m?? random elements of the dataset is (0, ?)-DP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Case I: Non-adversarial Setting</head><p>We prove below our lower bound due to privacy, stated in Proposition 3.1.</p><p>Proposition 3.1. Let n, m ? 1, and ?, ? ? (0, 1).</p><p>We consider an arbitrary distributed algorithm A : X m?n ? R d that satisfies (?, ?)-distributed DP (see Definition 2.3), and (0, ?)-robustness (see Definition 2.1). We assume that ? ? 1/4 2n ln (m + 1) and that 2 -m 1-? ? n? ? 1/8m 1+? for some ? ? (0, 1).</p><p>Proof outline. We consider the centralized algorithm M which takes as input dataset D ? X m and executes A(D 1 , . . . , D n ) on n copies of D, i.e., D 1 = . . . = D n = D. Then, we derive the DP guarantee and utility of M using the facts that A satisfies (?, ?)-distributed DP (see Definition 2.3) and (0, ?)-robustness, respectively. Finally, we apply the centralized DP lower bound on M (stated in Lemma A.1) to conclude the proof.</p><p>Privacy guarantee of M. We first analyze the DP guarantees of M inherited from A.</p><p>Recall from Definition 2.3 that, since A is (?, ?)-DP, it can communicate with each database D i subject to (?, ?)-DP. Thus, when running M, in the worst case, algorithm A may adaptively query the same database D a total of n times, subject to (?, ?)-DP budget for each query. Therefore, M is (? n , ? n )-DP where (? n , ? n ) is the privacy guarantee resulting from</p><p>Proof. The proof follows directly from (Theorem 4.2, <ref type="bibr" target="#b79">(Zhu et al., 2022)</ref>) combined with (Lemma 2.2, <ref type="bibr" target="#b79">(Zhu et al., 2022)</ref>).</p><p>Discussion. Note that Filter does not satisfy (f, ?)-robust averaging (see Definition 4.1) as its parameter ? 2 0 must depend on the maximum eigenvalue of the honest inputs. Indeed, such dependency is precluded by (f, ?)-robust averaging. Moreover, in our learning setting, the bound ? 2 0 potentially depends on the noise of stochastic gradients ? 2 and the heterogeneity metric G 2 , which are unknown a priori. Thus, devising aggregation rules agnostic to the statistical properties of the honest inputs, like SMEA, is even more desirable in our setting.</p><p>Observe now that, as t = t + a 1 L ? ? a 1 = 240 (because L ? ?), we have ( t + 1) 2 ? (1 + 1 240 ) 2 t2 ? 2 t2 . Plugging this bound in the inequality above gives</p><p>Therefore, we have for every t ? {0, . . . , T -1} that</p><p>However, recalling the definition (57) of V t , we obtain</p><p>By rearranging terms, and using the fact that L ? ? 1, we then get</p><p>It remains to bound V 0 . By definition, we have</p><p>and the initializations m</p><p>0 -m 0 ) ? = 0. Therefore, we have</p><p>Moreover, by definition of ? t in (52), we obtain that</p><p>Recall that L H is L-smooth. Thus, ??L H (? 0 )? 2 ? 2L(L H (? 0 ) -L * ) (see <ref type="bibr" target="#b55">(Nesterov et al., 2018)</ref>, Theorem 2.1.5).</p><p>Therefore, substituting z 1 = 1 16 , we have</p><p>Discussion. We consider four different attacks executed by the adversarial nodes, and report on the performance of the algorithms in three different privacy regimes. Our observations are twofold.</p><p>First, as expected, we see that as the privacy regime becomes more demanding, the performances of DP-DSGD and SMEA degrade both in terms of test accuracy and training loss. This confirms that the standard privacy-utility trade-off also occurs in the presence of adversarial workers. Second, we see that under all three privacy regimes, SAFE-DSHB with SMEA is able to successfully mitigate adversarial attacks while still ensuring strong levels of differential privacy. Indeed, the final accuracies reached by SAFE-DSHB with SMEA are around 80% in the low and moderate privacy regimes, and around 75% in high privacy (a bit lower under the FOE attack). On the other hand, the training losses are decreasing under all attacks and in all privacy regimes, sometimes asymptotically matching the curves of DP-DSGD (e.g., the LF attack in all three privacy regimes, the ALIE attack in low and moderate privacy). The same observations hold for SAFE-DSHB with Filter.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2016 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust testing and estimation under manipulation attacks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="43" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Information-theoretic lower bounds on the oracle complexity of convex optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">cpsgd: Communication-efficient and differentially-private distributed sgd</title>
		<author>
			<persName><forename type="first">N</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Byzantine-resilient non-convex stochastic gradient descent</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ebrahimianghazani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alistarh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fixing by mixing: A recipe for optimal byzantine ml under heterogeneity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Allouah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farhadkhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1232" to="1300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gonz?lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Menart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ullah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.00846</idno>
		<title level="m">Faster rates of convergence to stationary points in differentially private optimization</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Private and polynomial time algorithms for learning gaussians and beyond</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ashtiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liaw</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1075" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A little is enough: Circumventing defenses for distributed learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baruch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baruch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-14">2019, 8-14 December 2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Private empirical risk minimization: Efficient algorithms and tight error bounds</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 55th annual symposium on foundations of computer science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="464" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parallel and distributed computation: numerical methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Machine learning with adversaries: Byzantine tolerant gradient descent</title>
		<author>
			<persName><forename type="first">P</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>El Mhamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stainer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="119" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Practical secure aggregation for federated learning on user-held data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kreuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marcedone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04482</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimization methods for large-scale machine learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Curtis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Siam Review</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="311" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fingerprinting codes and the price of approximate differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the forty-sixth annual ACM symposium on Theory of computing</title>
		<meeting>the forty-sixth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Manipulation attacks in local differential privacy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cheu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="883" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust estimation of discrete distributions under local differential privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chhor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sentenac</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Algorithmic Learning Theory</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="411" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gkoulalas-Divanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sylla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.02578</idno>
		<title level="m">Differential privacyenabled federated learning for sensitive health data</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Byzantine-resilient highdimensional sgd with local iterations on heterogeneous data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Data</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Diggavi</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v139/data21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07">Jul 2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Large scale distributed deep networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Being robust (in high dimensions) can be practical</title>
		<author>
			<persName><forename type="first">I</forename><surname>Diakonikolas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Kane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="999" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust estimators in high-dimensions without the computational intractability</title>
		<author>
			<persName><forename type="first">I</forename><surname>Diakonikolas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="742" to="864" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Local privacy and statistical minimax rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 54th Annual Symposium on Foundations of Computer Science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Differential privacy and robust statistics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<idno type="DOI">10.1145/1536414.1536466</idno>
		<ptr target="https://doi.org/10.1145/1536414.1536466" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Forty-First Annual ACM Symposium on Theory of Computing, STOC &apos;09</title>
		<meeting>the Forty-First Annual ACM Symposium on Theory of Computing, STOC &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="371" to="380" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery. ISBN 9781605585062</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The algorithmic foundations of differential privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The hidden vulnerability of distributed learning in Byzantium</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>El Mhamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rouault</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v80/mhamdi18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<title level="s">Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</editor>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07">Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">on the protection of natural persons with regard to the processing of personal data and on the free movement of such data</title>
		<imprint>
			<date type="published" when="2016-04-27">2016/679 of 27 april 2016. 2016</date>
			<publisher>European Parliament and European Council</publisher>
		</imprint>
		<respStmt>
			<orgName>EU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Regulation (eu</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Byzantine machine learning made easy by resilient averaging of momentums</title>
		<author>
			<persName><forename type="first">S</forename><surname>Farhadkhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v162/farhadkhani22a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sabato</surname></persName>
		</editor>
		<meeting>the 39th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2022-07">Jul 2022</date>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Distributed robust learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Model inversion attacks that exploit confidence information and basic countermeasures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<idno type="DOI">10.1145/2810103.2813677</idno>
		<ptr target="https://doi.org/10.1145/2810103.2813677" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;15</title>
		<meeting>the 22nd ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1322" to="1333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Stochastic heavy ball</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gadat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Panloup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saadane</surname></persName>
		</author>
		<idno type="DOI">10.1214/18-EJS1395</idno>
		<ptr target="https://doi.org/10.1214/18-EJS1395" />
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="461" to="529" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Privacy induces robustness: Information-computation gaps and sparse mean estimation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hopkins</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=g-OkeNXPy-X" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Differential privacy and Byzantine resilience in sgd: Do they add up?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guerraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rouault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1145/3465084.3467919</idno>
		<ptr target="https://doi.org/10.1145/3465084.3467919" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Symposium on Principles of Distributed Computing, PODC&apos;21</title>
		<meeting>the 2021 ACM Symposium on Principles of Distributed Computing, PODC&apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="391" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fault-tolerance in distributed optimization: The case of redundancy</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Vaidya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Symposium on Principles of Distributed Computing</title>
		<meeting>the 39th Symposium on Principles of Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="365" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Byzantine fault-tolerant distributed machine learning with norm-based comparative gradient elimination</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vaidya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 51st Annual IEEE/I-FIP International Conference on Dependable Systems and Networks Workshops (DSN-W)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="175" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep models under the gan: Information leakage from collaborative deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hitaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ateniese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perez-Cruz</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133956.3134012</idno>
		<ptr target="https://doi.org/10.1145/3133956.3134012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;17</title>
		<meeting>the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="603" to="618" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficient mean estimation with pure differential privacy via a sum-ofsquares exponential mechanism</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Majid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing</title>
		<meeting>the 54th Annual ACM SIGACT Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1406" to="1417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Majid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.05015</idno>
		<title level="m">Robustness implies privacy in statistical estimation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Personalized federated learning with differential privacy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="9530" to="9539" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Linear convergence of gradient and proximal-gradient methods under the polyak-?ojasiewicz condition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nutini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European conference on machine learning and knowledge discovery in databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="795" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Scaffold: Stochastic controlled averaging for federated learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5132" to="5143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning from history for Byzantine robust optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference On Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">139</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Byzantine-robust learning on heterogeneous datasets via bucketing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=jXKKDEi5vJt" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">What can we learn privately?</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Kasiviswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raskhodnikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="793" to="826" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Byzantine generals problem</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shostak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pease</surname></persName>
		</author>
		<idno type="DOI">10.1145/357172.357176</idno>
		<ptr target="https://doi.org/10.1145/357172.357176" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<idno type="ISSN">0164-0925</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="382" to="401" />
			<date type="published" when="1982-07">jul 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1544" to="1551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Berrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.00751</idno>
		<title level="m">On robustness and local differential privacy</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Approximate Byzantine fault-tolerance in distributed optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Vaidya</surname></persName>
		</author>
		<idno type="DOI">10.1145/3465084.3467902</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Symposium on Principles of Distributed Computing, PODC&apos;21</title>
		<meeting>the 2021 ACM Symposium on Principles of Distributed Computing, PODC&apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery. ISBN 9781450385480</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Robust and differentially private mean estimation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3887" to="3901" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Differential privacy and robust statistics in high dimensions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1167" to="1246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Private federated learning without a trusted server: Optimal algorithms for convex losses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lowy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=TVY6GoURrw" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Private non-convex federated learning without a trusted server</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lowy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghafelebashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5749" to="5786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Differentially private Byzantine-robust federated learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Exploiting unintended feature leakage in collaborative learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Cristofaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2019.00029</idno>
		<ptr target="https://doi.org/10.1109/SP.2019.00029" />
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Symposium on Security and Privacy</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-05-19">2019. May 19-23, 2019. 2019</date>
			<biblScope unit="page" from="691" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">R?nyi differential privacy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 30th computer security foundations symposium (CSF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Lectures on convex optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">137</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Differentially private federated learning on heterogeneous data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Noble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dieuleveut</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10110" to="10145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Privacy-preserving deep learning: Revisited and enhanced</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Phong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Aono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moriai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications and Techniques in Information Security</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Batten</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="100" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Some methods of speeding up the convergence of iteration methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Polyak</surname></persName>
		</author>
		<idno type="DOI">10.1016/0041-5553(64)90137-5</idno>
		<ptr target="https://doi.org/10.1016/0041-5553(64)90137-5" />
	</analytic>
	<monogr>
		<title level="s">USSR Computational Mathematics and Mathematical Physics</title>
		<idno type="ISSN">0041-5553</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Mathematical statistics and data analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rice</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Cengage Learning</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">High dimensional statistics. Lecture notes for course 18S997</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rigollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>H?tter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">813</biblScope>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multivariate estimation with high breakdown point</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical statistics and applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page" from="283" to="297" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Minimizing finite sums with the stochastic average gradient</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Le Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="112" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sheller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Reina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kotrotsou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Milchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Colen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Membership inference attacks against machine learning models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno>CoRR, abs/1610.05820</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Is interaction necessary for distributed private learning?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Upadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="58" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Robust learning: Information theory and algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Resilience: A criterion for learning in the presence of arbitrary outliers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Innovations in Theoretical Computer Science Conference (ITCS 2018)</title>
		<imprint>
			<publisher>Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Between pure and approximate differential privacy</title>
		<author>
			<persName><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Privacy and Confidentiality</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Fault-tolerant multi-agent optimization: optimal iterative distributed algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Vaidya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM symposium on principles of distributed computing</title>
		<meeting>the 2016 ACM symposium on principles of distributed computing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="425" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Vershynin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1011.3027</idno>
		<title level="m">Introduction to the non-asymptotic analysis of random matrices</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Subsampled r?nyi differential privacy and analytical moments accountant</title>
		<author>
			<persName><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Kasiviswanathan</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1226" to="1235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Beyond inferring class representatives: User-level privacy leakage from federated learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mengkai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2019.8737416</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">04</biblScope>
			<biblScope unit="page" from="2512" to="2520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">?-stochastic sign sgd: A Byzantine resilient and differentially private gradient compressor for federated learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.00665</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Generalized Byzantinetolerant sgd</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Koyejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gupta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Fall of empires: Breaking Byzantine-tolerant SGD by inner product manipulation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Koyejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI 2019</title>
		<meeting>the Thirty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI 2019<address><addrLine>Tel Aviv, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">July 22-25, 2019. 2019</date>
			<biblScope unit="page">83</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Byzantinerobust distributed learning: Towards optimal statistical rates</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5650" to="5659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Yousefpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Testuggine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bharadwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2109.12298" />
		<title level="m">Opacus: Userfriendly differential privacy library in pytorch</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Mopuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName><surname>Idlg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.02610</idno>
		<title level="m">Improved deep leakage from gradients</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Robust estimation via generalized quasi-gradients. Information and Inference: A</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the IMA</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="581" to="636" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Bridging differential privacy and Byzantine-robustness via model aggregation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2022/337</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2022/337.MainTrack" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Raedt</surname></persName>
		</editor>
		<meeting>the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</meeting>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
