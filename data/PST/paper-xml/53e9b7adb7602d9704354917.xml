<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast CU Size Decision and Mode Decision Algorithm for HEVC Intra Coding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Liquan</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Laboratory of Advanced Display and System Application</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="institution">Shanghai University</orgName>
								<address>
									<postCode>200072</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Communication and Information Engineering</orgName>
								<orgName type="institution">Shanghai University</orgName>
								<address>
									<postCode>200072</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaoyang</forename><surname>Zhang</surname></persName>
							<email>zhyzhang@shu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Laboratory of Advanced Display and System Application</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="institution">Shanghai University</orgName>
								<address>
									<postCode>200072</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ping</forename><surname>An</surname></persName>
							<email>anping@shu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Laboratory of Advanced Display and System Application</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="institution">Shanghai University</orgName>
								<address>
									<postCode>200072</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast CU Size Decision and Mode Decision Algorithm for HEVC Intra Coding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B6DD0910E5CCE5BA3E0268D028080826</idno>
					<note type="submission">Contributed Paper Manuscript received 12/16/12 Current version published 03/25/13 Electronic version published 03/25/13.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>HEVC</term>
					<term>mode decision</term>
					<term>intra prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The emerging international standard of High Efficiency Video Coding (HEVC) is a successor to H.264/AVC. In the joint model of HEVC, the tree structured coding unit (CU) is adopted, which allows recursive splitting into four equally sized blocks. At each depth level, it enables up to 34 intra prediction modes. The intra mode decision process in HEVC is performed using all the possible depth levels and prediction modes to find the one with the least rate distortion (RD) cost using Lagrange multiplier. This achieves the highest coding efficiency but requires a very high computational complexity. In this paper, we propose a fast CU size decision and mode decision algorithm for HEVC intra coding. Since the optimal CU depth level is highly content-dependent, it is not efficient to use a fixed CU depth range for a whole image. Therefore, we can skip some specific depth levels rarely used in spatially nearby CUs. Meanwhile, there are RD cost and prediction mode correlations among different depth levels or spatially nearby CUs. By fully exploiting these correlations, we can skip some prediction modes which are rarely used in the parent CUs in the upper depth levels or spatially nearby CUs. Experimental results demonstrate that the proposed algorithm can save 21% computational complexity on average with negligible loss of coding efficiency 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In recent years, digital video has become the dominant form of media content in many consumer applications. Video coding is one of the enabling technologies for the delivery of digital video. Motivated by potential for improving coding efficiency for high resolution videos, ISO/IEC Moving Picture Experts Group (MPEG) and ITU-T Video Coding Experts Group (VCEG) recently form a Joint Collaborative Team on Video Coding (JCT-VC) to develop the next-generation video coding standard <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. The new standardization project referred to as High Efficiency Video Coding (HEVC) aims to substantially improve coding efficiency compared to H.264/AVC, to reduce bitrate requirements by half with comparable image quality, at the expense of increased computational complexity. The tree structured coding unit (CU) is adopted in HEVC, and this kind of structure completely breaks the normal procedure of 16×16 macroblock (MB) coding architecture in H.264/AVC <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. In current test model of HEVC (HM) <ref type="bibr" target="#b4">[5]</ref>, pictures are divided into slices and slices are divided into a sequence of treeblocks. A treeblock is an N×N (64×64) block of luma samples together with two corresponding blocks of chroma samples, whose concept is broadly analogous to that of the MB in previous standards such as H.264/AVC. CUs are the basic unit of region splitting used for inter/intra prediction. The CU concept allows recursive splitting into four equally sized blocks. This process gives a content-adaptive coding tree structure comprised of CU blocks that may be as large as a treeblock or as small as 8×8 pixels. The Prediction Unit (PU) is the basic unit used for carrying the information related to the prediction processes. For intra prediction, two PU sizes are supported at each depth level, which are 2N×2N and N×N. PUs are coded in alphabetical order following the depth-first rule. In current HM, 5 types of PUs are supported for intra coding, which are 64×64, 32×32, 16×16, 8×8, and 4×4. Expect for the increased number of prediction blocks, the number of prediction modes for each CU also increases. Intra prediction supports up to 34 directions to select the best direction. For example, the mode number for 64×64, 32×32, 16×16, 8×8 and 4×4 PUs has been raised to 34, 34, 34, 34 and 17, respectively. In this way, the total computation burden is dramatically increased compared with that of H.264/AVC. Fig. <ref type="figure">1</ref> shows the architecture of tree structured CUs and the prediction direction of each PU. Part (a) of Fig. <ref type="figure">1</ref> shows the CU splitting procedure (from 64×64 to 8×8), and (b) is the PU size and the prediction direction. For current CU in depth level (X), the procedure of part (a) of Fig. <ref type="figure">1</ref> will be followed, and current CU will be split into the next depth level (X+1) when the split flag enables. The CU is divided into 4 sub-CUs. The procedure of part (a) of Fig. <ref type="figure">1</ref> will also be conducted for each sub-CU. In determining the best depth level, HM tests every possible depth level in order to estimate the coding performance of each CU defined by the CU size. Similar to H.264/AVC, the intra mode decision process in HEVC is performed using all the possible depth levels (CU sizes) and intra modes to find the one with the least rate distortion (RD) cost using Lagrange multiplier. <ref type="bibr">RD</ref>  where mod e B specifies bit cost to be considered for mode decision, which depends on each decision case. SSE is the average difference between current CU and the matching blocks, MODE  is the Lagrange multiplier. These depth level decision and intra prediction mode decision cause major computational complexity within the encoding process, which should be overcome for the implementation of a fast encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1 Illustration of recursive CU structure and intra prediction directions at each depth level</head><p>Recently, a number of fast algorithms <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b12">[13]</ref> have been proposed to reduce the mode decision complexity for the HEVC encoder achieving significant time saving with little loss of coding efficiency. A pre-decision using hadamard cost <ref type="bibr" target="#b6">[7]</ref> is introduced to determine the first N best candidate intra modes. Instead of the total intra prediction mode decision, the RD optimization is only applied to the N best candidate modes selected by the rough mode decision where all modes are compared in this decision. However, the intra mode correlation among spatially nearby CUs has not been explored in the mode decision process. Since the local image texture which has a consistent orientation may cover several nearby CUs, the mode information of the neighboring CUs can be used to accelerate the procedure of intra mode decision. To further relieve the computation load of the encoder, Zhao et al. <ref type="bibr" target="#b7">[8]</ref> utilize the direction information of the spatially adjacent CUs to speed up intra mode decision. Meanwhile, the intra mode of corresponding previous-depth PU and the block size of current-depth transform units <ref type="bibr" target="#b8">[9]</ref> are utilized to early terminate the procedure of intra mode decision. Fast HEVC intra mode decision algorithms <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> respectively use edge information of the current PU and the gradient-mode histogram to choose a reduced set of candidate prediction directions. The calculation of gradient information or texture complexity requires huge time. A low-complexity cost model <ref type="bibr" target="#b11">[12]</ref> is employed to implement the level filtering process for different CU sizes, which reduces the number of PU levels requiring fine processing from five to two. PU size information of encoded neighboring blocks <ref type="bibr" target="#b12">[13]</ref> is utilized to skip small prediction unit candidates for current block. The aforementioned methods are well developed for HEVC achieving significant time savings. However, coding information correlations among different depth levels are not fully studied. With similar video characteristic, the prediction mode of a CU at the depth level X is strongly related to that of its parent CU at the depth level X-1. Prediction mode information of parent CUs can be used to reduce candidates for intra mode decision. To overcome these problems, this paper proposes a fast CU size and intra mode decision algorithm for HEVC. Considering that the optimal CU depth level is highly content-dependent, it is not efficient to use a fixed CU depth range for the whole sequence. Therefore, we can skip some specific depth levels rarely used in nearby CUs. Meanwhile, there are RD cost and prediction mode correlations among different depth levels or spatially nearby CUs. By fully exploiting these correlations, we can skip some modes which are rarely used in parent CUs in the upper depth levels or spatially nearby CUs.</p><p>The rest of the paper is organized as follows. In Section II, we analyze the coding information correlation among CUs from different depth levels or spatially nearby CUs, and propose a fast CU size decision and intra mode decision algorithm. Section III compares performances of the proposed algorithm with the state-of-the-art fast algorithms. Section IV concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED FAST INTRA PREDICTION ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Fast CU size decision algorithm</head><p>HM usually allows the maximum CU size equal to 64, and the depth level range is from 0 to 3. CU depth has a fixed range for a whole video sequence in HM. In fact, small depth values tend to be chosen for CUs in the homogeneous region, and large depth values are chosen for CUs with rich textures. We can see from experiments of intra coding that the depth value of "0" occurs very frequently for large homogeneous region coding. On the other hand, the depth value of "0" is rarely chosen for treeblocks with rich textures. These results show that CU depth range should be adaptively determined based on the property of treeblocks. In natural pictures, nearby treeblocks usually hold similar textures. Consequently, the optimal depth level of current treeblock may have a strong correlation with its neighboring treeblocks.</p><p>Based on this concept, the depth level of current treeblock ( pre Depth ) can be predicted using spatially nearby treeblocks (shown in Fig. <ref type="figure" target="#fig_1">2</ref>) as follows,</p><formula xml:id="formula_0">1 0 N i i i w       pre Depth (<label>2</label></formula><formula xml:id="formula_1">)</formula><p>where N is the number of treeblocks equal to 4, i  is the treeblock-weight factor in Table <ref type="table" target="#tab_1">I</ref> defined according to correlations between the current treeblock and its neighboring treeblocks. i w is the value of depth level. Since coding information of the Left-below treeblock can not be obtained before coding current block, only Left treeblock, Up treeblock, Left-up treeblock and Right-up treeblock are chosen in Fig. <ref type="figure" target="#fig_1">2</ref>.  </p><formula xml:id="formula_2">                          (3)</formula><p>Extensive simulations have been conducted on 6 video sequences with different resolutions to analyze the depth level distribution for these four types of treeblocks. Among these test sequences, "Horseriding" and "Basketball" are in "720×576" format, "ShipCalendar" and "StockholmPan," are in "1280×720" format, while "Flamingo" and "Fireworks" are in "1920×1088" format. The test conditions are as follows: Quantization Parameter (QP) is chosen with 24, 30 and 36; RD optimization (RDO) and context-adaptive binary arithmetic coding (CABAC) entropy coding are enabled; Treeblock Size =64; Number of coded frames=50. By exploiting the exhaustive intra mode decision in HM under the aforementioned test conditions, we investigate the depth level distribution for these four types of treeblocks. Table <ref type="table" target="#tab_1">II</ref> shows the depth level distribution for each type of treeblocks, where "I", "II", "III" and "IV" are the types of treeblocks and "0", "1", "2" and "3" are the depth levels. It can be seen that for the type of "I" treeblocks, about 35% of total treeblocks choose the optimal depth level with "0", and about 54% treeblocks choose the optimal depth value with "1". In other words, if the maximum depth level is set to be "1", it will most likely cover about 89% treeblocks. For the type of "II" treeblocks, about 92% of treeblocks choose depth levels with "0", "1" and "2". If the maximum depth level is set to be "2", it will most likely cover about 92% of treeblocks. On the other side, for the type of "III" treeblocks, the probability of choosing the depth level with "0" is very low, less than 3%, and thus intra prediction on depth level of "0" (CU size 64×64) can be skipped. For the type of "IV" treeblocks, the probability of choosing the depth levels of "2" and "3" are more than 88% , and thus intra prediction on depth levels of "0" and "1" ( CU sizes 64×64 and 32×32) can be skipped. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Fast intra mode decision algorithm</head><p>In our proposed fast intra mode decision algorithm, we use the combination of the rough mode decision (RMD) and RDO process to select the best intra direction. HM determines the first N best candidate modes based on the RMD process where all modes are tested by minimum absolute sum of hadamard transformed coefficients of residual signal and the mode bits. Instead of the total intra prediction modes decision, the RDO is only applied to the N best candidate modes selected by the rough mode decision where all modes are compared in this decision. The number of N best modes in RMD for RDO process is shown in Table <ref type="table" target="#tab_2">III</ref>. However, computation load of the encoder is still very high. On the other side, the intra prediction modes are always correlated among the nearby CUs, which are not considered in HM. There are two differences between the intra mode decision in HM encoder and the proposed method. First, we utilize the prediction direction correlation among nearby CUs to early terminate the RDO process; second, the RD cost correlation is utilized to reduce some directions with a low probability used for RDO process. By making use of intra prediction information from nearby CUs (including spatial neighboring CUs and the parent CU in upper depth level), we reduce the number of directions taking part in RDO process. This proposed method results in significant reduction of the encoder complexity. Detailed algorithm is described as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy 1: Early termination (ET) based on the modecorrelation</head><p>Based on lots of experiments, we first observe that the candidates selected from rough mode decision render a descending trend to be the RDO-optimal mode according to their rank in candidates. Meanwhile, neighboring blocks usually hold similar textures in natural pictures. Consequently, the optimal intra prediction of current CU may have strong correlation with its neighboring CUs. There also exits the intra prediction mode correlation among different depth levels from the view of the inter-level correlation. With similar video characteristic, the prediction mode of current CU at the depth level X is strongly related to that of its parent CU at the depth level X-1. By exploiting the exhaustive CU size decision in HM under the aforementioned test conditions in Section II-A, we respectively estimate the conditional probabilities of the optimal intra direction of current CU to be the first candidate of RMD, the optimal mode of the parent CU at the previous depth level or most probable mode (MPM) from spatially nearby CUs. The MPM from spatially nearby CUs is obtained by the Left, Up, Left-up, and Right-up CUs. Table <ref type="table" target="#tab_3">IV</ref> shows conditional probabilities of the optimal intra direction for current CU. It can see that there are 58.6%, 22.5% and 33.6% of CUs selecting the optimal prediction mode with the first candidate of RMD, the optimal mode of the parent CU and MPM from spatially nearby CUs, respectively. From our statistic results, we find that the first candidate of RMD, the optimal mode of the parent CU and MPM from spatially nearby CUs possess a large ratio to be the best mode in current CU and these ratios fluctuate only a little between different sequences. When the first candidate of RMD, the optimal mode of the parent CU at the previous depth level and MPM from spatially nearby CUs are with the same intra prediction mode, it indicates that the current CU and its nearby CUs have a consistent orientation. Consequently, the optimal intra mode of current CU may have a high probability to be the optimal mode from its nearby CUs. We can skip test of other intra modes, and coding time can be reduced dramatically. The determination of the optimal mode is empirically obtained, and the anticipation here is verified in our experimental results later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy 2: ET based on the RD cost correlation</head><p>It can be seen from Table <ref type="table" target="#tab_3">IV</ref> that the majority of best prediction modes after intra mode decision come from the first candidate of RMD, the optimal mode of the parent CU at the previous depth level or MPM from spatially nearby CUs. Thus, it is better to have a proper ET strategy from the midway of the fast intra mode decision algorithm for HEVC.</p><p>We analyze the optimal modes from spatially nearby CUs and the candidates selected in rough mode selection. Fig. <ref type="figure">3</ref> illustrates the percentage of candidate of RMD or the optimal modes from nearby CUs to be the optimal prediction mode for current CU in high efficiency test conditions. From our statistic results, we find that the first candidate from RMD possesses the largest ratio to be the best mode of current CU, which is larger than 55%. The ratio of the second candidate from RMD is about 15%. The MPM from spatially nearby CUs and the optimal mode of the parent CU at the previous depth level also present a large ratio to be the RDO-optimal mode on average, respectively reaching 34% and 23%. In our proposed algorithm, we first check whether MPM from spatially nearby CUs and the optimal mode from the parent CU are included in the candidates from RMD. If these two optimal modes are not included in candidate set, 2 N  modes comprised of N best modes from RMD and these two candidates will be employed in RDO process. Otherwise, only N best modes will be employed in RDO process. Then, we rank candidate modes according to a descending trend to be the RDO-optimal mode based on the distribution in Fig. <ref type="figure">3</ref>.</p><formula xml:id="formula_3">0% 10% 20% 30% 40% 50% 60% M_Par MPM c0 c1 c2 c3 c4 c5 c6 c7</formula><p>Probability to be selected as the optimal prediction mode M_Par: the prediction mode from the parent CU in upper depth level; MPM : most probable mode from spatially nearby CUs; c i (i: 0~7) : the i th candidate form RMD</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3 probability to be selected as the optimal prediction mode</head><p>A threshold based on neighboring RD costs, is used to achieve ET for different modes, which makes it content dependent. The threshold ( Tr ) is set to the average of the RD costs of nearby CUs as shown in ( <ref type="formula">4</ref> To verify legitimacy of the proposed two ET methods, extensive simulations have been conducted on a set of video sequences as listed in Table <ref type="table" target="#tab_5">V</ref>. By exploiting the exhaustive CU size decision in HM under the aforementioned test conditions in Section II-A, we investigate the effectiveness of the proposed ET methods. Table <ref type="table" target="#tab_5">V</ref> shows the accuracies of the proposed ET methods. The average accuracy of the proposed ET based on the mode correlation is larger than 80%. The average accuracy of the proposed ET based on the RD cost correlation method achieves 91% with a maximum of 95% in "StockholmPan" and a minimum of 86% in "Basketball". The accuracies of the proposed ET methods are consistent for all test sequences with different properties. The results shown in Table <ref type="table" target="#tab_5">V</ref> indicate that the proposed ET methods can accurately reduce unnecessary intra prediction modes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Overall algorithm</head><p>Based on the aforementioned analysis, including the approaches of fast CU size decision and intra mode decision, we propose a fast intra prediction algorithm for HEVC as follows.</p><p>Step 1: Start intra prediction for a treeblock.</p><p>Step 2: Derive the depth level information of spatially nearby treeblocks including Left, Up, Left-up and Right-up treeblocks.</p><p>Step 3: Compute pre Depth based on (2) and classifies current treeblock into one of four types: "I", "II", "III" and "IV". If current treeblock belongs to type "I", the maximum depth level is reset with "1"; else if current treeblock belongs to type "II", the maximum depth level is reset with "2"; else if current treeblock belongs to type "III", the minimum depth level is reset with "1"; else if current treeblock belongs to type "IV", the minimum depth level is reset with "2".</p><p>Step 4: Loop depth levels from the minimum depth level to the maximum depth level.</p><p>Step 4.1: Derive the coding information of spatially nearby CUs and the parent CU in the previous depth level.</p><p>Step 4.2: When the first candidate from RMD, the optimal mode of the parent CU and the MPM from spatially nearby CUs are with the same intra prediction mode ( M ), select M as the best mode, skip the process of intra mode decision and go to Step 4.5.</p><p>Step 4.3: Compute Thr for RD cost based on ( 4).</p><p>Step 4.4: Loop each candidate defined in Section II-B. If the minimal RD cost of a candidate is smaller than Thr , terminate the procedure of intra mode decision at current depth level.</p><p>Step 4.5: Go to step 4.1 and proceed next depth level. end loop.</p><p>Step 5: Determine the best intra prediction mode and depth level. Go to step 1 and proceed with next treeblock.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTAL RESULTS</head><p>In order to evaluate the performance of the proposed fast intra prediction algorithm, it is implemented on the recent HEVC reference software (HM 5.2). We compare the proposed algorithm in low complexity configuration with the state-of-the-art fast intra prediction algorithms for HEVC, i.e., the fast intra mode decision algorithm (FIMDA) <ref type="bibr" target="#b7">[8]</ref> and early termination for intra prediction (ET-IP) <ref type="bibr" target="#b8">[9]</ref>. The performance of the proposed algorithm is shown in Tables <ref type="table" target="#tab_6">VI</ref> and<ref type="table" target="#tab_7">VII</ref>. Experiments are carried out for all I-frames sequences. Coding treeblock has a fixed size of 64×64 pixels (for luma) and a maximum depth level of 4, resulting in a minimum CU size of 8×8 pixels, and CABAC is used as the entropy coder. The proposed algorithm is evaluated with QPs 22, 27, 32 and 37 using sequences recommended by JCT-VC in four resolutions <ref type="bibr" target="#b13">[14]</ref> (416×240/832×480/1920×1080/2560×1600 formats). Note that the six training sequences, which are utilized to verify legitimacy of the proposed algorithm in Section II, are not used as test sequences. Coding efficiency is measured with PSNR and bit rate, and computational complexity is measured with consumed coding time. BDPSNR (dB) and BDBR (%) are used to represent the average PSNR and bitrate differences <ref type="bibr" target="#b14">[15]</ref>, and "DT (%)" is used to represent coding time change in percentage. Positive and negative values represent increments and decrements, respectively.</p><p>Table <ref type="table" target="#tab_6">VI</ref> shows performances of the proposed fast intra prediction algorithm compared to FIMDA. The proposed algorithm can greatly reduce coding time for all sequences. The proposed algorithm can reduce coding time by 21% with a maximum of 36% in "Kimono1 (1920×1080)" and the minimum of 13% in "RaceHorses (416×240)". For sequences with large resolutions (such as 1920×1080 and 2560×1600), the proposed algorithm shows impressive performance with more than 25% coding time saving. The gain of our algorithm is high because unnecessary small CU size decision has been skipped. For sequences with large smooth texture areas like "Kimono1," and "BasketballDrive", the proposed algorithm saves more than 30% coding time. The computation reduction is particularly high because the exhaustive CU size decision and mode decision procedures of a significant number of CUs are not processed by the encoder. On the other hand, coding efficiency loss is negligible in Table <ref type="table" target="#tab_6">VI</ref>, where the average coding efficiency loss in term of PSNR is about 0.08 dB with the minimum of 0.03 dB. Therefore, the proposed algorithm can efficiently reduce coding time while keeping nearly the same RD performance as FIMDA. Table <ref type="table" target="#tab_7">VII</ref> shows performances of the proposed fast intra prediction algorithm compared to ET-IP <ref type="bibr" target="#b8">[9]</ref>. Experimental results shown in Table VII indicate that the proposed algorithm consistently outperforms ET-IP. The proposed algorithm can save 7.5% coding time on average compared to ET-IP, with a maximum of 11.5% in "PartyScene (832×480)" and the minimum of 2.4% in "BasketballPass (416×240)". Additional, the proposed fast intra prediction algorithm achieves a better RD performance, with 0.02 dB PSNR increase or 0.44% bitrate decrease compared to ET-IP. Fig. <ref type="figure" target="#fig_3">4</ref> gives more detail information of the proposed algorithm compared to FIMDA (QPs with 22, 27, 32, and 37) for "BQMall (832×480)" and "Kimono1 (1920×1080)". We can observe that our proposed algorithm performs almost the same coding efficiency from low to high bit-rate compared to FIMDA. Meanwhile, it can achieve consistent time saving.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Meanwhile, a CU can split into several PUs as shown in part (b) of Fig. 1. Besides the direct current (DC) prediction mode, each PU has 33 possible intra prediction directions shown as Fig.1 (b) below.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Depth level correlation among nearby treeblocks. C: current treeblock; L: left treeblock; U: up treeblock; L-U: left-up treeblock; R-U: right-up treeblock.</figDesc><graphic coords="3,115.02,241.80,115.50,63.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>5 0 15 71 11 3 5 39 35 22 0 20 48 32 Basketball 0 88 0 12 4 70 14 12 2 33 33 32 0 11 30 59 ShipCalendar 62 32 1 5 21 55 19 6 4 31 31 34 0 6 20 74 StockholmPan 44 45 10 1 20 41 33 7 3 26 42 29 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Experimental results of "BQMall" (832×480) and "Kimono1" (1920×1080) under different QPs (22, 27, 32, and 37).</figDesc><graphic coords="6,333.05,549.64,209.25,136.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) RD curves of "BQMall" (b) Time saving curve of "BQMall" compared to FIMDA (c) RD curves of "Kimono1" (d) Time saving curve of "Kimono1" compared to FIMDA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="2,46.80,262.14,252.09,210.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I WEIGHT FACTORS ASSIGNED TO NEIGHBORING TREEBLOCKS Left treeblock Up treeblock Left-up treeblock Right-up treeblock</head><label>I</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.3</cell><cell></cell><cell>0.3</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell cols="7">According to the predicted depth level of a treeblock, we</cell></row><row><cell cols="7">divide treeblocks into four types as follows,</cell></row><row><cell cols="3">when Depth</cell><cell cols="2">pre</cell><cell cols="2">0.5</cell><cell>treeblock</cell><cell>I</cell></row><row><cell>when</cell><cell>0.5</cell><cell cols="4">Depth</cell><cell>pre</cell><cell>1.5 treeblock</cell><cell>II</cell></row><row><cell>when</cell><cell>1.5</cell><cell cols="3">Depth</cell><cell cols="2">pre</cell><cell>2.5 treeblock</cell><cell>III</cell></row><row><cell cols="4">when Depth</cell><cell>pre</cell><cell cols="2">2.5</cell><cell>treeblock</cell><cell>IV</cell></row></table><note><p>i </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III NUMBER OF N IN ROUGH MODE DECISION</head><label>III</label><figDesc></figDesc><table><row><cell>PU size</cell><cell>the number of N</cell></row><row><cell>64×64</cell><cell>3</cell></row><row><cell>32×32</cell><cell>3</cell></row><row><cell>16×16</cell><cell>3</cell></row><row><cell>8×8</cell><cell>8</cell></row><row><cell>4×4</cell><cell>8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV CONDITIONAL PROBABILITIES OF THE OPTIMAL INTRA MODE First candidate of RMD Optimal mode of the parent CU MPM of spatially nearby CUs</head><label>IV</label><figDesc></figDesc><table><row><cell>Horseriding</cell><cell>62%</cell><cell>23%</cell><cell>34%</cell></row><row><cell>Basketball</cell><cell>48%</cell><cell>16%</cell><cell>25%</cell></row><row><cell>ShipCalendar</cell><cell>59%</cell><cell>21%</cell><cell>32%</cell></row><row><cell>StockholmPan</cell><cell>68%</cell><cell>28%</cell><cell>42%</cell></row><row><cell>Flamingo</cell><cell>56%</cell><cell>20%</cell><cell>34%</cell></row><row><cell>Fireworks</cell><cell>59%</cell><cell>28%</cell><cell>35%</cell></row><row><cell>Average</cell><cell>59%</cell><cell>23%</cell><cell>34%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc> are the RD costs from Left CU, Up CU, Left-up CU and Right-up CU, and cos p Rd t is the RD cost from the parent CUs in upper depth levels. When the minimal RD cost of a candidate is smaller than Thr , terminate the procedure of intra mode decision at current CU.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">),</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tr</cell><cell></cell><cell cols="2">Rd</cell><cell cols="2">cos / 4 p t</cell><cell></cell><cell cols="2">Rd</cell><cell>cos</cell><cell cols="3">l t Rd </cell><cell>cos 5</cell><cell>u t Rd </cell><cell cols="2">cos</cell><cell>t</cell><cell>l u </cell><cell></cell><cell>Rd</cell><cell>cos</cell><cell>t</cell><cell>R u </cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(4)</cell></row><row><cell cols="3">where</cell><cell cols="2">Rd</cell><cell>cos l t ,</cell><cell cols="2">Rd</cell><cell cols="3">cos u t ,</cell><cell>Rd</cell><cell cols="4">cos l u t  and</cell><cell cols="2">Rd</cell><cell>cos R u t</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V STATISTICAL ANALYSIS FOR ACCURACIES OF ET METHODS Accuracy of ET based on the mode-correlation</head><label>V</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Accuracy of ET based on</cell></row><row><cell></cell><cell></cell><cell>the RD cost correlation</cell></row><row><cell>Horseriding</cell><cell>83%</cell><cell>94%</cell></row><row><cell>Basketball</cell><cell>70%</cell><cell>86%</cell></row><row><cell>ShipCalendar</cell><cell>83%</cell><cell>90%</cell></row><row><cell>StockholmPan</cell><cell>81%</cell><cell>95%</cell></row><row><cell>Flamingo</cell><cell>81%</cell><cell>91%</cell></row><row><cell>Fireworks</cell><cell>85%</cell><cell>87%</cell></row><row><cell>Average</cell><cell>81%</cell><cell>91%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI RESULTS OF THE PROPOSED ALGORITHM COMPARED TO FIMDA [8]</head><label>VI</label><figDesc></figDesc><table><row><cell></cell><cell>Picture</cell><cell>BDBR</cell><cell>BDPSNR</cell><cell>DT</cell></row><row><cell>Sequnces</cell><cell>Size</cell><cell>(%)</cell><cell>(dB)</cell><cell>(%)</cell></row><row><cell cols="2">PeopleOnStreet 2560×1600</cell><cell>2.37</cell><cell>-0.12</cell><cell>-21.6</cell></row><row><cell>Traffic</cell><cell>2560×1600</cell><cell>2.19</cell><cell>-0.10</cell><cell>-22.3</cell></row><row><cell cols="2">BasketballDrive 1920×1080</cell><cell>3.04</cell><cell>-0.06</cell><cell>-31.8</cell></row><row><cell>BQTerrace</cell><cell>1920×1080</cell><cell>2.40</cell><cell>-0.13</cell><cell>-25.5</cell></row><row><cell>Cactus</cell><cell>1920×1080</cell><cell>2.13</cell><cell>-0.07</cell><cell>-23.5</cell></row><row><cell>Kimono1</cell><cell>1920×1080</cell><cell>1.03</cell><cell>-0.03</cell><cell>-36.0</cell></row><row><cell>ParkScene</cell><cell>1920×1080</cell><cell>2.21</cell><cell>-0.09</cell><cell>-26.1</cell></row><row><cell>RaceHorses</cell><cell>832×480</cell><cell>1.44</cell><cell>-0.08</cell><cell>-16.9</cell></row><row><cell cols="2">BasketballDrill 832×480</cell><cell>1.53</cell><cell>-0.06</cell><cell>-17.9</cell></row><row><cell>BQMall</cell><cell>832×480</cell><cell>2.06</cell><cell>-0.12</cell><cell>-18.6</cell></row><row><cell>PartyScene</cell><cell>832×480</cell><cell>0.97</cell><cell>-0.07</cell><cell>-17.8</cell></row><row><cell>RaceHorses</cell><cell>416×240</cell><cell>1.05</cell><cell>-0.07</cell><cell>-12.9</cell></row><row><cell>BasketballPass</cell><cell>416×240</cell><cell>1.48</cell><cell>-0.08</cell><cell>-15.1</cell></row><row><cell cols="2">BlowingBubbles 416×240</cell><cell>1.18</cell><cell>-0.06</cell><cell>-15.1</cell></row><row><cell>BQSquare</cell><cell>416×240</cell><cell>1.03</cell><cell>-0.08</cell><cell>-14.9</cell></row><row><cell>Average</cell><cell></cell><cell>1.74</cell><cell>-0.08</cell><cell>-21.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII RESULTS OF THE PROPOSED ALGORITHM COMPARED TO ET-IP [9] Sequnces Picture Size BDBR (%) BDPSNR (dB) DT (%)</head><label>VII</label><figDesc></figDesc><table><row><cell cols="2">PeopleOnStreet 2560×1600</cell><cell>-1.41</cell><cell>0.07</cell><cell>-5.1</cell></row><row><cell>Traffic</cell><cell>2560×1600</cell><cell>-1.32</cell><cell>0.06</cell><cell>-6.7</cell></row><row><cell cols="2">BasketballDrive 1920×1080</cell><cell>0.32</cell><cell>-0.01</cell><cell>-10.0</cell></row><row><cell>BQTerrace</cell><cell>1920×1080</cell><cell>1.00</cell><cell>-0.06</cell><cell>-10.9</cell></row><row><cell>Cactus</cell><cell>1920×1080</cell><cell>-0.83</cell><cell>0.03</cell><cell>-6.6</cell></row><row><cell>Kimono1</cell><cell>1920×1080</cell><cell>0.41</cell><cell>-0.01</cell><cell>-9.4</cell></row><row><cell>ParkScene</cell><cell>1920×1080</cell><cell>0.65</cell><cell>-0.03</cell><cell>-9.0</cell></row><row><cell>RaceHorses</cell><cell>832×480</cell><cell>-0.38</cell><cell>0.03</cell><cell>-5.2</cell></row><row><cell cols="2">BasketballDrill 832×480</cell><cell>-3.27</cell><cell>0.14</cell><cell>-2.6</cell></row><row><cell>BQMall</cell><cell>832×480</cell><cell>0.15</cell><cell>-0.01</cell><cell>-9.0</cell></row><row><cell>PartyScene</cell><cell>832×480</cell><cell>-0.99</cell><cell>0.07</cell><cell>-11.5</cell></row><row><cell>RaceHorses</cell><cell>416×240</cell><cell>-0.96</cell><cell>0.06</cell><cell>-5.6</cell></row><row><cell>BasketballPass</cell><cell>416×240</cell><cell>-0.19</cell><cell>0.01</cell><cell>-2.4</cell></row><row><cell cols="2">BlowingBubbles 416×240</cell><cell>-0.24</cell><cell>0.01</cell><cell>-7.3</cell></row><row><cell>BQSquare</cell><cell>416×240</cell><cell>0.52</cell><cell>-0.04</cell><cell>-11.0</cell></row><row><cell>Average</cell><cell></cell><cell>-0.44</cell><cell>0.02</cell><cell>-7.5</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is sponsored by Shanghai Rising-Star Program (11QA1402400) and Innovation Program (13ZZ069) of Shanghai Municipal Education Commission, and is supported by the National Natural Science Foundation of China under grant No. 60832003, 60902085 and 61171084.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In this paper, we propose a fast intra prediction algorithm to reduce the computational complexity of the HEVC encoder including two fast approaches: fast CU size decision approach and fast intra mode decision approach at each depth level. The recent HEVC reference software is applied to evaluate the proposed algorithm. The comparative experimental results show that the proposed algorithm can significantly reduce the computational complexity of HEVC and maintain almost the same RD performances as the HM encoder, exhibiting applicability to various types of video sequences; meanwhile, it achieves a better result than the state-of-the-art fast algorithms, FIMDA and ET-IP. The proposed fast intra prediction algorithm is beneficial to real-time realization of for the HEVC encoder through the hardware or software implementation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BIOGRAPHIES</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved Video Compression Efficiency through Flexible Unit Representation and Corresponding Extension of Coding Tools</title>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alshina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alshin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuit System for Video Technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1709" to="1720" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Video compression-From concepts to the H.264/AVC standard</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2005-01">Jan. 2005</date>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="18" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A hybrid video coder based on extended macroblock sizes, improved interpolation, and flexible motion representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karczewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuit System for Video Technology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1698" to="1708" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">3D video compression based on high efficiency video coding</title>
		<author>
			<persName><forename type="first">G</forename><surname>Van Wallendael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Leuven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>De Cock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bruls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Walle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint Collaborative Team on Video Coding (JCT-VC) of ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11, document JCTVC-H1001</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Ohm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Meeting</title>
		<meeting><address><addrLine>José, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>San</publisher>
			<date type="published" when="2012-02">Feb. 2012</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
	<note>HEVC software guidelines</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Complexity control of high efficiency video encoders for power-constrained devices</title>
		<author>
			<persName><forename type="first">G</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Assuncao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Agostini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1866" to="1874" />
			<date type="published" when="2011-11">Nov. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Joint Collaborative Team on Video Coding (JCT-VC)of ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11, Document: JCTVC-C207</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-10">Oct. 2010</date>
			<pubPlace>Guangzhou</pubPlace>
		</imprint>
	</monogr>
	<note>Encoder improvement of unified intra prediction</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast Mode Decision Algorithm for Intra Prediction in HEVC</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visual Communications and Image Processing</title>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast intra mode decision of HEVC based on hierarchical structure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Information, Communications and Signal Processing</title>
		<imprint>
			<date type="published" when="2011-12">Dec. 2011</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast HEVC intra prediction mode decision based on EDGE direction information</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Agostini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silva</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th European Signal Processing Conference</title>
		<meeting>the 20th European Signal Processing Conference</meeting>
		<imprint>
			<date type="published" when="2012-08">Aug. 2012</date>
			<biblScope unit="page" from="1214" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradient based fast mode decision algorithm for intra predicion in HEVC</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Consumer Electronics, Communications and Networks (CECNet)</title>
		<imprint>
			<date type="published" when="2012-04">Apr. 2012</date>
			<biblScope unit="page" from="1836" to="1840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A low-complexity HEVC intra prediction algorithm based on level and mode filtering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2012-07">July 2012</date>
			<biblScope unit="page" from="1085" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Content adaptive prediction unit size decision algorithm for HEVC intra coding</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Picture coding symposium (PCS)</title>
		<imprint>
			<date type="published" when="2012-05">May, 2012</date>
			<biblScope unit="page" from="405" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint Collaborative Team on Video Coding (JCT-VC)of ITU-T SG16 WP3 and ISO/IEC JTC1/SC</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document: JCTVC-B300, 2nd Meeting</title>
		<imprint>
			<publisher>CH</publisher>
			<date type="published" when="2010-07">July, 2010</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
	<note>Common test conditions and software reference configurations</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Calculation of average PSNR difference between RD-curves</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bjontegaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th VCEG-M33 Meeting</title>
		<meeting><address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-02-04">Apr. 2-4, 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
