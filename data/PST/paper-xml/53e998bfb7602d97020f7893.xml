<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">also considering other applications of the proposed model, the most straightforward cases being classification and regression with non-Gaussian noise (including robust regression). Neural-Network-Based Adaptive Leader-Following Control for Multiagent Systems with Uncertainties</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Long</forename><surname>Cheng</surname></persName>
							<email>chenglong@compsys.ia.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">Zeng-Guang</forename><surname>Hou</surname></persName>
							<email>hou@compsys.ia.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Tan</surname></persName>
							<email>min.tan@ia.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">Yingzi</forename><surname>Lin</surname></persName>
							<email>yilin@coe.neu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Key Laboratory of Complex Systems and Intelligence Science</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Mechanical and Industrial Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">College of Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>02108-4910</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Mechanical Engineering</orgName>
								<orgName type="institution">Uni-versity of Saskatchewan</orgName>
								<address>
									<postCode>S7N 5A9</postCode>
									<settlement>Saskatoon</settlement>
									<region>SK</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">also considering other applications of the proposed model, the most straightforward cases being classification and regression with non-Gaussian noise (including robust regression). Neural-Network-Based Adaptive Leader-Following Control for Multiagent Systems with Uncertainties</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EEB0E19F5F3A43D3EAC68BAA23B93637</idno>
					<idno type="DOI">10.1109/TNN.2010.2050601</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adaptive</term>
					<term>leader-following control</term>
					<term>multiagent system</term>
					<term>neural networks</term>
					<term>uncertainty</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A neural-network-based adaptive approach is proposed for the leader-following control of multiagent systems. The neural network is used to approximate the agent's uncertain dynamics, and the approximation error and external disturbances are counteracted by employing the robust signal. When there is no control input constraint, it can be proved that all the following</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>S TUDIES on the collective behavior in biological systems show that each biological individual makes decisions solely on the basis of communications with its neighbor individuals <ref type="bibr">[6]</ref>. These biological observations draw some enlightenments on how to design distributed consensus protocols for complex multiagent systems <ref type="bibr">[4]</ref>, <ref type="bibr" target="#b22">[12]</ref>, <ref type="bibr" target="#b28">[18]</ref>. As an effective consensus seeking approach, the leader-following strategy has attracted considerable attention from the control community <ref type="bibr">[2]</ref>, <ref type="bibr">[5]</ref>, <ref type="bibr">[9]</ref>- <ref type="bibr">[11]</ref>, <ref type="bibr" target="#b23">[13]</ref>, <ref type="bibr" target="#b25">[15]</ref>, <ref type="bibr" target="#b27">[17]</ref>. By this strategy, all the following agents' states can reach consensus on the leader's state. In <ref type="bibr">[11]</ref>, each agent was modeled by the first-order integral dynamics, and the following agent used the estimated leader's velocity to construct its tracking controller. Extensions to the multiagent system with the second-order integral individual dynamics were made in <ref type="bibr">[10]</ref>. In addition, the leaderfollowing approach for the multiagent system with the noised communication was studied in <ref type="bibr" target="#b25">[15]</ref>. However, these leaderfollowing approaches have the limitation: the leader's state should be constant <ref type="bibr" target="#b25">[15]</ref>, or the leader's velocity/acceleration <ref type="bibr">[10]</ref>, <ref type="bibr">[11]</ref> should be accessible to all the following agents. In <ref type="bibr">[5]</ref> and <ref type="bibr">[9]</ref>, the leader-following approach was proposed for a group of unicycle agents with input constraints and with the limited sensor information, respectively. Although the state of leader agent is time-varying and only a portion of following agents can obtain the leader's state information, the topology of the multiagent system is restrictive. Each following agent can receive information from only one neighbor agent, which means that the leader-following control of multiagent systems cannot be achieved if the communication link fails. In <ref type="bibr" target="#b23">[13]</ref>, a "Stop-Go" policy was proposed for the leader agents to drive all the following agents to a given destination; however, the leader agent is required to know whether all the following agents remain in a convex polytope spanned by the leader agents. In <ref type="bibr" target="#b27">[17]</ref>, the aforementioned limitations were overcome, and all following agents could track the leader's time-varying state through local interactions. Extensions to the agents with discrete-time dynamics were made in <ref type="bibr">[2]</ref>.</p><p>According to survey <ref type="bibr" target="#b29">[19]</ref>, most existing researches on the coordination of multiagent systems consider the agents with first-order or second-order integral dynamics. There are only a few studies about the leader-following control of multiagent systems with the uncertain dynamics. In <ref type="bibr">[3]</ref>, Cheng et al. proposed an adaptive leader-following approach for the multimanipulator system with uncertainties. However, the traditional adaptive method was employed to deal with the 1045-9227/$26.00 c 2010 IEEE uncertainty, which suffered from the assumption of "linearityin-parameters." It is also noted that the neural-network-based adaptive control has been broadly accepted as an effective alternative to the traditional adaptive control <ref type="bibr" target="#b26">[16]</ref>. The stability of this controller is guaranteed by the Lyapunov synthesis method, and synaptic weights of neural networks are tuned online. Successful applications to the robot and nonlinear system control can be found in <ref type="bibr" target="#b24">[14]</ref>. For the general framework of this neural-network-based method and the state of art of intelligent adaptive control, the readers are referred to <ref type="bibr">[7]</ref>.</p><p>Motivated by the aforementioned discussion, a neuralnetwork-based adaptive leader-following controller is proposed for the multiagent system with uncertain dynamics. The contributions of this paper lie in: 1) uncertainties in the agent's dynamics are considered and then approximated by the neural network; 2) approximation errors and external disturbances are counteracted by using the robust signal; 3) all following agents can track the leader's time-variant state with the tracking error as small as desired if no control input constraint is considered; and 4) the proposed controller and the updating law of the neural network weight matrix are only dependent on the information of neighbor agents. The differences between this paper and our previous work <ref type="bibr">[4]</ref>, <ref type="bibr" target="#b22">[12]</ref> are that: the controller proposed in <ref type="bibr" target="#b22">[12]</ref> can only ensure the synchronization of all agents' states, and it cannot solve the leader-following problem with the leader having a time-varying state trajectory; the agent's dynamics in this brief includes the uncertain term which cannot be solved by the algorithm proposed for agents with the deterministic linear model <ref type="bibr">[4]</ref>. Therefore, the proposed approach renders itself to a meaningful contribution to the current literature. Finally, the theoretical analysis is validated by simulation examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Problem Formulation and Preliminaries</head><p>The following notations will be used throughout this paper: 1 n = (1, 1, . . . , 1) ∈ R n , 0 n = (0, 0, . . . , 0) ∈ R n , I n denotes the n×n dimensional identity matrix, ⊗ denotes the Kronecker operator. For a given matrix X, X denotes its Euclidean norm, X F denotes its Frobenius norm, and λ min (X) denotes its smallest eigenvalue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiagent System Description</head><p>Consider a network of N following agents indexed by 1, 2, . . . , N, respectively, and one leader indexed by 0. The ith following agent has the nonlinear dynamics</p><formula xml:id="formula_0">ẋi = f i (x i ) + u i + i , i = 1, 2, . . . , N<label>(1)</label></formula><p>where x i ∈ R n denotes the agent's state, f i (x i ) : R n → R n is the smooth nonlinear function containing both parametric and non-parametric uncertainties, its structure can be unknown either, u i ∈ R n denotes the control input, i ∈ R n represents the external disturbance, such as the unstructured unmodeled dynamics and the external noise. The leader plays the role of the reference signal which guides the movements of all following agents. x 0 denotes the state of leader which is properly designed for specific applications. In practice, there are several cases where the agent's dynamics can be described by <ref type="bibr">(1)</ref>. For example, when the object moves in a viscous environment with the high speed, such as the supersonic aerial vehicle, the speed of object is subject to the influence of velocity damping. Then, x i can represent the object's velocity, u i is the force applied to the object, i is the external noise, and f i (x i ) is the velocity damping containing the uncertain damping parameters. The communication topology of the multiagent system can be described by the weighted digraph</p><formula xml:id="formula_1">G = (V G , E G , A G ). V G = {v 0 , v 1 , . . . , v N } denotes the set of nodes, E G ⊆ V G × V G</formula><p>denotes the set of edges, and</p><formula xml:id="formula_2">A G = [a ij ] ∈ R (N+1)×(N+1)</formula><p>denotes the weighted adjacency matrix, where a ii = 0 and a ij ≥ 0. Node v i represents the ith agent. A directed edge in E G is denoted by the pair e ij = (v i , v j ). e ij ∈ E G if and only if there is the information flow from agent j to agent i, node v j is called the parent node and node v i is called the child node. The neighborhood of the ith node is denoted by</p><formula xml:id="formula_3">N i = {j ∈ V G |e ij ∈ E G },</formula><p>which is the set of all parent nodes of the ith node. The adjacency element a ij represents the quality of communication channel, and e ij ∈ E G → a ij &gt; 0. Because the leader agent does not receive any information from following agents, e 0j / ∈ E G and a 0j = 0, ∀j = 0, 1, . . . , N.</p><p>A sequence of edges</p><formula xml:id="formula_4">(v i k , v i k -1 ), . . . , (v i 3 , v i 2 ), (v i 2 , v i 1 ) is called a directed path from node v i 1 to node v i k .</formula><p>If there exists a directed path from one node to itself, then the digraph contains a loop. A directed tree is a digraph, where every node, except the root, has exactly one parent node. A spanning tree of G is a directed tree whose node set is V G and whose edge set is a subset of E G . Apparently, if the topology G of leader-following multiagent system has a spanning tree, then the root of this spanning tree must be the node v 0 (leader).</p><p>The Laplacian matrix L G of digraph G is defined by</p><formula xml:id="formula_5">L G = D G -A G (<label>2</label></formula><formula xml:id="formula_6">)</formula><p>where </p><formula xml:id="formula_7">D G = diag(d 0 ,</formula><formula xml:id="formula_8">: i ≤ i .</formula><p>Assumption 3: The leader's state trajectory x 0 (t) is bounded: x 0 (t) ≤ X M , ∀t ≥ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Radial Basis Function Neural Networks</head><p>Similar to <ref type="bibr" target="#b22">[12]</ref>, the radial basis function neural network (RBFNN) can be employed to approximate the smooth unknown function, h(Z) : R n → R n , as follows:</p><formula xml:id="formula_9">h nn (Z) = W T S(Z) (<label>3</label></formula><formula xml:id="formula_10">)</formula><p>where the input vector Z ∈ ⊂ R n , weight matrix W ∈ R l×n , l denotes the number of neurons, and</p><formula xml:id="formula_11">S(Z) = [s 1 (Z), . . . , s l (Z)] T with s j (Z) = exp -(Z -µ j ) T (Z -µ j ) σ 2 j , j = 1, . . . , l</formula><p>where µ j ∈ R n is the center of the receptive field and ( √ 2σ j )/2 is the width of the Gaussian function.</p><p>It has been proved that the above RBFNN can approximate any smooth function over a compact set Z ⊂ R n to arbitrarily accuracy. That is, for any given positive constant ε N , providing a sufficiently large l, there exists the weight matrix W * such that</p><formula xml:id="formula_12">h(Z) = W * T S(Z) + ε (<label>4</label></formula><formula xml:id="formula_13">)</formula><p>where ε is the bounded function approximation error satisfying</p><formula xml:id="formula_14">ε &lt; ε N in Z .</formula><p>It is noted that the optimal matrix W * is only quantity required for analytical purpose, which can be calculated by</p><formula xml:id="formula_15">W * = arg min W∈R l×n { sup Z∈ Z h(Z) -W T S(Z) }.</formula><p>For real applications, its estimation Ŵ is used for the practical function approximation. The estimation of h(Z) can be given by ĥ(Z) = ŴT S(Z).</p><p>(</p><p>The following lemmas will be used to analyze the controller performance.</p><p>Lemma 3 <ref type="bibr" target="#b28">([18,</ref><ref type="bibr">Lem. 3.3]</ref>): The Laplacian matrix L G of a digraph G has at least one zero eigenvalue and all the non-zero eigenvalues have the positive real part. Furthermore, L G has only one zero eigenvalue with the associated eigenvector 1 N+1 if and only if the digraph G has a spanning tree.</p><p>Lemma 4 <ref type="bibr" target="#b28">([18,</ref><ref type="bibr">Lem. 1.1]</ref>): Let function V (t) ≥ 0 be a continuous function defined over t ∈ [0, +∞), and V (t) ≤ -γV (t) + κ, where γ and κ are positive constants, then</p><formula xml:id="formula_17">V (t) ≤ V (0)e -γt + κ γ (1 -e -γt ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Controller Design and Related Analysis</head><p>The control objective is to design the controller for each following agent which drives the agent to track the trajectory of a leader's time-varying states using the neighbor agents' information.</p><p>According to the "nearest neighbor rule," the weighted average of neighbor agents' states, xi , can be used as the reference signal for the ith following agent:</p><formula xml:id="formula_18">xi = N j=1 a ij x j + a i0 x 0 N j=0 a ij , i = 1, . . . , N. (<label>6</label></formula><formula xml:id="formula_19">)</formula><p>Let e i = xix i be the error between the reference and the ith agent's state. Differentiating e i with respect to time</p><formula xml:id="formula_20">obtains ėi = N j=1 a ij ẋj + a i0 ẋ0 N j=0 a ij -f i (x i ) -u i -i . (<label>7</label></formula><formula xml:id="formula_21">)</formula><p>Design the ith following agent's controller as follows:</p><formula xml:id="formula_22">u i = N j=1 a ij ẋj + a i0 ẋ0 N j=0 a ij -fi (x i ) + k i e i + ψ i (<label>8</label></formula><formula xml:id="formula_23">)</formula><p>where</p><formula xml:id="formula_24">k i &gt; 0 is the control gain. fi (x i ) = ŴT i S i (x i ) is the RBFNN estimation of f i (x i ). Ŵi ∈ R l i ×n</formula><p>and l i is the number of hidden neurons of the ith RBFNN. It will be proved in the following section that there exists such a compact region x i from which the trajectory of the ith agent's state never escapes. Then, according to Section II-B, there exists the optimal weight matrix</p><formula xml:id="formula_25">W * i such that f i (x i ) = W * i T S i (x i ) + ε i with ε i ≤ ε Ni in x i , where ε Ni &gt; 0 is a predesigned parameter. ψ i = (ψ i1 , ψ i2 , . . . , ψ in ) T ∈ R n</formula><p>is the robust signal for counteracting the approximation error ε i and external disturbance i . ψ ij is defined as follows:</p><formula xml:id="formula_26">ψ ij = δ Mi tanh nk u δ Mi e ij i , j = 1, 2, . . . , n<label>(9)</label></formula><p>where e ij is the jth element of e i , k u = 0.2785, i is a designed parameter which affects the control performance, and the robust gain δ Mi is chosen to satisfy that</p><formula xml:id="formula_27">δ Mi ≥ ε Ni + i ≥ ε i + i .</formula><p>It is also noted that the robust gain δ Mi can be adjusted online by employing the adaptive bounding method (see [7, Sec. 6.2.7]), which will be considered in the future work. The following two inequalities can be easily proved by <ref type="bibr">[16,</ref>  <ref type="bibr">Lemma 1</ref>]:</p><formula xml:id="formula_28">e T i ψ i ≥ 0, δ Mi e i -e T i ψ i ≤ i . (<label>10</label></formula><formula xml:id="formula_29">)</formula><p>Combining ( <ref type="formula" target="#formula_20">7</ref>) and ( <ref type="formula" target="#formula_22">8</ref>)</p><formula xml:id="formula_30">obtains ėi =-k i e i -WT i S i (x i ) -ψ i -i -ε i (<label>11</label></formula><formula xml:id="formula_31">)</formula><p>where Wi = W * i -Ŵi . By the projection algorithm, the updating law for the RBFNN weight matrix Ŵi is derived as follows:</p><formula xml:id="formula_32">Ẇi = ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ -β wi S i (x i )e T i , if Tr ( ŴT i Ŵi ) &lt; W max i , or if Tr ( ŴT i Ŵi ) = W max i and e T i ŴT i S i (x i ) ≥ 0 -β wi S i (x i )e T i + β wi e T i ŴT i S i (x i ) Tr ( ŴT i Ŵi ) Ŵi , if Tr ( ŴT i Ŵi ) = W max i and e T i ŴT i S i (x i ) &lt; 0 (<label>12</label></formula><formula xml:id="formula_33">)</formula><p>where β wi &gt; 0 is the adaption gain, W max i is a given positive constant for limiting the neural network weight matrix Ŵi , W max i is selected to satisfy Tr ((</p><formula xml:id="formula_34">W * i ) T W * i ) ≤ W max i . Although W *</formula><p>i is hard to be determined, it is a constant value. Therefore, there always exists the upper bound W max i such that Tr((W * i ) T W * i ) ≤ W max i . Hence, W max i only needs to be set as a sufficiently large value in practice. Furthermore, if more knowledge of f i (x i ) is known, W max i could be chosen relatively small and accurate. It is noted that the proposed neural network weight updating law is designed based on the projection method, which inherently needs the condition Tr(( <ref type="bibr" target="#b30">[20,</ref><ref type="bibr">Th. 4.6.1]</ref>). Other methods, such as the σ-modification or -modification, can also be employed to design the neural network weight updating law, which could eliminate the computation of W max i . In addition, the initial neural network weight matrix Ŵi (0) should satisfy the condition Tr ( ŴT i (0) Ŵi (0)) ≤ W max i . Remark 2: By the definition of adjacency matrix A G , it follows that a ij = 0 if and only if there is the information flow from agent j to agent i. Thus, by observing the proposed controller defined by <ref type="bibr">(8)</ref> and the weight matrix updating law defined by <ref type="bibr" target="#b22">(12)</ref>, it is easy to see that the proposed adaptive controller for the ith agent only uses the information of its neighbor agents. Hence, the proposed algorithm is distributed.</p><formula xml:id="formula_35">W * i ) T W * i ) ≤ W max i (see</formula><p>Remark 3: According to the conclusion in <ref type="bibr" target="#b27">[17]</ref>, most existing consensus methods cannot solve the leader-following problem with the time-varying leader's state. In order to solve this problem, consider the multiagent system composed of only two agents (one leader agent and one following agent). Assume that the leader's time-varying position is x l (t), and the following agent is modeled by the single-integrator dynamics ẋf = u f . In order to track the leader's position, u f could be designed as</p><formula xml:id="formula_36">u f = ẋl (t) + (x l (t) -x f (t)) such that d dt (x l (t) -x f (t)) = -(x l (t) -x f (t)).</formula><p>Then, as t → +∞, x l (t)x f (t) → 0. This simple example implies that one possible solution to solve the time-varying trajectory tracking is to combine the relative position x l (t)x f (t) and the target's velocity ẋl (t) together. Inspired by this observation, the controller defined by ( <ref type="formula" target="#formula_22">8</ref>) is designed, which employs not only the neighbor agent's position but also its velocity.</p><p>Theorem 2: Assume that the topology digraph G of the multiagent system has a spanning tree and no loop. By the proposed distributed adaptive controller defined by ( <ref type="formula" target="#formula_22">8</ref>) and <ref type="bibr" target="#b22">(12)</ref>, if no control input constraint is considered, all following agents can track the leader's time-varying state, and the tracking error can be reduced as small as desired by properly choosing the control parameters.</p><p>Proof: First, according to [12, Lemma 2], it can be proved that Tr ( ŴT</p><formula xml:id="formula_37">i (t) Ŵi (t)) ≤ W max i . Hence, if the initial condition Tr ( ŴT i (0) Ŵi (0)) ≤ W max i holds, then Tr ( ŴT i (t) Ŵi (t)) ≤ W max i (i = 1, 2, . . . , N) always holds. Therefore, the approx- imation error Wi F = W * i -Ŵi F ≤ Ŵi F + W * i F = 2 √ W max i is also bounded.</formula><p>Second, the error signal e i can be reduced as small as desired by properly choosing the control parameters. Construct the Lyapunov function</p><formula xml:id="formula_38">V i = (1/2)e T i e i + (1/(2β wi )) Tr( WT i Wi ).<label>(13)</label></formula><p>By ( <ref type="formula" target="#formula_28">10</ref>)-( <ref type="formula" target="#formula_32">12</ref>), it follows that</p><formula xml:id="formula_39">dV i dt ≤ -k i e T i e i + i -Tr WT i S i (x i )e T i + Ẇi β wi . (<label>14</label></formula><formula xml:id="formula_40">)</formula><p>By the same technique in the proof of Theorem 2 in <ref type="bibr" target="#b22">[12]</ref>, it can be proved that Tr( WT i ( 1</p><formula xml:id="formula_41">β wi Ẇi + S i (x i )e T i )) ≥ 0. By (14), it</formula><p>follows that</p><formula xml:id="formula_42">dV i dt ≤-k i e T i e i + i ≤-k i e T i e i -k i Tr 1 β wi WT i Wi + 4k i W max i β wi + i = -2k i V i (t) + 4k i W max i β wi + i . (<label>15</label></formula><formula xml:id="formula_43">)</formula><p>Hence, by Lemma 4, it can be obtained that</p><formula xml:id="formula_44">V i (t) ≤ V i (0)e -2k i t + ρ i (1 -e -2k i t ) (<label>16</label></formula><formula xml:id="formula_45">)</formula><p>where ρ i = (2W max i )/(β wi ) + ( i )/(2k i ). Therefore, for any prescribed value η &gt; 0, by choosing i &lt; (ηk i )/4 and</p><formula xml:id="formula_46">β wi &gt; (16W max i )/η, it follows that, for i = 1, 2, . . . , N ∀t ≥ T i = 1 2k i ln 4V i (0) η , 1 2 e T i (t)e i (t) ≤ V i (t) ≤ η 2 . (<label>17</label></formula><formula xml:id="formula_47">)</formula><p>Finally, it can be proved that all following agents will track the leader's state and the tracking error can be reduced as small as desired. Let e(t) = (0 T n , e T 1 (t), . . . , e T N (t)) T and T = max i T i . By <ref type="bibr" target="#b27">(17)</ref>, it can be obtained that e i (t) 2 ≤ η, ∀t ≥ T . Because 1 N+1 is the eigenvector associated with eigenvalue 0 of L G , it can be proved that</p><formula xml:id="formula_48">(D G ⊗ I n )e(t) = -(L G ⊗ I n )(x(t) -1 N+1 ⊗ x 0 (t))<label>(18)</label></formula><p>where x(t) = (x T 0 (t), x T 1 (t), . . . , x T N (t)) T . Since the topology digraph G has a spanning tree, by Lemma 3, L G has exactly one zero eigenvalue and other eigenvalues are all in the open right plane. It is also noted that</p><formula xml:id="formula_49">L G = 0 0 T N -a *</formula><p>LG where a * = (a 10 , a 20 , . . . , a N0 ) T . Therefore, all eigenvalues of LG have the positive real part. Then, (18) can be rewritten as</p><formula xml:id="formula_50">( DG ⊗ I n )ẽ(t) = -( LG ⊗ I n )(x(t) -1 N ⊗ x 0 (t))<label>(19)</label></formula><p>where ẽ(t) = (e T 1 (t), . . . , e T N (t)) T , DG = diag(d 1 , d 2 , . . . , d N ), and</p><formula xml:id="formula_51">x(t) = (x T 1 (t), . . . , x T N (t)) T . Then, ∀t ≥ T , λ 2 min ( LT G LG ) x(t)-1 N ⊗x 0 (t) 2 ≤ ( D⊗I n )ẽ(t) 2 ≤ η N i=1 d 2 i . Hence, x i (t) -x 0 (t) 2 ≤ (η N i=1 d 2 i )/λ 2 min ( LT G</formula><p>LG ), ∀t ≥ T (i = 1, . . . , N). Since η can be any prescribed positive value, all following agents can track the leader's state and the tracking error can be reduced as small as desired.</p><p>Remark 4: It is noted that the parameter selection method for β wi in the Theorem proof is very conservative due to the inequality used in <ref type="bibr" target="#b25">(15)</ref>. In practice, β wi does not need to be set as a very large value.</p><p>Remark 5: By the proof of Theorem 2, it follows that 2 , ∀t ≥ 0. By ( <ref type="formula" target="#formula_44">16</ref>), it follows that e i (t) 2 ≤ 2V i (0) + 2ρ i , ∀t ≥ 0. Therefore,</p><formula xml:id="formula_52">x i (t) -x 0 (t) 2 ≤ N i=1 d 2 i e i (t)</formula><formula xml:id="formula_53">x i (t) ≤ x 0 (t) + ( N i=1 d 2 i (2V i (0) + 2ρ i )) 1/2 , ∀t ≥ 0.</formula><p>According to Assumption 3, the compact approximation region</p><p>x i of the ith RBFNN can be set as</p><formula xml:id="formula_54">x i = {x i | x i ≤ X M + ( N i=1 d 2 i (2V i (0) + 2ρ i )) 1/2 }, i = 1, 2, .</formula><p>. . , N. Remark 6: According to <ref type="bibr" target="#b29">(19)</ref>, the convergence of tracking error is strongly related with the convergence of e i (t) (i = 1, . . . , N). The convergence of e i (t) can be determined by <ref type="bibr" target="#b27">(17)</ref>. Hence, if the initial neural network weight matrix Ŵi (0) is close to the optimal weight matrix W * i and the initial following agent's state x i (0) is close to the leader agent's state x 0 (0), then the convergence of e i (t) (or tracking error) can be speeded up. In addition, the convergence of e i (t) is also strongly related with the control gain k i . The larger k i is, the faster the convergence is.</p><p>Remark 7: The "no-loop in the topology graph G" condition in Theorem 2 is necessary. Otherwise, without loss of generality, assume that there is the mutual information exchange between agents i and j. According to <ref type="bibr">(8)</ref>, the ith agent needs ẋj to design its controller u i , and the agent j has to know ẋi for u j . However, ẋi and ẋj are determined by u i and u j , respectively. Therefore, there is the implementation dead loop, which means that the proposed controller defined by ( <ref type="formula" target="#formula_22">8</ref>) is un-implementable. In practice, a possible solution to relax this condition is to design the controller based on the delayed velocity of neighbor agents. However, the rigorous proof of the tracking performance in this case needs to be further studied. Intuitively, there is a tradeoff between the delay length and the tracking performance. In addition, some effort could be made to study the discrete-time leaderfollowing problem addressed in <ref type="bibr">[2]</ref>. By using the backward difference of agent's state to approximate the agent's velocity, the "no-loop" condition could be removed.</p><p>Remark 8: Compared with the related results <ref type="bibr">[2]</ref>, <ref type="bibr">[5]</ref>, <ref type="bibr">[9]</ref>- <ref type="bibr">[11]</ref>, <ref type="bibr" target="#b23">[13]</ref>, <ref type="bibr" target="#b25">[15]</ref>, <ref type="bibr" target="#b27">[17]</ref>, this paper addresses the leader-following problem of multiagent systems with the uncertain dynamics. The leader agent has the time-variant state, and only a portion of following agents have access to the leader's information. In addition, the "no-loop in the topology graph G" condition is considered for the algorithm implementation. Therefore, the proposed leader-following approach contributes to the current literature.</p><p>Remark 9: It should be noted that this paper only considers the case where the control input is unconstrained. To the best of the authors' knowledge, there are very few results on the neural-network-based adaptive tracking control with control input constraints even in the field of single agent control. How to solve the constrained control problem would be an interesting topic for the future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Extensions</head><p>Similar to the idea in <ref type="bibr" target="#b22">[12]</ref>, the proposed leader-following approach can be extended to the case where the agent's dynamics has the higher relative degree by the backstepping technique. For simplicity, consider the following dynamic equation:</p><formula xml:id="formula_55">ẍi = f i (ẋ i , x i ) + u i + i , i = 1, 2, . . . , N.</formula><p>(20) First, it is assumed that the leader's state trajectory x 0 (t) and its derivatives up to the second order ẋ0 (t), ẍ0 (t) are bounded. Then, the controller can be designed by the following steps.</p><p>Step 1: design the virtual controller y id for ẋi as follows:</p><formula xml:id="formula_56">y id = χ 1 i s i + ẋi<label>(21)</label></formula><p>where</p><formula xml:id="formula_57">χ 1 i &gt; 0 is the feedback gain, xi = 1 N j=0 a ij ( N j=1 a ij x j + a i0 x 0 ), s i = xi -x i .</formula><p>Define the error signal r i = ẋiy id , and then differentiating r i with respect to time obtains</p><formula xml:id="formula_58">ṙi = ẍi -ẏid = f i (ẋ i , x i ) + u i + i -ẏid . (<label>22</label></formula><formula xml:id="formula_59">)</formula><p>Step 2: design the controller u i to reduce r i</p><formula xml:id="formula_60">u i = -χ 2 i r i -ŴT si S i (x i , ẋi , xi , ẋi , ẍi ) -φ i (<label>23</label></formula><formula xml:id="formula_61">)</formula><p>where χ 2 i &gt; 0 is the control gain, φ i = (φ i1 , φ i2 , . . . , φ in ) T ∈ R n is the robust signal, and φ ij is defined similar as ψ ij by replacing e ij in (9) with r ij (r ij is the jth element of r i ), ŴT si S i (x i , ẋi , xi , ẋi , ẍi ) is the ith RBFNN for approximating f i (x i , ẋi ) + ẏid + s i , and the weight updating law for each RBFNN is similar to <ref type="bibr" target="#b22">(12)</ref> [replacing S i (x i ) and e i in <ref type="bibr" target="#b22">(12)</ref> with S i (x i , ẋi , xi , ẋi , ẍi ) and r i , respectively]. The closed-loop system can be analyzed similarly as Theorem 2.</p><p>Remark 10: Generally speaking, it's hard to extend the following agent's dynamics defined by (1) to the general case dx i /dt = f i (x i )+g i (x i )u i . However, the following special cases could be considered. 1) Assume that g i (x i ) ∈ R n×m is the known gain matrix which has the generalized inverse</p><formula xml:id="formula_62">g + i (x i ) = g T i (x i )(g i (x i )g T i (x i )) -1 .</formula><p>Then, the proposed approach could be straightforwardly extended to solving this case. 2) Assume that the following agent's dynamics is an singleinput single-output (SISO) system. Then, the proposed leader-following approach could be modified to deal with this kind of agent's dynamics by using the integraltype Lyapunov function (see <ref type="bibr" target="#b30">[20,</ref><ref type="bibr">Sec. 3]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Simulation Examples</head><p>In this section, simulation examples are given to demonstrate the effectiveness of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Example 1</head><p>The multiagent system is composed of five following agents and one leader. Every agent moves in the 2-D plane, and the agent's state could denote its position. The leader's dynamics is described by the van der Pol oscillator x 0 (t) = (x 01 (t),</p><formula xml:id="formula_63">x 02 (t)) T , ẋ01 (t) = 50x 02 (t), ẋ02 (t) = 50(-x 01 (t)+0.2(1- x 2 01 (t))x 02 (t)).</formula><p>The ith following agent's dynamics is given as follows:</p><formula xml:id="formula_64">d dt x i1 (t) x i2 (t) = x 2 i2 (t) sin(k i1 x i1 (t)) x 3 i1 (t) cos(k i2 x 3 i2 (t)) + u i + i (24)</formula><p>where x i1 and x i2 denote the first dimension and second dimension of the ith agent's state, respectively, k i1 and k i2 are the uncertain parameters, which are set as k 11 = 0.6, k 12 = 0.3, k 21 = -0.6, k 22 = 0.4, k 31 = 7, k 32 = -5, k 41 = -10, k 42 = -11, k 51 = 10, k 52 = 11, i is modeled by 1 = (exp(-t), sin(t 2 )) T , 2 = (exp(-2t), cos(t 2 )) T , 3 = (cos(t 2 ), exp(-3t)) T , 4 = (-sin(t 2 ), cos(t) exp(-3t)) T , 5 =cos(t) sin(t 2 ), sin(t) exp(-3t)) T . It is easy to see that the dynamics includes the nonlinear terms sin(•) and cos(•), and uncertain parameters k i1 and k i2 do not meet the "linearity-inparameters" condition. The traditional adaptive scheme consequently fails in solving this problem. The initial positions of agents are The configurations of RBFNN are the same for all following agents. The number of neurons is 13, the centers of RBFNN activation function are: (-1.5, 1.5) T , (0, 1.5) T , (1.5, 1.5) T , (-1.5, 0) T , (0, 0) T , (1.5, 0) T , (-1.5, -1.5) T , (0, -1.5) T , (1.5, -1.5) T , (0.5, 0.5) T , (-0.5, 0.5) T , (-0.5, -0.5) T , (0.5, -0.5) T , and the variances are all set to be 5 √ 2/2. The controller parameters are: k i = 50, δ Mi = 5, i = 0.1, β wi = 10000, W max i = 5000, and the initial RBFNN weight matrix Ŵi (0) is chosen to be the zero matrix. The profile of the following agent's tracking error, x 0 (t)x i (t), is given in Fig. <ref type="figure" target="#fig_0">1</ref>. The control input of each following agent is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. According to the simulation result, it can be seen that all following agents can track the leader's time-varying state. In order to show that the consensus algorithm proposed in <ref type="bibr" target="#b22">[12]</ref> cannot solve the leader-following problem considered in this brief, this example is conducted again by using the consensus algorithm proposed in <ref type="bibr" target="#b22">[12]</ref> under the same controller parameters. According to the simulation result shown in Fig. <ref type="figure" target="#fig_2">3</ref>, the tracking performance is not satisfactory, which coincides with the conclusion given in <ref type="bibr" target="#b27">[17]</ref>.</p><formula xml:id="formula_65">x 0 (0) = (1, 1) T , x 1 (0) = (2, 2) T , x 2 (0) = (-0.5, -0.5) T , x 3 (0) = (-2, 2) T , x 4 (0) = (-2, -2) T , x 5 (0) = (2,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Example 2</head><p>In this subsection, five following manipulators will track the joint trajectory of one leader manipulator by the proposed distributed leader-following approach. The Denavit-Hartenberg parameters of each manipulator are given in Table <ref type="table" target="#tab_1">I</ref>. The physical parameters of all manipulators are the same: link lengths l 1 = 0.8 m, l 2 = 0.5 m, l 3 = 0.3 m, link masses  The manipulator's dynamics can be described as follows <ref type="bibr" target="#b24">[14]</ref>:</p><formula xml:id="formula_66">M i (q i )q i + V i (q i , qi )q i + G i (q i ) = τ i + τ di , i = 1, . . . , 5</formula><p>where q i , qi , qi ∈ R 3 denote the joint position, velocity, and acceleration vectors of manipulator i, respectively, M i (q i ) ∈ R 3×3 is the ith manipulator's inertia matrix, V i (q i , qi ) ∈ R 3×3 is the centripetal-Coriolis matrix of the ith manipulator, G i (q i ) ∈ R 3 is the ith manipulator's gravitational vector, τ di is the ith manipulator's input disturbance, and τ i ∈ R 3 represents the torque input vector of manipulator i. τ di is modeled by τ di = (0.5 sin(t/3), 0.5 sin(t/3), 0.5 sin(t/3)) T . The leader manipulator's joint trajectory is q 0 (t) = (π/6 + sin(t), sin(t), -π/6 + sin(t)) T rad. The initial joint configuration of each following manipulator is: q 1 (0) = (π/3, π/3, π/3) T rad, q 2 (0) = (π/4, π/4, π/4) T rad, q 3 (0) = (-π/3, -π/3, -π/3) T rad, q 4 (0) = (-π/5, -π/5, -π/5) T rad, q 5 (0) = (π/4, π/2, -π/4) T rad, q1 (0) = q2 (0) = q3 (0) = q4 (0) = q5 (0) = (0, 0, 0) T rad/s. By combining the previous work <ref type="bibr">[3]</ref> and discussion in Section IV, the distributed controller can be designed to solve this leader-following control of multimanipulator systems. The simulation result is shown in Fig. <ref type="figure" target="#fig_4">4</ref>, which illustrates the effectiveness of the proposed method. Compared with the previous work <ref type="bibr">[3]</ref>, the leader manipulator's information is only accessible to partial following manipulators, and there is no need to know the specific values of M i (q i ), V i (q i , qi ) and G i (q i ). The control algorithm proposed in <ref type="bibr" target="#b27">[17]</ref>, which does not consider the uncertainties in agent's dynamics, is also used to solve this problem. According to the simulation results shown in Fig. <ref type="figure" target="#fig_5">5</ref>, the leader-following algorithm proposed in this brief has the better control performance than the one proposed in <ref type="bibr" target="#b27">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Conclusion and Future Work</head><p>This paper proposed an adaptive leader-following controller for multiagent systems by using neural networks. Uncertainties in the agent's dynamics were taken into account, and compensated by using neural networks. The robust signal was employed to counteract the approximation error and external disturbances. While the leader's state can be time-variant, all following agents can track the leader's state with the tracking error as small as desired if no control input constraint is considered. At last, the theoretical analysis and the tracking performance were validated by simulation examples.</p><p>It is noted that the latest result on the neural-network-based adaptive control <ref type="bibr">[1]</ref> can ensure the transient performance of the closed-loop system. In the future, more effort is going to be made toward this direction. Also, the constraints on the agent's dynamics, such as the bounded input and the nonholonomic constraint, which are inevitable in practice, will be very interesting topics for the future research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exponential</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>IN the past decades, there has been much attention on dynamic neural networks due to their promising potential applications such as pattern recognition, signal processing, associative memories, and optimization. Some important results have been reported in [25], [26], and <ref type="bibr">[28]</ref>. Dynamic neural networks have been found to exhibit some complex and unpredictable behaviors including stable equilibria, periodic oscillations, bifurcation and chaotic attractors. As a special neural network, chaotic neural network has been successfully applied in combinational optimization <ref type="bibr" target="#b22">[12]</ref>, associative memory <ref type="bibr" target="#b24">[14]</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Difference between the leader agent's state and each following agent's state by using the leader-following algorithm proposed in this brief. (a) First dimension. (b) Second dimension.</figDesc><graphic coords="5,335.73,53.42,202.80,182.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Control input of each following agent. (a) Following agent 1. (b) Following agent 2. (c) Following agent 3. (d) Following agent 4. (e) Following agent 5.</figDesc><graphic coords="6,64.00,53.53,224.64,294.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Difference between the leader agent's state and each following agent's state by using the consensus algorithm proposed in [12]. (a) First dimension. (b) Second dimension.</figDesc><graphic coords="6,337.52,53.81,203.52,187.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>-2) T . The information exchange topology digraph G has the adjacency matrix A G = (a ij ) 6×6 : a 21 = 1.5, a 31 = 0.5, a 42 = 0.8, a 52 = 0.3, a 53 = 0.5, a 64 = 0.2, a 65 = 1.2, and a ij = 0 for the else element.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Difference between the leader manipulator's joint trajectory and each following manipulator's joint trajectory (by the proposed algorithm). (a) First dimension. (b) Second dimension. (c) Third dimension.</figDesc><graphic coords="7,72.72,151.43,202.56,272.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Difference between the leader manipulator's joint trajectory and each following manipulator's joint trajectory (by the algorithm proposed in [17]). (a) First dimension. (b) Second dimension. (c) Third dimension.</figDesc><graphic coords="7,335.73,53.74,202.56,285.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>H ∞ Synchronization of General Discrete-Time Chaotic Neural Networks With or Without Time Delays Donglian Qi, Meiqin Liu, Member, IEEE, Meikang Qiu, Senior Member, IEEE, and Senlin Zhang Abstract-This brief studies exponential H ∞ synchronization of a class of general discrete-time chaotic neural networks with external disturbance. On the basis of the drive-response concept and H ∞ control theory, and using Lyapunov-Krasovskii (or Lyapunov) functional, state feedback controllers are established to not only guarantee exponential stable synchronization between two general chaotic neural networks with or without time delays, but also reduce the effect of external disturbance on the synchronization error to a minimal H ∞ norm constraint. The proposed controllers can be obtained by solving the convex optimization problems represented by linear matrix inequalities. Most discrete-time chaotic systems with or without time delays, such as Hopfield neural networks, cellular neural networks, bidirectional associative memory networks, recurrent multilayer perceptrons, Cohen-Grossberg neural networks, Chua's circuits, etc., can be transformed into this general chaotic neural network to be H ∞ synchronization controller designed in a unified way. Finally, some illustrated examples with their simulations have been utilized to demonstrate the effectiveness of the proposed methods. Index Terms-Chaotic neural network, discrete-time system, drive-response conception, eigenvalue problem (EVP), H ∞ synchronization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I</head><label>I</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>, secure communication [21], chemical biology [8], etc. Since the pioneering work by Pecora and Carroll [23], originally proposed the drive-response (master-slave) concept Manuscript received September 22, 2009; revised May 4, 2010, May 8, 2010, May 10, 2010, and May 14, 2010; accepted May 14, 2010. Date of publication July 1, 2010; date of current version August 6, 2010. This work was supported in part by the National Natural Science Foundation of China, under Grants 60 874 050 and 60 702 023, by the Program for New Century Excellent Talents (NCET) in University, under Grant NCET-10-0692, by the Zhejiang Provincial Natural Science Foundation of China, under Grants Z1090 423 and Y106 010, by the Fundamental Research Funds for the Central Universities, under Grant 2009QNA4012, and by the Research Project of Zhejiang Provincial Education Department, under Grant Z200 909 334. D. Qi, M. Liu, and S. Zhang are with the College of Electrical Engineering, Zhejiang University, Hangzhou 310027, China (e-mail: qidl@zju.edu.cn; liumeiqin@zju.edu.cn; slzhang@zju.edu.cn). M. Qiu is with the Department of Electrical and Computer Engineering, University of Kentucky, Lexington, KY 40506 USA (e-mail: mqiu@engr.uky.edu).</figDesc><table /><note><p>Digital Object Identifier 10.1109/TNN.2010.2050904 1045-9227/$26.00 c 2010 IEEE</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Neural Networks for Pattern Recognition</title>
		<meeting><address><addrLine>Oxford, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford Univ. Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996-08">Aug. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bagging for Gaussian process regression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="1605" to="1610" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Some new results on neural network approximation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1069" to="1072" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian training of backpropagation networks by the hybrid Monte Carlo method</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<idno>CRG-TR-92-1</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. of Toronto</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive soft weight tying using Gaussian mixtures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="993" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A unifying view of sparse approximate Gaussian process regression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quiñonero-Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1939" to="1959" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<title level="m">Gaussian Processes for Machine Learning</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast forward selection to speed up sparse Gaussian process regression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Workshop AI Stats</title>
		<meeting>9th Int. Workshop AI Stats<address><addrLine>Key West, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-01">Jan. 2003</date>
			<biblScope unit="page" from="205" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse Gaussian processes using pseudo-inputs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Snelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 18</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1259" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Computing with infinite networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 9</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1069" to="1072" />
		</imprint>
	</monogr>
	<note>References</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust adaptive control of feedback linearizable MIMO nonlinear systems with prescribed performance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Bechlioulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Rovithakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2090" to="2099" />
			<date type="published" when="2008-09">Sep. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distributed discrete-time coordinated tracking with a time-varying reference state and limited communication</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1305" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Decentralized adaptive leaderfollower control of multimanipulator system with uncertain dynamics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-G</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 34th Annu. Conf. IEEE Ind</title>
		<meeting>34th Annu. Conf. IEEE Ind</meeting>
		<imprint>
			<publisher>Electron. Soc</publisher>
			<date type="published" when="2008-11">Nov. 2008</date>
			<biblScope unit="page" from="1608" to="1613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Observer-based consensus protocol for linear multiagent systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-G</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted to Automatica, for possible publication</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Leader-follower formation control of nonholonomic mobile robots with input constraints</title>
		<author>
			<persName><forename type="first">L</forename><surname>Consolinia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morbidib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prattichizzob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tosquesc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1343" to="1349" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective leadership and decision-making in animal groups on the move</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Couzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Franks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">433</biblScope>
			<biblScope unit="issue">7025</biblScope>
			<biblScope unit="page" from="513" to="516" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adaptive Approximation Based Control: Unifying Neural, Fuzzy and Traditional Adaptive Approximation Approaches</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Polycarpou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive neural control of uncertain MIMO nonlinear systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="674" to="692" />
			<date type="published" when="2004-05">May 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Observer-based leader-following formation control using onboard sensor information</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gustavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1457" to="1462" />
			<date type="published" when="2008-12">Dec. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributed observers design for leader-following control of multiagent networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bushnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tracking control for multiagent consensus with an active leader and variable topology</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1177" to="1182" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decentralized robust adaptive control for the multiagent system consensus problem using neural networks</title>
		<author>
			<persName><forename type="first">Z.-G</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybernet. B: Cybernet</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="636" to="647" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Containment control in mobile networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ferrari-Trecate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Egerstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buffa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1972" to="1975" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Neural Network Control of Robot Manipulators and Nonlinear Systems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yesildirek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Taylor and Francis</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Leader-following consensus control for multiagent systems under measurement noises</title>
		<author>
			<persName><forename type="first">C.-Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th IFAC World Congr</title>
		<meeting>17th IFAC World Congr</meeting>
		<imprint>
			<date type="published" when="2008-07">Jul. 2008</date>
			<biblScope unit="page" from="1528" to="1533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stable adaptive neural control scheme for nonlinear systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Polycarpou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="451" />
			<date type="published" when="1996-03">Mar. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multivehicle consensus with a time-varying reference state</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Control Lett</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="474" to="483" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Consensus seeking in multiagent systems under dynamically changing interaction topologies</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Beard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="655" to="661" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A survey of consensus problems in multiagent coordination</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Am</title>
		<meeting>Am</meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="page" from="1859" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptive neural network control for strict-feedback nonlinear systems using backstepping design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Hang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1835" to="1846" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
