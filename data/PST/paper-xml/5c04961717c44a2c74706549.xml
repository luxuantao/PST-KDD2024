<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Protein-Protein Interactions Prediction based on Ensemble Deep Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-05-22">May 22, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Long</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Information Sciences</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<postCode>400715</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guoxian</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Information Sciences</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<postCode>400715</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dawen</forename><surname>Xia</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Data Science and Information Engineering</orgName>
								<orgName type="institution">Guizhou Minzu University</orgName>
								<address>
									<postCode>550025</postCode>
									<settlement>Guiyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">College of National Culture and Cognitive Science</orgName>
								<orgName type="institution">Guizhou Minzu University</orgName>
								<address>
									<postCode>550025</postCode>
									<settlement>Guiyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Information Sciences</orgName>
								<orgName type="institution">Southwest University</orgName>
								<address>
									<postCode>400715</postCode>
									<settlement>Chongqing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Protein-Protein Interactions Prediction based on Ensemble Deep Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-05-22">May 22, 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">9F99A051EE48D08919CE0376C429E77C</idno>
					<idno type="DOI">10.1016/j.neucom.2018.02.097</idno>
					<note type="submission">Received date: 30 October 2017 Revised date: 3 February 2018 Accepted date: 26 February 2018 Preprint submitted to Neurocomputing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Protein-protein interactions</term>
					<term>Sequences of amino acids</term>
					<term>Deep neural networks</term>
					<term>Sequence descriptors</term>
					<term>Ensemble DNNs</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Protein-protein interactions (PPIs) are of vital importance to most biological processes. Plenty of PPIs have been identified by wet-lab experiments in the past decades, but there are still abundant uncovered PPIs. Furthermore, wet-lab experiments are expensive and limited by the adopted experimental protocols. Although various computational models have been proposed to automatically predict PPIs and provided reliable interactions for experimental verification, the problem is still far from being solved. Novel and competent models are still anticipated. In this study, a neural network based approach called EnsDNN (Ensemble Deep Neural Networks) is proposed to predict PPIs based on different representations of amino acid sequences. Particularly, EnsDNN separately uses auto covariance descriptor, local descriptor, and multi-scale continuous and discontinuous local descriptor, to represent and explore the pattern of interactions between sequentially distant and spatially close amino acid residues. It then trains deep neural networks (DNNs) with different configurations based on each descriptor. Next, EnsDNN integrates these DNNs into an ensemble predictor to leverage complimentary information of these descriptors and of DNNs, and to predict potential PPIs. EnsDNN achieves superior performance with accuracy of 95.29%, sensitivity of 95.12%, and precision of 95.45% on predicting PPIs of Saccharomyces cerevisiae. Results on other five independent PPI datasets also demonstrate that EnsDNN gets better prediction performance than other related comparing methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Protein-protein interactions (PPIs) play distinctly important roles in virtually all cellular processes, including signal transduction <ref type="bibr" target="#b0">[1]</ref>, immune response <ref type="bibr" target="#b1">[2]</ref>, and cell metabolism. Therefore, correctly identifying PPIs is not only helpful in understanding protein functions but also critical for structure-based drug design and disease treatment. Some high-throughput technologies have been invented for detecting PPIs, such as yeast two-hybrid, immune precipitation, X-ray crystallography, and protein chips <ref type="bibr" target="#b2">[3]</ref>. Nevertheless, there are some limitations in these wet-lab experiments based techniques, such as time intensive, high cost, and small coverage <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. These limitations have motivated the development of computational models to predict PPIs in large scale.</p><p>A number of computational approaches have been suggested to predict PPIs based on various data types <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>. These methods employ 3D structural information <ref type="bibr" target="#b8">[9]</ref>, Gene Ontology and annotations <ref type="bibr" target="#b9">[10]</ref>, phylogenetic profile, gene fusion <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref> and the interacting proteins co-evolution pattern <ref type="bibr" target="#b13">[14]</ref>. However, these approaches are not universal, their accuracy and reliability heavily depend on the prior knowledge of the collected proteins. In practice, the 3D structural of many proteins are unknown, Gene Ontology annotations of proteins are also incomplete <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>, and PPIs of many species are Many computational methods have been explored to predict PPIs directly based on amino acid sequences, such as support vector machine (SVM) with conventional auto covariance (AC) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, k-nearest neighbor (kNN) with local descriptor (LD) <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>, SVM with conjoint triad method <ref type="bibr" target="#b27">[28]</ref>, random forest (RF) with multi-scale continuous and discontinuous local descriptor (MCD) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, deep neural networks (DNNs) with amphiphilic pseudo amino acid composition descriptor (APAAC) <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>, and so on. Extensive experiments have proved that amino acid sequences data alone can be competent to identify new PPIs. Shen et al. <ref type="bibr" target="#b27">[28]</ref> grouped 20 standard amino acids into 7 classes according to their dipoles, volumes of the side chains, applied the conjoint triad method to extract feature from protein pairs, and then employed SVM to predict PPIs. This SVM based approach achieved a high accuracy of 83.9%. However, it does not take into account neighboring effect and PPIs generally exist in the non-continuous segments of amino acid sequences. Guo et al. <ref type="bibr" target="#b21">[22]</ref> applied the autocovariance (AC) method <ref type="bibr" target="#b22">[23]</ref> to discover the information in the segments of discontinuous amino acid sequences and obtained an accuracy of 86.55% on PPIs of Saccharomyces cerevisiae (S. cerevisiae). You et al. <ref type="bibr" target="#b28">[29]</ref> introduced a multi-scale continuous and discontinuous local feature descriptor to encode amino acid sequences. This descriptor hypothesizes that the segments of continuous amino acids with different segment lengths play important roles in identifying the interactions between proteins.</p><p>Then they used the Minimum Redundancy Maximum Relevancy criterion <ref type="bibr" target="#b32">[33]</ref>, which can reduce feature abundance and computation complexity, to select an optimal feature subset. Finally, they employed SVM to predict PPIs. This multi-scale continuous and discontinuous local feature descriptor based solution obtained a high accuracy of 91.36%. Du et al. <ref type="bibr" target="#b31">[32]</ref> employed the amphiphilic pseudo amino acid composition (APAAC) <ref type="bibr" target="#b30">[31]</ref> to extract features from amino acid sequences. After that, they took the extracted features of two respective proteins as inputs of two separate deep neural networks (DNNs) to predict PPIs. This DNNs based method obtained an accuracy of 92.5% on PPIs of S. cerevisiae.</p><p>Different descriptors can extract different feature information of interacting protein sequences. The feature information generated by these descriptors are complementary to each other. Thus, we advocate using a number of different descriptors, which can obtain more information than a single descriptor alone, for PPIs prediction <ref type="bibr" target="#b33">[34]</ref>. DNNs, a major recent advance in machine learning, can automatically learn a suitable representation of the raw data, discover high-level features, improve performance over traditional models, increase interpretability and provide additional understanding about the structure of the biological data <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>. Motivated by the characteristics of DNNs, we introduce a deep learning based approach called EnsDNN. Ens-DNN firstly employs the auto covariance descriptor (AC) <ref type="bibr" target="#b22">[23]</ref>, local descriptor(LD) <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> and multi-scale continuous and discontinuous local descriptor (MCD) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> to extract the interaction information of proteins from amino acid sequences, respectively. Then, EnsDNN uses these three feature sets as the inputs of 9 different and independent deep neural networks (DNNs) with different numbers of layers and neurons. After that, it takes the outputs of these 27 (9 DNNs × 3 descriptors) DNNs as inputs of a two-hidden layers neural network to produce the final ensemble prediction. EnsDNN not only combines the advantages of different descriptors, but also the diversity of 27 base DNNs, and thus produces a robust and competent ensemble predictor <ref type="bibr" target="#b36">[37]</ref>. We perform experiments on PPIs of S. cerevisiae <ref type="bibr" target="#b31">[32]</ref>, EnsDNN achieves 95.29% accuracy with 95.12% sensitivity and 95.45% precision. Experimental results on other five independent datasets: Caenorhabditis elegans (4013 interacting pairs), Escherichia coli (6954 interacting pairs), Homo sapiens (1412 interacting pairs), Helicobacter pylori (1420 interacting pairs), and Mus musculus (313 interacting pairs) also show that EnsDNN makes more accurate prediction than other related and competitive methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>In this section, we elaborate on the proposed EnsDNN approach for predicting PPIs based on amino acid sequences. Ens-DNN is consisted with the following three steps: (1) Encode the protein pairs interaction information into numeric vectors via the AC descriptor <ref type="bibr" target="#b22">[23]</ref>, LD descriptor <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> and MCD descriptor <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Feature vector extraction</head><p>Whether the extracted features are reliable or not can significantly affect the performance of PPIs prediction. Thus, how to effectively describe and encode the essential information of interacting protein pairs is a main challenge. To avoid the bias of using single descriptor alone, we use three representative and widely used feature descriptors (AC <ref type="bibr" target="#b22">[23]</ref>, LD <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>, MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Auto covariance descriptor (AC)</head><p>PPIs can be divided into four interaction modes: electrostatic, hydrophobic, steric and hydrogen bond <ref type="bibr" target="#b22">[23]</ref>. Seven physicochemical properties of amino acids are selected to reflect these interaction modes whenever possible. These properties include hydrophobicity (H 1 ) <ref type="bibr" target="#b38">[39]</ref>, hydrophilicity (H 2 ) <ref type="bibr" target="#b39">[40]</ref>, volumes of side chains of amino acids (VSC) <ref type="bibr" target="#b40">[41]</ref>, polarity (P 1 ) <ref type="bibr" target="#b41">[42]</ref>, polarizability (P 2 ) <ref type="bibr" target="#b42">[43]</ref>, solvent-accessible surface area <ref type="bibr" target="#b43">[44]</ref> and net charge index of side chains <ref type="bibr" target="#b44">[45]</ref>. Feature normalization can improve the accuracy and efficiency of mining algorithms on the data <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref>. Given that, we firstly normalized data with zero mean and unit standard deviation (SD) as follows:</p><formula xml:id="formula_0">P i j = P i, j -P j D j (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where P i, j is the j-th physicochemical property value for the i-th amino acid, P j is the mean of the j-th physicochemical property over 20 amino acids and D j is the corresponding standard deviation of the j-th physicochemical property. Then each protein sequence is translated into seven vectors with each amino acid represented by the normalized values. AC is a statistical tool proposed by Wold et al. <ref type="bibr" target="#b22">[23]</ref>, it was employed to transform amino acid sequences into uniform matrices. AC can account for the average interactions between residues, a certain lag apart throughout the entire sequence. To represent a protein sequence X with length L, the AC variables are computed as:</p><formula xml:id="formula_2">AC(lag, j) = 1 L -lag L-lag i=1 (X i j - 1 L L i=1 X i, j )×(X (i+lag), j - 1 L L i=1 X i, j ) (2)</formula><p>lag is the distance between residues, X i j is the j-th physicochemical property of the i-th amino acid of X. In this way, the number of AC variables can be calculated as D = lg × p, where p is the number of descriptors, which is set as 7 according to seven properties of amino acids and lg is the maximum lag(lag = 1, 2, ..., lg), which is set as 30 <ref type="bibr" target="#b21">[22]</ref>. After each protein sequence is represented by a vector of AC variables, a protein pair is characterized by concatenating the vectors of the two respective proteins. Finally, we can use a 420-dimensional vector to encode interacting (non-interacting) protein pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Multi-scale continuous and discontinuous local descriptor (MCD)</head><p>MCD is suggested by You et al. <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> to extract the interaction information of proteins. MCD firstly divides the entire amino acid sequences into a number of equal length segments and then uses a binary coding scheme to construct varying length segments. For example, "ACCLLACCAAALCCALLCACC-CALCA" contains 26 residues as shown in Figure <ref type="figure" target="#fig_1">2</ref>; MCD first divides this sequence into 5 equal length segments (denoted by S 1 , S 2 , S 3 , S 4 and S 5 ). Then it encodes the sequence using a 5-bit binary form with '1' and '0'. In each 5-bit binary, these combinations are written as 00001, 00010, 00011, 00100, 00101, 00110, 00111, • • • , 11100, 11101, and 11110. A protein sequence can be represented by 2 5 -2 sub-protein sequence segments. Here 0 or 1 denote one of the five equal length segments S 1 -S 5 is excluded or included in constructing the continuous and discontinuous regions, respectively. For instance, 00110 represents a continuous region constructed by S 3 and S 4 , 01010 <ref type="table" target="#tab_3">2 3 3 1 2 2 1 1 1 3 2 2 1 3 3 2 1 2 2 2 1 3 2</ref>  Protein sequence :</p><formula xml:id="formula_3">A C C E P T E D M A N U S C R I P T A C C L L A C C A A A L C C A L L C A C C C A L C A 1 2</formula><p>Group index of residue :</p><p>Ordinal number for 1 :</p><p>Ordinal number for 2 :</p><p>Ordinal number for 3 :</p><p>1-2 transitions:</p><p>2-3 transitions:</p><p>1-3 transitions:  </p><formula xml:id="formula_4">A, G, V C F, I, L, P M, S, T, Y H, N, Q, W K, R D, E</formula><p>denotes a discontinuous region constructed by S 2 and S 4 . These regions are illustrated in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>To reduce the complexity inherent in the representation of the 20 standard amino acids, MCD firstly divides them into 7 groups based on the dipoles and volumes of the side chains (See Table <ref type="table" target="#tab_0">1</ref>) <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27]</ref>. MCD extracts the interaction features of local protein sequences based on these 7 groups. For each sub-sequence, three descriptors, composition (C), transition (T) and distribution (D), are applied to describe its trait. C represents the proportion of each amino acid group; T represents the frequency with which amino acids in one group are followed by amino acids of another group; D measures the proportion of the chain length within which the first 25%, 50%, 75% and 100% of the amino acids of a particular group are located <ref type="bibr" target="#b47">[48]</ref>.</p><p>Then each sub-sequence is replaced by the index depending on its group.</p><p>For instance, protein sequence "ACCLLACCAAALCCALLCACCCALCA" is replaced by "12233122111322133212221321" based on divided amino acid groups as shown in Figure <ref type="figure" target="#fig_4">3</ref>. There are nine '1, eleven '2' and six '3' in this sequence. The composition for these three symbols is 9×100%/(9+11+6) = 34.61%, 11×100%/(9+11+6) = 42.31%, and 6 × 100%/(9 + 11 + 6) = 23.08%, respectively. There are 8 transitions from '1' to '2' or from '2' to '1' in this sequence, and the percentage frequency of these transitions is (8/25) × 100% = 32%. Similarly, we can calculate the transitions from '1' to '3' or '3' to '1', and transitions from '2' to '3' or '3' to '2' with (4/25) × 100% = 16% and (4/25) × 100% = 16%, respectively.</p><p>Next, MCD calculates the distribution of these three symbols. For example, there are 9 residues encoded as '1' in Figure <ref type="figure" target="#fig_4">3</ref>, the position of the first residue '1', the second residue '1' (25% × 9 ≈ 2), the fifth residue '1' (50% × 9 ≈ 5), the seventh residue '1' (75% × 9 ≈ 7), and the ninth residue <ref type="bibr">'</ref> For each continuous and discontinuous region, the three descriptors (C, T, D) are calculated and concatenated, and a total of 63 descriptors are generated: 7 for C, 21 (7 × 6/2) for T and 35 (7 × 5) for D. Then all descriptors from 30 (2 5 -2) segments are concatenated into a 1890-dimensional vector. Finally, MCD concatenates the numeric feature vectors of two individual proteins. Thus, a 3780-dimensional vector is constructed to characterize each protein pair and then used as input for DNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3.">Local descriptor (LD)</head><p>LD extracts feature in a more simple way than MCD. LD also groups 20 standard amino acids into 7 groups based on the dipoles and volumes of the side chains, as shown in Table <ref type="table" target="#tab_0">1</ref>, but it divides the entire protein sequence into 10 regions as shown in Figure <ref type="figure">4</ref> and extracts each segment information based on composition(C), transition(T), distribution(D) introduced in the previous subsection of MCD <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>. Each region can generate 63 attributes, 7 for C, 21 for T, and 35 for D. Thus, an entire protein sequence can be encoded by a 630-dimensional vector. Finally, it concatenates the two vectors of two individual proteins and obtains a 1260-dimensional vector to represent the information of pairwise proteins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Ensemble deep neural networks 2.2.1. Construct separate deep neural networks</head><p>Artificial neural network, inspired by the biological neural network that constitutes animal brains, consists of layers of interconnected nodes (neurons) <ref type="bibr" target="#b34">[35]</ref>. Each connection between neurons can transmit a signal to another neuron. The depth of a neural network corresponds to the number of hidden layers, and the width is the maximum number of neurons of its layers <ref type="bibr" target="#b34">[35]</ref>. Neural network with a large number (four or more) of hidden layers is called deep neural networks (DNNs) <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b49">50]</ref>. In general, a neural network feeds the data into the input layer, and then transforms these data in a nonlinear way through multiple hidden layers, and outputs the prediction by the output layer (See the left part of Figure <ref type="figure">5</ref> for example). Neurons of a hidden layer or output layer are connected to all neurons of the previous layer. Each neuron computes a weighted sum of its inputs and applies a nonlinear activation function to calculate its outputs f (x) (as shown in the right part of Figure <ref type="figure">5</ref>). The most popular activation function is the rectified linear unit (ReLU is a max(0, x) function that thresholds negative signals to 0 and passes through positive signals), which can accelerate model training. In this work, the loss is calculated by the cross entropy function, which can speed up the training and obtain better prediction results <ref type="bibr" target="#b50">[51]</ref>. The network is defined as: </p><formula xml:id="formula_5">H i1 = σ 1 (W i1 X i1 + b i1 )(i = 1, • • • , n) (<label>3</label></formula><formula xml:id="formula_6">)</formula><formula xml:id="formula_7">H i( j+1) = σ 1 (W i j H i j + b i j )( j = 1, • • • , h) (4)</formula><formula xml:id="formula_8">L = - 1 n n i=1 [y i ln(σ 2 (W ih H ih +b ih )+(1-y i )ln(1-σ 2 (W ih H ih +b ih ))] (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>where n is the number of PPIs for batch training. σ 1 is the activation function of ReLU, σ 2 is the activation function of output layer with sigmoid, X is the batch training inputs, H is the outputs of hidden layer, and y is the corresponding desired outputs. h is the depth of DNNs, and W is the weight matrix between the input layer and output layer, and b is the bias.</p><p>In this study, we individually construct 27 DNNs using Ten-sorFlow platform, as depicted in Figure <ref type="figure" target="#fig_0">1</ref>. Three types of feature vectors extracted by AC <ref type="bibr" target="#b22">[23]</ref>, LD <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> or MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> are separately used as the inputs for 9 independent neural networks with different configurations. These neural networks have different learning rates, batch sizes, and dropout rates. For each neural network, we use the mini-batch gradient descent <ref type="bibr" target="#b51">[52]</ref> and Adam algorithm <ref type="bibr" target="#b52">[53]</ref> to reduce the sensitivity to the specific choice of learning rate and to speed up training. In order to avoid overfitting, the dropout technique (the most common regularization) and the L1-norm, L2-norm are used at the same time. The activation of some neurons is randomly set to zero ("dropped out") during training in each forward pass, and intuitively results in an ensemble of different networks, whose predictions are averaged, as shown in Figure <ref type="figure" target="#fig_6">6</ref>. The dotted line means this neuron is dropout; in other words, this neuron will not be activated and calculated. We also use the batch normalization approach to reduce the dependency of training with the parameter initialization and overfitting, and to speed up training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Ensemble strategy</head><p>Aggregating the outputs of multiple predictors can generally improve the performance of a single predictor <ref type="bibr" target="#b36">[37]</ref>. However, to obtain a good aggregation effect, the individual predictors must be as accurate and diverse as possible. There are three commonly strategies to maintain the diversity: (1) using different algorithms to learn from the data, such as artificial neural network, support vector machine, decision tree and so on; (2) changing the internal structure of a given algorithm, for instance, the depth and width of the neural network, the number of trees in the decision tree classifier; (3) learning from different feature views <ref type="bibr" target="#b36">[37]</ref>. In this study, we use strategy ( <ref type="formula">2</ref>) and ( <ref type="formula" target="#formula_5">3</ref>) to maintain the diversity. In practice, DNNs is very sensitive to small changes and thus different configurations of base DNNs can result in diverse predictors. To fuse these predictors, Ens-DNN uses a two-hidden layers neural network to synergize their outputs and to predict PPIs. To further study the performance of EnsDNN under different numbers of based DNNs, we fuse different number of base DNNs and find that the performance is best and stable when the ensemble size is around 27, so we fuse 27 base DNNs. The flowchart of EnsDNN is shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental results and analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental setup</head><p>To quantitatively evaluate the performance of EnsDNN, we collected PPIs of S. cerevisiae used by Du et al. <ref type="bibr" target="#b31">[32]</ref> from the Database of Interacting Proteins (DIP) <ref type="bibr" target="#b53">[54]</ref>. This dataset contains 17257 positive protein pairs after removing protein pairs that contain a protein with fewer than 50 amino acids and 40% sequence identity <ref type="bibr" target="#b21">[22]</ref>. Selecting negative examples is very crucial for training a predictor for PPIs <ref type="bibr" target="#b48">[49]</ref>. The negative set was obtained by pairing proteins whose subcellular localizations are different. This selection should meet the following requirements <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b27">28]</ref>: (1) the non-interacting pairs cannot appear in the positive data set, and (2) the contribution of proteins in the negative set should be as harmonious as possible. Finally, 48594 negative pairs were generated based on these requirements. The final PPI dataset of S. cerevisiae consisted of 34514 protein pairs, where half were from the positive data set and the other were from the negative data set (randomly selected 17257 negative pairs from all negative pairs). Five independent PPI datasets, including Caenorhabditis elegans (4013 interacting pairs), Escherichia coli (6954 interacting pairs), Homo sapiens (1412 interacting pairs), Mus musculus (313 interacting pairs) and Helicobacter pylori (1420 interacting pairs) <ref type="bibr" target="#b37">[38]</ref>, which were used to evaluate previously proposed methods, were also collected to evaluate the performance of EnsDNN. These datasets are available at http://ailab.ahu.edu.cn:8087/DeepPPI/index.html. EnsDNN implemented using TensorFlow platform (https://www.tensorflow.org/). We separately implemented 27 DNNs as the base predictors and then constructed a two-hidden layers neural network to fuse the predicted outputs of these predictors. The flowchart of EnsDNN is shown in Figure <ref type="figure" target="#fig_0">1</ref>. The hyper-parameters of 27 base DNNs are differently specified to enlarge the diversity of these base predictors, and thus to produce accurate and robust consensus predictor. The best hyper-parameter configuration is data and application dependent, and models with different configurations can be evaluated on the test dataset. We summarized the recommended parameter setup of EnsDNN in Table <ref type="table" target="#tab_2">2</ref>. As to the parameter setup of the comparing methods, we used the grid search approach to obtain the optimal parameters. The optimal parameters are shown in 3. For Du et al. work <ref type="bibr" target="#b31">[32]</ref>, we obtained the information via http: //ailab.ahu.edu.cn:8087/DeepPPI/index.html. All the experiments were carried out on a desktop with Intel (R) Core (TM) i5-4590, 16 GB RAM and Win 7.</p><p>To comparatively evaluate the prediction performance of Ens-DNN, five-fold cross-validation is adopted. In other words, each PPI dataset is randomly divided into five equal subsets, and each subset is used as a testing set in turn, meanwhile the other four subsets are used as training set. We use the following metrics to measure the performance of these methods: overall prediction accuracy (ACC), recall (RE), specificity (SPE), precision (PE), matthews correlation coefficient (MCC), F 1 score values, and area under the receiver operating characteristic curve (AUC).  <ref type="bibr" target="#b31">[32]</ref> 92.58% ± 0.38% 94.21% ± 0.45% 90.95% ± 0.41% 94.41% ± 0.45% 85.41% ± 0.76% 92.55% ± 0.39% 97.55% ± 0.16% RF+MCD <ref type="bibr" target="#b29">[30]</ref> 89.15% ± 0.33% 90.00% ± 0.57% 88.10% ± 90.21% ± 0.61% 78.33% ± 0.67% 89.04% ± 0.31% 94.78% ± 0.21% SVM+LD <ref type="bibr" target="#b37">[38]</ref> 88.76% ± 0.37% 89.44% ± 0.27% 87.89% ± 0.45% 89.62% ± 0.30% 77.53% ± 0.53% 88.66% ± 0.28% 94.69% ± 0.31% kNN+LD <ref type="bibr" target="#b26">[27]</ref> 84.81% ± 0.37% 87.53% ± 0.14% 81.18% ± 0.84% 88.44% ± 0.18% 69.80% ± 0.71% 84.23% ± 0.47% 90.03% ± 0.31% SVM+AC <ref type="bibr" target="#b21">[22]</ref> 87.88% ± 0.56% 88.16% ± 0.90% 87.53% ± 0.59% 88.24% ± 1.02% 75.77% ± 1.12% 87.84% ± 0.53% 93.69% ± 0.33%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The first six metrics are defined as follows:</p><formula xml:id="formula_10">ACC = T P + T N T P + T N + FP + FN (6) RE = T P T P + FN (7) S PE = T N T N + FP (8) PE = T P T P + FP (9) MCC = T P × T N -FP × FN √ (T P + FP)(T P + FN)(T N + FP)(T N + FN)<label>(10)</label></formula><formula xml:id="formula_11">F 1 = 2T P 2T P + FP + FN (<label>11</label></formula><formula xml:id="formula_12">)</formula><p>where T P (true positive) is the number of true PPIs that are correctly predicted, T N (true negative) is the number of true non-interacting pairs that are correctly predicted, FP (false positive) is the number of the wrongly predicted interacting pairs, and FN (false negative) is the number of the true interacting pairs that are failed to be predicted. MCC is a measure of the quality of binary classifications, which is a correlation coefficient between the observed and predicted results. MCC equal to 0 means completely random prediction, -1 means completely wrong prediction and 1 means perfect prediction. F 1 score is a harmonic average of precision and recall. Receiver operating characteristic curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. This curve is the plot of the true positive rate versus the false positive rate under different thresholds. AUC is the area under the curve and the value of AUC can be used to compare predictors. A larger AUC indicates a better predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Results on PPIs of S. cerevisiae</head><p>To evaluate the robustness of EnsDNN, five-fold crossvalidation is employed to reduce the impact of data dependency and to improve the reliability of the results. Table <ref type="table" target="#tab_4">4</ref> reports the results of EnsDNN on five individual folds (fold 1-5) and the overall results of five folds. From Table <ref type="table" target="#tab_4">4</ref>, we can see that the overall accuracy of EnsDNN is ranging from 94.86% to 95.31%. In order to comprehensively evaluate the performance of Ens-DNN, the results with respect to other six evaluation metrics (including RE, S PE, PE, MCC, F 1 and AUC) are also included. EnsDNN achieves competent prediction performance with an average sensitivity of 95.12%, specificity of 95.48%, precision of 95.45%, MCC of 90.59%, F 1 of 95.29% and AUC of 97.00%.</p><p>We compare EnsDNN against the approaches proposed by Guo et al. <ref type="bibr" target="#b21">[22]</ref>, Yang et al. <ref type="bibr" target="#b26">[27]</ref>, Zhou et al. <ref type="bibr" target="#b37">[38]</ref>, You et al. <ref type="bibr" target="#b29">[30]</ref>, and Du et al. <ref type="bibr" target="#b31">[32]</ref> and reveal their results in Table <ref type="table" target="#tab_4">4</ref>. These comparing approaches were introduced in the Section 1, they separately used AC <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, LD <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>, MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> or APAAC <ref type="bibr" target="#b30">[31]</ref> to encode amino acid sequences, and then made prediction using SVM, k-nearest neighbor (kNN), random forest (RF) or DNNs to predict PPIs. From Table <ref type="table" target="#tab_4">4</ref>, we can observe that EnsDNN generally outperforms these state-of-the-art PPIs predictors. That is because EnsDNN resorts to different classifiers and feature representations. EnsDNN has higher RE, PE, SPE, MCC, F 1 than other comparing methods. Based on these results, we can conclude that EnsDNN is more effective than other comparing methods in predicting PPIs. These observations can be attributed to that the adopted three feature descriptors of amino acid sequences can explore more patterns of PPIs and the base DNNs trained on these feature descriptors are complementary to each other.</p><p>To show the effectiveness and non-redundancy of our ensemble strategy, we designed two variants of EnsDNN. One of them is EnsDNN-Con, the other is EnsDNN-Sep. EnsDNN-Con firstly concatenates three feature representations (AC <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, LD <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> and MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>), and then takes the concatenated features as input of a dropout network <ref type="bibr" target="#b54">[55]</ref>. The hidden layers for this network fixed as 2048-1024-256-32, which means 4 hidden layers with 2048, 1024, 256, 32 neurons, respectively. EnsDNN-Sep has three DNNs, it separately takes AC <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, LD <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> and MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> feature representation as inputs. The hidden layers for these three DNNs are fixed as 256-128-4, 512-128-4, and 1024-512-128-4, respectively. After that, it concatenates the outputs of these three DNNs to generate 12 neurons as the input of a dropout DNNs. The average results of five-fold cross validation are also reported in  base DNNs with dropout for ensemble and achieves the best performance. These results prove that although the dropout is also an ensemble method, using it alone cannot effectively and adequately extract the complementarity of different descriptors. In contrast, using the explicit ensemble strategy can more adequately employ the complementarity and diversity of base DNNs, and thus improve the performance of EnsDNN.</p><p>To further investigate the contribution of using different feature descriptors, we separately trained 27 DNNs based on AC <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, LD <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>, and MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, and then integrated these DNNs in the same way as EnsDNN. We report the results in Figure <ref type="figure">7</ref>. From the figure, we can observe that the LD <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref> descriptor is better than AC <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> descriptor, because LD has more features than AC, it can encode more interactions information. MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> descriptor is only 0.23% better than LD descriptor on ACC. That is because they are similar. From Figure <ref type="figure">7</ref>, we can find that EnsDNN+AC+LD+MCD performs significantly better than its cousins that use single type of feature sets extracted by AC, LD, or MCD. From the results in this Figure , we can conclude that these three descriptors are complementary to each other.</p><p>To study the performance of EnsDNN under different numbers of base DNNs, we fixed the number of base DNNs as 3, 9, 12, • • • , 45, respectively. The results of EnsDNN under each fixed number of DNNs are plotted in Figure <ref type="figure" target="#fig_7">8</ref>. We can see the performance of EnsDNN steadily increases as the number of base DNNs increasing and keeps relatively stable when the number of base DNNs is ≥ 27. To balance the efficiency and effectiveness, we fix the number of base DNNs as 27 for experiments.</p><p>Meanwhile, to further investigate the contribution of using  an ensemble predictor to fuse the outputs of 27 DNNs. We integrated the outputs of 27 base DNNs by using averaging, the results are reported in Figure <ref type="figure">9</ref>. From Figure <ref type="figure">9</ref>, we can observe that EnsDNN has better performance than averaging across all evaluation metrics. The reason is that the averaging method equally treats the outputs of 27 base DNNs, it may be misled by some low quality base DNNs. In contrast, by using two additional layers to fuse the outputs of these base DNNs, EnsDNN can assign different weights to them. From these results, we can conclude that the additional two layers for fusing DNNs can improve the performance of prediction. We also report the training times of different comparing methods in Table <ref type="table" target="#tab_8">5</ref>. From Table <ref type="table" target="#tab_8">5</ref>, we can observe that EnsDNN takes the most time for training, but it has the highest prediction performance across all evaluation metrics, except AUC. That is because EnsDNN has to train 27 base DNNs and fuse them. As well as that, it trains DNNs based on MCD <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> feature representation, which encodes amino acid sequences by a 3780-dimensional numeric vector and asks for DNNs with 4 or 5 hidden layers. The more hidden layers, the more training parameters and training time are. kNN has the smallest training time but its performance is the lowest. Since SVM has a high time complexity, SVM+LD also takes a long time for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results on independent datasets</head><p>To further evaluate the practical prediction ability of EnsDNN. We firstly trained EnsDNN using PPIs of S. cerevisiae dataset and then applied it on five independent datasets, including C. elegans (4013 interacting pairs), E. coli (6954 interacting pairs), Homo sapiens (1412 interacting pairs), H. pylori (1420 interacting pairs), and M. musculus (313 interacting pairs). The prediction results are shown in Table <ref type="table" target="#tab_9">6</ref>. From Table <ref type="table" target="#tab_9">6</ref>, we can see that the accuracy of EnsDNN on C. elegans, E. coli, H. sapiens, H. pylori, and M. musculus are 93.22%, 95.10%, 95.00%, 89.14%, and 94.06%, respectively. EnsDNN obtains larger accuracy than DeepPPI <ref type="bibr" target="#b31">[32]</ref> and SVM+LD <ref type="bibr" target="#b37">[38]</ref> on E. coil, H. sapiens, and M. musculus. The accuracy of EnsDNN on other two datasets is slightly lower than that of DeepPPI, but still much higher than that of SVM+LD. We can see the accuracy is over 93% on C.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>In this paper, we proposed an effective and accurate sequencebased approach called EnsDNN to predict PPIs. EnsDNN firstly extract the feature information of protein sequences by AC descriptor <ref type="bibr" target="#b22">[23]</ref>, LD descriptor <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27]</ref>, and MCD descriptor <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, respectively. These descriptors can complementarily capture the interactions information from the continuous and discontinuous amino acid segments. Three types of interactions feature sets were obtained based on these three descriptors, respectively. Then, nine independent DNNs with different configurations were trained on each feature set, resulting in 27 DNNs. Finally, we adopted a two-hidden layers neural network to integrate these DNNs. Multiple metrics were applied to evaluate the performance of EnsDNN. Meanwhile, PPIs of five independent species were further used to assess the practical prediction ability of EnsDNN. The experimental results showed that EnsDNN generally outperforms current machine learning based PPIs predictors and fusing these three descriptors can complement each other very well.</p><p>There are three factors contribute to the competitive performance of EnsDNN. The first factor is that we utilized three descriptors to extract feature information of amino acid sequences, which can capture more interactions information than a single descriptor alone. The second factor is that we used nine DNNs with different configurations for each descriptor to generate diverse base DNNs, and the diversity among base DNNs improved the robustness and accuracy of EnsDNN. The third factor is that we integrated the predicted outputs of base DNNs by a two-hidden layers neural network to nonlinearly fuse these base DNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgement</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Flowchart of EnsDNN for predicting protein-protein interactions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 2 )</head><label>2</label><figDesc>Train nine individual DNNs based on each of the three types of vectors. (3) Ensemble the twenty-seven individual DNNs via a two-hidden layers neural network. The flowchart of EnsDNN is shown in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustrative diagram for constructing continuous and discontinuous descriptor regions for a hypothetical protein sequence using 5-bit binary form. Each protein sequence is divided into 30 (2 5 -2) sub-sequences (S 1 -S 30 ) of varying length to represent multi-overlapping continuous or discontinuous segments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sequence of a hypothetic protein indicating the construction of composition, transition and distribution description descriptors of a protein region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: Schematic diagram for constructing ten descriptor regions (A-J) for a hypothetical protein sequence. Adapted from Tong et al. [25] and Davies et al. [49]. The regions (A-D) and (E-F) are respectively generated by dividing the whole sequence into four equal regions and two equal regions. The region G, H, I, and J stand for the central 50%, the first 75%, the final 75%, and the central 75% of the entire sequence, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The structure of a deep neural network with AC descriptor and the dropout technique.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Prediction performance under different numbers of base DNNs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Division of amino acids into seven groups based on the dipoles and volumes of the side chains.</figDesc><table><row><cell>Group 1</cell><cell>Group 2</cell><cell>Group 3</cell><cell>Group 4</cell><cell>Group 5</cell><cell>Group 6</cell><cell>Group 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1' (100% × 9 ≈ 9) in the encoded sequence are 1, 6, 11, 19 and 26, respectively. Thus D descriptor for '1' is: (1/26 × 100% = 3.84%), (2/26 × 100% = 7.69%), (5/26 × 100% = 19.23%), (7/26 × 100% = 26.92%) and (9/26 × 100% = 34.62%), respectively. Similarly, the D descriptor for '2' and '3' are 7.69%, 26.92%, 53.85%, 76.92%, 96.15% and 15.38%, 19.23%, 46.15%, 65.39%, 92.31%, respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Recommended parameters of DNNs in the experiments.</figDesc><table><row><cell>Name</cell><cell>Range</cell><cell>AC</cell><cell cols="2">Recommendation LD</cell><cell>MCD</cell></row><row><cell>Learning rate</cell><cell>1,0.1,0.001,0.0001,0.0007</cell><cell>0.0007</cell><cell>0.001</cell><cell cols="2">0.0003</cell></row><row><cell>Weight initialization</cell><cell>uniform, normal, lecun uniform, glorot normal, glorot uniform</cell><cell cols="4">glorot normal glorot normal glorot normal</cell></row><row><cell>Per-parameter adaptive learning rate</cell><cell>SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>Activation function</cell><cell cols="2">relu, tanh, sigmoid, softmax, softplus, relu</cell><cell>relu</cell><cell>relu</cell></row><row><cell>Dropout rate</cell><cell>0.5, 0.4, 0.7</cell><cell>0.5, 0.4</cell><cell>0.5, 0.7</cell><cell cols="2">0.5, 0.7</cell></row><row><cell>Depth</cell><cell>2, 3, 4, 5, 6, 7, 8 ,9</cell><cell>2, 3, 4</cell><cell>3, 4, 5</cell><cell cols="2">4, 5, 6, 7, 9</cell></row><row><cell>Width</cell><cell>2 2 , 2 3 , 2 4 , 2 5 , 2 6 , 2 7 , 2 8 , 2 9 , 2 10 , 2 11</cell><cell>2 2 , 2 3 , 2 4 , 2 5 , 2 6 , 2 7 , 2 8</cell><cell>2 2 ,2 3 ,2 4 ,2 5 , 2 6 , 2 7 , 2 8 , 2 9 ,</cell><cell cols="2">2 2 , 2 3 , 2 4 , 2 5 , 2 6 , 2 7 , 2 8 , 2 9 , 2 10 , 2 11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Parameter setup for comparing methods.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">Parameters</cell><cell></cell></row><row><cell></cell><cell>C</cell><cell>γ</cell><cell></cell><cell>kernel</cell></row><row><cell>SVM+AC [22]</cell><cell>32768.0</cell><cell cols="2">0.074325444687670064</cell><cell>poly</cell></row><row><cell></cell><cell>n neighbors</cell><cell>weights</cell><cell>algorithm</cell><cell>p</cell></row><row><cell>kNN+LD [27]</cell><cell>3</cell><cell>distance</cell><cell>auto</cell><cell>1</cell></row><row><cell></cell><cell>C</cell><cell>γ</cell><cell></cell><cell>kernel</cell></row><row><cell>SVM+LD [38]</cell><cell>3.1748021</cell><cell cols="2">0.07432544468767006</cell><cell>rbf</cell></row><row><cell></cell><cell>n estimators</cell><cell>max features</cell><cell>criterion</cell><cell>bootstrap</cell></row><row><cell>RF+MCD [30]</cell><cell>5000</cell><cell>auto</cell><cell>gini</cell><cell>True</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Results of five-fold cross validation on PPIs of S. cerevisiae.</figDesc><table><row><cell>Method</cell><cell></cell><cell>ACC</cell><cell>PE</cell><cell>RE</cell><cell>SPE</cell><cell>MCC</cell><cell>F 1</cell><cell>AUC</cell></row><row><cell></cell><cell>fold 1</cell><cell>95.31%</cell><cell>95.31%</cell><cell>95.26%</cell><cell>95.35%</cell><cell>90.61%</cell><cell>95.29%</cell><cell>96.89%</cell></row><row><cell></cell><cell>fold 2</cell><cell>94.86%</cell><cell>94.24%</cell><cell>95.33%</cell><cell>94.40%</cell><cell>89.72%</cell><cell>94.78%</cell><cell>97.19%</cell></row><row><cell>EnsDNN</cell><cell>fold 3</cell><cell>96.00%</cell><cell>96.50%</cell><cell>95.50%</cell><cell>96.51%</cell><cell>92.01%</cell><cell>96.00%</cell><cell>97.19%</cell></row><row><cell></cell><cell>fold 4</cell><cell>95.19%</cell><cell>96.11%</cell><cell>94.35%</cell><cell>96.06%</cell><cell>90.40%</cell><cell>95.22%</cell><cell>97.15%</cell></row><row><cell></cell><cell>fold 5</cell><cell>95.10%</cell><cell>95.10%</cell><cell>95.15%</cell><cell>95.06%</cell><cell>90.21%</cell><cell>95.12%</cell><cell>96.60%</cell></row><row><cell></cell><cell></cell><cell>95.29% ± 0.43%</cell><cell>95.45% ± 0.89%</cell><cell>95.12% ± 0.45%</cell><cell>95.48% ± 0.82%</cell><cell>90.59% ± 0.86%</cell><cell>95.29% ± 0.44%</cell><cell>97.00% ± 0.26%</cell></row><row><cell>EnsDNN-Con EnsDNN-Sep DNNs+APAAC</cell><cell></cell><cell>90.68% ± 0.55% 91.19% ± 0.57%</cell><cell>91.19% ± 2.22% 90.41% ± 1.81%</cell><cell>90.14% ± 2.44% 92.23% ± 1.02%</cell><cell>91.19% ± 2.67% 90.17% ± 2.14%</cell><cell>81.43% ± 1.06% 82.44% ± 1.10%</cell><cell>90.62% ± 0.55% 91.29% ± 0.48%</cell><cell>96.45% ± 0.37% 96.59% ± 0.19%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>. From</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 ,</head><label>4</label><figDesc>we can observe that the performance of EnsDNN is better than EnsDNN-Con and EnsDNN-Sep. EnsDNN-Con has relatively lower performance among these three methods. EnsDNN-Con only uses single DNNs with dropout, it cannot adequately extract the complementarity of different descriptors. The performance of EnsDNN-Sep is better than EnsDNN-Con, except PE and SPE. That is because EnsDNN-Sep uses three DNNs with dropout, it can extract more complementarity of different descriptors than EnsDNN-Con. EnsDNN trains 27</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Comparison of training times of different comparing methods. Comparison of the prediction performance between averaging 27 base DNNs and fusing 27 base DNNs by two-hidden layers neural network. elegans, E. coli, H. sapiens and M. musculus, while the accuracy on H. pylori is only 89.14%. The reason is that S. cerevisiae has closer relationship with C. elegans, H. sapiens and M. musculus than H. pylori. The prediction results show that EnsDNN is capable of predicting PPIs of the other species based on PPIs of another species, and it holds good generalization ability.</figDesc><table><row><cell></cell><cell></cell><cell>Method</cell><cell cols="2">EnsDNN</cell><cell cols="2">DNNs+APAAC [32]</cell><cell>RF+MCD [30]</cell><cell>SVM+LD [38]</cell><cell>kNN+LD [27]</cell><cell>SVM+AC [22]</cell></row><row><cell></cell><cell cols="2">Times(seconds)</cell><cell></cell><cell>23400</cell><cell>519</cell><cell></cell><cell>1341</cell><cell>18820</cell><cell>488</cell><cell>6925</cell></row><row><cell>98.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>96.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>94.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>92.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>90.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>88.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>86.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>84.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>82.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>80.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>78.00%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ACC</cell><cell>PE</cell><cell>RE</cell><cell>SPE</cell><cell>MCC</cell><cell>F1</cell><cell>AUC</cell></row><row><cell></cell><cell></cell><cell cols="2">DNNs+Averaging</cell><cell>EnsDNN</cell><cell></cell><cell></cell></row><row><cell>Figure 9:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Prediction results on five independent PPI datasets, PPIs of S. cerevisiae are used as the training set.</figDesc><table><row><cell>Species</cell><cell>Test pairs</cell><cell></cell><cell>ACC</cell><cell></cell></row><row><cell></cell><cell></cell><cell>EnsDNN</cell><cell>DNNs+APAAC [32]</cell><cell>SVM+LD [38]</cell></row><row><cell>C. elegans</cell><cell>4013</cell><cell>93.22%</cell><cell>94.84%</cell><cell>75.73%</cell></row><row><cell>E. coli</cell><cell>6984</cell><cell>95.10%</cell><cell>92.19%</cell><cell>71.24%</cell></row><row><cell>H. sapiens</cell><cell>1412</cell><cell>95.00%</cell><cell>93.77%</cell><cell>76.27%</cell></row><row><cell>H. pylori</cell><cell>1420</cell><cell>89.14%</cell><cell>93.66%</cell><cell>75.87%</cell></row><row><cell>M. musculus</cell><cell>313</cell><cell>94.06%</cell><cell>91.37%</cell><cell>76.68%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported by Natural Science Foundation of China (61741217, 61402378 and 61762020), Natural Science Foundation of CQ CSTC (cstc2016jcyjA0351), Science and Technology Foundation of Guizhou (QKHJC20161076), Science and Technology Top-notch Talents Support Project of Colleges and Universities in Guizhou (QJHKY2016065), Fundamental Research Funds for the Central Universities of China (2362015XK07).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Uncovering signal transduction networks from high-throughput data by integer linear programming</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aihara</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkn145</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Immunoprecipitation procedures</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0091-679X(08)61549-6</idno>
	</analytic>
	<monogr>
		<title level="j">Methods Cell Biol</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page">449</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Global analysis of protein activities using proteome chips</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilgin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bangham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casamayor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bertone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bidlingmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Houfek</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1062191</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="issue">5537</biblScope>
			<biblScope unit="page" from="2101" to="2105" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A comprehensive analysis of protein-protein interactions in Saccharomyces cerevisiae</title>
		<author>
			<persName><forename type="first">P</forename><surname>Uetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Giot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cagney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Mansfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Judson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lockshon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pochart</surname></persName>
		</author>
		<idno type="DOI">10.1038/35001009</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">403</biblScope>
			<biblScope unit="issue">6770</biblScope>
			<biblScope unit="page" from="623" to="627" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Algorithmic approaches to protein-protein interaction site prediction, Algorithms for</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Aumentado-Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Istrate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Murgita</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13015-015-0033-9</idno>
	</analytic>
	<monogr>
		<title level="j">Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Protein classification with imbalanced data</title>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aihara</surname></persName>
		</author>
		<idno type="DOI">10.1002/prot.21870</idno>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1125" to="1132" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discovering functional interdependence relationship in PPI networks for protein complex identification</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBME.2010.2093524</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="899" to="908" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deciphering protein-protein interactions. Part II. Computational methods to predict protein and domain interaction partners</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Shoemaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Panchenko</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.0030043</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Prediction of proteinprotein interactions by docking methods</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J E</forename><surname>Sternberg</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0959-440X(02)00285-3</idno>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Structural Biology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An integrated approach to the prediction of domain-domain interactions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2105-7-269</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting protein function and protein-protein interactions from genome sequences</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Marcotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Yeates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eisenberg</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.285.5428.751</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="issue">5428</biblScope>
			<biblScope unit="page" from="751" to="753" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protein interaction maps for complete genomes based on gene fusion events</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Enright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Iliopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Kyrpides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ouzounis</surname></persName>
		</author>
		<idno type="DOI">10.1038/47056</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">402</biblScope>
			<biblScope unit="issue">6757</biblScope>
			<biblScope unit="page" from="86" to="90" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Independent component analysis-based penalized discriminant method for tumor classification using gene expression data</title>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btl190</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1855" to="1862" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Co-evolutionary analysis of domains in interacting proteins reveals insights into domaindomain interactions mediating protein-protein interactions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jothi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Cherukuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tasneem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Przytycka</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmb.2006.07.072</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">861</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting new GO annotations of proteins by bi-random walks on a hybrid graph</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newgoa</forename></persName>
		</author>
		<idno type="DOI">10.1109/TCBB.2017.2715842</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Computational Biology and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">NegGOA: negative GO annotations selection using ontology structure</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btw366</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">2996</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short report</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Mungall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Blake</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1002386</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1002386</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Predicting hub genes associated with cervical cancer through gene co-expression networks</title>
		<author>
			<persName><forename type="first">S.-P</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCBB.2015.2476790</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="35" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tumor clustering using nonnegative matrix factorization with gene selection</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Z</forename><surname>Kong</surname></persName>
		</author>
		<idno type="DOI">10.1109/TITB.2009.2018115</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="607" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">SFAPS: an R package for structure/function analysis of protein sequences based on informational spectrum method</title>
		<author>
			<persName><forename type="first">S.-P</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymeth.2014.08.004</idno>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="212" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Prediction of protein-protein interactions based on protein-protein correlation using least squares regression</title>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.2174/1389203715666140724084019</idno>
	</analytic>
	<monogr>
		<title level="j">Current Protein and Peptide Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="553" to="560" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using support vector machine combined with auto covariance to predict protein-protein interactions from protein sequences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkn159</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3025" to="3030" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dna and peptide sequences and chemical processes multivariately modelled by principal component analysis and partial least-squares projections to latent structures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sjrstrm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rnnar</surname></persName>
		</author>
		<idno type="DOI">10.1016/0003-2670(93)80437-P</idno>
	</analytic>
	<monogr>
		<title level="j">Analytica Chimica Acta</title>
		<imprint>
			<biblScope unit="volume">277</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="253" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimizing amino acid groupings for GPCR classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Secker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Timmis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Flower</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btn382</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="1980" to="1986" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Prediction of protein allergenicity using local description of amino acid sequence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Tammi</surname></persName>
		</author>
		<idno type="DOI">10.2741/3138</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Bioscience A Journal &amp; Virtual Library</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">6072</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Computer prediction of allergen proteins from sequence-derived protein structural and physicochemical properties</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Ung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.molimm.2006.02.010</idno>
	</analytic>
	<monogr>
		<title level="j">Molecular Immunology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="514" to="520" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Prediction of protein-protein interactions from protein sequence using local descriptors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gui</surname></persName>
		</author>
		<idno type="DOI">10.2174/092986610791760306</idno>
	</analytic>
	<monogr>
		<title level="j">Protein &amp; Peptide Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1085</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions based only on sequences information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0607879104</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4337" to="4441" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Prediction of protein-protein interactions from amino acid sequences using a novel multi-scale continuous and discontinuous feature set</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2105-15-S15-S9</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">S15</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions from primary protein sequences using a novel multi-scale local feature representation scheme and the random forest</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0125811</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">125811</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using amphiphilic pseudo amino acid composition to predict enzyme subfamily classes</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chou</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/bth466</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Boosting Prediction of Protein-Protein Interactions with Deep Neural Networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepppi</forename></persName>
		</author>
		<idno type="DOI">10.1021/acs.jcim.7b00028</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information &amp; Modeling</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2005.159</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1226</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mining the bladder cancer-associated genes by an integrated strategy for the construction and analysis of differential co-expression networks</title>
		<author>
			<persName><forename type="first">S.-P</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2164-16-S3-S4</idno>
	</analytic>
	<monogr>
		<title level="j">BMC genomics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep learning for computational biology</title>
		<author>
			<persName><forename type="first">C</forename><surname>Angermueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Prnamaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Parts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Stegle</surname></persName>
		</author>
		<idno type="DOI">10.15252/msb.20156651</idno>
	</analytic>
	<monogr>
		<title level="j">Molecular Systems Biology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">878</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Systematic theory of neural networks for pattern recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Google Scholar</publisher>
			<pubPlace>China</pubPlace>
		</imprint>
	</monogr>
	<note>Publishing House of Electronic Industry</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural network ensembles: evaluation of aggregation algorithms</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Granitto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Verdes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Ceccatto</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2004.09.006</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="162" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Prediction of protein-protein interactions using local description of amino acid sequence</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-22456-0_37</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Computer &amp; Information Science</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="254" to="262" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Contribution of hydrophobic interactions to the stability of the globular conformation of proteins</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tanford</surname></persName>
		</author>
		<idno type="DOI">10.1021/ja00881a009</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Chemical Society</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="4240" to="4247" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Prediction of protein antigenic determinants from amino acid sequences</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Hopp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Woods</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.78.6.3824</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3824</biblScope>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Local interactions as a structure determinant for protein molecules: II</title>
		<author>
			<persName><forename type="first">W</forename><surname>Krigbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Komoriya</surname></persName>
		</author>
		<idno type="DOI">10.1016/0005-2795(79)90498-7</idno>
	</analytic>
	<monogr>
		<title level="j">Biochimica et Biophysica Acta (BBA)-Protein Structure</title>
		<imprint>
			<biblScope unit="volume">576</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="204" to="228" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Amino acid difference formula to help explain protein evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grantham</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.185.4154.862</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">4154</biblScope>
			<biblScope unit="page" from="862" to="864" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The structural dependence of amino acid hydrophobicity parameters</title>
		<author>
			<persName><forename type="first">M</forename><surname>Charton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I</forename><surname>Charton</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-5193(82)90191-6</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Theoretical Biology</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="644" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Hydrophobicity of amino acid residues in globular proteins</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Geselowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Lesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Zehfus</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.4023714</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<biblScope unit="issue">4716</biblScope>
			<biblScope unit="page" from="834" to="838" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Genetic algorithm-based virtual screening of combinative mode for peptide/protein</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Chimica Sinica</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="691" to="697" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Data mining: A preprocessing engine</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Al</forename><surname>Shalabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shaaban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kasasbeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="735" to="739" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Normalized feature vectors: a novel alignment-free sequence comparison method based on the numbers of adjacent amino acids</title>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCBB.2013.10</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Computational Biology and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="457" to="467" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>TCBB)</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Prediction of protein folding class using global description of amino acid sequence</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dubchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Muchnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Holbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.92.19.8700</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">8700</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Protein-protein interaction as a predictor of subcellular location</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ragan</surname></persName>
		</author>
		<idno type="DOI">10.1186/1752-0509-3-28</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Systems Biology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Radial basis probabilistic neural networks: Model and application</title>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1142/S0218001499000604</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">07</biblScope>
			<biblScope unit="page" from="1083" to="1101" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Michael</surname></persName>
		</author>
		<ptr target="http://neuralnetworksanddeeplearning.com/index.html" />
		<title level="m">Neural networks and deep learning</title>
		<imprint>
			<date type="published" when="2017-10-30">Oct 30, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">An overview of gradient descent optimization algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04747</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">DIP, the Database of Interacting Proteins: a research tool for studying cellular networks of protein interactions</title>
		<author>
			<persName><forename type="first">I</forename><surname>Xenarios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Salwnski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Higney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eisenberg</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/30.1.303</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">303</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A review on machine learning principles for multi-view biological data integration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ngom</surname></persName>
		</author>
		<idno type="DOI">10.1093/bib/bbw113</idno>
	</analytic>
	<monogr>
		<title level="j">Briefings in bioinformatics</title>
		<imprint>
			<biblScope unit="page">113</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
