<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Error-Control Coding for Physical-Layer Secrecy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Member IEEE, Masahito Hayashi, Senior Member IEEE</roleName><forename type="first">Matthieu</forename><surname>Bloch</surname></persName>
							<email>matthieu.bloch@ece.gatech.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<postCode>30332</postCode>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Mathematics</orgName>
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<postCode>464-8602</postCode>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Thangaraj</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<postCode>30332</postCode>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Indian Institute of Technology Madras (IIT Madras)</orgName>
								<address>
									<postCode>600036</postCode>
									<settlement>Chennai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Quantum Technologies</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>117543</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Error-Control Coding for Physical-Layer Secrecy</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3BBC9EB6B1560D19CA8CD8E48D7B379D</idno>
					<idno type="DOI">10.1109/JPROC.2015.2463678</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Channel resolvability</term>
					<term>error-control coding</term>
					<term>physical- layer security</term>
					<term>privacy amplification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How to design good wiretap codes? This paper investigates the challenges posed by the design of wiretap coding, often using error-correcting codes as core component, creating new design challenges.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The emergence of wireless communication networks has profoundly affected every aspect of our modern societies. By allowing access to information from virtually anywhere at anytime, wireless devices have not only increased the efficiency of existing infrastructures but also fostered the emergence of new services and systems, ranging from electronic payment to implanted medical devices. However, this seamless connectivity also opens numerous vulnerabilities that are causing growing public concern about secrecy and privacy. As an increasing amount of sensitive information is now conveyed through wireless networks, from financial and medical records to travel patterns and consumption habits, the intrinsically open nature of the wireless transmission medium makes all communications particularly susceptible to eavesdropping with nothing but the simplest off-the-shelf laptop. While the upper layers of the protocol stack traditionally ensure secrecy by means of public-key-and privatekey-based encryption algorithms, new technologies and devices are emerging in which the power and complexity constraints make it difficult to justify a direct deployment of standard security solutions. For instance, implanted medical devices, wireless sensors, or RFID tags, deployed in a home as part of the ''Internet of Things'' may not have the capability to host a full-blown public key infrastructure, hence rendering key generation and distribution more complex than the system can afford, either in terms of communication or computation resources. Motivated by these challenges, there has been a renewed interest in keyless techniques ensuring an intrinsic level of secrecy at the physical layer of communication systems. The rationale for this ''physicallayer security'' approach is that secret keys are a means to introduce randomness in the system, and that one could potentially reduce the burden of randomness generation by harnessing the randomness stemming from the communication channel itself. Numerous works studying secure communication over the wiretap channel <ref type="bibr" target="#b0">[1]</ref> and secret-key generation from correlated observations <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> also support the benefits of physical-layer security techniques. All these studies suggest that physical-layer security schemes could achieve some level of informationtheoretic secrecy. Although the information-theoretic models admittedly suffer from several weaknesses, such as idealized assumptions regarding the knowledge of the channel, one of the major hurdles toward broader acceptance has been the absence of explicit low-complexity algorithms ensuring a provable level of informationtheoretic secrecy. However, there has recently been much progress toward this goal, thanks in part to new conceptual approaches to secrecy and advances in errorcontrol coding.</p><p>The objective of this paper is to survey recent advances in this area, with the hope that it will foster further studies of error-control codes for secrecy and encourage system engineers to consider their integration in actual devices. The remainder of this paper is organized as follows.</p><p>Section II describes the canonical information-theoretic security model and highlights how the secrecy metrics under consideration make the problem more challenging than coding for reliability. Section III provides a brief overview of error-control coding, with a specific emphasis on low-density parity-check (LDPC) codes, polar codes, and extractors. Section IV takes a very pragmatic perspective on the problem and describes an explicit but suboptimal code construction for a simple model. Building upon some of the insights obtained from the example, Section V takes an information-theoretic view of the problem and describes potential coding approaches for a systematic exploration of error-control codes for secrecy. This includes a discussion of channel resolvability <ref type="bibr" target="#b3">[4]</ref> and privacy amplification <ref type="bibr" target="#b4">[5]</ref>. Section VI discusses several implementations of these informationtheoretic approaches with explicit low-complexity families of codes, such as LDPC codes, polar codes, and universal hash functions. Section VII concludes the paper with a discussion of the challenges and opportunities ahead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. INFORMATION-THEORETIC MODELS AND MEASURES OF SECRECY</head><p>The canonical model to study information-theoretic secrecy is Shannon's cryptosystem <ref type="bibr" target="#b5">[6]</ref>, which is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. The model captures the problem of confidential transmission in the upper layers of the protocol stack; it considers a situation in which a transmitter (Alice) aims at communicating with a legitimate receiver (Bob) over a noiseless channel, in the presence of a passive adversary (Eve), who observes all the signals transmitted. Alice and Bob possess an advantage over Eve by having access to a secret key K, which allows them to randomize the encoding of the message M into codewords X n and to render the information content of X n unintelligible for Eve.</p><p>In contrast, the standard model to investigate physicallayer security is the wiretap channel introduced by Wyner <ref type="bibr" target="#b0">[1]</ref> and extended by Csisza ´r and Ko ¨rner <ref type="bibr" target="#b6">[7]</ref>, which is illustrated in Fig. <ref type="figure">2</ref>. The wiretap channel model differs from Shannon's cryptosystem by considering the physical layer of communication systems and introducing noise into the two distinct channels linking Alice, Bob, and Eve. Intuitively, the model represents a situation in which Eve ''taps'' the wire connecting Alice to Bob. Instead of exploiting secret keys to give Alice and Bob an advantage over Eve, the model attempts to exploit the communication asymmetry created by the distinct channels. The channel between Alice and Bob is referred to as the ''main channel,'' and is considered here to be a memoryless channel characterized by input alphabet X , output alphabet Y, and transition probability W YjX . The channel between Alice and Eve is referred to as the ''eavesdropper's channel,'' and consists of another memoryless channel characterized by input alphabet X , output alphabet Z, and transition probability W ZjX . The statistics of both channels are assumed known to all parties ahead of time and authentication is implicitly already in place. Although these are arguably strong assumptions, it is worth emphasizing that the wiretap channel model does not rely on any shared secret key Fig. <ref type="figure">2</ref>. Wiretap channel model for confidential communication over noisy channels <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b6">[7]</ref>.</p><p>between Alice and Bob, 1 and assumes that Eve knows the coding scheme used by Alice and Bob. The ''keyless'' nature of the system is perhaps one of the major benefits of the approach, which is further discussed along with the possibility of removing the simplifying assumptions in Section VII.</p><p>Formally, the objective is for Alice to communicate a message M to Bob by encoding it into a codeword of n symbols X n 2 X n and subject to two constraints: a reliability constraint measured in terms of the average probability of decoding error of M from the legitimate observations Y n ; a secrecy constraint measured in terms of the statistical dependence between the message M and the eavesdropper's observations Z n .</p><p>The definition of the average probability of decoding error PðM 6 ¼ MÞ does not leave too much room for debate; however, finding a proper metric to measure statistical dependence offers a lot more leeway. Measuring secrecy in terms of statistical dependence is motivated by the idea that the more dependencies are present between M and Z n , the easier it is to extract information about M from Z n . Ideally, if one could guarantee that no dependence exists, then the optimal attack to infer M from Z n would be to guess M uniformly at random. Several metrics have been proposed to characterize statistical dependence, which we describe below in increasing strength order.</p><p>Probability of decoding error. Measuring the secrecy of the message M in terms of the probability of decoding error from the observation Z n is rather natural. Decades of research in code design suggest that, when the best known decoding algorithms yield a block error close to one or a bit error close to one-half, it is nearly impossible to retrieve information. Using probability of error as a proxy for secrecy has the advantage of directly leveraging the extensive literature on code design, and strong converse theorems <ref type="bibr" target="#b8">[9]</ref> support the ability to drive the block error probability to one. Unfortunately, this metric is not easily tied to information-theoretic secrecy and does not allow one to say much about the actual information leakage to the eavesdropper. Also, as shown in Section IV, one may construct examples in which the probability of decoding error is high, even if M and Z n are dependent. In practice, for finite blocklengths, semantic secrecy (discussed further on) appears to be a more widely acceptable metric across the information/communication theory and cryptography communities. Therefore, despite the growing literature on the subject <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, the probability of decoding error metric will not be discussed in this paper. Weak secrecy. This metric was introduced by Wyner <ref type="bibr" target="#b0">[1]</ref> and consists in measuring the normalized mutual information rate</p><formula xml:id="formula_0">S weak ðM; Z n Þ ¼ 1 n IðM; Z n Þ ¼ 1 n Dðp MZ n kp M p Z n Þ (1)</formula><p>where D is the Kullback-Leibler divergence.</p><p>Although the metric has been used in most subsequent works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b13">[13]</ref>, the quantity ð1=nÞIðM; Z n Þ remains small as soon as the information leaked grows sublinearly with n. Since it is easy to devise schemes with obvious secrecy flaws and for which ð1=nÞIðM; Z n Þ is arbitrarily small <ref type="bibr" target="#b14">[14]</ref>, this metric is often deemed unacceptable by the cryptography community.</p><p>Strong secrecy. The metric was proposed by Maurer <ref type="bibr" target="#b15">[15]</ref> to overcome the shortcomings of weak secrecy and consists in characterizing the total information leakage</p><formula xml:id="formula_1">S strong ðM; Z n Þ ¼ IðM; Z n Þ ¼ Dðp MZ n kp M p Z n Þ:<label>(2)</label></formula><p>One should note that strong secrecy still relies on the distribution of the message p M , and could be strengthened even further. Semantic secrecy. This last and even more stringent information-theoretic secrecy metric was formalized by Bellare et al. <ref type="bibr" target="#b16">[16]</ref> by adapting the notion of semantic secrecy used in computational cryptography <ref type="bibr" target="#b17">[17]</ref>. Formally, semantic secrecy is measured in terms of the advantage AdvðM; Z n Þ where</p><formula xml:id="formula_2">AdvðM; Z n Þ ¼ max f ;p M X z n p Z n ðz n Þ max f i 2suppðf Þ P f ðMÞ ¼ f i jz n ð Þ À max f i 2suppðf Þ P f ðMÞ ¼ f i ð Þ :<label>(3)</label></formula><p>Typically, for strong secrecy, the leaked mutual information IðM; Z n Þ is computed assuming a uniform distribution for the message M. However, for semantic secrecy, the advantage AdvðM; Z n Þ is bounded above by the maximum of IðM; Z n Þ over all possible distributions of the message M. Essentially, AdvðM; Z n Þ G means that the knowledge of the observation z n increases the probability 1 A small secret key is needed to authenticate the communication. log n bits of secret are known to be sufficient to authenticate n bits of data <ref type="bibr" target="#b7">[8]</ref>.</p><p>of guessing any function f of the message M by no more than , irrespective of its distribution p M . s-bit semantic secrecy. In practical cryptography, s-bit secrecy means that 2 s guesses have to be made to break the cryptographic system. In the wiretap channel scenario, a length-n coding scheme is said to achieve s-bit semantic secrecy if AdvðM; Z n Þ G 2 Às or s G À log 2 AdvðM; Z n Þ. Note that this metric can be used for finite n, and it means that 2 s or more random guesses have to be made before M can be deduced from the observations Z n . Ideally, one would like to ensure that M and Z n are completely independent, so that their joint distribution p MZ n factorizes as the product p M p Z n . In this ideal case, known as perfect secrecy, one would ensure S weak ðM;</p><formula xml:id="formula_3">Z n Þ ¼ S strong ðM; Z n Þ ¼ AdvðM; Z n Þ ¼ 0.</formula><p>Unfortunately, as realized by Shannon himself, perfect secrecy is too stringent to be really useful in all but a few specific models; in particular, achieving perfect secrecy in Shannon's cryptosystem requires the use of a onetime pad, with a key K containing as many bits as the message M to transmit. Nevertheless, as first recognized by Wyner <ref type="bibr" target="#b0">[1]</ref>, information-theoretic secrecy becomes amenable to further analysis if one requires instead a small but carefully controlled statistical dependence.</p><p>We will restrict our attention to codes ensuring strong or semantic secrecy, which are somewhat connected because of the relation <ref type="bibr" target="#b16">[16]</ref> AdvðM;</p><formula xml:id="formula_4">Z n Þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 2 log e 2 max p M S strong ðM; Z n Þ r :<label>(4)</label></formula><p>The design of codes for weak secrecy is only briefly discussed in Section V-B to highlight the fundamentally different coding mechanisms involved.</p><p>In the remainder of this paper, an ðn; k; ; Þ code refers to a code for the wiretap channel that transmits one of 2 k distinct messages over n uses of the channel, ensures an average probability of error less than , and guarantees a secrecy leakage measured in terms of S strong or Adv less than . The quantity k=n is the rate of the code.</p><p>Most information-theoretic studies of the wiretap channel focus on characterizing the secrecy capacity C s , which is intuitively the highest rate at which one may communicate with arbitrarily low probability of error and secrecy leakage in the limit of infinite block length. Formally, C s is the supremum of all rates R, such that there exists sequences of ðn; k n ; n ; n Þ codes with</p><formula xml:id="formula_5">lim n!1 k n n ! R; lim n!1 n ¼ lim n!1 n ¼ 0:</formula><p>Surprisingly, as shown by Csisza ´r, and Ko ¨rner, the secrecy capacity of a discrete memoryless wiretap channel may be positive; furthermore, it is completely characterized for the weak secrecy, strong secrecy, and semantic secrecy metrics, as <ref type="bibr" target="#b6">[7]</ref> C s ¼ max</p><formula xml:id="formula_6">VÀXÀYZ IðV; YÞ À IðV; ZÞ ð Þ :<label>(5)</label></formula><p>The notation V À X À YZ in (5) means that IðV; YÞ À IðV; ZÞ is maximized over joint distributions p VXYZ of random variables V; X; Y; Z, such that V À X À YZ form a Markov chain and p ZYjX is defined by the channel W YZjX , i.e., p VXYZ ¼ W YZjX p XjV p V . In particular, C s is positive as long as the eavesdropper's channel is not less noisy than the eavesdropper's channel <ref type="bibr" target="#b6">[7]</ref>, i.e., unless for all random variables V such that V À X À YZ forms a Markov chain, we have IðV; ZÞ ! IðV; YÞ. We defer the reader to Section VII for a discussion of how this advantage could be engineered, but the possibility of jointly ensuring reliability and secrecy is intriguing: reliability calls for the introduction of redundancy to counter the randomness in the data stream due to channel noise, while secrecy intuitively calls for the reduction of redundancy to maximize the eavesdropper's perceived randomness of the data stream. As illustrated in Fig. <ref type="figure" target="#fig_1">3</ref>, the information-theoretic analysis reveals that the following two key ingredients are required to achieve secrecy.</p><p>A codebook with a ''bin'' structure, by which several codewords form a bin that represents the same message M and are chosen at random upon transmission according to an auxiliary message M 0 . Intuitively, the role of this structure is to allow control of the statistical dependence between M and Z n . Without a bin structure, the leakage of information about messages is equal to the leakage of information about codewords, which is determined by the channel. In contrast, a bin structure allows one to control the leakage of information about messages by making it distinct from the leakage of information about codewords. ''Channel prefixing,'' by which the encoder artificially corrupts his codewords with noise by sending them through a noisy channel. Intuitively, the role of channel prefixing is to introduce artificial noise that jams Eve's channel, with the hope that it will degrade the quality of Eve's observations more than it will degrade that of Bob.</p><p>This paper focuses exclusively on the design of codebooks with a bin structure and discusses how this allows one to implement coding mechanisms beyond those traditionally used for reliability. The use of injected artificial noise to improve secrecy plays a crucial role in multiuser terminal problems <ref type="bibr" target="#b18">[18]</ref>, which are beyond the scope of this paper. Without channel prefixing, the supremum of achievable rates in the wiretap channel model becomes</p><formula xml:id="formula_7">R s ¼ max XÀYZ IðX; YÞ À IðX; ZÞ ð Þ<label>(6)</label></formula><p>and will be our reference for code design.</p><p>The fact that the fundamental information-theoretic limits in ( <ref type="formula" target="#formula_6">5</ref>) and ( <ref type="formula" target="#formula_7">6</ref>) remain identical for the weak, strong, and semantic secrecy metrics suggests that strong and semantic secrecy come ''for free.'' While this is certainly true from an information-theoretic point of view, the transition from a metric to another tends to modify code design, and at least requires different analysis techniques to establish secrecy. One of the objectives of Section V is, therefore, to lay out a framework for a systematic analysis of and search for good secrecy codes.</p><p>The information-theoretic characterization of the secrecy capacity with semantic secrecy given in <ref type="bibr" target="#b4">(5)</ref> for the wiretap channel in Fig. <ref type="figure">2</ref> is essentially solved. <ref type="foot" target="#foot_0">2</ref> What makes the design of actual codes challenging is the introduction of additional requirements that account for the limited computation capability of the transmitter and the receiver. Given the promising applications to sensor networks and low-power wireless devices mentioned earlier, these constraints are of paramount importance, even though they are not captured in information-theoretic analyses. Specifically, actual codes for physical-layer secrecy should also possess the following characteristics: a low encoding complexity with the blocklength n, ideally order of OðnÞ; a low decoding complexity with the blocklength n, ideally order of OðnÞ; an analytical or numerical characterization of the probability of error as a function of n and the channel parameters; an analytical characterization of the secrecy leakage as a function of n and the channel parameters.</p><p>Note that unlike , one cannot resort to numerical simulations to estimate ; this would require the estimation of the joint distribution p MZ n , for which the complexity would typically grow exponentially with the block length n.</p><p>In addition, codes should be explicit, in the sense that one should either exhibit a code or at least characterize an ensemble of codes and prove an ensemble concentration result, showing that most codes in the ensemble have the desired behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. A BRIEF REVIEW OF ERROR-CONTROL CODES</head><p>This section briefly reviews the concepts behind linear error-control codes <ref type="bibr" target="#b21">[21]</ref> and the salient properties of three families of codes, whose properties are particularly useful to design specific low-complexity instances of codes for secrecy: LDPC codes <ref type="bibr" target="#b22">[22]</ref>, polar codes <ref type="bibr" target="#b23">[23]</ref>, and universal hash functions <ref type="bibr" target="#b7">[8]</ref>. The reader already familiar with the concepts may skip this section and directly jump to Section IV.</p><p>To alleviate notation when indices are not critical, we use bold fonts to denote vectors and the dimension should be clear from the context. One notable exception to this convention is the discussion of polar codes in Sections III-C, VI-A2, and VI-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Linear Error-Control Codes</head><p>Consider a noisy channel characterized by an input alphabet X , an output alphabet Y, and a transition probability W YjX . In general, X is a finite field F so that X n is a vector space, and we will often consider the case F 2 , the Galois field of size 2. An ðn; kÞ error-control code for this channel consists of a set C &amp; X n , called codebook, that comprises 2 k sequences of length n, called codewords. Associated to the codebook is an encoder, which is a bijective function : F k 2 ! C mapping k message bits to a codeword, and a decoder, which is a surjective function : Y n ! F k 2 forming an estimate of the k message bits from a sequence of n channel observations. An ðn; kÞ code is linear if the codebook C forms a subvector space of X n with dimension k. A linear code C 0 &amp; C forms a subcode of C, and the sets of the form c þ C 0 with c 2 C form the cosets of C 0 in C. The distinct cosets of C 0 in C form a partition of C, which will be convenient to create the bin structure mandated for secrecy. An ðn; kÞ linear code C is conveniently described by an k Â n generator matrix G, whose rows form a basis for the vector space C. The encoding of a k bit message m into an n symbol codeword c may then be obtained as c ¼ mG. The dual of an ðn; kÞ linear code C is an ðn; n À kÞ linear code C ? , which consists of the sequences that are orthogonal to all sequences of C. An n À k Â n generator matrix of C ? is called a parity-check matrix of C, and is denoted by H. The parity-check matrix is such that a sequence r 2 X n is a codeword of C if and only if rH T ¼ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. LDPC Codes</head><p>A binary linear code with a sparse parity-check matrix is said to be a binary LDPC code. This is a fairly general definition, and, in practice, ensembles (sets with a probability distribution on its elements) of sparse parity-check matrices are considered. The ensemble, consisting of sparse matrices, typically exhibits concentration of performance metrics such as bit error or block error rates in the sense that most codes in the ensemble have bit error or block error rates close to the average over all codes in the ensemble. The average over all codes in the ensemble is studied and characterized in the analysis and design.</p><p>1) Tanner Graph: The Tanner graph of an m Â n paritycheck matrix H is a bipartite graph with n left nodes representing the columns or bits and m right nodes representing the rows or checks. Bit node i is connected to check node j if the ðj; iÞth entry of H is 1. The degree of a bit node or check node is easily seen to be equal to the weight of the corresponding column of H or row of H, respectively.</p><p>2) Socket Ensemble: The popular socket ensemble of binary LDPC codes is defined using the Tanner graph representation of a parity-check matrix. We first set up the notation and specification. The socket ensemble with n bit nodes is specified using the bit degree distribution ¼ f i : 2 i l max g and check degree distribution ¼ f j : 2 j r max g, where i and j are nonnegative fractions satisfying</p><formula xml:id="formula_8">P i i ¼ P j j ¼ 1.</formula><p>The distributions are denoted as polynomials ðxÞ ¼ P i i x iÀ1 and ðxÞ ¼ P j j x jÀ1 , and the ensemble is called the ðn; ðxÞ; ðxÞÞ-ensemble. The fraction i is the fraction of edges connected to degree-i bit nodes, while j is the fraction of edges connected to degree-j check nodes. A simple calculation shows that the number of check nodes m is given by m ¼ nð P j j =jÞ=ð P i i =iÞ, and this means that the design rate of the ðn; ; Þ-ensemble is 1 À ð P j j =jÞ=ð P i i =iÞ. Further, one can show that the fraction of degree-i bit nodes L i is given by L i ¼ ð i =iÞ=ð P i i =iÞ, while the fraction of degree-j check nodes R j is given by R j ¼ ð j =jÞ=ð P j j =jÞ. We are now ready to describe the ðn; ðxÞ; ðxÞÞ socket ensemble on Tanner graphs with n bit nodes and m check nodes. First, we attach sockets to nodes for holding edges. For bit nodes, i sockets are attached to nL i nodes. For check nodes, j sockets are attached to mR j nodes. A simple calculation shows that the number of edges E is equal to the number of sockets on either side resulting in E ¼ n P i iL i ¼ m P j jR j . The sockets on both sides are numbered from 1 to E. Next, a permutation of E objects is chosen uniformly at random, and socket i on the bit node side is connected by an edge to socket ðiÞ on the check node side to create a Tanner graph from the ensemble.</p><p>3) Message-Passing Decoders: We will skip the encoder for LDPC codes, since typically the parity-check matrix is used directly for performing the encoding. Let us consider transmission over a class of binary-input symmetric channels characterized completely by one channel parameter . For instance, the binary erasure channel (BEC) with ¼ D the erasure probability, the binary symmetric channel (BSC) with ¼ D p the crossover probability, and the binary-input additive white Gaussian noise (AWGN) channel with set as the channel noise variance, are standard examples in this category of channels. Let a codeword c ¼ ½c 1 c 2 Á Á Á c n be transmitted with the received word being r ¼ ½r 1 r 2 Á Á Á r n . Decoding is performed on the Tanner graph with channel input as the log-likelihood ratio (LLR) logðPrðc i ¼ 0jr i Þ= Prðc i ¼ 1jr i ÞÞ associated with the ith bit node. A message-passing decoder progresses in iterations by passing messages between bit nodes and check nodes over the edges that connect them. In every iteration, the message from/to bit node i is an LLR (or more generally belief) for the ith bit c i . Incoming messages are processed locally at the nodes to generate outgoing messages. Globally, the goal is to iteratively compute the overall LLR logðPrðc i ¼ 0jrÞ= Prðc i ¼ 1jrÞÞ in an approximate manner. The approximation used is that the incoming messages at a node contain independent information in every iteration, which holds asymptotically as n ! 1 for a fixed ððxÞ; ðxÞÞ. The precise message and node processing can be simplified depending on the channel, and we skip the details pointing to the standard texts <ref type="bibr" target="#b22">[22]</ref>, <ref type="bibr" target="#b24">[24]</ref>. Note that the computations required per iteration are of the order of the number of edges E, which grows linearly in n for sparse graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Density Evolution and Threshold Phenomenon:</head><p>In the analysis, a symmetric channel is assumed and the all-zero codeword is assumed to be transmitted. A message sent in any iteration is said to be in error if it is negative.</p><p>The commonly analyzed performance metric is the average message-error probability P ðl;nÞ ð; ; Þ of the ðn; ðxÞ; ðxÞÞ ensemble in the lth iteration of a message passing decoder for a channel with parameter , where the average is over all codes in the ensemble, all Tanner graph edges, and random channel noise realizations. We will drop the ð; Þ in the notation to reduce clutter from now on. Since every message is a belief for a bit of the codeword, the notion of message error makes sense. Since the message-error rates concentrate around the average, most codes in the ensemble behave close to the average. Of particular interest is the asymptotic message-error probability P ðlÞ ðÞ ¼ lim n!1 P ðl;nÞ ðÞ.</p><p>Density evolution for a message passing decoder is a procedure or recursion that computes P ðlþ1Þ ðÞ given P ðlÞ ðÞ. For binary-input symmetric channels, density evolution can be implemented efficiently in most cases of interest. Interestingly, the infinite iteration limit PðÞ ¼ lim l!1 P ðlÞ ðÞ exhibits a phase change, also called threshold phenomenon. That is, there exists a threshold channel parameter Ã such that, for G Ã , PðÞ ¼ 0. In practice, the threshold Ã plays the role of the capacity for the specific ð; Þ ensemble of LDPC codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Block</head><p>Error Threshold: As we will see in Section VI-A1, the standard message-error analysis is not entirely sufficient for the design of secrecy codes, and one needs to study instead the block error rate behavior. Specifically, the threshold phenomenon must be established for the average block error probability instead of the average message-error probability. This study is slightly more nuanced and requires more sophisticated ensembles, such as the protograph ensemble <ref type="bibr" target="#b25">[25]</ref>, for analysis and design. However, a thumb rule that is valid over several channels of interest is that LDPC codes with block error thresholds at rates close to capacity can be constructed and implemented with low-complexity encoders and decoders <ref type="bibr" target="#b26">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6) Construction of LDPC Codes:</head><p>In the construction of LDPC codes, the first task is the choice of degree distribution ð; Þ, which is typically made by optimizing threshold for a given rate or vice versa <ref type="bibr" target="#b22">[22]</ref>. Once the degree distribution is chosen, typical random construction involves sampling from the socket ensemble. However, several rules of thumb such as maximizing girth or other metrics <ref type="bibr" target="#b24">[24]</ref> are employed in practice for better performance at finite lengths. The progressive edge growth algorithm <ref type="bibr" target="#b27">[27]</ref> and its variants are popular for random constructions. The area of structured constructions suitable for implementations is the most popular in practice. In particular, protograph constructions <ref type="bibr" target="#b28">[28]</ref> and quasi-cyclic LDPC codes (see <ref type="bibr" target="#b29">[29]</ref> and references therein) are almost exclusively used in commercial standards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Polar Codes</head><p>Polar codes are cosets of binary linear codes and are defined by specifying their generator matrices. Let n ¼ 2 N ,</p><formula xml:id="formula_9">F ¼ 1 0 1 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>!</head><p>, and G n ¼ F N , where denotes the Kronecker product. To specify an ðn; kÞ polar code, one specifies a subset A &amp; ½ ½1; n of size k and a binary vector u of length n À k. Letting G A denote the submatrix formed by the rows of G n indexed by A, the codewords of the polar code are defined to be fuG</p><formula xml:id="formula_10">A c þ mG A : m 2 F k 2 g</formula><p>, where A c ¼ ½ ½1; n n A. We will denote such a polar code as an ðn; k; A; uÞ polar code.</p><p>1) Channel Polarization: The choice of the set A depends on the channel and how it polarizes. Let WðyjxÞ be a binary-input symmetric channel with x 2 F 2 and an arbitrary finite output alphabet for y. Consider n uses of the channel W with the n-bit vector channel input, denoted</p><formula xml:id="formula_11">x n 1 ¼ ½x 1 ; . . . ; x n , set as x n 1 ¼ u n 1 G n , where u n 1 ¼ ½u 1 ; . . . ; u n is a vector of n input bits. The output corresponding to x n 1 is denoted y n 1 . Now, this vector channel W n : u n 1 ! y n 1 is split into the n ''bit channels'' W ðiÞ n : u i 7 !ðy n 1 ; u iÀ1 1 Þ, where u iÀ1 1 ¼ ½u 1 u 2 Á Á Á u iÀ1 .</formula><p>The n bit channels polarize, i.e., tend to either perfect error-free channels or fully noisy channels, as n goes to 1.</p><p>The polarization effect is precisely described in terms of the Bhattacharya parameter ZðWÞ of a binary-input channel W defined as</p><formula xml:id="formula_12">ZðWÞ ¼ X y ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi Wðyj0ÞWðyj1Þ q :</formula><p>The Bhattacharya parameter takes values in ½0; 1 and is an upper bound on the probability of error for maximumlikelihood decoding for a single bit across W. For an errorfree binary-input channel, the Bhattacharya parameter is equal to 0. If ZðWÞ is close to 1, the channel W is highly noisy with capacity close to 0. Let CðWÞ denote the capacity of W. For any fixed small fraction , the fraction of indices i for which ZðW ðiÞ n Þ G tends to CðWÞ as n goes to 1, while the fraction of indices with ZðW ðiÞ n Þ &gt; 1 À tends to 1 À CðWÞ as n goes to 1 <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Construction and Decoding of Polar Codes:</head><p>The main task in the construction of polar codes is identifying the coordinates i for which the bit channels W ðiÞ n polarize to perfect channels. More precisely, the set A is defined as the k-element subset of ½ ½1; n containing the indices of the bit channels with the k least Bhattacharya parameters out of the set fZðW ðiÞ n Þ : 1 i ng. Either a successive cancellation decoder that decodes the bit channels in sequence from 1 to n or a messagepassing decoder can be used for decoding polar codes. The successive cancellation decoder has strong theoretical guarantees, while the message-passing decoder is more practical for implementation. The successive cancellation decoder works as follows. For i 2 A c , there is nothing to do. For i 2 A, the decoder decides the ith bit ûi by the following rule: Now, along with the polarization result, we conclude that there exists a choice for u such that an ðn; k; A; uÞ polar code achieves arbitrarily low block errors over a channel W with the rate k=n approaching the capacity CðWÞ. The complexity of the encoding and decoding is of the order of n log n. For symmetric channels, the choice of u has no effect on performance, and it is common to choose u ¼ 0.</p><formula xml:id="formula_13">ûi ¼ 1; if W ðiÞ n y n 1 ; ûiÀ1 1 j1 À Á &gt; W ðiÞ n y n 1 ; ûiÀ1 1 j0 À Á 0;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Extractors and Universal Hash Functions</head><p>Informally, extractors are functions that are able to extract randomness efficiently; they have come to play an important role in theoretical computer science <ref type="bibr" target="#b30">[30]</ref> as means to ''extract'' uniform bits of randomness from stochastic processes. Formally, a seeded extractor Ext is a function</p><formula xml:id="formula_14">Ext : F d 2 Â F n 2 ! F k 2 : ðs; xÞ7 !b:<label>(7)</label></formula><p>Let S d denote the choice of a seed s uniformly at random in F d 2 , let ðX n ; Z n Þ be joint random variables with X n 2 F n 2 and conditional min-entropy 3 H 1 ðX n jZ n Þ, and let q k denote the uniform distribution on F k 2 . Then, Ext is an ðh; Þ extractor if</p><formula xml:id="formula_15">H 1 ðX n jZ n Þ &gt; h ) V p S d ;Z n ;ExtðX n Þ ; p S d p Z n q k À Á<label>(8)</label></formula><p>where Vðp; qÞ ¼ ð1=2Þ P x2X jpðxÞ À qðxÞj denotes the variational distance between two distributions p and q on a finite set X . In other words, the extractor is able to generate k nearly uniform bits that are independent of Z n and S d as soon as the min-entropy H 1 ðX n jZ n Þ is large enough. If ðX n ; Z n Þ has a product distribution, then with high probability and for n large enough, H 1 ðX n jZ n Þ is not too different from nHðXjZÞ; hence, one can think of an ðh; Þ extractor as a means to extract randomness in a universal way using a random seed as a catalyst.</p><p>Two-universal (universal for short) hash functions are a specific instance of extractors, which were originally introduced in the context of unconditional authentication <ref type="bibr" target="#b7">[8]</ref>. Specifically, a family of hash functions H is an ensemble of functions f h :</p><formula xml:id="formula_16">F n 2 ! F k 2 , with h a parameter that indexes the function in H, such that 8x; x 0 2 F n 2 x 6 ¼ x 0 ) P f H ðxÞ ¼ f H ðx 0 Þ ð Þ 1 2 k (9)</formula><p>where H denotes the choice of a function in H uniformly at random. Let ðX n ; Z n Þ be joint random variables with X n 2 F n 2 and min-entropy H 1 ðX n jZ n Þ, and let q k denote the uniform distribution on F k 2 . Then, by the leftover hash lemma <ref type="bibr" target="#b31">[31]</ref> </p><formula xml:id="formula_17">V p H;Z n ;f H ðX n Þ ; p H p Z n q k À Á 1 2 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 2 k 2 ÀH 1 ðX n jZ n Þ p :<label>(10)</label></formula><p>In other words, universal hash functions are ðh; ð1=2Þ ffiffiffiffiffiffiffiffi ffi 2 kÀh p Þ seeded extractors. We will see explicit examples of universal hash functions in Section VI-A3.</p><p>A specific class of extractors that is particularly useful for secrecy is that of invertible extractors. By definition, the inverser Inv of an extractor Ext is a stochastic map</p><formula xml:id="formula_18">Inv : F d 2 Â F k 2 ! F n 2 : ðs; bÞ7 !x<label>(11)</label></formula><p>such that the distribution of Invðs; bÞ is the same as that of the pre-image x conditioned on Extðs; xÞ ¼ b. A somewhat implicit constraint is that Inv should be computed efficiently with low complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. AN EXPLICIT EXAMPLE WITH SEMANTIC SECRECY</head><p>In this section, we exhibit explicit codes for binary-input wiretap channels with a noiseless main channel and a binary-input eavesdropper's channel. We begin by constructing a code for the special case illustrated in Fig. <ref type="figure" target="#fig_2">4</ref>, in which the main channel is noiseless and the eavesdropper's channels is a BEC with output alphabet f0; 1; eg and e denoting erasure. Despite its simplicity, the BEC has proved particularly useful to guide the design of powerful codes, such as LDPC codes <ref type="bibr" target="#b32">[32]</ref> and polar codes <ref type="bibr" target="#b23">[23]</ref>, and we will see that secrecy codes over the BEC may be extended to arbitrary binary-input channels. Here, our objective is to show that practical codes achieving semantic secrecy at finite length do exist, and to use this as a motivating example. We start by illustrating why the probability of block error is not a suitable proxy for information-theoretic secrecy. Since the main channel is noiseless, Alice may reliably communicate 2 n distinct messages with all sequences of F n 2 as codewords. Assuming that all messages M are equally likely, the corresponding channel inputs X n are then independent identically distributed (i.i.d.) according to a uniform distribution. While the strong converse for channel capacity <ref type="bibr" target="#b8">[9]</ref> ensures that</p><formula xml:id="formula_19">3 H 1 ðX n jZ n Þ ¼ À P z n p Z n ðz n Þ log 2 max x n Pðx n jz n Þ.</formula><formula xml:id="formula_20">lim n!1 PðM 6 ¼ b MÞ ¼ 1, the information leaked to the eavesdropper about M through Z n is IðM; Z n Þ ¼ IðX n ; Z n Þ ¼ X n i¼1 IðX i ; Z i Þ ¼ nð1 À Þ:</formula><p>Therefore, even though the probability of block error is maximum in the limit of large block length, the leakage grows unbounded. Fundamentally, the above coding scheme lacks information-theoretic secrecy guarantees because it does not possess the bin structure discussed in Section II. Although the need for a bin structure has already been discussed from an information-theoretic perspective, it is insightful to explicitly consider the need for binning in the specific case of the BEC. Assume that the encoder were to use a classical codebook with a deterministic encoder, which maps messages and codewords one to one. Upon observing an unerased symbol, the eavesdropper is able to gain some information about the transmitted message by simply listing the codewords matching the observations; the only situation in which no information is leaked is when all codewords have the same symbols in the unerased positions. Unfortunately, the only way of controlling the information leaked for all erasure patterns is then to assign the same symbols to all codewords, which of course prevents any transmission of information. Hence, the only method to circumvent this issue is to assign a bin with multiple codewords to the same message, and to randomize the choice of the codeword upon transmission. A constructive method to assign bins to messages that is very natural with linear codes is coset coding, which we describe next.</p><p>a) Coset coding: Consider an ðn; n À kÞ binary linear code C with generator matrix G of dimension ðn À kÞ Â n. The code C possesses 2 k cosets, which form a partition of F n 2 . Coset coding consists in using a message M of k bits to select one of the 2 k cosets of C in a one-to-one map, and the transmitted codeword X n is set to be a uniformly random vector from the chosen coset. In other words, we set</p><formula xml:id="formula_21">X n ¼ UG þ MG 0 (12)</formula><p>where G 0 is a k Â n binary matrix such that G G 0 Â Ã has row rank equal to n, and the ðn À kÞ-bit vector U is chosen uniformly at random. Note that the complexity of the encoding is n 2 , which makes this approach unsuitable for dense large unstructured matrices. For sparse matrices, it is possible to alleviate complexity of encoding by using ideas from efficient encoder design of LDPC codes <ref type="bibr" target="#b22">[22]</ref>, <ref type="bibr" target="#b33">[33]</ref>.</p><p>b) Strong and semantic secrecy of coset coding: When X n as per ( <ref type="formula">12</ref>) is transmitted, let Z n be received across the eavesdropper's BEC with erasure probability . Let the set S ¼ fi : Z i 6 ¼ eg denote the set of unerased positions in Z n . Let G S denote the submatrix of G formed by the columns indexed by S. Define an event E as</p><formula xml:id="formula_22">E ¼ 0; if rankðG S Þ ¼ jSj 1; else &amp;<label>(13)</label></formula><p>which indicates when the submatrix G S is not of full column rank. The equivocation of M given Z n , defined as HðMjZ n Þ, can be lower bounded as follows:</p><formula xml:id="formula_23">HðMjZ n Þ ! HðMjZ n ; EÞ (14) ! PðE ¼ 0ÞHðMjZ n ; E ¼ 0Þ:<label>(15)</label></formula><p>A well-known argument <ref type="bibr" target="#b34">[34]</ref> shows that</p><formula xml:id="formula_24">HðMjZ n ; E ¼ 0Þ ¼ HðMÞ:<label>(16)</label></formula><p>In other words, the message entropy conditioned on Z n and the event that G S has full column rank is equal to its original unconditioned value. The mutual information IðM; Z n Þ can now be upper bounded as follows:</p><formula xml:id="formula_25">IðM; Z n Þ ¼ HðMÞ À HðMjZ n Þ (17) HðMÞ À PðE ¼ 0ÞHðMÞ (18) ¼ HðMÞPðE ¼ 1Þ (<label>19</label></formula><formula xml:id="formula_26">)</formula><p>where we have used <ref type="bibr" target="#b16">(16)</ref> and</p><formula xml:id="formula_27">PðE ¼ 0Þ þ PðE ¼ 1Þ ¼ 1.</formula><p>To compute PðE ¼ 1Þ, we consider the dual code C ? , for which G is a parity-check matrix. We assume that C ? is used with equiprobable codewords over a BEC with erasure probability 1 À and decoded with an optimal decoder that solves for the erasures using the linear conditions imposed by the parity-check matrix G. Letting S now denote the positions of erasures in the received vector, which is consistent with the earlier definition over BECðÞ, we see that the submatrix G S does not have full column rank whenever the optimal decoder fails. So, it is easily seen that</p><formula xml:id="formula_28">PðE ¼ 1Þ P B ðC ? ; 1 À Þ (<label>20</label></formula><formula xml:id="formula_29">)</formula><p>where P B ðC ? ; 1 À Þ denotes the probability of block error of the optimal decoder for C ? over the BECð1 À Þ. To upper bound P B ðC ? ; 1 À Þ, we use the Bhattacharya bound, which states that</p><formula xml:id="formula_30">P B ðC ? ; 1 À Þ X n i¼1 A i ð1 À Þ i<label>(21)</label></formula><p>where A i denotes the number of weight-i codewords in C ? . The bound in ( <ref type="formula" target="#formula_28">20</ref>) is expected to be tight because the optimal decoder will have to randomly guess between multiple possibilities for the transmitted codeword when the submatrix rank of the erased positions is not full. The Bhattacharya bound is based on a union bounding argument, and the bound in <ref type="bibr" target="#b21">(21)</ref> should be tight for low values of 1 À .</p><p>Putting everything together, we get</p><formula xml:id="formula_31">S strong ðM; Z n Þ ¼ IðM; Z n Þ HðMÞ X n i¼1 A i ð1 À Þ i (22)</formula><p>and using (4) and max p M HðMÞ ¼ k, we get that</p><formula xml:id="formula_32">AdvðM; Z n Þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð2 log e 2Þk X n i¼1 A i ð1 À Þ i s :<label>(23)</label></formula><p>c) Performance of Reed-Muller codes: Using a code C ? for which the weight distribution is known, it is straightforward to use <ref type="bibr" target="#b23">(23)</ref> and compute the number of bits of semantic secrecy s ¼ À log 2 AdvðM; Z n Þ. Fig. <ref type="figure" target="#fig_3">5</ref> shows a plot of semantic secrecy when we set C ? as the second-order Reed-Muller codes RM <ref type="bibr" target="#b7">(8,</ref><ref type="bibr" target="#b1">2)</ref> or RM(9, 2), whose exact weight distributions are well known. RM(8, 2) is a (256, 37) code, while RM(9, 2) is a (512, 46) code. Consequently, the designed secrecy rates when RM <ref type="bibr" target="#b7">(8,</ref><ref type="bibr" target="#b1">2)</ref> or RM(9, 2) is used as C ? are 37/256 or 46/512, respectively. Note that these are finite-length schemes for which we can guarantee a finite-bit semantic secrecy as per our calculations above.</p><p>For a secrecy rate of R, from secrecy capacity arguments, it is clear that s-bit secrecy for any s can be obtained for sufficiently large length n over a BECðÞ for &gt; R. Now, RM(8, 2) (block length of 256) achieves 100-b semantic secrecy for &gt; 0:9 as seen from Fig. <ref type="figure" target="#fig_3">5</ref>, while secrecy capacity arguments allow for &gt; 37=256 (although required block length might be much larger). For RM(9, 2), 100-b semantic secrecy is possible for &gt; 0:7, while secrecy capacity arguments allow for &gt; 46=512.</p><p>The analysis above allows us to consider situations in which the eavesdropper's channel W ZjX is any binary-input channel. In fact, as illustrated in Fig. <ref type="figure">6</ref>, any binary-input channel is degraded with respect to an erasure channel, in the sense that it is statistically equivalent to the concatenation of a BEC with a noisy channel characterized by a transition probability W ZjZ 0 . One can show <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b35">[35]</ref> that the erasure probability of the BEC is</p><formula xml:id="formula_33">Ã ¼ Z Z min x2F 2 W ZjX ðzjxÞdz:<label>(24)</label></formula><p>The data processing inequality <ref type="bibr" target="#b36">[36]</ref> states that IðX n ; Z n Þ IðX n ; Z 0n Þ, so that any coding scheme achieving s-bit semantic secrecy for the BEC with erasure probability Fig. <ref type="figure">6</ref>. Degrading binary-input channel with respect to erasure channels.</p><p>Ã will also achieve s-bit semantic secrecy over the original eavesdropper's channel.</p><p>In particular, this result may be applied to a binaryinput AWGN channel with X 2 fÀ1; 1g and Z ¼ X þ W, where W $ N ð0; 2 Þ. Applying <ref type="bibr" target="#b24">(24)</ref>, it is easy to check that the binary-input AWGN channel with noise variance 2 is a degraded version of a BEC with erasure probability Ã ¼ 2Qð1=Þ, where the standard Q-function is defined as</p><formula xml:id="formula_34">QðxÞ ¼ R 1 x<label>ð1=</label></formula><p>ffiffiffiffiffi ffi 2 p Þe Àu 2 =2 du. Using this fact, one can compute the number of bits of semantic secrecy provided by the Reed-Muller codes over the binary-input AWGN channel with noise variance 2 . Fig. <ref type="figure">7</ref> shows a plot of number of bits of semantic secrecy versus signal-to-noise ratio (SNR) ¼ 1= 2 in decibels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. GENERIC CODING APPROACHES FOR SECRECY</head><p>Although Section IV explicitly characterizes the semantic secrecy of coset coding with duals of Reed-Muller codes over a wide range of eavesdropper's channel, the example suffers from a number of shortcomings. First and foremost, the analysis of strong and semantic secrecy is somewhat ad hoc and largely exploits the specificities of the BEC. Second, the BEC wiretap channel does not impose any reliability constraint over the main channel and the proposed scheme offers low encoding complexity only by exploiting the specific nature of RM codes. Finally, the achieved secrecy rate falls short of the secrecy capacity by a significant amount when the channel is not a BEC. In this section, we introduce generic coding approaches for secrecy in a more abstract way, with the objective of laying out a framework to explore the design of secrecy codes in a systematic manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. A Coding Approach: Channel Reliability and Channel Resolvability</head><p>Intuitively, the secrecy of codes for the wiretap channel stems from their ability to ''confuse'' the eavesdropper and make it unable to distinguish between two distinct messages; said differently, irrespective of the message transmitted, the statistical distribution of the eavesdropper's observations follows the same distribution q Z n . As suggested in <ref type="bibr" target="#b37">[37]</ref> and developed in <ref type="bibr" target="#b38">[38]</ref>- <ref type="bibr" target="#b42">[42]</ref>, this idea can be rigorously formalized using the concept of approximation of output statistics <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b43">[43]</ref>, <ref type="bibr" target="#b44">[44]</ref>, which we review next.</p><p>The idea behind the approximation of output statistics is to use a codebook to control the statistical distribution induced at the output of a noisy channel. As illustrated in Fig. <ref type="figure">8</ref>, consider a memoryless channel with transition probabilities W ZjX and an i.i.d. input process fX n g n!1 in which all samples are drawn according to q X . This induces an i.i.d. output process fZ n g n!1 in which all samples are drawn according to q Z ðzÞ ¼ X</p><p>x W ZjX ðzjxÞq X ðxÞ:</p><p>The objective is to approximate the process fZ n g n!1 by drawing codewords uniformly at random from a codebook. Formally, an ðn; k 0 ; Þ code consists of 2 k 0 codewords fc i g i¼1...2 k 0 of length n, which induce an output distribution</p><formula xml:id="formula_36">p Z n ðzÞ ¼ X 2 k 0 i¼1 1 2 k 0 W Z n jX n ðzjc i Þ<label>(26)</label></formula><p>such that Dðp Z n kq Z n Þ , where q Z n ðzÞ ¼ Q n i¼1 q Z ðz i Þ and q Z is defined in <ref type="bibr" target="#b25">(25)</ref>. The minimum asymptotic rate required to make the divergence vanish is called the channel resolvability. With a slight abuse of language, we call the codes described above ''channel resolvability codes.'' Fig. <ref type="figure">7</ref>. Semantic secrecy of RM(8, 2) and RM(9, 2) over a binary-input AWGN channel. Fig. <ref type="figure">8</ref>. Principle of channel resolvability. The distributions q Z and p Z n are defined by ( <ref type="formula" target="#formula_35">25</ref>) and ( <ref type="formula" target="#formula_36">26</ref>), respectively. The objective is to make the distributions q Z n and p Z n nearly identical.</p><p>One can show that there exists a sequence of ðn; k 0</p><formula xml:id="formula_37">n ; n Þ codes such that lim n!1 n ¼ 0 if lim n!1 k 0 n n &gt; IðX; ZÞ<label>(27)</label></formula><p>with X and Z defined as per (25) <ref type="bibr" target="#b39">[39]</ref>, <ref type="bibr" target="#b41">[41]</ref>. Although the proof requires a random coding argument, Fig. <ref type="figure" target="#fig_4">9</ref> provides an illustration of the key ideas behind this result. If n is large enough and the asymptotic equipartition property (AEP) holds, one only needs to reproduce the sequences z that constitute the typical set of q Z , which are also known to be nearly uniformly distributed in the typical set having size of the order of 2 nHðZÞ <ref type="bibr" target="#b36">[36]</ref>. The transmission of a typical input sequence x through the channel generates a subset of typical sequences z, represented by the dark gray circle, which are again uniformly distributed and on the order of roughly 2 nHðZjXÞ . Consequently, the number of input sequences required to approximate the process Z n is the number of subsets required to cover the entire set of typical sequences, and should be at least 2 nHðZÞ =2 nHðZjXÞ ¼ 2 nIðX;ZÞ . Although the information-theoretic argument is not too different from this intuitive explanation, the design of an actual channel resolvability code is more involved, and is discussed in Section VI. While the argument above resembles that of the channel coding theorem, Fig. <ref type="figure" target="#fig_5">10</ref> illustrates a fundamental conceptual difference. If n is large enough so that the AEP holds, one may assume that all codewords x and channel observations z are typical sequences. The transmission of x through the channel generates again a subset of typical sequences, indicated by a dark gray circle. However, the goal of channel coding is to ensure that the receiver may distinguish the input codewords to obtain a negligible probability of decoding error. Consequently, the maximum number of distinguishable codewords is the number of nonoverlapping subsets required to pack the entire set of typical sequences, which is at most 2 nIðX;ZÞ .</p><p>Going back to the problem of secrecy, channel resolvability plays a fundamental role because of the following upper bound on S strong ðM; Z n Þ. Using the chain rule of divergence <ref type="bibr" target="#b36">[36]</ref>, we have</p><formula xml:id="formula_38">S strong ðM; Z n Þ ¼ D p MZ n kp M p Z n ð Þ ¼ D p MZ n kp M q Z n ð ÞÀD p Z n kq Z n ð Þ D p MZ n kp M q Z n ð Þ ¼ E D p Z n jM kq Z n À Á jM À Á :<label>(28)</label></formula><p>In other words, a sufficient condition to ensure strong secrecy is to guarantee that, on average, the distribution p Z n jM¼m of eavesdropper's observations induced by every message m is the same fixed distribution q Z n . Furthermore, if this property holds for every message m without averaging, then semantic secrecy follows. Combining ( <ref type="formula" target="#formula_38">28</ref>) with ( <ref type="formula" target="#formula_37">27</ref>), a sufficient condition to ensure semantic secrecy is therefore to associate to every message m an ðn; k 0 n ; n Þ channel resolvability code with lim n!1 n ¼ 0. Simultaneously, to ensure reliability over the main channel W YjX , the union of all codewords of all the channel resolvability codes should form a code with vanishing error probability as n goes to infinity. If the total number of messages is 2 k n another standard random coding argument <ref type="bibr" target="#b39">[39]</ref>, <ref type="bibr" target="#b40">[40]</ref> shows that the union of ðn; k 0 n ; n Þ resolvability codes may form a sequence of ðn;  Combining ( <ref type="formula" target="#formula_39">29</ref>) and ( <ref type="formula" target="#formula_37">27</ref>), one may check that the rate of secret messages k n =n may be chosen arbitrarily close to IðX; YÞ À IðX; ZÞ, which is exactly <ref type="bibr" target="#b5">(6)</ref>. This combination of channel reliability with channel resolvability may be interpreted in terms of the bin structure of Fig. <ref type="figure" target="#fig_1">3</ref>: every bin of a secrecy code constitutes a channel resolvability code, and the union of all bins constitutes a channel reliability code. Information theory shows that this approach leads to optimal codes, and may therefore be used as a guideline for systematic design. Examples of designs following this approach are given in Section VI.</p><formula xml:id="formula_39">k n þ k 0 n ; n Þ reliability codes with lim n!1 n ¼ 0 if lim n!1 k n þ k 0 n n G IðX; YÞ:<label>(29)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. An Alternative Coding Approach: Deriving Secrecy From Channel Reliability</head><p>A large body of the information-theoretic secrecy literature <ref type="bibr" target="#b13">[13]</ref> follows the approach laid out by Wyner <ref type="bibr" target="#b0">[1]</ref> to establish weak secrecy. This approach leads to somewhat different guidelines regarding the design of the codes, which we briefly summarize. The central idea behind Wyner's approach consists in explicitly introducing the random variable M 0 that denotes the choice of a codeword in a bin, and in upper bounding S weak ðM; Z n Þ as</p><formula xml:id="formula_40">S weak ðM; Z n Þ ¼ 1 n IðM; Z n Þ ¼ 1 n IðMM 0 ; Z n Þ À 1 n IðM 0 ; Z n jMÞ 1 n IðX n ; Z n Þ À 1 n HðM 0 Þ þ 1 n HðM 0 jZ n MÞ C e À 1 n HðM 0 Þ þ 1 n HðM 0 jZ n MÞ<label>(30)</label></formula><p>where the first inequality follows by the data-processing inequality and the Markov chain MM 0 À X À Z n , whereas the second inequality follows by defining C e the capacity of the eavesdropper's channel. Now assume that every bin stems from a sequence of ðn; k 0 n ; n Þ capacity-achieving codebooks with error probability n for the eavesdropper's channel further satisfying</p><formula xml:id="formula_41">lim n!1 n ¼ 0 lim n!1 k 0 n n ¼ C e :<label>(31)</label></formula><p>Then, ð1=nÞHðM 0 Þ ¼ k 0 n =n may be chosen arbitrarily close to C e and ð1=nÞHðM 0 jZ n MÞ, which represents the average uncertainty about the transmitted codeword knowing which bin was used, vanishes since it may be upper bounded by ð1=nÞ þ C e n by Fano's inequality <ref type="bibr" target="#b36">[36]</ref>. Consequently, the design of practical weakly secure codes may exploit any known family of low-complexity capacity achieving codes, such as polar codes <ref type="bibr" target="#b45">[45]</ref>- <ref type="bibr" target="#b48">[48]</ref> and LDPC codes <ref type="bibr" target="#b49">[49]</ref>- <ref type="bibr" target="#b53">[51]</ref>. Unfortunately, the fact that such weakly secure codes exploit channel capacity achieving codes per (31) instead of channel resolvability codes per <ref type="bibr" target="#b27">(27)</ref> fundamentally prevents them from achieving strong secrecy <ref type="bibr" target="#b40">[40]</ref>, <ref type="bibr" target="#b54">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. A Binning Approach: Source Coding With Side Information and Privacy Amplification</head><p>We now describe a conceptually different approach to code design, which relies on source coding mechanisms. This approach is the one used in Csisza ´r's proof of the strong secrecy capacity <ref type="bibr" target="#b37">[37]</ref> and is the tool of choice in many quantum information-theory works <ref type="bibr" target="#b55">[53]</ref>; it has also been extended to multiuser terminal problems under the name of ''output statistics of random binning'' <ref type="bibr" target="#b56">[54]</ref>. As will be discussed in Section VI-B, it is only recently that practical codes based on this conceptual approach have been designed.</p><p>Instead of generating a subset of sequences of X n to form a single codebook, the principle of the binning approach is to assign all possible sequences to several codebooks. The term ''binning'' refers to the idea that every sequence is thrown into a ''bin'' representing a codebook. Specifically, consider an i.i.d. input process fX n g n!1 with X i $ p X , which is sent through the main channel and the eavesdropper's channel to create correlated observations Y n and Z n , respectively. Every sequence</p><formula xml:id="formula_42">X n is assigned two indices, C ¼ n ðX n Þ and M ¼ n ðX n Þ.</formula><p>Index C is meant to indicate which codebook the sequence is assigned to while index M is meant to indicate the message that the sequence represents. For these indices to be meaningful, they should satisfy the following constraints.</p><p>The sequence X n is reconstructed as b X n from C and Y n with average probability of error n . Intuitively, this means that the decoder may reconstruct the transmitted sequence from its observation if it knows the codebook to which the sequence belongs. The indices M and C are nearly uniformly distributed, independent of each other, and i n d e p e n d e n t o f Z n , i n t h e s e n s e t h a t Dðp CMZ n kq C q M p Z n Þ n where q C and q M denote uniform distributions over the same support as p C and p M . Intuitively, this constraint is required to ensure that the messages may be chosen independently of the codebook and kept hidden from the eavesdropper. Well-known results from source coding with side information <ref type="bibr" target="#b57">[55]</ref> show that there exist sequences of functions n : X n ! ½ ½1; 2 k 0 n : x7 !c with lim n!1 n ¼ 0 as long as</p><formula xml:id="formula_43">lim n!1 k 0 n n &gt; HðXjYÞ:<label>(32)</label></formula><p>In contrast, the possibility of generating uniform indices C and M that are nearly independent of Z n follows from a result known as privacy amplification <ref type="bibr" target="#b4">[5]</ref>. One can show that there exist sequences of functions n :</p><formula xml:id="formula_44">X n ! ½ ½1; 2 k 0 n : x7 !c a n d n : X n ! ½ ½1; 2 k n : x7 !m w i t h lim n!1 n ¼ 0 as long as lim n!1 k n þ k 0 n n GHðXjZÞ:<label>(33)</label></formula><p>Similarly to what was done for channel resolvability, we illustrate the principle of privacy amplification. As shown in Fig. <ref type="figure" target="#fig_6">11</ref>, the key idea is to extract from X n the randomness that is nearly independent of the observation Z n . If n is large enough and the AEP applies, this is possible because any sequence z is jointly typical with a set of sequences x comprising roughly 2 nHðXjZÞ uniformly distributed sequences. Consequently, if one assigns no more than 2 nHðXjZÞ indices, these indices are nearly uniformly distributed, independent of each other, and independent of Z n . A secrecy code is finally obtained by ''inverting'' the binning procedure. Specifically, the codebook is first defined by fixing and publicly disclosing index C. To transmit a secret message M, one uses M as the second index and generates a codeword X n according to the distribution p X n j n ðX n Þ¼C; n ðX n Þ¼M defined by the bin structure. Combining the conditions in <ref type="bibr" target="#b32">(32)</ref> and <ref type="bibr" target="#b33">(33)</ref>, one may check that the resulting codes can reliably and secretly transmit M at a rate k n =n arbitrarily close to HðXjZÞ À HðXjYÞ ¼ IðX; YÞ À IðX; ZÞ.</p><p>The combination of source coding with side information and privacy amplification may therefore be viewed as the dual of the channel reliability and channel resolvability approach outlined in Section V-A. Although the two approaches are completely equivalent from an information-theoretic perspective in terms of asymptotic performance, they actually rely on distinct mechanisms, which lead to different code constructions described in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SECRECY-CAPACITY APPROACHING CODES</head><p>We now describe several constructions of secrecy codes based on the design principles outlined in Section V that approach or achieve the secrecy capacity. These constructions are explicit, in the sense defined at the end of Section II, and exploit the properties of the three families of codes discussed in Section III.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Coding and Channel Resolvability Constructions</head><p>In this section, we describe three practical constructions based on the channel resolvability approach described in Section V-A. The performances of the three resulting code families are summarized in Table <ref type="table" target="#tab_1">1</ref>, to illustrate the various tradeoffs between complexity, performance, and applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Channel Resolvability and Wiretap Coding Over the BEC With Duals of LDPC Codes:</head><p>We revisit the example given in Section IV from the perspective of channel resolvability and using duals of LDPC codes. Consider again the binary erasure wiretap channel of Fig. <ref type="figure" target="#fig_2">4</ref>. Let G be the generator matrix of an ðn; n À kÞ code C, chosen as the dual of an LDPC code with erasure threshold Ã . In other words, G is the parity-check matrix of the ðn; kÞ LDPC code. The distribution p Z n of eavesdropper's observations induced by the choice of codewords uniformly at random in C is then As long as the number of distinct sequences does not exceed the size of the conditionally typical sets in gray, the index is nearly independent of z. Denote by q Z n the distribution induced at the output of the channel when the input is an i.i.d. process of uniformly distributed bits. Following the principles laid out in Section V-A, we will establish conditions under which the code C becomes a channel resolvability code, i.e., conditions under which the distributions p Z n and q Z n become nearly identical; however, instead of showing that Dðp Z n kq Z n Þ vanishes, we show that the variational distance Vðp Z n ; q Z n Þ ¼ ð1=2Þ P z jp Z n ðzÞ À q Z ðzÞj vanishes, which is a slightly weaker result. 4  As was done in Section IV, let us introduce S the random variable representing the number of unerased observations in the eavesdropper's observation Z n , and let G S be the submatrix formed by the columns of G indexed by S. For the same reasons leading to <ref type="bibr" target="#b16">(16)</ref>, one can show that for all realizations s of S such that G s has full column rank, the distributions q Z n jS¼s and p Z n jS¼s are identical. Consequently, the variational distance between p Z n and q Z n may be upper bounded as</p><formula xml:id="formula_45">p Z n ðzÞ ¼ X m2F nÀk 2 W Z n jX n ðzjmGÞ 1 2 nÀk :<label>(34)</label></formula><formula xml:id="formula_46">Vðp Z n ; q Z n Þ 1 2 X z X s pðsÞjp Z n jS ðzjsÞ À q Z n jS ðzjsÞj ¼ 1 2 X z X s:G s is not full rank</formula><p>pðsÞ p Z n jS ðzjsÞ À q Z n jS ðzjsÞ PðG S is not full rankÞ:</p><p>If P B ð1 À Þ and P b ð1 À Þ, respectively, denote the probability of block error and bit error of the LDPC code over a BEC with erasure probability 1 À , we have by the same reasoning as in Section IV PðG S is not full rankÞ</p><formula xml:id="formula_48">P B ð1 À Þ nP b ð1 À Þ:<label>(36)</label></formula><p>Therefore, the variational distance</p><formula xml:id="formula_49">Vðp Z n ; q Z n Þ vanishes if the threshold Ã is such that Ã &gt; 1 À , and if P b ð1 À Þ ¼ Oð1=n Þ with &gt; 1.</formula><p>In general, an LDPC code sampled from the standard socket code ensemble with degree distribution ð; Þ does not satisfy the latter property, even if its threshold satisfies the former. However, one may use more specific ensembles to recover the desired property.</p><p>For instance, one may use ensembles with variable node degree at least three and girth at least four to avoid short cycles in the code. One can then show that the probability of error decays with the desired behavior if</p><formula xml:id="formula_50">Ã eff &gt; 1 À [57]</formula><p>, where Ã eff is the effective threshold of the code <ref type="bibr" target="#b60">[58]</ref>. Unfortunately, in general, Ã eff G Ã , which makes this ensemble suboptimal. To circumvent this issue, one may use an ensemble of large-girth LDPC codes whose girth grows logarithmically with the blocklength <ref type="bibr" target="#b61">[59]</ref>. For such ensembles, one can show that the probability of error decays with the desired behavior if Ã &gt; 1 À ; however, the performance gain comes at the cost of an increased complexity of the code. Another alternative is to use largegirth protograph LDPC constructions <ref type="bibr" target="#b26">[26]</ref>, which guarantee block error threshold equal to bit error threshold.</p><p>Finally, one obtains a secrecy code by combining the coset coding procedure described in Section IV with the chosen codes. Since an LDPC code and its cosets have the same threshold over a BEC, the resulting secrecy code achieves semantic secrecy. To put this result in more concrete perspective, consider the regular LDPC code ensemble with ðxÞ ¼ x 2 and ðxÞ ¼ x 5 , for which the threshold is Ã ¼ 0:429 and the effective threshold is Ã eff ¼ 0:366. The use of a code in the ensemble with girth at least four together with coset coding yields semantic secrecy if &gt; 0:634. In contrast, the use of a large girth LDPC code would result in semantic secrecy for &gt; 0:571. Since the code rate is 0.5, this is still suboptimal since an optimal code should be able to guarantee secrecy for &gt; 0:5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Channel Resolvability and Wiretap Coding Over</head><p>Symmetric Channels With Polar Codes: Polar codes provide a low-complexity solution to achieve semantic secrecy over wiretap channels when the main channel and the eavesdropper's channel are both binary-input symmetric channels <ref type="bibr" target="#b54">[52]</ref>, <ref type="bibr" target="#b62">[60]</ref>. Although the original proof did not make any explicit connection with the channel resolvability approach, it is rather natural with hindsight to present the construction within this framework.</p><p>Denote again by q Z n the distribution induced at the output of the symmetric eavesdropper's channel when the input is an i.i.d. process of uniformly distributed bits. We describe next how polar codes may be used to perform channel resolvability. Consider the standard polar transform G n and let 0 G G 1=2. Upon polarization, the bit channels W ðiÞ ZjX over the eavesdropper's channel may be classified according to their capacity CðW ðiÞ ZjX Þ as ''poor bits''</p><formula xml:id="formula_51">P ZjX ¼ i 2 ½ ½1; n : CðW ðiÞ ZjX Þ G 2 Àn n o<label>(37)</label></formula><p>and ''good bits''</p><formula xml:id="formula_52">G ZjX ¼ i 2 ½ ½1; n : C W ðiÞ ZjX ! 2 Àn n o :<label>(38)</label></formula><p>The strategy to simulate the distribution q Z n is to place random uniformly distributed bits in the positions of the good bits, and to fix the value of those in the positions of 4</p><p>In general, the only relation between Vðp Z n ; q Z n Þ and Dðp Z n kq Z n Þ is Pinsker's inequality <ref type="bibr">[56, p. 44]</ref>.</p><p>the bad bits. Intuitively, the uniform bits will be preserved by the nearly noiseless good bit channels, while the almost purely noisy poor bit channels will produce almost uniform bits for any input.</p><p>Formally, set n À k ¼ jG ZjX j, and consider the ðn; n À kÞ polar code obtained by using G ZjX as the set of information bits and P ZjX as the set of frozen bits. The distribution p Z n induced by this code at the output of the channel with uniformly distributed information bits is then</p><formula xml:id="formula_53">p Z n ðzÞ ¼ 1 2 nÀk X m2F nÀk 2 W Z n jX n zjðm0ÞG n ð Þ :</formula><p>Using the definition of the poor bit channels and the symmetry of the channel, one can show <ref type="bibr" target="#b54">[52]</ref>, <ref type="bibr" target="#b63">[61]</ref> that</p><formula xml:id="formula_54">lim n!1 n À k n ¼ IðX; ZÞ and lim n!1 Dðp Z n kq Z n Þ ¼ 0 (39)</formula><p>i.e., this constitutes an optimal channel resolvability code. Furthermore, if the channel is symmetric, one can show that the result remains true irrespective of the value of the frozen bits.</p><p>If the main channel were noiseless, then semantic secrecy of the bits in the frozen position would immediately follow. If the main channel is noisy, then polarization may be used once again to transmit information reliably over the main channel. Upon polarization, the bit channels W ðiÞ YjX over the main channel may be classified according to their Bhattacharyya parameter ZðW ðiÞ YjX Þ as ''bad bits''</p><formula xml:id="formula_55">B YjX ¼ i 2 ½ ½1; n : Z W ðiÞ YjX &gt; 2 Àn n o<label>(40)</label></formula><p>and ''good bits''</p><formula xml:id="formula_56">G YjX ¼ i 2 ½ ½1; n : Z W ðiÞ YjX 2 Àn n o :<label>(41)</label></formula><p>The bits placed in good bit positions may be used as information bits, while the bits in bad bits positions should be frozen to a fixed value. One can formally show that <ref type="bibr" target="#b23">[23]</ref> lim</p><formula xml:id="formula_57">n!1 jG YjX j n ¼ IðX; YÞ and lim n!1 P e ¼ 0:<label>(42)</label></formula><p>If G ZjX were a strict subset of G YjX , then the bits in positions G YjX n G ZjX could be transmitted both reliably and secretly, using the bits in G ZjX as randomization bits. Unfortunately, in general, we have G ZjX \ B YjX 6 ¼ ;, which means that some of the bits that need to be randomized to ensure secrecy should be fixed to ensure reliability. We refer to this problem as the ''misalignement'' of polarization indices, which will reappear in Section VI-B. An astute solution to circumvent this issue consists in protecting the bits in positions G ZjX \ B YjX using a shared secret key and a one-time pad <ref type="bibr" target="#b62">[60]</ref>. Assume that W YjZ is degraded with respect to W YjX , i.e., there exists a transition probability W ZjY such that</p><formula xml:id="formula_58">W ZjX ðzjxÞ ¼ X y W ZjY ðzjyÞW YjX ðyjxÞ:<label>(43)</label></formula><p>One can then show <ref type="bibr" target="#b54">[52]</ref> lim</p><formula xml:id="formula_59">n!1 jG ZjX \ B YjX j n ¼ 0<label>(44)</label></formula><p>so that the secret key required has negligible size; in addition, one may exploit a ''chaining construction'' over multiple blocks, in which a small fraction of the bits in G YjX \ P ZjX could be used as a secret key in the next block. This operation effectively increases the block length, but incurs a negligible secrecy penalty. In particular, note that (39), <ref type="bibr" target="#b42">(42)</ref>, and <ref type="bibr" target="#b44">(44)</ref> show that this polar code construction achieves rates arbitrarily close to IðX; YÞ À IðX; ZÞ with X $ Bð1=2Þ for symmetric channels. Finally, we note that the construction of such polar codes may be performed efficiently, using the algorithm described in <ref type="bibr" target="#b64">[62]</ref> to identify the various bit channels as per <ref type="bibr" target="#b37">(37)</ref>, <ref type="bibr" target="#b38">(38)</ref>, <ref type="bibr" target="#b40">(40)</ref>, and <ref type="bibr" target="#b41">(41)</ref>.</p><p>Remark: As discussed in Section VI-B, polar codes may work equally well for asymmetric channels, and without assuming that W YjZ is degraded with respect to W YjX , at the expense of relaxing semantic secrecy to strong secrecy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Channel Resolvability and Wiretap Coding With</head><p>Invertible Extractors Over Symmetric Channels: The last construction we describe uses invertible extractors, but is actually a specific instance of channel resolvability with injective homomorphisms <ref type="bibr" target="#b65">[63]</ref>. Specifically, denote again by q Z n , the distribution induced at the output of the symmetric eavesdropper's channel when the input is an i.i.d. process of uniformly distributed bits X. Consider now a family F of injective homomorphisms f : F k 2 ! F n 2 , such that the following property is satisfied:</p><formula xml:id="formula_60">8x 2 F n 2 n f0g8m 2 F k 2 n f0g P FðmÞ ¼ x ð Þ 1 2 n À 1 (<label>45</label></formula><formula xml:id="formula_61">)</formula><p>where F denotes the choice of a homomorphism uniformly at random in the family. Let p Z n denote the distribution induced at the output of the eavesdropper's channel when choosing m k uniformly at random. One can show <ref type="bibr" target="#b65">[63]</ref> that as long as lim n!1 ðk=nÞ &gt; IðX; ZÞ, then</p><formula xml:id="formula_62">lim n!1 E F V p Z n ; q Z n ð Þ ð Þ¼0:<label>(46)</label></formula><p>A specific instance of family F is the seeded invertible extractors proposed in <ref type="bibr" target="#b16">[16]</ref>. Specifically, for a seed s 2 F n 2 n f0g, consider the extractor</p><formula xml:id="formula_63">Ext : F n 2 Â F n 2 ! F nÀk 2 : ðs; xÞ7 !b ¼ D ðs xÞj ½½1;nÀk</formula><p>where is the multiplication in F 2 n and ðÁÞj ½½1;nÀk is the truncation of the last k bits. The family is parametrized by the choice of s. The inverser of Ext is</p><formula xml:id="formula_64">Inv : F n 2 Â F nÀk 2 Â F k 2 ! F n<label>2</label></formula><p>ðs; b; rÞ 7 ! s À1 ðbkrÞ <ref type="bibr" target="#b47">(47)</ref> where ðÁkÁÞ denotes the concatenation of two vectors and the auxiliary random variable r is assumed to be chosen uniformly at random in F k 2 . One can check that this family satisfies condition <ref type="bibr" target="#b45">(45)</ref>, hence ensuring channel resolvability.</p><p>The encoding complexity of Inv may be performed in Oðn log nÞ, for some, but limited, values of n. Indeed, the finite-field multiplication can be reduced to a ring multiplication, which is a convolution and can be efficiently performed by the number theoretic transform (see, for instance, <ref type="bibr" target="#b66">[64,</ref><ref type="bibr">Sec. 7.3]</ref>). However, the main issue is to find an irreducible polynomial in Z 2 ½X of degree n. Although it can be done when n is a Mersenne exponent, that is 2 n À 1 is prime, it is a difficult problem for arbitrary n. Another method for efficient finite-field multiplication consists in using a discrete Fourier transform [65, App. D], which requires the polynomial ðX nþ1 À 1Þ=ðX À 1Þ to be irreducible in F 2 ½X. The two methods are complementary, since they have similar complexities but have different constraints on n.</p><p>The construction of a secrecy code using this invertible extractor is much more versatile and general than the constructions described in Section VI-A1 and VI-A2. In fact, one can show that it is possible to combine the extractor with any linear ðn; k 0 Þ code ensuring reliability over the main channel <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b65">[63]</ref>, <ref type="bibr" target="#b68">[66]</ref>. Specifically, if the encoding function of the code is : F k 0 2 ! F n 2 , one may combine it with the inverser</p><formula xml:id="formula_65">Inv : F k 0 2 Â F k 0 Àk 2 Â F k 2 ! F k 0 2 ðs; b; rÞ 7 ! s À1 ðbkrÞ<label>(48)</label></formula><p>to obtain, for a fixed choice of the seed s, the encoder</p><formula xml:id="formula_66">f Inv : F k 2 Â F k 0 Àk 2 ! F n 2 m Â m 0 7 ! Invðs; m; m 0 Þ ð Þ :<label>(49)</label></formula><p>Another low-complexity option with similar performance consists in using a Toeplitz matrix over F 2 . In this case, the seed s consists of the components of the first line and first column of the Toeplitz matrix, and we denote TðsÞ a k Â ðk 0 À kÞ Toeplitz matrix defined by s. This allows us to then define another inverser Inv as</p><formula xml:id="formula_67">Inv : F k 0 À1 2 Â F k 0 Àk 2 Â F k 2 ! F k 0 2 ðs; b; rÞ 7 ! b À TðsÞrkr ð Þ<label>(50)</label></formula><p>where, when Inv is replaced by Inv, the code given in <ref type="bibr" target="#b49">(49)</ref> has similar performance for a symmetric channel W ZjX <ref type="bibr" target="#b69">[67]</ref>.</p><p>The complexity of Inv is also similar to that of Inv.</p><p>The main benefit of the inverser Inv over Inv is that there is no restriction on the size k 0 , so that Inv is a more powerful solution to design a wiretap code. However, the inverser Inv has a few advantages over the inverser Inv. In fact, instead of viewing the auxiliary random variable r as a random number, one may build upon <ref type="bibr" target="#b70">[68]</ref> to view it as another information source that is multiplexed with b. In this scenario, condition (45) is also required for the variable r; fortunately, the inverser Inv satisfies this condition for r, as well as for s <ref type="bibr" target="#b65">[63]</ref>. Another advantage of the inverser Inv is further discussed in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark:</head><p>The construction above also applies to asymmetric channels. In this case, however, semantic secrecy has to be dropped in favor of strong secrecy, and the result holds not for a specific code, but averaged over the code and its cosets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Binning and Privacy Amplification Constructions</head><p>Although the binning approach discussed in Section V-C is a well-established technique in information theory, most practical constructions are not based on this principle. This may be partly attributed to the fact that ''inverting'' the binning procedure to obtain an explicit construction does not seem the most promising way to obtain a low-complexity code, especially given the potential complexity of the required stochastic encoding. However, several recent works have developed constructive approaches, based on polar codes <ref type="bibr" target="#b71">[69]</ref>, <ref type="bibr" target="#b72">[70]</ref> and sparse matrices <ref type="bibr" target="#b73">[71]</ref>, <ref type="bibr" target="#b74">[72]</ref>. The performance versus complexity tradeoffs is provided in Table <ref type="table" target="#tab_2">2</ref> for reference.</p><p>Admittedly, these constructions are more involved than their counterparts of Section VI-A, and we refer the reader to <ref type="bibr" target="#b73">[71]</ref> and <ref type="bibr" target="#b74">[72]</ref> for a discussion of binning with sparse matrices. In the next paragraphs, we merely provide the high-level intuition behind the implementation of the binning approach with polar codes. We start by revisiting the two basic coding mechanisms underlying the binning approach: source coding with side information and privacy amplification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Source Coding With Polar Codes</head><formula xml:id="formula_68">: Consider a discrete memoryless source ðX Â Y; p XY Þ. For each x n 1 2 F n 2 polarized as u n 1 ¼ x n 1 G n , let u n 1 ½H XjY denote the high entropy bits of u n 1 in positions H XjY ¼ fi 2 ½½1; n : HðU i jU iÀ1 1 Y n 1 Þ &gt; n g and n ¼ 2 Àn with 0 G G 1=2.</formula><p>Intuitively,H XjY contains the positions of the bits that one cannot compress further, while H c XjY contains the positions of the nearly deterministic bits given y n 1 . Given the bits u n 1 ½H XjY and y n 1 , consider the following procedure to reconstruct x n 1 . For every i 2 ½½1; n, sample ũn 1 from the distribution</p><formula xml:id="formula_69">pU i jU iÀ1 1 ũi jũ iÀ1 1 À Á ¼ 11fũ i ¼ u i g; if i 2 H YjX p U i jU iÀ1 1 Y n 1 ũi jũ iÀ1 1 y n 1 À Á ; if i 2 H c YjX &amp;<label>(51)</label></formula><p>and create xn 1 ¼ ũn 1 G n . Then, one can show <ref type="bibr" target="#b75">[73]</ref> that</p><formula xml:id="formula_70">P Xn 1 6 ¼ X n 1 À Á n and that lim n!1 1 n jH XjY j ¼ H XjY ð Þ:<label>(52)</label></formula><p>In other words, the high entropy bits in positions H XjY play the same role as the bin index C ¼ n ðX n 1 Þ created with random binning in Section V-C for source coding with side information.</p><p>2) Privacy Amplification With Polar Codes: Consider now another discrete memoryless source ðX Â Z;</p><formula xml:id="formula_71">p XZ Þ. For each x n 1 2 F n 2 polarized as u n 1 ¼ x n 1 G n , let u n 1 ½V XjZ denote the very high entropy bits of u n 1 in positions V XjZ ¼ fi 2 ½½1; n : HðU i jU iÀ1 1 Z n 1 Þ &gt; 1 À n g a n d n ¼ 2 Àn w i t h 0 G G 1=2.</formula><p>Intuitively, the bits in V XjZ are the almost completely random bits that are nearly independent of Z n , and one can formally show [74, Lemma 1]</p><formula xml:id="formula_72">V p U n 1 ½V XjZ Z n 1 ; q U n 1 ½V XjZ p Z n 1 n and lim n!1 1 n jV XjZ j ¼ HðXjZÞ<label>(53)</label></formula><p>where q U n 1 ½V XjZ is the uniform distribution on V XjZ . In other words, the very high entropy bits in positions V XjZ therefore play the same role as the bin index used in random binning proofs of privacy amplification.</p><p>3) Construction of Secrecy Code: Since source coding and privacy amplification may be implemented with polarization, the secrecy codes obtained from random binning in Section V-C can be derived using source polarization as a linear and low-complexity alternative. Specifically, let X n 1 have an i.i.d. distribution according to p X , let U n 1 ¼ X n 1 G n , and denote by V X ¼ fi 2 ½½1; n : HðU i jU iÀ1 1 Þ &gt; 1 À n g the positions of the very high entropy bits of X n 1 . Let Y n 1 and Z n 1 be the correlated random variables obtained at the output of the wiretap channel. If the set H XjY were a strict subset of V XjZ , an encoder could be constructed as follows. 1) Place secret bits in positions indexed by V XjZ n H XjY ; this corresponds to the index M in Section V-C. 2) Place random bits representing the code in positions indexed by H XjY ; this corresponds to the index C in Section V-C. Although the code is chosen randomly and not deterministically, these bits need not be regenerated in every block. 3) Reconstruct the codeword by ''inverting'' the binning, i.e., placing uniform bits in positions indexed by V X n V XjZ , generating the bits in positions indexed by V c X according to p U i jU iÀ1 1 , and applying the polarization transform G n to the resulting vector; this corresponds to the sampling according to p X n j n ðX n 1 Þ¼C; n ðX n 1 Þ¼M in Section V-C. Unfortunately, in general, the polarization indices are misaligned and H XjY \ V c XjZ 6 ¼ ;. As in Section VI-A2, this problem may be circumvented in the case of degraded channels using a chaining over multiple blocks and a small secret key. It has also been recently shown <ref type="bibr" target="#b71">[69]</ref>, <ref type="bibr" target="#b72">[70]</ref> that the procedure could be generalized for nondegraded and asymmetric channels, as well. Although the approach remains conceptually similar to what was presented here, the actual constructions rely on subtle techniques over multiple blocks to handle misaligned indices, and are therefore not discussed further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. TOWARD INTEGRABLE SECRECY CODES</head><p>In this final section, we discuss what we believe are the most important challenges toward the deployment and integration of secrecy codes in actual communication devices. In spite of the significant recent conceptual and practical progress toward a better understanding of the coding approaches for secrecy highlighted in Sections V and VI, much remains to be done to make secrecy codes as easily implementable as traditional codes for reliability.</p><p>At a high level, one must recognize that error control codes for physical-layer secrecy are not meant to replace the secrecy algorithms and protocols already deployed in practical systems. Many of the current cryptographic solutions are the result of intense optimizations and offer a tradeoff between ease of implementation and performance that is deemed acceptable for most legacy communication systems. While the effectiveness of this approach is unquestionable, new systems are emerging in which treating security as an overlay feature on top of reliability may not be the most appropriate solution. For instance, secret-key management in modern wireless networks, which comprise many heterogeneous nodes with limited computational and energy resources, is far from trivial. These networks could benefit from the integration of keyless security mechanisms in the physical layer by design, which is all the more justified if it is cost effective and transparent for the upper layers.</p><p>One must also acknowledge that the secrecy performance of all codes discussed in this paper relies on the assumption that the eavesdropper's channel statistics are known. In realistic settings, one may not even be aware of the presence of a passive adversary, in which case it may be difficult to introduce an a priori model for statistics. Fortunately, signal processing and communications techniques have been recently developed to mitigate if not overcome these challenges. In particular, three techniques seem particularly promising.</p><p>Cooperative jamming <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b77">[75]</ref>. The principle of cooperative jamming is to exploit interference in a way that is more detrimental to an adversary than to a legitimate receiver. Interferences can be introduced either with artificial noise, whose effect is typically to reduce the SNR of undesirable receivers or with codewords from well-designed codebooks <ref type="bibr" target="#b53">[51]</ref>.</p><p>Cooperation and two-way communication <ref type="bibr" target="#b78">[76]</ref>, <ref type="bibr" target="#b79">[77]</ref>. The idea behind cooperation for secrecy is to exploit the ability for legitimate terminals to interact to gain an advantage over a potential adversary. This interaction may take many forms, from receiver feedback to complete two-way communication. In general, two-way communication makes physical-layer security systems not only more efficient but also more robust.</p><p>Signaling over multiple antennas <ref type="bibr" target="#b80">[78]</ref>- <ref type="bibr" target="#b83">[80]</ref>. The use of multiple antennas allows one to exploit multiple spatial degrees of freedom. For instance, one can spread coded messages across degrees of freedom and relax assumptions regarding the exact statistics of potential adversaries. Although we restricted our discussion to binary codes for simplicity, the generalization of all the code constructions given in Section VI does not offer any major conceptual difficulty. Nonbinary LDPC codes and nonbinary polar codes could be designed following the same guidelines and leveraging known properties <ref type="bibr" target="#b84">[81]</ref>. Thanks to the modular nature of the constructions based on invertible extractors, these constructions would generalize to nonbinary settings even more easily.</p><p>Developing families of secrecy-capacity achieving codes for continuous channels, especially Gaussian and wireless channels, is practically relevant and requires not completely trivial extensions of existing ones. Nevertheless, as illustrated in Section IV, a simple degradation argument as in <ref type="bibr" target="#b24">(24)</ref> allows one to use secrecy codes developed for discrete channels over Gaussian channels, at the expense of a rate penalty. Secrecy codes based on invertible extractors may also be extended to continuous channels, as shown in <ref type="bibr" target="#b65">[63,</ref><ref type="bibr">App. D]</ref>. The generalization to wireless channels, which depend on a fading state, is not as direct and would require the construction of codes with information-theoretic secrecy guarantees for statedependent channels. There are several works that suggest the benefits of lattice codes for secrecy <ref type="bibr" target="#b85">[82]</ref>, although the complexity of the constructions is presently not quite on par with those provided in this paper.</p><p>A more fundamental issue, which we have not addressed in this paper, is the robustness of the secrecy code constructions to imperfections. In particular, two imperfections may have adverse effects on the operation of secrecy codes: imperfections in channel modeling and imperfections in the randomization of the stochastic encoder. In fact, all constructions discussed so far require a knowledge of the eavesdropper's channel statistics. Ideally, it would be desirable to develop universal constructions that offer a guaranteed secrecy performance as soon as the eavesdropper's channel capacity drops below a prescribed threshold, irrespective of its actual statistics. The existence of such codes has been proved with information-theoretic arguments <ref type="bibr" target="#b65">[63]</ref>, but practical constructions are still elusive. Another assumption behind all presented code constructions is that the randomization is exactly performed with uniformly distributed bits. However, in practice, random numbers may stem either from another information source or a biased random number generator. This problem of nonuniformity of information sources is often dismissed by invoking a ''folklore result'' in source coding, according to which the distribution of compressed sources is uniform. Unfortunately, this is only true in a really weak sense <ref type="bibr" target="#b86">[83]</ref>, <ref type="bibr" target="#b87">[84]</ref>; even optimal data compression codes typically only guarantee that the normalized divergence between the distribution of compressed data and a uniform distribution is small. Fortunately, several theoretical results show the existence of secrecy codes that operate with nonuniform randomiza-tion <ref type="bibr" target="#b65">[63]</ref>, <ref type="bibr" target="#b88">[85]</ref>. A practical construction of low-complexity codes is also possible by modifying the inverser Inv <ref type="bibr" target="#b65">[63]</ref>.</p><p>Finally, an important task that lies ahead is to analyze the precise behavior of secrecy codes at finite length. The typical lengths found in wireless communication devices rarely exceed a few thousands of bits, far from the ''large blocklength'' regime used to design some of the long codes in Section VI. For instance, the known performance bounds of polar codes for finite length shed a somewhat pessimistic light on their practicality. Nevertheless, the performance bounds of extractor-based codes are much more promising and, as shown in the example of Section IV and investigated in <ref type="bibr" target="#b89">[86]</ref>, the design of short secrecy codes is possible. It remains unclear how far from optimal known constructions are, and the development of finite block length bounds for actual codes or converse bounds <ref type="bibr" target="#b90">[87]</ref> would be a valuable tool to answer this conclusively. h</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Shannon's cryptosystem for confidential communication [6].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Generic structure of encoder for secrecy. The encoder consists of a codebook with a bin structure in which codewords V n are addressed by the secret message M and an auxiliary randomization message M 0 ; a noisy channel to inject artificial noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Binary erasure wiretap channel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Semantic secrecy of RM(8, 2) and RM(9, 2) over BEC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Intuitive illustration of channel resolvability. With enough sequences x, the union of the conditional typical sets covers the entire set of typical sequences z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Intuitive illustration of channel coding. The number of sequences x in the codebook should be sufficiently small to ensure that the union of conditional typical sets packs the entire set of typical sequences z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Intuitive illustration of privacy amplification. The indices assigned by binning are represented by the various white symbols.As long as the number of distinct sequences does not exceed the size of the conditionally typical sets in gray, the index is nearly independent of z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Comparison of Secrecy Codes Built From Channel Resolvability Bloch et al.: Error-Control Coding for Physical-Layer Secrecy</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Comparison of Secrecy Codes Built From Binning</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>One could argue that solving the problem also requires an efficient algorithm to compute the secrecy capacity, which is only known in certain cases<ref type="bibr" target="#b19">[19]</ref>,<ref type="bibr" target="#b20">[20]</ref>. Bloch et al.: Error-Control Coding for Physical-Layer Secrecy Vol. 103, No. 10, October 2015 | Proceedings of the IEEE 1729</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Bloch et al.: Error-Control Coding for Physical-Layer Secrecy Vol. 103, No. 10, October 2015 | Proceedings of the IEEE 1737</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Vol. 103, No. 10, October 2015 | Proceedings of the IEEE 1739</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Bloch et al.: Error-Control Coding for Physical-Layer Secrecy</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Vol. 103, No. 10, October 2015 | Proceedings of the IEEE 1743</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The authors would like to thank the reviewers for their constructive comments and careful review, which have improved the presentation of this paper. faculty of the School of Electrical and Computer Engineering, Georgia Institute of Technology, and from 2009 to 2013, he was based at Georgia Tech Lorraine. He is the coauthor of the textbook Physical-Layer Security: From Information Theory to Security Engineering (Cambridge, U.K.: Cambridge Univ. Press, 2011). His research interests are in the areas of information theory, error-control coding, wireless communications, and cryptography. Dr. Bloch has served on the organizing committee of several international conferences. He was the Chair the Online Committee of the IEEE Information Theory Society from 2011 to 2014. He is the corecipient of the IEEE Communications Society and the IEEE Information Theory Society 2011 Joint Paper Award. Masahito Hayashi (Senior Member, IEEE) was born in Japan in 1971. He received the B.S. degree from the Faculty of Sciences and the M.S. and Ph.D. degrees in mathematics from Kyoto University, Kyoto, Japan, in 1994, 1996, and 1999, respectively. He was with Kyoto University as a Research Fellow of the Japan Society of the Promotion of Science (JSPS) from 1998 to 2000, and with the Laboratory for Mathematical Neuroscience, Brain Science Institute, RIKEN, from 2000 to 2003. He worked in ERATO Quantum Computation and Information Project, Japan Science and Technology Agency (JST) as the Research Head from 2000 to 2006. He also worked in the Superrobust Computation Project Information Science and Technology Strategic Core (21st Century COE by MEXT), Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan, as an Adjunct Associate Professor from 2004 to 2007. He worked in the Graduate School of Information Sciences, Tohoku University, Sendai, Japan, as an Associate Professor from 2007 to 2012. In 2012, he joined the Graduate School of Mathematics, Nagoya University, Nagoya, Japan, as a Professor. He also worked in the Centre for Quantum Technologies, National University of Singapore, Singapore, as a Visiting Research Associate Professor from 2009 to 2012 and as a Visiting Research Professor from 2012 to now. He published the book Quantum Information: An Introduction(New York, NY, USA: Springer-Verlag, 2006). His research interests include classical and quantum information theory and classical and quantum statistical inference. Dr. Hayashi received the 2011 Information Theory Society Paper Award for the paper ''Information-spectrum approach to second-order coding rate in channel coding.'' He is on the Editorial Board of the International Journal of Quantum Information and the International Journal on Advances in Security.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The work of M. Bloch was supported in part by the NSF-CIF-1320298 and ANR-13-BS03-0008 grants. The work of M. Hayashi was supported in part by a MEXT Grant-in-Aid for Science Research (A) 23246071 and by the National Institue of Information and Communication Technology (NICT), Japan. Andrew Thangaraj (Senior Member, IEEE) received the B.Tech. degree in electrical engineering from the Indian Institute of Technology Madras (IIT Madras), Chennai, India, in 1998 and the Ph.D. degree in electrical engineering from the Georgia Institute of Technology, Atlanta, GA, USA, in 2003. He was a Postdoctoral Researcher at the GTL-CNRS Telecom lab, Georgia Tech Lorraine, Metz, France, from August 2003 to May 2004. From June 2004, he has been with the Department of Electrical Engineering, IIT Madras, where he is currently a Professor. Dr. Thangaraj has been serving as Editor for the IEEE TRANSACTIONS ON COMMUNICATIONS since January 2012.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The wire-tap channel</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech. J</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1355" to="1367" />
			<date type="published" when="1975-10">Oct. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Common randomness in information theory and cryptography. I. Secret sharing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ahlswede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Csisza ´r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1121" to="1132" />
			<date type="published" when="1993-07">Jul. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Secret key agreement by public discussion from common information</title>
		<author>
			<persName><forename type="first">U</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="733" to="742" />
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Approximation theory of output statistics</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verdu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="752" to="772" />
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalized privacy amplification</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brassard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1915" to="1923" />
			<date type="published" when="1995-11">Nov. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Communication theory of secrecy systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech. J</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="656" to="715" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Broadcast channels with confidential messages</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csisza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ko ¨rner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="348" />
			<date type="published" when="1978-05">May 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">New hash functions and their use in authentication and set equality</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="265" to="279" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the converse to the coding theorem for discrete memoryless channels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="357" to="359" />
			<date type="published" when="1973-05">May 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LDPC codes for the Gaussian wiretap channel</title>
		<author>
			<persName><forename type="first">D</forename><surname>Klinc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-J</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Forens. Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="532" to="540" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Coding with scrambling, concatenation, HARQ for the AWGN wire-tap channel: A security gap analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chiaraluce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><surname>Forens</surname></persName>
		</author>
		<author>
			<persName><surname>Security</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-06">Jun. 2012</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="883" to="894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Gaussian wire-tap channel</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Leung-Yan-Cheong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="456" />
			<date type="published" when="1978-07">Jul. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information-Theoretic Security, ser. Foundations and Trends in Communications and Information Theory</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2009">2009</date>
			<publisher>Now Publishers</publisher>
			<pubPlace>Delft, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barros</surname></persName>
		</author>
		<title level="m">Physical Layer Security: From Information Theory to Security Engineering</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The strong secret key rate of discrete random triples,&apos;&apos; in Communications and Cryptography: Two Sides of One Tapestry</title>
		<author>
			<persName><forename type="first">U</forename><surname>Maurer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Kluwer</publisher>
			<biblScope unit="page" from="271" to="285" />
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semantic security for the wiretap channel</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tessaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology-CRYPTO 2012</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Safavi-Naini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Canetti</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7417</biblScope>
			<biblScope unit="page" from="294" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic encryption</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Micali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="299" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cooperative security at the physical layer: A summary of recent advances</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bassily</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An algorithm for computing the secrecy capacity of broadcast channels with confidential messages</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yasui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Suko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Matsushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="936" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computation of secrecy capacity for more-capable channel pairs</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Gowtham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thangaraj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="529" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Macwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sloane</surname></persName>
		</author>
		<title level="m">The Theory of Error-Correcting Codes</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland</publisher>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urbanke</surname></persName>
		</author>
		<title level="m">Modern Coding Theory</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Channel polarization: A method for constructing capacity-achieving codes for symmetric binary-input memoryless channels</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arikan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3051" to="3073" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<title level="m">Channel Codes. Classical and Modern</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Capacity-approaching protograph codes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Divsalar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dolinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="876" to="888" />
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deterministic constructions for large girth protograph LDPC codes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thangaraj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-07">Jul. 2013</date>
			<biblScope unit="page" from="1680" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Regular and irregular progressive edge-growth Tanner graphs</title>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Eleftheriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arnold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="386" to="398" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Low-density parity-check (LDPC) codes constructed from protographs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thrope</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INP Progr. Rep</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="42" to="154" />
			<date type="published" when="2005-08">Aug. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Construction of quasi-cyclic LDPC codes for AWGN and binary erasure channels: A finite field approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2429" to="2458" />
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Vadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pseudorandomness, ser. Foundations and Trends in Communications and Information Theory</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<date type="published" when="2012">2012</date>
			<publisher>Now Publishers</publisher>
			<pubPlace>Delft, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fuzzy extractors: How to generate strong keys from biometrics and other noisy data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dodis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Reyzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="139" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Threshold saturation via spatial coupling: Why convolutional LDPC ensembles perform so well over the BEC</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kudekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urbanke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="803" to="834" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Applications of LDPC codes to the wiretap channels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dihidar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Merolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2933" to="2945" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wiretap channel II</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ozarow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AT&amp;T Bell Lab. Tech. J</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2135" to="2157" />
			<date type="published" when="1984-12">Dec. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Secure nested codes for type II wiretap channels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spasojevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Inf. Theory Workshop</title>
		<meeting>IEEE Inf. Theory Workshop<address><addrLine>Lake Tahoe, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="337" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of Information Theory</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Almost independence and secrecy capacity</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csisza ´r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probl. Inf. Transm</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="47" />
			<date type="published" when="1996-03">Jan.-Mar. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The private classical capacity and quantum capacity of a quantum channel</title>
		<author>
			<persName><forename type="first">I</forename><surname>Devetak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="55" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">General nonasymptotic and asymptotic formulas in channel resolvability and identification capacity and their application to the wiretap channels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1562" to="1575" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Strong secrecy from channel resolvability</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Laneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="8077" to="8098" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Effective secrecy: Reliability, confusion and stealth</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-07">Jul. 2014</date>
			<biblScope unit="page" from="601" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reliability and secrecy functions of the wiretap channel under cost constraint</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="6819" to="6843" />
			<date type="published" when="2014-11">Nov. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The common information of two dependent random variables</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="179" />
			<date type="published" when="1975-03">Mar. 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Distributed channel synthesis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cuff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7071" to="7096" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Achieving the secrecy capacity of wiretap channels using polar codes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mahdavifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="913" to="917" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Secrecy-achieving polar-coding</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Inf. Theory Workshop</title>
		<meeting>IEEE Inf. Theory Workshop<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Polar coding for secure transmission and key agreement</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">O</forename><surname>Koyluoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Gamal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp</title>
		<meeting>IEEE Int. Symp<address><addrLine>Istambul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
			<biblScope unit="page" from="2698" to="2703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Nested polar codes for wiretap and relay channels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thobaben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kliewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skoglund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Lett</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="752" to="754" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Two edge type LDPC codes for the wiretap channel</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thobaben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kliewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skoglund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Asilomar Conf. Signals Syst. Comput</title>
		<imprint>
			<biblScope unit="page" from="834" to="838" />
			<date type="published" when="2009">2009</date>
			<pubPlace>Monticello, IL, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Equivocation of Eve using two edge type LDPC codes for the binary erasure wiretap channel</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thobaben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kliewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Skoglund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Asilomar Conf. Signals Syst. Comput</title>
		<imprint>
			<biblScope unit="page" from="2045" to="2049" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">LDPC-based coded cooperative jamming codes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Pierrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Inf. Theory Workshop</title>
		<meeting>IEEE Inf. Theory Workshop<address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09">Sep. 2012</date>
			<biblScope unit="page" from="462" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Achieving the secrecy capacity of wiretap channels using polar codes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mahdavifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6428" to="6443" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Noisy channel coding via privacy amplification and information reconciliation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Renes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Renner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7377" to="7385" />
			<date type="published" when="2011-11">Nov. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Achievability proof via output statistics of random binning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yassaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Aref</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gohari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07">Jul. 2012</date>
			<biblScope unit="page" from="1044" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Noiseless coding of correlated information sources</title>
		<author>
			<persName><forename type="first">D</forename><surname>Slepian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="480" />
			<date type="published" when="1973-07">Jul. 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Csisza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ko ¨rner</surname></persName>
		</author>
		<title level="m">Information Theory: Coding Theorems for Discrete Memoryless Systems</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Strong secrecy for erasure wiretap channels</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mclaughlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Inf. Theory Workshop</title>
		<meeting>IEEE Inf. Theory Workshop<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Stopping set distribution of LDPC code ensembles</title>
		<author>
			<persName><forename type="first">A</forename><surname>Orlitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="929" to="953" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Strong secrecy on the binary erasure wiretap channel using large-girth LDPC codes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mclaughlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Forens. Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="585" to="594" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A new polar coding scheme for strong security on wiretap channels</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sasoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1117" to="1121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Strong coordination with polar codes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kliewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 50th Allerton Conf</title>
		<meeting>50th Allerton Conf<address><addrLine>Monticello, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-10">Oct. 2012</date>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">How to construct polar codes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6562" to="6582" />
			<date type="published" when="2013-10">Oct. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Secure multiplex coding with dependent and non-uniform multiple messages</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Matsumoto</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1202.1332" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Reconciliation of a quantum-distributed Gaussian key</title>
		<author>
			<persName><forename type="first">G</forename><surname>Van Assche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cardinal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Cerf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="394" to="400" />
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">More efficient privacy amplification with less random seeds via dual universal Hash function</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tsurumaru</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1311.5322" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Channel upgrading for semantically-secure encryption on wiretap channels</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory, Istanbul, Turkey</title>
		<meeting>IEEE Int. Symp. Inf. Theory, Istanbul, Turkey</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1561" to="1565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Exponential decreasing rate of leaked information in universal random privacy amplification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3989" to="4001" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Secure multiplex coding attaining channel capacity in wiretap channels</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="8131" to="8143" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Achieving secrecy capacity of the wiretap channel and broadcast channel with a confidential component</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gulcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barg</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1410.3422" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Polar coding for the broadcast channel with confidential messages and constrained randomization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.0281" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Construction of wiretap channel codes by using sparse matrices</title>
		<author>
			<persName><forename type="first">J</forename><surname>Muramatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miyake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Inf. Theory Workshop</title>
		<meeting>IEEE Inf. Theory Workshop<address><addrLine>Taormina, Sicily</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-10">Oct. 2009</date>
			<biblScope unit="page" from="105" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Channel coding and lossy source coding using a generator of constrained random numbers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Muramatsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2667" to="2686" />
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Source polarization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arikan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="899" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Polar coding for secret-key generation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Abbe</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1305.4746" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">The general Gaussian multiple-access and two-way wiretap channels: Achievable rates and cooperative jamming</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2735" to="2751" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Secrecy when the eavesdropper controls its channel states</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory, Saint</title>
		<meeting>IEEE Int. Symp. Inf. Theory, Saint<address><addrLine>Petersburg, Russia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="618" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Strongly secure communications over the two-way wiretap channel</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Pierrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Forens. Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="595" to="605" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Providing secrecy irrespective of eavesdropper&apos;s channel state</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Global Telecommun</title>
		<meeting>IEEE Global Telecommun<address><addrLine>Miami, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Providing secrecy when the eavesdropper channel is arbitrarily varying: A case for multiple antennas</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 48th Annu. Allerton Conf. Commun</title>
		<meeting>48th Annu. Allerton Conf. Commun</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Control Comput</title>
		<imprint>
			<biblScope unit="page" from="1228" to="1235" />
			<date type="published" when="2010">2010</date>
			<pubPlace>Monticello, IL, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">MIMO wiretap channels with unknown and varying eavesdropper channel states</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="6844" to="6869" />
			<date type="published" when="2014-11">Nov. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Polar codes for discrete alphabets</title>
		<author>
			<persName><forename type="first">E</forename><surname>˘lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2137" to="2141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Semantically secure lattice codes for the Gaussian wiretap channel</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Belfiore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stehl</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1210.6673" />
		<imprint>
			<date type="published" when="2012-10">October 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Folklore in source coding: Information-spectrum approach</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="747" to="753" />
			<date type="published" when="2005-02">Feb. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Second-order asymptotics in fixed-length source coding and intrinsic randomness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4619" to="4637" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">On secure communication with constrained randomization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kliewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07">Jul. 2012</date>
			<biblScope unit="page" from="1172" to="1176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Best binary equivocation code construction for syndrome coding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomlinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ambroze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Commun</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1696" to="1704" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Strong converse and second-order asymptotics of channel resolvability</title>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Inf. Theory</title>
		<meeting>IEEE Int. Symp. Inf. Theory<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1882" to="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">He is an Associate Professor in the School of Electrical and Computer Engineering, Georgia Institute of Technology</title>
	</analytic>
	<monogr>
		<title level="m">Gif-sur-Yvette, France, the M.S. degree in electrical engineering from the Georgia Institute of Technology</title>
		<meeting><address><addrLine>Atlanta, GA, USA; Franche-Comte ´, Besançon, France; South Bend, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008-2009. July 2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Notre Dame</orgName>
		</respStmt>
	</monogr>
	<note>2006, and the Ph.D. degree in electrical engineering from the Georgia Institute of Technology in 2008. he has been on the</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
