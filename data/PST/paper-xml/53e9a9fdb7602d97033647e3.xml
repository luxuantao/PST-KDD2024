<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Summarizing tourist destinations by mining user-generated travelogues and photos</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-12-08">8 December 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yanwei</forename><surname>Pang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information Engineering</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300072</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qiang</forename><surname>Hao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information Engineering</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300072</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
							<email>yuany@opt.ac.cn</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Center for OPTical IMagery Analysis and Learning (OPTIMAL)</orgName>
								<orgName type="department" key="dep2">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep3">Xi&apos;an Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Shaanxi</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tanji</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information Engineering</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300072</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Cai</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Summarizing tourist destinations by mining user-generated travelogues and photos</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-12-08">8 December 2010</date>
						</imprint>
					</monogr>
					<idno type="MD5">6D9A056085CA12D4CF996F1802AE4B21</idno>
					<idno type="DOI">10.1016/j.cviu.2010.10.010</idno>
					<note type="submission">Received 5 February 2010 Accepted 1 October 2010</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Travelogue mining Destination summarization User-generated content Virtual tour</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatically summarizing tourist destinations with both textual and visual descriptions is highly desired for online services such as travel planning, to facilitate users to understand the local characteristics of tourist destinations. Travelers are contributing a great deal of user-generated travelogues and photos on the Web, which contain abundant travel-related information and cover various aspects (e.g., landmarks, styles, activities) of most locations in the world. To leverage the collective knowledge of travelers for destination summarization, in this paper we propose a framework which discovers locationrepresentative tags from travelogues and then select relevant and representative photos to visualize these tags. The learnt tags and selected photos are finally organized appropriately to provide an informative summary which describes a given destination both textually and visually. Experimental results based on a large collection of travelogues and photos show promising results on destination summarization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the prosperity of travel and the World Wide Web in recent years, the increasing amount of travel-related information and services on the Web facilitates people to plan their trips online. We consider a scenario where a user plans a trip in two steps: <ref type="bibr" target="#b0">(1)</ref> selecting a destination from some candidate destinations recommended by other tourists or a travel recommendation system and (2) browsing the characteristics of the selected destination to get an overview of things-to-do (e.g., landmarks to visit, styles to experience, activities to participate), so as to plan detailed travel route. In both steps of such a scenario, it is highly desired to summarize the information related to a destination to help users understand its local characteristics efficiently, for further destination selection or travel route planning.</p><p>According to the above scenario, we believe a good destination summary should be both representative and comprehensive in content. Being representative helps identify popular landmarks while being comprehensive is even more important because travel is more than landmark browsing; it is more attractive to provide potential tourists with information covering various interesting aspects such as styles (e.g., desert, ocean) and activities (e.g., dive, surf). In addition, a satisfactory destination summary should contain both textual and visual information. The textual descriptions facilitate users to capture the high-level concepts that characterize a destination, while visual descriptions supplement the textual descriptions with intuitive presentation so as to help users experience a virtual tour <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b30">31]</ref> before their trips.</p><p>Meanwhile, more and more people, encouraged by the Web 2.0 technologies, are enthusiastic about recording and sharing their travel experiences on the Web by contributing user-generated content (UGC) in the form of textual travelogues and photos taken during the trips. Although on the Web there is a great deal of structured travelrelated information (e.g., vacation packages, flights, hotels) provided by travel websites and travel agents, lots of people who are planning a trip prefer to learn folk experience and guidance from other travelers, by surveying the UGC contributed by them. UGC supplements the structured information with unstructured but personal descriptions of tourist destinations and services, in the form of textual (e.g., travelogues) and visual (e.g., photos) information. Although the information in a single travelogue or photo is possibly noisy or biased, the content contributed by numerous travelers as a whole could reflect people's overall preference and understanding of travel resources, and thus can serve as a reliable knowledge source for destination summarization.</p><p>Therefore, in this paper, the summarization of tourist destinations is based on the UGC on the Web. Specifically, we consider two types of UGC, namely travelogues and photos. By travelogues we refer to the text contributed by travelers to record and share their travel experiences on weblogs, forums, or Web 2.0 communities; by photos we refer to the images photographed by travelers during their trips and published on online albums such as Flickr <ref type="bibr" target="#b0">[1]</ref>.</p><p>Travelogues and photos correspond to the textual and visual descriptions necessary in the satisfactory destination summaries, respectively. Moreover, we claim that travelogues and photos should play different roles in the summarization of destinations due to their distinct characteristics. Recently, mining locationrelated information (e.g., textual tags that characterize a location) from tags associated with Flickr photos has been actively investigated <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref>. However, since tagging on Flickr is open, the tags are semantically unconstrained and only a part of them are related to travel. It is non-trivial to distinguish these travel-related tags from noisy ones simply based on Flickr data, as there are few contextual evidences other than the geo-tags associated with photos. By contrast, travelogues not only naturally concentrate on travelrelated themes but also contain much richer textual contexts of locations to help characterize locations. In addition, travelogues cover various travel-related aspects, including not only landmarks and natural things which correspond to specific visual characteristics and photos, but also abstract aspects (e.g., history, culture) which are informative to tourists but difficult to visualize using photos. With such rich information, travelogues could support more comprehensive descriptions of destinations than photos.</p><p>Motivated by the above observations, we propose to outline a given destination based on its relevant travelogues and photos successively in two steps. First, we figure out the semantics to be involved in the destination summary by mining locationrepresentative tags from travelogues relevant to the given destination. Then, we visualize these representative tags by selecting relevant and representative photos from the location-relevant photos. In this way, travelogues and photos complement each other to characterize the given destination both textually and visually, covering representative and comprehensive aspects which are informative for trip planners.</p><p>However, either travelogue mining for location-representative tags or photo selection for tag visualization is a non-trivial task because user-generated travelogues and photos, like other UGC, are noisy and unstructured data.</p><p>On one hand, mining location-representative knowledge from travelogues is challenging due to the data's intrinsic limitations listed as follows:</p><p>Noisy topics: As other UGC, most travelogues are unstructured and contain much noise. Particularly, the depictions of tourist destinations, in which the common tourists are most interested, are usually intertwined with common topics which tend to appear in travelogues related to various locations. Although these topics (e.g., accommodation, transportation, expense) are possibly useful for tourists, they can hardly characterize tourist destinations, and thus are beyond our objective of destination summarization in this paper. Multiple viewpoints: For each destination, there are usually various descriptions coming from many previous travelers. When trying to comprehensively know about a destination, users usually confront a dilemma that the viewpoint in each single travelogue may be biased, while it is time-consuming to read and summarize lots of related travelogues to obtain an overview of the destination.</p><p>To overcome the above limitations of travelogue data, some information processing techniques are necessary. To cope with the noisy topics, we need to discover topics from travelogues and further differentiate between location-related topics and other topics. To tackle the multiple viewpoints, we need to find a location representation that could summarize all the informative descriptions of a location to capture its location-representative knowledge (i.e., local characteristics from the perspective of tourism).</p><p>On the other hand, it is challenging to select relevant and representative photos from a set of user-generated photos for a given textual query. There are mainly two reasons: Ambiguous queries: The given textual query might be ambiguous for photo selection, due to its limited length and the information gap between travelogues and photos. For instance, a query tag cable for the destination San Francisco refers to the cable cars popular in the city, but some photos annotated with cable are actually depicting cable wires instead of the desired semantic. Noisy tags: Since most of the tags associated with user-generated photos are provided by the owners of the photos, the tag list of each photo is possibly noisy and inaccurate. Consequently, the semantic gap between tags and photos is enlarged, and the results of simple text-based photo selection are much less reliable, as a photo with exactly the query text in its tag list might be totally irrelevant.</p><p>To tackle the above challenges in text-based photo selection, we need to expand the given textual queries with relevant information for disambiguation, and simultaneously refine the raw tags associated with photos to narrow the semantic gap between textual and visual information.</p><p>In this paper, we consider the above issues and investigate the problem of leveraging user-generated travelogues and photos to generate summary, including textual and visual descriptions, for a given tourist destination.</p><p>For the travelogue mining, we resort to probabilistic topic models, e.g., probabilistic latent semantic analysis (PLSA) <ref type="bibr" target="#b15">[16]</ref> and latent Dirichlet allocation (LDA) <ref type="bibr" target="#b16">[17]</ref>, which have been successfully applied to a variety of text mining tasks in recent years, owing to their powerful capability of discovering topics from text and representing documents in a low-dimensional space spanned by the topics. However, to the best of our knowledge, the existing models are not applicable for our objective because they do not consider or address the limitations of travelogue data. Therefore, we propose a probabilistic topic model to discover topics that are appropriate to characterize locations, from a large amount of travelogues. Specifically, we define two distinct types of topics, i.e., local topics which correspond to the characteristics of specific locations (e.g., beach, dive), and global topics (e.g., hotel, airport) which do not particularly characterize certain locations but rather extensively co-occur with various locations in travelogues. Based on this model, the aforementioned limitations of travelogues are handled to some extent. By decomposing travelogues into local and global topics, we can obtain location-representative knowledge from local topics, with other semantics captured by global topics filtered out. In addition, by representing each destination as a mixture of local topics mined from the entire travelogue collection, multiple viewpoints of each destination can be naturally summarized.</p><p>For the photo selection given a set of textual tags to visualize, we first perform mutual reinforcement between a tag similarity matrix and a photo similarity matrix to propagate information between them and narrow the semantic gap. Then, the resulting tag similarity matrix is used to expand the query tags, while the resulting photo similarity matrix supports the refinement of tags associated with photos, based on a neighbor voting manner. In this way, we explicitly tackle the aforementioned challenges in photo selection.</p><p>Based on the above algorithms, we formulate a framework of destination summarization, which consists of three modules, i.e., travelogue mining, location-representative tag generation, and photo selection and summary generation. As shown in Fig. <ref type="figure" target="#fig_1">1</ref>, first a probabilistic topic model is trained offline on a collection of travelogues to learn a number of local and global topics to span a lowdimensional topic space. Then, given a query destination, its relevant traveloguesare projected into the topic space to generate location-representative tags based on the words projected onto the local topics. Finally, relevant and representative photos are selected from the destination's relevant photo set to visualize the mined tags; the location-representative tags and corresponding photos are eventually organized together to create a summary for the given destination. An example destination summary is illustrated in the bottom right of Fig. <ref type="figure" target="#fig_1">1</ref>, where San Francisco is characterized by some representative tags (where different font sizes correspond to different levels of representativeness), each of which is accompanied by some relevant photos.</p><p>The rest of this paper is organized as follows. Section 2 surveys some related work. In Section 3, we introduce the proposed probabilistic topic model for travelogue mining and location-representative tag generation. Then we describe the module of photo selection and summary generation in Section 4. Experimental and evaluation results are shown in Section 5. Section 6 gives conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Although tourist destination summarization is important in application needs, not many research efforts have been dedicated specially to this problem. Some related work focused on the issue of landmark/scene visual summarization. For instance, Kennedy and Naaman <ref type="bibr" target="#b3">[4]</ref> used content-based technologies to select diverse and representative images for a given landmark, while Simon et al. <ref type="bibr" target="#b4">[5]</ref> aimed at visually summarizing scenes with canonical views. In <ref type="bibr" target="#b12">[13]</ref>, a system was proposed to generate personalized tourism summary in the form of text, image, video, and real-time news. Luo et al. <ref type="bibr" target="#b40">[41]</ref> developed a place exploration system, which could identify photos precisely depicting a user-specified place by estimating the view directions of photos taken near the specified place. In a recent work <ref type="bibr" target="#b13">[14]</ref>, representative tags were mined from travelogues and then visualized by relevant images to generate overviews for locations; although the scenario is similar to ours, the authors focused on the mining of textual tags and simply relied on Web image search engines for image retrieval.</p><p>Besides, some research efforts have been dedicated to organizing the information on the Web to provide online travel assistant services such as travel planning service. For instance, Jing et al. <ref type="bibr" target="#b5">[6]</ref> proposed a travel plan assistant system that provided highquality images relevant to given locations based on tourist sight extraction and image retrieval. Another trip planning assistant system was presented in <ref type="bibr" target="#b11">[12]</ref>, where places are recommended to users according to the previous choices of users and tag-based place similarity. In <ref type="bibr" target="#b10">[11]</ref>, the authors built a travel blog writing assistant system that automatically enriched text with images by measuring visual and textual similarities between a paragraph and some candidate images.</p><p>In recent years, the leveraging of user-generated content has attracted extensive attention in the literature. Specifically, an active stream of work has been proposed to mine knowledge from usergenerated photos on Flickr <ref type="bibr" target="#b0">[1]</ref> to support various applications such as landmark discovery and recognition <ref type="bibr" target="#b7">[8]</ref>, landmark image selection <ref type="bibr" target="#b3">[4]</ref>, location explorer <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>, and image tag suggestion <ref type="bibr" target="#b9">[10]</ref>. Recently, some work has been presented on knowledge mining from user-generated travelogues, such as mining representative tags to outline locations <ref type="bibr" target="#b13">[14]</ref>, and mining location-representative knowledge to support travel-related applications <ref type="bibr" target="#b14">[15]</ref>.</p><p>Probabilistic topic models such as probabilistic latent semantic analysis (PLSA) <ref type="bibr" target="#b15">[16]</ref>, latent Dirichlet allocation (LDA) <ref type="bibr" target="#b16">[17]</ref> and their extensions <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> have achieved success in many text mining tasks, by assuming that each document is generated based on a number of latent topics. Rosen-Zvi et al. <ref type="bibr" target="#b17">[18]</ref> extended LDA by incorporating authors of documents as a set of observed variables and representing authors with mixtures of topics. In <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, locations mentioned in documents are explicitly modeled as generated by topics, while in <ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> locations serves as labels associated with documents.</p><p>Related to our objective of leveraging both textual and visual information, there are several streams of work that aim to analyze and utilize cross-media data.</p><p>Some researches focused on bridging the gap between textual and visual data, and investigated the image annotation refinement and text-based image retrieval <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42]</ref>. Since the raw tags associated with Web images are sometimes irrelevant to the image content, a popular series of approaches is to refine the tags based on their relevance to the corresponding image. Li et al. <ref type="bibr" target="#b28">[29]</ref> proposed to estimate the relevance of each tag in a given image by accumulating votes from visually similar images. In <ref type="bibr" target="#b41">[42]</ref>, the relevance scores of tags were initialized via probability density estimation, and then refined based on random walk over a tag similarity graph which encodes both exemplar similarity and concurrence similarity between tags. Chen et al. <ref type="bibr" target="#b37">[38]</ref>   visual content, textual tags and geographic locations from a large amount of geo-tagged images.</p><p>Some other researchers modeled the cross-media data from more general viewpoints. Wang et al. <ref type="bibr" target="#b29">[30]</ref> proposed an iterative similarity propagation model to exploit the mutual reinforcement of relational data (e.g., images and their textual annotations) and discover intrinsic similarities between objects in the form of nonlinear combinations of different modalities. Yang et al. <ref type="bibr" target="#b38">[39]</ref> presented a framework for cross-media retrieval based on a novel ranking algorithm which learns a robust Laplacian matrix for data ranking. In specific, the authors employed a local linear regression model for each data point and globally aligned the local models to achieve optimal ranking.</p><p>Recently, some researchers suggested leveraging the loosely labeled Web data to boost the analysis of user-generated content. Liu et al. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref> built a real-time textual query based personal photo retrieval system by leveraging numerous Web images and their associated text. For a user-specified textual query, the system retrieves relevant and irrelevant Web images as training data, based on which classifiers are trained so as to retrieve relevant personal photos. The results of photo retrieval are further refined by involving two relevance feedback <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref> methods via cross-domain learning, which effectively utilize both the Web images and personal images. Duan et al. <ref type="bibr" target="#b36">[37]</ref> proposed an event recognition framework for consumer videos by leveraging a large amount of loosely labeled Web videos. A novel cross-domain learning method was introduced to tackle the variation between consumer Web video domain and video domain. The authors also presented a new aligned space-time pyramid matching method to measure the distances between video clips from different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Travelogue mining</head><p>In this section, we describe the proposed probabilistic topic model of travelogues, called Travelogue Model (TM), as well as its application in mining location-representative tags from travelogues relevant to a given destination. By modeling the generative process of travelogues, the model can discover latent topics from a large collection of travelogues. Based on the learnt topics, location-representative tags could be mined from travelogues related to a destination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Basic idea</head><p>Following the existing work on probabilistic topic models such as PLSA, we assume that each travelogue document is generated from a mixture of topics, where each topic is a probability distribution over terms in the vocabulary and corresponds to some specific semantics. As discussed in Section 1, we further suppose two types of topics involved in travelogues, namely local topics and global topics. Each local topic corresponds to some semantics that charac-terize a few specific locations, and thus exclusively appears in travelogues about these locations; whereas each global topic corresponds to some common semantics, which extensively appear in travelogues related to various locations. In other words, there should be specific relationships between local topics and locations. Thus, we assume that every travelogue is composed of two components: one arising from the location(s) it depicts (e.g., the local characteristics of the tourist destinations), the other directly arising from itself (e.g., accommodation and feelings of the travelogue author). The intuitive aim of the travelogue mining is to decompose travelogue documents into such two components and capture them respectively with local and global topics.</p><p>In Fig. <ref type="figure" target="#fig_2">2</ref>, we illustrate the travelogue mining as a matrix decomposition problem where a given travelogue collection is represented by a Term-Document matrix with the jth column encoding the jth document's distribution over terms. Based on this representation, our goal is to decompose the Term-Document matrix into multiple matrices, including (1) the Term-LocalTopic matrix which characterizes the local topics, (2) the Term-GlobalTopic matrix which characterizes the global topics, (3) the LocalTopic-Location matrix which characterizes locations using local topics, and (4) the GlobalTopic-Document matrix which characterizes each document's distribution over global topics. The Location-Document matrix gives the general case where a travelogue could be related to multiple locations. In this paper, we consider the special case that each travelogue is related to a single location namely its associated location label. Hence, each column in the Location-Document matrix is simply a unit vector encoding ''1'' for the location label of the corresponding document and ''0'' otherwise.</p><p>According to the decomposition of likelihood p(w|d) shown in Fig. <ref type="figure" target="#fig_2">2</ref>, each word in a document is assumed to be ''written'' by making a binary decision between two paths, i.e., (1) selecting a location (exactly the location label in this paper), a local topic, and a term in sequence and (2) selecting a global topic and a term in sequence. Once decomposed as above, a travelogue collection preserves its local and global topics in Term-LocalTopic and Term-GlobalTopic matrices, respectively. For each local topic z 2 Z loc , draw u loc z ,fu loc z;w g w2W , i.e., a multinomial distribution over terms in the vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Generative process of travelogues</head><p>For each global topic z 2 Z gl , draw u gl z ,fu gl z;w g w2W , i.e., a multinomial distribution over terms in the vocabulary. For each location l 2 L, draw w l ,fw l;z g z2Z loc , i.e., a multinomial distribution over local topics. For each document d 2 D (with location label l d 2 L): </p><formula xml:id="formula_0">-draw p d ,</formula><formula xml:id="formula_1">z d;n Þ.</formula><p>According to the generative process of travelogues, the log-likelihood of travelogue collection D can be written as</p><formula xml:id="formula_2">LðDÞ ¼ X d2D X w2W nðd; wÞ Â log pðx ¼ locjdÞ X z2Z loc w l d ;z u loc z;w þ pðx ¼ gljdÞ X z2Z gl h d;z u gl z;w 2 4 3 5 ;<label>ð1Þ</label></formula><p>where n(d, w) denotes the number of times term w appears in document d. The corresponding graphical representation is illustrated in Fig. <ref type="figure">3</ref>, where shaded circles denote observed variables while other circles denote latent variables which need to be estimated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Mutual-information based regularization</head><p>As each local topic is expected to characterize a few specific locations, its occurrences in documents should be highly correlated with those locations. Therefore, we measure the correlation between the location set L and the local topic set Z loc with mutual information, and define a regularizer, which is encouraged to have a high value, as</p><formula xml:id="formula_3">IðL; Z loc Þ, X l2L X z2Z loc pðl; zÞ log pðl; zÞ pðlÞpðzÞ ¼ X l2L pðlÞD KL ðw l k w l Þ;<label>ð2Þ</label></formula><p>where D KL (Á||Á) denotes the Kullback-Leibler divergence, and w l , P l2L pðlÞw l , with probability distribution fpðlÞg l2L set to uniform distribution if no prior of locations exists. The regularizer can be interpreted that the location-specific distributions over local topics are encouraged to deviate from their ''mean'' w l , leading to both a diverse set of fw l g l2L and a set of local topics that are highly correlated with locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Parameter estimation</head><p>The Expectation-Maximization (EM) algorithm is commonly used for maximum likelihood estimation (MLE) of parameters in PLSA-like models. However, due to the introduction of the mutual-information based regularizer, the parameter estimation of the proposed model goes beyond MLE. Hence, we apply the generalized Expectation-Maximization (GEM) algorithm <ref type="bibr" target="#b23">[24]</ref> to estimate the parameters (denoted by X Z for simplicity). Similar to <ref type="bibr" target="#b22">[23]</ref>, the algorithm iteratively finds a better value of X, denoted by X (n+1) , given X (n) namely the value of X estimated in the last GEM iteration, by solving the constrained optimization problem</p><formula xml:id="formula_4">X ðnþ1Þ ¼ arg max X ð1 À kÞQ X; X ðnÞ þ kI L; Z loc h i s:t: Q X; X ðnÞ &gt; Q X ðnÞ ; X ðnÞ 8 &gt; &lt; &gt; : ;<label>ð3Þ</label></formula><p>where Q(X; X (n) ) is the expectation of the likelihood, which is defined (according to the proposed model) as</p><p>QðX;</p><formula xml:id="formula_5">X ðnÞ Þ ¼ X d2D X w2W nðd; wÞ Â X z2Z loc pðz; x ¼ locjd; wÞ log pðx ¼ locjdÞw l d ;z u loc z;w h i 8 &lt; : þ X z2Z gl pðz; x ¼ gljd; wÞ log pðx ¼ gljdÞh d;z u gl z;w h i 9 = ; :<label>ð4Þ</label></formula><p>and is computed after the calculation of probability distribution {p(z, x|d, w)} in E-step; coefficient k 2 ½0; 1 controls the trade-off between the expectation of the likelihood and the regularizer in the objective function. Since the regularizer I(L; Z loc ) only depends on fw l g l2L , other parameters can be solved separately by maximizing Q(X; X (n) ) in M-step as in the standard EM algorithm, yielding close-form updating formulas shown with Eqs. ( <ref type="formula">6</ref>)- <ref type="bibr" target="#b7">(8)</ref>. With these parameters calculated and fixed, fw l g l2L can be solved iteratively using penalty function methods. Eq. ( <ref type="formula" target="#formula_6">9</ref>) gives the starting point for such iterations, which is also the close-form updating formula when k is set to zero. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P</head><p>w2W nðd; wÞpðz 0 ; x ¼ locjd; wÞ</p><formula xml:id="formula_6">; z 2 Z loc :<label>ð9Þ</label></formula><p>Fig. <ref type="figure">3</ref>. The graphical representation of the proposed Travelogue Model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Location-representative tag generation</head><p>Given a destination l, its relevant travelogues (either retrieved from our data collection or specified by users) are aggregated as a virtual document d l . Then, document d l is projected into the topic space spanned by all of the learnt topics Z,Z loc S Z gl , by estimating a probability distribution over these topics iteratively using EM algorithm, as pðzjd l ; wÞ ¼ u z;w p ðnÞ ðzjd l Þ P z 0 2Z u z 0 ;w p ðnÞ ðz 0 jd l Þ ; After the convergence of EM iterations, the possibility of term w to be a representative tag for destination l is measured according to the expected number of times term w is projected onto a local topic (i.e., generated from a local topic) given destination-specific document d l , yielding the representativeness score computed as Rep l ðwÞ ¼ nðd l ; wÞ</p><formula xml:id="formula_7">p<label>ð10Þ</label></formula><formula xml:id="formula_8">P z2Z loc u z;w pðzjd l Þ P z 0 2Z u z 0 ;w pðz 0 jd l Þ :<label>ð12Þ</label></formula><p>By ranking the terms appearing in document d l in decreasing order of representativeness, we could obtain a list of location-representative tags for destination l.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Photo selection and summary generation</head><p>In this section, we introduce the detailed algorithm for selecting relevant and representative photos from a candidate photo set to visualize the given location-representative tags and finally generate a destination summary. Note that this photo selection is different from the task of traditional image retrieval where only visual information is available <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Basic idea</head><p>As discussed in Section 1, there are mainly two challenges in the photo selection process, namely the ambiguity of query tags and the inaccurate tags associated with user-generated photos.</p><p>For the former challenge, we propose to expand each query tag with some similar tags to avoid ambiguity. As a by-product, the photo selection could be improved besides such disambiguation processing, because more tags, other than the exact query tag, contribute to the photo ranking. Intuitively, the key point here is to measure the similarity between tags. We involve two metrics of pair-wise tag similarity, i.e., (1) co-occurrence in tag sets of photos (co-occurrence similarity for short) and (2) visual similarity of corresponding photo sets (visual similarity for short). The cooccurrence similarity metric is commonly used to measure the semantic distance of two terms in the text mining and natural language processing areas; while the visual similarity is involved particularly for the scenario in this paper, so as to narrow the semantic gap introduced by the text-based tag expansion. These two tag similarity metrics are merged non-linearly in a mutual reinforcement manner, instead of in a linear combination manner.</p><p>For the latter challenge, we apply the idea of learning tag relevance by neighbor voting proposed in <ref type="bibr" target="#b28">[29]</ref> to refine the annotations of photos. Specifically, the relevance of a tag to a seed image is estimated in terms of the tag's occurrence in the neighbor images of the seed image. The neighbor images are defined as visually similar images in <ref type="bibr" target="#b28">[29]</ref>; whereas in this paper, we treat images not only visually similar but also semantically similar as neighbors of a given image, considering that some visually similar images may be semantically irrelevant to the seed image due to the semantic gap between textual and visual information. Hence, we need to merge the visual similarity and semantic similarity between images to find appropriate neighbor images for subsequent neighbor-voting-based annotation refinement.</p><p>Motivated by the above ideas, we propose to propagate information between pair-wise tag similarities and pair-wise photo similarities. In this way, the similarities in both textual and visual spaces could complement each other, leading to a better measurement of tag similarity and photo similarity with less semantic gap, so as to overcome the aforementioned challenges.</p><p>The flowchart of the detailed photo selection algorithm is depicted in Fig. <ref type="figure" target="#fig_3">4</ref>. Three (i.e., Tag-Tag, Photo-Photo, and Tag-Photo) matrices are first created from the given candidate photo set, and then involved into a mutual reinforcement framework to propagate textual similarity and visual similarity to each other. Based on the resulting similarity matrices, annotation refinement and query expansion are performed to support the final ranking and selection of photos. The selected photos are combined with location-representative tags to generate destination summary at last.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Matrix initialization</head><p>Given a destination-relevant photo set S = {s 1 , . . . , s N } consisting of N photos, each associated with a set of tags, we can build three matrices, including a tag similarity matrix U MÂM , a photo similarity matrix V NÂN , and an annotation matrix A MÂN , where M is the total number of unique tags associated with at least one photo. The element u i,j in matrix U MÂM denotes the similarity between the ith and jth tags, while the element v i,j in matrix V NÂN denotes the similarity between the ith and jth photos. In the matrix A MÂN , the element a i,j encodes the probability that the ith tag is relevant to the jth photo.</p><p>Intuitively, it is straightforward to initialize the annotation matrix A according to the existing tags associated with each photo in the given photo set S, by assigning ''1'' to a i,j if the jth photo is annotated with the ith tag, and assigning ''0'' otherwise. Since we aim to measure pair-wise tag similarity locally, i.e., exclusively based on the data relevant to a given location, it is improper to apply some commonly used term similarity metrics such as Google distance (NGD) <ref type="bibr" target="#b24">[25]</ref> to initialize the tag similarity matrix U. Therefore, we leverage the geographic constraint embedded in geo-tagged photos and derive a tag similarity measurement based on the co-occurrences of tags in the photos geographically relevant to the given destination. In specific, we compute the co-occurrence similarity between two tags t i and t j analogous to the normalized Google distance (NGD) <ref type="bibr" target="#b24">[25]</ref> as</p><formula xml:id="formula_9">u ð0Þ i;j ¼ exp À max log nðt i Þ; log nðt j Þ Â Ã À log nðt i ; t j Þ N À min log nðt i Þ; log nðt j Þ Â Ã ( ) ;<label>ð13Þ</label></formula><p>where n(t i ) and n(t j ) denote the numbers of photos annotated with tag t i and tag t j , respectively; n(t i , t j ) is the number of photos annotated with both t i and t j . All the photo counts are computed exclusively on the destination-relevant photo set.</p><p>To demonstrate the effect of tag-to-photo similarity propagation, the photo similarity matrix V is initialized entirely based on visual features of photos. Since the selection of visual features is beyond the focus of this paper, we simply adopt the commonly used bag-of-visual-words (BOV) based on Scale Invariant Feature Transform (SIFT) <ref type="bibr" target="#b25">[26]</ref> descriptors to represent the photos. We first extract SIFT local descriptors from the photo collection, and then perform k-means clustering to generate 500 clusters of descriptors, yielding a 500-dimensional BOV vector representation for each photo. Accordingly, the similarity between two photos s i and s j is initialized as the cosine similarity between their corresponding BOV vectors, as</p><formula xml:id="formula_10">v ð0Þ i;j ¼ BOVðs i Þ; BOVðs j Þ BOVðs i Þ k k 2 BOVðs j Þ 2 ;<label>ð14Þ</label></formula><p>where hÁ, Ái denotes the inner product of two vectors, and k Á k 2 denotes L2-norm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Tag-photo similarity propagation</head><p>Given the initialized three matrices, we aim to propagate information between the tag similarity matrix U and the photo similarity matrix V iteratively, along their links characterized by the annotation matrix A. Here we apply the iterative similarity propagation algorithm proposed by Wang et al. <ref type="bibr" target="#b29">[30]</ref>, with the following updating formulas for the nth iteration.</p><formula xml:id="formula_11">U ðnÞ ¼ ð1 À aÞU ð0Þ þ aAV ðnÀ1Þ A T V ðnÞ ¼ ð1 À bÞV ð0Þ þ bA T U ðnÀ1Þ A ( ;<label>ð15Þ</label></formula><p>where A T is the transpose of matrix A. The coefficient a 2 ð0; 1Þ controls the extent to which the updating process of tag similarity matrix U relies on the information propagation from the photo similarity matrix V, in other words, the strength of photo-to-tag similarity propagation. Similarly, the coefficient b 2 ð0; 1Þ controls the strength of tag-to-photo similarity propagation. The values of these two coefficients are set empirically. The above iterations would converge at the end. For detailed parameter selection and proof of convergence please refer to <ref type="bibr" target="#b29">[30]</ref>. In the implementation, both similarity matrices are normalized after each iteration, to ensure that the diagonal elements are equal to 1, namely each tag or photo has the highest similarity to itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Annotation refinement</head><p>Inspired by <ref type="bibr" target="#b28">[29]</ref>, we refine the raw tags associated with a seed photo by referring to its neighbor photos, i.e., photos similar to the seed one. Based on the annotation matrix and the photo similarity matrix after similarity propagation, the relevance between tag t i and photo s j is computed as a combination of (1) tag t i 's occurrence in the raw tag set of photo s j and (2) t i 's occurrence in the nearest neighbors of photo s j weighted by each neighbor photo's similarity to s j , yielding the following estimation formula:</p><formula xml:id="formula_12">Relðt i ; s j Þ ¼ ð1 À kÞa i;j þ k P k2NN V ðs j Þ v j;k a i;k P k2NN V ðs j Þ v j;k ;<label>ð16Þ</label></formula><p>where NN V (s j ) denotes the set of nearest neighbors of photo s j according to the photo similarity matrix V, and coefficient k 2 ð0; 1Þ controls the extent to which the estimation of tag relevance for photo s j relies on its nearest neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Query expansion and photo ranking</head><p>After similarity propagation, the tag similarity matrix U is applied to expand a given query tag t i to its nearest neighbors ft k jk 2 NN U ðt i Þg, where NN U (t i ) is the index set of tags most similar to tag t i according to the tag similarity matrix U. Then, the score of photo s j 's relevance/representativeness to the query tag t i is estimated as</p><formula xml:id="formula_13">Score t i ðs j Þ ¼ ð1 À lÞRelðt i ; s j Þ þ l P k2NN U ðt i Þ u i;k Relðt k ; s j Þ P k2NN U ðt i Þ u i;k ;<label>ð17Þ</label></formula><p>where coefficient l 2 ð0; 1Þ controls the extent to which we resort to the expanded tags to rate photos for a given query tag. All the photos in the candidate photo set S are ranked in decreasing order of the above score, and then a number of top-ranked photos are taken as the relevant and representative photos to visualize the query tag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Summary generation</head><p>After selecting photos for each tag in the location-representative tag set T l of destination l, we organize these tags and corresponding photos to form a summary for the destination. Considering that some tags in T l may be quite similar to each other (e.g., multiple names for a single landmark), and meanwhile the space to represent the destination summary is usually too limited to visualize all the tags using photos, we need to merge similar tags and prune trivial tags. Therefore, we first cluster the tags in T l based on the final tag similarity matrix, and then conduct two kinds of ranking, namely (1) intra-cluster tag ranking based on each tag's representativeness score, so as to visualize a tag cluster using the photos corresponding to the top-ranked tags, instead of all tags, in the cluster and (2) inter-cluster ranking according to the sum of representativeness scores of all tags in a cluster, so as to prioritize the tag clusters and only preserve the top ones in the destination summary when the space is limited. In this way, similar tags could share photos while trivial tags could be truncated, leading to diversified and informative destination summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results</head><p>In this section, we present the experimental results of the proposed framework of summarizing tourist destinations by mining a large collection of user-generated travelogues and photos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data sets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Travelogue data</head><p>There are many sources of user-generated travelogues on the Web, either from weblogs such as Windows Live Spaces, or travel community websites like TravelPod <ref type="bibr" target="#b1">[2]</ref> and IgoUgo <ref type="bibr" target="#b2">[3]</ref>. We collected approximately 66,000 travelogues written in English from TravelPod and IgoUgo to form a corpus. Each travelogue is associated with a single location label within the United States, which indicates the tourist destination the travelogue is related to, covering 817 unique destinations in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Photo data</head><p>In our experiments, user-contributed photos relevant to tourist destinations were collected from Flickr <ref type="bibr" target="#b0">[1]</ref>, a famous online album website, by issuing the PlaceId of a destination as the query to retrieve photos with geo-tags (i.e., latitude and longitude of where a photo was taken) located in the destination via Web API. <ref type="foot" target="#foot_2">1</ref> Since the numbers of such geo-relevant photos vary drastically from destination to destination, we conducted a pre-processing to select an appropriate and relatively equal number of photos for each destination in the implementation. That is, all the geo-relevant photos of a destination were ranked in decreasing number of location-representative tags a photo was annotated with; among photos with tied score, the fewer tags a photo had in total, the higher it was ranked. In this way, we formed the photo data sets by crawling top-ranked 50,000 photos for each of five destinations including New York City, San Francisco, Las Vegas, Seattle, and Maui. Such photos are expected to include the most potentially relevant and representative ones for the visualization of location-representative tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Travelogue mining</head><p>Since the topic model is based on unigrams, we need to extract and mark the locations (especially ones with multiple-word names) mentioned in the travelogues to avoid them being tokenized in the subsequent text pre-processing. There are several methods for location extraction, e.g., looking up a gazetteer. In the implementation, we applied the Yahoo! Placemaker<ref type="foot" target="#foot_3">2</ref> Web service to identify locations in the travelogues and then concatenated multiple-word location references with underscores to treat them as unigrams.</p><p>After text pre-processing including tokenization, stemming and stop-word removal, we trained a Travelogue Model (as described in Section 3) on the travelogue corpus to learn local topics and global topics. The numbers of local and global topics were set empirically to 100 and 50, respectively.</p><p>To illustrate the topics learnt by the proposed model, we show the top terms (i.e., terms with the highest probabilities in a topic) of some example topics in Table <ref type="table" target="#tab_3">1</ref>, where ''local (or global) #j'' denotes the jth local (or global) topic discovered by the model. From the table we can see that local topics characterize some travel styles and corresponding locations, including both natural styles like seaside (local #4), mountain (local #6) and cultural styles like Disney (local #75); whereas global topics correspond to common themes of travel, such as time (global #1), accommodation (global #10), transportation (global #14), dining (global #15), and opinion (global #27), which tend to appear in travelogues related to almost any destination and thus are not appropriate for characterizing or summarizing destinations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Location-representative tag generation</head><p>To evaluate the proposed location-representative tag generation algorithm (called Travelogue Model-based or TM method) de-scribed in Section 3.5, four baseline methods were implemented for comparison: TF method is to first generate a pseudo document for each destination by concatenating all the travelogues related to it, and then rank terms in decreasing term frequency (TF) in the pseudo document. Top-ranked terms are finally taken as the location-representative tags for each given destination. TF-IDF method is similar to the TF method but multiplies each term's frequency with the Inverse Document Frequency (IDF) to penalize terms commonly appearing in many destinationspecific documents. PLSA method is to first train a PLSA model on the travelogue corpus to learn 150 topics, and then treat the topics with the most uneven (i.e., sparse) distributions over destinations as local topics while others as global topics, to further perform the same tag generation process as proposed in Section 3.5. The numbers of local and global topics are set to the same as TM approach. Naive Travelogue Model-based (NTM) method is similar to the proposed TM method but does not involve the mutualinformation-based regularization during the topic mining.</p><p>In the evaluation, we involved 20 popular destinations, each associated with at least 100 travelogues in our corpus. As there is no existing ground-truth for location-representative tags of these destinations, we built one by borrowing people's knowledge. For each destination, we first formed a tag pool by merging the top  20 tags generated by each of the five methods, and then asked 15 graduate students to label the location-representativeness of each tag in the pool as ''0'' (irrelevant), ''1'' (somewhat relevant but not representative) or ''2'' (representative). Finally, each tag was rated as 1 to 5 based on the total scores it received, to generate a ranking list of tags as the ground-truth.</p><p>Based on the ground-truth, the tag ranking list generated by each method is evaluated using the Normalized Discounted Cumulative Gain at top K (NDCG@K) <ref type="bibr" target="#b27">[28]</ref>, which is commonly used in the information retrieval area to measure ranking accuracy. The results averaged over all the 20 destinations are shown in Fig. <ref type="figure" target="#fig_4">5</ref>. It can be observed that: (1) TF method is the worst in performance, mainly because there is no penalty to tags with high frequency but extensively appearing in travelogues of various destinations. (2) PLSA method outperforms TF method consistently with K increasing, owing to the differentiation between local and global topics after the topic mining. (3) NTM method consistently outperforms TF and PLSA baselines, which justifies the explicit differentiation between local and global topics during the topic mining. (4) The proposed TM method outperforms NTM method significantly, indicating the effectiveness of mutual-information-based regularization. <ref type="bibr" target="#b4">(5)</ref> The NDCG score of TF-IDF method is the lowest at top 1, but gradually improves with K increasing, even better than TM method at top 5-20. It can be interpreted that tags (e.g., location names) that exclusively appear in the travelogues of a destination would benefit a lot from TF-IDF method due to high values of IDF, leading to some top-ranked tags highly correlated with the destination but not representative enough from the perspective of tourism. With K increasing, the non-location-representative tags, which are ranked relatively low by TF-IDF method, contribute much    to the NDCG score. In other words, TF-IDF method can identify the tags with relatively high representativeness, but lack of the ability to further differentiate between the tags with highest and second highest representativeness, resulting in a NDCG@K curve with low values at the beginning and higher values with increasing K.   (e.g., Golden Gate Bridge), styles (e.g., historic, beach) and activities (e.g., gamble, surf) that are highly correlated with travel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Photo selection</head><p>To evaluate the proposed photo selection algorithm given a query in the form of ''{tag} in {destination}'' and a candidate photo set, we involved three baseline methods:</p><p>Naive method is simply based on the occurrence of the query tag in the tag list of each photo. Among the candidate photos that contain the query tag, photos with the fewest tags in total are selected as the results. Naive Query Expansion (NQE) method is to first expand the query tag using Flickr.tags.getRelated API, <ref type="foot" target="#foot_4">3</ref> and then apply the same photo ranking equation as described in Section 4.5. Query Expansion (QE) method is similar to the propose method but does not perform annotation refinement for the candidate photos before photo ranking.</p><p>For the sake of uniformity, the proposed method is called Query Expansion plus Annotation Refinement (QE + AR).</p><p>Since it is usually subjective to evaluate the extent to which a photo is representative to something at somewhere, we resorted to user study for the evaluation. Based on the collected photos, we prepared eight groups of data, each composed of a query in the form of ''{tag} in {destination}'' and top 10 photos (as a set) selected by each of the four methods. Fifteen graduate students were asked to assess the four photo sets (presented in random order) in each data group using 1-5 ratings, to evaluate the overall representativeness of each photo set to the query.</p><p>For each group of data, we averaged all the participators' evaluations as the ratings of the four methods. The results are shown in Fig. <ref type="figure" target="#fig_5">6</ref>, while Fig. <ref type="figure" target="#fig_7">7</ref> exemplifies the selected photos for two out of the eight queries. From Fig. <ref type="figure" target="#fig_5">6</ref> we can observe some interesting phenomena. (1) For most queries related to landmarks, NQE method receives the lowest assessment; QE method slightly outperforms Naive method; QE + AR method shows significant advantages in the three baselines. (2) For queries related to concepts with more extensive semantics (e.g., beach, hotel), Naive method shows the lowest satisfaction, while the other three methods do not show explicitly consistent differentiation. (3) When the query tag (e.g., cable) is ambiguous, the rating of Naive method is fairly low, and that of QE method is even worse.</p><p>It can be interpreted that since NQE method is essentially based on all the photos rather than ones taken at the given destination, the query expansion might involve noise and consequently contaminate the photo selection results, especially when the query tags correspond to some fixed semantics like landmark names (i.e., no ''space'' to expand) or ambiguous semantics (i.e., improper to expand based on too much irrelevant data). By contrast, QE method shows effectiveness in most queries, because its query expansion mechanism not only exclusively relies on the destination-relevant photos, but also benefits from the tag-photo similarity propagation to overcome semantic gap.</p><p>The proposed QE + AR method outperforms the baselines for most queries, due to the improvement to raw annotations of photos. In addition, when the query (e.g., Central Park) has multiple views (i.e., aspects to depict using photos), the photos corresponding to the most popular and representative views tend to be ranked high and selected since they have abundant similar neighbors to enhance the confidence of relevance to the query and expanded tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Summary generation</head><p>In the implementation of summary generation, we applied the Affinity Propagation <ref type="bibr" target="#b26">[27]</ref> algorithm to cluster location-representative tags of a given destination, considering its capability of determining the number of clusters automatically. After selecting the content to be involved in the destination summary as described in Section 4.6, we employed NetDraw<ref type="foot" target="#foot_5">4</ref> software for the layout of the selected tags in a graph structure. Specifically, each tag is presented in a text box, associate with a node in the graph. The more location-representative a tag is, the larger the font size it has. To further show the tag relationships, the tags are positioned in such a way that tags belonging to the same clusters are close to each other, while the inter-cluster layout is based on the overall tag similarity between tag clusters. Different tag clusters are marked with different node colors and shapes.</p><p>The corresponding photos of each tag cluster are presented in the form of a photo collage and positioned beside the tag cluster. The size of the photo collage has a positive correlation with the total representativeness of tags in the tag cluster.</p><p>Two example destination summaries are illustrated in Fig. <ref type="figure" target="#fig_9">8</ref>, for New York City and San Francisco, respectively. From such summaries users could understand the local characteristics of a destination efficiently, from a representative and comprehensive overview with both textual and visual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and future work</head><p>It is highly desired to outline tourist destinations with summaries consisting of both textual and visual descriptions. In this paper, we present a framework of summarizing tourist destinations by leveraging the rich textual and visual information in large amount of user-generated travelogues and photos on the Web. The proposed framework first discovers location-representative tags from travelogues and then select relevant and representative photos to visualize these tags. Finally, the tags and photos are organized appropriately to generate a representative and comprehensive summary which describes a given destination both textually and visually. Experimental results based on a large collection of travelogues and photos show the effectiveness of the proposed destination summarization framework.</p><p>For the future work, we plan to take full advantage of the content of photos to improve the performance of photo selection and user experience. Besides, it is an interesting direction to take the various granularity levels of locations into consideration, so as to better meet application needs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>introduced a tag-based photo retrieval framework by re-tagging a group of semantically related photos essentially in two steps, namely (1) training classifiers on loosely labeled training Web images and (2) refining the annotation via a graph-based approach considering both visual and semantic similarities. Cao et al. [40] presented a framework of enhancing the semantic and geographic annotation of images, based on a new algorithm called Logistic Canonical Correlation Regression, which could learn the coherent information among</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The proposed framework of destination summarization: (1) travelogue mining; (2) location-representative tag generation; and (3) photo selection and summary generation.</figDesc><graphic coords="3,134.76,67.92,312.14,173.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An illustration of the travelogue decomposition with (I) local topics Z loc and (II) global topics Z gl . The figure mainly serves as an illustrative interpretation of the basic idea, but does not exactly accord with the model details.</figDesc><graphic coords="4,133.23,631.56,340.17,98.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.<ref type="bibr" target="#b3">4</ref>. The flowchart of the proposed photo selection algorithm, given a destination and its location-representative tags as queries to visualize using a set of candidate photos.</figDesc><graphic coords="6,323.66,490.22,226.83,231.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. NDCG@K results of location-representative tags generated by five methods including (a) TF, (b) TF-IDF, (c) PLSA, (d) Naive TM, and (e) TM. (Here K denotes the number of top tags considered in the performance measurement for each method.)</figDesc><graphic coords="8,323.26,608.49,227.51,113.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. A subjective evaluation of the top photos selected by four methods including (a) Naive, (b) Naive Query Expansion, (c) Query Expansion, and (d) Query Expansion plus Annotation Refinement, given queries in the form of ''{tag} in {destination}''.</figDesc><graphic coords="9,80.90,216.00,423.38,84.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) Central Park in New York City (b) cable in San Francisco</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Top photos selected by four methods for two queries: (a) Central Park in New York City, and (b) cable in San Francisco.</figDesc><graphic coords="9,66.68,351.47,453.69,195.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) Summary for New York City (b) Summary for San Francisco</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. An illustration of the generated destination summaries for (a) New York City and (b) San Francisco, each composed of top nine clusters of location-representative tags and top three photos for each cluster. In the summaries, different colors and shapes of nodes stand for different tag clusters; the larger a tag (or a photo collage) is, the more representative it is.</figDesc><graphic coords="10,90.68,67.91,420.16,559.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>fpðxjdÞg x2floc;glg , i.e., a binomial distribution over local topics versus global topics;&gt; -draw w l d directly from fw l g l2L , i.e., a multinomial distribution over local topics according to the location label l d ; -draw h d ,fh d;z g z2Z gl , i.e., a multinomial distribution over global topics; -for each word w d;n 2 fw d;1 ; . . . ; w d;N d g (where N d is the total number of words in document d): draw a binary switch x d,n $ Binomial(p d ); if (x d,n = loc), draw a local topic z d;n $ Multinomialðw l d Þ; if (x d,n = gl), draw a global topic z d,n $ Multinomial(h d ); draw word w d;n $ Multinomialðu</figDesc><table /><note><p>x d;n</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>ðnþ1Þ ðzjd l Þ ¼ / z,w is the component w.r.t. to term w of / z namely topic z's multinomial distribution over terms.</figDesc><table><row><cell>P</cell><cell>P w2W nðd l ; wÞpðzjd l ; wÞ z 0 2Z P w2W nðd l ; wÞpðz 0 jd l ; wÞ</cell><cell>;</cell><cell>ð11Þ</cell></row></table><note><p>where</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>Top terms of example local topics and global topics.</figDesc><table><row><cell>Local #4</cell><cell>Local #6</cell><cell>Local #29</cell><cell>Local #55</cell><cell>Local #75</cell></row><row><cell>Beach</cell><cell>Canyon</cell><cell>Alaska</cell><cell>Yellowstone</cell><cell>Disney</cell></row><row><cell>Island</cell><cell>Grand_Canyon</cell><cell>Glacier</cell><cell>Geyser</cell><cell>Ride</cell></row><row><cell>Kauai</cell><cell>Rim</cell><cell>Anchorage</cell><cell>Park</cell><cell>Orlando</cell></row><row><cell>Snorkel</cell><cell>Arizona</cell><cell>Cruise</cell><cell>Bear</cell><cell>World</cell></row><row><cell>Hawaii</cell><cell>Flagstaff</cell><cell>Bear</cell><cell>Teton</cell><cell>Theme</cell></row><row><cell>Princeville</cell><cell>Desert</cell><cell>Denali</cell><cell>Elk</cell><cell>Universal</cell></row><row><cell>Coast</cell><cell>Rock</cell><cell>Ship</cell><cell>Bison</cell><cell>Kingdom</cell></row><row><cell>Helicopter</cell><cell>Sedona</cell><cell>Alaskan</cell><cell>Old</cell><cell>Epcot</cell></row><row><cell>Ocean</cell><cell>Navajo</cell><cell>Salmon</cell><cell>Spring</cell><cell>Resort</cell></row><row><cell>Surf</cell><cell>Hike</cell><cell>Fish</cell><cell>Faithful</cell><cell>Studio</cell></row><row><cell>Global #1</cell><cell>Global #10</cell><cell>Global #14</cell><cell>Global #15</cell><cell>Global #27</cell></row><row><cell>Month</cell><cell>Room</cell><cell>Flight</cell><cell>Dinner</cell><cell>Best</cell></row><row><cell>Sunday</cell><cell>Hotel</cell><cell>Airport</cell><cell>Lunch</cell><cell>Great</cell></row><row><cell>Monday</cell><cell>Bed</cell><cell>Plane</cell><cell>Meal</cell><cell>Pretty</cell></row><row><cell>Friday</cell><cell>Night</cell><cell>Bag</cell><cell>Eat</cell><cell>Fun</cell></row><row><cell>Christmas</cell><cell>Inn</cell><cell>Hotel</cell><cell>Breakfast</cell><cell>Nice</cell></row><row><cell>Saturday</cell><cell>Floor</cell><cell>Check</cell><cell>Nice</cell><cell>Awesome</cell></row><row><cell>Holiday</cell><cell>Breakfast</cell><cell>Seat</cell><cell>Enjoy</cell><cell>Love</cell></row><row><cell>Tuesday</cell><cell>Bathroom</cell><cell>Train</cell><cell>Steak</cell><cell>Amaze</cell></row><row><cell>Thursday</cell><cell>Comfort</cell><cell>Board</cell><cell>Ate</cell><cell>Good</cell></row><row><cell>Wednesday</cell><cell>Desk</cell><cell>Airline</cell><cell>Special</cell><cell>Cute</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Top location-representative tags generated by the proposed method for some example destinations. , moose, bear, Seward, fish, salmon, native, Denali_National_Park, cruise Boston Common, Freedom_Trail, Harvard_University, red, Quincy_Market, revere, historic, sox, Fenway_Park, whale Chicago Navy_Pier, pizza, Michigan, lake, Sears_Tower, field, institute, blue, cub, architecture Las Vegas Casino, strip, hotel, show, buffet, gamble, bellagio, circus, slot, mgm Los Angeles Hollywood, star, beach, studio, Venice_Beach, universal, theatre, Santa_Monica, movie, boulevard Maui Beach, island, Lahaina, snorkel, ocean, whale, Haleakala_National_Park, surf, luau, volcano New York City Subway, Manhattan, Times_Square, Central_Park, broadway, island, ferry, Statue_of_Liberty, Ground_Zero, Brooklyn San Francisco Bridge, bay, Alcatraz, Golden_Gate_Bridge, cable, Fisherman's_Wharf, prison, Pier_39, Union_Square, Chinatown Seattle Space_Needle, Pike_Place_Market, fish, ferry, market, starbuck, underground, waterfront, salmon, Pioneer_Square Washington, DC Memorial, monument, metro, museum, mall, capitol, smithsonian, war, The_White_House, Lincoln_Memorial</figDesc><table><row><cell>Destination</cell><cell>Top 10 representative tags</cell></row><row><cell>Anchorage</cell><cell>Alaskan, glacier</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note><p>exemplifies the top location-representative tags generated by the proposed method, by listing top 10 representative tags for each of 10 destinations. It shows that the tags mined by our approach characterize the corresponding destinations clearly and comprehensively, from diverse aspects including landmarks</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Y. Pang et al. / Computer Vision and Image Understanding 115 (2011) 352-363</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Y. Pang et al. / Computer Vision and Image Understanding 115 (2011) 352-363</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2"><p>http://www.flickr.com/services/api/flickr.photos.search.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>http://developer.yahoo.com/geo/placemaker/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>http://www.flickr.com/services/api/flickr.tags.getRelated.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>http://www.analytictech.com/Netdraw/netdraw.htm.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the National Basic Research Program of China (973 Program) (Grant No. 2011CB707104), the National Natural Science Foundation of China (No. 60975001), the Tianjin Research Program of Application Foundation and Advanced Technology (No. 10JCYBJC07700), and the Specialized Research Fund for the Doctoral Program of Higher Education (No. 20090032110028).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Flickr</surname></persName>
		</author>
		<ptr target="&lt;http://www.flickr.com/&gt;" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Travelpod</surname></persName>
		</author>
		<ptr target="&lt;http://www.travelpod.com/&gt;" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><surname>Igougo</surname></persName>
		</author>
		<ptr target="&lt;http://www.igougo.com/&gt;" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generating diverse and representative image search results for landmarks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 17th International Conference on World Wide Web</title>
		<meeting>eeding of the 17th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scene summarization for online image collections</title>
		<author>
			<persName><forename type="first">I</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE International Conference on Computer Vision</title>
		<meeting>the 11th IEEE International Conference on Computer Vision<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">VirtualTour: an online travel assistant based on high quality images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Multimedia</title>
		<meeting>the 14th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="599" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How Flickr helps us make sense of the world: context and content in community-contributed media collections</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rattenbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM International Conference on Multimedia</title>
		<meeting>the 15th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="631" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Tour the world: building a web-scale landmark recognition engine</title>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Buddemeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 22nd IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mapping the world&apos;s photos</title>
		<author>
			<persName><forename type="first">D</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on World Wide Web</title>
		<meeting>the 18th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SpiritTagger: a geo-aware tag suggestion tool mined from Flickr</title>
		<author>
			<persName><forename type="first">E</forename><surname>Moxley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 1st ACM International Conference on Multimedia Information Retrieval</title>
		<meeting>eeding of the 1st ACM International Conference on Multimedia Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="24" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Travel blog assistant system (TBAS) -an example scenario of how to enrich text with images and images with text using online multimedia repositories</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bressan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hoppenot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Renders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISAPP Workshop on Metadata Mining for Image Understanding</title>
		<imprint>
			<publisher>Workshop</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TripTip: a trip planning service with tag-based recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference Extended Abstracts on Human Factors in Computing Systems</title>
		<meeting>the 27th International Conference Extended Abstracts on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="3467" to="3472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Neo</surname></persName>
		</author>
		<title level="m">Proceeding of the 17th International Conference on World Wide Web</title>
		<meeting>eeding of the 17th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1025" to="1026" />
		</imprint>
	</monogr>
	<note>Personalized multimedia web summarizer for tourist</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generating location overviews with images and tags by mining user-generated travelogues</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Multimedia</title>
		<meeting>the 17th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="801" to="804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Proceeding of the 19th International Conference on World Wide Web</title>
		<meeting>eeding of the 19th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="401" to="410" />
		</imprint>
	</monogr>
	<note>Equip tourists with knowledge mined from travelogues</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 15th Conference on Uncertainty in Artificial Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The author-topic model for authors and documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 20th Conference on Uncertainty in Artificial Intelligence<address><addrLine>Arlington, VA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Statistical entity-topic models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chemudugunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="680" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mining geographic knowledge using location aware topic model</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM Workshop on Geographical Information Retrieval</title>
		<meeting>the 4th ACM Workshop on Geographical Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="65" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A probabilistic approach to spatiotemporal theme pattern mining on weblogs</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 15th International Conference on World Wide Web</title>
		<meeting>eeding of the 15th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="533" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A mixture model for contextual text mining</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="649" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Topic modeling with network regularization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 17th International Conference on World Wide Web</title>
		<meeting>eeding of the 17th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A view of the EM algorithm that justifies incremental, sparse, and other variants</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning in Graphical Models</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="355" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Google similarity distance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vitányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="383" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Clustering by passing messages between data points</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="issue">5814</biblScope>
			<biblScope unit="page" from="972" to="976" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">IR evaluation methods for retrieving highly relevant documents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jarvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kekalainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning social tag relevance by neighbor voting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Multimedia</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1310" to="1322" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-model similarity propagation and its application for web image retrieval</title>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-R</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM International Conference on Multimedia</title>
		<meeting>the 12th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="944" to="951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Travelogue enriching and scenic spot overview based on textual and visual topic models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Laplacian regularized d-optimal design for active learning and its application to image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="254" to="263" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Using large-scale web data to facilitate textual query-based retrieval of consumer photos</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Multimedia</title>
		<meeting>the 17th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Textual query of consumer photos facilitated by large-scale web data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2010.142</idno>
		<ptr target="&lt;http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.142&gt;" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Asymmetric bagging and random subspace for support vector machines-based relevance feedback in image retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1088" to="1099" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multitraining support vector machine for image retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Allinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3597" to="3601" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visual event recognition in videos by learning from web data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 23rd IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Tag-based web photo retrieval improved by batch mode re-tagging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the 23rd IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ranking with local regression and global alignment for cross media retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Multimedia</title>
		<meeting>the 17th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="175" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Enhancing semantic and geographic annotation of web images via logistic canonical correlation regression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Multimedia</title>
		<meeting>the 17th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">ViewFocus: explore places of interests on Google maps using photos with view direction filtering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Multimedia</title>
		<meeting>the 17th ACM International Conference on Multimedia<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="963" to="964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Tag ranking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 18th International Conference on World Wide Web</title>
		<meeting>eeding of the 18th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="351" to="360" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
