<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Image Tag Refinement Towards Low-Rank, Content-Tag Prior and Error Sparsity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guangyu</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yi</forename><surname>Ma</surname></persName>
							<email>yima@uiuc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Image Tag Refinement Towards Low-Rank, Content-Tag Prior and Error Sparsity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B53B0C81254EF7A9E4D1DB73AB11FEC8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; I.2.6 [Artificial Intelligence]: Learning Algorithm</term>
					<term>Theory</term>
					<term>Experimentation Tag Refinement</term>
					<term>Social Images</term>
					<term>Content Consistency</term>
					<term>Tag Correlation</term>
					<term>Low-rank</term>
					<term>Error Sparsity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The vast user-provided image tags on the popular photo sharing websites may greatly facilitate image retrieval and management. However, these tags are often imprecise and/or incomplete, resulting in unsatisfactory performances in tag related applications. In this work, the tag refinement problem is formulated as a decomposition of the user-provided tag matrix D into a low-rank refined matrix A and a sparse error matrix E, namely D = A + E, targeting the optimality measured by four aspects: 1) low-rank : A is of low-rank owing to the semantic correlations among the tags; 2) content consistency: if two images are visually similar, their tag vectors (i.e., column vectors of A) should also be similar; 3) tag correlation: if two tags co-occur with high frequency in general images, their co-occurrence frequency (described by two row vectors of A) should also be high; and 4) error sparsity: the matrix E is sparse since the tag matrix D is sparse and also humans can provide reasonably accurate tags. All these components finally constitute a constrained yet convex optimization problem, and an efficient convergence provable iterative procedure is proposed for the optimization based on accelerated proximal gradient method. Extensive experiments on two benchmark Flickr datasets, with 25K and 270K images respectively, well demonstrate the effectiveness of the proposed tag refinement approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>With the rapid advance in the technology of digital imaging, there is an explosive growth in the amount of available image data in our daily lives. This trend urgently necessitates the development of effective retrieval technology for large volume of images <ref type="bibr" target="#b1">[1]</ref>.</p><p>Considering the elementary features undertaken in the approaches, a distinction can be generally made between content based image retrieval (CBIR) <ref type="bibr" target="#b2">[2]</ref> and text based image retrieval (TBIR) <ref type="bibr" target="#b1">[1]</ref>. The features adopted by CBIR are extracted from visual information, e.g., image color, texture and shape of the objects involved in the images. Although CBIR has been extensively studied for more than a decade, there exist three limitations which restrict its practicability <ref type="bibr" target="#b3">[3]</ref>. Firstly, the precision of CBIR is usually unsatisfactory because of the semantic gap between low-level visual features and high-level semantic concepts. Secondly, the efficiency of CBIR is usually low due to the high dimensionality of visual features. Thirdly, the query form of CBIR is unnatural for image search owing to the possible absence of appropriate example images. In contrast, TBIR solely adopts the text information to carry through the image indexing and search. Compared with the visual information, text is essentially a kind of representation for image content from the view of human-being concepts and provided with the characteristics in terms of low dimension and easy description. TBIR is a straightforward solution to conquer the disadvantages of CBIR.</p><p>The text information used in TBIR can be acquired from image title <ref type="bibr" target="#b4">[4]</ref>, surrounding text <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5]</ref> and user tag <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b6">6]</ref>. Thereinto, user tags are more consistent with semantic concepts and effective to describe image contents. Especially with the prevalence of photo sharing websites such as Flickr and Piscasa, which host vast of digital images with userprovided tags, tag based image retrieval has become potentially popular and practical in extensive applications. Nevertheless, the performance of tag based image retrieval is still far from satisfactory suffering from the inferior quality of image tags. Figure <ref type="figure" target="#fig_0">1</ref> illustrates a representative image for flying eagle downloaded from Flickr and its associated tags. We can observe that only "fly" and "bird" truly describe the visual content of the image, while other tags are imprecise. Meanwhile, some additional tags are missing, such as "sky" and "eagle" that are highly associated with the given image. The reason causing this phenomena is that the current image tagging on the photo sharing websites solely relies on the user inputs, which often prohibits accurate and comprehensive textual description of image visual content. Refining tags is thus highly desirable for tag based image retrieval and other related applications.</p><p>In this paper, to address the aforementioned imprecise and incomplete issues of user-provided image tags, we propose a novel refinement approach aiming to improve the quality of tags. The approach is motivated by the following four observations of image tags from large volume social images.</p><p>• Low-rank. The existing work on text information processing <ref type="bibr" target="#b7">[7]</ref> has demonstrated that the semantic space spanned by text keywords can be approximated by a smaller subset of salient words derived from the original space. As one kind of text information, image tags are consequently subject to such low-rank property.</p><p>• Content consistency. From large-scale image dataset, we can observe that visually similar images often reflect similar themes and thus are typically annotated with similar tags. Content consistency describes the relationships between content level and semantic level.</p><p>Being an important prior, this observation has been widely explored in visual category learning <ref type="bibr">[8,</ref><ref type="bibr" target="#b9">9]</ref>.</p><p>• Tag correlation. Semantic tags associated with images do not appear in isolation, instead often appear correlatively and naturally interact with each other at the semantic level. As another important prior, tag correlation characterizes the relationships within semantic level and is often the preliminary assumption of multi-label and contextual learning algorithms <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b11">11]</ref>.</p><p>• Error sparsity. With the general knowledge that the human-beings share most of the common concepts in the semantic space, the tagging results for one image are reasonably accurate to certain level. Moreover, one image usually is labeled with only couple of tags. Such observations lead to the characteristics of error sparsity for image tag matrix.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the framework of our problem formulation and solution. Given the user-provided image tag matrix D, to comprehensively characterize the above four factors, we cast the tag refinement task into a convex optimization problem, which simultaneously minimizes the matrix rank and priors as well as error sparsity. Concretely, the nuclear norm, 1 norm and trace operation are employed to model the properties regarding tag low-rank, error sparsity, content consistency and tag correlation, respectively. The results are the low-rank matrix A which encodes the refined image tags, and the sparse matrix E which represents the tagging errors in user-provided tags. To obtain the results effectively, we also propose an efficient convergence provable iterative procedure to accomplish the optimization. The novelties and main contributions of this paper are summarized as follows.</p><p>• We propose a new tag refinement formulation in form of convex optimization which comprehensively considers the tag characteristics from the points of view of low-rank, error sparsity, content consistency and tag correlation.</p><p>• Compared with existing works, the low-rank and error sparsity are firstly integrated into the optimization procedure for image tag refinement. With the assistance of constraints of content consistency and tag correlation, the proposed approach is capable of correcting imprecise tags and enriching the incomplete ones.</p><p>• We propose to use an accelerated proximal gradient method to speedup the optimization, which facilitates the proposed approach to be workable on large-scale image datasets.</p><p>The rest of the paper is organized as follows. Section 2 reviews the related work on image tag refinement. In Section 3, we introduce the formulation details of our proposed refinement approach. Section 4 describes an efficient iterative procedure for the solution to tag refinement. Experimental results on two Flickr image datasets are reported and analyzed in Section 5. Finally, we conclude the paper with future work discussion in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Many efforts have been devoted to the research on image tag refinement. As a pioneer work, Jin et al. <ref type="bibr" target="#b12">[12]</ref> utilized WordNet to estimate the semantic correlation among the annotated keywords and remove weakly correlated ones. This method, however, can only achieve limited success as it totally ignores the visual content of the images. In <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b13">13]</ref>, Wang et al. proposed a content based approach within the random walk with restart (RWR) framework for image annotation refinement where the visual similarity and word cooccurrence conditioned on visual similarities are both considered. In addition, a similar work was proposed by Jia et al. in <ref type="bibr" target="#b14">[14]</ref>, where the textual similarities of tags and visual similarities of images are fused in a multi-graph reinforcement framework. Liu et al. <ref type="bibr" target="#b15">[15]</ref> proposed to rank the image tags according to their relevance with respect to the associated images by tag similarity and image similarity in a random walk model. In <ref type="bibr" target="#b16">[16]</ref>, Xu et al. proposed to do tag refinement from topic modeling point of view. A new graphical model named as regularized latent Dirichlet allocation (rLDA) is presented to jointly model the tag similarity and tag relevance. These works are typical based on rerankingand-removing strategy, which focuses on selecting a coherent subset of keywords from the automatically annotated keywords. On the other side, the tags associated with the social images are often imprecise and incomplete. These works are thus not applicable in directly addressing the problems with inferior image tags, which is compelling to further extension on proposed algorithmic framework.</p><p>The most related work to our image tag refinement scheme is the improved version of <ref type="bibr" target="#b15">[15]</ref> proposed by <ref type="bibr">Liu et al. in [17]</ref> recently. In this work, the authors formulated image tag refinement as an optimization framework based on the consistency between visual similarity and semantic similarity in social images. An iterative bound optimization algorithm was applied to discover the improved tag assignment. Despite this work has shown encouraging results, it is not scalable to large-scale applications due to its high computation-cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TAG REFINEMENT TOWARDS LOW-RANK, CONTENT-TAG PRIOR AND ERROR SPARSITY</head><p>Denote the image collection I = {x1, x2, . . . , xn}, where n is the size of the image set. All initial tags appearing in the collection form a tag set T = {t1, t2, . . . , tm}, where m denotes the total number of unique tags. The initial tag membership for the whole image collection can be represented by a binary matrix D ∈ {0, 1} m×n whose element Dij indicates the presence of tag ti in image xj, i.e., Dij = 1 if ti is associated with image xj, otherwise Dij = 0. To represent the final refined results, we define the matrix A whose element Aij ≥ 0 denotes the confidence score of assigning tag ti to image xj, given by tag refinement approach.</p><p>For a given tag matrix D, the essential purpose of image tag refinement is to uncover the tag error matrix E, such that,</p><formula xml:id="formula_0">D = A + E,<label>(1)</label></formula><p>where matrix A is the ultimate refined tag matrix. As aforementioned as well as introduced later, this decomposition of the matrix D into A and E shall target four properties, which correspond to four items for the objective to optimize. More specifically, we use T l (A) to characterize the rank of the matrix A, Tc(A) and Tt(A) to measure the image content consistency and tag correlation of the refined tag matrix A, respectively, and Te(E) to measure the sparsity of the tagging error matrix E. Then the image tag refinement problem is generally formulated as follows:</p><p>min</p><formula xml:id="formula_1">A,E T l (A) + λ1Te(E) + λ2[Tc(A) + Tt(A)],</formula><p>subject to D = A + E .</p><p>(</p><formula xml:id="formula_2">)<label>2</label></formula><p>In the following subsections, we elaborate on how to define these four items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Low Rank and Error Sparsity</head><p>As we have discussed, the image tags are subject to lowrank property, and the semantically correlated tags in semantic space usually appear in images synchronously. Meanwhile, the tag error matrix is sparse for two reasons: 1) the number of annotated tags is essentially sparse compared with the relatively large tag number, and 2) humans generally share the similar semantic concepts and may provide reasonably accurate tags.</p><p>Motivated by the latest research on robust principal component analysis (RPCA) <ref type="bibr" target="#b18">[18]</ref>, we can formulate this problem as a matrix decomposition problem. In <ref type="bibr" target="#b18">[18]</ref>, it has been shown that a low-rank matrix A from D = A + E with gross but sparse errors E can be derived by solving the following optimization problem minimize</p><formula xml:id="formula_3">A * + λ E 1 , subject to D = A + E .<label>(3)</label></formula><p>Here, • * represents the nuclear norm of a matrix (the sum of its singular values), • 1 is the 1 norm denoting the sum of the absolute values of matrix entries, and λ is a positive weighting parameter. In our formulation, matrix D is the initial user-provided tags, A and E represent and characterize the low-rank refined tag matrix and sparse error matrix, respectively. Because it is hard to identify the model and control gross amount of the labeling error in the userprovided tags, this optimization strategy is suitable for our problem. Therefore, in our approach, the low-rank and error sparsity are modeled by nuclear norm (T l (A) = A * ) and 1 norm (Te(E) = E 1) according to the definition of Eq. (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Content Consistency for Tag Refinement</head><p>Based on the assumption of content consistency that visually similar images often reflect similar themes and thus are typically annotated with similar tags, the content consistency can be formulated as follows.</p><p>Given two images xi and xj associated with tag vectors ai and aj, where ai and aj are the i-th and j-th column vectors of the refined tag matrix A, we calculate the visual similarities between images. Let G = {I, W c } be an undirected weighted graph with vertex set I and similarity matrix W c ∈ IR n×n . Each element of the symmetric matrix W c measures, for a pair of vertices, its similarity. In our formulation, the similarity matrix W c is defined based on k-nearest-neighbor (k-NN) graph</p><formula xml:id="formula_4">w c ij = exp(-xi -xj 2 /σ 2 c ) if j ∈ N kc (i) or i ∈ N kc (j) , 0</formula><p>o t h e r w i s e , (4) where N kc (•) denotes the index set for the kc nearest neighbors of an image measured by Euclidean distance. In our approach, we empirically set kc = 0.001n and σc as the median value of the entries in W c . To solve this problem, we define the diagonal matrix P c as</p><formula xml:id="formula_5">P c ii = j =i w c ij , ∀ i . (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>Then, the content consistency among the images can be enforced by solving the following optimization min</p><formula xml:id="formula_7">A n i=1 n j=1 ai -aj 2 w c ij . (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>By following the graph embedding terminologies in <ref type="bibr" target="#b19">[19]</ref>, this formulation can be regarded as a kind of dimensionality reduction where A encodes the low-dimensional representations of the image set I.</p><p>The term Tc(A) in Eq. ( <ref type="formula" target="#formula_2">2</ref>) can then be rewritten as follows based on Eq. ( <ref type="formula" target="#formula_5">5</ref>) and ( <ref type="formula" target="#formula_7">6</ref>)</p><formula xml:id="formula_9">Tc(A) = Tr[A(P c -W c )A T ] , (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>where Tr(•) denotes the trace operation on a matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Tag Correlation for Tag Refinement</head><p>Similar to the formulation for image content consistency, we can construct the regularization item regarding the correlation among image tags. The difference from content consistency is that the k-NN graph for tag correlation is constructed by tag similarity. In this work, we adopt a concurrence based method to estimate the tag similarity, which is analogous to the principle of Google distance <ref type="bibr" target="#b20">[20]</ref>. We first estimate the semantic distance d(ti, tj ) between tags ti and tj as</p><formula xml:id="formula_11">d(ti, tj) = max[log q(ti), log q(tj)] -log q(ti, tj) log R -min[log q(ti), log q(tj)] , (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where q(ti) and q(tj) are the numbers of images containing tag ti and tag tj respectively and q(ti, tj) is the number of images containing both tags ti and tj. Such numbers can be obtained by performing search "tags only" on Google image website using the tags as queries. In addition, R is the total number of the images in Google image. Then, the semantic similarity between ti and tj in matrix W t is defined as</p><formula xml:id="formula_13">w t ij = exp[-d(ti, tj) 2 /σ 2 t ] , (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>where σt is empirically set as the median value of the entries in</p><formula xml:id="formula_15">W t = [w t ij ]</formula><p>. Similar to the case of content consistency, we calculate the diagonal matrix P t . The regularization term of tag correlation for refinement is thus represented as</p><formula xml:id="formula_16">Tt(A) = Tr[A T (P t -W t )A] .</formula><p>(10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">OPTIMIZATION VIA ACCELERATED PROXIMAL GRADIENT</head><p>Based on the definitions of the terms regarding low-rank, error sparsity, content consistency and tag correlation, we rewrite the objective function in Eq. ( <ref type="formula" target="#formula_2">2</ref>) as follows.</p><p>min</p><formula xml:id="formula_17">A,E A * + λ1 E 1+ λ2{Tr[A(P c -W c )A T ] + Tr[A T (P t -W t )A]} , subject to D = A + E .</formula><p>(11) Note that the regularization terms of content consistency and tag correlation share the same weight λ2 stemming from the consideration of tradeoff between optimization efficiency and performance accuracy. To solve this problem, we can intuitively employ the traditional Lagrange multiplier method. Unfortunately, this method will be generally computationintensive. Considering Eq. ( <ref type="formula">11</ref>) is convex and often computationally expedient to relax the equality constraint, we here pursuit an effective iterative procedure to solve this optimization based on the accelerated proximal gradient (APG) method with O(k -2 ) convergence rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">General Accelerated Proximal Gradient</head><p>To better introduce the solution to our problem, in this subsection, we firstly present a brief introduction on accelerated proximal gradient method and then give two basic propositions for the solution.</p><p>Given the following unconstrained convex problem</p><formula xml:id="formula_18">min X∈H F (X) . = μg(X) + f (X) , (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where H is a real Hilbert space endowed with an inner product •, • and a corresponding norm • , μ &gt; 0 is a relaxation parameter. Both g(X) and f (X) are convex and f (X) is further Lipschitz continuous ∇f (X1) -∇f (X2) ≤ L f X1 -X2 , where L f is the Lipschitz constant. Instead of directly minimizing F (X), proximal gradient algorithms minimize a sequence of separable quadratic approximations to F (X), denoted as Q(X, Y ), formed at specially chosen points</p><formula xml:id="formula_20">Y Q(X, Y ) . = f (Y )+ ∇f (Y ), X -Y + L f 2 X -Y 2 + μg(X) . (<label>13</label></formula><formula xml:id="formula_21">) Let G = Y -1 L f ∇f (Y ), then X = arg min X Q(X, Y ) = arg min X μg(X) + L f 2 X -G 2 . (<label>14</label></formula><formula xml:id="formula_22">)</formula><p>To solve Eq. ( <ref type="formula" target="#formula_18">12</ref>), one may repeatedly set X k+1 = arg minX Q( X, Y k ) with Y k chosen based on X0, . . . , X k . The convergence of this iteration depends strongly on the points Y k at which the approximations Q(X, Y k ) are formed. The natural choice Y k = X k can be interpreted as a gradient algorithm and results in a convergence rate no worse than O(k -1 ) <ref type="bibr" target="#b21">[21]</ref>. However, the work in <ref type="bibr" target="#b22">[22]</ref> has showed that instead setting</p><formula xml:id="formula_23">Y k = X k + b k-1 -1 b k (X k -X k-1 ) for a sequence {b k } satisfy- ing b 2 k+1 -b k+1 ≤ b 2 k can improve the convergence rate to O(k -2</formula><p>). The general proximal gradient method is described in Algorithm 1.</p><p>Algorithm 1: General Proximal Gradient Method</p><formula xml:id="formula_24">while not converged do Y k ← X k + b k-1 -1 b k (X k -X k-1 ). G k ← Y k -1 L f ∇f (Y k ). X k+1 ← arg minX μg(X) + L f 2 X -G k 2 . b k+1 ← 1+ √ 4b 2 k +1 2 , k ← k + 1. end</formula><p>The main motivation for forming the separable quadratic approximation in Algorithm 1 is that in many cases of interest, the minimizer X k+1 has a simple or even closed-form expression. Before presenting the details, we first introduce a soft-thresholding operators. For x ∈ R and ε &gt; 0, the soft-thresholding operation is defined as</p><formula xml:id="formula_25">Sε[x] . = ⎧ ⎨ ⎩ x -ε if x &gt; ε , x + ε if x &lt; -ε , 0 o t h e r w i s e. (<label>15</label></formula><formula xml:id="formula_26">)</formula><p>By extending this operator to vector and matrix, we then have <ref type="bibr" target="#b23">[23]</ref> Proposition 1. If H is an Euclidean space endowed with the Frobenius norm • F and g(•) is 1 norm, then X k+1 is given by soft-thresholding the entries of G k as</p><formula xml:id="formula_27">X k+1 = Sε[G k ] = arg min X ε X 1 + 1 2 X -G k 2 F . (<label>16</label></formula><formula xml:id="formula_28">)</formula><p>Proposition 2. if H is an Euclidean space endowed with the Frobenius norm and g(•) is the matrix nuclear norm, then X k+1 is given by soft-thresholding the singular values as</p><formula xml:id="formula_29">X k+1 = U Sε(Σ)V T = arg min X ε X * + 1 2 X -G k 2 F , (<label>17</label></formula><formula xml:id="formula_30">)</formula><p>where U ΣV T is the singular value decomposition (SVD) of G k .</p><p>Based on Eq. ( <ref type="formula">11</ref>) and ( <ref type="formula" target="#formula_18">12</ref>), we can obtain the objective function F (X) for our relaxed problem as</p><formula xml:id="formula_31">F (X) . = μ A * + μλ1 E 1 + μλ2 2 {Tr[A(P c -W c )A T ] + Tr[A T (P t -W t )A]} + 1 2 D -A -E 2 F , (<label>18</label></formula><p>) then g(X) and f (X) are respectively defined as</p><formula xml:id="formula_32">g(X) = μ A * + μλ1 E 1 , f (X) = μλ2 2 {Tr[A(P c -W c )A T ] + Tr[A(P t -W t )A T ]} + 1 2 D -A -E 2 F , (<label>19</label></formula><formula xml:id="formula_33">)</formula><p>where X = A E and the term 1 2 D -A -E 2 F penalizes violations for the equality constraint of Eq. <ref type="bibr" target="#b11">(11)</ref>. In the next subsections, we will show that f (X) in Eq. ( <ref type="formula" target="#formula_32">19</ref>) satisfies Lipschitz continuous condition and present the iterative solution of A and E based on the definitions in Eq. ( <ref type="formula" target="#formula_32">19</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Proof of Lipschitz Continuity</head><p>Observing terms in Eq. ( <ref type="formula">11</ref>), we can have that A * and E 1 are convex <ref type="bibr" target="#b22">[22]</ref>. Moreover, because P c -W c and P t -W t in the regularization terms regarding content consistency and tag correlation are the Laplacian matrices which are positive semidefinite, the terms Tr[A(P c -W c )A T ] and Tr[A T (P t -W t )A] are therefore convex with respect to A. Consequently, the linear combination of convex terms, namely the objective function for our problem, is also convex.</p><p>Based on the definition in Eq. ( <ref type="formula" target="#formula_32">19</ref>) and let R c = P c -W c and R t = P t -W t , we can calculate ∇f (X) as</p><formula xml:id="formula_34">∇f (A) = μλ2(AR c + R t A) + A + E -D , ∇f (E) = A + E -D . (<label>20</label></formula><formula xml:id="formula_35">)</formula><p>Given X1 = (A1 E1) and X2 = (A2 E2) , we have</p><formula xml:id="formula_36">∇f (X1) -∇f (X2) F = μλ2( AR c + R t A) + A + E A + E F , (<label>21</label></formula><formula xml:id="formula_37">)</formula><p>where A = A1 -A2 and E = E1 -E2. Then we have</p><formula xml:id="formula_38">∇f (X1) -∇f (X2) 2 F ≤ [4σ 2 max (μλ2R c ) + 4σ 2 max (μλ2R t ) + 6] A 2 F + 6 E 2 F ≤ L 2 f A1 -A2 E1 -E2 2 F ,<label>(22)</label></formula><p>where σmax(•) represents the maximum singular value of a matrix. Therefore, the Lipschitz constant is</p><formula xml:id="formula_39">L f = 4σ 2 max (μλ2R c ) + 4σ 2 max (μλ2R t ) + 6 . (<label>23</label></formula><formula xml:id="formula_40">)</formula><p>As the objective function is convex, we are able to use iterative optimization similar to Algorithm 1 to achieve the globally optimal solution <ref type="bibr" target="#b22">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimizing Low-Rank Refined Matrix</head><p>From Eq. ( <ref type="formula" target="#formula_20">13</ref>), ( <ref type="formula" target="#formula_21">14</ref>) and ( <ref type="formula" target="#formula_34">20</ref>), we can infer the optimal solution of X as following</p><formula xml:id="formula_41">X k+1 = arg min X Q(X, Y k ) = arg min X f (Y k ) + ∇f (Y k ), X -Y k + L f 2 X -Y k 2 F + μg(X) ,<label>(24)</label></formula><p>where</p><formula xml:id="formula_42">X = A E and Y = Y A Y E .</formula><p>When solving A k+1 , E is assumed to be constant and set as E k . The solution of A k+1 is thus simplified as</p><formula xml:id="formula_43">A k+1 = arg min A f (Y k ) + L f 2 A -Y A k 2 F + μg(A) + μλ2(Y A k R c + R t Y A k ) + Y A k + Y E k -D, A -Y A k . (25) Let O A k = μλ2(Y A k R c + R t Y A k ) + Y A k + Y E k -D, we have A k+1 = arg min A L f 2 A -Y A k + 1 L f O A k 2 F + μ A * + μλ1 E k 1 + f (Y k ) - 1 2L f O A k 2 F . (<label>26</label></formula><formula xml:id="formula_44">)</formula><p>In Eq. ( <ref type="formula" target="#formula_43">26</ref>), the term μλ1</p><formula xml:id="formula_45">E k 1 + f (Y k ) -1 2L f O A k 2 F is</formula><p>constant for the optimization of A. Therefore,</p><formula xml:id="formula_46">A k+1 = arg min A μ L f A * + 1 2 A -(Y A k - 1 L f O A k ) 2 F , (27) and G A k = Y A k -1 L f O A k .</formula><p>According to Proposition 2 (Eq. ( <ref type="formula" target="#formula_29">17</ref>)), this optimization can be solved by singular value thresholding algorithm as</p><formula xml:id="formula_47">A k+1 = U S μ L f [S]V T , (<label>28</label></formula><formula xml:id="formula_48">)</formula><p>where USV T is the SVD of G A k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Optimizing Sparse Error Matrix</head><p>Similar to the deduction procedure of A, the optimal solution of E with fixed A set as A k+1 is inferred as</p><formula xml:id="formula_49">E k+1 = arg min E Q(E, Y k ) = arg min E f (Y k ) + Y A k + Y E k -D, E -Y E k + L f 2 E -Y E k 2 F + μg(E) . (<label>29</label></formula><formula xml:id="formula_50">)</formula><p>Let</p><formula xml:id="formula_51">O E k = Y A k + Y E k -D, we have E k+1 = arg min E L f 2 E -Y E k + 1 L f O E k 2 F + μ A k+1 * + μλ1 E 1 + f (Y k ) - 1 2L f O E k 2 F . (30) In Eq. (30), the term μ A k+1 * + f (Y k ) -1 2L f O E k 2</formula><p>F is constant for the optimization of E. Therefore,</p><formula xml:id="formula_52">E k+1 = arg min E μλ1 L f E 1 + 1 2 E -(Y E k - 1 L f O E k ) 2 F . (31) Let G E k = Y E k -1 L f O E</formula><p>k , then the solution E k+1 can be obtained according to Proposition 1 (Eq. ( <ref type="formula" target="#formula_27">16</ref>))</p><formula xml:id="formula_53">E k+1 = S μλ 1 L f [G E k ] . (<label>32</label></formula><formula xml:id="formula_54">)</formula><p>As we empirically set an upper bound for μ in the optimization, the formulation (and solution) is robust to grossly corrupted data, e.g., Gaussian error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Implementation Issues</head><p>Based on the aforementioned analysis and deduction, we summarize the procedure for tag refinement via accelerated proximal gradient method in Algorithm 2. To speedup the convergence rate, we vary μ in the procedure starting from a large initial value μ0 and decreasing it geometrically with each iteration until it reaches the floor μ, rather than applying the proximal gradient algorithm directly to Eq. ( <ref type="formula" target="#formula_31">18</ref>). We observe that this greatly reduces the number of iterations and therefore, the number of SVD computations. The general proof of convergence of Algorithm 2 can follow the general case in <ref type="bibr" target="#b22">[22]</ref>. A "grid-search" strategy <ref type="bibr" target="#b26">[26]</ref> can be employed to set λ1 and λ2. We set λ1 ∈ {2 -6 , 2 -4 , . . . , 2 4 } and λ2 ∈ {2 -10 , 2 -8 , . . . , 2 0 }. Various pairs of (λ1, λ2) values were tried and the one with the best performance was picked. In the experiments, μ0 was empirically initialized as 1.0 and δ = 10 -9 . The decreasing rate η was set as 0.9.</p><p>As one tag unassociated with an image in the user-provided tag matrix does not simply imply that it is definitely irrelevant while perhaps because of missing tags. Therefore, it is natural to re-initialize D by a simple tag propagation step before tag refinement. The user-provided tags for each image are propagated based on its k nearest neighbors measured by visual features. Given image xi and its tag vector pi where element pij = 1 means tj is associated with xi whereas pij = 0 if tj is not associated, its k-NN set of images is denoted as Mi = {(x l i , p l i ), l = 1, . . . , k} where p l i is the tag vector of image x l i . The propagated tag vector vi for image xi is defined as</p><formula xml:id="formula_55">vi = k l=0 exp(-xi -x l i 2 /σ 2 ) c p l i , (<label>33</label></formula><formula xml:id="formula_56">)</formula><p>where c = k l=0 exp(-xi -x l i 2 /σ 2 ) is a normalization constant. The parameter σ is set as the same as σc in Eq. ( <ref type="formula">4</ref>) and k is empirically set as 0.1n where n is the average number of images for each tag. Note that</p><formula xml:id="formula_57">x 0 i = xi is the image xi itself.</formula><p>The low-rank matrix A is the final refinement result, where each entry produces the confidence score for a tag associated with an image. To identify the ultimate image tags, we rank the tags of each image based on their confidence scores and then retain the top m (e.g., m = 5) ones to be the refined tags associated with an given image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: Tag Refinement via Accelerated Proximal Gradient Method</head><p>Input: User-provided tag matrix D ∈ R m×n , matrix R c ∈ R n×n and R t ∈ R m×m for content consistency and tag correlation, and weighting parameters λ1, λ2.</p><formula xml:id="formula_58">A0, A-1 ← 0; E0, E-1 ← 0; b0, b-1 ← 1; μ ← δμ0. while not converged do Y A k ← A k + b k-1 -1 b k (A k -A k-1 )</formula><p>,</p><formula xml:id="formula_59">Y E k ← E k + b k-1 -1 b k (E k -E k-1 ). G A k ← Y A k -1 L f [μλ2(Y A k R c + R t Y A k )+Y A k + Y E k -D], (U, S, V ) ← svd(G A k ), A k+1 = U S μ k L f [S]V T . G E k ← Y E k -1 L f (Y A k + Y E k -D), E k+1 = S μ k λ 1 L f [G E k ]. b k+1 ← 1+ √ 4b 2 k +1 2 , μ k+1 ← max(ημ k , μ). k ← k + 1. end Output: A ← A k , E ← E k .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head><p>To systematically demonstrate the effectiveness of our proposed tag refinement algorithm, we performed thorough experiments on two large volume image datasets: MIRFlickr-25K <ref type="bibr" target="#b6">[6]</ref> and NUS-WIDE-270K <ref type="bibr" target="#b24">[24]</ref>. The MIRFlickr-25K and NUS-WIDE-270K datasets are both collected from Flickr website. The MIRFlickr-25K dataset contains 25, 000 images with 1, 386 tags. The second dataset, NUS-WIDE-270K, comprises a total of 269, 648 images with 5, 018 unique tags. Note that the tags in the above two collections are rather noisy and many of them are misspelling or meaningless words. Hence, a pre-processing was performed to filter out these tags. We matched each tag with entries in a Wikipedia thesaurus and only the tags with coordinates in Wikipedia were retained. Moreover, to avoid sample insufficiency issue in optimization, we further removed those tags To calculate the visual similarities between images, each image was extracted a 428-dimensional feature vector as the content representation, including 225-dimensional blockwise color moment features generated from 5-by-5 fixed partition on image, 128-dimensional wavelet texture features and 75-dimensional edge distribution histogram features <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b17">17]</ref>. To evaluate the performance of tag refinement, we evaluated the performance on 18 tags in MIRFlickr-25K and 81 tags in NUS-WIDE-270K where the ground-truth annotations of these tags have been provided. The F-score, which was widely used as evaluation metric of tag refinement <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b17">17]</ref>, was calculated to measure the refinement results for each tag and average them as the final evaluation.</p><p>In the experiments, the datasets of MIRFlickr-25K and NUS-WIDE-270K were both employed to evaluate the performance of tag refinement. In addition, MIRFlickr-25K was also utilized for the systematic evaluation of refinement performance against the noise rate, namely to study at least what percentage of tags are required to be annotated such that the tags are reasonably refinable, which is an important index for tag/annotation refinement, yet to our best knowledge, none of previous research effort has ever been devoted to this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation of Tag Refinement on MIRFlickr-25K</head><p>In this subsection, we demonstrate the convergence property of the optimization process. Two types of results are reported in terms of the value of objective function Eq. ( <ref type="formula" target="#formula_31">18</ref>) and the refinement performance (F-score) against iteration times. Figure <ref type="figure" target="#fig_2">2</ref> shows the detailed results. From Figure <ref type="figure" target="#fig_2">2</ref>(a), we can observe that the objective function converges after about 30 iterations. For this experiment, the relaxation parameter μ was fixed as 1.0 to avoid the affection from varying μ in Algorithm 2.  To study the tag refinement performance, three algorithms were employed as the baselines:</p><p>• User tagging (UT): i.e., the original user-provided tags.</p><p>• Random walk with restarts (RWR): the tag refinement algorithm based on random walk with restarts proposed in <ref type="bibr" target="#b13">[13]</ref>.</p><p>• Tag refinement based on visual and semantic consistency (TRVSC): the tag refinement algorithm based on visual and semantic consistency proposed in <ref type="bibr" target="#b17">[17]</ref>.</p><p>The RWR and TRVSC are the two state-of-the-art algorithms for tag refinement task. In addition, we compared the performance of our approach with different combinations of regularization terms: 1) low-rank and error sparsity only (LR ES), 2) low-rank, error sparsity and content consistency (LR ES CC), 3) low-rank, error sparsity and tag correlation (LR ES TC), and 4) all regularization terms (LR ES CC TC). Figure <ref type="figure" target="#fig_3">3</ref> shows the detailed performances of image refinement for individual tags between our proposed approach and the baselines. From Figure <ref type="figure" target="#fig_3">3</ref>, we can observe that the performance of tag refinement from our approach is much superior over those from user-provided tags, RWR and TRVSC algorithms. Table <ref type="table" target="#tab_0">1</ref> further lists the average performances measured by F-score for different tag refinement schemes.</p><p>The experiments were performed in Matlab platform on a server machine with dual quad-core 3.0GHz Intel Xenon processors and 32GB RAM. Our proposed approach (here refers to LR ES CC TC, note that the four versions of our proposed approach with different combinations of regularization terms are quite similar in computational cost) only cost 1 hour while, in contrast, RWR algorithm cost nearly 22 hours and TRVSC consumed more than 9 hours. Such results can be explained by analyzing the details of different algorithms. For RWR algorithm, it has to calculate large amount of visual similarity matrices conditioned on all the tags of each image against all the other images, which is highly computation-intensive. TRVSC algorithm equally needs to perform an intensive optimization during the refinement procedure, of which the algorithmic complexity is of O(mn 2 ), m and n are the total numbers of tags and images, respectively. Nevertheless, for our approach, the key computational bottleneck is the SVD required by each iteration, and the computational cost is lower compared with RWR and TRVSC. In addition, for the singular value thresholding step at each iteration, it is observed that full SVD computation is not always necessary, especially in the first few iterations when μ k is quite large. A partial SVD <ref type="bibr" target="#b25">[25]</ref> can be used to speed up the optimization procedure, and thus the computational cost can be further alleviated significantly.</p><p>Figure <ref type="figure" target="#fig_4">4</ref> further shows the tag refinement results for some exemplary images produced by our proposed approach. It can be seen that our proposed approach can effectively correct and enrich the imprecise and incomplete image tags. For example, in Figure <ref type="figure" target="#fig_4">4</ref>(c), only the tag "architecture" is related with the image content while other tags are annotated by users with their personal intentions. After tag refinement, the weakly related tags are removed and the close-related tags, e.g., "building" and "house", are enriched by considering the content consistency and tag correlation. Moreover,  the enrichment capacity of our proposed algorithm can be particularly seen from Figure <ref type="figure" target="#fig_4">4</ref>(b) and (h), where only one tag is associated with each image as original annotations, and the incomplete tags are finally enriched by our proposed refinement strategy reasonably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation of Tag Refinement on NUS-WIDE-270K</head><p>NUS-WIDE-270K is one of the most representative largescale image datasets. The evaluation on this dataset can not only verify the algorithmic performance, but also check the efficiency of our proposed approach on large-scale dataset. In this evaluation, we only compared the performance of our proposed tag refinement strategy in different optimization configurations, as the existing RWR and TRVSC algorithms are hard to be implemented for large-scale datasets due to their computation-intensive insights discussed above. The refinement duration on NUS-WIDE-270K is about 6 hours for our proposed approach (LR ES CC TC). This demonstrates that the APG based iterative procedure is efficient for optimization. Figure <ref type="figure" target="#fig_5">5</ref> shows the detailed tag refinement results for individual tags and Table <ref type="table" target="#tab_1">2</ref> summaries the average F-score for all tags. The baseline algorithm UT is evaluated based on user-provided initial tagging results.</p><p>Figure <ref type="figure" target="#fig_6">6</ref> displays some exemplary images with their initial tags and the refined tags. Such examples demonstrate the capacity of our proposed approach on large-scale image dataset. From Figure <ref type="figure" target="#fig_6">6</ref>(b), (c) and (d), we can see that the imprecise tags (e.g., girl, excellence and sigma) are removed by tag refinement. In Figure <ref type="figure" target="#fig_6">6</ref>(g) and (h), the missed tags (e.g., sky, night, people, and portrait) are enriched. From these results, we particularly observe that the proposed tag refinement approach is capable of automatic image annotation. There are about 25K images without any initial tags in NUS-WIDE-270K data collection. Figure <ref type="figure" target="#fig_6">6</ref>(a) and (f) illustrate two unlabeled images with refined tags. We can see that the added tags are reasonable regarding the image contents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation of Refinement Performance against Noise Rate</head><p>In this subsection, we systematically evaluate the tag refinement capability of our proposed approach at different tag noise rate and aim to uncover the breakdown point, where the performance of tag refinement shall decrease significantly. This breakdown point is valuable for guiding users to provide proper amount of tags, such that reasonably accurate tags can be recovered by tag refinement algorithms. However, to our best knowledge, no research effort has ever been devoted to this study. As our proposed approach is relatively more efficient and more effective, the experiments were performed based on our proposed tag refinement approach. The MIRFlickr-25K dataset and its tags with ground truth were utilized for these experiments.</p><p>Denote the binary tag membership matrix from the ground truth as Dg. We simulate the tag noises of different rates as follows. Assume that Dg is with N1 entries of value 1 and N0 entries of value 0, and the corresponding user-provided tag matrix is denoted Du. Based on Dg and Du, we can calculate two statistics T F1→0 and F T0→1. T F1→0 is the number of entries with value 1 in Dg whereas with value 0 in Du, and F T0→1 represents the number of entries with value 0 in Dg whereas with value 1 in Du. Then two statistics can be used to compute the ratio of two types of errors in human tagging. For a given rate (0 ≤ α ≤ 1) of noise,    we first randomly select N1→0 = αN1 entries of which the values are changed from 1 to 0. Then, N0→1 = F T 0→1 T F 1→0 N1→0 entries with value 0 are randomly selected and adjusted as 1.</p><p>Our proposed tag refinement approach is then performed on the noise-added tag matrix. Figure <ref type="figure" target="#fig_7">7(a)</ref> shows the tag refinement performance against different noise rate. From these results, we can observe that the tag refinement generally improves the tag quality by comparing with noise-added tag matrix. By increasing the noise rate, the tag refinement performance degrades gradually, and this phenomena is further detailed by calculating the curve of the absolute values of the degradation gradients as shown in Figure <ref type="figure" target="#fig_7">7</ref>(b). The degradation gradient gi is defined as gi = ri -ri+1 where ri and ri+1 are the refinement performance (F-score value) against i-th and (i+1)-th configurations of noise rates. From Figure <ref type="figure" target="#fig_7">7</ref>(b), we can conclude that our proposed approach is robust to the noise when increasing the noise rate from 0.1 to 0.8. When α is increased higher than 0.8, the degradation gradient is significantly increased, which is right at the breakdown point as marked in Figure <ref type="figure" target="#fig_7">7</ref>(b). This breakdown point means that, given that the ratio of two types of tagging errors is fixed, at least about 20% tags need be correctly tagged if we expect to achieve reasonably good performance in tag refinement task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS AND FUTURE WORK</head><p>Motivated by the fact that the existing user-provided image tags in public photo sharing websites are imprecise and incomplete, we proposed an efficient iterative approach for image tag refinement by pursuing the low-rank, content consistency, tag correlation and error sparsity. Extensive experiments on large-scale image datasets, 25K and 270K respectively, well demonstrated the effectiveness and efficiency of our proposed algorithm.</p><p>Our future work shall focus on two directions. First, more effective visual features shall be integrated in the current framework for measuring the image content consistency. Second, more efficient iterative optimization procedure shall be further exploited, such that the proposed algorithm can work on even larger volume image corpus.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Framework of image tag refinement towards low-rank, content consistency, tag correlation and error sparsity. The column-wise user-provided tag matrix D (Note that D is sub-sampled from a larger real user-provided tag matrix for ease of display), where white grid represents the association of a tag with image and black one represents non-association, is decomposed into a low-rank matrix A (the refined tag matrix and here rank(A) = 13) and a sparse matrix E (tagging error in user-provided tags and sparse error is E 0 = 72 in this illustration) by considering the properties of content consistency and tag correlation.</figDesc><graphic coords="2,104.04,53.72,401.56,241.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2(b) shows the refinement performance against iteration times. It is shown that the Fscore increases steadily as the iteration proceeds and finally reaches a satisfactory result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Convergence properties of the optimization process. (a) Convergence of the objective function value vs. iteration times with fixed μ = 1.0; (b) Convergence of the performance F-score vs. iteration times.</figDesc><graphic coords="7,53.76,541.31,238.98,93.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Detailed performances for individual tags of different approaches on MIRFlickr-25K dataset.</figDesc><graphic coords="8,83.88,54.04,441.80,124.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Exemplar tag refinement results from our proposed approach on MIRFlicker-25K dataset.</figDesc><graphic coords="8,68.88,211.83,471.93,131.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Detailed performances for individual tags of different approaches on NUS-WIDE-270K dataset.</figDesc><graphic coords="9,78.96,110.78,451.73,419.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Examples of tag refinement results by our approach on NUS-WIDE-270K dataset.</figDesc><graphic coords="9,66.36,561.13,476.84,140.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Detailed tag refinement results with different tag noise rate by our proposed algorithm on MIRFlickr-25K dataset. (a) Tag refinement performance against different noise rate compared with simulated noisy user-provided tags; (b) Absolute degradation gradient of the tag refinement performance against different noise rate.</figDesc><graphic coords="10,53.76,53.88,238.98,98.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Average performances of different algorithms for tag refinement on MIRFlickr-25K</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>UT</cell><cell>RWR</cell><cell>TRVSC</cell><cell>LR ES</cell><cell>LR ES CC</cell><cell>LR ES TC</cell><cell>LR ES CC TC</cell></row><row><cell>F-score</cell><cell>0.221</cell><cell>0.338</cell><cell>0.412</cell><cell>0.423</cell><cell>0.465</cell><cell>0.463</cell><cell>0.477</cell></row><row><cell cols="4">whose occurrence numbers are below 50. Consequently, 205</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">and 521 unique tags were obtained in total for MIRFlickr-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">25K and NUS-WIDE-270K, respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 : Average performances of different approaches for tag refinement on NUS-WIDE-270K</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>UT</cell><cell>RWR</cell><cell>TRVSC</cell><cell>LR ES</cell><cell>LR ES CC</cell><cell>LR ES TC</cell><cell>LR ES CC TC</cell></row><row><cell>F-score</cell><cell>0.269</cell><cell>-</cell><cell>-</cell><cell>0.299</cell><cell>0.321</cell><cell>0.330</cell><cell>0.353</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGMENT</head><p>This work was partially supported by AcRF Tier-1 Grant of R-263-000-464-112 Singapore and partially supported by IDMPO-MDA project number NRF20071DM-1DM002-069 on "Live Spaces -Place Oriented Embodied Media (POEM)" Singapore.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Image retrieval: ideas, influences, and trends of the new age</title>
		<author>
			<persName><forename type="first">R</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ACM Computing Surveys</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Content-based image retrieval at the end of the early years</title>
		<author>
			<persName><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scalable search-based image annotation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Image annotation by large-scale content-based image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bipartite graph reinforcement model for web image annotation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The mir flickr retrieval evaluation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Huiskes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ACM MIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Narrowing the semantic gapimproved text-based web document retrieval using visual features</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMM</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">80 million tiny images: a large dataset for non-parametric object and scene recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Svm-knn: discriminative nearest neighbor classification for visual category recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Semi-supervised multi-label learning by constrained non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to detect unseen object classes by between-class attribute transfer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Image annotations by combining multiple evidence and wordnet</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Awad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Content-based image annotation refinement</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-graph similarity reinforcement for image annotation refinement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Tag ranking</title>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Tag refinement by regularized lda</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image retagging</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust principal component analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<ptr target="http://watt.csl.illinois.edu/∼perceive/matrix-rank/Files/RobustPCA.pdf" />
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graph embedding and extension: a general framework for dimensionality reduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The google similarity distance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vitany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkage-thresholding algorithm for linear inverse problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sciences</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Fast convex optimization algorithms for exact recovery of a corrupted low-rank matrix</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno>UILU-ENG-09-2214</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">UIUC Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A singular value thresholding algorithm for matrix completion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nus-wide: A real-world web image database from national university of singapore</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CIVR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Lanczos bidiagonalization with partial reorthogonalization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Larsen</surname></persName>
		</author>
		<idno>DAIMI-PB-357</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Aarhus University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A practical guide to support vector classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/∼cjlin/papers/guide/guide.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
