<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Novel Hybrid Harris Hawks Optimization and Support Vector Machines for Drug Design and Discovery Journal Pre-proof A Novel Hybrid Harris Hawks Optimization and Support Vector Machines for Drug Design and Discovery</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-11-22">November 22, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Essam</forename><forename type="middle">H</forename><surname>Houssein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computers and Information</orgName>
								<orgName type="institution">Minia University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mosa</forename><forename type="middle">E</forename><surname>Hosney</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Computers and Information</orgName>
								<orgName type="institution">Luxor University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Diego</forename><surname>Oliva</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Depto. de Ciencias Computacionales</orgName>
								<orgName type="institution" key="instit1">Universidad de Guadalajara</orgName>
								<orgName type="institution" key="instit2">CUCEI</orgName>
								<address>
									<settlement>Guadalajara</settlement>
									<region>Jal</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Waleed</forename><forename type="middle">M</forename><surname>Mohamed</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computers and Information</orgName>
								<orgName type="institution">Minia University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Hassaballah</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Faculty of Computers and Information</orgName>
								<orgName type="institution">South Valley University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Novel Hybrid Harris Hawks Optimization and Support Vector Machines for Drug Design and Discovery Journal Pre-proof A Novel Hybrid Harris Hawks Optimization and Support Vector Machines for Drug Design and Discovery</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-11-22">November 22, 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">0CA83542E866C59B6621FD0872E9BB51</idno>
					<idno type="DOI">10.1016/j.compchemeng.2019.106656</idno>
					<note type="submission">Received date: 4 September 2019 Revised date: 14 November 2019 Accepted date: 18 November 2019 Preprint submitted to Elsevier</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computers and Chemical Engineering Chemoinformatics and Chemical Compound</term>
					<term>Classification Accuracy and Feature Selection</term>
					<term>Computer-Aided Drug Design</term>
					<term>Drug</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Design and Discovery; Harris Hawks Optimization; Support Vector Machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Cheminformatics is a field that predicts and analyzes different molecular properties by combining processes from diverse areas like computer sciences, mathematics, and information sciences <ref type="bibr" target="#b0">[1]</ref>. The principal aspects of Cheminformatics are closely related to databases, especially for the storage and retrieval of molecule structures and properties as pharmacogenomics data. Experts in chemistry and biology are the most related to diseases based on molecular analysis. For example, they can design molecules to interact with the disease agents in order to reduce or deactivate the damage <ref type="bibr" target="#b1">[2]</ref>. One of the main problems in this field is that the search space increases exponentially with the number of features contained in the datasets <ref type="bibr" target="#b2">[3]</ref>.</p><p>The use of Cheminformatics is extended to drug design where it is necessary to know the basis of cellular processes, predicting of protein structures, and estimating the interactions between a molecule and the normal biological molecular targets <ref type="bibr" target="#b3">[4]</ref>. In this sense, a drug is a small organic molecule used to activate or inhibit the effects of a disease. The process of drug design and discovery has different elements, but the most important are the lead structures optimization <ref type="bibr" target="#b4">[5]</ref>, establishment of quantitative structure-activity relationships (QSAR) <ref type="bibr" target="#b5">[6]</ref>, and docking of a ligand into a receptor de novo design of ligands <ref type="bibr" target="#b6">[7]</ref>. The process of drug design can be defined as rational drug design or as simply rational design <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. The aim is to find new medicines considering the knowledge of a biological target.</p><p>In recent years, important signs of progress in treating diseases are achieved; the current drug discovery process is mainly focused on the search and validation of drug candidates that act on a particular therapeutic target <ref type="bibr" target="#b9">[10]</ref>. First, the process of a particular disease is studied and its physiologic mechanisms are determined to detect the drug targets related to this disease. Then, new drugs are designed to act on these targets. Due to the high cost and the long-time required by the drug development process, pharmaceutical industry needs to improve the strategies for prioritizing targets and drug candidates in the drug discovery process. A broader knowledge of these targets can help to understand the mechanisms of action of drugs at molecular level and provide insights that guide drug design and the search for new targets. As a consequence of the above, new research studies on drug targets are continually published including the use of different techniques of machine learning for drug design. Some examples of such methods are neural networks, deep learning, wisdom of crow, ensembles of kernel predictors, random forest, support vector machines among others. An example of the use of this kind of techniques is the prediction of molecular properties closed to virtual drug screening of chemical library presented in Cheminformatics <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Working with large datasets is complicated because, in many cases, the instances are not well-defined <ref type="bibr" target="#b12">[13]</ref>. In other cases, there are many features that define information elements and it is difficult to identify the most appropriate elements. The datasets of Cheminformatics are not the exception; for that reason, tools as classification, Feature Selection (FS), and object recognition are widely used. The idea of this kind of algorithms is to remove irrelevant and redundant features from the original dataset <ref type="bibr" target="#b13">[14]</ref>. It helps to reduce dimensionality considering only the information that is relevant for posterior analysis. FS in classification has four steps: 1) selecting a subset of features by a search process, 2) evaluating the subset using different metrics, 3) if it is necessary select another subset, 4) validate the features considering the domain of knowledge. The main goal of the FS process is to minimize the number of features that reduces search space size and helps in machine learning techniques for using only the most important features <ref type="bibr" target="#b14">[15]</ref>. unfortunately, FS takes more time to define the relevant features on a dataset due to the strategies of identifying them at each iteration, and in the worst case, the features could be increased <ref type="bibr" target="#b15">[16]</ref>. To overcome these issues, algorithms from swarm and computational intelligence are commonly utilized <ref type="bibr" target="#b16">[17]</ref>.</p><p>There are two main FS categories, namely, wrapper and filter based methods <ref type="bibr" target="#b17">[18]</ref>. The Wrapper-based methods consider a classifier to identify the best subset of features. On the other hand, the filter-based methods do not need any classifier; they work using the information contained in the dataset. In general, the wrapper-based methods give better results than the filter-based methods <ref type="bibr" target="#b18">[19]</ref>. Overcoming the drawbacks of FS can be done by formulating it as an optimization problem that searches for the optimal subset of features <ref type="bibr" target="#b19">[20]</ref>. Here, the use of metaheuristic (evolutionary and swarm) algorithms will be very helpful. In such algorithms, each subset of features is considered as a solution that must be evaluated in an objective function. Beside, the use of metaheuristics can substantially reduce the computational effort in the search process.</p><p>Classification and feature optimization (i.e., feature selection and param-eter optimization) are two of many application domains that successfully employ metaheuristics algorithms. Motivated by the fact that the Cheminformatics field is a hot topic and metaheuristics algorithms can achieve good results, this paper introduces two classification approaches called (HHO-SVM and HHO-kNN). They are hybrid algorithms that combine the Harris Hawks Optimization algorithm with the Support Vector Machine and k-Nearest neighbors algorithm (k-NN) for the chemical descriptor selection and chemical compound activities. The HHO was firstly introduced in <ref type="bibr" target="#b20">[21]</ref> and it mimics the cooperative hunting behavior of Harris hawks. Under the HHO scheme, each Harris hawk is a candidate solution defined on a bounded space. To our knowledge, the HHO is a new optimization algorithm and its potential has not been extensively studied in real problems. Considering the above, the motivation of this paper is to propose a feature selection algorithm that combines the benefits of the HHO with SVM to extract the best features with accuracy. The experimental results and comparison support the fact that the proposed HHO-SVM is an excellent alternative for FS. The results are presented in terms of convergence curves, box plot, and statistical measurements such as mean, best, worst and standard deviation. Two chemical datasets (MonoAmine Oxidase (MAO) and QSAR Biodegradation are used in the comparison with several well-known methods such as the Particle Swarm Optimization (PSO) <ref type="bibr" target="#b21">[22]</ref>, Simulated Annealing (SA) <ref type="bibr" target="#b22">[23]</ref>, Dragonfly Algorithm (DA) <ref type="bibr" target="#b23">[24]</ref>, Butter Fly Optimization Algorithm (BOA) <ref type="bibr" target="#b24">[25]</ref>, Moth-Flame Optimization Algorithm (MFO) <ref type="bibr" target="#b25">[26]</ref>, Grey Wolf Optimizer (GWO) <ref type="bibr" target="#b26">[27]</ref>, Sine Cosine Algorithm (SCA) <ref type="bibr" target="#b27">[28]</ref>, Slap Swarm Algorithm (SSA) <ref type="bibr" target="#b28">[29]</ref>.</p><p>It noticed that HHO algorithm with SVM classifier presents the best results in terms of classification accuracy. The rest of the paper is organized as follows: In Section 2, a literature review is presented. Section 3 introduces the preliminaries of various material and methods of QSAR, the basics of HHO for feature selection, fitness function, and classification methods. Section 4 explains the preprocessing steps and the proposed HHO-SVM and HHO-kNN algorithms. In Section 5, the experimental results and discussion are presented. Finally, Section 6 provides the conclusions for this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Literature Review</head><p>With the advent of new technologies (e.g., Molecular Biology, Genomics, High Throughput Screening, etc.), it is expected that many new drugs would be discovered in the current decade. The working mechanism of drugs relies heavily on the accurate binding of drug molecules to complementary structures or protein targets. The field of study is termed 'docking', which refers to the usage of computer-aided drug design (CADD) in predicting binding modes between ligand and possible receptors. Over the years, this field has greatly matured with an ever-increasing database of proteins and nucleic acids <ref type="bibr" target="#b29">[30]</ref>. The concept of CADD permits to use valuable tools in identification of chemical compounds that minimize the risks of the later rejection of different lead compounds.</p><p>The CADD methods can be divided into ligand and hit identification or ligand and hit optimization. These methods are mostly based on the concept of docking large libraries for small molecules such as ZINC or the chemical information for the known compounds such as Pubchem by using the docking or the pharmacophore modeling tools. They are used for predicting the best medicine by the protein and ligand. Then, the selection of the best ligand to become the best drug is performed by the pymol software for separate ligand from protein <ref type="bibr" target="#b30">[31]</ref> and calculated the energy by outodock software <ref type="bibr" target="#b6">[7]</ref>. As an example of the implementation of metaheuristics in this field, we can refer to the use of Genetic Algorithms (GA) in outodock software as GOLD or AutoDock Vina <ref type="bibr" target="#b31">[32]</ref>. Also, a robust fuzzy optimization approach for chemical product design is proposed in <ref type="bibr" target="#b32">[33]</ref>. Meanwhile, Yu Liu et al. <ref type="bibr" target="#b33">[34]</ref> proposed FIPSDock based on Particle Swarm Optimization (PSO) to ligand docking that is more suitable than conventional GA in flexible docking. GA and PSO are excellent alternatives for optimization and their use in drug design is the evidence of their capabilities in complex optimization problems. However, depending on the circumstances they could be trapped into suboptimal solutions that demerit the accuracy <ref type="bibr" target="#b34">[35]</ref>. Moreover, both GA and PSO are depended on population initialization and proper setting of their control parameters <ref type="bibr" target="#b31">[32]</ref>.</p><p>Another direction for CADD is the quantitative structure-activity relationship (QSAR) model. It permits different descriptions of the correlation between the structures from a set of molecules and the response for target. The general QSAR consists of constant comparison between the collected information from a set of active and inactive molecules against the target and the production of the descriptor, QSAR algorithms are continuously evolving along the process <ref type="bibr" target="#b35">[36]</ref>.</p><p>Drug design and discovery represent one of the main aspects of Cheminformatics including two phases. The first phase is called the encoding and it indicates the three-dimensional information. While, the second phase is called the mapping and it is a model building phase to use machine learning in the Cheminformatics <ref type="bibr" target="#b11">[12]</ref>. In the first phase, the molecular structure is showed as the molecular graph or the connection table. It is converted for vector of features. It is done by calculating descriptors as in <ref type="bibr" target="#b35">[36]</ref>. In the second phase, the machine-learning is used for building various models in Cheminformatics. This task can be done by discovering different functions that are used for the maps between different feature vectors and a property. The mapping can be done by different machine learning algorithms <ref type="bibr" target="#b10">[11]</ref>. A considerable amount of literature has been proposed such as the comparison of machine learning techniques that have been performed to obtain a satisfactory classifier for detecting drug-target articles using semantic information from biomedical resources <ref type="bibr" target="#b36">[37]</ref>. A interesting review including machine learning techniques such as Bayesian neural networks, self-organizing maps, multi-layer perceptron, and support vector machines as drug design tools is presented in <ref type="bibr" target="#b37">[38]</ref>. Further, the work presented in <ref type="bibr" target="#b38">[39]</ref> provides step-wise tools for building machine learning and statistical methods for drug designing in chemoinformatics. The training process and design of learning mechanisms in such techniques imply complex tasks required to obtain accurate solutions.</p><p>The metaheuristic algorithms are used widely in drug design and discovery <ref type="bibr" target="#b14">[15]</ref>. The capabilities of computational models with human knowledge using a genetic algorithm and interactive evolutionary computation were combined to describe the Drug Candidate Design Environment <ref type="bibr" target="#b39">[40]</ref>. Also, the bacterial foraging optimization method has been successfully applied in Ligand docking for Drug Design <ref type="bibr" target="#b40">[41]</ref>. Nicolaou, Christos, and Nathan Brown <ref type="bibr" target="#b41">[42]</ref> reviews the latest multi-objective methods and applications reported in the literature, specifically in quantitative structure-activity modeling, docking, de novo design and library design.</p><p>The swarm intelligence algorithms combining with the machine learning techniques are currently used for classification tasks. In this work, they are utilized for detecting features that contain drug-target interactions to reduce the time and effort needed to create a drugtarget database manually. The main goals of classification are maximizing the accuracy, minimizing the different number of features and reducing the computational time <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. More attempts are needed for the speed up for the process of selecting the best information and the more useful features in databases, considering this fact many methods were proposed and studied extensively <ref type="bibr" target="#b44">[45]</ref>. The process of selecting significant information is called feature selection problem that uses machine learning strategies for exploring the importance of the selected features <ref type="bibr" target="#b45">[46]</ref>.</p><p>As a consequence of the above, the metaheuristic-based approaches achieve the task in less time compared to the exhaustive search. In this sense, the proposed metaheuristic approaches for the FS problem exhibit good performance in selecting the best set of features. Some examples are Forest Optimization Algorithm (FOA) in <ref type="bibr" target="#b46">[47]</ref>, hybrid whale optimization algorithm with simulated annealing <ref type="bibr" target="#b47">[48]</ref> and the Ant Colony Optimization (ACO) <ref type="bibr" target="#b19">[20]</ref> which shows the more desirable results. The advantage of this kind of methods is their acceptable time complexity. However, it is necessary to develop more accurate methods that can handle more complex datasets. This fact occurs because an optimization algorithm has no ability to solve all the problems with the same degree of accuracy <ref type="bibr" target="#b48">[49]</ref>. based on the aforementioned analysis, the metaheuristic algorithms with different machine learning techniques are commonly used in different fields of applications. Their use leads to the implementation of the chemical compound. Such algorithms help in generating more effective methods and to provide faster results. These hybrid techniques are applied for QSAR methods. As they are based on the descriptors calculated, the optimal results can be calculated by the E-dragn software <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b5">6]</ref>. One example is the use of swarm algorithms with machine learning in chemical data, it shows that the SSA combined with k-NN based on QSAR is an interesting alternative that provides competitive solutions <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Material and methods</head><p>This section provides an explanation of the basic QSAR methods and framework of Harris hawks optimization with Support Vector Machine along with some key concepts of the K-nearest neighbor algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Quantitative structure-activity relationship</head><p>Quantitative structure-activity relationship (QSAR) is used for given information to declare the relationship between chemical structure and biological activity expressed in a mathematical form. There are advantages of QSAR method to identify the main properties of chemical compounds. There is no need for synthesis and testing of them (chemical structure and biological activity). More techniques of machine learning were successfully applied to structure-activity relationship analysis to predict if a compound is similar to demonstrate drug-like activity in the presence of a given disease (or simply a given chemical target). Complex molecular compounds may be used for describing a large number of attributes or features, such as topological indices, characterizing. Molecular descriptors play the main role in chemistry, pharmaceutical sciences <ref type="bibr" target="#b5">[6]</ref>. QSAR methodologies are used to develop statistical models relating chemical structure and biological activity, as well as they are useful in elucidating the mechanisms of the chemical-biological interaction in several biomolecules. The next step in QSAR studies is developing a suitable statistical model, employing the descriptors obtained previously for a compound set, and the main application of this model is the activity prediction of new compounds and, consequently, to use such model for understanding the possible mechanisms of action for a particular drug. The quality and success of a QSAR model depend strictly on the accuracy of input data, selection of appropriate descriptors and statistical tools, and, most importantly validation of the developed model <ref type="bibr" target="#b49">[50]</ref>. Recently, there is also a growing interest in the application of artificial neural networks and support vector machines in the field of QSAR as well as other molecular modeling approaches have been recognized as important tools in drug discovery <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">k-Nearest neighbors algorithm</head><p>The k-Nearest neighbors algorithm can be used in both classification and regression for predictive problems <ref type="bibr" target="#b52">[53]</ref>. It is widely used in classification problems. It has some advantages like, easy to interpret the output, low calculation time and predictive power. The k-NN algorithm represents one of supervised learning algorithms for classifying an unknown sample of instance based on the plurality of the k-NN, and also it represents one of methods for machine learning methods for understanding and explaining. It is used as a classification for the correct importance for the selected features. It depends on the two main parts. A metric is used for computing the distance between two points and it depends on the value of k that also represents the number of neighbors to consider. The classification process depends on the closest neighbors instead of the learning and a good separating frontier between classes, if k is a very big number then k-NN will be underfitting in contrast if the k value is a small number, then k-NN can overfitting.</p><p>An interesting application is a chemical application; here, the molecules are described in position vectors for the feature space. Neighbors can be known as the basis for distance of the feature space and includes the target variable, if it is present. More exactly, the data points represent in a metric space and can be possibly even multidimensional vectors or scalars. This idea is based on Euclidean distance, although in other metrics are based on the Jaccard distance. The steps that compose the k-NN are then given in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Pseudo-code of k-NN algorithm</head><p>Inputs </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Support vector machines</head><p>The supervised learning algorithms for classification can be represented using SVM <ref type="bibr" target="#b53">[54]</ref>. This approach is used for mapping the data for a highdimensional space by using the main concepts of the kernel function that is nonlinear. The SVM is used to find the best solution that separates two classes. The SVM represents a linear model for regression and classification problems. It can solve linear and non-linear problems and work well for practical problems. The main idea of SVM is simple, where the algorithm creates a line or a hyperplane which used to separate the data into classes. The first main task is what SVMs do is finding a separating line (or hyperplane) between data of two classes. SVM is an algorithm that takes data as an input and outputs a line that separates those classes. It maximizes different margins in the closest points called support vectors and hyperplane. The output of the algorithm is an optimal hyperplane. In a two-dimensional space, this hyperplane represents a line for dividing a plane into two parts wherein each class lay on either side. There are some parameters control in the result of SVM. Tuning parameters represents the arguments defined by the designer when it is created the classifier. The C parameter controls the tradeoff between smooth decision boundary and the classifying training points correctly.</p><p>If large value of C is defined, it will get more training points correctly, and it also will mean that the output has more intricate decision curves trying to fit in all the points. The different values of C for the dataset to get the perfectly balanced curve and avoid overfitting. Meanwhile, Γ defines how far for the influence of single training. If it has a low value, it means that every point will have a far reach and conversely a high value of Γ means that every point has close reach. If Γ has a very high value, then the decision boundary is just going to be dependent upon the points that are very close for the line that effectively results in ignoring some for the points that are very far from the boundary of the decision. This is because the closer points have a higher weight. If the Γ value is low even the far away points get considerable weight.</p><p>SVM is one of most popular machine-learning methods which is widely used in Cheminformatics. One application of SVM is for prediction toxicityrelated properties such as HERF blockade, 47,63,64 mutagenic toxicity, 65 toxicity classification, 66 and phospholipidosis toxicity. The pseudo-code of SVM is presented in Algorithm 2 and a graphical explanation is given in Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Pseudo-code of SVM algorithm</head><p>Inputs:Load the training and test data.</p><p>Outputs:Calculate accuracy.</p><p>Choose the cost value C and Γ for SVM. while (stopping condition is not met) do Implement SVM train step for each data point.</p><p>Implement SVM classify for testing data points. end while Return accuracy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Harris hawks optimization</head><p>The Harris Hawks Optimization is inspired by the cooperative behaviors and chasing style of Harris hawks in nature called surprise pounce. In this strategy, several hawks cooperatively pounce a prey from different directions in an attempt to surprise it. Harris hawks can reveal a variety of chasing patterns based on the dynamic nature of scenarios and escaping patterns of the prey <ref type="bibr" target="#b20">[21]</ref>. This work mathematically mimics such dynamic patterns and Harris hawks behaviors to develop an optimization algorithm that has been presented as a competitive alternative for complex problems. HHO as a stochastic metaheuristic is able to tackle many complex optimization problems. The HHO model can be expressed between exploratory and exploitative phases. The core steps of HHO can be visually understood concerning the state of energy as exposed in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>The exploration phase mimics the process where a Harris hawk is no able to properly track the prey. When it occurs, the hawks take a break to monitor and identify new preys. In the HHO approach, the candidate solutions are the hawks and the best so far solution at each step is the prey. The hawks then perch randomly in a different location and wait for a prey using two operators that are selected based on a probability q. This process is modeled in Eq. ( <ref type="formula">1</ref>), where q &lt; 0.5 means that the hawks perch using the position of other members of the population and the prey (rabbit). Meanwhile, if q ≥ 0.5, the hawks perch on random trees that are random locations around the population range. To facilitate understanding of the HHO algorithm, Table <ref type="table" target="#tab_1">1</ref> presents a list of symbols used in this algorithm.  </p><formula xml:id="formula_0">X(t + 1) = X rand (t) -r 1 |X rand (t) -2r 2 X(t)| q ≥ 0.5 (X rabbit (t) -X m (t)) -r 3 (LB + r 4 (U B -LB)) q &lt; 0.5 (1)</formula><p>Where, X m is the average location of the hawks obtained using:</p><formula xml:id="formula_1">X m (t) = 1 N N i=1 X i (t)<label>(2)</label></formula><p>Where, X i (t) represent the position for each hawk in the iteration t and N is the total number for the hawks. The average location can be obtained using different ways, but this is the simplest way.</p><p>The transition from exploration to exploitation occurs when it is necessary a change between different exploitative simulate behaviors depending on the energy of prey escaping. The prey energy decreases considerably while the escaping behavior. To model this concept the prey energy is modeled as:</p><formula xml:id="formula_2">E = 2E 0 (1 - t T )<label>(3)</label></formula><p>Figure <ref type="figure" target="#fig_3">3</ref> monitors the variation of E over specified number of iterations. One of the main steps in the HHO algorithm is the soft besiege. It occurs  When r ≥ 0.5 and |E| ≥ 0.5, then the rabbit has enough energy. It can try to escape by random misleading shifts but unfortunately it can not do it. This process is stimulated by the following rules:</p><formula xml:id="formula_3">X(t + 1) = ∆X(t) -E |JX rabbit (t) -X(t)| (4) ∆X(t) = X rabbit (t) -X(t)<label>(5)</label></formula><p>Where, ∆X(t) represents the difference between the positions vector for all the rabbit and the present locations in the different iteration t, r 5 is a random number inside (0, 1), and J = 2(1r 5 ) represent the random leap the strength for all rabbit throughout in the escaping steps. The J value changes randomly in each iteration to simulate the behavior for the rabbit suggestion.</p><p>In the hard besiege, if r ≥0.5 and |E| &lt;0.5, the prey is extremely tired and it is in a low escaping energy. The Harris hawks hardly encircle the prepared prey and perform the surprise attack. The current locations are updated for this situation using</p><formula xml:id="formula_4">X(t + 1) = X rabbit (t) -E |∆X(t)|<label>(6)</label></formula><p>In the real behavior of hawks, it is supposed that they can progressively select the best possible dive toward the prey when they wish to catch the prey in competitive situations. This is simulated as</p><formula xml:id="formula_5">Y = X rabbit (t) -E |JX rabbit (t) -X(t)|<label>(7)</label></formula><p>The process described in Eq. ( <ref type="formula" target="#formula_5">7</ref>) is called soft besiege with progressive rapid dives occurs if |E| ≥0.5 and r &lt;0.5. In this case, the rabbit has enough energy for escaping and it is applied a soft besiege before making the surprise of the attack. The HHO algorithm models different escaping patterns of the prey and leapfrog movements. Here, Levy flights (LF) are introduced to imitate the different movements of the rabbit and the complex dives of hawks. Eq. ( <ref type="formula" target="#formula_6">8</ref>) permits to compute such patterns.</p><formula xml:id="formula_6">Z = Y + S × LF (D)<label>(8)</label></formula><p>Where, S is a random vector of size 1 × D and LF represents the levy flight function that can be calculated using:</p><formula xml:id="formula_7">LF (x) = 0.01 × u × σ |v| 1 β , σ = γ(1 + β) × sin( πβ 2 ) γ( 1+β 2 ) × β × 2 ( β-1 2 ) ) 1 β<label>(9)</label></formula><p>Where, u and v are random values between (0,1) and β represents the default constant set to 1.5. The final step of this process is updating the positions of the hawks using:</p><formula xml:id="formula_8">X(t + 1) = Y if LF (Y ) &lt; LF (X(t)) Z if LF (Z) &lt; LF (X(t))<label>(10)</label></formula><p>Where, Y and Z are obtained by using Eq.( <ref type="formula" target="#formula_5">7</ref>) and Eq.( <ref type="formula" target="#formula_6">8</ref>).</p><p>The HHO also considers the hard besiege with progressive rapid dives that is presented if |E| &lt;0.5 and r &lt;0.5. In this case, the rabbit has not enough energy for escaping and the hard besiege is applied before making the surprise attack for the catching and killing the prey. In this step, the hawks are looking for a reduction of the distance between their average location and the prey. Eq. ( <ref type="formula" target="#formula_8">10</ref>) explains this operator where the values of Y and Z are obtained using new rules in Eqs.( <ref type="formula">11</ref>) and ( <ref type="formula" target="#formula_6">8</ref>) and X m (t) is obtained using Eq. <ref type="bibr" target="#b1">(2)</ref>.</p><formula xml:id="formula_9">Y = X rabbit (t) -E |JX rabbit (t) -X m (t)| (11)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Proposed HHO-SVM Approach</head><p>The HHO algorithm is hybridized with SVM for the purpose of classification and feature optimization (feature selection and parameter optimization). In HHO, X rabbit as the location of the rabbit (best location) is identified as SVM parameters in the selected features set for all cross-validation folds. The flowchart of the proposed HHO-SVM approach is illustrated in Fig. <ref type="figure">4</ref>, which shows the three phases of the proposed HHO-SVM approach: (1) Preprocessing, (2) Feature selection and optimization, and (3) Classification and validation. The Pseudo-code of HHO-SVM classifier algorithm is also described in Algorithm 3.</p><p>Equation 12 is defined to update the location vector in the soft and hard besiege with progressive rapid dives as follows;</p><formula xml:id="formula_10">X(t + 1) = Y if LF (f obj(D, G, Y )) &lt; LF (f obj(D, G, X((t)) * X((t) Z if LF (f obj(D, G, Z)) &lt; LF (f obj(D, G, X((t)) * X((t)<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Fitness function (fobj)</head><p>The solutions obtained by HHO must evaluated during the iterative process to verify its performance. The fitness function (f obj) used by the HHO is defined as: Outputs: The accuracy value for each iteration (best location) and the best accuracy value. Initialize the random population X i (i = 1, 2, . . . , N ) while (stopping condition is not met) do Calculate the new fitness values of hawks Set X rabbit as the location of rabbit (best location) for (each hawk (X i )) do Update the initial energy E 0 and jump strength J E 0 =2rand()-1, J=2(1-rand()) Update the E using Eq. ( <ref type="formula" target="#formula_2">3</ref>) if (|E| ≥ 1) then Exploration phase Update the location vector using Eq. ( <ref type="formula">1</ref>)</p><formula xml:id="formula_11">f obj = α + β |R| |C| -G. (<label>13</label></formula><formula xml:id="formula_12">end if if (|E| &lt; 1) then</formula><p>Exploitation phase if (r ≥0.5 and |E| ≥ 0.5 ) then Soft besiege Update the location vector using Eq. ( <ref type="formula">4</ref>) else if (r ≥0.5 and |E| &lt; 0.5 ) then</p><p>Hard besiege Update the location vector using Eq. ( <ref type="formula" target="#formula_4">6</ref>) else if (r &lt;0.5 and |E| ≥ 0.5 ) then Soft besiege with progressive rapid dives Update the location vector using Eq. ( <ref type="formula" target="#formula_10">12</ref>): Call the feature selection method. Call the SVM classifier. else if (r &lt;0.5 and |E| &lt; 0.5 ) then</p><p>Hard besiege with progressive rapid dives Update the location vector using Eq. ( <ref type="formula" target="#formula_10">12</ref>). Call the feature selection method. Call the SVM classifier. end if end if end for end while Return T he best accuracy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Feature selection Process</head><p>Feature selection is considered a preprocessing step commonly used before machine learning algorithms for choosing a subset of the features that is clean of redundancies. The improvement of prediction accuracy and the understanding of data for the different machine learning techniques is done by selecting features that can be highly correlated over other features. It means that if the two features represent perfectly in correlated but only the one feature is used in the sufficient describing the data. For the feature vector sized N , the different combinations of feature would be 2N that it is a huge space hard to be exhaustively explored. Therefore, the directly evaluating becomes as a NP-hard problem due the increment in the number of features <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b54">55]</ref>. A large search space represents a big challenge for the task of feature selection. Therefore, metaheuristic algorithms are widely used for solving feature selection problems. Here, HHO is adapted to select the significant features as demonstrated in Fig. <ref type="figure">4</ref> and to search adaptively in the feature space for selecting the best feature subset. The best solution must maximize the classification accuracy, must achieve the target for which feature is one with a minimum classification error rate and have the minimum number of selected features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>To avoid possible bias in the selection of the test and training sets, 10-fold cross-validation for SVM and k = 5 for k-NN are utilized in this work. For evaluation of the performance of the proposed approach, it is compared with eight other well-known algorithms. All the algorithms were implemented using the Matlab and well-documented studies to generate results. In particular, the compared algorithms were hybridized with two well-known machine learning classifiers in the literature (KNN and SVM). Two chemical datasets (MonoAmine Oxidase (MAO) and QSAR Biodegradation were used. Each compared algorithm has been run 30 times with 30 agents and 100, 500 and 1000 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data description</head><p>We have used two chemical compound datasets to perform the experimental evaluations for the proposed approach. The first one is the monoamine oxidase (MAO) dataset and is available on the web page IAPR-TC15 (http://iapr-tc15.greyc.fr/links.html), which consists of 68 molecules, and is divided into two classes: 38 molecules inhibit MAO (antidepressant drugs) and 30 do not. The mean size of each of the 68 molecules is 18.4 atoms. The mean degree of atoms in this dataset is 2.1 edges. The smallest molecule has 11 atoms and the largest has 27 atoms. Molecules (rows) and each molecule has 1665 descriptors. The second dataset (QSAR biodegradation) is defined from the Acquired Immunodeficiency Syndrome (AIDS) and an antiviral screen database of active compounds and is available on (https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation), which composed of 1055 chemical compounds and 41 molecular descriptors and 1 experimental class. The data have been used to develop QSAR models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Data preprocesing</head><p>This section describes how can transfer from monoamine oxidase (MAO) to features that define the chemical information. The used Cheminformatics data has been transformed into a Simplified Molecular-Input LineEntry System style using OpenTable software <ref type="bibr" target="#b55">[56]</ref>. Then, we calculate molecular descriptor <ref type="bibr" target="#b35">[36]</ref> using E-dragon <ref type="bibr" target="#b56">[57]</ref> as shown in Fig. <ref type="figure" target="#fig_5">5</ref>. Complex molecular compounds can be described by a large number of attributes or features, such as topological indices, characterizing the three-dimensional molecular structures, quantum mechanical descriptors, and molecular field parameters, which could be tens or hundreds of thousands of features. The descriptors can be structural or physicochemical (molecular weight, volume, rotatable bonds, interatomic distances, atom types, molecular walk counts, electronegativity, atom distribution, aromaticity, and solvation properties). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Evaluation metrics</head><p>The following measures are used to validate and evaluate the proposed approach considering the best fitness value f obj obtained at run i:</p><p>1. The mean is the average of the fitness function values obtained by running algorithm M for times. The Mean fitness function can be calculated as:</p><formula xml:id="formula_13">M ean = M i=1 f obj M<label>(16)</label></formula><p>2. Best fitness function corresponds to the minimum value of the fitness function that it has been obtained running the algorithm M times. The Best fitness function value can be calculated as</p><formula xml:id="formula_14">Best = M max i=1 f obj<label>(17)</label></formula><p>3. Worst fitness function is the higher value of the fitness function that it is obtained from the running algorithm M times. The Worst fitness function value can be calculated by</p><formula xml:id="formula_15">W orst = M min i=1 f obj<label>(18)</label></formula><p>4. Standard Deviation (Std) is used for the variation of the fitness function value that computed from the running algorithm M times. It declares an indicator of the stability and robustness of an algorithm. Larger values for standard deviation would indicate the wandering results although the smaller value suggests that the algorithm converges for the same value most of the runs. Std can be calculated using:</p><formula xml:id="formula_16">Std = 1 M -1 Σ M i=1 (f obj -mean) 2<label>(19)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Results analysis and discussion</head><p>The experiments are carried out on a PC of Intel Core i3-5200 CPU 2.20GHz, 4.00 GB RAM, Windows 7 and Matlab 2013a. Parameters of all tested algorithms are defined as follows: number of search agents 30, problem dimension 1665, number of iterations 100,500,1000, number of experiments (runs) 30, α in the fitness function is 0.99, β in the fitness function is 0.01, the lower bound is 0 and the upper bound is 1. Several recently proposed metaheuristics are considered in evaluation of the proposed approach including; Particle Swarm Optimization (PSO), Simulated Annealing (SA), Dragonfly Algorithm (DA), Butterfly Optimization Algorithm (BOA), Moth-Flame Optimization Algorithm (MFO), Grey Wolf Optimizer (GWO), Sine Cosine Algorithm (SCA), Slap Swarm Algorithm (SSA). All these algorithms use the same number of elements in the population that at the beginning is randomly distributed in a multidimensional bounded search space. The fitness function (f obj) is the same as is explained in previous sections. Here, it is important to mention that the configuration of the parameters for all the algorithms is provided in Table <ref type="table" target="#tab_2">2</ref>. The experiments are divided into two groups; in the first group, all the algorithms are tested using the k-NN classifier, while, in the second group the optimization techniques use the SVM for classification. Both groups have performed the experiments using 100, 500 and 1000 iterations, respectively and 30 independent runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1.">k-NN experiments</head><p>In this group of experiments, the competitor algorithms combined with k-NN are firstly tested with 100 iterations in 30 independent runs. The results are reported in Table <ref type="table" target="#tab_3">3</ref> over the two datasets (MonoAmine Oxidase (MAO) and QSAR Biodegradation). From this table it is noticed that HHO has the best value in mean, the third-best value for in Std and the first in the best criteria for maximizing the classification accuracy solution. In this context, the MFO provides the second-best values for mean and the second-best value for the best. In this test, the HHO has a good performance that is reflected in the convergence curve presented in Fig. <ref type="figure" target="#fig_9">6a</ref> and<ref type="figure" target="#fig_9">6d</ref>. Moreover, a graphical analysis of the results of HHO is shown in the box plot of Fig. <ref type="figure" target="#fig_11">7a</ref> and<ref type="figure" target="#fig_11">7d</ref>.</p><p>Continuing with the methodology, the number of iterations for all the algorithms is set to 500 in each of the 30 runs. In Table <ref type="table" target="#tab_4">4</ref>, the classification results are presented over the two datasets (MonoAmine Oxidase (MAO) and QSAR Biodegradation). It is clear that the HHO-based approach has the best value in mean, the second-best values for in Std, and the first best in the best criteria for maximizing the classification accuracy. Again, the MFO is located in second place in the rank for the mean and best criteria. The convergence curve is presented in Fig. <ref type="figure" target="#fig_9">6b</ref> and<ref type="figure" target="#fig_9">6e</ref> where is possible to see the performance of all the algorithms and how the HHO can find the best solution in a reduced number of iterations. The statistical values are reported in the box plot of Fig. <ref type="figure" target="#fig_11">7b</ref> and<ref type="figure" target="#fig_11">7e</ref>.</p><p>The final part of these experiments requires to set the iterations in 1000, the same criteria of 30 runs is considered. As in the previous experiments the Table <ref type="table" target="#tab_5">5</ref> over the two datasets (MonoAmine Oxidase (MAO) and QSAR Biodegradation), provides evidence that the HHO is the first ranked in terms of the mean, best value and Std for this classification problem. The second position is the MFO that has the second optimal solution in terms of mean and best solution. The performance of the algorithms along the iterative process is shown in Fig. <ref type="figure" target="#fig_9">6c</ref> and<ref type="figure" target="#fig_9">6f</ref>. Here, the HHO has the best performance in terms of accuracy an speed of convergence followed by MFO and SCA. Finally, the box plot Fig. <ref type="figure" target="#fig_11">7c</ref> and 7f statistically supports the results.       </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2.">SVM experiments</head><p>Similar to the previous experiments, in the first experiment, the limit of iterations is set to 100. The experimental results are reported in Table <ref type="table" target="#tab_6">6</ref>. In this experiment, the HHO based on SVM obtains the best mean value, and the best solution, however, it is ranked at third position in the Std. In this case the MFO is the second-ranked in terms of the mean and for the best criteria. For the Std, the MFO is fourth-ranked, and the best mean value is for the SCA that also has the second value on the mean. In terms of the fitness evolution in Fig. <ref type="figure" target="#fig_16">8a</ref> and 8d can be seen that the HHO is the most accurate followed by the MFO and the SSA. The worst algorithm in this case, is the BOA. These facts can also be statistically analyzed from the box plot in Fig. <ref type="figure" target="#fig_17">9a 9d</ref>. The following experiment involves the use of 500 iterations for each of the 30 runs. The values in Table <ref type="table" target="#tab_7">7</ref> confirm that the HHO-SVM approach provides the best mean value, the first rank for the Std and the best criteria in terms of the accuracy. Meanwhile, the MFO is the second-ranked in all the metrics. The worst value is then provided by BOA. The convergence curves are plotted in Fig. <ref type="figure" target="#fig_16">8b</ref> and<ref type="figure" target="#fig_16">8e</ref>, in this figure the HHO converges in a small number of iterations and has a higher fitness. Here the MFO is the second algorithm followed by the DA. The statistical information is presented in the box plot in Fig. <ref type="figure" target="#fig_17">9b</ref> and<ref type="figure" target="#fig_17">9e</ref>.</p><p>The final experiment is performed by using 1000 iterations in each run. In this case, the HHO combined with the SVM is the fist ranked approach for mean, Std and best criteria for maximizing the accuracy. Meanwhile, the second algorithm in the rank is the MFO for the mean and the best criteria. For the Std, the SSA, SCA, GWO, and MFO have the same value 0.00E +00. The plots in Fig. <ref type="figure" target="#fig_16">8c</ref> and 8f provides evidence about the performance of the algorithms along the iterations. In this figure the HHO-SVM outperforms the rest of the algorithms in terms of accuracy and speed of convergence, the second algorithm in this context is the MFO, and the worst is the BOA.</p><p>Regarding the statistical analysis the plot box of Fig. <ref type="figure" target="#fig_17">9c</ref> and<ref type="figure" target="#fig_17">9f</ref>, validate the accuracy and performance of the compared algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.3.">Discussion</head><p>It is noticed that the HHO maximizes accuracy and reduces the number of features. In most cases, when the number of iterations increases the Std values becomes better for both the HHO-SVM and HHO-kNN. The evidence       of this fact is supported by the convergence curves when it is possible to see that the HHO-SVM in Fig. <ref type="figure" target="#fig_16">8</ref> is better in comparison to the convergence curve for HHO-kNN in Fig. <ref type="figure" target="#fig_9">6</ref>. Convergence curve is selected because it represents in a graphical form the relationship between the number of iterations and the fitness function. It indicates the best-performed algorithm from comparison between different approaches, and when increasing the number of iterations it represents a direct correlation. On the other hand, in descriptive statistics, a box plot is a method for graphically depicting groups of numerical data through their quartets. Box plots may also have lines extending vertically from the boxes indicating variability outside the upper and lower quartets, hence the terms "box-andwhisker plot" and "box-and-whisker diagram'. Outlines may be plotted as individual points. Box plots are non-parametric. They display variation in samples of a statistical population without making any assumptions of the underlying statistical distribution. The space between the different parts of the box indicates the degree of dispersion (spread) and skewness in the data and shows outlines. In addition to the points themselves, they allow to visually analyze for various L-estimators, notably the Internationale range, mid hinge, range, and mid-range. Box plots can be drawn either horizontally or vertically. Box plots received their name from the box in the middle. In the experiments, the box plots for SVM are presented in Fig. <ref type="figure" target="#fig_17">9</ref>. Noticeably, the values presented on SVM are better than those of k-NN as shown in Fig. <ref type="figure" target="#fig_11">7</ref> for the HHO.</p><p>In this work, Tables 3, 4 and 5 presents the obtained statistical values of According to the aforementioned analysis, the proposed HHO-SVM approach is achieved a superiority results better than HHO-kNN when the number of iterations increases. The MFO is the second-ranked, meanwhile, the BOA is in the last rank.</p><p>For fair comparison and under the same parameter setting, number of search agents was set 30 for all the experiments. For the second dataset, the number of search agents is chosen 30 from 1055 in contrast for the first dataset, the number of search agents is chosen 30 from 65 as described in data description section. This means, the number of search agents for the second dataset is a major reason for lower accuracy compared with the first dataset with the lower number of search agents. Moreover, the accuracy value directly affected by the nature of datasets, number of search agents and the dimension space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The use of meta-heuristic algorithms and machine learning techniques have increased in the last decades which indicates a tendency in the Cheminformatics field. These techniques are useful tools in drug design studies nowadays. This paper proposed a classification approach called (HHO-SVM) which hybridize a metaheuristic algorithm termed Harris hawks optimization with the support vector machine for the chemical descriptor selection and chemical compound activities. To the best of our knowledge, this is the first work that has addressed the HHO algorithm in the Cheminformatics field. The major function of HHO is adapted to select the significant features, while, the SVM is adjusted to achieve an accurate and fast classification rate over two datasets (MonoAmine Oxidase (MAO) and QSAR Biodegradation). The experimental results revealed that the proposed HHO-SVM approach obtained a superior accuracy compared with well-known algorithms including Particle Swarm Optimization, Simulated Annealing, Dragonfly Algorithm, Butterfly Optimization Algorithm), Moth-Flame Optimization Algorithm, Grey Wolf Optimizer, Sine Cosine Algorithm, Slap Swarm Algorithm over the same data using different evaluation criteria. It is concluded that the proposed HHO-SVM approach achieved high performance compared to the competitor algorithms. Additionally, the proposed HHO-SVM approach can be further upgraded to improve its performance and accuracy. Also, the proposed HHO-SVM approach can be applied to solve actual problems such as prediction of biological activities, construction of QSAR/QSPR models and virtual screening in the Cheminformatics field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: General structure of SVM used for a classification task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The main stages of the original HHO algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Evolution of E parameter along 500 iterations in the HHO HHO algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :Algorithm 3</head><label>43</label><figDesc>Figure 4: Flowchart of the proposed HHO-SVM approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The mapping from monoamine oxidase (MAO) to Simplified Molecular-Input Line Entry System styles.</figDesc><graphic coords="20,95.73,351.26,377.93,232.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Convergence curves using the k-NN and different values of iterations used as stop criteria over the first dataset (MonoAmine Oxidase (MAO)) and the second dataset (QSAR Biodegradation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Comparison of the box plots of the selected algorithms using k-NN and different stop criteria applied over the first dataset (Mono Amine Oxidase (MAO)) and the second dataset (QSAR Biodegradation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>100 iteration on MAO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Convergence curves using the SVM and different values of iterations as stop criteria over the first dataset (MonoAmine Oxidase (MAO)) and the second dataset (QSAR Biodegradation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Comparison of the box plots of the selected algorithms using SVM and different stop criteria applied over the first dataset (Mono Amine Oxidase (MAO)) and the second dataset (QSAR Biodegradation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>:Load the training and test data. Outputs: Assign a class to the test point based on the majority of classes presented in the chosen points calculate accuracy.</figDesc><table /><note><p>Choose the value of k for each point in test data. while (stopping condition is not met) do Find the Euclidean distance for all training data. Store the Euclidean distances in a list and sort it. Choose the first k points . end while Return accuracy</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Meanings of symbols used in the HHO algorithm.</figDesc><table><row><cell>Description</cell></row></table><note><p>1 , r 2 , r 3 , r 4 , r 5 , q</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Parameters setting of the tested algorithms used in the evaluation and comparison.</figDesc><table><row><cell>Algorithm</cell><cell>Parameters</cell><cell>Value</cell></row><row><cell>GWO</cell><cell>R</cell><cell>rand</cell></row><row><cell>DA</cell><cell>D</cell><cell>2</cell></row><row><cell>SCA</cell><cell>A</cell><cell>2</cell></row><row><cell>HHO</cell><cell>Beta</cell><cell>1.5</cell></row><row><cell>SSA</cell><cell>C</cell><cell>rand</cell></row><row><cell>BOA</cell><cell>PS</cell><cell>0.8</cell></row><row><cell>MFO</cell><cell>B and Population size</cell><cell>1 and 50</cell></row><row><cell>PSO</cell><cell>Population size and Velocity</cell><cell>50 ,and 65</cell></row><row><cell>SA</cell><cell>alpha</cell><cell>0.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Mean, Std, Best, Worst and CPU time values obtained by the selected algorithms using the k-NN and a stop criterion of 100 iterations.</figDesc><table><row><cell>Algorithm</cell><cell>Mean</cell><cell>Std</cell><cell>Best</cell><cell>Worst</cell><cell>CPU time</cell></row><row><cell></cell><cell cols="5">First Dataset: MonoAmine Oxidase (MAO)</cell></row><row><cell>GWO</cell><cell cols="3">9.00E+01 1.08E-01 90.231</cell><cell>89.998</cell><cell>0.741</cell></row><row><cell>DA</cell><cell cols="3">9.10E+01 9.13E-01 90.713</cell><cell>88.973</cell><cell>0.936</cell></row><row><cell>SCA</cell><cell cols="3">9.20E+01 3.27E-01 91.999</cell><cell>91.992</cell><cell>0.729</cell></row><row><cell>HHO</cell><cell cols="3">9.69E+01 3.09E-02 96.196</cell><cell>95.583</cell><cell>0.480</cell></row><row><cell>SSA</cell><cell cols="3">9.19E+01 3.86E-01 91.999</cell><cell>90.718</cell><cell>0.761</cell></row><row><cell>BOA</cell><cell cols="3">8.87E+01 4.37E-01 89.034</cell><cell>88.415</cell><cell>0.860</cell></row><row><cell>MFO</cell><cell cols="3">9.45E+01 3.25E-01 94.300</cell><cell>94.300</cell><cell>0.711</cell></row><row><cell>PSO</cell><cell cols="3">8.42E+01 4.40E-01 88.654</cell><cell>87.248</cell><cell>0.811</cell></row><row><cell>SA</cell><cell cols="3">8.57E+01 4.39-E01 88.954</cell><cell>87.785</cell><cell>0.991</cell></row><row><cell></cell><cell cols="4">Second Dataset: QSAR Biodegradation</cell><cell></cell></row><row><cell>GWO</cell><cell>8.43E-01</cell><cell cols="2">8.60E-02 79.008</cell><cell>78.464</cell><cell>0.776</cell></row><row><cell>DA</cell><cell>8.43E-01</cell><cell cols="2">8.30E-03 83.260</cell><cell>81.034</cell><cell>0.983</cell></row><row><cell>SCA</cell><cell>8.51E-01</cell><cell cols="2">8.97E-01 83.090</cell><cell>82.260</cell><cell>0.994</cell></row><row><cell>HHO</cell><cell>8.59E-01</cell><cell cols="2">4.22E-03 84.310</cell><cell>84.205</cell><cell>0.606</cell></row><row><cell>SSA</cell><cell>8.53E-01</cell><cell cols="2">5.19E-02 80.300</cell><cell>79.480</cell><cell>0.687</cell></row><row><cell>BOA</cell><cell>8.24E-01</cell><cell cols="2">2.50E-01 80.019</cell><cell>79.901</cell><cell>0.883</cell></row><row><cell>MFO</cell><cell>8.60E-01</cell><cell cols="2">8.17E-01 82.590</cell><cell>81.990</cell><cell>1.024</cell></row><row><cell>PSO</cell><cell>8.19E-01</cell><cell cols="2">5.95E-01 80.000</cell><cell>77.878</cell><cell>0.994</cell></row><row><cell>SA</cell><cell>8.23E-01</cell><cell cols="2">5.69E-01 80.300</cell><cell>79.930</cell><cell>1.306</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Mean, Std, Best, Worst and CPU time values obtained by the selected algorithms using the k-NN and a stop criterion of 500 iterations.</figDesc><table><row><cell>Algorithm</cell><cell>Mean</cell><cell>Std</cell><cell>Best</cell><cell>Worst</cell><cell>CPU time</cell></row><row><cell></cell><cell cols="5">First Dataset: MonoAmine Oxidase (MAO)</cell></row><row><cell>GWO</cell><cell cols="3">9.00E+01 1.02E-01 91.999</cell><cell>89.379</cell><cell>0.921</cell></row><row><cell>DA</cell><cell cols="3">9.16E+01 8.21E-01 94.914</cell><cell>90.018</cell><cell>1.986</cell></row><row><cell>SCA</cell><cell cols="3">9.20E+01 2.22E-01 91.999</cell><cell>91.994</cell><cell>1.069</cell></row><row><cell>HHO</cell><cell cols="3">9.70E+01 3.59E-03 96.999</cell><cell>96.866</cell><cell>0.710</cell></row><row><cell>SSA</cell><cell cols="3">9.20E+01 2.06E-01 92.231</cell><cell>91.998</cell><cell>0.961</cell></row><row><cell>BOA</cell><cell cols="3">8.81E+01 7.47E-01 89.292</cell><cell>86.932</cell><cell>1.461</cell></row><row><cell>MFO</cell><cell cols="3">9.60E+01 3.20E-01 95.707</cell><cell>95.707</cell><cell>1.091</cell></row><row><cell>PSO</cell><cell cols="3">8.77E+01 7.50E-01 88.965</cell><cell>86.541</cell><cell>1.691</cell></row><row><cell>SA</cell><cell cols="3">8.79E+01 7.49E-01 88.993</cell><cell>86.671</cell><cell>1.960</cell></row><row><cell></cell><cell cols="4">Second Dataset: QSAR Biodegradation</cell><cell></cell></row><row><cell>GWO</cell><cell>8.39E-01</cell><cell cols="2">7.69E-02 83.016</cell><cell>81.249</cell><cell>0.870</cell></row><row><cell>DA</cell><cell>8.45E-01</cell><cell cols="2">7.30E-03 82.925</cell><cell>81.810</cell><cell>2.083</cell></row><row><cell>SCA</cell><cell>8.43E-01</cell><cell cols="2">7.20E-01 84.300</cell><cell>83.159</cell><cell>2.193</cell></row><row><cell>HHO</cell><cell>8.60E-01</cell><cell cols="2">3.70E-03 84.671</cell><cell>84.531</cell><cell>0.615</cell></row><row><cell>SSA</cell><cell>8.49E-01</cell><cell cols="2">1.01E-02 82.590</cell><cell>82.060</cell><cell>0.881</cell></row><row><cell>BOA</cell><cell>8.25E-01</cell><cell cols="2">3.51E-02 83.201</cell><cell>79.850</cell><cell>1.083</cell></row><row><cell>MFO</cell><cell>8.59E-01</cell><cell cols="2">5.13E-01 82.208</cell><cell>81.080</cell><cell>2.125</cell></row><row><cell>PSO</cell><cell>8.25E-01</cell><cell cols="2">1.09E-01 81.060</cell><cell>80.960</cell><cell>2.013</cell></row><row><cell>SA</cell><cell>8.30E-01</cell><cell cols="2">6.20E-01 79.802</cell><cell>78.930</cell><cell>2.501</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Mean, Std, Best, Worst CPU time values obtained by the selected algorithms using the k-NN and a stop criterion of 1000 iterations.</figDesc><table><row><cell>Algorithm</cell><cell>Mean</cell><cell>Std</cell><cell>Best</cell><cell>Worst</cell><cell>CPU time</cell></row><row><cell></cell><cell cols="5">First Dataset: MonoAmine Oxidase (MAO)</cell></row><row><cell>GWO</cell><cell cols="3">9.20E+01 6.94E-02 92.003</cell><cell>91.999</cell><cell>1.521</cell></row><row><cell>DA</cell><cell cols="3">9.23E+01 1.27E+00 92.532</cell><cell>90.253</cell><cell>1.986</cell></row><row><cell>SCA</cell><cell cols="3">9.60E+01 2.16E-01 95.002</cell><cell>94.999</cell><cell>1.268</cell></row><row><cell>HHO</cell><cell cols="3">9.70E+01 3.09E-03 97.599</cell><cell>96.884</cell><cell>1.092</cell></row><row><cell>SSA</cell><cell cols="3">9.40E+01 1.05E-01 94.001</cell><cell>93.530</cell><cell>1.671</cell></row><row><cell>BOA</cell><cell cols="3">8.82E+01 7.26E-01 88.077</cell><cell>86.924</cell><cell>1.331</cell></row><row><cell>MFO</cell><cell cols="3">9.83E+01 3.16E-01 96.285</cell><cell>95.981</cell><cell>1.271</cell></row><row><cell>PSO</cell><cell cols="3">8.77E+01 7.30E-01 87.987</cell><cell>86.472</cell><cell>1.481</cell></row><row><cell>SA</cell><cell cols="3">8.79E+01 7.29E-01 87.990</cell><cell>86.547</cell><cell>1.961</cell></row><row><cell></cell><cell cols="4">Second Dataset: QSAR Biodegradation</cell><cell></cell></row><row><cell>GWO</cell><cell>8.40E-01</cell><cell cols="2">4.01E-02 83.070</cell><cell>82.128</cell><cell>0.917</cell></row><row><cell>DA</cell><cell>8.40E-01</cell><cell cols="2">4.01E-02 80.918</cell><cell>78.237</cell><cell>3.393</cell></row><row><cell>SCA</cell><cell>8.40E-01</cell><cell cols="2">5.53E-01 83.805</cell><cell>81.429</cell><cell>3.183</cell></row><row><cell>HHO</cell><cell>8.62E-01</cell><cell cols="2">2.39E-03 84.523</cell><cell>82.584</cell><cell>0.918</cell></row><row><cell>SSA</cell><cell>8.45E-01</cell><cell cols="2">3.98E-03 82.581</cell><cell>80.645</cell><cell>0.987</cell></row><row><cell>BOA</cell><cell>8.33E-01</cell><cell cols="2">3.19E-02 78.061</cell><cell>77.804</cell><cell>1.985</cell></row><row><cell>MFO</cell><cell>8.65E-01</cell><cell cols="2">5.33E-01 84.346</cell><cell>81.046</cell><cell>3.141</cell></row><row><cell>PSO</cell><cell>8.28E-01</cell><cell cols="2">4.39E-01 75.297</cell><cell>73.397</cell><cell>3.731</cell></row><row><cell>SA</cell><cell>8.35E-01</cell><cell cols="2">6.65E-01 80.802</cell><cell>78.740</cell><cell>4.223</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Mean, Std, Best, Worst and CPU time values obtained by the selected algorithms using the SVM and a stop criterion of 100 iterations.</figDesc><table><row><cell>Algorithm</cell><cell>Mean</cell><cell>Std</cell><cell>Best</cell><cell>Worst</cell><cell>CPU time</cell></row><row><cell></cell><cell cols="5">First Dataset: MonoAmine Oxidase (MAO)</cell></row><row><cell>GWO</cell><cell cols="3">8.97E+01 2.92E-01 89.705</cell><cell>88.001</cell><cell>0.631</cell></row><row><cell>DA</cell><cell cols="3">9.43E+01 9.87E-01 91.058</cell><cell>90.647</cell><cell>0.836</cell></row><row><cell>SCA</cell><cell cols="3">9.12E+01 1.46E-01 91.882</cell><cell>90.176</cell><cell>0.669</cell></row><row><cell>HHO</cell><cell cols="3">9.74E+01 8.71E-02 96.597</cell><cell>94.464</cell><cell>0.470</cell></row><row><cell>SSA</cell><cell cols="3">9.12E+01 2.01E-01 91.176</cell><cell>90.764</cell><cell>0.671</cell></row><row><cell>BOA</cell><cell cols="3">9.12E+01 1.25E+00 88.176</cell><cell>86.176</cell><cell>0.750</cell></row><row><cell>MFO</cell><cell cols="3">9.41E+01 1.45E-01 94.117</cell><cell>94.117</cell><cell>0.671</cell></row><row><cell>PSO</cell><cell cols="3">9.11E+01 1.29E+00 88.065</cell><cell>86.014</cell><cell>0.781</cell></row><row><cell>SA</cell><cell cols="3">9.10E+01 1.26E+00 88.186</cell><cell>86.125</cell><cell>0.961</cell></row><row><cell></cell><cell cols="4">Second Dataset: QSAR Biodegradation</cell><cell></cell></row><row><cell>GWO</cell><cell>8.48E-01</cell><cell cols="2">4.77E-03 82.809</cell><cell>80.434</cell><cell>0.676</cell></row><row><cell>DA</cell><cell>8.47E-01</cell><cell cols="2">7.27E-03 82.762</cell><cell>79.234</cell><cell>0.883</cell></row><row><cell>SCA</cell><cell>8.56E-01</cell><cell cols="2">3.07E-03 83.595</cell><cell>80.007</cell><cell>0.893</cell></row><row><cell>HHO</cell><cell>8.64E-01</cell><cell cols="2">9.23E-04 84.512</cell><cell>83.200</cell><cell>0.576</cell></row><row><cell>SSA</cell><cell>8.58E-01</cell><cell cols="2">5.08E-03 81.561</cell><cell>79.484</cell><cell>0.587</cell></row><row><cell>BOA</cell><cell>8.29E-01</cell><cell cols="2">4.30E-05 82.519</cell><cell>81.513</cell><cell>0.783</cell></row><row><cell>MFO</cell><cell>8.67E-01</cell><cell cols="2">3.11E-03 84.294</cell><cell>80.694</cell><cell>0.924</cell></row><row><cell>PSO</cell><cell>8.22E-01</cell><cell cols="2">6.45E-01 78.578</cell><cell>74.178</cell><cell>0.893</cell></row><row><cell>SA</cell><cell>8.27E-01</cell><cell cols="2">6.69E-01 82.032</cell><cell>79.732</cell><cell>1.106</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7</head><label>7</label><figDesc>Mean, Std, Best, Worst and CPU time values obtained by the selected algorithms using the SVM and a stop criterion of 500 iterations.</figDesc><table><row><cell>Algorithm</cell><cell>Mean</cell><cell>Std</cell><cell>Best</cell><cell>Worst</cell><cell>CPU time</cell></row><row><cell></cell><cell cols="5">First Dataset: MonoAmine Oxidase (MAO)</cell></row><row><cell>GWO</cell><cell cols="3">8.97E+01 2.90E-01 89.705</cell><cell>89.705</cell><cell>0.831</cell></row><row><cell>DA</cell><cell cols="3">9.32E+01 7.20E-01 92.117</cell><cell>91.647</cell><cell>1.036</cell></row><row><cell>SCA</cell><cell cols="3">9.11E+01 7.51E-02 92.647</cell><cell>89.705</cell><cell>0.969</cell></row><row><cell>HHO</cell><cell cols="3">9.67E+01 3.47E-03 97.576</cell><cell>95.676</cell><cell>0.690</cell></row><row><cell>SSA</cell><cell cols="3">9.12E+01 1.99E-01 92.176</cell><cell>91.764</cell><cell>0.871</cell></row><row><cell>BOA</cell><cell cols="3">9.26E+01 1.24E+00 88.047</cell><cell>87.176</cell><cell>1.050</cell></row><row><cell>MFO</cell><cell cols="3">9.41E+01 7.49E-01 95.117</cell><cell>92.117</cell><cell>0.961</cell></row><row><cell>PSO</cell><cell cols="3">9.23E+01 1.29E+00 88.046</cell><cell>87.166</cell><cell>1.081</cell></row><row><cell>SA</cell><cell cols="3">9.24E+01 1.26E+00 88.046</cell><cell>87.169</cell><cell>1.161</cell></row><row><cell></cell><cell cols="4">Second Dataset: QSAR Biodegradation</cell><cell></cell></row><row><cell>GWO</cell><cell>8.41E-01</cell><cell cols="2">7.61E-04 84.656</cell><cell>83.049</cell><cell>0.770</cell></row><row><cell>DA</cell><cell>8.54E-01</cell><cell cols="2">7.03E-03 83.525</cell><cell>80.818</cell><cell>1.283</cell></row><row><cell>SCA</cell><cell>8.47E-01</cell><cell cols="2">5.42E-03 83.480</cell><cell>80.089</cell><cell>1.093</cell></row><row><cell>HHO</cell><cell>8.67E-01</cell><cell cols="2">4.60E-04 84.871</cell><cell>83.900</cell><cell>00.716</cell></row><row><cell>SSA</cell><cell>8.54E-01</cell><cell cols="2">4.16E-02 84.398</cell><cell>80.560</cell><cell>0.781</cell></row><row><cell>BOA</cell><cell>8.30E-01</cell><cell cols="2">1.61E-02 81.809</cell><cell>78.855</cell><cell>0.983</cell></row><row><cell>MFO</cell><cell>8.61E-01</cell><cell cols="2">8.32E-03 82.383</cell><cell>78.083</cell><cell>1.025</cell></row><row><cell>PSO</cell><cell>8.30E-01</cell><cell cols="2">1.07E-01 82.263</cell><cell>78.963</cell><cell>1.013</cell></row><row><cell>SA</cell><cell>8.35E-01</cell><cell cols="2">6.72E-01 80.420</cell><cell>77.830</cell><cell>2.001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8</head><label>8</label><figDesc>Mean, Std, Best, Worst and CPU time values obtained by the selected algorithms using the SVM and a stop criterion of 1000 iterations. in terms of mean, Std, best, worst and CPU time values on over 30 runs using k-NN classifier. Also, Tables 6, 7 and 8 illustrates the obtained statistical values of the competitor algorithms in terms of mean, Std, best, worst and CPU time values on over 30 runs using SVM classifier.</figDesc><table><row><cell>Algorithm</cell><cell>Mean</cell><cell>Std</cell><cell>Best</cell><cell>Worst</cell><cell>CPU time</cell></row><row><cell></cell><cell cols="5">First Dataset: MonoAmine Oxidase (MAO)</cell></row><row><cell>GWO</cell><cell cols="3">8.97E+01 2.70E-01 89.705</cell><cell>89.705</cell><cell>1.121</cell></row><row><cell>DA</cell><cell cols="3">9.41E+01 2.08E-01 91.088</cell><cell>90.647</cell><cell>1.036</cell></row><row><cell>SCA</cell><cell cols="3">9.12E+01 7.90E-02 92.647</cell><cell>91.176</cell><cell>1.068</cell></row><row><cell>HHO</cell><cell cols="3">9.76E+01 2.53E-03 97.583</cell><cell>97.250</cell><cell>0.992</cell></row><row><cell>SSA</cell><cell cols="3">9.26E+01 1.07E-01 91.647</cell><cell>91.235</cell><cell>1.071</cell></row><row><cell>BOA</cell><cell cols="3">8.19E+01 1.04E+00 89.117</cell><cell>88.176</cell><cell>1.231</cell></row><row><cell>MFO</cell><cell cols="3">9.12E+01 0.00E+00 96.176</cell><cell>90.176</cell><cell>1.071</cell></row><row><cell>PSO</cell><cell cols="3">8.17E+01 1.06E+00 88.981</cell><cell>87.981</cell><cell>1.481</cell></row><row><cell>SA</cell><cell cols="3">8.18E+01 1.05E+00 89.012</cell><cell>88.014</cell><cell>1.861</cell></row><row><cell></cell><cell cols="4">Second Dataset: QSAR Biodegradation</cell><cell></cell></row><row><cell>GWO</cell><cell>8.57E-01</cell><cell cols="2">8.78E-05 83.070</cell><cell>81.128</cell><cell>0.917</cell></row><row><cell>DA</cell><cell>8.45E-01</cell><cell cols="2">4.11E-03 83.318</cell><cell>80.237</cell><cell>3.393</cell></row><row><cell>SCA</cell><cell>8.43E-01</cell><cell cols="2">8.63E-03 83.025</cell><cell>80.429</cell><cell>3.183</cell></row><row><cell>HHO</cell><cell>8.68E-01</cell><cell cols="2">2.40E-05 85.023</cell><cell>83.700</cell><cell>0.918</cell></row><row><cell>SSA</cell><cell>8.50E-01</cell><cell cols="2">3.20E-03 82.981</cell><cell>80.645</cell><cell>0.987</cell></row><row><cell>BOA</cell><cell>8.30E-01</cell><cell cols="2">3.23E-03 82.361</cell><cell>79.804</cell><cell>1.985</cell></row><row><cell>MFO</cell><cell>8.70E-01</cell><cell cols="2">5.43E-03 81.946</cell><cell>78.646</cell><cell>3.141</cell></row><row><cell>PSO</cell><cell>8.34E-01</cell><cell cols="2">4.46E-01 79.897</cell><cell>75.397</cell><cell>3.731</cell></row><row><cell>SA</cell><cell>8.40E-01</cell><cell cols="2">6.77E-01 81.942</cell><cell>79.840</cell><cell>4.223</cell></row><row><cell cols="2">the competitor algorithms</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Great thankful go to Dr. Ali Asghar Heidari, School of computing, National University of Singapore, for his valuable assistance during this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>All persons who have made substantial contributions to the work reported in the manuscript (e.g., technical help, writing and editing assistance, general support), but who do not meet the criteria for authorship, are named in the Acknowledgements and have given us their written permission to be named. If we have not included an Acknowledgements, then that indicates that we have not received substantial contributions from non-authors.</p><p>This statement is signed by all the authors (a photocopy of this form may be used if there are more than 10 authors):</p><p>Author's name (typed)</p><p>Author's signature Date</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of interest</head><p>The authors declare that there is no conflict of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest</head><p>The authors have declared that there is no conflict of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHORSHIP STATEMENT Manuscript title: A Novel Hybrid Harris Hawks Optimization and Support Vector Machines for Drug Design and Discovery</head><p>All persons who meet authorship criteria are listed as authors, and all authors certify that they have participated sufficiently in the work to take public responsibility for the content, including participation in the concept, design, analysis, writing, or revision of the manuscript. Furthermore, each author certifies that this material or similar material has not been and will not be submitted to or published in any other publication before its appearance in the Hong Kong Journal of Occupational Therapy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authorship contributions</head><p>Please indicate the specific contributions made by each author (list the authors' initials followed by their surnames, e.g., Y.L. Cheung). The name of each author must appear at least once in each of the three categories below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category 3</head><p>Approval of the version of the manuscript to be published (the names of all authors must be listed): Essam H. Houssein, Mosa E. Hosney, Diego Oliva, M. Hassaballah, Waleed M. Mohamed.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A study on cheminformatics and its applications on modern drug discovery</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Begam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1264" to="1275" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sequence-based design of bioactive small molecules that target precursor micrornas</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Velagapudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Disney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Chemical Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="291" to="305" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Machine-learning approaches in drug discovery: methods and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lavecchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discovery Today</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="318" to="331" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Chemical product design: Advances in and proposed directions for research and teaching</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Chemical Engineering</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computer aided drug design: success and limitations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hassan Baig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Mohammad</forename><surname>Ashraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Provazník</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Pharmaceutical Design</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="572" to="581" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Advantages of relative versus absolute data for the development of quantitative structure-activity relationship classification models</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gomez-Nieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2776" to="2788" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computational protein-ligand docking and virtual drug screening with the autodock suite</title>
		<author>
			<persName><forename type="first">S</forename><surname>Forli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Pique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Goodsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Protocols</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="905" to="917" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational approaches in target identification and drug discovery, Computational and Structural</title>
		<author>
			<persName><forename type="first">T</forename><surname>Katsila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Spyroulias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Patrinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Matsoukas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biotechnology Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="177" to="184" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computer aided chemical product designprocapd and tailor-made blended products</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kalakul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Intikhab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elbashir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="37" to="55" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Therapeutic targets: progress of their exploration and investigation of their characteristics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pharmacological Reviews</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="279" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine learning in chemoinformatics and drug discovery</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Rensi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Torng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discovery Today</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1538" to="1546" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Drugminer: comparative analysis of machine learning algorithms for prediction of potential druggable proteins</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ferdousi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Razzaghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Safdari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ebrahimie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discovery Today</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="718" to="724" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Computational methods of feature selection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A binary whale optimization algorithm with hyperbolic tangent fitness function for feature selection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hussien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Houssein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Intelligent Computing and Information Systems (ICICIS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="166" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Swarming behaviour of salps algorithm for predicting chemical compound activities</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hussien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Houssein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Intelligent Computing and Information Systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="315" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An enhanced harmony search based algorithm for feature selection: Applications in epileptic seizure detection and prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zainuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="143" to="162" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Hashim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Houssein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Mabrouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Al-Atabany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Henry gas solubility optimization: A novel physics-based algorithm</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="646" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Novel artificial bee colony based feature selection method for filtering redundant information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="868" to="885" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">S-shaped binary whale optimization algorithm for feature selection, in: Recent trends in signal and image processing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hussien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Houssein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A feature selection method based on modified binary coded ant colony optimization algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="248" to="258" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Harris hawks optimization: Algorithm and applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="849" to="872" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Symposium on Micro Machine and Human Science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1053" to="1073" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Butterfly algorithm with levy flights for global optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Signal Processing, Computing and Control</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="220" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="228" to="249" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sca: a sine cosine algorithm for solving optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="120" to="133" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Salp swarm algorithm: A bio-inspired optimizer for engineering design problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="163" to="191" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Structure-based drug design</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="issue">6604</biblScope>
			<biblScope unit="page" from="23" to="35" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pymol and inkscape bridge the data and the data visualization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Filipek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structure</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2041" to="2042" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Comprehensive evaluation of ten docking programs on a diverse set of proteinligand complexes: the prediction accuracy of sampling power and scoring power</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Chemistry Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="12964" to="12975" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust chemical product design via fuzzy optimisation approach</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Chemmangattuvalappil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="186" to="202" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fipsdock: a new molecular docking technique driven by fully informed swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="75" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving data clustering using fuzzy logic and pso algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Tabrizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Iranian Conference on Electrical Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="784" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pydescriptor: A new pymol plugin for calculating thousands of easily understandable molecular descriptors</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Masand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rastija</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics and Intelligent Laboratory Systems</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="12" to="18" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A comparison of machine learning techniques for detection of drug target articles</title>
		<author>
			<persName><forename type="first">R</forename><surname>Danger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Segura-Bedmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="902" to="913" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Gertrudes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Maltarollo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Honorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Da</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning techniques and drug design</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="4289" to="4297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Machine learning methods in chemoinformatics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Computational Molecular Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="468" to="481" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A drug candidate design environment using evolutionary computation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wikel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bonabeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="591" to="603" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bacteria foraging optimization for drug design</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C W</forename><surname>Peh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Science and Its Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="322" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multi-objective optimization methods in drug design</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discovery Today: Technologies</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="427" to="435" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A survey on semi-supervised feature selection methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sheikhpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sarram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gharaghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A Z</forename><surname>Chahooki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="141" to="158" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Feature selection in machine learning: A new perspective</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">300</biblScope>
			<biblScope unit="page" from="70" to="79" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Two hybrid wrapper-filter feature selection algorithms applied to high-dimensional microarray experiments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Apolloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Leguizamón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="922" to="932" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Feature selection: A data perspective</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Trevino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="94" to="106" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Feature selection using forest optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghaemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-R</forename><surname>Feizi-Derakhshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="121" to="129" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hybrid whale optimization algorithm with simulated annealing for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">260</biblScope>
			<biblScope unit="page" from="302" to="312" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Basic validation procedures for regression models in qsar and qspr studies: theory and application</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiralj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Brazilian Chemical Society</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="770" to="787" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Honório</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>De Lima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Quiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Molfetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial neural networks and the study of the psychoactivity of cannabinoid compounds</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="632" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The application of discriminant analysis and machine learning methods as tools to identify and classify compounds with potential as transdermal enhancers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Pharmaceutical Sciences</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="116" to="127" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A gene selection method for microarray data based on binary pso encoding gene-to-class sensitivity information</title>
		<author>
			<persName><forename type="first">F</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Computational Biology and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="96" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Support vector machine classification and regression prioritize different structural features for binary compound activity and potency value prediction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rodríguez-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bajorath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS Omega</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6371" to="6379" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A survey on feature selection methods</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chandrashekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sahin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Open babel: An open chemical toolbox</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>O'boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Banck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vandermeersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hutchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="48" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Descriptors and their selection methods in qsar analysis: paradigm for drug design</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">U</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discovery Today</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1291" to="1302" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Essam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Houssein Essam</surname></persName>
		</author>
		<author>
			<persName><surname>Houssein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-11-14">14 Nov 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Mosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hosney Mosa</surname></persName>
		</author>
		<author>
			<persName><surname>Hosney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-11-14">14 Nov 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Diego</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019-11-14">14 Nov 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Waleed</forename><forename type="middle">M</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waleed</forename><forename type="middle">M</forename><surname>Mohamed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-11-14">14 Nov 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Hassaballah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hassaballah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-11-14">14 Nov 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
