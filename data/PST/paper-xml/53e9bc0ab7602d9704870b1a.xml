<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bagging Gradient-Boosted Trees for High Precision, Low Variance Ranking Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yasser</forename><surname>Ganjisaffar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information &amp; Computer Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine Irvine</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
							<email>rcaruana@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<postCode>98052</postCode>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cristina</forename><forename type="middle">Videira</forename><surname>Lopes</surname></persName>
							<email>lopes@ics.uci.edu</email>
							<affiliation key="aff2">
								<orgName type="department">School of Information &amp; Computer Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine Irvine</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bagging Gradient-Boosted Trees for High Precision, Low Variance Ranking Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CBCDBDBF095691CBBB9B7A51E95731A0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Systems]: Information Search and Retrieval; H.4.m [Information Systems]: Miscellaneous-Machine Learning Algorithms</term>
					<term>Experimentation Learning-to-rank</term>
					<term>Tree Ensembles</term>
					<term>Bagging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent studies have shown that boosting provides excellent predictive performance across a wide variety of tasks. In Learning-to-rank, boosted models such as RankBoost and LambdaMART have been shown to be among the best performing learning methods based on evaluations on public data sets. In this paper, we show how the combination of bagging as a variance reduction technique and boosting as a bias reduction technique can result in very high precision and low variance ranking models. We perform thousands of parameter tuning experiments for LambdaMART to achieve a high precision boosting model. Then we show that a bagged ensemble of such LambdaMART boosted models results in higher accuracy ranking models while also reducing variance as much as 50%. We report our results on three public learning-to-rank data sets using four metrics. Bagged LamdbaMART outperforms all previously reported results on ten of the twelve comparisons, and bagged LambdaMART outperforms non-bagged LambdaMART on all twelve comparisons. For example, wrapping bagging around LambdaMART increases NDCG@1 from 0.4137 to 0.4200 on the MQ2007 data set; the best prior results in the literature for this data set is 0.4134 by RankBoost.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The general problem of ranking, and in particular ranking of web search results, has received significant attention. Given the large amount of training data now available it has become possible to learn effective ranking models using machine learning. Methods that learn how to combine predefined features for ranking are called "Learning-to-rank" methods. A large number of learning-to-rank algorithms have been proposed, such as <ref type="bibr" target="#b8">[8,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b30">30]</ref> (see <ref type="bibr" target="#b22">[22]</ref> for a more complete list).</p><p>Recent studies have shown that tree models combined with ensemble techniques provide excellent predictive performance. In the recent Yahoo! learning-to-rank challenge <ref type="bibr" target="#b10">[10]</ref>, the top ranked teams all used tree ensemble methods. The winning entry in this competition used an ensemble of LambdaMART <ref type="bibr" target="#b32">[32]</ref> models.</p><p>In this work, we study the effectiveness of bagged ensembles of ranking models to achieve higher prediction accuracy. We train multiple independent ranking models on different samples of the training data and combine the outputs of these models to get improved prediction accuracy. In our experiments, we use LambdaMART, which is a boosted ensemble of trees, as the baseline model. Thus we are forming bagged ensembles of boosted ensembles of trees. Our approach is motivated by Breiman's Bagging <ref type="bibr" target="#b3">[3]</ref>, so we call this method BL-MART for Bagged LambdaMART. Since sub-models are independent they can be trained in parallel and the training time is not more than training time of a single LambdaMART model. In fact, because we perform sampling without replacement, each of the LambdaMART models is trained on a smaller training set and therefore the training time is less than training a single LambdaMART model on the full train set.</p><p>We summarize the main contributions of this paper as follows: (a) We perform thousands of parameter tuning experiments for the LambdaMART algorithm to find near optimal parameter configurations for it and also study its sensitiveness to its parameters (section 3.4). (b) We show that adding randomness during the training of LambdaMART models can improve the accuracy of these models. We introduce randomness by sub-sampling queries that are available to the algorithm during each of the training iterations. We also use feature sampling as another method for increasing randomness of the algorithm (section 3.3). (c) We study the effectiveness of bagging ensembles of Lamb-daMART models to both increase the prediction accuracy of the ranking model and reduce the model variance. (d) We show that bagged ensembles of overfitted base-level models (overfitted boosted tree models) result in higher prediction accuracy than bagging optimally generated baselevel models and we explain why this happens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND AND RELATED WORK</head><p>LambdaMART <ref type="bibr" target="#b32">[32]</ref> is a ranking algorithm that uses Gradient boosting <ref type="bibr" target="#b15">[15]</ref> to optimize a ranking cost function similar to the LambdaRank <ref type="bibr">[7]</ref> cost function. Readers can refer to <ref type="bibr" target="#b6">[6]</ref> for details of this algorithm. However, since it is our base model, we briefly describe some of the important concepts that are referenced in the reminder of this paper.</p><p>Gradient boosting produces an ensemble of weak models (typically regression trees) that together form a strong model. The ensemble is built in a stage-wise process by performing gradient descent in function space. The final model maps an input feature vector x ∈ R d to a score F (x) ∈ R:</p><formula xml:id="formula_0">Fm(x) = Fm-1(x) + γmhm(x)</formula><p>where each hi is a function modeled by a single regression tree and the γi ∈ R is the weight associated with the i-th regression tree. Both the hi and the γi are learned during training. A given tree hi maps a given feature vector x to a real value by passing x down the tree, where the path (left or right) at a given node is determined by the value of a particular feature in the feature vector and the output is a fixed value associated with the leaf that is reached by following the path.</p><p>Gradient boosting usually requires regularization to avoid overfitting. In an overfitted model, the model's generalization ability degrades because of fitting too closely to the training data. Different kinds of regularization techniques can be used to reduce overfitting in boosted trees. One common regularization parameter is the number of trees in the model, M . Increasing M reduces the error on training set, but setting it too high often leads to overfitting. An optimal value of M often is selected by monitoring prediction error on a separate validation data set.</p><p>Another regularization approach is to control the complexity of the individual trees via a number of user-chosen parameters. For example, Max Number of Leaves per tree limits the size of individual trees thus preventing them from overfitting to the training data. Another user-set parameter for controlling tree size is the minimum number of observations allowed in leaves. This parameter is used in the tree building process by ignoring splits that lead to nodes containing fewer than this number of training set observations. This prevents adding leaves that contain statistically small samples of training data.</p><p>Another important regularization technique is shrinkage which modifies the boosting update rule as follows:</p><formula xml:id="formula_1">Fm(x) = Fm-1(x) + ηγmhm(x), 0 &lt; η ≤ 1,</formula><p>where parameter η is called the learning rate. Small learning rates can dramatically improve a model's generalization ability over gradient boosting without shrinkage (η = 1), however they result in more boosting iterations and therefore larger models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bias-Variance Decomposition of Error</head><p>According to the bias-variance decomposition of error <ref type="bibr" target="#b16">[16]</ref>, the squared error of a single example x can be decomposed into the sum of three non-negative terms: noise, bias, and variance. The first term, Noise, is the irreducible error which cannot be avoided regardless of the learning algorithm. In learning-to-rank domain, it can be interpreted as the noise in relevance judgments of query-url pairs. The second term, Bias, measures how closely the average prediction of the learning algorithm (considering all possible training sets of a fixed size) matches the optimal prediction (the Bayes rate prediction). Finally, the Variance of an algorithm is how much the algorithm's prediction fluctuates over different possible training sets of a given size.</p><p>Ensemble methods such as Gradient Boosting <ref type="bibr" target="#b15">[15]</ref> reduce bias by increasing the expressive power of the base learner and by forcing learning to attend to training cases that consistently are mispredicted. Because boosting combines the predictions of multiple trees it also can reduce variance, but boosted trees are so powerful that regularization usually is needed to prevent overfitting. Other ensemble methods such as Bagging <ref type="bibr" target="#b3">[3]</ref> mainly reduce variance by averaging outputs of several models trained on different samples of training data. Because bagging usually does not significantly increase expressive power and often yields large reductions in variance, it is a relatively safe procedure that usually does not require regularization or careful parameter tuning. In fact, bagging can be used as an effective regularization method when wrapped around other high-variance learning methods that are prone to overfitting such as boosting. There has been attempts for combining bias and variance reduction techniques for classification <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b29">29]</ref> and regression <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b27">27]</ref> problems. In this work, we combine bagging and boosting for improved learning-to-rank.</p><p>Similar to us, BagBoo <ref type="bibr" target="#b23">[23]</ref> wraps Bagging around Boosting for improved learning-to-rank. However, there are several fundamental differences that make our work different from BagBoo. The most important difference is the size of the final model. On two public data sets that BagBoo reports its results, our BL-MART models are approximately 250 times smaller and also more accurate on most metrics (section 4). BagBoo is training more than a million trees on these data sets which makes its size infeasible for real time applications. In addition, the boosting algorithm that is used in BagBoo is a pointwise method, while BL-MART uses LambdaMART for boosting which is a listwise algorithm. Pointwise methods such as <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b21">21]</ref> do not exploit relative rank information between documents, instead attempting to directly create a scoring function. In contrast, listwise methods such as <ref type="bibr">[7,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b30">30]</ref> use lists of ranked documents as instances during training, and learn a ranking model by minimizing a listwise loss function. In addition, we also show that bagging boosted ensembles that are mildy overfitted to their training data gives better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data sets</head><p>For our experiments we work with three public data sets: TD2004 and MQ2007 from LETOR data sets <ref type="bibr" target="#b24">[24]</ref> and the recently published MSLR-WEB10K data set from Microsoft Research <ref type="bibr" target="#b1">[1]</ref>. Table <ref type="table" target="#tab_1">1</ref> summarizes the properties of these data sets. The TD2004 and MQ2007 data sets have been used many times for evaluating new learning-to-rank algorithms. This provides a baseline for comparing our method with other state-of-the-art learning-to-rank algorithms. MSLR-WEB10K is a large data set which is more similar to commercial search data sets. Because it is larger it should provide results that are more reliable. All three data sets are pre-folded and come with evaluation scripts that allow fair comparison of different ranking algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Metrics</head><p>For model comparison we use two information retrieval metrics: Normalized Discounted Cumulative Gain (NDCG) <ref type="bibr" target="#b19">[19]</ref> and Mean Average Precision (MAP) <ref type="bibr" target="#b2">[2]</ref>. NDCG@k is a measure for evaluating top k positions of a ranked list using multiple levels of relevance judgment. It is defined as follows,</p><formula xml:id="formula_2">N DCG@k = N -1 k j=1 g(rj)d(j),</formula><p>where N -1 is a normalization factor chosen so that a perfect ordering of the results will receive the score of one; rj denotes the relevance level of the document ranked at the j-th position; g(rj) is a gain function:</p><formula xml:id="formula_3">g(rj) = 2 r j -1;</formula><p>and d(j) denotes a discount function. The evaluation scripts that come with the three data sets use the following discount function:</p><formula xml:id="formula_4">d(j) = 1 for j = 1,2 1 log 2 (j)</formula><p>otherwise.</p><p>We use the same scripts for fair comparison of our final models with other algorithms. However in our implementation of the LambdaMART algorithm and in all of our training and parameter tuning experiments, we optimize for the following discount function which places stronger emphasis on higher positions:</p><formula xml:id="formula_5">d(j) = 1 log 2 (1 + j)</formula><p>Also, based on whether we assign NDCG values of zero or one to a query where all of the documents are assigned nonrelevant labels, the scale of NDCG values will change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Randomization for LambdaMART</head><p>In <ref type="bibr" target="#b14">[14]</ref>, Friedman proposed a modification of the gradient boosting algorithm which was motivated by Breiman's bagging method. He proposed that at each iteration of the algorithm, a base learner should be fit on a sub-sample of the training set drawn at random without replacement. Friedman observed a substantial improvement in gradient boosting's accuracy with this modification. Sub-sample size is some constant fraction s of the size of the training set. When s = 1, the algorithm is deterministic. Smaller values of s introduce randomness into the algorithm and help prevent overfitting, acting as a kind of regularization. The algorithm also becomes faster, because regression trees have to be fit to smaller data sets at each iteration.</p><p>Also similar to Random Forests <ref type="bibr" target="#b4">[4]</ref>, more randomness can be introduced by sampling features that are available to the algorithm on each tree split. On each split, the algorithm In our experiments, we add both observation sub-sampling and feature sampling as two new parameters that need to be tuned for the LambdaMART algorithm. These parameters can take values between 0 and 1, where 1 means no sampling and values less than 1 introduce sampling randomness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Parameter Tuning</head><p>The original LambdaMART algorithm has three parameters that need to be tuned to achieve the best results: "Max number of leaves", "Min percentage of observations per leaf", and "Learning rate". These were described in section 2. As mentioned above, to these we have added two new parameters: "Sub-sampling rate" and "Feature sampling rate". We use grid search to test 1,008 different combination of parameters on the smaller data sets and 162 combinations on the larger data set. Table <ref type="table" target="#tab_0">2</ref> shows the values we tried for each of the parameters. Since MSLR-WEB10K contains more features for each query-url pair, we need more complex trees (trees with more leaves) on this data set.</p><p>Each combination of parameters is tested on 5 folds of each data set. On each fold we use 3 different random seeds to get more accurate results. This requires 1, 008 × 5 × 3 = 15, 120 experiments on each of the smaller data sets and 162 × 5 × 3 = 2, 430 experiments on MSLR-WEB10K. We used a MapReduce cluster of 40 nodes for these experiments. Map tasks receive experiments as input and compute validation and test NDCG for the configuration specified by that experiment. Reduce tasks perform NDCG averaging over different folds and random seeds for each parameters combination. It takes about 8 hours to run this portion of our experiments once on this cluster.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the best configurations based on Validation NDCG@3 on each data set. The best performing configurations on all three data sets use feature sampling. The smaller data sets also get better results by sub-sampling of training queries on each iteration. We conjecture that sub-sampling queries helps when the training data is small because it helps avoid overfitting by not allowing trees to see all queries on each iteration of boosting. This adds diversity to the individual trees which is then reduced when boosting averages  Grid search for parameter tuning is computationally expensive and becomes prohibitive as the data sets become large. Because of this it is useful to study the sensitivity of the LambdaMART algorithm to its parameters to have a better understanding of the number of training experiments needed on a new data set. We use the results of our parameter tuning experiments to study the effect of number of experiments on improvement in NDCG. For each dataset, we create a pool of configurations that we evaluated during parameter tuning experiments. Then we randomly select different numbers of these configurations. On each random selection, we pick the config with best validation NDCG@3 and then record validation and test NDCG@3 for that config. To get more accurate results, we repeat this random process 10K times and report average NDCG@3. Figure <ref type="figure" target="#fig_0">1</ref> shows the results.</p><p>As expected, for all three data sets, validation NDCG improves monotonically as we perform more experiments. On MSLR-WEB10K, the largest data set, there is less discrepancy between validation and test scores. The discrepancy between validation and test is largest on TD2004, the smallest data set, because the validation sets which are held aside form the training data must also be small.</p><p>Given that the parameter values we had chosen for grid search where chosen based on our experiments with Lamb-daMART on different data sets, we were expecting the pa-rameter tuning experiments to reach to the pick value on test set after trying few combinations. On TD2004, the data set with the smallest validation sets, accuracy on the test set peaks after only about 100 parameter configurations, and then slowly drops. Accuracy on the validation set is still rising at 100 iterations, suggesting that hyperparameter optimization is overfitting to the validation sets. A similar effect is observed on MQ2007, but overfitting does not begin on this problem until about 400 parameter configurations have been tried. And on MSLR-WEB10K, we again observe overfitting to the validation sets after fewer than 25 configurations have been tested.</p><p>When there is randomness in the algorithm and the validation sets are not infinite, as more parameter combinations are tried search begins to find parameter combinations that look better on the validation set because of this randomness. If one is not careful, the computational power provided by MapReduce Clusters is so great that it is possible to overdo parameter tuning and find parameter combinations that work not better than the hyperparameters that would have been found by less thorough search. One way to avoid overfitting at the hyperparameter learning stage is to use a 2nd held-out validation set to detect when parameter tuning begins to overfit and early-stop the parameter optimization. Holding out a 2nd validation set will reduce the size of the primary hyperparameter tuning validation sets, making overfitting more likely. But as we have seen, even large cross-validated validation sets do not completely protect from overfitting when hyperparameter optimization is exhaustive, so care must be exercised to prevent hyperparameter optimization from becoming counterproductive. We do not directly control the best number of trees for the LambdaMART models via a user-set parameter. Instead, as iterations of boosting continue, the prediction accuracy of the model is checked on a separate validation set. Boosting continues until there has been no improvement in accuracy for 250 iterations. The algorithm then returns the number of iterations that yielded maximum accuracy on the validation set.</p><p>Figure <ref type="figure">2</ref> shows two sample runs on MQ2007 and MSLR-WEB10K data sets. While NDCG@3 continues to improve on the training set, it reaches its maximum on validation sets after a few hundred iterations on both data sets. It is also interesting that we do not see significant drop in NDCG on validation sets even after 2000 iterations. This suggests that the combination of regularization techniques we use is sufficient to prevent models from overfitting on these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">BL-MART details</head><p>As mentioned before, for bagged LambdaMART we train many LambdaMART models in parallel and then aggregate their outputs for improved accuracy. In order to have more diverse models in the final ensemble, we randomly sample training data (without replacement) for training each of the LambdaMART sub-models. The randomization techniques discussed in section 3.3 also contribute additional diversity to the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Combining Scores</head><p>For combining scores of the sub-models, one can simply take average of their scores. However, the scale and distribution of the scores generated from LambdaMART algorithm is dependent on the training data and on smaller training data can be very different for models trained on different sub-samples. Because of this, simply averaging LambdaMART scores may not give the best results. As an example, Figure <ref type="figure">3</ref> shows the distributions of validation scores generated from two models that are trained on different random samples of MQ2007 and MSLR-WEB10K training data. While on the larger data set, the output scores have very similar distributions, on the smaller data set we observe difference distributions and different scales of the scores. Note that even on the MSLR-WEB10K data set the output score of individual queries do not necessarily have the same scales across different models. The reason that we see a final normal-like distribution on this data set is that scores of individual queries have close to uniform distributions with different scales and result in a normal-like distribution once aggregated.</p><p>Since scores of different sub-models are on different scales, we initially tried using Borda count <ref type="bibr" target="#b18">[18]</ref> as a rank aggregation technique. Each of the LambdaMART sub-models is used for generating a ranking of the test data. For each ranking, a score of 0 is assigned to the lowest ranked result, 1 to the next-to-lowest result, and so forth; then the total score of each result is computed over all the sub-models and the ensemble orders documents by this score. However, since Borda count converts real valued scores of documents to integer value ranks and then combines these ranks, the possibility of having ties increases significantly when averaging only have a few LambdaMART sub-models. Since tied documents would have to be ordered arbitrarily, this can significantly reduce the performance of the bagged model. Our experiments showed that Borda count works well when used to aggregate ranks of many model, but performs even worse than a single model when applied to only a few sub-models.</p><p>A better approach for combining the outputs of different sub-models is to normalize the scores of documents generated by each sub-model for each query. For each query we linearly scale the scores of its corresponding documents such that the document with the highest score will have a score of 1.0 and the document with the lowest score will have a score of 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Overfitting Tolerance</head><p>As mentioned in section 2, prediction error can be reduced by reducing both bias and variance. When bagging single decision or regression trees, bagging typically results in higher accuracy if applied to unpruned trees. The reason is that unpruned trees are overfitted to their training data and therefore have low bias and high variance. Since bagging is a variance reduction technique, it can reduce this variance so that the final bagged model has both low bias and low variance and thus lower total prediction error. Similarly, we may get better results by bagging boosted tree models that have less bias but more variance. We test the effectiveness of this idea by adding an overfitting tolerance as a new parameter to the LamdaMART algorithm.</p><p>To generate overfitted LambdaMART models, we monitor the prediction accuracy on a separate validation set. Without overfitting, we would select the first N trees that results in the maximum prediction accuracy on the validation set. With overfitting tolerance, we add more trees after this maximum point until accuracy drop is more than a threshold value. We experimented with different threshold values and found that 2% worked well across the three data sets. As Figure <ref type="figure">2</ref> shows, it is possible that even after adding hundreds of additional trees, the drop in prediction accuracy on validation set is small. To prevent the size of the overfitted model from growing excessively large in this situation we allow a maximum of 250 trees to be added after the maximum point has been reached on the validation set. It is possible that allowing more overfitting would further improve the results from bagging, but at the expense of a much larger model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head><p>BL-MART combines LambdaMART sub-models in order to achieve higher accuracy. There is a trade-off between increasing accuracy and model complexity: as we add more sub-models, the gain in accuracy is offset by the final model becoming too complex. It is important to balance the number of sub-models needed to achieve a reasonable gain in accuracy with the need to control complexity so that the models are still feasible to use in practice. To do this, we train BL-MART with different number of sub-models and evaluate its performance on the validation sets. We first create pools of LambdaMART models for each of the folds of the three data sets and then use these pools of models during the bagging process. We used pools of size 1000 models for TD2004 and MQ2007 data sets and 50 models for MSLR-WEB10K data set. The reason is that on the smaller data sets variance is higher and bagging needs to add more models before accuracy asymptotes.</p><p>We create different pools for overfitted and non-overfitted models. Overall, we need to train 10,000 LambdaMART models on each of the smaller data sets and 500 models on MSLR-WEB10K data set. We used a MapReduce cluster for this purpose. Each mapper task is assigned a fold in one of the data sets. It then randomly selects 67% of the training queries from that fold and generates a LambdaMART model on this random sample. Once the model is created, it evaluates the scores of validation and test data corresponding to that fold and passes these scores to reducer tasks. Reducer tasks just dump the scores that they receive. It takes about 18 hours to generate output scores for these models on a cluster of 40 nodes.</p><p>To study the effectiveness of using overfitted models in the bagging process, we create bagged models of different sizes from overfitted and non-overfitted models and then compare their MAP. Since we use a pool of models and each bagged model is created by randomly selecting a subset of models from these pools, we repeat the random process of bagged model creation 100 times and compute average validation MAP of these bagged models to have more reliable results. Figure <ref type="figure">4</ref> shows the results confirming that using overfitted models results in better accuracy for the final bagged ensemble. On MSLR-WEB10K data set, we need to include more models in the bagged ensemble before overfitted models show better results.</p><p>We use the same results of Figure <ref type="figure">4</ref> for determining the number of models that should be included in the bagged ensemble. In order to have a balance between accuracy and model complexity, we picked 45 models on smaller data sets and 20 models on the larger data set.</p><p>To compare the performance of BL-MART model with the original LambdaMART model and other learning-to-rank algorithms, we create BL-MART models for each of the data sets. Since, we create bagged models by random selection of sub-models from our model pools, we repeat this process for 20 times and report average results. Similarly, we use 20 different random seeds for "LambdaMART with randomization" and report average results. The original Lamb-daMART algorithm is deterministic and we only need to run it once. Since LambdaMART code is not publicly available, we re-implemented it for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Accuracy Analysis</head><p>Table <ref type="table">4</ref> summarizes the results of our experiments analyzing the accuracy of BL-MART models in comparison to LambdaMART and other learning-to-rank algorithms. On TD2004 and MQ2007 all prior published results are included in the table for four metrics. For the new MSLR-WEB10K data set no other results have yet been published.</p><p>On TD2004 data set, BL-MART significantly outperforms LambdaMART on all four metrics. Also bagging overfitted models results in better performance on this data set. In comparison to other learning-to-rank algorithms, BL-MART performs best in terms of MAP and NDCG@5, but on NDCG@1 and NDCG@3 RankBoost and BagBoo are slightly better. It should be noted that we have limited the size of BL-MART to control complexity. For example, on this data set, BL-MART contains about 4,500 trees while BagBoo is using 1.1 million trees which is 250 times larger than our model.</p><p>On MQ2007 data set, BL-MART again significantly outperforms LambdaMART on all metrics and it also achieves the best results compared to other learning-to-rank algorithms which have reported their results on this data set.</p><p>On the new MSLR-WEB10K data set, BL-MART again improves LambdaMART performance on all of the metrics. However, on this data set the difference between bagging of overfitted and non-overfitted models is not statistically significant.</p><p>Across the three problems and four metrics, BL-MART with overfitting improves accuracy an average of 2.6% when compared to LambdaMART with randomization.</p><p>While we have reported the best results (as far as we know) compared to other ranking algorithms on TD2004 and MQ2004 data sets, it should be noted that we did not tune the LamdaMART models for bagging. We tuned a single LambdaMART model and then used the same set of best parameters in the bagged model. It might be possible to get better results by bagging LambdaMART models which are generated from different set of parameters. For example, using more complex trees in sub-models might lead to overfitting which shows to be a desirable property for sub-models of a bagged ensemble. However, tuning the bagged model would have required much more experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Variance Analysis</head><p>Variance can hurt in several ways: 1) by increasing the variance term in the bias/variance decomposition it reduces the expected accuracy of the trained models; 2) by increasing uncertainty it increases the number of experiments that must be run to determine which learning method and parameters yield the best results; and 3) it creates risk when a final model must be selected to deploy. All other things being equal (e.g. expected accuracy across multiple trials), the lower-variance learning method is prefered. For example, reducing variance by half reduces the number of experiments that must be run to pass a t-test by √ 2, and reduces the expected loss of the single deployed model compared to the expected loss of a typical model by a factor of 2. Because of this, learning methods that exhibit high variance can be difficult to work with, and learning methods that have lower variance are safer to deploy and easier to use for new feature development. Boosting often has relatively high variance. Bagging, however, is an effective variance reduction method. Thus we expect BL-MART to have significantly lower variance than LambdaMART.</p><p>In order to compare the variance of LambdaMART and BL-MART models, we use the MSLR-WEB10K data set. We randomly select 10 samples from the training data of Fold1 of this data set. Each sample contains a random selection of 67% of the training queries in this fold. We then train LambdaMART and BL-MART models on each of these samples and evaluate these models on the test data of this fold.</p><p>Table <ref type="table" target="#tab_3">5</ref> shows the NDCG and MAP scores and their corresponding variance for each of the models. If we compare "LambdaMART with randomization" with "BL-MART with overfitting", the following would be the reduction in variance for different metrics:</p><p>• NDCG@1: -67.3%</p><p>• NDCG@3: -18.8%</p><p>• Mean NDCG: -40.2%</p><p>• MAP: -57.1%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION</head><p>Wrapping bagging around LambdaMART boosting yields two distinct benefits: 1) it achieves accuracy comparable to Table <ref type="table">4</ref>: Evalutation results on three public learning-to-rank data sets.</p><p>(a) TD2004 data set NDCG@1 NDCG@3 NDCG@5 MAP SVMmap <ref type="bibr" target="#b34">[34]</ref> 0.2933 0.3035 0.3007 0.2049 RankSVM-Struct <ref type="bibr" target="#b20">[20]</ref> 0.3467 0.3371 0.3192 0.2196 ListNet <ref type="bibr" target="#b9">[9]</ref> 0.3600 0.3573 0.3325 0.2231 SmoothRank <ref type="bibr" target="#b11">[11]</ref> 0.4000 0.3832 0.3555 0.2326 RankSVM <ref type="bibr" target="#b17">[17]</ref> 0.4133 0.3467 0.3240 0.2237 AdaRank-MAP <ref type="bibr" target="#b33">[33]</ref> 0.4133 0.3757 0.3602 0.2189 AdaRank-NDCG <ref type="bibr" target="#b33">[33]</ref> 0.4267 0.3688 0.3514 0.1936 BoltzRank <ref type="bibr" target="#b30">[30]</ref> 0.4767 0.3902 0.3635 0.2390 FRank <ref type="bibr" target="#b28">[28]</ref> 0 For those interested in delivering high accuracy search results at commercial search engines, the reduction in variance may be the more important result. In commercial search engines most gains come not from improved learning methods, but from developing new or improved features (and data) to feed into learning. Feature and data refinement requires frequent experimentation to determine if the refinement is better and should be released. Reduced learning variance makes these experiments easier and more reliable. Because bagging can easily be parallelized across multiple computers, it allows one to obtain low variance experimental results with little increase in wall clock time. That these results also will have state-of-the-art accuracy makes the method even more appealing.</p><p>The final output of our BL-MART method is a high precision and low variance bagged ensemble of models. However, in real-time applications such as search engines, it may not be feasible to use such large models. We are currently working on compression pruning techniques that allow dropping a large fraction of trees from the final model without significantly impacting the accuracy. This is possible because we find empirically that large shrinkage is necessary to prevent massive overfitting in LambdaMART models. When shrinkage is high, boosting sometimes needs to generate a sequence of nearly identical trees to do what it might have accomplished with one tree without shrinkage. Yet in other places shrinkage is critical and subsequent trees are quite different from each other. By deleting and reweighting trees after the full LambdaMART ensemble has been grown, we can determine post-facto which trees are redundant and contribute little to the model, and which trees are critical for the model to have high accuracy. The method is currently under development, but it looks like we can also exploit the fact that bagging boosted trees generates even more reduntant trees that can safely be eliminated afterwards with little or no loss in accuracy. For example, in one set of experiments we are able to prune away 40-80% of the trees without significant loss in NDCG.</p><p>To run experiments, we developed a platform called jforests that not only implements LambdaMART and BL-MART, but which supports many tree-based learning methods such as bagging, boosting, regression, classification, ranking, etc. The platform is written in such a way to make it easy to code additional tree-based methods with minimum effort. For example, AdaRank and RankBoost can each be implemented in less than a dozen lines of new code. Our code platform including the implementations of LamdaMART and BL-MART will be made publicly available. The jforests platform also supports running on MapReduce environments to allow parallelization of methods such as bagging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>We present new results for LambdaMART, a state-of-theart learning-to-rank algorithm, on three public data sets. We show that wrapping bagging around a boosting-based ranking model can improve its performance while also significantly reducing model variance. In our experiments, bagged LambdaMART (BL-MART) increased NDCG@1, NDCG@3, Mean NDCG, and MAP on all three test problems compared to un-bagged LambdaMART. Moreover, bagging reduced variance an average of 46% across all metrics on the MSLR-WEB10K data set on which we measured variance. Most of the ideas and methods reported in this paper are general and not limited specifically to ranking. For example, our finding that overfitting boosted models that will be bagged improves accuracy can be used in other classification and regression problems to further improve performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: As more combinations of parameters are tested during parameter tuning of LambdaMART, NDCG@3 improves on the validation sets, but the test set curves show overfitting of the hyperparameters eventually occurs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: As more trees are added to the LamdaMART model train set accuracy begins to deviate from validation set accuracy. The appropriate number of iterations is determined by monitoring performance on the validation set.Model 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Values used in grid search for parameter tuning</figDesc><table><row><cell cols="2">(a) TD2004 and MQ2007 data sets</cell></row><row><cell>Parameter</cell><cell>Values</cell></row><row><cell>Max Number of Leaves</cell><cell>2, 4, 7, 10, 15, 20, 25</cell></row><row><cell cols="2">Min Percentage of Obs. per Leaf 0.12, 0.25, 0.50</cell></row><row><cell>Learning rate</cell><cell>0.05, 0.1, 0.2, 0.3</cell></row><row><cell>Sub-sampling rate</cell><cell>0.3, 0.5, 1.0</cell></row><row><cell>Feature Sampling rate</cell><cell>0.1, 0.3, 0.5, 1.0</cell></row><row><cell cols="2">(b) MSLR-WEB10K data set</cell></row><row><cell>Parameter</cell><cell>Values</cell></row><row><cell>Max Number of Leaves</cell><cell>10, 40, 70</cell></row><row><cell cols="2">Min Percentage of Obs. per Leaf 0.12, 0.25, 0.50</cell></row><row><cell>Learning rate</cell><cell>0.05, 0.1, 0.2</cell></row><row><cell>Sub-sampling rate</cell><cell>0.5, 1.0</cell></row><row><cell>Feature Sampling rate</cell><cell>0.3, 0.5, 1.0</cell></row></table><note><p>selects the best feature from a random subset of features instead of the best overall feature.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Properties of data sets used for experiments</figDesc><table><row><cell>Data set</cell><cell cols="4">Queries Query-URL Pairs Features Relevance Labels</cell></row><row><cell cols="2">TD2004 MQ2007 MSLR-WEB10K 10,000 75 1,692</cell><cell>74,146 69,623 1,200,192</cell><cell>64 46 136</cell><cell>{0, 1} {0, 1, 2} {0, 1, 2, 3, 4}</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Best combinations of parameters found after parameter tuning.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">(a) TD2004 data set</cell><cell></cell><cell></cell></row><row><cell cols="6">Validation NDCG@3 Max Leaves Min Obs. Per Leaf Learning Rate Sub-sampling Feature Sampling</cell></row><row><cell>0.5113</cell><cell>20</cell><cell>0.25</cell><cell>0.1</cell><cell>0.5</cell><cell>0.1</cell></row><row><cell>0.5105</cell><cell>10</cell><cell>0.50</cell><cell>0.05</cell><cell>0.3</cell><cell>0.1</cell></row><row><cell>0.5061</cell><cell>10</cell><cell>0.12</cell><cell>0.05</cell><cell>0.5</cell><cell>0.3</cell></row><row><cell>0.5056</cell><cell>10</cell><cell>0.50</cell><cell>0.1</cell><cell>0.3</cell><cell>0.1</cell></row><row><cell>0.5055</cell><cell>15</cell><cell>0.25</cell><cell>0.05</cell><cell>0.5</cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell cols="2">(b) MQ2007 data set</cell><cell></cell><cell></cell></row><row><cell cols="6">Validation NDCG@3 Max Leaves Min Obs. Per Leaf Learning Rate Sub-sampling Feature Sampling</cell></row><row><cell>0.5647</cell><cell>7</cell><cell>0.25</cell><cell>0.05</cell><cell>0.3</cell><cell>0.3</cell></row><row><cell>0.5643</cell><cell>4</cell><cell>0.25</cell><cell>0.1</cell><cell>1.0</cell><cell>0.1</cell></row><row><cell>0.5643</cell><cell>10</cell><cell>0.25</cell><cell>0.05</cell><cell>0.5</cell><cell>0.3</cell></row><row><cell>0.5635</cell><cell>7</cell><cell>0.50</cell><cell>0.05</cell><cell>0.5</cell><cell>0.5</cell></row><row><cell>0.5633</cell><cell>7</cell><cell>0.25</cell><cell>0.05</cell><cell>0.5</cell><cell>0.3</cell></row><row><cell></cell><cell></cell><cell cols="2">(c) MSLR-WEB10K data set</cell><cell></cell><cell></cell></row><row><cell cols="6">Validation NDCG@3 Max Leaves Min Obs. Per Leaf Learning Rate Sub-sampling Feature Sampling</cell></row><row><cell>0.4873</cell><cell>40</cell><cell>0.25</cell><cell>0.1</cell><cell>1.0</cell><cell>0.5</cell></row><row><cell>0.4872</cell><cell>70</cell><cell>0.50</cell><cell>0.05</cell><cell>1.0</cell><cell>0.3</cell></row><row><cell>0.4870</cell><cell>40</cell><cell>0.25</cell><cell>0.05</cell><cell>1.0</cell><cell>0.5</cell></row><row><cell>0.4867</cell><cell>40</cell><cell>0.50</cell><cell>0.1</cell><cell>1.0</cell><cell>0.3</cell></row><row><cell>0.4865</cell><cell>40</cell><cell>0.50</cell><cell>0.05</cell><cell>0.5</cell><cell>1.0</cell></row></table><note><p>tree predictions. With very large data sets this is less critical because individual trees cannot themselves significantly overfit a large data set when tree size is limited.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>Variance reduction in BL-MART models compared to LambdaMART models. The first column in each group is the mean accuracy. The second column in the variance of this accuracy measured across the trials. LambdaMART with randomization 0.4492 22 × 10 -6 0.4421 5.4 × 10 -6 0.5647 1.4 × 10 -6 0.3665 1.3 × 10 -6 BL-MART without overfitting 0.4516 10 × 10 -6 0.4468 7.8 × 10 -6 0.5675 1.5 × 10 -6 0.3690 0.9 × 10 -6 BL-MART with overfitting 0.4528 7 × 10 -6 0.4471 4.4 × 10 -6 0.5686 0.8 × 10 -6 0.3703 0.5 × 10 -6</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>.4933</cell><cell>0.3875</cell><cell>0.3629</cell><cell>0.2388</cell></row><row><cell>RankBoost [13]</cell><cell></cell><cell></cell><cell></cell><cell>0.5067</cell><cell>0.4295</cell><cell>0.3878</cell><cell>0.2614</cell></row><row><cell>BagBoo [23]</cell><cell></cell><cell></cell><cell></cell><cell>0.5067</cell><cell>0.4080</cell><cell>0.3898</cell><cell>0.2499</cell></row><row><cell>LambdaMART</cell><cell></cell><cell></cell><cell></cell><cell>0.4267</cell><cell>0.3584</cell><cell>0.3266</cell><cell>0.2378</cell></row><row><cell cols="5">LambdaMART with randomization 0.4560</cell><cell>0.4033</cell><cell>0.3722</cell><cell>0.2513</cell></row><row><cell cols="3">BL-MART without overfitting</cell><cell></cell><cell>0.4947</cell><cell>0.4217</cell><cell>0.3886</cell><cell>0.2649</cell></row><row><cell cols="2">BL-MART with overfitting</cell><cell></cell><cell></cell><cell>0.4947</cell><cell>0.4270</cell><cell>0.3948</cell><cell>0.2684</cell></row><row><cell></cell><cell></cell><cell cols="4">(b) MQ2007 data set</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">NDCG@1 NDCG@3 Mean NDCG MAP</cell></row><row><cell cols="2">RankSVM-Struct [20]</cell><cell></cell><cell cols="2">0.4096</cell><cell>0.4063</cell><cell>0.4966</cell><cell>0.4645</cell></row><row><cell>ListNet [9]</cell><cell></cell><cell></cell><cell cols="2">0.4002</cell><cell>0.4091</cell><cell>0.4988</cell><cell>0.4652</cell></row><row><cell>AdaRank-MAP [33]</cell><cell></cell><cell></cell><cell cols="2">0.3821</cell><cell>0.3984</cell><cell>0.4891</cell><cell>0.4577</cell></row><row><cell cols="2">AdaRank-NDCG [33]</cell><cell></cell><cell cols="2">0.3876</cell><cell>0.4044</cell><cell>0.4914</cell><cell>0.4602</cell></row><row><cell>RankBoost [13]</cell><cell></cell><cell></cell><cell cols="2">0.4134</cell><cell>0.4072</cell><cell>0.5003</cell><cell>0.4662</cell></row><row><cell>CRR [25]</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell>-</cell><cell>0.5000</cell><cell>0.4660</cell></row><row><cell>BagBoo [23]</cell><cell></cell><cell></cell><cell cols="2">0.4071</cell><cell>0.4176</cell><cell>-</cell><cell>0.4676</cell></row><row><cell>LambdaMART</cell><cell></cell><cell></cell><cell cols="2">0.4147</cell><cell>0.4119</cell><cell>0.5011</cell><cell>0.4660</cell></row><row><cell cols="5">LambdaMART with randomization 0.4137</cell><cell>0.4157</cell><cell>0.5035</cell><cell>0.4684</cell></row><row><cell cols="3">BL-MART without overfitting</cell><cell cols="2">0.4197</cell><cell>0.4217</cell><cell>0.5079</cell><cell>0.4726</cell></row><row><cell cols="2">BL-MART with overfitting</cell><cell></cell><cell cols="2">0.4200</cell><cell>0.4224</cell><cell>0.5093</cell><cell>0.4731</cell></row><row><cell></cell><cell cols="5">(c) MSLR-WEB10K data set</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">NDCG@1 NDCG@3 Mean NDCG MAP</cell></row><row><cell>LambdaMART</cell><cell></cell><cell></cell><cell cols="2">0.4580</cell><cell>0.4467</cell><cell>0.5693</cell><cell>0.3670</cell></row><row><cell cols="5">LambdaMART with randomization 0.4628</cell><cell>0.4487</cell><cell>0.5706</cell><cell>0.3684</cell></row><row><cell cols="3">BL-MART without overfitting</cell><cell cols="2">0.4640</cell><cell>0.4514</cell><cell>0.5720</cell><cell>0.3696</cell></row><row><cell cols="2">BL-MART with overfitting</cell><cell></cell><cell cols="2">0.4642</cell><cell>0.4516</cell><cell>0.5729</cell><cell>0.3705</cell></row><row><cell></cell><cell cols="2">NDCG@1</cell><cell></cell><cell cols="2">NDCG@3</cell><cell cols="2">Mean NDCG</cell><cell>MAP</cell></row><row><cell></cell><cell>Mean</cell><cell cols="2">Variance</cell><cell>Mean</cell><cell>Variance</cell><cell>Mean</cell><cell>Variance</cell><cell>Mean</cell><cell>Variance</cell></row><row><cell>LambdaMART</cell><cell cols="8">0.4484 18 × 10 -6 0.4395 9.1 × 10 -6 0.5640 1.2 × 10 -6 0.3657 0.9 × 10 -6</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Authors would like to thank Amazon for a research grant that allowed us to use their MapReduce cluster. This work has been also partially supported by NSF grant OCI-074806.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://research.microsoft.com/en-us/projects/mslr/" />
		<title level="m">Microsoft learning to rank datasets</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m">Modern Information Retrieval</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996-08">August 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1010933404324</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using iterated bagging to debias regressions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="261" to="277" />
			<date type="published" when="2001-12">December 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">From RankNet to LambdaRank to LambdaMART: An overview</title>
		<author>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2010-82</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Microsoft Research</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to rank with nonsmooth cost functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ragno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to rank using gradient descent</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;07: Proceedings of the 24th international conference on Machine learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://learningtorankchallenge.yahoo.com" />
		<title level="m">The Yahoo! learning to rank challenge</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gradient descent optimization of smoothed information retrieval metrics</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="216" to="235" />
			<date type="published" when="2010-06">June 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pranking with ranking</title>
		<author>
			<persName><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="641" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An efficient boosting algorithm for combining preferences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="933" to="969" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Stochastic gradient boosting</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>Dept. Statistics, Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bienenstock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Doursat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks and the bias/variance dilemma</title>
		<imprint>
			<date type="published" when="1992-01">January 1992</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large margin rank boundaries for ordinal regression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="115" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decision combination in multiple classifier systems. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="75" />
			<date type="published" when="1994-01">Jan. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">IR evaluation methods for retrieving highly relevant documents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;00: Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Training linear SVMs in linear time</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;06</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mcrank: Learning to rank using multiple classification and gradient boosting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to rank for information retrieval</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BagBoo: a scalable hybrid bagging-the-boosting model</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gorodilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Brunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM &apos;10</title>
		<meeting>the 19th ACM international conference on Information and knowledge management, CIKM &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1897" to="1900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">LETOR: A benchmark collection for research on learning to rank for information retrieval</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10791-009-9123-y</idno>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="346" to="374" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Combined regression and ranking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;10</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="979" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Additive groves of regression trees</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sorokina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedewald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th European conference on Machine Learning, ECML &apos;07</title>
		<meeting>the 18th European conference on Machine Learning, ECML &apos;07<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="323" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Combining bias and variance reduction techniques for regression trees</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Melville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning (ECML&apos;05)</title>
		<meeting>the European Conference on Machine Learning (ECML&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="741" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">FRank: a ranking method with fidelity loss</title>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="383" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Low bias bagged support vector machines</title>
		<author>
			<persName><forename type="first">G</forename><surname>Valentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning, ICML&apos;03</title>
		<meeting>the International Conference on Machine Learning, ICML&apos;03</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="752" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Boltzrank: learning to maximize expected ranking gain</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Volkovs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning, ICML &apos;09</title>
		<meeting>the 26th Annual International Conference on Machine Learning, ICML &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1089" to="1096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiboosting: A technique for combining boosting and wagging</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="159" to="196" />
			<date type="published" when="2000-08">August 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Ranking, boosting and model adaptation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno>MSR-TR-2008-109</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="report_type">Microsoft Technical Report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AdaRank: a boosting algorithm for information retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="391" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A support vector method for optimizing average precision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;07</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
