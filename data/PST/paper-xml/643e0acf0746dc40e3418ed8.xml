<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-View Graph Representation Learning Beyond Homophily</title>
				<funder ref="#_AKqNrPn #_M4TESxm">
					<orgName type="full">Science and Technology Research and Development Program Project of China railway group</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-04-15">15 Apr 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lin</forename><forename type="middle">+</forename><surname>Bei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">You</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">+</forename><surname>Ning</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhuopeng</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhiwu</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">National Engineering Research Center of High-speed Railway Construction Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Central South University</orgName>
								<address>
									<addrLine>YueLu Street</addrLine>
									<postCode>410083</postCode>
									<settlement>Changsha, Hunan, Zhiwu Yu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">National Engineering Research Center of High-speed Railway Construction Technology</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-View Graph Representation Learning Beyond Homophily</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-15">15 Apr 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2304.07509v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>graph representation learning</term>
					<term>autoencoder</term>
					<term>multi-view</term>
					<term>homophily</term>
					<term>heterophily</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised graph representation learning(GRL) aims to distill diverse graph information into task-agnostic embeddings without label supervision. Due to a lack of support from labels, recent representation learning methods usually adopt self-supervised learning, and embeddings are learned by solving a handcrafted auxiliary task(so-called pretext task). However, partially due to the irregular non-Euclidean data in graphs, the pretext tasks are generally designed under homophily assumptions and cornered in the low-frequency signals, which results in significant loss of other signals, especially high-frequency signals widespread in graphs with heterophily. Motivated by this limitation, we propose a multi-view perspective and the usage of diverse pretext tasks to capture different signals in graphs into embeddings. A novel framework, denoted as Multi-view Graph Encoder(MVGE), is proposed, and a set of key designs are identified. More specifically, a set of new pretext tasks are designed to encode different types of signals, and a straightforward operation is propxwosed to maintain both the commodity and personalization in both the attribute and the structural levels. Extensive experiments on synthetic and real-world network datasets show that the node representations learned with MVGE achieve significant performance improvements in three different downstream tasks, especially on graphs with heterophily. Source code is available at https://github.com/G-AILab/MVGE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graphs provide a natural and efficient representation for non-Euclidean data, such as brain networks, social networks, traffic maps in logistics <ref type="bibr" target="#b23">[24]</ref>, and financial networks <ref type="bibr" target="#b3">[4]</ref>. To simplify the learning process, the current graph learning community generally divides graphs into two significant types from the node label's perspective: homophily and heterophily. In graphs with homophily, linked nodes often belong to the same class or have similar features, which is a crucial principle of many real-world networks, e.g., in the citation network, papers tend to cite papers from the same research area <ref type="bibr" target="#b25">[26]</ref>. Partially due to its simplicity, this type of network has been under intensive study. In heterophily settings, trends in connections are reversed with the so-called "opposites attract" phenomenon. Linked nodes are likely from different classes or have different features, e.g., the chemical interactions in proteins often occur between different types of amino acids <ref type="bibr" target="#b2">[3]</ref>. Learning on graphs with heterophily is more difficult <ref type="bibr" target="#b14">[15]</ref>.</p><p>However, either homophily or heterophily is classified based on the global assortativity <ref type="bibr" target="#b26">[27]</ref>, a metric defined only concerning node labels across the whole graph. In reality, real-world graphs can not be readily classified into either homophily or heterophily while they essentially reveal a complex and typically mixture of patterns from both node and attribute levels <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30]</ref>. Fig. <ref type="figure" target="#fig_8">1a</ref> shows that real-world graphs have different degrees of homophily: Cora, Citeseer, and Pubmed are with high homophily, while Cornell, Texas, and Wisconsin are with high heterophily. Furthermore, even within a graph, the actual distribution patterns are highly diverse, Fig. <ref type="figure" target="#fig_8">1b</ref> shows that Cora with strong homophily still exist nodes with local heterophily, and vice versa also holds for Wisconsin with strong global heterophily. This fact clearly shows abundant signals, including low-frequency signals for commonality and high-frequency signals for disparity and the mixtures of those signals.  The goal of unsupervised Graph Representation Learning(GRL) is to condense different types of information existing in both the graph attributes and the topology into task-agnostic low-dimension embeddings <ref type="bibr" target="#b8">[9]</ref>. Such complex patterns in high-dimensional and intractable non-Euclidean graph data bring enormous challenges for unsupervised GRL research without direct access to ground truth labels during embeddings. Due to the lack of label guidelines and the popularity of homophily, most GRL solutions are designed under strong homophily assumption <ref type="bibr" target="#b21">[22]</ref>. For example, random walk-based methods(e.g., DeepWalk <ref type="bibr" target="#b31">[32]</ref>, Node2Vec <ref type="bibr" target="#b6">[7]</ref>) match nodes' co-occurrence rate on short random walks over the graph to force neighboring nodes to have similar representations. GAE, VGAE <ref type="bibr" target="#b18">[19]</ref> and later variants ARVGE <ref type="bibr" target="#b28">[29]</ref> assumes the connected nodes have more similar embeddings. GNN-based solutions are optimized for the network with homophily by propagating features and aggregating them within various graph neighborhoods via different mechanisms (e.g., averaging, LSTM, self-attention) <ref type="bibr" target="#b48">[49]</ref>, e.g., GCN <ref type="bibr" target="#b17">[18]</ref>, SGC <ref type="bibr" target="#b39">[40]</ref>, GAT <ref type="bibr" target="#b36">[37]</ref>, can be regarded as a particular form of the low-pass filter <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b40">41]</ref>, which can extract the low-frequency information in the graph data and make the characterization information of a node and its surrounding context closer <ref type="bibr" target="#b20">[21]</ref>. Another major stream of GRL is contrastive learning in which graph augmentations preserve the low-frequency components and perturb the middle and high-frequency components of the graph. This design hinders its application on graphs with heterophily <ref type="bibr" target="#b38">[39]</ref>.</p><p>However, as shown in Fig. <ref type="figure" target="#fig_8">1b</ref>, there are abundant signals in the network, merely retaining the low-frequency information, which denotes the commonality in node features, is insufficient to support patterns differing from commonality. The high-frequency information, capturing the difference between node features, may be more suitable for heterophily. However, very limited GRL works have been proposed to support the embeddings for heterophily. Our previous work, PairE <ref type="bibr" target="#b21">[22]</ref> tries to encode both low-frequency and high-frequency signals among connected nodes by employing node pairs as basic embedding units. However, systematic encoding of different signals in GRL remains under-explored.</p><p>One major limitation faced by most GRL solutions lies in that one pretext task may only retain information from one perspective and can not cover the rich patterns existing in graphs <ref type="bibr" target="#b16">[17]</ref>. To support this conclusion, we assess the quality of the embeddings generated from two different pretext tasks: the ego-task that keeps the difference between node attributes and the agg-task that keeps the commonality signals between a node and its surrounding neighbors, which explore highfrequency and low-frequency signals respectively. Fig. <ref type="figure" target="#fig_8">1c</ref> and 1d clearly illustrate an important fact: embeddings from the two tasks have the exact opposite performance in Pubmed and Wisconsin. Specifically, Fig. <ref type="figure" target="#fig_8">1d</ref> shows that when a network exhibits heterophily(Wisconsin), embeddings from high-frequency signals (ego-task) perform much better than low-frequency signals (agg-task), while under homophily settings(Cora) are opposite, as shown in Fig. <ref type="figure" target="#fig_8">1c</ref>. As already discussed, real-world graphs usually display a complex and typically mixture of patterns. Thus, it is essential to extract different frequency signals simultaneously.</p><p>Motivated by the above discussed limitations with one pretext task, this paper proposes a novel Multi-view Graph Encoder(MVGE) framework that can effectively condense different types of signals into the embeddings with multiple novel pretext tasks. In order to tackle the problems of the semantic difference among embeddings learned from different tasks, we also propose a novel design to transform those embeddings into one uniform semantic space. Our contribution is summarized as follows:</p><p>? GRL beyond the homophily assumption. We analyze the efficacy and limitations of different pretext tasks in terms of their capabilities in capturing different types of signals existing in graphs. We show that different pretext tasks can be only effective for graphs with either homophily or heterophily and innovatively point out the necessity of learning from multiple perspectives.</p><p>? Capturing different types of information in the graph. This paper designs two pretext tasks that capture the graph's high and low-frequency signals within node features. More specifically, the paper proposes two pretext tasks: the ego-task learns the distributions of node features with rich high-frequency signals, and the agg-task learns the distributions of the smoothed aggregated neighbor attributes with low-frequency signals. Two separated autoencoders are proposed to support those two tasks. ? Effective integration of embeddings from multiple perspectives. The direct use of multi-task learning might not improve final embedding quality due to their diverse semantic meanings. This paper designs and implements MVGE that can merge different embeddings with an adjacent reconstruction task which can translate embeddings in different semantic spaces into one coherent space.</p><p>In order to evaluate the quality of generated embeddings, we compare MVGE with nine state-ofthe-art baselines on eight real-world networks covering the full spectrum of low-to-high global homophily. Extensive comparative experiments, including node classification, link prediction, and pairwise node classification, validate that MVGE has advantages over state-of-the-arts and gains significant performance improvement in heterophily while being competitive in homophily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we introduce the graph representation learning under the homophily or heterophily assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">GRL under Homophily Assumption.</head><p>Matrix Factorization &amp; DeepWalk. Early unsupervised methods for learning node representation are traditionally based on matrix factorization and random walks. Matrix factorization methods calculate losses with handcrafted similarity metrics to build vector representations for each node with latent features <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b44">45]</ref>. The inspiration for random walk-based unsupervised methods for learning node representation comes from the effectiveness of the NLP method. DeepWalk <ref type="bibr" target="#b31">[32]</ref> and Node2Vec <ref type="bibr" target="#b6">[7]</ref> optimize node embeddings by matching nodes' co-occurrence rate on short random walks over graphs. They are shown to over-emphasize proximity information at the expense of structural information <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b37">38]</ref>. Also, they are limited to preserving the similarity of adjacent nodes and cannot extend to heterophily settings. AutoEncoder-based. Graph autoencoders, e.g., GAE and VGAE <ref type="bibr" target="#b18">[19]</ref> and their follow-up work ARVGE <ref type="bibr" target="#b28">[29]</ref> with an adversarial regularization framework use two-layer GCN as their encoder and consider that impose the topological closeness of nodes in the graph structure on the latent space by predicting the first-order neighbors. GAEs over-emphasize proximity information and are also based on the assumption that connected nodes should be more similar. Unsupervised GNNs. Unsupervised GNN-based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref>, on the other hand, propagate features and aggregate them within various graph neighborhoods via different mechanisms (e.g., averaging, LSTM), where the node representations evolve over multiple rounds of propagation with becoming prohibitively similar. Uniform aggregation and update in GNNs ignore the difference in information between similar and dissimilar neighbors. On heterophilic graphs, discriminative node representation learning yearns for distinguishable information with diverse message passing <ref type="bibr" target="#b48">[49]</ref> <ref type="bibr" target="#b46">[47]</ref>. Contrastive methods. Contrastive methods aim to learn representations by maximizing feature consistency under different augmentation views <ref type="bibr" target="#b11">[12]</ref>. For example, DGI <ref type="bibr" target="#b37">[38]</ref> employs the idea of Deep InfoMax <ref type="bibr" target="#b12">[13]</ref> and considers both local and global information during discrimination. MVGRL <ref type="bibr" target="#b9">[10]</ref> proposed to train graph encoder by maximizing MI between representations encoded from firstorder neighbors and a graph diffusion. MERIT <ref type="bibr" target="#b15">[16]</ref> utilized Siamese networks <ref type="bibr" target="#b4">[5]</ref> and proposed cross-views and cross-network contrastive objectives to maximize the similarity between node representations from local and global perspectives. These methods can, to some extent, mitigate the impacts of heterophily. However, most of those solutions only augment the low-frequency signals between nodes and perturb the middle and high-frequency components of the graph. It contributes to the success of GCL algorithms in homophily but hinders its application in heterophily <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning beyond Homophily</head><p>Due to the lack of node labels, graph representation learning beyond homophily remains largely unexplored. Existing works are mainly limited to the semi-supervised GNNs for heterophily. The common philosophy behind these works is weakening the smoothing effect. For example, MixHop <ref type="bibr" target="#b0">[1]</ref> and H2GCN <ref type="bibr" target="#b48">[49]</ref> combine multi-scale information by concatenation to modify the smoothed node representations based on local information, while FAGCN <ref type="bibr" target="#b2">[3]</ref> and GPRGNN <ref type="bibr" target="#b5">[6]</ref> relax the edges with positive values, which tends to induce the smoothing effect, to possess real values (which can be either positive or negative). GNN-LF/HF <ref type="bibr" target="#b49">[50]</ref> designs filter weights from the perspective of graph optimization functions, which can simulate high-and low-pass filters and LINKX <ref type="bibr" target="#b22">[23]</ref> separately embeds node features and graph topology. After that, the two embeddings are combined with MLPs to generate node embeddings. However, these methods are semi-supervised and rely on the node labels to define the homophily level and guide the learning processes. Actually, different attributes possess diverse characteristics in unsupervised settings.</p><p>GRL adopting an unsupervised/self-supervised paradigm still remains challenging due to the uncertainty in defining a learning objective. Selene <ref type="bibr" target="#b47">[48]</ref> proposes a dual-channel feature embedding mechanism to fuse node attributes and network structure information and leverage a sampling and anonymization strategy to break the implicit homophily assumption of existing embedding mechanisms. However, Selene needs to extract the high-order subnetwork (? -Ego) corresponding to each node, which will significantly increase the computational and space burden. Our previous work, PairE <ref type="bibr" target="#b21">[22]</ref> preserves both information for homophily and heterophily by going beyond the localized node view and utilizing paired node entities as the basic embedding unit. It can, to some extent, maintain high-frequency signals. But it demands hand-craft design to translate pair-based embeddings to node embeddings for typical downstream tasks. AF-GCL <ref type="bibr" target="#b38">[39]</ref> leverages the features aggregated by GNN to construct the self-supervision signal, which prevents perturbing middle and high-frequency information due to the heavily relying on graph augmentation and is less sensitive to the homophily degree. However, AF-GCL still aims to learn similarities between nodes rather than keep high-frequency signals in node features. In the settings of unsupervised GRLs, how to effectively encode different frequency signals into embeddings and make the graph representation can effectively support a wealth of unknown downstream tasks remains largely unexplored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NOTATION AND PRELIMINARIES</head><p>Let G = (V; E) be an undirected, unweighted graph with node set V and edge set E. For each node ?, there contains a unique class label ? ? . We denote a general random walk rooted at vertex ? as ? (?) and the ? hops/steps random walk as ? ? (?). For example, ? 1 (?) = ? : (?, ?) ? E is one of the immediate neighbors of ?. ? (?) denotes the 1-hop neighbors of node ?. We represent the graph by its adjacency matrix ? ? 0, 1 ? ?? and its node feature matrix ? ? R ? ?? , where the vector ? ? corresponds to the ego-feature of node ? and ? ? : ? ? ? (?) to features of the node in its random walk path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Global and Local Homophily</head><p>Here, we define the metrics to describe the essential characteristics of a graph. There exist multiple metrics, e.g., the label smoothness defined in <ref type="bibr" target="#b13">[14]</ref> or the network assortativity in <ref type="bibr" target="#b26">[27]</ref>. Here, we adopt the edge homophily ratio ? ?????? , the fraction of edges which connect nodes that have the same class label(i.e., intra-class edges), which gives an overall trend for all the edges in the graph. This metric is firstly defined in H2GCN <ref type="bibr" target="#b48">[49]</ref>. Definition 1 (Global Homophily). The edge homophily ratio ? ??????</p><formula xml:id="formula_0">? ?????? = |{(?, ?) : (?, ?) ? E ? ? ? = ? ? }| |E |<label>(1)</label></formula><p>When the global edge homophily ratio ? ?????? ? 1, it shows that the graph has strong homophily. In contrast, graph with strong heterophily(i.e., low/weak homophily) have small global edge homophily ratio ? ?????? ? 0.</p><p>However, as discussed in the introduction, this metric only represents the global trend of a graph. In different parts of real-world graphs, different homophily degrees can be observed. Here, we explicitly introduce a new metric that measures the homophily degree from a node's local view. Definition 2 (Local Homophily). The local homophily is the fraction of nodes in node ?'s immediate neighbors that have the same class label as node ?:</p><formula xml:id="formula_1">? ????? ? = |{(?, ?) : (?, ?) ? E ? ? ? = ? ? }| |{(?, ?) : (?, ?) ? E}|<label>(2)</label></formula><p>Rather than ? ?????? that represent global trend with one scalar, the local edge homophily ratio ? ????? ? is node-specific. When ? ????? ? ? 1, it indicates that node ? connects to surrounding nodes with the same label, while node ? with strong heterophily ? ????? ? ? 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Node Features in Ego and Aggregation Views</head><p>As pointed out by previous works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b48">49]</ref>, in graphs with strong homophily, the attribute aggregation operation in GNNs can usually intensify the low-frequency signals. While in graphs with strong heterophily, the node attributes themselves and MLP can often achieve SOTA performance as those attributes contain a distinctive node pattern for classification. As we do not have any labels and downstream tasks might rely on different types of signals, we go beyond the traditional homophily assumption and innovatively propose two views to capture the low-and high-frequency information existing in the node features: specifically, ego features and aggregated features. Definition 3 (Node-specific Ego features). We use the nodes' original features as ego features:</p><formula xml:id="formula_2">? ??? = {? ??? ? : ? ??? ? = ? ? , ? ? V}<label>(3)</label></formula><p>It contains the unique information of the node itself, which can preserve the information difference between nodes to the greatest extent, which is the high-frequency signals.</p><p>Definition 4 (Walk-based Aggregated features). Merely using the ego features, the noise in them will cause the learned representations to deviate from reality. To reduce the impacts of the noise, similar to the GNN-based solutions, we define an aggregation function to aggregate the surrounding context, denoted as ? ??? . One important requirement is the aggregated feature should be able to intensify the low-frequency signals and/or the mean-smoothed high-frequency signals around a node ?. Furthermore, to some extent, the aggregated features should represent the local structure of node ?. Here, the aggregated neighbor feature for each node ? is given as: Specifically, for each node ?, we generate several paths through unbiased random walks with unequal steps, e.g., ? ? (?),? ? (?). Here, i and j represent the length of the path. The aggregated features from each path are calculated with the features-wise average for all the nodes along the path. Figure <ref type="figure" target="#fig_2">2</ref> shows the three paths starting from node 8 with lengths 3, 5, and 10. Then, we mixed the aggregated features of each random walk path by concatenation. This design is based on the following observation. (1) multiple random walks help to capture mixing latent information from neighbors at various distances. (2) As verified in H2GCN, in heterophily settings, although the labels of immediate neighbors tend to be different from the ego node, the higher-order neighborhoods may have the same class of the ego node and can provide more relevant context. Thus, by higher-order random walk and aggregating information beyond the immediate neighbors, the similarity between nodes with structural and semantic similarity can be preserved.</p><formula xml:id="formula_3">? ??? ? = ????(??????? (? ? ? : ? ? ? ? ? (?)), ??????? (? ? ? : ? ? ? ? ? (?)), ...)<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature-wise Low and High-frequency Signals</head><p>Here we hope to explain low-frequency and high-frequency signals and their relationship to ego and aggregated features. Definition 5 (Low/High-frequency signals) According to the definition in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b49">50]</ref>, the low-frequency signal represents the similarity information between node features, and the high-frequency signal represents the difference information between node features. The greater the similarity of node feature information, the stronger the low-frequency signal transmitted, otherwise, the high-frequency signal dominates.</p><p>Actually, different features possess diverse characteristics and can not be directly compared. To explicitly model the diversity, we define low and high-frequency signals from a single feature dimension. As shown in Fig. <ref type="figure" target="#fig_3">3</ref>, taking a central node ? and any node ? as an example, the 1st/2nd-dim features with significant differences can be seen as existing high-frequency signals, while the 3rd-dim features exist as low-frequency signals. The agg features, which are the aggregated features from neighbor node ? and central node ?, smooth high-frequency signals and identify low-frequency signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MULTI-VIEW GRAPH ENCODER</head><p>MVGE is inspired by the approaches that explore the combination of multiple pretext tasks to learn different signals <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22]</ref>. This framework includes two novel pretext tasks supported with multi-view parallel AutoEncoders(Section 4.1), a novel solution to integrate embeddings from two views into one coherent semantic space(Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Separated Encoders for Different Views</head><p>Traditional self-supervised learning feeds different data augmentations into a single embedding space or two embedding spaces with shared parameters, which interferes with learning different features. Motivated by this limitation, our model learns to construct separated embedding subspaces for different views, which avoids mixing low frequency and high-frequency signals and allows for more expressiveness for different frequency signals. Furthermore, we devise two similar pretext tasks to learn signals from the two views for each encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Linear Encoder for Ego-features.</head><p>To preserve high-frequency information in ego features, we propose to replace the generic GCN encoder with a linear encoding scheme. As illustrated in Figure <ref type="figure" target="#fig_4">4</ref> in blue block, the ego features are encoded by two single layer MLP ? ? (?) and ? ? (?). Different from the standard GNN-based encoder, a single linear transformation of the features does not smooth the feature signal of the surrounding neighbors during propagation, thus maximizing the preservation of the high-frequency information of the nodes themselves and keeping node representations from becoming indistinguishable. Besides, similar to the "add skip connection" operation introduced in ResNet <ref type="bibr" target="#b10">[11]</ref>, which is later adopted in jumping knowledge networks for graph representation learning <ref type="bibr" target="#b41">[42]</ref>, we (2) concatenate the original inputs and the intermediate representations at the final layer, to preserve the integrity and personalization of the input information as much as possible.</p><p>4.1.2 GNN Encoder for Agg-features. For the aggregated features from neighbors, we want to learn the commonality among neighbors. Thus, we adopt a GCN encoder for the aggregated features. In general, GCN updates node representations by aggregating information from neighbors, which can be seen as a special form of low-pass filter <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b39">40]</ref> and can retain the commonality in the neighbors. As shown in Figure <ref type="figure" target="#fig_4">4</ref> in red block, the agg features are encoded by a two-layer GCN ? ? (?) and a single layer MLP ? ? (?). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Learning in Different</head><p>Views. Generally, the self-supervision task are normally use the reconstruction loss <ref type="bibr" target="#b36">[37]</ref> or the contrast loss <ref type="bibr" target="#b37">[38]</ref>. To capture both the low-frequency and high-frequency signals in the node attribute, we utilize Kullback-Leibler divergence <ref type="bibr" target="#b19">[20]</ref> and propose two feature reconstruction pretext tasks to learn signals from two views. Ego Feature Reconstruction. To capture low-frequency signals in the embedding, MVGE adopts the ego feature reconstruction pretext task from the ego feature view. This task is designed to recover the ego features ? ??? . As each node usually has its own specific feature vector, it usually has distinctive information that differs itself from other nodes. As pointed out by many previous GNNs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b48">49]</ref>, the integration of ego-features can help the embeddings keep high-frequency signals and prevent the node representation from tending to be similar during the model training process.</p><p>Specifically, we use ? ??? = ? ? (? ) to denote the output embedding of decoder ? ? . Aiming to pull closer to the representations from the original features, we use the ego feature reconstruction loss with the Kullback-Leibler divergence L ??? . L ??? calculate the distribution difference between ? ??? and ? ??? , where Q is the distribution of the reconstructed features ? ??? and ? ??? is the original distribution of ? ??? :   (2) Embeddings from the two tasks become similar in strong homophily settings while dissimilar in heterophily settings. In datasets with low homophily, nodes with different labels tend to be connected, and the nodes are very different from their surrounding neighbors. Thus, the ego embeddings are quite different from agg embeddings. In datasets with strong homophily(? ?????? = 0.9), the similarity between linked nodes is very high, and the feature difference between the connected node(high-frequency signals) is relatively less. Thus, as shown in Fig. <ref type="figure">5b</ref>, these two tasks generate almost identical distributions. Fig. <ref type="figure">5a</ref> and 5b clearly show that the two tasks can capture different types of signals.</p><formula xml:id="formula_4">L ??? = ??[? ??? ||? ??? ] = ?? ? ?? ? ? ??? ? ? ??? ? ??? ? ? ? ??? ? ?<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Integration of multiple semantic embeddings</head><p>Our model learns to capture low-frequency and high-frequency signals for node representations by constructing separate embedding spaces and introducing two pretext tasks. Although, as pointed in <ref type="bibr" target="#b45">[46]</ref>, learning with multiple tasks can generally improve performance compared to learning from a single task in CV, NLP, etc. However, simply using multiple pretext tasks in graph learning normally leads to unstable and poor performance in graphs <ref type="bibr" target="#b35">[36]</ref>. The key to this factor, we guess, is due to the fact that the learned embeddings from different pretext tasks are actually from different semantic spaces. It is hard for the ML classifier to use embeddings from different semantic spaces effectively.</p><p>In MVGE, although the ego-task and agg-task are similar as they are both based on the feature distribution reconstruction, their semantic meanings are still quite different. To bridge the gap between two semantic spaces of different pretext tasks, we propose one additional pretext task, the adjacency matrix reconstruction task, to seamlessly integrate the embeddings from two views. Another reason to introduce this pretext task is that we need to keep a certain graph structure while the two views are generally from the feature view and lack topology information. Adjacency Matrix Reconstruction. Specifically, as shown in Fig. <ref type="figure" target="#fig_4">4</ref> in purple blocks, we use a traditional inner product decoder ? to reconstruct the graph structure for link prediction, which is defined as:</p><formula xml:id="formula_5">? = ? (?? ? ) (<label>8</label></formula><formula xml:id="formula_6">)</formula><p>where ? is obtained by concatenating 'Ego Embeddings' and 'Agg Embeddings', ? denotes the reconstructed adjacency matrix, and ? (?) is a non-linear activation function -we use the sigmoid activation function in MVGE. This function determines the likelihood of pairwise nodes connected in ?. During the training phase, our goal is to iteratively minimize a reconstruction loss by capturing the similarity between ? and ?. Thus, the objective function L ? can be formulated as a cross-entropy loss:</p><formula xml:id="formula_7">L ? = - 1 ? 2 ? ?? ?=1 ? ?? ?=1 ? ? ? ??? ?? ? + (1 -? ? ? )???(1 -?? ? )<label>(9)</label></formula><p>Learning with three pretext tasks. To train our model end-to-end and learn node representations for downstream tasks, we jointly leverage both the ego and aggregated feature restoration loss and the adjacency matrix reconstruction loss. Thus, the overall object function is defined as:</p><formula xml:id="formula_8">L = ? (? L ??? + (1 -?)L ??? ) + (1 -?)L ?<label>(10)</label></formula><p>where we aim to minimize L during the optimization, and ? represents the weights that balance the L ??? and L ??? , ? is a balance factor that balances the averaged feature reconstruction loss and the adjacency matrix reconstruction loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We choose three graph analysis tasks, i.e., node classification, link prediction, and pairwise node classification, to evaluate the effectiveness of representations learned from graphs with different global homophily. And we demonstrate the superiority of MVGE by comparison with 9 stateof-the-art techniques. Furthermore, we show the significance of designs in MVGE through rich ablation studies. The experiments are performed based on 8 popular benchmark datasets with global homophily ratio ? ?????? ranging from strong heterophily to strong homophily and two synthetic datasets where we can control the homophily/heterophily level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Settings:</head><p>Datasets. Statistic details of those datasets are listed in Table <ref type="table" target="#tab_0">1</ref>.</p><p>? Cora, Citeseer, Pubmed, Cora_full <ref type="bibr" target="#b24">[25]</ref>: standard citation networks where nodes represent documents, edges are citation links, and features are the bag-of-words representation of the document.</p><p>? Chameleon <ref type="bibr" target="#b34">[35]</ref>: page-page networks in Wikipedia, where nodes represent articles from the English Wikipedia, edges reflect mutual links between them. Node features indicate the presence of particular nouns in the articles and the average monthly traffic. ? Cornell, Texas, Wisconsin <ref type="bibr" target="#b30">[31]</ref>: school department Web Page networks, where nodes represent web pages, and edges are hyperlinks between them. Node features are the bag-of-words representation of web pages. The web pages are manually classified into the five categories, student, project, course, staff, and faculty. ? Synthetic datasets. syn-cora and syn-products are two synthetic datasets where we can control the homophily/heterophily level <ref type="bibr" target="#b48">[49]</ref>. Node features are generated by sampling nodes with the same class label from real-world datasets Cora and ogb-products. Baselines. In comparative experiments, we compare MVGE with 9 self-supervised models with open source code, including two contrastive models learning from multi-views with several training objectives, MERIT and MVGRL, and one beyond homophily assumption, PairE. We aim to provide a rigorous and fair comparison between different models on each dataset by using the same dataset splits and training procedure. The introduction of the comparison method is as follows:</p><p>? DeepWalk <ref type="bibr" target="#b31">[32]</ref>: A GRL algorithm based on random walk, utilizing Word2Vec and optimizing node embeddings by matching the co-occurrence rates of nodes on short random walk paths over graphs. ? SAGE-U <ref type="bibr" target="#b7">[8]</ref>: An unsupervised variant of GraphSAGE generates node embeddings by sampling a fixed number of neighbors for each node and aggregating their features.</p><p>? DGI <ref type="bibr" target="#b37">[38]</ref>: A contrastive learning method via maximizing mutual information between local and global representations for embedding learning. ? GAE <ref type="bibr" target="#b18">[19]</ref>: The first algorithm to process graph-structured data with autoencoder, which captures the structural information of the graph by reconstructing the adjacency matrix.</p><p>? ARVGE <ref type="bibr" target="#b28">[29]</ref>: An autoencoder-based solution that augments GAE by adding an adversarial module on the obtained embeddings to learn more robust graph representations, thereby improving the model's performance on sparse and noisy graph data. ? P-GNN <ref type="bibr" target="#b43">[44]</ref>: A new class of GNNs for computing position-aware node embeddings, which capture positions/locations of nodes with respect to the anchor nodes by computing the distance of a given target node to each anchor-set. ? MERIT <ref type="bibr" target="#b15">[16]</ref>: A multi-view self-supervised model that learns node representations by enhancing Siamese self-distillation with multi-scale contrastive learning.</p><p>? MVGRL <ref type="bibr" target="#b9">[10]</ref>: A multi-view self-supervised model that learns node representations and graph level representations by contrasting structural views of graphs. ? PairE <ref type="bibr" target="#b21">[22]</ref>: A multi-task unsupervised model to preserve both information for homophily and heterophily by going beyond the localized node view and utilizing paired nodes entities with richer expression powers.</p><p>Experiment Settings. For MVGE and all state-of-the-art baselines, we use the Adam optimizer with a learning rate of 0.01, and the embedding dimension of both embeddings in MVGE and node embeddings for other benchmarks is fixed to 128. All models are run 10 times, and the experiment results are the mean values with standard deviation. Other parameters are set as the default settings in the corresponding papers. For the walk-based aggregated features in MVGE, we generate 3 random walk paths for each node and set them with deep walk lengths as 3, 5, and 10 respectively. We run 200 epochs for each trainning. Downstream Tasks. The experimental settings for different downstream tasks are as follows: Node classification. For this task, all the nodes are used in the embedding generation process.</p><p>To balance the effect of three reconstruction tasks, we perform Optuna <ref type="bibr" target="#b1">[2]</ref> for efficient hyperparameter search and tune ? and ? between 0 and 1 with a step size of 0.1. Then, the graph encoder is trained with the obtained loss weights. To evaluate the trained graph encoder, we adopt a linear evaluation protocol by training a separate logistic regression classifier on top of the learned node representations with the one-vs-rest strategy. For all of the datasets, we use 30% of nodes to construct the training set, while using the remaining nodes as the testing set. We repeat the experiments ten times and report the average Micro-F1-score with the standard deviation. Link prediction. The models are trained on an incomplete version of these datasets where parts of the citation links(edges) have been removed, while all node features are kept. Specifically, we use 15% existing links and an equal number of nonexistent links as test sets. The remaining 85% existing links and an equal number of randomly generated nonexistent links were used as the training set. Pairwise node classification. For the pairwise node classification task, we predict whether a pair of nodes belong to the same class or not. In this case, a pair of nodes that belong to the same class is a positive example and the label will be marked as 1 otherwise as 0 <ref type="bibr" target="#b43">[44]</ref>. Specifically, we randomly generate the same number of positive and negative samples and follow the same dataset split ratio as link prediction.</p><p>For both the link prediction task and pairwise node classification task, the paired node embeddings are calculated from the source and target node embedding with the L2 operator. We report the averaged ROC_AUC score with the standard deviation on the test set over 10 runs with different random seeds and train/test split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on Synthetic Datasets</head><p>Using synthetic graphs syn-cora and syn-products with various global homophily ratio ? ?????? , we show the effectiveness of MVGE and the significance of diverse pretext tasks through node classification comparison task and ablation studies of variants of MVGE. Performance comparison under different global homophily. Fig. <ref type="figure" target="#fig_9">6a</ref> shows the Micro-F1 score of node classification on syn-cora. While all models achieve near-perfect performance under strong homophily, the performance of baselines based on homophily assumptions, e.g., DGI and SAGE-U, significantly deteriorates under heterophily settings. In comparison, MVGE has the best overall performance, outperforming other baselines, especially in heterophily settings, while tying with other models in homophily. PairE, which encodes different signals in the embeddings, has more advantages than other baselines under heterophily settings but still has weak performance.  Impact of ego-task/agg-task under different global homophily. To discuss the performance impact of the two feature reconstruction tasks on downstream tasks under different global homophily, we conduct node classification on two synthetic benchmark syn-cora and syn-products. Fig. <ref type="figure" target="#fig_9">6</ref> shows the classification results at 30% training ratio. We can observe that the performance under the two feature reconstruction tasks is generally better than the single pretext task. It verifies the importance of integrating different information into node embeddings. On the other hand, comparing the effects of ego-task and agg-task, we can observe that for networks with strong heterophily, embeddings from ego-task generally achieve much better performance, even better than all-task in syn-cora with global homophily 0.1. In this graph, a node significantly differs from its neighbors. In this case, the agg-task might collect much noise that can perturb the learning process and deviate node representations from the ground truth. In comparison, the ego-task guarantees the basic facts by preserving the high-frequency signals of the nodes themselves. For networks with strong homophily, only the agg-task can achieve good performance. The reason is that the agg-task essentially enhances the low-frequency signals (similar parts) in the neighborhood information. Of course, due to the lack of labels during GRL, we actually do not know the actual trend of connectivity during embedding. Thus, it is important to use two pretext tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on real-world Datasets</head><p>In this section, we evaluate MVGE with three different downstream tasks. Each of them normally demands different types of information for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Results</head><p>on Node Classification Task. We report the overall node classification results in Table <ref type="table" target="#tab_1">2</ref>. We can observe from the table that MVGE outperforms all unsupervised baselines on all eight datasets with different global homophily. For example, in Cornell, MVGE achieves the average Micro-F1 score of 78.89%, and up to 12% relative performance improvements over the compared baselines.</p><p>Experiment results clearly show that MVGE can effectively retain rich signals during embeddings with its multi-view self-supervision design and the distribution-based reconstruction tasks that can keep both low-frequency and high-frequency signals in node features. Other baselines generally achieve good performance in the graphs with homophily while comparably poor performance in heterophily settings. There still exists a large performance gap compared with the models beyond homophily assumption. For example, the contrastive method MVGRL achieves 82.09% Micro-F1 score in Cora with strong homophily, while only 58.85% in Cornell with strong heterophily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Results</head><p>on Link Prediction task. Table <ref type="table" target="#tab_2">3</ref> shows the ROC_AUC scores of the link prediction task on all eight datasets. We can find that our model achieves state-of-the-art results with respect to unsupervised models in six out of eight datasets. For example, in Wisconsin, we achieve a 90.33% ROC_AUC score which is almost 4% relative improvement over the previous state-of-the-art. It attributes to the fact that we design an adjacency matrix reconstruction task to predict whether there is a link between two nodes directly. In addition, the random walk operation in data augmentation also captures the structural information of different local neighborhoods in the network to a certain extent. GAE and ARVGE, which adopt link reconstruction in the decoder, also achieve competitive performance under homophily settings. However, their homophily assumption making connected nodes with similar embeddings, these models fail to predict links accurately in heterophily settings, e.g., Cornell, Texas, and Wisconsin. In the pairwise node classification task, we believe that the implicit relationship of the pair is related to the low-and high-frequency information of the features of the paired nodes. In other words, two nodes with similar embeddings are more likely to fall into the same class. For paired nodes belonging to different classes, the embeddings of paired nodes should contain enough highfrequency information for classification. Results show that MVGE has a superior classification performance and can effectively differentiate nodes from different classes. While models based on homophily assumption are concerned with capturing the commonality of node features and inevitably ignore the difference. Their designs make rich relationship patterns become vague and indistinguishable in learned representation. Thus, their performance in graphs with heterophily is rather poor, e.g., DGI 59.88% and MGRL 59.95% v.s. MVGE 87.85%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Study</head><p>In this section, we analyze and verify the effectiveness of different designs.  and three variants, where ? 3 , ? 5 , and ? 10 denotes there is only single walk path in Eq. ( <ref type="formula" target="#formula_3">4</ref>) with different length respectively. We observe that MVGE consistently performs better than all the variants, indicating that the agg features obtained by combining multiple walk paths contain the richest information. (2) Furthermore, we consider compare the performance of MVGE with different ???? function in Eq. ( <ref type="formula" target="#formula_3">4</ref>), i.e., ?????? (?), ????(?), and ???(?). Fig. <ref type="figure">7c</ref> and<ref type="figure">7d</ref> show that the ?????? (?) generally achieves that best performance in all global homophily settings and significantly outperforms the others (????(?)) on syn-cora (? ?????? = 0.3) by up to 13%. These results support the effectiveness of the concatenation operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Effectiveness of Linear Encoder For Ego Features.</head><p>To verify the effectiveness of the linear encoder for ego features, we compare it with a variant of MVGE with two separated GCN encoders. Fig. <ref type="figure">8</ref> shows the node classification results in Micro-F1 score on syn-cora and syn-products with different global homophily. We observe that MVGE with linear encoder consistently performs better than the variant, existing a significantly bigger performance gap in strong heterophily settings. As a popular encoding scheme, the essence of GCN is a low-pass filter: each node repeatedly averages its own features and those of its neighbors to update its own feature representation <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b40">41]</ref>. This mechanism results in final embeddings that are similar across neighboring nodes for any set of original features <ref type="bibr" target="#b33">[34]</ref>. While this may work well in the case of homophily, where neighbors likely belong to the same class or have similar features, it poses severe challenges in the case of heterophily: it is not possible to distinguish neighbors from different labels based on the similar learned representations. In contrast, a simple linear encoding scheme for ego features can avoid smoothing high-frequency information in features and allow learning distinguishable representations. 5.4.3 Effectiveness of Adjacency Matrix Reconstruction Task. Fig. <ref type="figure" target="#fig_12">9</ref> gives the node classification and link prediction results of MVGE and a variant without the adjacency reconstruction task on two synthetic datasets. We observe similar trends on both two benchmarks and two downstream tasks: MVGE with adj-task almost has the best overall performance outperforming the variants without adj-task. Results clearly show the importance of merging embeddings with different semantic meanings. In addition, when the global homophily is rather high (0.9), ego embeddings and agg embeddings have very close semantics, which results in a comparably small performance gap between MVGE and its variant. In comparison, when with low global homophily, their performance gaps are generally large. Particularly, as shown in Fig. <ref type="figure" target="#fig_12">9a</ref>, since the purpose of adj-ask is to learn neighboring patterns between connected nodes, e.g., close representations, MVGE with adj-task is less effective than MVGE without adj-task in node classification under strong heterophily (0.1). Furthermore, as the adj-task is able to capture some important characteristics of the graph structure by reconstructing an adjacency matrix ? close to the true one starting from the node embeddings, the performance of link prediction is greatly improved. An interesting observation worth noting is that the performance gaps to be opposite in syn-cora and syn-products under strong heterophily (? ?????? =0.1). The three core designs involved in this article all have their unique roles: t1, Linear Encoder for Ego-features, to preserve high-frequency information in ego features; t2, GNN Encoder for Agg-features, to learn the commonality among neighbors; t3, Reconstruct the Adjacency Matrix, to learn the proximity of topological distances. t1 and t2 directly preserve the difference and commonality between node features, and their role is to make the distance between the node and its neighbors as consistent as possible in the original feature space and embedding space. While t3 only considers structural information, it is expected that structurally adjacent nodes will also maintain a relatively close distance in the embedding space.</p><p>Therefore, in some cases, the goals of the two will conflict, especially when there are sparse networks with high heterogeneity and low degree (such as syn-cora with heterophily=0.1 and degree = 3.9), at this time, the labels of the central node and its neighbors are all different with a high probability. In such a case, the t1/t2 task will maintain the characteristics of the node ? and the commonality with the neighborhood ? (?), which usually keeps the embeddings of ? and ? (?) highly distinguishable, while t3 will make the embeddings of ? and ? (?) are as similar as possible. At this time, there is a serious conflict between the learning goals of the two, which may cause confusion in learning. For syn-product, its degree is 11, so even if homophily=0.1, there may still be some similar nodes around the central node ?. Therefore, t1/t2 and t3 can better find consistent signals, and their collaborative learning can also effectively improve performance. We think this is what causes the performance gaps to be opposite in syn-cora and syn-products under strong heterophily (?=0.1). All in all, the impact of homophily level is closely related to the sparsity of the network (node degree), in heterophily, low-degree nodes pose stronger challenges in learning <ref type="bibr" target="#b48">[49]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Due to a lack of support from labels, graph representation learning methods normally make the homophily assumptions on the graph, which result in their poor performance in heterophily settings. Furthermore, one pretext task can hardly capture diverse graph information into taskagnostic embeddings without label supervision. In this paper, we present a novel multi-view graph representation framework MVGE with the usage of diverse pretext tasks to capture different signals in graphs into embeddings. More specifically, a set of new pretext tasks are designed to encode different types of signals, and a straightforward operation is proposed to maintain both the commodity and personalization in both the attribute and the structural levels. Extensive experiments on both synthetic and real-world network datasets show that the node representations learned with MVGE achieve significant performance improvements in different downstream tasks, especially on graphs with heterophily.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Global homophily of different real-world datasets. (b) Local homophily of Pubmed and Wisconsin. (c)-(d) Node Classification accuracy under homophily/heterophily settings. 'ego' and 'agg' denote ego feature reconstruction and aggregated feature reconstruction respectively.</figDesc><graphic url="image-1.png" coords="2,49.98,253.31,94.64,67.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. DeepWalk-based feature aggregation</figDesc><graphic url="image-5.png" coords="6,47.80,419.59,134.07,122.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Different colors denote different dimensions of features. Different values represent high-frequency signals in this dimension, otherwise lowfrequency signals.</figDesc><graphic url="image-6.png" coords="7,315.95,88.66,110.42,62.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Overall framework of MVGE. MVGE tasks two augmentation views as input, i.e., ego features ? ??? ? with high-frequency signals and aggregated features ? ??? with low-frequency signals. From these two views, we design two feature reconstruction pretext tasks with KL loss. By employing two separated encoders, MVGE generate embeddings including different semantic information: (1) linear encoder for ? ??? ? , with two single layer MLP ? ? (?) and ? ? (?); and (2) GNN encoder for ? ??? , with a two-layer GCN ? ? (?) and a single layer MLP ? ? (?); (3) Similar to the "add skip connections" operation, we 'concat' the inputs and the intermediate representation at the final layer. With the above preparations, MVGE starts the training process controlled by three terms loss function. ? ? and ? ? denotes a linear layer-based decoder. ? ? is an inner product decoder.</figDesc><graphic url="image-7.png" coords="8,65.55,84.68,354.90,200.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>, Vol. 1 ,</head><label>1</label><figDesc>No. 1, Article . Publication date: April 2023. where ? represents the ?-th node in V, ? represents the ?-th feature. ? ??? ? ? and ? ??? ? ? are the distribution possibility and the target distribution of the ?-th features of the ?-th node, respectively: Aggregated Feature Reconstruction. Similar to the ego feature reconstruction task, this task reconstructs the aggregated features ? ??? and uses a loss function based on KL divergence: L ??? = ??[? ??? ||? ??? ] = ?? and ? ??? ? ? can be calculated as the same way like ? ??? ? ? and ? ??? ? ? . By reconstructing the smoothed node neighborhood features, the model can capture lowfrequency information, which helps avoid node representations deviating from reality in multiple rounds of learning guided by self-feature reconstruction tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4. 2</head><label>2</label><figDesc>Learning different signals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>9 Fig. 5 .</head><label>95</label><figDesc>Fig. 5. Embedding distribution of syn-cora dataset under different global homophily in the first dimension.Others have similar distributions Fig.5shows the embedding distributions in the first dimension generated by respective feature reconstruction tasks on the syn-cora with low (0.1) and high (0.9) homophily ratios. As we can see from this figure, as the NN optimizer algorithms normally generate weights according to Gaussian distribution, all those embeddings basically follow a Gaussian distribution, however, with different standard deviations ?.Here, we can observe two important facts. 1) Under different global homophily, ? ??? is bigger than ? ??? . This result demonstrates that the ego feature reconstruction task preserves more high-frequency signals. In comparison, in the aggregated feature reconstruction task, due to its smoothing operations in both deepwalk generation and GCN, the embeddings generated by the agg-task mainly contain low-frequency signals with small ?. (2) Embeddings from the two tasks become similar in strong homophily settings while dissimilar in heterophily settings. In datasets with low homophily, nodes with different labels tend to be connected, and the nodes are very different from their surrounding neighbors. Thus, the ego embeddings are quite different from agg embeddings. In datasets with strong homophily(? ?????? = 0.9), the similarity between linked nodes is very high, and the feature difference between the connected node(high-frequency signals) is relatively less. Thus, as shown in Fig.5b, these two tasks generate almost identical distributions. Fig.5aand 5b clearly show that the two tasks can capture different types of signals.</figDesc><graphic url="image-8.png" coords="9,245.70,303.57,94.64,64.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>, Vol. 1 ,</head><label>1</label><figDesc>No. 1, Article . Publication date: April 2023.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Node classification results on synthetic datasets with different global/local homophily. (a)-(c) shows the classification performance of the existing typical GRL method on syn-cora. (d)-(e) are the ablation analysis of ego task and agg task.</figDesc><graphic url="image-13.png" coords="13,115.56,193.05,126.19,89.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>5. 4 . 1</head><label>41</label><figDesc>Design choices for walk-based aggregated features. This subsection analyzes and evaluates the contribution of multiple random walk paths and impacts of different aggregators in Definition 4 based on node classification on synthetic datasets. (1) Fig. 7a and 7b shows the results for MVGE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. (a)-(b): performance of MVGE for different number of random walk path. (c)-(d): performance of MVGE for different aggregated function.</figDesc><graphic url="image-19.png" coords="16,72.68,217.87,144.92,100.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Effect of the adj-task. (a)/(b) Node classification results on syn-cora and syn-products. (c)/(d) Link prediction results on syn-cora and syn-products.</figDesc><graphic url="image-24.png" coords="17,341.38,85.26,94.64,77.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Cp. between different functions in merging ego and agg embeddings on six real-world datasets.</figDesc><graphic url="image-25.png" coords="18,124.70,121.76,236.60,93.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>5. 4 . 4</head><label>44</label><figDesc>Functions in merging ego and agg embeddings. To validate the effectiveness of the concatenation operation for learned representations, we conduct experiments on six datasets for three MVGE variants with different functions to merge the ego embeddings and agg embeddings, i.e., ?????? (?), ???(?) and ????(?). Fig.10shows the node classification results under 30% training ratio. We can observe that ?????? ? function achieves the best performance in all six datasets under different global homophily, as ?????? (?) function can keep the integrity and personalization of the input information as much as possible, and avoid losses caused by information mixing. The performance of the other two aggregator functions is relatively unstable. Specifically, the ???(?) function generally achieves better performance than the ????(?) function. The embedding accumulation operation of ???(?) can, to a certain extent, preserve the degree information of nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The statistics of the datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Nodes Edges Features Classes</cell><cell>? ??????</cell></row><row><cell>Cora</cell><cell>2,708</cell><cell>5,278</cell><cell>1,433</cell><cell>7</cell><cell>0.81</cell></row><row><cell>Citeseer</cell><cell>3,327</cell><cell>4,676</cell><cell>3,703</cell><cell>6</cell><cell>0.74</cell></row><row><cell>Pubmed</cell><cell cols="2">19,717 44,327</cell><cell>500</cell><cell>3</cell><cell>0.8</cell></row><row><cell>Cora_full</cell><cell cols="2">19.793 63,421</cell><cell>8710</cell><cell>70</cell><cell>0.57</cell></row><row><cell>Chameleon</cell><cell cols="2">2,277 31,371</cell><cell>2325</cell><cell>5</cell><cell>0.23</cell></row><row><cell>Cornell</cell><cell>183</cell><cell>277</cell><cell>1,703</cell><cell>5</cell><cell>0.3</cell></row><row><cell>Texas</cell><cell>183</cell><cell>279</cell><cell>1,703</cell><cell>5</cell><cell>0.11</cell></row><row><cell>Wisconsin</cell><cell>251</cell><cell>450</cell><cell>1,703</cell><cell>5</cell><cell>0.21</cell></row><row><cell>syn-cora</cell><cell>1,490</cell><cell>2,968</cell><cell>1,433</cell><cell>5</cell><cell>[0.1,0.3,0.5,0.7,0.9]</cell></row><row><cell cols="3">syn-products 10,000 59,648</cell><cell>101</cell><cell>10</cell><cell>[0.1,0.3,0.5,0.7,0.9]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Node classification results, evaluated with average Micro-F1, bold font represent the best results. "-" denotes that the model can not finish the training in 5 days.</figDesc><table><row><cell>Name</cell><cell>Cora</cell><cell>Citeseer</cell><cell>Pubmed</cell><cell cols="2">Cora_full Chameleon</cell><cell>Cornell</cell><cell>Texas</cell><cell>Wisconsin</cell></row><row><cell>Hom.ratio</cell><cell>0.81</cell><cell>0.74</cell><cell>0.8</cell><cell>0.57</cell><cell>0.23</cell><cell>0.3</cell><cell>0.11</cell><cell>0.21</cell></row><row><cell>DeepWalk</cell><cell cols="4">80.05?5.74 56.02?10.14 79.80?3.66 37.44?3.73</cell><cell>24.16?0.17</cell><cell cols="3">48.67?27.84 47.00?29.28 48.67?27.84</cell></row><row><cell>SAGE-U</cell><cell cols="4">80.18?9.85 71.34?4.32 83.82?3.01 55.77?1.54</cell><cell>42.90?9.27</cell><cell cols="2">48.18?13.61 61.27?11.93</cell><cell>60.00?8.43</cell></row><row><cell>DGI-gcn</cell><cell cols="4">81.28?7.58 68.94?9.10 83.11?1.50 43.46?1.66</cell><cell>42.90?7.33</cell><cell cols="3">38.73?11.93 77.82?18.31 60.00?22.31</cell></row><row><cell>GAE</cell><cell cols="4">78.20?4.61 56.32?7.89 81.89?1.87 54.96?1.68</cell><cell>39.45?5.56</cell><cell cols="3">63.09?9.87 59.09?16.26 54.67?21.33</cell></row><row><cell>ARVGE</cell><cell cols="4">79.06?7.94 60.42?10.01 71.50?3.18 45.11?2.21</cell><cell>41.61?6.11</cell><cell cols="3">54.33?30.27 50.33?28.20 54.42?21.84</cell></row><row><cell>P-GNN</cell><cell cols="4">63.60?10.28 46.92?6.04 69.08?2.42 46.12?2.16</cell><cell>33.85?6.67</cell><cell cols="2">53.89?11.17 57.80?6.78</cell><cell>49.33?9.49</cell></row><row><cell>MERIT</cell><cell cols="3">41.80?1.46 68.13?0.23 85.05?0.10</cell><cell>-</cell><cell>26.50?0.54</cell><cell cols="2">30.46?4.79 66.90?13.09</cell><cell>54.66?5.33</cell></row><row><cell>MVGRL</cell><cell cols="4">82.09?5.25 62.64?4.41 80.12?1.71 52.99?2.04</cell><cell>41.19?6.64</cell><cell cols="3">58.85?16.79 62.22?18.33 60.13?18.75</cell></row><row><cell>PairE</cell><cell cols="4">86.51?8.52 72.14?2.53 85.73?2.34 61.02?0.95</cell><cell>45.52?3.37</cell><cell>66.73?7.77</cell><cell>61.51?4.86</cell><cell>68.00?9.98</cell></row><row><cell>MVGE</cell><cell cols="8">86.95?2.40 75.35?0.95 86.82?0.85 66.90?1.98 45.68?1.79 78.89?9.19 81.27?10.05 79.33?9.10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Link prediction task, measured in ROC_AUC. Standard deviation errors are given. bold font respectively represent the best results in all algorithms. "-" is similar to Table2</figDesc><table><row><cell>Name</cell><cell>Cora</cell><cell>Citeseer</cell><cell>Pubmed</cell><cell cols="2">Cora_full Chameleon</cell><cell>Cornell</cell><cell>Texas</cell><cell>Wisconsin</cell></row><row><cell cols="5">DeepWalk 74.35?0.83 77.79?0.53 72.84?0.71 86.69?0.27</cell><cell>74.23?0.59</cell><cell cols="2">55.97?4.28 55.39?5.41</cell><cell>66.69?2.94</cell></row><row><cell>SAGE-U</cell><cell cols="4">89.97?0.39 92.44?0.22 87.97?0.23 95.73?0.04</cell><cell>82.64?0.64</cell><cell cols="2">75.98?4.60 63.91?2.53</cell><cell>77.21?2.86</cell></row><row><cell>DGI-gcn</cell><cell cols="4">83.70?1.00 85.74?2.24 84.57?0.33 79.20?0.56</cell><cell>82.22?0.44</cell><cell cols="2">82.98?3.52 83.81?2.90</cell><cell>84.34?1.99</cell></row><row><cell>P-GNN</cell><cell cols="4">82.17?0.04 77.91?1.44 82.76?0.17 90.05?0.15</cell><cell>87.60?0.80</cell><cell cols="3">48.15?7.08 48.21?12.37 64.07?1.11</cell></row><row><cell>GAE</cell><cell cols="4">91.18?0.58 88.00?0.93 96.41?0.11 96.92?0.10</cell><cell>98.48?0.09</cell><cell cols="2">47.16?3.58 43.56?2.63</cell><cell>54.11?3.39</cell></row><row><cell cols="5">ARVGAE 92.14?0.24 89.08?0.47 92.04?1.21 95.82?0.61</cell><cell>97.82?0.16</cell><cell cols="2">56.70?3.12 48.96?2.56</cell><cell>75.38?1.62</cell></row><row><cell>MERIT</cell><cell cols="3">85.84?0.10 61.95?0.32 63.90?0.23</cell><cell>-</cell><cell>52.44?1.38</cell><cell cols="2">70.11?1.36 56.25?5.86</cell><cell>53.64?3.30</cell></row><row><cell>MVGRL</cell><cell cols="4">84.52?1.47 60.38?2.23 80.91?1.35 78.59?0.96</cell><cell>80.72?0.55</cell><cell cols="2">75.05?5.84 81.17?6.50</cell><cell>76.08?6.95</cell></row><row><cell>PairE</cell><cell cols="4">92.92?0.41 95.10?0.20 94.98?0.23 96.91?0.09</cell><cell>93.63?0.27</cell><cell cols="2">80.57?2.47 83.89?1.56</cell><cell>86.47?2.64</cell></row><row><cell>MVGE</cell><cell cols="4">94.86?0.31 95.36?0.16 96.20?0.06 97.72?0.04</cell><cell>94.76?0.08</cell><cell cols="3">85.15?1.46 84.58?1.38 90.33?1.50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>pair-wise prediction task, measured in ROC_AUC. Standard deviation errors are given. bold font respectively represent the best results in all algorithms. "-" is similar to Table2Results on Pair-wise Prediction task. Table4summarizes the performance of MVGE and other baselines on pairwise node classification tasks, where MVGE gains the best classification accuracy on all eight datasets. Specifically, MVGE achieves 89.89% ROC_AUC score while the previous state-of-the-art method MERIT can only achieve 72.74% ROC_AUC, which means that MVGE gives about 15% relative improvement on this task.</figDesc><table><row><cell>Name</cell><cell>Cora</cell><cell>Citeseer</cell><cell>Pubmed</cell><cell cols="2">Cora_full Chameleon</cell><cell>Cornell</cell><cell>Texas</cell><cell>Wisconsin</cell></row><row><cell cols="5">DeepWalk 60.37?1.24 53.05?1.47 53.05?0.27 61.91?0.51</cell><cell>58.20?0.61</cell><cell cols="3">52.58?3.19 60.57?3.95 52.50?1.78</cell></row><row><cell>SAGE-U</cell><cell cols="4">57.17?1.53 50.85?1.65 50.47?0.18 53.34?0.59</cell><cell>50.18?0.61</cell><cell cols="3">70.49?4.07 71.73?4.30 71.23?1.69</cell></row><row><cell>DGI-gcn</cell><cell cols="4">62.81?1.33 51.99?1.42 58.43?1.82 53.71?1.58</cell><cell>49.72?0.40</cell><cell cols="3">65.45?3.88 71.44?4.39 59.88?1.52</cell></row><row><cell>GAE</cell><cell cols="4">75.84?2.87 65.09?1.14 76.28?1.00 86.91?0.06</cell><cell>57.78?0.86</cell><cell cols="3">53.51?2.30 56.23?4.24 52.49?5.16</cell></row><row><cell cols="5">ARVGAE 77.38?1.43 64.75?1.77 73.28?1.11 85.91?0.56</cell><cell>60.90?0.30</cell><cell cols="3">53.62?4.98 57.99?8.63 57.63?4.53</cell></row><row><cell>P-GNN</cell><cell cols="4">66.40?0.83 58.07?0.98 61.69?0.20 74.18?0.32</cell><cell>58.47?0.55</cell><cell cols="3">51.97?4.49 52.73?3.53 49.32?1.88</cell></row><row><cell>MERIT</cell><cell cols="3">67.08?1.12 53.67?0.81 60.23?0.31</cell><cell>-</cell><cell>51.04?0.25</cell><cell>72.74?1.28</cell><cell>69.7?1.46</cell><cell>63.25?3.87</cell></row><row><cell>MVGRL</cell><cell cols="4">81.49?0.58 64.03?0.64 81.62?1.00 90.10?0.20</cell><cell>57.62?1.02</cell><cell cols="3">62.47?6.58 71.17?1.13 59.95?5.58</cell></row><row><cell>PairE</cell><cell cols="4">66.54?1.46 60.95?0.96 69.67?0.63 73.64?0.72</cell><cell>58.64?0.67</cell><cell cols="3">72.62?3.51 71.89?4.40 73.56?2.95</cell></row><row><cell>MVGE</cell><cell cols="8">83.25?0.49 79.61?0.56 84.13?0.03 90.21?0.11 60.97?0.29 87.89?0.46 85.61?0.53 87.85?1.54</cell></row><row><cell>5.3.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>, Vol. 1, No. 1, Article . Publication date: April 2023.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">ACKNOWLEDGEMENTS</head><p>This work was supported by the <rs type="funder">Science and Technology Research and Development Program Project of China railway group</rs> limited (Project Nos. <rs type="grantNumber">2020-Special-02</rs> and <rs type="grantNumber">2021-Special-08</rs>). The computing resources supporting this work were partially provided by <rs type="institution">High-Flyer AI. (Hangzhou High-Flyer AI Fundamental Research Co</rs>., Ltd.)</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AKqNrPn">
					<idno type="grant-number">2020-Special-02</idno>
				</org>
				<org type="funding" xml:id="_M4TESxm">
					<idno type="grant-number">2021-Special-08</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</title>
		<author>
			<persName><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Ver Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optuna: A next-generation hyperparameter optimization framework</title>
		<author>
			<persName><forename type="first">Takuya</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shotaro</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshihiko</forename><surname>Yanase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takeru</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2623" to="2631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Deyu</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00797</idno>
		<title level="m">Beyond low-frequency information in graph convolutional networks</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Adaptive universal generalized pagerank graph neural network</title>
		<author>
			<persName><forename type="first">Eli</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olgica</forename><surname>Milenkovic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07988</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Inductive representation learning on large graphs. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05584</idno>
		<title level="m">Representation learning on graphs: Methods and applications</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Contrastive multi-view representation learning on graphs</title>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hosein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khasahmadi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4116" to="4126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning canonical representations for scene graph to image generation</title>
		<author>
			<persName><forename type="first">Roei</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="210" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06670</idno>
		<title level="m">Learning deep representations by mutual information estimation and maximization</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Measuring and improving the use of graph information in graph neural networks</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaili</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard Tb</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Chang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Junteng</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austin</forename><surname>Benson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08274</idno>
		<title level="m">Outcome correlation in graph neural network regression</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multi-scale contrastive siamese networks for self-supervised graph representation learning</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan-Fang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05682</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Automated self-supervised learning for graphs</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05470</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<title level="m">Variational graph auto-encoders</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Information theory and statistics</title>
		<author>
			<persName><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Courier Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Label efficient semi-supervised learning via graph filtering</title>
		<author>
			<persName><forename type="first">Qimai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Ming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9582" to="9591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graph Representation Learning Beyond Node and Homophily</title>
		<author>
			<persName><forename type="first">You</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Gui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods</title>
		<author>
			<persName><forename type="first">Derek</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hohne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Sijia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaishnavi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omkar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Bhalerao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="20887" to="20902" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dual attentive graph neural network for metro passenger flow prediction</title>
		<author>
			<persName><forename type="first">Yuhuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongliang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqian</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaocheng</forename><surname>Nn Sze</surname></persName>
		</author>
		<author>
			<persName><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="13417" to="13431" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Query-driven active surveying for collective classification</title>
		<author>
			<persName><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><surname>Edu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">th International Workshop on Mining and Learning with Graphs</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Networks</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Oxford university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mixing patterns in networks</title>
		<author>
			<persName><surname>Mark Ej Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">26126</biblScope>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Revisiting graph neural networks: All we have is low-pass filters</title>
		<author>
			<persName><forename type="first">Hoang</forename><surname>Nt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takanori</forename><surname>Maehara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09550</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04407</idno>
		<title level="m">Adversarially regularized graph autoencoder for graph embedding</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiscale mixing patterns in networks</title>
		<author>
			<persName><forename type="first">Leto</forename><surname>Peel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Charles</forename><surname>Delvenne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renaud</forename><surname>Lambiotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="4057" to="4062" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Hongbin</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingzhe</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Chen-Chuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05287</idno>
		<title level="m">Geom-gcn: Geometric graph convolutional networks</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">struc2vec: Learning node representations from structural identity</title>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Hp</forename><surname>Leonardo Fr Ribeiro</surname></persName>
		</author>
		<author>
			<persName><surname>Saverese</surname></persName>
		</author>
		<author>
			<persName><surname>Daniel R Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On proximity and structural role-based embeddings in networks: Misconceptions, techniques, and applications</title>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nesreen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Koutra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Boaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-scale attributed node embedding</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Benedek Rozemberczki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rik</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Complex Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Which tasks should be learned together in multi-task learning</title>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Standley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9120" to="9132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deep Graph Infomax. ICLR (Poster)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Haonan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.04874</idno>
		<title level="m">Augmentation-Free Graph Contrastive Learning</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Graph convolutional networks using heat kernel for semi-supervised learning</title>
		<author>
			<persName><forename type="first">Bingbing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huawei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.16002</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Keting Cen, and Xueqi Cheng</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomohiro</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5453" to="5462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Network representation learning with rich text information</title>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-fourth international joint conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Position-aware graph neural networks</title>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7134" to="7143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">ProNE: Fast and Scalable Network Representation Learning</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="4278" to="4284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A survey on multi-task learning</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07082</idno>
		<title level="m">Graph Neural Networks for Graphs with Heterophily: A Survey</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Daniele Grattarola, and Jun Pang. 2022. Unsupervised Heterophilous Network Embedding via ? -Ego Network Discrimination</title>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guadalupe</forename><surname>Gonzalez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.10866</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Beyond homophily in graph neural networks: Current limitations and effective designs</title>
		<author>
			<persName><forename type="first">Jiong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7793" to="7804" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Interpreting and unifying graph neural networks with an optimization framework</title>
		<author>
			<persName><forename type="first">Meiqi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1215" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
