<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Wang</surname></persName>
							<email>yifanwang@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Suyao</forename><surname>Tang</surname></persName>
							<email>tangsuyao@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Yuntong</forename><surname>Lei</surname></persName>
							<email>leiyunton@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Weiping</forename><surname>Song</surname></persName>
							<email>songweiping@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Sheng</forename><surname>Wang</surname></persName>
							<email>swang@cs.washington.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">Paul G. Allen School of Computer Science</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DisenHAN: Disentangled Heterogeneous Graph Attention Network for Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3340531.3411996</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Collaborative Filtering</term>
					<term>Heterogeneous Information Network</term>
					<term>Graph Neural Network</term>
					<term>Disentangled Representation Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Heterogeneous information network has been widely used to alleviate sparsity and cold start problems in recommender systems since it can model rich context information in user-item interactions. Graph neural network is able to encode this rich context information through propagation on the graph. However, existing heterogeneous graph neural networks neglect entanglement of the latent factors stemming from different aspects. Moreover, meta paths in existing approaches are simplified as connecting paths or side information between node pairs, overlooking the rich semantic information in the paths. In this paper, we propose a novel disentangled heterogeneous graph attention network DisenHAN for top-ùëÅ recommendation, which learns disentangled user/item representations from different aspects in a heterogeneous information network. In particular, we use meta relations to decompose highorder connectivity between node pairs and propose a disentangled embedding propagation layer which can iteratively identify the major aspect of meta relations. Our model aggregates corresponding aspect features from each meta relation for the target user/item. With different layers of embedding propagation, DisenHAN is able to explicitly capture the collaborative filtering effect semantically. Extensive experiments on three real-world datasets show that Dis-enHAN consistently outperforms state-of-the-art approaches. We further demonstrate the effectiveness and interpretability of the learned disentangled representations via insightful case studies and visualization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommender systems play an important role for guiding a user in a personalized way of discovering interested products from overwhelming alternatives. Collaborative filtering (CF) based methods (e.g., matrix factorization <ref type="bibr" target="#b17">[18]</ref>) have been extensively used for recommendation, assuming users who have made similar choices tend to have similar preferences in the future. Since CF based methods usually suffer from the sparsity of user-item interactions and the cold start problems, many methods integrate other context information by transforming the interaction into a feature-rich data instance for user and item. These instances are then used by supervised learning models to predict the score <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>. However, these methods always treat each user-item record as an independent instance and overlook the relations among them.</p><p>Heterogeneous information network (HIN), which consists of multiple types of nodes and/or links, is flexible to model the heterogeneity and complexity of user-item interactions with rich context information. In particular, meta path, a composite relation connecting node pairs in HIN, is widely used to capture the relevant semantic of two nodes. Recent efforts using HIN for recommendation represent each user, item and context entity as nodes with different types and can be categorized into two types. The first type leverages meta paths or knowledge-aware embeddings to encode the relatedness between users and items, and the relatedness are subsequently used to enhance the performance of recommendation <ref type="bibr">[1, 4, 14, 25-27, 40, 42, 43]</ref>. The second type, as a comparison, due to the powerful representation ability of graph neural networks (GNNs), directly uses GNNs framework to obtain better user and item representations by aggregating neighborhood information <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref>.</p><p>However, these studies share several common limitations. First, most of these works fail to disentangle the latent factors. As a toy example shown in Figure <ref type="figure" target="#fig_0">1</ref>, the characteristics of Electronic products stem from several aspects. Since various types of connections reflect distinct aspects of a node, it is more natural and suitable to learn disentangled representations instead of preserving the confounding of the factors in HIN. Second, previous works directly simplify meta paths as side information or connecting paths, neglecting the specific influences for each factor. In fact, different semantic relations have specific influence to the corresponding disentangled factors. For example, users have bought this product, reflecting the product is popular with certain groups; the product is laptop, which is suitable for office crowds; the brand is Apple and welcomed by the fans. Third, because of the above two points, these methods lead to non-robustness and low interpretability, i.e., they cannot explicitly model user preferences on the item with specific characteristics. Thus, it is suitable to learn disentangled representations in HIN for recommendation. Particularly, user and item's representation can be disentangled into the same aspects. By calculating matching score of the target user and item in different aspects, user preferences on the item with specific characteristics can be explicitly modeled.</p><p>In this paper, we propose a novel Disentangled Heterogeneous Graph Attention Network (DisenHAN) for recommendation. Instead of exploiting entangled influential factors, our proposed approach explicitly models factors from different aspects and corresponding influence from semantic relations. Specifically, we represent user-item interactions with rich context information as a HIN, which consists different types of nodes and corresponding relations between node pairs. Given the node features as input, we project them into different embedding places and propose a semantic embedding propagation layer to identify the major aspect of the information flows in the relations, viewed as an iterative clustering process in the embedding space. Moreover, instead of designing meta paths manually, we take one-hop relations of nodes and use the attention mechanism to softly generate meta paths. By stacking multiple embedding propagation layers, each type of nodes especially users and items aggregate embeddings from different meta paths to capture the semantic information in high-order connectivity.</p><p>To summarize, in this paper we make the following contributions:</p><p>‚Ä¢ We propose to learn the disentangled representations with different aspects in HIN for recommendation. To the best of our knowledge, this is the first attempt to study the heterogeneous graph neural network on disentangled representations. And the proposed mechanism can be potentially generalized to other HIN based applications. ‚Ä¢ We propose a disentangled embedding propagation layer, which can iteratively identify the major aspect of the relation between node pairs and propagate corresponding information semantically. Moreover, we make the model more practical by automatically extract meta paths. ‚Ä¢ We conduct extensive experiments on several real-world data sets to evaluate the proposed approach. Experimental results demonstrate that our approach not only outperforms the existing state-of-the-art models, but also has outstanding interpretability for recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We review existing works on three lines of fields: 1) HIN based CF Methods, 2) Graph Neural Networks, 3) Disentangled Representation Learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">HIN based CF Methods</head><p>HIN based CF methods have been proposed to avoid disparate treatment of each user-item interaction with rich context information.</p><p>Especially meta paths in HIN, which are described as semantic relations between nodes pairs, can be defined by the network schema and used for recommendation. Shi et al. <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> calculate the meta path based similarities between users, and infer the rating score based on similar users. Yu et al. <ref type="bibr" target="#b39">[40]</ref> and Zhao et al. <ref type="bibr" target="#b42">[43]</ref> employ various types of meta paths between users and items in matrix factorization to generate latent features for recommendation. Shi et al. <ref type="bibr" target="#b24">[25]</ref> and Hu et al. <ref type="bibr" target="#b13">[14]</ref> explicitly extract meta paths connecting users to items and integrate the representation of meta paths to improve recommendation. Han et al. <ref type="bibr" target="#b9">[10]</ref> extract aspect-level factors from different meta paths and fuse the factors with attention mechanism for recommendation. However, defining effective meta paths require domain knowledge and is traditionally labor-intensive. Since knowledge graph (KG) can be seen as a special HIN, some works also leverage knowledge-aware embedding to guide the representation of items. Ai et al. <ref type="bibr" target="#b0">[1]</ref> learn the knowledge graph embeddings to find connection paths between users and items. Cao et al. <ref type="bibr" target="#b3">[4]</ref> and Zhang et al. <ref type="bibr" target="#b41">[42]</ref> jointly learn latent representations in CF as well as items' semantic representations from KG. However, due to the lack of explicit encoding CF signals, which reveal behavior similarity of users/items, high order connectivity is hard to be captured <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Neural Networks</head><p>Graph neural networks (GNNs) , especially gated graph neural network (GGNN) <ref type="bibr" target="#b18">[19]</ref>, graph convolutional network (GCN) <ref type="bibr" target="#b16">[17]</ref>, graph inductive representation learning (GraphSAGE) <ref type="bibr" target="#b8">[9]</ref> and graph attention network (GAT) <ref type="bibr" target="#b31">[32]</ref>, have been attracting considerable attention recently. The key idea behind GNNs is aggregating features from nodes' neighbors via neural network. Compared to the traditional graph embedding models, the explicit and end to end manner exploiting high-order connectivity information in graph is suitable for the down-stream tasks, especially for recommendation. For example, GC-MC <ref type="bibr" target="#b29">[30]</ref> and NGCF <ref type="bibr" target="#b36">[37]</ref> leverage GNNs in user-item bipartite graph to CF. KGAT <ref type="bibr" target="#b35">[36]</ref>, KGCN <ref type="bibr" target="#b34">[35]</ref> and KGCN-LS <ref type="bibr" target="#b33">[34]</ref> Full Paper Track CIKM '20, October 19-23, 2020, Virtual Event, Ireland extend items to knowledge graph, and utilize GNNs to strengthening items' representations. Although these works leverage GNNs for recommendation, they directly aggregate information from different types of nodes and ignore corresponding semantic relations. Recently, some HIN based GNNs are proposed for information propagation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41]</ref>, but still overlook the different aspects of semantic information between nodes pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Disentangled Representation Learning</head><p>Disentangled representation learning, which aims to learn representations that separate explanatory factors of variations behind the data <ref type="bibr" target="#b2">[3]</ref>, has recently gained much attention. Not only such representations are demonstrated to be more robust, i.e., bring enhanced generalization ability as well as improved robustness to adversarial attack <ref type="bibr" target="#b1">[2]</ref>, but also make the downstream process more interpretable which can directly find applications in various fields with semantic data, such as images <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13]</ref>, texts <ref type="bibr" target="#b15">[16]</ref> and user behaviors <ref type="bibr" target="#b21">[22]</ref>. For graph-structure data, GAT performs multi-head attention to jointly attend information from different representation subspaces <ref type="bibr" target="#b31">[32]</ref>, while treats each subspace equally, and can be seen as a special case of disentangled representation learning. PolyDeepwalk <ref type="bibr" target="#b19">[20]</ref> notices multiple aspects of nodes, but learns the disentangled embeddings in separate two stages. Inspired by the capsule neural network (CapsNet) <ref type="bibr" target="#b23">[24]</ref>, some works replace scalar-valued neurons with vector-valued ones to learn disentangled node representations with GNNs' framework in homogeneous network <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref>. Our work focus on learning disentangled representation in HIN, a more complicated data structure with different node types and relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>In this section, we first introduce some important concepts related to HIN, meta path and meta relation. Next we give some formal definitions of our problem. Definition 3.1. Heterogeneous Information Network. A heterogeneous information network is defined as G = (V, E) with a node type mapping function ùúô : V ‚àí ‚Üí A and an edge type mapping function ùúì : E ‚àí ‚Üí R, where each node ùë£ ‚àà V and edge ùëí ‚àà E belong to one particular type in the corresponding node type set A : ùúô (ùë£) ‚àà A and edge type set R : ùúì (ùëí) ‚àà R. Heterogeneous information networks have the property that |A| + |R| &gt; 2.</p><p>Definition 3.2. Meta Path and Meta Relation. A meta path is defined as a path in the form of A 1</p><formula xml:id="formula_0">R 1 ‚àí ‚àí ‚Üí A 2 R 2 ‚àí ‚àí ‚Üí . . . R ùëô ‚àí ‚àí ‚Üí A ùëô+1 (abbreviated as A 1 A 2 . . . A ùëô+1 ), which describes a composite rela- tion R 1 ‚Ä¢ R 2 ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ R ùëô between node types A 1 and A ùëô+1</formula><p>, where ‚Ä¢ denotes the composition operator on relations. However, a datasetspecific meta path always need to be selected manually based on prior knowledge from domain experts. With the number of meta paths growing largely, it becomes intractable to find optimal meta paths.</p><p>Thus, we divide meta paths into individual meta relations and automatically generate meta paths based on different combination of meta relations. For an edge ùëí = (ùë†, ùë°) linked from source node ùë† to target node ùë°, a meta relation is defined as &lt; ùúô (ùë†),ùúì (ùëí), ùúô (ùë°) &gt;, which represents the semantic relation between the two nodes. Given target node ùë° as well as the meta relation ùúì (ùëí), there could be multiple source neighbors in type ùúô (ùë†). Definition 3.3. Problem Definition. The HIN based recommendation problem can be formulated as follows. In a typical recommendation scenario, given a set of users U = {ùë¢ 1 , ùë¢ 2 , ...ùë¢ ùëÄ } and items V = {ùë£ 1 , ùë£ 2 , ...ùë£ ùëÅ }, we have user-item interaction matrix ùëå ‚àà ùëå ùëÄ * ùëÅ , where ùë¶ ùë¢ùë£ = 1 indicates that user ùë¢ engages with item ùë£, otherwise ùë¶ ùë¢ùë£ = 0. Additionally, we also have corresponding context information of users and items, such as, social relationships between users, item brands and categories. We abstract user, item and their context information as different types of nodes connected by meta relations in G. Our task is to predict whether user ùë¢ has a potential interest in item ùë£ with which he has had no interaction before. Specially, we aim to learn the low-dimensional representations of ùë¢ and ùë£ stem from different aspects for the prediction function ≈∑ùë¢ùë£ = F (ùë¢, ùë£ |Œò, ùëå, G), where ≈∑ùë¢ùë£ denotes the probability that user ùë¢ will engage with item ùë£ and Œò denotes the model parameters of prediction function F .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED MODEL</head><p>In this section, we first introduce motivation and the overall architecture of the proposed model DisenHAN, which can iteratively identify the major aspect of meta relations for information propagation in HIN. We then present the details of each component and how they are applied to top-ùëÅ recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>The basic idea of our proposed model is to design a GNN to enrich the representation of users and items which are nodes in HIN. However, their representations often stem from different aspects and are determined by corresponding meta relations. Thus, previous GNNs are no longer suitable in this scenario.</p><p>As shown in Figure <ref type="figure" target="#fig_26">2</ref>, there are three components in DisenHAN framework. Given a target node ùë°, we group its source neighbors based on meta relation ùúì (ùëí) and project their attributes into different subspaces to extract features from different aspects. Then, for each meta relation group, we aggregate source neighbor features under each aspect to capture the specific semantic information. Next, our proposed mechanism iteratively identifies the major aspect of each meta relation to get the optimal combined aspect information. We denote the output of (ùëô)-th DisenHAN layer as ùê∑ (ùëô) , which could be the input of the (ùëô + 1)-th layer. By stacking ùêø layers, we can aggregate multiple hops of neighbor information to enrich the representation of users and items, which are used for predicting the matching score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Disentangled Content Transformation</head><p>Different types of nodes always have attributes from different feature spaces in HIN. Thus, given target node ùë° and all its one hop neighbors ùë† ‚àà ùëÅ (ùë°), we group them by different meta relations to get ùëÅ ùúì (ùëí) , which denotes the same type of source nodes connecting to ùë° with meta relation ùúì (ùëí). Then for each group, we apply a type-specific transformation for both target and source nodes before feeding their features into DisenHAN layer. For ùë° of type ùúô (ùë°) ‚àà A, we project its feature vector ùë• ùë° ‚àà R ùëë ùëñùëõ into ùêæ different subspaces:       &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v H</p><formula xml:id="formula_1">ùëê ùë°,ùëò = ùúé (ùëä ùúô (ùë° ),ùëò ‚Ä¢ ùë• ùë° ) ‚à•ùúé (ùëä ùúô (ùë° ),ùëò ‚Ä¢ ùë• ùë° )‚à• 2 ,<label>(1)</label></formula><formula xml:id="formula_2">P p / Y H F H x G E = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J a 0 G V B E J c t 2 A f U I s l 0 W o f m x W Q i l K I / 4 F a / T f w D / Q v v j C m o R X R C k j P n 3 n N m 7 r 1 + E o h U O c 5 r w V p a X l l d K 6 6 X N j a 3 t n f K u 3 u d N M 4 k 4 2 0 W B 7 H s + V 7 K A x H x t h I q 4 L 1 E c i / 0 A 9 7 1 J + c 6 3 r 3 j M h V x d K W m C R + E 3 j g S I 8 E 8 R V R L 3 Z Q r T t U x y 1 4 E b g 4 q y F c z L r / g G k P E Y M g Q g i O C I h z A Q 0 p P H y 4 c J M Q N M C N O E h I m z n G P E m k z y u K U 4 R E 7 o e + Y d v 2 c j W i v P V O j Z n R K Q K 8 k p Y</formula><formula xml:id="formula_3">P p / Y H F H x G E = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J a 0 G V B E J c t 2 A f U I s l 0 W o f m x W Q i l K I / 4 F a / T f w D / Q v v j C m o R X R C k j P n 3 n N m 7 r 1 + E o h U O c 5 r w V p a X l l d K 6 6 X N j a 3 t n f K u 3 u d N M 4 k 4 2 0 W B 7 H s + V 7 K A x H x t h I q 4 L 1 E c i / 0 A 9 7 1 J + c 6 3 r 3 j M h V x d K W m C R + E 3 j g S I 8 E 8 R V R L 3 Z Q r T t U x y 1 4 E b g 4 q y F c z L r / g G k P E Y M g Q g i O C I h z A Q 0 p P H y 4 c J M Q N M C N O E h I m z n G P E m k z y u K U 4 R E 7 o e + Y d v 2 c j W i v P V O j Z n R K Q K 8 k p Y</formula><formula xml:id="formula_4">P p / Y H F H x G E = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J a 0 G V B E J c t 2 A f U I s l 0 W o f m x W Q i l K I / 4 F a / T f w D / Q v v j C m o R X R C k j P n 3 n N m 7 r 1 + E o h U O c 5 r w V p a X l l d K 6 6 X N j a 3 t n f K u 3 u d N M 4 k 4 2 0 W B 7 H s + V 7 K A x H x t h I q 4 L 1 E c i / 0 A 9 7 1 J + c 6 3 r 3 j M h V x d K W m C R + E 3 j g S I 8 E 8 R V R L 3 Z Q r T t U x y 1 4 E b g 4 q y F c z L r / g G k P E Y M g Q g i O C I h z A Q 0 p P H y 4 c J M Q N M C N O E h I m z n G P E m k z y u K U 4 R E 7 o e + Y d v 2 c j W i v P V O j Z n R K Q K 8 k p Y</formula><formula xml:id="formula_5">P p / Y H F H x G E = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J a 0 G V B E J c t 2 A f U I s l 0 W o f m x W Q i l K I / 4 F a / T f w D / Q v v j C m o R X R C k j P n 3 n N m 7 r 1 + E o h U O c 5 r w V p a X l l d K 6 6 X N j a 3 t n f K u 3 u d N M 4 k 4 2 0 W B 7 H s + V 7 K A x H x t h I q 4 L 1 E c i / 0 A 9 7 1 J + c 6 3 r 3 j M h V x d K W m C R + E 3 j g S I 8 E 8 R V R L 3 Z Q r T t U x y 1 4 E b g 4 q y F c z L r / g G k P E Y M g Q g i O C I h z A Q 0 p P H y 4 c J M Q N M C N O E h I m z n G P E m k z y u K U 4 R E 7 o e + Y d v 2 c j W i v P V O j Z n R K Q K 8 k p Y</formula><formula xml:id="formula_6">v M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z K q 6 L L g p s u K 9 g G 1 l C S d 1 t C 8 m E y U U g R / w K 1 + m v g H + h f e G</formula><formula xml:id="formula_7">A 2 x f + l m m f / V y V o E h j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U J w T 9 p V y 1 m d T a T J V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O O d B q 2 o 5 R</formula><formula xml:id="formula_8">x 3 l L c K n 8 U l R D C I V 9 O R u h P f a 3 Q = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 r L g p s u K 9 g G 1 l C S d 1 t C 8 m E y U U g R / w K 1 + m v g H + h f e G a e g F t E J S c 6 c e 8 + Z u f d 6 a R h k w r Z f C 8 b C 4 t L y S n G 1 t L a + s b l V 3 t 5 p Z U n O f d b 0 k z D h H c / N W B j E r C k C E b J O y p k b e S F r e + N z G W / f M p 4 F S X w l J i n r R e 4 o D o a B 7 w q i L r P + S b 9 c s S 1 b L X M e O B p U o F c j K b / g G g M k 8 J E j A k M M Q T i E i 4 y e L h z Y S I n r Y U o c J x S o O M M 9 S q T N K Y t R h k v s m L 4 j 2 n U 1 G 9 N e e m Z K 7 d M p I b 2 c l C Y O S J N Q H i c s T z N V P F f O k v 3 N e 6 o 8 5 d 0 m 9 P e 0 V 0 S s w A 2 x f + l m m f / V y V o E h j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U J w T 9 p V y 1 m d T a T J V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O O d B q 2 o 5 R 1 b 1 4 r h S s / S o i 9 j D P g 5 p n q e o o Y 4 G m u Q 9 w i O e 8 G z U j d j I j b v P V K O g N b v 4 t o y H D w l L k B E = &lt; / l a t e x i t &gt; s 7 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 O r z s y v g u L p A / 1 7 q A o F j 1 E n 7 J 9 c = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 1 G X B T Z c V 7 Q N q K U k 6 r a F 5 k Z k o p Q j + g F v 9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 j D g w r Z f C 8 b S 8 s r q W n G 9 t L G 5 t b 1 T 3 t 1 r 8 y T P f N b y k z D J u p 7 L W R j E r C U C E b J u m j E 3 8 k L W 8 S b n M t 6 5 Z R k P k v h K T F P W j 9 x x H I w C 3 x V E X f J B b V C u 2 J a t l r k I H A 0 q 0 K u Z l F 9 w j S E S + M g R g S G G I B z C B a e n B w c 2 U u L 6 m B G X E Q p U n O E e J d L m l M U o w y V 2 Q t 8 x 7 X q a j W k v P b l S + 3 R K S G 9 G S h N H p E k o L y M s T z N V P F f O k v 3 N e 6 Y 8 5 d 2 m 9 P e 0 V 0 S s w A 2 x f + n m m f / V y V o E R j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U j w j 7 C v l v M + m 0 n B V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O B d B u 2 o 5 J 1 b 1 4 r R S t / S o i z j A I Y 5 p n j X U 0 U A T L f I e 4 x F P e D Y a R m z k x t 1 n q l H Q m n 1 8 W 8 b D B w u r k B I = &lt; / l a t e x i t &gt; s 8 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O w c d D w A 3 / F 8 I k 4 y j K N s R Y 5 n a f U 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 2 G X B T Z c V 7 Q N q K U k 6 r a F 5 M Z k o p Q j + g F v 9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 j D I h G 2 / F o y l 5 Z X V t e J 6 a W N z a 3 u n v L v X z p K c + 6 z l J 2 H C u 5 6 b s T C I W U s E I m T d l D M 3 8 k L W 8 S b n M t 6 5 Z T w L k v h K T F P W j 9 x x H I w C 3 x V E X W a D 2 q B c s S 1 b L X M R O B p U o F c z K b / g G k M k 8 J E j A k M M Q T i E i 4 y e H h z Y S I n r Y 0 Y c J x S o O M M 9 S q T N K Y t R h k v s h L 5 j 2 v U 0 G 9 N e e m Z K 7 d M p I b 2 c l C a O S J N Q H i c s T z N V P F f O k v 3 N e 6 Y 8 5 d 2 m 9 P e 0 V 0 S s w A 2 x f + n m m f / V y V o E R q i p G g K q K V W M r M 7 X L r n q i r y 5 + a U q Q Q 4 p c R I P K c 4 J + 0 o 5 7 7 O p N J m q X f b W V f E 3 l S l Z u f d 1 b o 5 3 e U s a s P N z n I u g X b W c E 6 t 6 c V q p W 3 r U R R z g E M c 0 z z P U 0 U A T L f I e 4 x F P e D Y a R m z k x t 1 n q l H Q m n 1 8 W 8 b D B w 4 L k B M = &lt; / l a t e x i t &gt; s 4</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 4 y 7 b i h o 4 n i P e N y a j p z n W C h y t</p><formula xml:id="formula_9">V c = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J a 0 G X B T Z c V 7 Q N q K c l 0 W k P z I j N R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + / 1 k s A X 0 r Z f C 8 b S 8 s r q W n G 9 t L G 5 t b 1 T 3 t 1 r i z h L G W + x O I j T r u c K H v g R b 0 l f B r y b p N w N v Y B 3 v M m 5 i n d u e S r 8 O L q S 0 4 T 3 Q 3 c c + S O f u Z K o S z G o D c o V 2 7 L 1 M h e B k 4 M K 8 t W M y y + 4 x h A x G D K E 4 I g g C Q d w I e j p w Y G N h L g + Z s S l h H w d 5 7 h H i b Q Z Z X H K c I m d 0 H d M u 1 7 O R r R X n k K r G Z 0 S 0 J u S 0 s Q R a W L K S w m r 0 0 w d z 7 S z Y n / z n m l P d b c p / b 3 c K y R W 4 o b Y v 3 T z z P / q V C 0 S I 5 z p G n y q K d G M q o 7 l L p n u i r q 5 + a U q S Q 4 J c Q o P K Z 4 S Z l o 5 7 7 O p N U L X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P k 5 z k X Q r l r O i V W 9 q F X q V j 7 q I g 5 w i G O a 5 y n q a K C J F n m P 8 Y g n P B s N I z I y 4 + 4 z 1 S j k m n 1 8 W 8 b D B w S L k A 8 = &lt; / l a t e x i t &gt; s 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 t 5 M w 9 H R 0 O Y y E F n X l O N + / P t W H J 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J W 0 G X B T Z c V 7 Q N q K U k 6 r U P z I j N R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + / 1 k o A L a d u v B W N p e W V 1 r b h e 2 t j c 2 t 4 p 7 + 6 1 R Z y l P m v 5 c R C n X c 8 V L O A R a 0 k u A 9 Z N U u a G X s A 6 3 u R c x T u 3 L B U 8 j q 7 k N G H 9 0 B 1 H f M R 9 V x J 1 K Q a 1 Q b l i W 7 Z e 5 i J w c l B B v p p x + Q X X G C K G j w w h G C J I w g F c C H p 6 c G A j I a 6 P G X E p I a 7 j D P c o k T a j L E Y Z L r E T + o 5 p 1 8 v Z i P b K U 2 i 1 T 6 c E 9 K a k N H F E m p j y U s L q N F P H M + 2 s 2 N + 8 Z 9 p T 3 W 1 K f y / 3 C o m V u C H 2 L 9 0 8 8 7 8 6 V Y v E C G e 6 B k 4 1 J Z p R 1 f m 5 S 6 a 7 o m 5 u f q l K k k N C n M J D i q e E f a 2 c 9 9 n U G q F r V 7 1 1 d f x N Z y p W 7 f 0 8 N 8 O 7 u i U N 2 P k 5 z k X Q r l p O z a p e n F T q V j 7 q I g 5 w i G O a 5 y n q a K C J F n m P 8 Y g n P B s N I z I y 4 + 4 z 1 S j k m n 1 8 W 8 b D B w I r k A 4 = &lt; / l a t e x i t &gt; s 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L S Y X U R e 7 a B S p l U T N / m V Y 2 W b e 7 M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g p s u K t h V q K U k 6 r U P T J G Q m S i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 g z T i Q r r u a 8 F a W F x a X i m u l t b W N z a 3 y t s 7 L Z H k W c i a Y R I l 2 V X g C x b x m D U l l x G 7 S j P m j 4 O I t Y P R m Y q 3 b 1 k m e B J f y k n K u m N / G P M B D 3 1 J 1 I X o V X v l i u u 4 e t n z w D O g A r M a S f k F 1 + g j Q Y g c Y z D E k I Q j + B D 0 d O D B R U p c F 1 P i M k J c x x n u U S J t T l m M M n x i R / Q d 0 q 5 j 2 J j 2 y l N o d U i n R P R m p L R x Q J q E 8 j L C 6 j R b x 3 P t r N j f v K f a U 9 1 t Q v / A e I 2 J l b g h 9 i / d L P O / O l W L x A C n u g Z O N a W a U d W F x i X X X V E 3 t 7 9 U J c k h J U 7 h P s U z w q F W z v p s a 4 3 Q t a v e + j r + p j M V q / a h y c 3 x r m 5 J A / Z + j n M e t K q O d + R U z 4 8 r N c e M u o g 9 7 O O Q 5 n m C G u p o o E n e Q z z i C c 9 W 3 Y q t 3 L r 7 T L U K R r O L b 8 t 6 + A D / v J A N &lt; / l a t e x i t &gt; s 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A j H H J V n 9 Y l h a G r A / L l r w M h D Q R l M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g p s u K t h V q K U k 6 r U P T J G Q m S i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 g z T i Q r r u a 8 F a W F x a X i m u l t b W N z a 3 y t s 7 L Z H k W c i a Y R I l 2 V X g C x b x m D U l l x G 7 S j P m j 4 O I t Y P R m Y q 3 b 1 k m e B J f y k n K u m N / G P M B D 3 1 J 1 I X o e b 1 y x X V c v e x 5 4 B l Q g V m N p P y C a / S R I E S O M R h i S M I R f A h 6 O v D g I i W u i y l x G S G u 4 w z 3 K J E 2 p y x G G T 6 x I / o O a d c x b E x 7 5 S m 0 O q R T I n o z U t o 4 I E 1 C e R l h d Z q t 4 7 l 2 V u x v 3 l P t q e 4 2 o X 9 g v M b E S t w Q + 5 d u l v l f n a p F Y o B T X Q O n m l L N q O p C 4 5 L r r q i b 2 1 + q k u S Q E q d w n + I Z 4 V A r Z 3 2 2 t U b o 2 l V v f R 1 / 0 5 m K V f v Q 5 O Z 4 V 7 e k A X s / x z k P W l X H O 3 K q 5 8 e V m m N G X c Q e 9 n F I 8 z x B D X U 0 0 C T v I R 7 x h G e r b s V W b t 1 9 p l o F o 9 n F t 2 U 9 f A D 9 X J A M &lt; / l a t e x i t &gt; s 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A j H H J V n 9 Y l h a G r A / L l r w M h D Q R l M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g p s u K t h V q K U k 6 r U P T J G Q m S i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 g z T i Q r r u a 8 F a W F x a X i m u l t b W N z a 3 y t s 7 L Z H k W c i a Y R I l 2 V X g C x b x m D U l l x G 7 S j P m j 4 O I t Y P R m Y q 3 b 1 k m e B J f y k n K u m N / G P M B D 3 1 J 1 I X o e b 1 y x X V c v e x 5 4 B l Q g V m N p P y C a / S R I E S O M R h i S M I R f A h 6 O v D g I i W u i y l x G S G u 4 w z 3 K J E 2 p y x G G T 6 x I / o O a d c x b E x 7 5 S m 0 O q R T I n o z U t o 4 I E 1 C e R l h d Z q t 4 7 l 2 V u x v 3 l P t q e 4 2 o X 9 g v M b E S t w Q + 5 d u l v l f n a p F Y o B T X Q O n m l L N q O p C 4 5 L r r q i b 2 1 + q k u S Q E q d w n + I Z 4 V A r Z 3 2 2 t U b o 2 l V v f R 1 / 0 5 m K V f v Q 5 O Z 4 V 7 e k A X s / x z k P W l X H O 3 K q 5 8 e V m m N G X c Q e 9 n F I 8 z x B D X U 0 0 C T v I R 7 x h G e r b s V W b t 1 9 p l o F o 9 n F t 2 U 9 f A D 9 X J A M &lt; / l a t e x i t &gt; s 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L S Y X U R e 7 a B S p l U T N / m V Y 2 W b e 7 M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g p s u K t h V q K U k 6 r U P T J G Q m S i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 g z T i Q r r u a 8 F a W F x a X i m u l t b W N z a 3 y t s 7 L Z H k W c i a Y R I l 2 V X g C x b x m D U l l x G 7 S j P m j 4 O I t Y P R m Y q 3 b 1 k m e B J f y k n K u m N / G P M B D 3 1 J 1 I X o V X v l i u u 4 e t n z w D O g A r M a S f k F 1 + g j Q Y g c Y z D E k I Q j + B D 0 d O D B R U p c F 1 P i M k J c x x n u U S J t T l m M M n x i R / Q d 0 q 5 j 2 J j 2 y l N o d U i n R P R m p L R x Q J q E 8 j L C 6 j R b x 3 P t r N j f v K f a U 9 1 t Q v / A e I 2 J l b g h 9 i / d L P O / O l W L x A C n u g Z O N a W a U d W F x i X X X V E 3 t 7 9 U J c k h J U 7 h P s U z w q F W z v p s a 4 3 Q t a v e + j r + p j M V q / a h y c 3 x r m 5 J A / Z + j n M e t K q O d + R U z 4 8 r N c e M u o g 9 7 O O Q 5 n m C G u p o o E n e Q z z i C c 9 W 3 Y q t 3 L r 7 T L U K R r O L b 8 t 6 + A D / v J A N &lt; / l a t e x i t &gt; s 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 t 5 M w 9 H R 0 O Y y E F n X l O N + / P t W H J 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J W 0 G X B T Z c V 7 Q N q K U k 6 r U P z I j N R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + / 1 k o A L a d u v B W N p e W V 1 r b h e 2 t j c 2 t 4 p 7 + 6 1 R Z y l P m v 5 c R C n X c 8 V L O A R a 0 k u A 9 Z N U u a G X s A 6 3 u R c x T u 3 L B U 8 j q 7 k N G H 9 0 B 1 H f M R 9 V x J 1 K Q a 1 Q b l i W 7 Z e 5 i J w c l B B v p p x + Q X X G C K G j w w h G C J I w g F c C H p 6 c G A j I a 6 P G X E p I a 7 j D P c o k T a j L E Y Z L r E T + o 5 p 1 8 v Z i P b K U 2 i 1 T 6 c E 9 K a k N H F E m p j y U s L q N F P H M + 2 s 2 N + 8 Z 9 p T 3 W 1 K f y / 3 C o m V u C H 2 L 9 0 8 8 7 8 6 V Y v E C G e 6 B k 4 1 J Z p R 1 f m 5 S 6 a 7 o m 5 u f q l K k k N C n M J D i q e E f a 2 c 9 9 n U G q F r V 7 1 1 d f x N Z y p W 7 f 0 8 N 8 O 7 u i U N 2 P k 5 z k X Q r l p O z</formula><p>a p e n F T q V j 7 q I g 5 w i G O a 5 y n q a K C J F n m P 8 Y g n P B s N I z I y 4 + 4 z 1 S j k m n 1 8 W 8 b D B w I r k A 4 = &lt; / l a t e x i t &gt; s 4</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 4 y 7 b i h o 4 n i P e N y a j p z n W C h y t         T z z P / q V C 0 S I 5 z p G n y q K d G M q o 7 l L p n u i r q 5 + a U q S Q 4 J c Q o P K Z 4 S Z l o 5 7 7 O p N U L X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P k 5 z k X Q r l r O i V W 9 q F X q V j 7 q I g 5 w i G O a 5 y n q a K C J F n m P 8 Y g n P B s N I z I y 4 + 4 z 1 S j k m n 1 8 W 8 b D B w S L k A 8 = &lt; / l a t e x i t &gt;        </p><formula xml:id="formula_10">V c = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J a 0 G X B T Z c V 7 Q N q K c l 0 W k P z I j N R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + / 1 k s A X 0 r Z f C 8 b S 8 s r q W n G 9 t L G 5 t b 1 T 3 t 1 r i z h L G W + x O I j T r u c K H v g R b 0 l f B r y b p N w N v Y B 3 v M m 5 i n d u e S r 8 O L q S 0 4 T 3 Q 3 c c + S O f u Z K o S z G o D c o V 2 7 L 1 M h e B k 4 M K 8 t W M y y + 4 x h A x G D K E 4 I g g C Q d w I e j p w Y G N h L g + Z s S l h H w d 5 7 h H i b Q Z Z X H K c I m d 0 H d M u 1 7 O R r R X n k K r G Z 0 S 0 J u S 0 s Q R a W L K S w m r 0 0 w d z 7 S z Y n / z n m l P d b c p / b 3 c K y R W 4 o b Y v 3 T z z P / q V C 0 S I 5 z p G n y q K d G M q o 7 l L p n u i r q 5 + a U q S Q 4 J c Q o P K Z 4 S Z l o 5 7 7 O p N U L X r n r r 6 v i b z l S s 2 r M 8 N 8 O 7 u i U N 2 P k 5 z k X Q r l r O i V W 9 q F X q V j 7 q I g 5 w i G O a 5 y n q a K C J F</formula><formula xml:id="formula_11">v M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z K q 6 L L g p s u K 9 g G 1 l C S d 1 t C 8 m E y U U g R / w K 1 + m v g H + h f e G a e g F t E J S c 6 c e 8 + Z u f d 6 a R h k w r Z f C 8 b C 4 t L y S n G 1 t L a + s b l V 3 t 5 p Z U n O f d b 0 k z D h H c / N W B j E r C k C E b J O y p k b e S F r e + N z G W / f M p 4 F S X w l J i n r R e 4 o D o a B 7 w q i L r P + S b 9 c s S 1 b L X M e O B p U o F c j K b / g G g M k 8 J E j A k M M Q T i E i 4 y e L h z Y S I n r Y U o c J x S o O M M 9 S q T N K Y t R h k v s m L 4 j 2 n U 1 G 9 N e e m Z K 7 d M p I b 2 c l C Y O S J N Q H i c s T z N V P F f O k v 3 N e 6 o 8 5 d 0 m 9 P e 0 V 0 S s w A 2 x f + l m m f / V y V o E h j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U J w T 9 p V y 1 m d T a T J V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O O d B q 2 o 5 R 1 b 1 4 r h S s / S o i 9 j D P g 5 p n q e o o Y 4 G m u Q 9 w i O e 8 G z U j d j I j b v P V K O g N b v 4 t o y H D w b r k B A = &lt; / l a t e x i t &gt; s 6 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v H x 3 l L c K n 8 U l R D C I V 9 O R u h P f a 3 Q = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 r L g p s u K 9 g G 1 l C S d 1 t C 8 m E y U U g R / w K 1 + m v g H + h f e G a e g F t E J S c 6 c e 8 + Z u f d 6 a R h k w r Z f C 8 b C 4 t L y S n G 1 t L a + s b l V 3 t 5 p Z U n O f d b 0 k z D h H c / N W B j E r C k C E b J O y p k b e S F r e + N z G W / f M p 4 F S X w l J i n r R e 4 o D o a B 7 w q i L r P + S b 9 c s S 1 b L X M e O B p U o F c j K b / g G g M k 8 J E j A k M M Q T i E i 4 y e L h z Y S I n r Y U o c J x S o O M M 9 S q T N K Y t R h k v s m L 4 j 2 n U 1 G 9 N e e m Z K 7 d M p I b 2 c l C Y O S J N Q H i c s T z N V P F f O k v 3 N e 6 o 8 5 d 0 m 9 P e 0 V 0 S s w A 2 x f + l m m f / V y V o E h j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U J w T 9 p V y 1 m d T a T J V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O O d B q 2 o 5 R</formula><formula xml:id="formula_12">A o F j 1 E n 7 J 9 c = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 1 G X B T Z c V 7 Q N q K U k 6 r a F 5 k Z k o p Q j + g F v 9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 j D g w r Z f C 8 b S 8 s r q W n G 9 t L G 5 t b 1 T 3 t 1 r 8 y T P f N b y k z D J u p 7 L W R j E r C U C E b J u m j E 3 8 k L W 8 S b n M t 6 5 Z R k P k v h K T F P W j 9 x x H I w C 3 x V E X f J B b V C u 2 J a t l r k I H A 0 q 0 K u Z l F 9 w j S E S + M g R g S G G I B z C B a e n B w c 2 U u L 6 m B G X E Q p U n O E e J d L m l M U o w y V 2 Q t 8 x 7 X q a j W k v P b l S + 3 R K S G 9 G S h N H p E k o L y M s T z N V P F f O k v 3 N e 6 Y 8 5 d 2 m 9 P e 0 V 0 S s w A 2 x f + n m m f / V y V o E R j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U j w j 7 C v l v M + m 0 n B V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O B d B u 2 o 5 J</formula><formula xml:id="formula_13">= " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 2 G X B T Z c V 7 Q N q K U k 6 r a F 5 M Z k o p Q j + g F v</formula><formula xml:id="formula_14">L k v h K T F P W j 9 x x H I w C 3 x V E X W a D 2 q B c s S 1 b L X M R O B p U o F c z K b / g G k M k 8 J E j A k M M Q T i E i 4 y e H h z Y S I n r Y 0 Y c J x S o O M M 9 S q T N K Y t R h k v s h L 5 j 2 v U 0 G 9 N e e m Z K 7 d M p I b 2 c l C a O S J N Q H i c s T z N V P F f O k v 3 N e 6 Y 8 5 d 2 m 9 P e 0 V 0 S s w A 2 x f + n m m f / V y V o E R q i p G g K q K V W M r M 7 X L r n q i r y 5 + a U q Q Q 4 p c R I P K c 4 J + 0 o 5 7 7 O p N J m q X f b W V f E 3 l S l Z u f</formula><formula xml:id="formula_15">P p / Y H F H x G E = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J a 0 G V B E J c t 2 A f U I s l 0 W o f m x W Q i l K I / 4 F a / T f w D / Q v v j C m o R X R C k j P n 3 n N m 7 r 1 + E o h U O c 5 r w V p a X l l d K 6 6 X N j a 3 t n f K u 3 u d N M 4 k 4 2 0 W B 7 H s + V 7 K A x H x t h I q 4 L 1 E c i / 0 A 9 7 1 J + c 6 3 r 3 j M h V x d K W m C R + E 3 j g S I 8 E 8 R V R L 3 Z Q r T t U x y 1 4 E b g 4 q y F c z L r / g G k P E Y M g Q g i O C I h z A Q 0 p P H y 4 c J M Q N M C N O E h I m z n G P E m k z y u K U 4 R E 7 o e + Y d v 2 c j W i v P V O j Z n R K Q K 8 k p Y</formula><formula xml:id="formula_16">A j H H J V n 9 Y l h a G r A / L l r w M h D Q R l M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g p s u K t h V q K U k 6 r U P T J G Q m S i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 g z T i Q r r u a 8 F a W F x a X i m u l t b W N z a 3 y t s 7 L Z H k W c i a Y R I l 2 V X g C x b x m D U l l x G 7 S j P m j 4 O I t Y P R m Y q 3 b 1 k m e B J f y k n K u m N / G P M B D 3 1 J 1 I X o e b 1 y x X V c v e x 5 4 B l Q g V m N p P y C a / S R I E S O M R h i S M I R f A h 6 O v D g I i W u i y l x G S G u 4 w z 3 K J E 2 p y x G G T 6 x I / o O a d c x b E x 7 5 S m 0 O q R T I n o z U t o 4 I E 1 C e R l h d Z q t 4 7 l 2 V u x v 3 l P t q e 4 2 o X 9 g v M b E S t w Q + 5 d u l v l f n a p F Y o B T X Q O n m l L N q O p C 4 5 L r r q i b 2 1 + q k u S Q E q d w n + I Z 4 V A r Z 3 2 2 t U b o 2 l V v f R 1 / 0 5 m K V f v Q 5 O Z 4 V 7 e k A X s / x z k P W l X H O 3 K q 5 8 e V m m N G X c Q e 9 n F I 8 z x B D X U 0 0 C T v I R 7 x h G e r b s V W b t 1 9 p l o F o 9 n F t 2 U 9 f A D 9 X J A M &lt; / l a t e x i t &gt; s 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L S Y X U R e 7 a B S p l U T N / m V Y 2 W b e 7 M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g p s u K t h V q K U k 6 r U P T J G Q m S i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 g z T i Q r r u a 8 F a W F x a X i m u l t b W N z a 3 y t s 7 L Z H k W c i a Y R I l 2 V X g C x b x m D U l l x G 7 S j P m j 4 O I t Y P R m Y q 3 b 1 k m e B J f y k n K u m N / G P M B D 3 1 J 1 I X o V X v l i u u 4 e t n z w D O g A r M a S f k F 1 + g j Q Y g c Y z D E k I Q j + B D 0 d O D B R U p c F 1 P i M k J c x x n u U S J t T l m M M n x i R / Q d 0 q 5 j 2 J j 2 y l N o d U i n R P R m p L R x Q J q E 8 j L C 6 j R b x 3 P t r N j f v K f a U 9 1 t Q v / A e I 2 J l b g h 9 i / d L P O / O l W L x A C n u g Z O N a W a U d W F x i X X X V E 3 t 7 9 U J c k h J U 7 h P s U z w q F W z v p s a 4 3 Q t a v e + j r + p j M V q / a h y c 3 x r m 5 J A / Z + j n M e t K q O d + R U z 4 8 r N c e M u o g 9 7 O O Q 5 n m C G u p o o E n e Q z z i C c 9 W 3 Y q t 3 L r 7 T L U K R r O L b 8 t 6 + A D / v J A N &lt; / l a t e x i t &gt; s 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 t 5 M w 9 H R 0 O Y y E F n X l O N + / P t W H J 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J W 0 G X B T Z c V 7 Q N q K U k 6 r U P z I j N R S h</formula><formula xml:id="formula_17">l P m v 5 c R C n X c 8 V L O A R a 0 k u A 9 Z N U u a G X s A 6 3 u R c x T u 3 L B U 8 j q 7 k N G H 9 0 B 1 H f M R 9 V x J 1 K Q a 1 Q b l i W 7 Z e 5 i J w c l B B v p p x + Q X X G C K G j w w h G C J I w g F c</formula><formula xml:id="formula_18">t V c = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J a 0 G X B T Z c V 7 Q N q K c l 0 W k P z I j N R S h</formula><formula xml:id="formula_19">A 2 x f + l m m f / V y V o E h j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U J w T 9 p V y 1 m d T a T J V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O O d B q 2 o 5 R</formula><formula xml:id="formula_20">A 2 x f + l m m f / V y V o E h j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U J w T 9 p V y 1 m d T a T J V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O O d B q 2 o 5 R</formula><formula xml:id="formula_21">A o F j 1 E n 7 J 9 c = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 1 G X B T Z c V 7 Q N q K U k 6 r a F 5 k Z k o p Q j + g F v</formula><formula xml:id="formula_22">k z D J u p 7 L W R j E r C U C E b J u m j E 3 8 k L W 8 S b n M t 6 5 Z R k P k v h K T F P W j 9 x x H I w C 3 x V E X f J B b V C u 2 J a t l r k I H A 0 q 0 K u Z l F 9 w j S E S + M g R g S G G I B z C B a e n B w c 2 U u L 6 m B G X E Q p U n O E e J d L m l M U o w y V 2 Q t 8 x 7 X q a j W k v P b l S + 3 R K S G 9 G S h N H p E k o L y M s T z N V P F f O k v 3 N e 6 Y 8 5 d 2 m 9 P e 0 V 0 S s w A 2 x f + n m m f / V y V o E R j h T N Q R U U 6 o Y W Z 2 v X X L V F X l z 8 0 t V g h x S 4 i Q e U j w j 7 C v l v M + m 0 n B V u + y t q + J v K l O y c u / r 3 B z v 8 p Y 0 Y O f n O B d B</formula><formula xml:id="formula_23">= " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 2 G X B T Z c V 7 Q N q K U k 6 r a F 5 M Z k o p Q j + g F v</formula><formula xml:id="formula_24">C 3 x V E X W a D 2 q B c s S 1 b L X M R O B p U o F c z K b / g G k M k 8 J E j A k M M Q T i E i 4 y e H h z Y S I n r Y 0 Y c J x S o O M M 9 S q T N K Y t R h k v s h L 5 j 2 v U 0 G 9 N e e m Z K 7 d M p I b 2 c l C a O S J N Q H i c s T z N V P F f O k v 3 N e 6 Y 8 5 d 2 m 9 P e 0 V 0 S s w A 2 x f + n m m f / V y V o E R q i p G g K q K V W M r M 7 X L r n q i r y 5 + a U q Q Q 4 p c R I P K c 4 J + 0 o 5 7 7 O p N J m q X f b W V f E 3 l S l Z u f</formula><formula xml:id="formula_25">T X h G x A j f E / q W b Z f 5 X J 2 s R G O J U 1 R B Q T a l i Z H W + d s l V V + T N z S 9 V C X J I i Z N 4 Q H F O 2 F f K W Z 9 N p c l U 7 b K 3 r o q / q U z J y</formula><formula xml:id="formula_26">/ Z n / f j V n G j y t f k H t R 8 H O y a y w = " &gt; A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g R n B T w T 6 g l p J M p 3 V s m s R k I t b S l T / g V n 9 M / A P 9 C + + M K a h F d E K S M + f e c 2 b u v V 7 k i 0 T a 9 m v O m J t f W F z K L x d W V t f W N 4 q b W / U k T G P G a y z 0 w 7 j p u Q n 3 R c B r U k i f N 6 O Y u 0 P P 5 w 1 v c K L i j V s e J y I M L u Q o 4 u 2 h 2 w 9 E T z B X E l V P O m P H n n S K J d u y 9 T J n g Z O B E r J V D Y s v u E Q X I R h S D M E R Q B L 2 4 S K h p w U H N i L i 2 h g T F x M S O s 4 x Q Y G 0 K W V x y n C J H d C 3 T 7 t W x g a 0 V 5 6 J V j M 6 x a c 3 J q W J P d K E l B c T V q e Z O p 5 q Z 8 X + 5 j 3 W n u p u I / p 7 m d e Q W I k r Y v / S T T P / q 1 O 1 S P R w r G s Q V F O k G V U d y 1 x S 3 R V 1 c / N L V Z I c I u I U 7 l I 8 J s y 0 c t p n U 2 s S X b v q r a v j b z p T s W r P s t w U 7 + q W N G D n 5 z h n Q b 1 s O Q d W + f y w V L G y U e e</formula><p>x g 1 3 s 0 z y P U M E p q q i R 9 z U e 8 Y R n 4 8 y 4 M e 6 M + 8 9 U I 5 d p t v F t G Q 8 f M m O R U g = = &lt; / l a t e x i t &gt; s 11</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r G 9  We assume that there are three aspects for the nodes. The same color between nodes and the relation denotes the major aspect of the relation where the grouped neighbors are similar in ùëò ùë°‚Ñé channel. The model iteratively takes features of target node ùë° as well as its neighbors as input and output three channels of disentangled representation for ùë°. The output of the channels is feed back as features for the next iteration.</p><formula xml:id="formula_27">1 k B x w 3 A 9 r v L i n 5 3 J 9 T a E c k V A = " &gt; A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g R n B T w T 6 g l p J M p 3 V s m s R k I t b S l T / g V n 9 M / A P 9 C + + M K a h F d E K S M + f e c 2 b u v V 7 k i 0 T a 9 m v O m J t f W F z K L x d W V t f W N 4 q b W / U k T G P G a y z 0 w 7 j p u Q n 3 R c B r U k i f N 6 O Y u 0 P P 5 w 1 v c K L i j V s e J y I M L u Q o 4 u 2 h 2 w 9 E T z B X E l V P O m P H m X S K J d u y 9 T J n g Z O B E r J V D Y s v u E Q X I R h S D M E R Q B L 2 4 S K h p w U H N i L i 2 h g T F x M S O s 4 x Q Y G 0 K W V x y n C J H d C 3 T 7 t W x g a 0 V 5 6 J V j M 6 x a c 3 J q W J P d K E l B c T V q e Z O p 5 q Z 8 X + 5 j 3 W n u p u I / p 7 m d e Q W I k r Y v / S T T P / q 1 O 1 S P R w r G s Q V F O k G V U d y 1 x S 3 R V 1 c / N L V Z I c I u I U 7 l I 8 J s y 0 c t p n U 2 s S X b v q r a v j b z p T s W r P s t w U 7 + q W N G D n 5 z h n Q b 1 s O Q d W + f y w V L G y U e e x</formula><formula xml:id="formula_28">Q i s = " &gt; A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 L L g R n B T w T 6 g l p J M p z U 2 T W J m I t b S l T / g V n 9 M / A P 9 C + + M K a h F d E K S M + f e c 2 b u v V 4 c + E L a 9 m v O m J t f W F z K L x d W V t f W N 4 q b W 3 U R p Q n j N R Y F U d L 0 X M E D P + Q 1 6 c u A N + O E u 0 M v 4 A 1 v c K L i j V u e C D 8 K L + Q o 5 u 2 h 2 w / 9 n s 9 c S V R d d M Z O e d I p l m z L 1 s u c B U 4 G S s h W N S q + 4 B J d R G B I M Q R H C E k 4 g A t B T w s O b M T E t T E m L i H k 6 z j H B A X S p p T F K c M l d k D f P u 1 a G R v S X n k K r W Z 0 S k B v Q k o T e 6 S J K C 8 h r E 4 z d T z V z o r 9 z X u s P d X d R v T 3 M q 8 h s R J X x P 6 l m 2 b + V 6 d q k e j h W N f g U 0 2 x Z l R 1 L H N J d V f U z c 0 v V U l y i I l T u E v x h D D T y m m f T a 0 R u n b V W 1 f H 3 3 S m Y t W</formula><p>where ùëä ùúô (ùë° ),ùëò ‚àà R ùëë ùëñùëõ √ó ùëë ùëúùë¢ùë° ùêæ is the weight of ùëò-th channel, ùúé is the activation function. Similarly, original features of ùë† are also projected into ùêæ corresponding subspaces. Notice that for ùë°, we can apply ùêø layers to aggregate information from multi-hops, and node features could be projected into different number of subspaces at different layers. In practice, local neighbors have more effect on the target node, thus, we add the constraint ùëò (1) ‚â• ùêæ (2) ‚â• ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚â• ùêæ (ùêø)  reflecting the number of aspects decrease along with neighbor hops increasing. Inspired by the architecture design of Transformer <ref type="bibr" target="#b30">[31]</ref>, we leverage attention mechanism to learn the weight of source nodes under different aspects. And the importance of neighbor ùë† ‚àà ùëÅ ùúì (ùëí) under aspect ùëò is calculated as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Disentangled Propagation Layer</head><formula xml:id="formula_29">ùëí ùëò ùë°,ùë† = ReLU(ùõº T ùúì (ùëí) ‚Ä¢ [ùëß (ùëñ‚àí1) ùë°,ùëò ‚à• ùëê ùë†,ùëò ]),<label>(2)</label></formula><p>where ùõº ùúì (ùëí) ‚àà R 2 ùëë ùëúùë¢ùë° ùêæ is attention vector for meta relation ùúì (ùëí).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ùëß (ùëñ‚àí1)</head><p>ùë°,ùëò , ùëê ùë†,ùëò is the target and source node feature where we set ùëß </p><formula xml:id="formula_30">ùúì (ùëí),ùëò ‚Ä¢ ùëí ùëò ùë°,ùë† ,<label>(3)</label></formula><p>where ùëü</p><formula xml:id="formula_31">(ùëñ‚àí1)</formula><p>ùúì (ùëí),ùëò is the weight of aspect ùëò for meta relation ùúì (ùëí). We set ùëü </p><p>where ùúé is the activation function. Notice that the attention weight is generated for single meta-relation, it is semantic-specific and able to capture corresponding semantic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Inter-relation Aggregation.</head><p>In this stage, we need to combine the semantic information revealed by all meta relations. Since each meta relation focuses on specific aspect, we should not fuse all the meta relations to describe the semantic information of aspect ùëò. Therefore, we let the weight ùëü ùúì (ùëí),ùëò be the probability that ùúì (ùëí) related to target node ùë° due to factor ùëò, which should satisfy ùëü ùúì (ùëí),ùëò ‚â• 0 and ùêæ ùëò ‚Ä≤ =1 ùëü ùúì (ùëí),ùëò = 1. For each aggregated aspect features, we learn the related weight as follows:</p><formula xml:id="formula_33">r (ùëñ) ùúì (ùëí),ùëò = ùëû T ùúì (ùëí) ‚Ä¢ tanh(ùëä ùëß ùúì (ùëí) ùë°,ùëò ),<label>(5)</label></formula><p>whereùëä is the weight matrix, ùëû ùúì (ùëí) is the semantic attention vector for meta relation ùúì (ùëí). And the related probability can be normalized by using softmax function,</p><formula xml:id="formula_34">ùëü (ùëñ) ùúì (ùëí),ùëò = softmax( r (ùëñ) ùúì (ùëí),ùëò ) = exp( r (ùëñ) ùúì (ùëí),ùëò ) ùêæ ùëò ‚Ä≤ =1 exp( r (ùëñ) ùúì (ùëí),ùëò ‚Ä≤ ) .<label>(6)</label></formula><p>Taking all the meta relations ùúì ùë° connected to target node ùë°, we iteratively search their major aspects and obtain the representation of ùë° as follows:</p><formula xml:id="formula_35">ùëß (ùëñ) ùë°,ùëò = ùëê ùë°,ùëò + ùúì (ùëí) ‚ààùúì ùë° ùëü (ùëñ) ùúì (ùëí),ùëò ùëä ùëß ùúì (ùëí) ùë°,ùëò ‚à•ùëê ùë°,ùëò + ùúì (ùëí) ‚ààùúì ùë° ùëü (ùëñ) ùúì (ùëí),ùëò ùëä ùëß ùúì (ùëí) ùë°,ùëò ‚à• 2 ,<label>(7)</label></formula><p>for iteration ùëñ = 1, 2, . . . , ùêº , where the output ùëß </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Recommendation</head><p>We treat the user as target node and the output of ùêø layers of disentangled propagation is a set of embedding vectors {ùëß ùë¢,1 , ùëß ùë¢,2 . . . , ùëß ùë¢,ùêæ }, representing different aspects of user. Similarly, we can treat the item as target node and get the corresponding ùêæ aspects of item embedding vectors denoted as {ùëß ùë£,1 , ùëß ùë£,2 . . . , ùëß ùë£,ùêæ }. For the final top-ùëÅ recommendation, we simply conduct the inner product of each aspect to estimate the user's preference towards the target item in aspect ùëò, and sum all the aspects as the final matching score:</p><formula xml:id="formula_36">ùë† ùë¢ùë£ = ùêæ ùëò=1 ùëß T ùë¢,ùëò ‚Ä¢ ùëß ùë£,ùëò .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Training</head><p>To optimize the top-ùëÅ recommendation with implicit feedback, we optimize it as a binary classification problem. The prediction score ≈∑ùë¢ùë£ then represents how likely user ùë¢ will select item ùë£ in the future.</p><p>We constrain the matching score ùë† ùë¢ùë£ in the range of [0, 1], which can be estimated by using a probabilistic function like Logistic,</p><formula xml:id="formula_37">≈∑ùë¢ùë£ = sigmod(ùë† ùë¢ùë£ ) = 1 1 + ùëí ‚àíùë† ùë¢ùë£ . (<label>9</label></formula><formula xml:id="formula_38">)</formula><p>Over all the training set, we learn the parameters of the model with negative sampling and the complete loss function is as follows:</p><formula xml:id="formula_39">L = ‚àí (ùë¢,ùë£) ‚ààY log ≈∑ùë¢ùë£ ‚àí (ùë¢,ùë£ ‚àí ) ‚ààY ‚àí log(1 ‚àí ≈∑ùë¢ùë£ ‚àí ),<label>(10)</label></formula><p>where Y is positive instances and Y ‚àí is negative instances uniformly sampled from unobserved interactions by controlling the sampling ratio w.r.t. number of observed interactions. We leverage mini-batch training to calculate the gradient. For each training iteration, we consider ùêµ size of user-item pairs. And for each mini-batch, we need to fix the number of source nodes to the max and pad zeros due to the different number of nodes in each meta relation. However, we observe that the number of nodes in some relations tends to obey a long-tail distribution, so the padding would lead to both high space and time complexity. Followed by the previous work <ref type="bibr" target="#b8">[9]</ref>, we sample fixed number of source nodes and pad zeros when source nodes less than the fixed number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Analysis of DisenHAN</head><p>Given target node and meta relation grouped source neighbors, we now analyze the iterative propagation process in HIN.</p><p>Iterative Forward Propagation Process. The key insight here is that we should only combine the feature from related meta relations to enrich the aspect ùëò of target node. Thus, the task of the process is to design a mechanism inferring the related source neighbors under aspect ùëò. We suppose aspect ùëò is likely to be the major aspect of the meta relation if grouped source neighbors are similar w.r.t. aspect ùëò, i.e., they form a cluster in the ùëò ùë°‚Ñé subspace. Thus, the iterative forward propagation is actually a clustering process which searches the major cluster of the grouped neighbors and aggregates their features to the target node. We calculate the aspect weight of each meta relation for each iteration, which can attend source nodes in the largest cluster to prune noise and achieve fast convergence.</p><p>Convergence Analysis. The iterative forward propagation process is equivalent to an expectation maximization(EM) algorithm for the mixture model. , <ref type="bibr" target="#b10">(11)</ref> where the first term is evidence lower bound denoted by ELBO(ùê∂; ùëÖ, ùëç ) and second term is the Kullback-Leibler (KL) divergence with nonnegative value. Our model alternatively updates ùëû(ùëÖ) and ùëç by a) setting optimal ùëû(ùëÖ) to ùëù (ùëÖ|ùê∂; ùëç ) so that ELBO(ùê∂; ùëÖ, ùëç ) = ln ùëÉ (ùê∂; ùëç ) for current ùê∂ and ùëç in E step and b) maximizing ELBO w.r.t. ùëç in M step. Thus, for ùëñ ùë°‚Ñé iteration, ln ùëÉ (ùê∂; ùëç (ùëñ) ) ‚â• ELBO(ùê∂; ùëÖ (ùëñ) , ùëç (ùëñ) ) ‚â• ELBO(ùê∂; ùëÖ (ùëñ) , ùëç (ùëñ‚àí<ref type="foot" target="#foot_0">1</ref>) ) = ln ùëÉ (ùê∂; ùëç (ùëñ‚àí1) ), which improves the loglikelihood monotonically and the algorithm converges.</p><p>Automatic Meta Paths Selection. Our model can iteratively identify aspect weight of each meta relation which can be seen as the semantic relatedness among nodes. For each layer, we incorporate one hop neighbor information. And by stacking multiple layers, the proposed attention mechanism is able to automatically aggregate corresponding aspect information multiple hops away, which can be seen as a soft way to select meta paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we present experiments to evaluate the effectiveness of our proposed approach. We aim to answer the following research questions:</p><p>RQ1: How does DisenHAN perform compared with state-of-theart models for top-ùëÅ recommendation? Can DisenHAN has the potential to alleviate cold-start problems?</p><p>RQ2: Is it necessary to keep key components of DisnHAN, such as disentangled representation, meta relation aspect weight iterative calculation? How do hyper-parameters in DisenHAN impact recommendation performance?</p><p>RQ3: Will DisenHAN interpret different semantics of meta relations in HIN for recommendation?</p><p>We first present the experimental settings, followed by answering the above three research questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>5.1.1 Data Sets. We apply our model to three public accessible data sets for top-ùëÅ recommendation. The statistics of the data sets are summarized in Table <ref type="table">1</ref>.</p><p>Yelp 1 This is a widely adopted local business recommendation data set, where users can review local businesses online. We treat local businesses like restaurants as the items and each review as an interaction between the user and item. To ensure the quality of the data set, we use the core setting, i.e., retaining users and items with at least ten interactions and users with at least five friends.</p><p>Amazon-electricity<ref type="foot" target="#foot_1">2</ref> Amazon-review is a widely used data set for product recommendation <ref type="bibr" target="#b10">[11]</ref>. We select Amazon-electricity from the collection and treat each review as an interaction between the user and item. Similarly, we use the core setting to ensure that each user and item have at least eight interactions and each item has at least two related items.</p><p>MovieLens<ref type="foot" target="#foot_2">3</ref> This is a widely used benchmark data set in movie recommendation, which consists of explicit ratings on the Movie-Lens website. We follow the prior work <ref type="bibr" target="#b11">[12]</ref> to transform it into implicit data, where each interaction between the user and item is marked as 0 or 1 indicating whether the user has rated the item or not. We treat movies as the items and use the core setting where each user and item have at least five interactions in order to ensure data quality.</p><p>For each data set, we rank the interactions in chronological order and select the first 80% of historical interactions as the training set with the remaining 10%, 10% as the validation and test data set respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Evaluation Metrics.</head><p>For each user in the test data set, we treat all the items that the user has not interacted with as the negative items. Since it is time consuming to rank all items for every user during evaluation, we follow the common strategy that randomly samples 100 negative items and rank the test items among the 100 items for each user <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>. To evaluate the performance of top-ùëÅ recommendation for all methods, we adopt three widely used metrics: Precision, Recall and Normalized Discounted Cumulative Gain(NDCG). By default, we truncate the ranked list at 10 for both metrics, which are Prec@10, Recall@10 and NDCG@10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Baselines.</head><p>To demonstrate the effectiveness, we compare DisenHAN with three classes of methods: (A) classical CF methods; (B) HIN based recommenders, which model user-item interaction with rich context information as HIN; and (C) GNN based recommendation methods, which use information propagation way to exploit high-order connectivity in graph.</p><p>‚Ä¢ BPR-MF <ref type="bibr" target="#b22">[23]</ref> (A): This is a matrix factorization model optimized by the Bayesian personalized ranking (BPR), which exploits useritem implicit feedback directly. ‚Ä¢ NeuMF <ref type="bibr" target="#b11">[12]</ref> (A): This method combines the linearity of matrix factorization and non-linearity of deep neural networks for modeling the user-item interactions. ‚Ä¢ FMG ùëüùëéùëõùëò <ref type="bibr" target="#b42">[43]</ref> (B): This is a HIN based method which combines meta graph based matrix factorization with factorization machine for rating prediction. we follow the prior work <ref type="bibr" target="#b13">[14]</ref> to modify its optimization objective as BPR for top-ùëÅ recommendation.</p><p>‚Ä¢ MCRec <ref type="bibr" target="#b13">[14]</ref> (B): This method leverages meta-path based context with co-attention mechanism for top-ùëÅ recommendation in HIN.</p><p>Table <ref type="table">2</ref>: Results of effectiveness experiments on three different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Yelp Amazon Movielens</head><p>Prec@10 Recall@10 NDCG@10 Prec@10 Recall@10 NDCG@10 Prec@10 Recall@10 NDCG@10    baselines decreases with the increasing of training data. It indicates that our model can effectively improve the recommendation performance especially when the interaction records are sparse.</p><p>‚Ä¢ GNN based recommendation methods, i.e., NGCF, though captures the high connectivity information between users and items, can not guarantee the improvement over classical recommendation methods. This may attribute to the fact that they ignore the different aspects of semantic relations between users and items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Study of DisenHAN(RQ2)</head><p>As the disentangled propagation layer plays an important role in DisenHAN, we investigate its impact on the performance. We start by exploring the effect of aspect numbers for disentangled propagation layer, then we study how iteration times of each layer affect the performance. At last, we stack different numbers of disentangled propagation layers and compare the variations of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Effect of Disentangled Representation.</head><p>To investigate whether or not DisenHAN can benefit from disentangled representation, we study the performance of the model with varying aspect numbers in one disentangled propagation layer. In particular, we search the aspect numbers in the range of {1, 2, 5, 10}. Figure <ref type="figure" target="#fig_7">4</ref> summarizes the experimental results w.r.t. the Amazon data set and we have the following observations:</p><p>‚Ä¢ When the number of aspects for the representation is 1, the model can be degraded into HIN based GNN model without disentangled representation. The performance of the model is poor, which indicates modeling different aspects of semantic information can greatly facilitate the recommendation task.   ‚Ä¢ Increasing the number of aspects for disentangled propagation layer can substantially enhance the recommendation performance. And DisenHAN performs best when the number of aspects is around 5, which is close to the actual number in Amazon data set. ‚Ä¢ However, when the number of aspects is very large, i.e., ùêæ &gt; 10, the improvement is much lower which might be caused by applying too complex semantic structure for the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Effect of Iteration Times for Layer.</head><p>To further investigate how the iteration times affect the performance, we fix the aspect number of one disentangled propagation layer at 5 and consider the variants of the model with different iteration times. As shown in Figure <ref type="figure" target="#fig_8">5</ref>, we set the iteration times in the range of <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> and we have the following observations:</p><p>‚Ä¢ More iterations generally leads to better performance before saturation which is guaranteed by its convergence properties.</p><p>When the iteration times reach to 5, the performance becomes stable showing that few iteration times is enough to get the satisfactory performance. ‚Ä¢ Compared with other hyper parameters, i.e., the number of aspects, DisenHAN is not sensitive to the iteration times. This may be that multiple epochs of training can also make the model with smaller iteration times converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Effect of Propagation Layer Number</head><p>. By stacking different numbers of propagation layers, we investigate how the depth of DisenHAN affects the performance. In particular, we stack the layer numbers in the range of {1, 2, 3}. Table <ref type="table" target="#tab_1">3</ref> summarizes the experimental results and we have the following observations:  ‚Ä¢ More disentangled propagation layers will yield influence from high-order neighbors of the target node and increase the depth of model. Clearly, 2 layers of model achieve better performance than 1 layer. It means by stacking multiple propagation layers, we can automatically select the corresponding meta paths for each data set and aggregate information from meta paths based neighbors. ‚Ä¢ When stacking more than 2 propagation layers, the influence of the neighbors on the performance is small and can lead to overfitting. This is reasonable because short meta-paths is good enough <ref type="bibr" target="#b28">[29]</ref> and deep architecture might introduce noises to the representation learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Case Study and Visualization(RQ3)</head><p>To further investigate how the disentangled propagation layer facilitates the embedding learning. We explore the major aspect of each meta relation in test set. Then, we visualize node embeddings of DisenHAN and NGCF to conduct a qualitative assessment of the embedding results. aspects, user-item interaction is related to aspect A1 in Layer-1. Meanwhile, since there is only one meta relation for the user in Layer-1, the other relations are all related to aspect A1 in order to calculate the matching score. While in Layer-2, aspect A2, A3, A4 are more related to item context relations which can be categorized as ‚ü®Item, interact with ‚àí1 , User‚ü©, ‚ü®Item, has, Brand‚ü© and ‚ü®Item, has, Category‚ü©, respectively. This indicates that DisenHAN can capture different aspects of semantic information in HIN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Visualization.</head><p>For a more intuitive comparison, we conduct the task of visualization. We randomly select six users from amazon data set, as well as their relevant items. Figure <ref type="figure" target="#fig_9">7a</ref> and Figure <ref type="figure" target="#fig_9">7b</ref> show the results derived from DisenHAN and NGCF. One can quickly tell the differences that our model can effectively divide user and item nodes into two different groups. Meanwhile, the nodes correlated with different users exhibit discernible clustering, which demonstrates that different aspects of semantic information make a significant contribution to learn representation in HIN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this work, we propose a Disentangled Heterogeneous Graph Attention Network (DisenHAN) for top-ùëÅ recommendation in HIN.</p><p>To encode collaborative signals between users and items, we leverage embedding propagation to explicitly incorporate context information with rich semantic structure. We use meta relation to decompose high-order connectivity in HIN and propose a disentangled embedding propagation layer to aggregate different aspects of semantic information for users and items, respectively. Based on that, we can automatically generate meta paths with semantic information while capture major aspect of information flows in high-order connectivity. Extensive experiments on three real-world data sets demonstrate the effectiveness and interpretability of our model.</p><p>For future work, we will explore whether DisenHAN is able to capture dynamic interaction of users and items in temporal graph. Besides, we also plan to extend DisenHAN to general machine learning tasks in HIN, such as node classification and node clustering tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of different aspects for the item representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Aspect: 1 2 3</head><label>3</label><figDesc>Combination t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 6 9 t G c A A 1 l n L p 4 k Q y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>0 j 0 s S U J w n r 0 2 w T z 4 y z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W<ref type="bibr" target="#b6">7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s M H X r S P b w = = &lt; / l a t e x i t &gt; t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 6 9 t G c A A 1 l n L p 4 k Q y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>0 j 0 s S U J w n r 0 2 w T z 4 y z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W<ref type="bibr" target="#b6">7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s M H X r S P b w = = &lt; / l a t e x i t &gt; t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 6 9 t G c A A 1 l n L p 4 k Q y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>0 j 0 s S U J w n r 0 2 w T z 4 y z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W<ref type="bibr" target="#b6">7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s M H X r S P b w = = &lt; / l a t e x i t &gt; t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 6 9 t G c A A 1 l n L p 4 k Q y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 &lt; l a t e x i t s h a 1 _</head><label>51</label><figDesc>0 j 0 s S U J w n r 0 2 w T z 4 y z Z n / z n h l P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W 7 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s M H X r S P b w = = &lt; / l a t e x i t &gt; s b a s e 6 4 = " Y w e S 8 W 4 N C 0 x F m s 7 b b p V y 6 f 7 H b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>a e g F t E J S c 6 c e 8 + Z u f d 6 a R h k w r Z f C 8 b C 4 t L y S n G 1 t L a + s b l V 3 t 5 p Z U n O f d b 0 k z D h H c / N W B j E r C k C E b J O y p k b e S F r e + N z G W / f M p 4 F S X w l J i n r R e 4 o D o a B 7 w q i L r P + S b 9 c s S 1 b L X M e O B p U o F c j K b / g G g M k 8 J E j A k M M Q T i E i 4 y e L h z Y S I n r Y U o c J x S o O M M 9 S q T N K Y t R h k v s m L 4 j 2 n U 1 G 9 N e e m Z K 7 d M p I b 2 c l C Y O S J N Q H i c s T z N V P F f O k v 3 N e 6 o 8 5 d 0 m 9 P e 0 V 0 S s w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 b 1 4</head><label>4</label><figDesc>r h S s / S o i 9 j D P g 5 p n q e o o Y 4 G m u Q 9 w i O e 8 G z U j d j I j b v P V K O g N b v 4 t o y H D w b r k B A = &lt; / l a t e x i t &gt; s 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>5 &lt;</head><label>5</label><figDesc>n m P 8 Y g n P B s N I z I y 4 + 4 z 1 S j k m n 1 8 W 8 b D B w S L k A 8 = &lt; / l a t e x i t &gt; s l a t e x i t s h a 1 _ b a s e 6 4 = " Y w e S 8 W 4 N C 0 x F m s 7 b b p V y 6 f 7 H b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>7 &lt;</head><label>7</label><figDesc>1 b 1 4 r h S s / S o i 9 j D P g 5 p n q e o o Y 4 G m u Q 9 w i O e 8 G z U j d j I j b v P V K O g N b v 4 t o y H D w l L k B E = &lt; / l a t e x i t &gt; s l a t e x i t s h a 1 _ b a s e 6 4 = " 2 O r z s y v g u L p A / 1 7 q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>8 &lt;</head><label>8</label><figDesc>1 b 1 4 r R S t / S o i z j A I Y 5 p n j X U 0 U A T L f I e 4 x F P e D Y a R m z k x t 1 n q l H Q m n 1 8 W 8 b D B w u r k B I = &lt; / l a t e x i t &gt; s l a t e x i t s h a 1 _ b a s e 6 4 = " O w c d D w A 3 / F 8 I k 4 y j K N s R Y 5 n a f U 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 j D I h G 2 / F o y l 5 Z X V t e J 6 a W N z a 3 u n v L v X z p K c + 6 z l J 2 H C u 5 6 b s T C I W U s E I m T d l D M 3 8 k L W 8 S b n M t 6 5 Z T w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>d 1 b o 5 3 e U s a s P N z n I u g X b W c E 6 t 6 c V q p W 3 r U R R z g E M c 0 z z P U 0 U A T L f I e 4 x F P e D Y a R m z k x t 1 n q l H Q m n 1 8 W 8 b D B w 4 L k B M = &lt; / l a t e x i t &gt; t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M 6 9 t G c A A 1 l n L p 4 k Q y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>1 &lt;</head><label>1</label><figDesc>0 j 0 s S U J w n r 0 2 w T z 4 y z Z n / z n hl P f b c p / f 3 c K y R W 4 Z b Y v 3 T z z P / q d C 0 K I 5 y Z G g T V l B h G V 8 d y l 8 x 0 R d / c / l K V I o e E O I 2 H F J e E m V H O + 2 w b T W p q 1 7 3 1 T P z N Z G p W<ref type="bibr" target="#b6">7</ref> 1 m e m + F d 3 5 I G 7 P 4 c 5 y L o 1 K r u S b X W q l c a 9 X z U R R z g E M c 0 z 1 M 0 c I k m 2 s b 7 E U 9 4 t i 6 s w E q t 7 D P V K u S a f X x b 1 s M H X r S P b w = = &lt; / l a t e x i t &gt; s l a t e x i t s h a 1 _ b a s e 6 4 = "</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + / 1 k o A L a d u v B W N p e W V 1 r b h e 2 t j c 2 t 4 p 7 + 6 1 R Z y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>4 &lt; l a t e x i t s h a 1 _</head><label>41</label><figDesc>C H p 6 c G A j I a 6 P G X E p I a 7 j D P c o k T a j L E Y Z L r E T + o 5 p 1 8 v Zi P b K U 2 i 1 T 6 c E 9 K a k N H F E m p j y U s L q N F P H M + 2 s 2 N + 8 Z 9 p T 3 W 1 K f y / 3 C o m V u C H 2 L 9 0 8 8 7 8 6 V Y v E C G e 6 B k 4 1 J Z p R 1 f m 5 S 6 a 7 o m 5 u f q l K k k N C n M J D i q e Ef a 2 c 9 9 n U G q F r V 7 1 1 d f x N Z y p W 7 f 0 8 N 8 O 7 u i U N 2 P k 5 z k X Q r l p O z a p e n F T q V j 7 q I g 5 w i G O a 5 y n q a K C J F n m P 8 Y g n P B s N I z I y 4 + 4 z 1 S j k m n 1 8 W 8 b D B w I r k A 4 = &lt; / l a t e x i t &gt; s b a s e 6 4 = " M 4 y 7 b i h o 4 n i P e N y a j p z n W C h y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 zc + / 1 k s A X 0 r Z f C 8 b S 8 s r q W n G 9 t L G 5 t b 1 T 3 t 1 r i z h L G W + x O I j T r u c K H v g R b 0 l f B r y b p N w N v Y B 3 v M m 5 i n d u e S r 8 O L q S 0 4 T 3 Q 3 c c + S O f u Z K o S z G o D c o V 2 7 L 1 M h e B k 4 M K 8 t W M y y + 4 x h A x G D K E 4 I g g C Q d w I e j p w Y G N h L g + Z s S l h H w d 5 7 h H i b Q Z Z X H K c I m d 0 H d M u 1 7 O R r R X n k K r G Z 0 S 0 J u S 0 s Q R a W L K Sw m r 0 0 w d z 7 S z Y n / z n m l P d b c p / b 3 c K y R W 4 o b Y v 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>s 5 &lt;</head><label>5</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " Y w e S 8 W 4 N C 0 x F m s 7 b b p V y 6 f 7 H bv M = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z K q 6 L L g p s u K 9 g G 1 l C S d 1 t C 8 m E y U U g R / w K 1 + m v g H + h f e G a e g F t E J S c 6 c e 8 + Z u f d 6 a R h k w r Z f C 8 b C 4 t L y S n G 1 t L a + s b l V 3 t 5 p Z U n O f d b 0 k z D h H c / N W B j E r C k C E b J O y p k b e S F r e + N z G W / f M p 4 F S X w l J i n r R e 4 o D o a B 7 w q i L r P + S b 9 c s S 1 b L X M e O B p U o F c j K b / g G g M k 8 J E j A k M M Q T i E i 4 y e L h z Y S I n r Y U o c J x S o O M M 9 S q T N K Y t R h k v s m L4 j 2 n U 1 G 9 N e e m Z K 7 d M p I b 2 c l C Y O S J N Q H i c s T z N V P F f O k v 3 N e 6 o 8 5 d 0 m 9 P e 0 V 0 S s w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>1 b 1 4 6 &lt; l a t e x i t s h a 1 _ b a s e 6 4 =</head><label>4614</label><figDesc>r h S s / S o i 9 j D P g 5 p n q e o o Y 4 G m u Q 9 w i O e 8 G z U j d j I j bv P V K O g N b v 4 t o y H D w b r k B A = &lt; / l a t e x i t &gt; s " v H x 3 l L c K n 8 U l R D C I V 9 O R u h P f a 3 Q = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q 6 r L g p s u K 9 g G 1 l C S d 1 t C 8 m E y U U g R / w K 1 + m v g H + h f e Ga e g F t E J S c 6 c e 8 + Z u f d 6 a R h k w r Z f C 8 b C 4 t L y S n G 1 t L a + s b l V 3 t 5 p Z U n O f d b 0 k z D h H c / N W B j E r C k C E b J O y p k b e S F r e + N z G W / f M p 4 F S X w l J i n r R e 4 o D o a B 7 w q i L r P + S b 9 c s S 1 b L X M e O B p U o F c j K b / g G g M k 8 J E j A k M M Q T i E i 4 y e L h z Y S I n r Y U o c J x S o O M M 9 S q T N K Y t R h k v s m L 4 j 2 n U 1 G 9 N e e m Z K 7 d M p I b 2 c l C Y O S J N Q H i c s T z N V P F f O k v 3 N e 6 o 8 5 d 0 m 9 P e 0 V 0 S s w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>1 b 1 4 7 &lt; l a t e x i t s h a 1 _ b a s e 6 4 =</head><label>4714</label><figDesc>r h S s / S o i 9 j D P g 5 p n q e o o Y 4 G m u Q 9 w i O e 8 G z U j d j I j b v P V K O g N b v 4 t o y H D w l L k B E = &lt; / l a t e x i t &gt; s " 2 O r z s y v g u L p A / 1 7 q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 j D g w r Z f C 8 b S 8 s r q W n G 9 t L G 5 t b 1 T 3 t 1 r 8 y T P f N b y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>u 2 o 5 J 8 &lt; l a t e x i t s h a 1 _</head><label>581</label><figDesc>1 b 1 4 r R S t / S o i z j A I Y 5 p n j X U 0 U A T L f I e 4 x F P e D Y a R m z k x t 1 n q l H Q m n 1 8 W 8 b D B w u r k B I = &lt; / l a t e x i t &gt; s b a s e 6 4 = " O w c d D w A 3 / F 8 I k 4 y j K N s R Y 5 n a f U 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 j D I h G 2 / F o y l 5 Z X V t e J 6 a W N z a 3 u n v L v X z p K c + 6 z l J 2 H C u 5 6 b s T C I W U s E I m T d l D M 3 8 k L W 8 S b n M t 6 5 Z T w L k v h K T F P W j 9 x x H I w</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>d 1 b o 5 3 e 9 &lt; l a t e x i t s h a 1 _ b a s e 6 4 =</head><label>3914</label><figDesc>U s a s P N z n I u g X b W c E 6 t 6 c V q p W 3 r U R R z g E M c 0 z z P U 0 U A T L f I e 4 x F P e D Y a R m z k x t 1 n q l H Q m n 1 8 W 8 b D B w 4 L k B M = &lt; / l a t e x i t &gt;s " g d W i g b E U E l D H v 7 x 1 S a S J 6 U q T 7 U g = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z I q q L u C m y 4 r 2 g f U U p J 0 W k P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 5 y C W k Q n J D l z 7 j 1 n 5 t 7 r p W G Q C d t + L R g L i 0 v L K 8 X V 0 t r 6 x u Z W e X u n l S U 5 9 1 n T T 8 K E d z w 3 Y 2 E Q s 6 Y I R M g 6 K W d u 5 I W s 7 Y 3 P Z b x 9 y 3 g W J P G V m K S s F 7 m j O B g G v i u I u s z 6 Z / 1 y x b Z s t c x 5 4 G h Q g V 6 N p P y C a w y Q w E e O C A w x B O E Q L j J 6 u n B g I y W u h y l x n F C g 4 g z 3 K J E 2 p y x G G S 6 x Y / q O a N f V b E x7 6 Z k p t U + n h P R y U p o 4 I E 1 C e Z y w P M 1 U 8 V w 5 S / Y 3 7 6 n y l H e b 0 N /</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>r 2 v c 3 O 10 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f k 4</head><label>310144</label><figDesc>8 y 1 v S g J 2 f 4 5 w H r a r l H F n V i + N K z d K j L m I P + z i k e Z 6 g h j o a a J L 3 C I 9 4 w r N R N 2 I j N + 4 + U 4 2 C 1 u z i 2 z I e P g A Q a 5 A U &lt; / l a t e x i t &gt; s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>g 1 3 12 &lt;</head><label>312</label><figDesc>s 0 z y P U M E p q q i R 9 z U e 8 Y R n 4 8 y 4 M e 6 M + 8 9 U I 5 d p t v F t G Q 8 f N M S R U w = = &lt; / l a t e x i t &gt; s l a t e x i t s h a 1 _ b a s e 6 4 = " 4 g f R / l D g 1 l r 8 z N 8 5 a 0 d Z r D w 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: A schematic view of the DisenHAN. Node shapes and colors indicate types and features, respectively. We assume that there are three aspects for the nodes. The same color between nodes and the relation denotes the major aspect of the relation where the grouped neighbors are similar in ùëò ùë°‚Ñé channel. The model iteratively takes features of target node ùë° as well as its neighbors as input and output three channels of disentangled representation for ùë°. The output of the channels is feed back as features for the next iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>4. 3 . 1</head><label>31</label><figDesc>Intra-relation Aggregation. After type-specific transformation, the intra-relation layer learns the semantic information embedded in each meta relation ùúì (ùëí) by aggregating the features of grouped source nodes ùëÅ ùúì (ùëí) . Despite the grouped neighbors are of the same type, different nodes still play an unequal role for each aspect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>= ùëê ùë°,ùëò initially, ‚à• denotes the concatenation operation. Considering different contribution of node importance under each aspect, we calculate the importance of the node by weighted summing all aspects: ùëí ùúì (ùëí) ùë°,ùë† = ùêæ ùëò=1 ùëü (ùëñ‚àí1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head></head><label></label><figDesc>ùúì (ùëí),ùëò = 1/ùêæ initially and the weight can be iteratively learned in inter-relation aggregation. After that, we can get the normalized attention weight for the grouped source nodes and aggregate their features under each aspect, ùõº ùúì (ùëí) ùë°,ùë† = softmax(ùëí ùúì (ùëí) ùë°,ùë† ) = exp(ùëí ùúì (ùëí) ùë°,ùë† ) ùë† ‚Ä≤ ‚ààùëÅ ùúì (ùëí ) exp(ùëí ùúì (ùëí) ùë°,ùë† ‚Ä≤ ) , ùëß ùúì (ùëí) ùë°,ùëò = ùúé ( ùë† ‚ààùëÅ ùúì (ùëí ) ùõº ùúì (ùëí) ùë°,ùë† ‚Ä¢ ùëê ùë†,ùëò ),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Algorithm 1 : 19 for</head><label>119</label><figDesc>),ùëò can in turn feed back to guide the attention weight for each meta relation grouped neighbors. The final enriched disentangled representation of target node ùë° can be denoted as {ùëß (ùêº ) ùë°,1 , ùëß (ùêº ) ùë°,2 , . . . , ùëß (ùêº ) ùë°,ùêæ } and the overall iterative propagation process is shown in Algorithm 1. DisenHAN iterative forward propagation Input: Features of target node ùë• ùë° ‚àà R ùëë ùëñùëõ ; all connected meta relations ùúì ùë° ; features of meta relation grouped neighbors {ùë• ùë† ‚àà R ùëë ùëñùëõ , ‚àÄùë† ‚àà ùëÅ (ùë°)} Output: {ùëß ùë°,1 , . . . , ùëß ùë°,ùêæ } (disentangled representation of ùë°) 1 for ùë£ ‚àà {ùë° } ‚à™ {ùë† : ùë† ‚àà ùëÅ (ùë°)} do 2 for ùëò = 1, 2, . . . , ùêæ do 3 ùëê ùë£,ùëò ‚Üê ùúé (ùëä ùúô (ùë£),ùëò ‚Ä¢ ùë• ùë£ ); 4 ùëê ùë£,ùëò ‚Üê ùëê ùë£,ùëò /‚à•ùëê ùë£,ùëò ‚à• 2 ; ‚Üê ùëê ùë°,ùëò , ‚àÄùëò = 1, 2, . . . , ùêæ; // Initialize ùêæ channels 8 for forward propagation iteration ùëñ = 1, 2, . . . , ùêº do 9 for each meta relation ùúì (ùëí) ‚àà ùúì ùë° do 10 for ùëò = 1, 2, . . . , ùêæ do 11 for ùë£ ‚àà ùëÅ ùúì (ùëí) do 12 Calculate ùëí ùëò ùë°,ùë† using ùëß ùúì (ùëí),ùëò , ‚àÄùëò = 1, 2, . . . , ùêæ ; // Eq.5-6 18 end ùëò = 1, 2, . . . , ùêæ do 20 ùëß (ùëñ) ùë°,ùëò = ùëê ùë°,ùëò + ùúì (ùëí) ‚ààùúì ùë° ùëü (ùëñ) ùúì (ùëí),ùëò ùëä ùëß ùúì (ùëí) , ‚àÄùëò = 1, 2, . . . , ùêæ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head></head><label></label><figDesc>Let ùëç = {ùëß ùë°,ùëò } ùêæ ùëò=1 as estimated representation of target ùë°, ùê∂ = {ùëê ùë£,ùëò : ùë£ ‚àà {ùë° } ‚à™ {ùë† : ùë† ‚àà ùëÅ (ùë°)}} as noisy observation of ùëç and ùëÖ = ùëü ùúì (ùëí),ùëò for each meta relation. The EM algorithm maximize ùëù (ùê∂; ùëç ) = ùëÖ ùëù (ùê∂, ùëÖ; ùëç ), and the log-likelihood can be formulated as ln ùëÉ (ùê∂; ùëç ) = ùëÖ ùëû(ùëÖ) ln ùëÉ (ùê∂, ùëÖ; ùëç ) ùëû(ùëÖ) + ùëÖ ùëû(ùëÖ) ln ùëû(ùëÖ) ùëù (ùëÖ|ùê∂; ùëç )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Table 1 :</head><label>1</label><figDesc>Descriptive statistics of our three datasets. B: 1,347,861 #U-B: 41.3/39.4 #business(B): 34,193 #U-U: 1,566,400 #U-U: 48.0/48.0 #city(Ci): 387 #B-Ci:34,193 #B-Ci: 1.0/88.4 #category(Ca): 1006 #B-Ca: 156,886 #B-Ca: 4.6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance comparison over the sparsity distribution of data on Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance w.r.t. different aspect numbers on Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance w.r.t. different iteration times on Amazon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Visualization of the learned major facet and corresponding weight of each meta relation for Amazon data set. A1, A2, A3, A4, A5 represent 5 aspects of the relation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>5. 4 . 1 Figure 7 :</head><label>417</label><figDesc>Figure 7: Visualization of the learned t-SNE transformed representations. Each star represents a user from Amazon data set, while the points with the same color denote the relevant items.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>GC-MC<ref type="bibr" target="#b29">[30]</ref> (C): This model adopts GCN<ref type="bibr" target="#b16">[17]</ref> encoders in useritem bipartite graph to generate the representation of users and items, where only the first-order neighbors are considered.‚Ä¢ NGCF<ref type="bibr" target="#b36">[37]</ref> (C): This model uses embedding propagation layer to enrich user and item representations for exploiting high order connectivity in user-item bipartite graph.‚Ä¢ HAN<ref type="bibr" target="#b37">[38]</ref> (C): This is a heterogeneous graph neural network with attention mechanism to aggregate neighbor information via different meta paths. We modify the model for top-ùëÅ recommendation.5.1.4 Implementation Detail.We implement our DisenHAN model in Pytorch. The embedding size is fixed to 100 for all models. For our method, we set two propagation layers and the number of iterations ùêº per layer is 5 in default setting. Within the first and second layers, we set the number of aspects as 5, corresponding embedding dimension is 20 per aspect. To prevent overfitting, we employ dropout where the ratio is tuned amongst {0.0, 0.1, . . . , 0.9}. We optimize DisenHAN with Adam optimizer by setting the learning rate to 0.005 and using early stopping with a patience of 20, i.e. we stop training if recall@10 on the validation set does not increase for 20 successive epochs. For baseline methods, we split exactly the same training, validation and test set as DisenHAN and apply gird search for optimal hyper-parameters. We summarize the results by comparing the performance of all the methods shown in table 2 and have the following observations.‚Ä¢ HIN based recommendation methods, FMG ùëüùëéùëõùëò , MCRec and NeuACF, utilize designed meta paths to capture semantic relations between user and item node pairs. By modeling this context information, the performance of HIN based recommenders improves compared to the classical CF methods in most cases. However, due to the lack of explicit encoding CF signals, high-order connectivity of users and items are still hard to be captured and the improvement is marginal. Moreover, meta paths selection in these HIN based methods is more rely on prior knowledge from domain experts which can have a great effect on the performance. ‚Ä¢ GNN based methods achieve better performance than classical CF methods in most cases, which indicates the positive effect of modeling high-order connectivity based on information propagation. However, GC-MC only utilizes the first-order neighbors to guide the information aggregation, and NGCF utilizes multiple-order neighbors without semantic relations in HIN. HAN models information propagation on meta path based neighbors. Compared with the GC-MC and NGCF, HAN improves the recommendation performance which verifies the importance of capturing collaborative signals by modeling semantic relations in HIN.</figDesc><table><row><cell></cell><cell>0.08</cell><cell>BPR-MF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.30</cell><cell></cell><cell></cell><cell></cell><cell>0.35</cell><cell>BPR-MF</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>NeuMF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NeuMF</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.07</cell><cell>FMGrank MCRec</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.25</cell><cell></cell><cell></cell><cell></cell><cell>0.30</cell><cell>FMGrank MCRec</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>NeuACF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NeuACF</cell><cell></cell><cell></cell></row><row><cell>Prec@10</cell><cell>0.03 0.04 0.05 0.06</cell><cell>BPR-MF NeuMF FMG rank GC-MC NGCF HAN DisenHAN</cell><cell></cell><cell>0.2793 0.2717 0.2810</cell><cell>0.4734 0.4463 0.4749</cell><cell>Recall@10</cell><cell>0.5996 0.5899 0.6055 0.10 0.15 0.20</cell><cell>0.0780 0.0811 0.0788</cell><cell>0.2897 0.2791 0.2717</cell><cell>0.3126 0.3164 0.3120 DisenHAN NGCF HAN GC-MC BPR-MF NeuMF FMGrank MCRec NeuACF NDCG@10</cell><cell>0.10 0.15 0.20 0.25</cell><cell>0.4864 0.6016 0.5642 GC-MC NGCF HAN DisenHAN</cell><cell>0.1518 0.1710 0.1460</cell><cell></cell><cell>0.6964 0.7375 0.7838</cell></row><row><cell></cell><cell>0.02</cell><cell>MCRec 20%</cell><cell>40%</cell><cell>0.2874 60%</cell><cell>0.4642 80%</cell><cell></cell><cell>0.6023 20% 0.05</cell><cell>0.0753 40%</cell><cell>0.2882 60%</cell><cell>0.3048 80%</cell><cell>0.05</cell><cell>0.5477 20%</cell><cell>0.1477 40%</cell><cell>60%</cell><cell>0.7511</cell><cell>80%</cell></row><row><cell></cell><cell></cell><cell>NeuACF</cell><cell></cell><cell>0.2928</cell><cell>0.4861</cell><cell></cell><cell>0.6215</cell><cell>0.0714</cell><cell>0.2686</cell><cell>0.2833</cell><cell></cell><cell>0.5855</cell><cell>0.1682</cell><cell></cell><cell>0.7719</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(a) Prec@10</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Recall@10</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(c) NDCG@10</cell></row><row><cell></cell><cell></cell><cell>GC-MC</cell><cell></cell><cell>0.2819</cell><cell>0.4750</cell><cell></cell><cell>0.5983</cell><cell>0.0799</cell><cell>0.2760</cell><cell>0.3026</cell><cell></cell><cell>0.4964</cell><cell>0.1508</cell><cell></cell><cell>0.7061</cell></row><row><cell></cell><cell></cell><cell>NGCF</cell><cell></cell><cell>0.2853</cell><cell>0.4803</cell><cell></cell><cell>0.6075</cell><cell>0.0754</cell><cell>0.2829</cell><cell>0.2953</cell><cell></cell><cell>0.5533</cell><cell>0.1662</cell><cell></cell><cell>0.7532</cell></row><row><cell></cell><cell></cell><cell>HAN</cell><cell></cell><cell>0.3102</cell><cell>0.4937</cell><cell></cell><cell>0.6227</cell><cell>0.0830</cell><cell>0.2872</cell><cell>0.3166</cell><cell></cell><cell>0.5770</cell><cell>0.1524</cell><cell></cell><cell>0.7681</cell></row><row><cell></cell><cell cols="3">DisenHAN(Ours)</cell><cell>0.3174</cell><cell>0.5117</cell><cell></cell><cell>0.6512</cell><cell>0.0859</cell><cell>0.3193</cell><cell>0.3451</cell><cell></cell><cell>0.6145</cell><cell>0.1761</cell><cell></cell><cell>0.8000</cell></row><row><cell cols="9">‚Ä¢ NeuACF [10] (B): This method considers multiple aspects of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="8">users and items with a deep neural network for recommendation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">in HIN.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="16">‚Ä¢ 5.2 Performance Comparison(RQ1) 5.2.1 Overall Comparison. ‚Ä¢ DisenHAN performs consistently better than other baselines on all the datasets. In particular, DisenHAN improves over the strongest baselines w.r.t. Prec@10 by 2.3%, 3.5%, 2.1%; Recall@10 by 3.6%, 10.8%, 3.0% and NDCG@10 by 4.6%, 9.0%, 2.1% in Yelp, Amazon-electricity and Movielens respectively. By stacking mul-tiple disentangled propagation layers, DisenHAN is capable of exploring high-order connectivity in HIN with an explicit way, so as to capture collaborative signal effectively. Compared with HIN based and GNN based methods, DisenHAN can capture different aspects of semantic information and the significant improvement indicates the positive effect to achieve better representations for recommendation. 5.2.2 Cold-start Recommendation. The sparsity issue usually limits the performance of recommender systems since few user-item in-teractions are insufficient to generate high-quality representations. HINs are particularly useful to alleviate the problem by consider-ing the context information of users and items. We study whether</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">DisenHAN can alleviate this issue. Towards this end, we divide the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">training data into five equal folds and vary the amount of training</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">data from one fold to four folds, corresponding to 20%, 40%, 60%,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">80% of entire training data as training sets. Figure 3 illustrates the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">performance w.r.t. different sparsity distribution of data in Amazon</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">data set. Yelp and Movielens data sets are similar and omitted due</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">to the space limitation. We find that:</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">‚Ä¢ DisenHAN consistently outperforms other baselines over the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">sparsity distribution of data, and the improvement over other</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Effect of disentangled propagation layer numbersData sets Layers Prec@10 Recall@10 NDCG@10</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>0.3120</cell><cell>0.5051</cell><cell>0.6528</cell></row><row><cell></cell><cell>Yelp</cell><cell></cell><cell>2</cell><cell>0.3174</cell><cell>0.5117</cell><cell>0.6512</cell></row><row><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>0.3136</cell><cell>0.5059</cell><cell>0.6444</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>0.0857</cell><cell>0.3182</cell><cell>0.3414</cell></row><row><cell cols="3">Amazon</cell><cell>2</cell><cell>0.0859</cell><cell>0.3193</cell><cell>0.3451</cell></row><row><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>0.0858</cell><cell>0.3185</cell><cell>0.3398</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>0.6084</cell><cell>0.1748</cell><cell>0.7869</cell></row><row><cell cols="3">Movielens</cell><cell>2</cell><cell>0.6145</cell><cell>0.1761</cell><cell>0.8000</cell></row><row><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>0.6112</cell><cell>0.1741</cell><cell>0.7932</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Category</cell></row><row><cell></cell><cell></cell><cell>User</cell><cell></cell><cell></cell><cell>User</cell><cell>Item</cell><cell>Brand</cell></row><row><cell></cell><cell></cell><cell cols="2">A1(0.62)</cell><cell></cell></row><row><cell>User</cell><cell>Item A1(0.31) A 1 (0</cell><cell cols="3">Item .6 3 ) A 5 (0 .3 4 ) A5(0.77) Brand Category</cell><cell>Item A 5 (0 .</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.yelp.com/dataset/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">http://jmcauley.ucsd.edu/data/amazon/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://grouplens.org/datasets/hetrec-2011/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This paper is supported by National Key Research and Development Program of China with Grant No. 2018AAA0101900 / 2018AAA0101902 as well as the National Natural Science Foundation of China (NSFC Grant No. 61772039 and No. 91646202). We also thank Meituan-Dianping Group for their support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning Heterogeneous Knowledge Base Embeddings for Explainable Recommendation</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahid</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep Variational Information Bottleneck</title>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Representation Learning: A Review and New Perspectives</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zikun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2172" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Variational Lossy Autoencoder</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wide &amp; Deep Learning for Recommender Systems</title>
		<author>
			<persName><forename type="first">Heng-Tze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levent</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremiah</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrishi</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Ispir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zakaria</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichan</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vihan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hemal</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
				<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation</title>
		<author>
			<persName><forename type="first">Junxiong</forename><surname>Shaohua Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linmei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongliang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2478" to="2486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Aspect-Level Deep Collaborative Filtering via Heterogeneous Information Networks</title>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
				<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3393" to="3399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
				<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
				<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</title>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lo√Øc</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Leveraging Metapath based Context for Top-N Recommendation with A Neural Co-Attention Model</title>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1531" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Transformer</title>
		<author>
			<persName><forename type="first">Ziniu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM / IW3C2</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2704" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Disentangled Representation Learning for Non-Parallel Text Style Transfer</title>
		<author>
			<persName><forename type="first">Vineet</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the</title>
				<meeting>the 57th Conference of the</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics. Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Matrix Factorization Techniques for Recommender Systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding</title>
		<author>
			<persName><forename type="first">Ninghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoyu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuening</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="932" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Disentangled Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
				<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4212" to="4221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning Disentangled Representations for Recommendation</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5712" to="5723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">BPR: Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence</title>
				<meeting>the 25th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dynamic Routing Between Capsules</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3856" to="3866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Heterogeneous Information Network Embedding for Recommendation</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SemRec: a personalized semantic recommendation method based on weighted heterogeneous information networks</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yugang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weipeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="153" to="184" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semantic Path based Personalized Recommendation on Weighted Heterogeneous Information Networks</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yading</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 24th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="453" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks</title>
		<author>
			<persName><forename type="first">Weiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chence</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yewen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1161" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Wu</surname></persName>
		</author>
		<title level="m">Path-Sim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information Networks. Proc. VLDB Endow</title>
				<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="992" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<title level="m">Graph Convolutional Matrix Completion</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li√≤</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph capsule convolutional neural networks</title>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Li</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint ICML and IJCAI Workshop on Computational Biology</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Knowledge-aware Graph Neural Networks with Label Smoothness Regularization for Recommender Systems</title>
		<author>
			<persName><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="968" to="977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Knowledge Graph Convolutional Networks for Recommender Systems</title>
		<author>
			<persName><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3307" to="3313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">KGAT: Knowledge Graph Attention Network for Recommendation</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="950" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural Graph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Attention Network</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Capsule Graph Neural Network</title>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Xinyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihui</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Personalized entity recommendation: a heterogeneous information network approach</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Sturt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM International Conference on Web Search and Data Mining</title>
				<meeting>the 7th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="283" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Neural Network</title>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="793" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Collaborative Knowledge Base Embedding for Recommender Systems</title>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Jing Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks</title>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dik</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
