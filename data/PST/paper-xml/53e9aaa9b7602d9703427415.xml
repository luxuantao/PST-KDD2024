<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C4D8E59349B721CB93C4DA2993D54854</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experience With the Accuracy of Software Maintenance Task Effort Prediction Models Magne Jnrgensen</head><p>Abstract-This paper reports experience from the development and use of eleven different software maintenance effort prediction models. The models were developed applying regression analysis, neural networks and pattern recognition and the prediction accuracy was measured and compared for each model type. The most accurate predictions were achieved applying models based on multiple regression and on pattern recognition. We suggest the use of prediction models as instruments to support the expert estimates and to analyse the impact of the maintenance variables on the maintenance process and product. We believe that the pattern recognition based models evaluated, i.e., the prediction models based on the Optimized Set Reduction method, show potential for such use.</p><p>Index T e r m -C o s t models, neural network, pattern recognition, prediction models, regression, software maintenance, software measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>REDICTIONS of effort needed to carry out software mainte-P nance tasks may be an important input to maintenance managers when planning maintenance activities and performing costhenefit analyses. It is therefore surprising that very few research papers have been published describing the development and evaluation of formal models to predict software maintenance task effort; see however [l] and <ref type="bibr">[2]</ref>. A large number of papers describing prediction models for software development effort have, on the other hand, been published since at least 1966 <ref type="bibr">[3]</ref>.</p><p>A result of this lack of research on effort prediction models for software maintenance tasks is that the maintenance managers have to base their maintenance activity plans on expert judgements of needed maintenance effort or a combination of expert judgements and software development effort prediction models. For example, in a study conducted in a large Norwegian organisation we found that the predictions of maintenance task effort either were purely based on expert judgements or on a combination of expert judgements and the estimation part of the MkII Function Point Analysis [4]. In our opinion, none of these strategies is optimal.</p><p>Expert based effort predictions may have an acceptably high accuracy, but do not enable objective and quantitative analysis of what affects the maintenance productivity, or a packaging of experience independent of the experts.</p><p>If the predictions are based on formal software development effort prediction models, such as the estimation part of the of Oslo. e-mail: Magne.Jorgensen@tf.telenor.no.</p><p>MkII Function Point Analysis, essential differences in characteristics between software development and software maintenance are neglected, which are, for example: the focus of software development is the creation of software, but the focus of software maintenance is more the change of software. the development of a software application typically is a one-of-a-kind project, but the maintenance activities on an application usually comprise a large number of tasks carried out over a long period of time in a relatively stable environment. From these differences it follows, for example, that the variables to include in an effort prediction model and the calibration possibilities of the prediction model Within an organisation are not necessarily the same for software development and maintenance.</p><p>In this paper the focus is on the development and the relative accuracy of different types of software maintenance task effort prediction models. In addition, we give a brief evaluation on how the different types of prediction models may assist the human expert in the prediction process and enable improvements to the maintenance process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. COLLECTION OF DATA ABOUT " I E N A N C E TASKS</head><p>During a six-month period in 1992-1993, we collected data on 109 randomly selected maintenance tasks in a large Norwegian organisation with about 20,000 employees. The 110 maintainers of the organisation maintained more than 70 applications. Most applications were written in Cobol or in a Fourth Generation Language and were connected to a network database on a mainfiame. The size of the applications varied fiom a few thousand lines of code (LOC) to about 500,000 LOC, and the age of the applications varied fiom less than a year to more than 20 years. The functions of the applications included payroll, order entry, billing and invoicing, inventory control, service management, and personnel administration.</p><p>Among others, the following data were collected for each maintenance task 0 Type of maintenance task, i.e., corrective, adaptive, perfective or preventative maintenance (for definitions see 0 Priority of task, i.e., high, medium or low priority. High priority means that maintenance is needed immediately, medium priority means that maintenance is needed, but not necessarily immediately, low priority means that maintenance is wanted, but not essential to the application. Notice that the priorities were determined by the developers, not the managers. 0 Maintainer's knowledge and confidence about how to solve the task immediately after having read or heard the task specification. This variable was divided into three categories: Know how to solve the task, may know how to solve the task, do not know how to solve the task. 0 Years of experience as maintainer, and on the maintained application. 0 Education level of the maintainer. 0 <ref type="bibr">Work-hours (effort)</ref> spent on the task.</p><p>Task size (see Section 1II.A) and the programming languages used. 0 Types of change on code, i.e., introductioddeletion of module, change of interface, change of control flow, change of data declarations, change of data or assignment statement. 0 Information sources used, i.e., communication with the users of the application, user documentation, language or tool documentation, communication with system personnel, communication with other maintainers and use of application system documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>151).</head><p>Age and size of the changed application. 0 Informal description of the task. The data were collected through interviews with the maintainers immediately before they started the maintenance task and immediately after they had completed the task. The advantages of this approach are that the tasks are well-remembered and that detailed data are available. The dataset is available upon request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DI. DESIGN AND IMPLEMENTATION OF THE EFFORT PREDICTION MODELS</head><p>Important design decisions were: 0 the definition of the size of a maintenance task (Section 0 the variables to include in the prediction models (Section</p><formula xml:id="formula_0">1II.A) 1II.B)</formula><p>ware, lines of code (LOC) and Function Points, which are candidates for the measurement of software maintenance task size.</p><p>We chose a size measure based on LOC because LOC was easy to measure and standardised through the use of same or similar code standards within the organisation. The measure "Function Points" was considered as a candidate size measure, but had several disadvantages. For example, the number of Function Points is not very meaningful on small maintenance tasks, change oriented tasks and on maintenance tasks not concemed with user fhctionality. Size of a maintenance task was defined as: Size = LOC Inserted -I-LOC Updated -I-LOC Deleted. Comments inserted, updated or deleted were included in the number of LOC. The above size definition is similar to how software size during iterative software development is defined in the cost estimation model described in [6].</p><p>A measure based on LOC has disadvantages, as well. The size in LOC does not reflect task characteristics such as change of software functionality, quality and usefulness, very well. Neither does it reflect most of what the maintainer really does, such as design, test, documentation, and analysis activities. Better measures on the size of a maintenance task are, therefore, needed and research on this topic may be important to improve the quality of the maintenance effort prediction models.</p><p>We have used the actual and not the predicted task size in our comparison of the prediction models. This, is in our study, is not a serious limitation, since it focuses on the comparison of the relative prediction accuracy, and since the accuracy of each of the models is evaluated on the same data. The error source with respect to incorrect size prediction can, for this reason, be assumed to be the same for all the prediction models. Nevertheless, the size of a maintenance task should be possible to predict reasonably accurately, otherwise the types of prediction models compared in this study are not relevant.</p><p>Unfortunately, there are, as far as we know, no studies indicating how accurate maintenance task size can be predicted. There are, however, empirical studies on the accuracy of the prediction of software development size. These studies suggest that the size predictions based on the program specification alone may be very inaccurate [7], while the size predictions based on the high-level design may be rather accurate [SI.</p><p>Although the empirical results are lacking we will in the following assume that the maintenance task size can be reasonably accurately predicted and that the use of our LOC based size measure is meaningful. These assumptions should, however, be a subject for M e r research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Size of a Maintenance Task</head><p>The estimated size of a maintenance task is, probably, the most important input to an effort prediction model. Presently, there are only two commonly used measures of size of soft-extent possible to estimate in advance. Maintenance productivity is defined in this paper as:</p><formula xml:id="formula_1">(LOC inserted + LOC updated + LOC deleted) I eflort used on the task.</formula><p>The significance of a correlation was studied through the application of the t-tests with separate variance on the mean productivity values. The t-test on the mean values is assumed to be appropriate since the sample sizes are rather large, see <ref type="bibr" target="#b8">[9]</ref> or <ref type="bibr">[lo]</ref>.</p><p>The variables included in the effort prediction models are Cause of task, Change degree on code, Type of operation on code (Mode), and Confidence of maintainer, which all significantly predicted the maintenance productivity.</p><p>If two categories of a variable did not have a significantly different mean maintenance productivity the categories were joined. For example, there was no significant difference in maintenance productivity between adaptive and perfective maintenance tasks. The only significant difference was between corrective tasks and the other types of tasks.</p><p>The included variable, together with the categories significantly predicting the productivity were: 0 Cause: Corrective maintenance = 0, otherwise = 1 0 Change: More than 50% of the effort is believed to be spent on updating of code compared to inserting and deleting the code = 0, otherwise = l Mode: More than 50% of the effort is believed to be spent on development of new modules (New module mode) = 0, otherwise (Embedded mode) = 1 Confidence: The maintainer believes he/she knows how to solve the task when the task specification is readheard the first time = 0 (High confidence), otherwise = 1 (Medium or low confidence).</p><p>The correlation analysis showed that the following variables were not significantly correlating with the maintenance productivity:</p><p>Type of language: Dividing the programming languages into the two types 3GL (mainly Cobol) and 4GL (mainly ADS Online) showed that the productivity was almost the same for these two language types (34 LOC/maintenance-day vs. 36 LOC/maintenance-day) (p = 0.84).</p><p>Maintainer experience: All maintainers with either more than three years' experience on the application maintained, or more than three years' total experience and more than one year on the application maintained were classified as experienced. The other maintainers were classified as inexperienced. Surprisingly, the mean productivity of the experienced maintainers turned out to be lower than the mean productivity of the inexperienced.</p><p>The difference 43 LOC/maintenance-day vs 31 LOC/maintenance-day was, however, not significant (p = 0.22). Possible reasons for this result may be that the more experienced maintainers get the more difficult tasks and/or that the less experienced maintainers produce more code to solve a task. 0 Task priority: The priority of the tasks gave only small differences in the productivity. The high priority tasks had a mean productivity of 34 LOC/maintenance-day and the medium and low priority tasks had a mean productivity of 39 LOC/maintenance-day (p = 0.64).</p><p>;ACTIONS ON SOFTWARE ENGINEERING, VOL. This does not mean that these variables are not important for the maintenance efficiency (for example understood as the amount of functionality changed per person day). As described earlier, it is for example possible that the more experienced maintainers developed the most compact code and, therefore, had a lower productivity, measured in Size of task in LOC/effort. To make a prediction model really useful as an instrument to analyse the maintenance process such relations should be analysed and included in the prediction model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The Approaches</head><p>oped applying the approaches described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. I. Regression</head><p>The regression approach is frequently used when analysing the functional relations between variables. First, the model type, for example Effort = a Sizeb, and the cost function, for example CFl,,,n(actual effort,predicted effortJ2 where i is the task index and n the number of tasks, must be chosen. Then, trying to minimise the cost function, the values of the parameters of the model type are calculated. The regression approach is described in, for example, [ll]. Overfitting to the learning set may be a problem for multiple regression models including a high number of variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Neural Networks</head><p>The prediction models compared in this paper are devel-Artificial neural networks are inspired by the flexible and highly parallel way the nerve system (the neurons) process information. There are many types of neural networks, but in this paper only feed forward neural networks with back propagation will be considered (for a review, see <ref type="bibr">[12]</ref>). Such networks represent nonlinear regression models. As opposed to typical regression models, neural networks use a large number of parameters to allow complex hctional relations between the independent and the dependent variables. Therefore, a potential advantage of applying neural networks to predict maintenance effort is that the functional relation (i.e., the model type) between effort and the independent variables can be left more unspecified than with the use of the regression approach. It is to be expected that the neural network approach will lead to better prediction models than the regression approach if the specified model type of the regression approach is not appropriate. Due to the high number of parameters, overfitting to the learning set may be a serious problem in applying neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Pattern Recognition</head><p>The goal of the pattern recognition approach is to determine the subsets of experience from a historical data set (a learning sample) that provide the best characterisation of the object to be assessed (the measurement vector). We apply the recently developed Optimized Set Reduction (OSR) method described in [ 131, [ 141, and [ 151. The OSR method involves a successive decomposition of the learning sample into subsets. At each step of the decomposition an independent variable is selected. The objects having the same value (or belonging to the same class of values) of the independent variable as the measurement vector are extracted from the learning sample to form the reduced subset. This is done recursively on the reduced subsets. The set reduction stops when a termination criterion is met, for example that the reduced set consists of less than a given number of tasks. Then, based on the terminal subset, the effort is predicted.</p><p>A simplified example of the pattern recognition process is illustrated in Fig. <ref type="figure" target="#fig_3">1</ref>. Subsetl is the subset of the learning sample tasks (the historical tasks) with the same Confidence level of the maintainers as the task to be assessed, i.e., the set of tasks where the variable Confidence has the value HIGH. Similarly, Subset2 is an extract from Subsetl. In the example Subset2 meets the termination criterion and the effort prediction is, consequently, based on the tasks in Subset2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. The Prediction Models</head><p>T1 1, are briefly described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.I. Baseline is:</head><p>We developed eleven prediction models. The models, T1 -A simple rule of thumb predicting maintenance task effort T1) Effort = Size I mean Productivity</p><p>The more sophisticated prediction models, i.e., T2 -T1 1, should predict the effort more accurately than T1, otherwise the use of them is not meaningful. T1 is, therefore, our baseline with respect to prediction accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0.2.">Simple Regression</head><p>The simple (i.e., only one independent variable) regression models are commonly based on the relation Effort = a Sizeb, see for example <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b16">[17]</ref>. Two models were evaluated, minimising different cost functions:</p><formula xml:id="formula_2">T2) Effort = a Sizeb,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>min[log(actual effort /predicted e f f ~r t ) ] ~ T3) Effort = a Sizeb, min(lactua1 effort -predicted efforq I actual effort) = min(MRE)</head><p>T2 can be solved applying ordinary least square linear regression through a log transformation of ~f f ~r t = a Size6 to log(Effort) = log(a) + b log(Size). T3 is only possible to solve applying nonlinear methods. (We applied the iterative Newton method implemented in the software tool SASIETS, version 6.) The term minimised in T3 is the Magnitude of Relative Error (MRE) and is described in Section IV. The minimising of the MRE is, we believe, the most meaninghl term to minimise in an effort prediction model for a maintenance manager. Unfortunately, minimising the MRE requires, compared to the log linear model, more complex calculations that not always lead to a solution. In addition, minimising the MRE may lead to biased (sample mean different from population mean) models, and models difficult to analyse and to handle properly. More about the properties of non linear models is presented in [ 1 13 and [ 181.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">. 3 . Multiple Regression</head><p>Four multiple regression models were evaluated, minimising different cost functions.</p><p>The simplest multiple regression models are the linear models. This model type is preferable to the nonlinear multiple regression model types if not significantly less accurate.</p><formula xml:id="formula_3">T4) Effort = constant + a Size + b Cause + c Change + d Mode + e Confidence,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>min([actual effort -predicted e f f ~r t ] ) ~</head><p>The following two models, T5 and T6, apply only a subset of the variables. The selection of variables was carried out through an analysis of the effect on R2 of deletions and additions of sets of variables. We tried to keep the prediction models as easy as possible, i.e., as few variables as possible, while achieving an R2 value not far from the one achieved when including all the variables, i.e., a stepwise regression. More on this strategy in for example [ 111. The analysis re-sulted in three models, T5-T7.</p><p>observations. The combination of pattern recognition and regression described in T11 to predict software effort has, to the best of the author's knowledge, not been published before. The potential advantage of this hybrid model is that the productivity classification of the tasks, based on the pattern recognition, may lead to a regression analysis (for each productivity class) on a more homogeneous dataset, compared to a regression analysis on the whole dataset-T5 is a nonlinear model type minimising the MMRE: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. 4. Neural Network</head><p>Trying to avoid overfitting to the learning sets, only relatively simple feed forward neural networks were considered. In the terminology of [ 121, we primarily used: T8) A two-layer network with two hidden nodes and logistic activation functions (g(h) = 1/(1 + e-?) in the hidden nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The identity function was used as activation function in the output node. The parameters were determined by minimising the cost function [log(actual eflort I predicted effort)]2 using the back propagation algorithm (see [ 121).</head><p>The tool "PlaNet Version 5.6," described in <ref type="bibr" target="#b18">[19]</ref>, was used to execute the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D, 5. Pattern Recognition</head><formula xml:id="formula_4">MRE = lactual effort -predicted effortl / actual effort.</formula><p>MMRE is the mean magnitude of relative error of a prediction relative to a data set. For example, an MMRE of 0.3 means that the mean relative error of a prediction is 30%.</p><p>MRE based accuracy measures are useful because they are easy to interpret and meaningful for the maintenance managers.</p><p>A problem with the MMRE is that the value may be strongly influenced by a few very high MRE-values. We therefore included the median magnitude of relative error (MdMRE) in the evaluation.</p><p>In addition, the accuracy comparison is based on the following variants of the measure PRED. PREDl(0.25) = the % of the tasks with MRE &lt;= 0.25.</p><p>Based on the ideas of the Optimized Set Reduction ( 0 s ~) PREDl(O.50) = the % of the tasks with MRE &lt;= 0.50. method, a prototype of a pattern recognition model was implemented in the programming language C. The accuracy of the following three models was evaluated:</p><p>. T9) A model as described in <ref type="bibr" target="#b13">[14]</ref>, with fwe maintenance productivity classes and terminating on 12 or fewer matching observations. Instead of using the class "middle" value (class middle value = (lower-boundary-class-i + upper-boundary-class-9 / 2) to predict the efort @om the productivity class conditional probabilities as in [ 141 we used the class mean value. T10) As T9, diferent only in the choice of termination criterion. The set reduction terminated when no set reduction with statistically sign ficant (p &lt; 0.1) diference in distribution could be found, This extension of the OSR method is described in <ref type="bibr" target="#b14">[15]</ref>.</p><p>T1 1) A hybrid model based on both pattern recognition and regression. The pattern recognition approach classified the productivity classes very well. With three productivity classes 60-70% of the tasks were classfied correctly. Therefore, a model was developed applying pattern recognition principles to determine the productivity classes <ref type="bibr">(low, medium, high)</ref>, and the regression approach to develop a relation of type Effort = a Sizeb for each productivity class (minimising the MMRE). The set reduction was terminating on fwe or fewer matching PRED2(0.25,0.5) = the % of the task with (MRE &lt;= 0.25) OR (lactual effortpredicted effortl &lt;= 0.5 maintenance-days).</p><p>The need for a measure like PRED'(0.25, 0.5) is caused by the large number of small maintenance tasks (more than 50% of the tasks required less than three maintenance-days of effort) in our data set. We believe that a maintenance manager may, in most cases, accept a difference between actual and predicted effort of, for example, 0.5 maintenance-day, although the relative error (the MRE) is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DESIGN OF THE ACCURACY COMPARISON</head><p>The prediction models were to be developed and evaluated on the same data sets.</p><p>The original data set (1 09 tasks) contained three tasks where no part of the software was changed, three tasks with a very high degree of reuse or duplication of changes and three tasks where a temporary program was developed. These nine tasks had extremely low or high productivity and were removed fiom the data set, leaving 100 tasks in the data set.</p><p>To evaluate the accuracy of the different types of prediction models the statistical method of cross-validation, see for example [20], was applied.</p><p>Given a randomised sequence of the maintenance tasks rrm~aition (numbered from t l to t100) we:</p><p>1)formed five learning and five test sets of maintenance tasks. (Learning set 1 = {tl. .t80}, test set 1 = (t81. .t100}, learning set 2 = {tl. .t60} U (t8l. .t100}, test set 2 = (t61. .t80} etc.) 2) developed the prediction models for each learning set and for each model (see Section III.D), i.e., five prediction models for each model type. 3) evaluated the accuracy of the prediction models on each test set, applying the accuracy measures described in Section IV. (The prediction models developed using the learning set 1 were evaluated on the test set 1, the prediction models developed using the learning set 2 were evaluated on the test set 2 etc.) 4) averaged, for each model type, the prediction accuracy over all five test sets, i.e., the accuracy of a model type is the mean accuracy of the five models of that type. Another, maybe more common, evaluation method, is to divide the data set into a single learning set (on which the prediction models are developed) and a single test set (on which the prediction accuracy is evaluated). The advantage of the cross-validation method is that the prediction accuracy is evaluated on all the maintenance tasks instead of only a subset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. THE COMPARISON</head><p>In the following we will present the prediction accuracy results for each of the models (Section V1.A) and discuss how these accuracy results should be interpreted (Section VLB).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Accuracy of the Models</head><p>Table <ref type="table">I</ref> shows the values for the accuracy measures MMRFi, for each model. The ''top. three" types of models for each accuracy measure in Table <ref type="table">I</ref> are printed in bold.</p><p>MdMRE, PRED1(0.25), PREDl(O.SO), and PREDz(0.25, 0.5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I PREDICTION ACCURACY</head><p>The most accurate prediction model types seem to be T6, T7, and T11, i.e., the log linear multiple regression model types and the hybrid model type based on pattern recognition and simple regression.</p><p>Table <ref type="table">I</ref> shows, among others, that: Some of the models, for example T2 and T4, were not significantly more accurate than the baseline T1 with respect to any of the accuracy measures. T3 and T5 were only significantly more accurate than the baseline T1 with respect to the MMRE. T3 and T5 were, not surprisingly, regression based models minimising the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MMRE.</head><p>The The more sophisticated termination criterion of the OSR method described in [ 151, in our case, did not improve the prediction accuracy, i.e., T10 was not more accurate than T9. In addition, the evaluation of the accuracy of the different Calculation of the 95% confidence interval of the bvalues in the relation Effort = a Sizeb for models of type T2 and T3 showed that b was significantly (p &lt; 0.05) lower than 1.0. This result is normally, see for example <ref type="bibr" target="#b16">[17]</ref>, interpreted as an indicator of a nonlinear relation between effort and size. This nonlinearity result is, however, contradicted by the result that T1, which is based on a linear relation between effort and size, was not less accurate than T2 and T3 with respect to most of the accuracy measures. This contradiction illustrates the problems of a sound interpretation of the confidence interval of the b-value in the relation above. Analysing the difference in prediction accuracy between the five different test sets (for the same model type) gave an indication of the robustness of the model type. The prediction models with the largest differences in prediction accuracy between the test sets, i.e., the least robust models, were T4 (linear regression) and T8 (neural network). The prediction accuracy of T11 depended strongly on the correct recognition of productivity class. In a few cases a task could, for example, be classified as a "low productivity task" (productivity class 1) when it actually was a "high productivity task" (productivity class 3). This led to a situation where the typical predictions of T11 were close to the actual values, but the worst predictions were even more inaccurate than the worst predictions of the other model types.</p><p>prediction models led to the following results:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Interpretation of the Measured Accuracy</head><p>In order to get an indication of how accurate the expert predictions had been for the studied maintenance tasks we asked the maintenance group managers about what the typical MREi of the expert prediction had been for the period we had collected data. Typically, only the effort of the medium and the large maintenance tasks had been predicted and most of these predictions were claimed to have an MRE between 10 and 25%. The managers found this accuracy acceptable. Similarly, <ref type="bibr" target="#b20">[21]</ref> suggests an MMRE &lt;= 0.25 as acceptable prediction accuracy of software development effort prediction models. A comparison of these accuracy claims with our accuracy results, where the best models had an MMRE of 60%, may on first sight strongly indicate that our formal models are too inaccurate to be of any use. However, such a comparison does not do justice to the differences of the environments. While we have based our comparison of the prediction accuracy on historical data, the managers most likely had their data from an environment where the maintainers knew about the predictions in advance. The maintainers probably try to meet the predictions (interpreted by the maintainers as "plans" or "goals") and may, for example, work harder or reduce the testing in order not to use more time than predicted. It is, for this reason, difficult to interpret whether a high accuracy in expert predictions, where the maintainers know about the predictions in advance, is caused by high quality in the expert predictions, or a high "flexibility" of the task requirements or the efficiency of the maintainer, see also <ref type="bibr" target="#b21">[22]</ref>.</p><p>An interesting experiment to carry out would be to compare the prediction accuracy of the expert predictions with the prediction accuracy of formal prediction models when both types of predictions are carried out under the same conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WI. CONCLUSIONS AND RECOMMENDATIONS</head><p>We do not believe that a formal prediction model should replace the use of expert predictions. Expert predictions may include detailed knowledge about the maintainer and the environment which it is not practical to include in a formal model. A recommended use of an effort prediction model is, therefore, to support the expert predictions. Bayesian estimation may provide an appropriate fiamework for combining the output of our models and the expert predictions, see <ref type="bibr" target="#b8">[9]</ref>. Another important use of a formal prediction model may be to support the collection and analysis of maintenance data in order to enable improvement of the maintenance process and product.</p><p>The prediction approaches described in this paper have different qualities with respect to how well they support the expert predictions and enable an improvement of the maintenance process. There are reasons to believe that the pattern recognition approach has the potential for being superior to the other approaches both with respect to supporting the expert when predicting effort, and with respect to improving the maintenance process and product:</p><p>An advantage of the pattern recognition based prediction models is that they are able to support the experts with a set of similar maintenance tasks to the one to be pre-dicted and in this way extend the "expert experience base" with more quantitative and exact data. This set of similar tasks may also provide valuable information for anaiysing, understanding and improving the maintenance process. More on the use of a pattern recognition based prediction model to understand and improve the process can be found in <ref type="bibr">[13]</ref>. 0 The regression and neural network based models evaluated in this paper seem to be more "black box" than the pattern recognition based model, i.e., the maintainer can only accept or reject the predictions and not easily use them to extend his understanding of the maintenance process and increase the quality of his expert prediction.</p><p>The regression approach may, in theory, enable an interpretation of the parameter values, for example the bvalue in Effort = a Sizeb may be interpreted as the economy-of-scale (see, for example, <ref type="bibr" target="#b22">[23]</ref>). However, a sound interpretation of the parameters can in practice be very difficult, see Section VLA, especially for the more complex multiple regression relations. If the accuracy of the prediction models was the only criterion, the investments in the development, use and maintenance of the sophisticated formal prediction models T2 to T11 may not be justified compared to the investments in the much simpler baseline model T1. However, we believe that the increase in prediction accuracy together with the use of the prediction models as an instrument to support expert estimates and to analyse the variables affecting the maintenance process may justify the investments in sophisticated prediction models like T11.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Manuscript received December 1994; revised June 1995. M. Jorgensen is with Telenor Research and Development and University IEEECS Log Number S95024.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>I</head><label></label><figDesc>The paper describes the following steps of the study:1) Collection of data about maintenance tasks (Section 11) 2)Design and implementation of the prediction models 3) Design of accuracy measures (Section IV) 4) Design of the accuracy comparison (Section V) 5 ) Comparison of the accuracy and other characteristics of 6) The conclusions and recommendations (Section VII).(Section 111) the prediction models (Section VI)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>0</head><label></label><figDesc>the prediction approaches to use (Section 1II.C) B. The Variables Included in the Prediction Models 0 the prediction models to implement and compareWe decided to include only the variables significantly (p &lt; 0.05) correlating to maintenance productivity and to some (Section 1II.D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The pattern recognition process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>T5)</head><label></label><figDesc>Effort = a Sizeb + c Mode + d Confidence, min(MA4.m T6 is a log linear model type minimising [log(actual effort predicted effort)]': T6) l0EdEflort) = 'Onstant + a Mode + Mode + Confidence, min([log(actual eflort 1 predicted eflort)12) T7 is a log linear model type including all the variables and minimising [log(actual effort I predicted effort)]': T7) 1oAEffort) = constant + a 1oASize) + b Cause + c IV. DESIGN OF THE ACCURACY MEASURES In the evaluation of the accuracy of the prediction models we apply measures based on the magnitude of the relative error log(Size)Confidence + d Change ;e log(Size) Change + f Mode + g log(Size) Mode + h Confidence + i log(Size) Confidence, min([log(actual eflort I predicted eflort)]') (W):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The variables Type of language, Maintainer experience, Priority of task, Application age and Application size were, therefore, not included in our LOC based prediction model.</figDesc><table><row><cell>Splitting</cell></row><row><cell>the maintenance tasks into tasks on applications with age</cell></row><row><cell>eight years (the mean) or more and tasks on applications</cell></row><row><cell>with age less than eight years gave the surprising result</cell></row><row><cell>that the oldest applications had the highest productivity;</cell></row><row><cell>42 LOC/maintenance-days compared to 29 LOC/ main-</cell></row><row><cell>tenance-days. The difference between the mean values</cell></row><row><cell>was, however, not significant 0, = 0.13). A potential rea-</cell></row><row><cell>son for this result is that the least maintainable applica-</cell></row><row><cell>tions are replaced before they get old, i.e., only the most</cell></row><row><cell>maintainable applications reach a high age.</cell></row><row><cell>0 Application size: The Pearson's correlation coefficient of</cell></row><row><cell>the relation between productivity and the size of the ap-</cell></row><row><cell>plication was low and not significant (r = -0.04 and</cell></row><row><cell>p &gt; 0.05). Dividing the maintenance tasks into tasks</cell></row></table><note><p>21, NO. 8, AUGUST 1995 0 Application age: The Pearson's correlation coefficient of the relation between productivity and the application age was low and not significant (r = 0.19, p &gt; 0.05). where the application size was greater or equal to 23,500 LOC (the mean) and tasks on applications with less than 23,500 LOC gave only small and not significant differences in mean productivity values, 33 LOC/maintenanceday vs 39 LOC/maintenance-day (p = 0.53). A potential reason for this result is that maintenance work is more frequently carried out on large applications and the maintainers, therefore, know the larger applications better.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The author wishes to thank Arne Maus (University of Oslo), Knut Liestol (University of Oslo), Thorstein Lunde (Telenor) and Arve Meisingset (Telenor) for their assistance with this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Software complexity and maintenance costs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Banker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Kemerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">C o m . of the ACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="81" to="94" />
			<date type="published" when="1993-11">Nov. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A classification process for the effective management of changes during the maintenance process</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Con$ on Sofware Maintenance</title>
		<meeting>IEEE Con$ on Sofware Maintenance<address><addrLine>Orlando, Fla</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="328" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Predicting the costs of computer programs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Delaney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Processsmg Magazine</title>
		<imprint>
			<biblScope unit="page" from="32" to="34" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Software Sizing and Estimating, MWI FPA</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Symons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>New York John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Lientz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Swanson</surname></persName>
		</author>
		<title level="m">Sofware Maintenance Management</title>
		<meeting><address><addrLine>Reading, Mass</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cost estimation models for the reuse and prototype software development life-cycles</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Balda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sofiare Eng. Notes</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Function points in the estimation and evaluation of the software process</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Jeffery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="64" to="71" />
			<date type="published" when="1990-01">Jan. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Early software size estimation: A critical analysis of the software science length equation and a data-42-50, July 1990. structure-oriented size estimation approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Dunsmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. n i r d hjmp. on Empirical Fowrdarions of Information and SoMare Sciences</title>
		<meeting>n i r d hjmp. on Empirical Fowrdarions of Information and SoMare Sciences</meeting>
		<imprint>
			<date type="published" when="1985-10">Oct. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Wonnacott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Wonnacott</surname></persName>
		</author>
		<title level="m">Introductory Statistics, 5</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note>th ed</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Wetherill</surname></persName>
		</author>
		<title level="m">Intermediate Statistical Methods</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman and Hall</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Maddala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Econometrics</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Introduction to the Theory of Neural Computation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading Mass.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A pattern recognition approach for software engineering analysis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Sofhvare Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="931" to="942" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recognizing pattems for software development prediction and evaluation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Analytical Methodr in Sofiare Engineering Economics</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Gulledge</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Hutzler</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="151" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Developing interpretable models with optimized set reduction for identifying high-risk software components</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hetmanski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Sofhvare Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Sofhvare Engineering Economics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Boehm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, N.J.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Empirical studies of assumptions that underlie so&amp;-ware cost-estimation models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Sofhvare Technology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="21" to="21" />
			<date type="published" when="1992-04">Apr. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Nonlinear Regression Modeling</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Ratkowsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>New York Marcel Dekker</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A User&apos;s Guide to PIaNet Version 5</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Boulder</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Colorado</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A leisurely look at the bootstrap, the jackknife, and cross-validation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Statistician</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="48" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Software Engineering Metrics andMOdelS</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Dunsmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Benjamin Cummings</publisher>
			<pubPlace>Menlo Park, Calif</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Impact of schedule estimation on software project behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Abdel-Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madnic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sofhvare</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="70" to="75" />
			<date type="published" when="1986-07">July 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Magne Jergensen received the Diplom Ingeneur degree in Wirtschaftswissenschaften from the University of Karlsruhe, Germany, in 1988 and the DrScient degree in informatics from the University of Oslo, Norway</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Banker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Kemerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">His research interests are in software maintenance, cost modeling, CASE tools, and software measurement</title>
		<meeting><address><addrLine>Kjeller, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-10">028-1,044,N0~. 1993. 1,199-1,205, Oct. 1989. 1994</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note>Since 1989 he has been a research scientist at Telenor Research &amp; Development</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
