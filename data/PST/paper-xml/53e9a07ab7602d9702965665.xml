<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convergence rate for consensus with delays</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-11-04">4 November 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Angelia</forename><surname>Nedić</surname></persName>
							<email>angelia@uiuc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Asuman</forename><surname>Ozdaglar</surname></persName>
							<email>asuman@mit.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial and Enterprise Systems Engineering</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana, Champaign</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Convergence rate for consensus with delays</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-11-04">4 November 2008</date>
						</imprint>
					</monogr>
					<idno type="MD5">29A579CB27A6F0FFAB2ADF638EDB9978</idno>
					<idno type="DOI">10.1007/s10898-008-9370-2</idno>
					<note type="submission">Received: 4 October 2008 / Accepted: 9 October 2008 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the problem of reaching a consensus in the values of a distributed system of agents with time-varying connectivity in the presence of delays. We consider a widely studied consensus algorithm, in which at each time step, every agent forms a weighted average of its own value with values received from the neighboring agents. We study an asynchronous operation of this algorithm using delayed agent values. Our focus is on establishing convergence rate results for this algorithm. In particular, we first show convergence to consensus under a bounded delay condition and some connectivity and intercommunication conditions imposed on the multi-agent system. We then provide a bound on the time required to reach the consensus. Our bound is given as an explicit function of the system parameters including the delay bound and the bound on agents' intercommunication intervals.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has been much recent interest in distributed cooperative control problems, in which several autonomous agents try to collectively accomplish a global objective. This is motivated mainly by the emerging large scale networks which are characterized by the lack of centralized access to information and control. Most recent literature in this area focused on the consensus problem, where the objective is to develop distributed algorithms under which agents can reach an agreement or consensus on a common decision (represented by a scalar or a vector). Consensus problem arises in a number of applications including coordination of UAVs, information processing in wireless sensor networks, and distributed multi-agent optimization.</p><p>A widely studied algorithm in the consensus literature involves, at each time step, every agent computing a weighted average of its own value with values received from some of the other agents. This algorithm has been proposed and analyzed in the seminal work by Tsitsiklis <ref type="bibr" target="#b17">[18]</ref> (see also <ref type="bibr" target="#b19">[20]</ref>). The convergence properties of the consensus algorithm has been further studied under different assumptions on agent connectivity and information exchange by Jadbabaie et al. <ref type="bibr" target="#b8">[9]</ref> and Blondel et al. <ref type="bibr" target="#b3">[4]</ref>. Despite much work on the convergence of the consensus algorithm, there has not been a systematic study of the convergence rate of this algorithm in the presence of delays. The presence of delays is a good model for communication networks where there are delays associated with transmission of agent values. Establishing the rate properties of consensus algorithms in such systems is essential in understanding the robustness of the system against dynamic changes.</p><p>In this paper, we study convergence and convergence rate properties of the consensus algorithm in the presence of delays. Our analysis is based on reducing the consensus problem with delay to a problem with no delays using state augmentation, i.e., we enlarge the system by including a new agent for each delay element. The state augmentation allows us to represent the evolution of agent values using linear dynamics. The convergence and convergence rate analysis then translates to studying the properties of infinite products of stochastic matrices. Under a bounded delay assumption, we provide rate estimates for the convergence of products of stochastic matrices. Our estimates are per iteration and highlight the dependence on the system parameters including the delay bound.</p><p>Other than the papers cited above, our paper is also related to the literature on the consensus problem and average consensus problem (a special case, where the goal is to reach a consensus on the average of the initial values of the agents; see <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b20">21]</ref>). Recent work has studied the implications of noise and quantization effects on the limiting behavior of the consensus algorithm, see <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10]</ref>. Consensus algorithm also plays a key role in the development of distributed optimization methods. The convergence properties of such methods have been investigated by Tsitsiklis and Athans <ref type="bibr" target="#b18">[19]</ref>, Li and Basar <ref type="bibr" target="#b10">[11]</ref>, Bertsekas and Tsitsiklis <ref type="bibr" target="#b1">[2]</ref>, and more recently in our work <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>There has also been some work on the convergence of consensus algorithms in the presence of delays. In particular, Bliman and Ferrari-Trecate <ref type="bibr" target="#b2">[3]</ref> studied convergence of (average) consensus under symmetric delays for a continuous model of agent updates, i.e., a model that represents the evolution of agent values using partial differential equations (which is in contrast with the slotted update rule studied in this paper). Another related work is that of Angeli and Bliman <ref type="bibr" target="#b0">[1]</ref>, who consider consensus algorithms and the rate of convergence in the presence of delays assuming special topologies for agent connectivity, namely spanning-tree topologies. In contrast with this work, we establish convergence to consensus with delays without requiring any special topologies for agent connectivity. The main contribution of our work is the convergence rate result that quantifies the algorithm's progress per iteration and provides a performance bound in terms of the system and algorithm parameters.</p><p>The rest of this paper is organized as follows: In Sect. 2, we introduce our notation, formulate the consensus problem, and describe the assumptions imposed on the agent connectivity and information exchange. In Sect. 3, we introduce and analyze an equivalent consensus problem without a delay, but with an enlarged number of agents. This section also contains our main convergence and rate of convergence results. In Sect. 4, we provide concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Consensus problem</head><p>In this section, we formulate a generic consensus problem and state our assumptions imposed on agent connectivity and local information exchange. To do this, we start by introducing the basic notation and notions that we use throughout the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Basic notation and notions</head><p>A vector is viewed as a column, unless clearly stated otherwise. We denote by x i or [x] i the i-th component of a vector x. When x i ≥ 0 for all components i of a vector x, we write x ≥ 0. For a matrix A, we write A j i or [A] j i to denote the matrix entry in the i-th row and j-th column. We write [A] i to denote the i-th row of the matrix A, and [A] j to denote the j-th column of A.</p><p>We write x to denote the transpose of a vector x. The scalar product of two vectors x, y ∈ R m is denoted by x y. We use x to denote the standard Euclidean norm, x = √ x x. We write x ∞ to denote the max norm, x ∞ = max 1≤i≤m |x i |.</p><p>A vector a is said to be a stochastic vector when a i ≥ 0 for all i and i a i = 1. A square m × m matrix A is said to be a stochastic matrix when each row of A is a stochastic vector. A square m × m matrix A is said to be a doubly stochastic matrix when both A and A are stochastic matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Consensus problem with delay</head><p>We consider a network with m agents (or nodes). The neighbors of an agent i are the agents j communicating directly with agent i through a directed link ( j, i). Each agent updates and sends its information to its neighbors at discrete times t 0 , t 1 , t 2 , . . .. We index agents' information states and any other information at time t k by k. We use x i (k) ∈ R n to denote agent i information state (or estimates) at time t k .</p><p>Each agent i updates its estimate x i (k) by combining it with the available delayed estimates x j (s) of its neighbors j. An agent combines the estimates by using nonnegative weights a i j (k). These weights capture the information inflow to agent i at time k and the information delay. More specifically, suppose an agent j sends its estimate x j (s) to agent i. If agent i receives the estimate x j (s) at time k, then the delay is t i j (k) = ks and agent i assigns a weight a i j (k) &gt; 0 to the estimate x j (s). Otherwise, agent i uses a i j (k) = 0. Formally, each agent i updates its estimate according to the following relation:</p><formula xml:id="formula_0">x i (k + 1) = m j=1 a i j (k)x j k -t i j (k) for k = 0, 1, 2, . . . ,<label>(1)</label></formula><p>where the vector x i (0) ∈ R n is initial state of agent i, the scalar t i j (k) is nonnegative and it represents the delay of a message from agent j to agent i, while the scalar a i j (k) is a nonnegative weight that agent i assigns to a delayed estimate x j (s) arriving from agent j at time k. We use the vector a i (k) = (a i 1 (k), . . . , a i m (k)) to denote the set of nonnegative weights that agent i uses at time k.</p><p>The consensus problem involves determining conditions on the agents' connectivity and interactions (including conditions on the weights a i (k)) that guarantee the convergence of the estimates x i (k), as k → ∞, to a common vector i.e., a limit vector independent of i.</p><p>In the absence of a delay, we have t i k (k) = 0 and the update relation (1) reduces to an algorithm for the consensus problem without a delay. This algorithm has been proposed by Tsitsiklis <ref type="bibr" target="#b17">[18]</ref>. Variations of this algorithm for various specialized choices of weights and including quantization effects have been recently studied (see <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Assumptions</head><p>Here, we describe some rules that govern the information evolution of the agent system in time. Motivated by the model of Tsitsiklis <ref type="bibr" target="#b17">[18]</ref> and the "consensus" setting of Blondel et al. <ref type="bibr" target="#b3">[4]</ref>, these rules include:</p><p>-A rule on the weights that an agent uses when combining its information with the information received from its neighbors. -A connectivity rule ensuring that the information of each agent influences the information of any other agent infinitely often in time. -A rule on the frequency at which an agent sends his information to the neighbors.</p><p>Our first assumption is on the weights a i 1 (k), . . . , a i m (k) that agent i uses in the update rule of Eq. 1. These weights are assumed to be a convex combination, i.e., nonnegative and with sum equal to 1. Furthermore, the weight a i j (k) is nonzero if and only if agent i receives new information from agent j at time k. Finally, to ensure that each agent influences the information state of every other agent persistently in time, we require that every positive weight a i j (k) is bounded away from zero by some positive scalar η uniformly in time and across all agents i and j. This is formally stated in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assumption 1 (Weights Rule) We have:</head><p>(a) There exists a scalar η with 0 &lt; η &lt; 1 such that for all i ∈ {1,…,m} and all k ≥ 0, (i) a i i (k) ≥ η. (ii) a i j (k) ≥ η if agent i receives new (potentially delayed) information from agent j at time k. (iii) a i j (k) = 0 if agent i does not receive any information from agent j at time k.</p><p>(b) The vectors a i (k) are stochastic, i.e., m j=1 a i j (k) = 1 for all i and k.</p><p>Assumption 1(a) states that each agent gives significant weights to its own estimate x i (k) and the estimate x j (k) available from her neighboring agents j at the update time t k . Note that, under Assumption 1, for the matrix A(k) whose columns are a 1 (k), . . . , a m (k), the transpose A (k) is a stochastic matrix for all k ≥ 0.</p><p>We now discuss the rules we impose on the information exchange among agents. Here, it is convenient to view the agents as a set of nodes V = {1, . . . , m}. At each update time t k , the information exchange among the agents may be represented by a directed graph (V, E k ) with the set E k of directed edges given by</p><formula xml:id="formula_1">E k = {( j, i) | a i j (k) &gt; 0}.</formula><p>Note that, by Assumption 1(a), we have (i, i) ∈ E k for each agent i and all k. Also, we have ( j, i) ∈ E k if and only if agent i receives information x j from agent j at time k. The graph (V, E k ) represents the communications among the agents occurring at time instant k. At any given time k, the graph (V, E k ) need not be connected, but a union of such graphs over a period of time has to be connected to ensure a proper mixing of the agent information, which is discussed next.</p><p>The connectivity assumption that we impose on the agent system can be stated informally as: following any time t k , the information of an agent j reaches each and every agent i directly or indirectly (through a sequence of communications between the other agents). In other words, the information state of any agent i influences the information state of any other agent infinitely often in time. In formulating this, we use the set E ∞ consisting of edges ( j, i) such that j is a neighbor of i who communicates with i infinitely often in time. The connectivity requirement is formally stated in the following assumption.</p><p>Assumption 2 (Connectivity) The graph (V, E ∞ ) is connected, where E ∞ is the set of edges ( j, i) representing agent pairs communicating directly infinitely many times, i.e.,</p><formula xml:id="formula_2">E ∞ = {( j, i) | ( j, i) ∈ E k for infinitely many indices k}.</formula><p>To re-phrase, the assumption says that for any k and any two agents u, v ∈ V , there is a directed path from agent u to agent v with edges ( j, i) in the set ∪ l≥k E l . Thus, Assumption 2 is equivalent to having the composite directed graph (V, ∪ l≥k E l ) connected for all k.</p><p>When analyzing the system state behavior, we use an additional assumption that the intercommunication intervals are bounded for those agents that communicate directly. In particular, we use the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assumption 3 (Bounded Intercommunication Interval)</head><p>There exists an integer B ≥ 1 such that for every ( j, i) ∈ E ∞ , agent j sends information to its neighbor i at least once every B consecutive time slots, i.e., at time t k or at time t k+1 or . . . or (at latest) at time t k+B-1 for any k ≥ 0.</p><p>When there is no delay in the system, this assumption is equivalent to the requirement that there is B ≥ 1 such that</p><formula xml:id="formula_3">( j, i) ∈ E k ∪ E k+1 ∪ • • • ∪ E k+B-1 for all ( j, i) ∈ E ∞ and k ≥ 0.</formula><p>Thus, when there is no delay in the system, our Assumptions 1-3 coincide with those of Tsitsiklis <ref type="bibr" target="#b17">[18]</ref> (see also the "consensus" setting of Blondel et al. <ref type="bibr" target="#b3">[4]</ref> and our optimization model in <ref type="bibr" target="#b13">[14]</ref>).</p><p>Finally, we assume that the delays t i j (k) in delivering a message from an agent j to any neighboring agent i is uniformly bounded at all times. <ref type="foot" target="#foot_0">1</ref> Formally, this is imposed in the following assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assumption 4 (Bounded Delays) Let the following hold:</head><p>(a) We have t i i (k) = 0 for all agents i and all k ≥ 0. (b) We have t i j (k) = 0 for all agents j communicating with agent i directly and whose estimates x j are not available to agent i at time t k+1 . (c) There is an integer B 1 such that 0 ≤ t i j (k) ≤ B 1 -1 for all agents i, j, and all k.</p><p>Part (a) of the assumption states that each agent i has its own estimate x i (k) available (naturally) without any delay. Part (b) states that the delay is zero for those agents j whose (delayed) estimates x j (s) are not available to agent i at an update time. Under Weights Rule (a) [cf. Assumption 1 (a)], agent i assigns zero weight for the estimate x j of such an agent j, i.e., a i j (k) = 0. Thus, under Weights Rule (a), the part (b) of the preceding assumption reduces to the following relation: t i j (k) = 0 for all agents i and j such that a i j (k) = 0. Finally, part (c) of Assumption 4 states that the delays are uniformly bounded at all times and for all neighboring agents i and j. <ref type="foot" target="#foot_1">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Convergence analysis</head><p>In this section, we show that the agents updating their information according to Eq. 1 reach a consensus under the assumptions of Sect. 2.3. In particular, we establish the convergence of agent estimates to a consensus and provide a convergence rate estimate. Our analysis is based on reducing the consensus problem with a delay to a problem without a delay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Reduction to a consensus problem without delay</head><p>Here, we reduce the original agent system with delays to a system without delays, under the Bounded Delays assumption [cf. <ref type="bibr">Assumption 4]</ref>. In particular, we define an enlarged agent system that is obtained by adding "new" agents into the original system in order to deal with delays. With each agent i of the original system, we associate a new agent for each of the possible values of the delay that a message originating from agent i may experience. In view of the Bounded Delays assumption, it suffices to add (m -1)B 1 new agents handling the delays. <ref type="foot" target="#foot_2">3</ref>To differentiate between the original agents in the system and the new agents, we introduce the notions of computing and noncomputing agents (or nodes). We refer to the original agents as computing agents since these agents maintain and update their information state (estimates). We refer to the new agents as noncomputing agents since these agents do not compute or update any information, but only pass the received information to their neighbors.</p><p>In the enlarged system, we enumerate the computing agents first and then the noncomputing agents. In particular, the computing agents are indexed by 1, . . . , m and noncomputing agents are indexed by m + 1, . . . , (B 1 -1)m. Furthermore, the noncomputing agents are indexed so that the first m of them model the delay of 1 for the computing agents, the next m of them model the delay of 2 for the computing agents, and so on. Formally, we have that for a computing agent i, the noncomputing agents i + m, . . . , i + (B 1 -1)m model the nonzero delay values t = 1, . . . , (B 1 -1)m, respectively.</p><p>We now describe how the agents communicate in the enlarged system, i.e., we identify the neighbors of each agent. The computing agents are connected and communicate in the same way as in the original system. The noncomputing agents corresponding to the delays of different computing agents do not communicate among themselves. Specifically, for t with 1 ≤ t &lt; B 1 -1, a noncomputing agent j + tm receives the information only from agent j + (t -1)m, and sends the same information to either agent j + (t + 1)m or to a computing agent i only if agent j communicates with agent i in the original system. A noncomputing agent j + (B 1 -1)m communicates only with computing agents and in particular, agent j + (B 1 -1)m communicates with agent i if and only if j communicates with i in the original system. The communication connections among the agents in the original system and the corresponding enlarged system is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref> for a system with three agents and a maximum delay of 3.</p><p>We let xi (k) denote the estimate of agent i of the enlarged system at time t k . Then, the relation in Eq. 1 for the evolution of estimates of computing agents is given by: for all i ∈ {1, . . . , m},</p><formula xml:id="formula_4">xi (k + 1) = m B 1 h=1 ãi h (k) xh (k) for all k ≥ 0,<label>(2)</label></formula><p>where for all h ∈ {1, . . . ,</p><formula xml:id="formula_5">m B 1 }, ãi h (k) = a i j (k) if h = j + tm, t = t i j (k) 0 otherwise for all k ≥ 0,<label>(3)</label></formula><p>and a i j (k) are the weights used by the agents in the original network. The evolution of states for noncomputing agents is given by: for all i = m + 1, . . . , m B 1 ,</p><formula xml:id="formula_6">xi (k + 1) = xi-m (k) for all k ≥ 0,</formula><p>where the initial values are xi (0) = 0. Therefore, for noncomputing agents i we have</p><formula xml:id="formula_7">ãi h (k) = 1 for h = i -m 0 otherwise for all k ≥ 0. (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>Using these definitions of weights, we can compactly write the evolution of estimates xi (k) for all agents i in the enlarged system as follows:</p><formula xml:id="formula_9">xi (k + 1) = m B 1 h=1 ãi h (k) xh (k) for all i ∈ {1, . . . , m B 1 } and k ≥ 0, (<label>5</label></formula><formula xml:id="formula_10">)</formula><formula xml:id="formula_11">123</formula><p>where the initial vectors are given by</p><formula xml:id="formula_12">xi (0) = x i (0) for i ∈ {1, . . . , m}, xi (0) = 0 fori ∈ {m + 1, . . . , m B 1 },<label>(6)</label></formula><p>and the weights ãi h (k) for computing agents i ∈ {1, . . . , m} are given by Eq. 3, while the weights ãi h (k) for noncomputing agents i ∈ {m + 1, . . . , m B 1 } are given by Eq. 4. For a noncomputing agent i, the sum of weights m B 1 h=1 ãi h (k) is evidently equal to 1 for any k. For a computing agent i ∈ {1, . . . , m}, the sum of weights m B 1 h=1 ãi h (k) is equal to 1 for any k if and only if the weights a i j (k) of agent i in the original network sum to 1, i.e., m j=1 a i j (k) = 1 for all k.</p><p>In order to have a more compact representation of the evolution of the estimates xi (k) of Eq. 5, we rewrite this model using the matrices that govern the (linear) evolution. The resulting representation is also more suitable for our convergence analysis. In particular, we introduce matrices Ã(s) whose i-th column is the vector ãi (s). Using these matrices, we can relate estimate xi (k + 1) to the estimates x j (s) for all j and any s ≤ k. Specifically, it is straightforward to verify that for the iterates generated by Eq. 5, we have for any i, and any s and k with k ≥ s,</p><formula xml:id="formula_13">xi (k + 1) = m B 1 h=1 [ Ã(s) Ã(s + 1) • • • Ã(k -1) ãi (k)] h xh (s). (<label>7</label></formula><formula xml:id="formula_14">)</formula><p>As indicated by the preceding relation, to analyze the convergence of the iterates xi (k), we need to understand the behavior of the matrix product Ã(s) • • • Ã(k). Actually, this matrix product is the transition matrix for the agent system from time s to time k. We formally introduce these transition matrices as follows:</p><formula xml:id="formula_15">˜ (k, s) = Ã(s) Ã(s + 1) • • • Ã(k -1) Ã(k) for all s and k with k ≥ s,<label>(8)</label></formula><p>where</p><formula xml:id="formula_16">˜ (k, k) = Ã(k) for all k. (<label>9</label></formula><formula xml:id="formula_17">)</formula><p>Note that the i-th column of ˜ (k, s) is given by</p><formula xml:id="formula_18">[ ˜ (k, s)] i = Ã(s) Ã(s + 1) • • • Ã(k -1) ãi (k)</formula><p>for all i, s and k with k ≥ s, while the entry in i-th column and h-th row of ˜ (k, s) is given by</p><formula xml:id="formula_19">[ ˜ (k, s)] i h = [ Ã(s) Ã(s + 1) • • • Ã(k -1) ãi (k)</formula><p>] h for all i, h, s and k with k ≥ s.</p><p>We can now rewrite relation <ref type="bibr" target="#b6">(7)</ref> compactly in terms of the transition matrices ˜ (k, s), as follows:</p><formula xml:id="formula_20">for any i ∈ {1, . . . , m B 1 }, xi (k + 1) = m B 1 j=1 [ ˜ (k, s)] i j x j (s) for all s and k with k ≥ s ≥ 0. (<label>10</label></formula><formula xml:id="formula_21">)</formula><p>Under the Weights Rule [Assumption 1], from the definition of the weights ãi h (k) in Eqs. 3 and 4, it follows that each matrix Ã(k) is stochastic. Since the product of stochastic matrices is a stochastic matrix, it follows that the transition matrices ˜ (k, s) are stochastic for all k ≥ s ≥ 0. In what follows, we establish convergence of these matrices that will be important in our convergence analysis of the iterates generated by Eq. 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Convergence of transition matrices</head><p>In this section, our main goal is to show that the matrices ˜ (k, s) converge for any fixed s, as k → ∞, and to establish the rate of the convergence, which is done through a sequence of lemmas. The key property is that the matrices ˜ (s + T, s), with a specific choice of integer T , have rows bounded away from zero uniformly in time. This property is established in Lemma 2, and then used to establish the convergence and the rate of convergence for the products of such matrices in Lemma 4. Subsequently, by using Lemma 4 and the stochasticity of the matrices ˜ (k, s), we prove the convergence of ˜ (k, s) as k → ∞ in Lemma 5. This lemma plays a key role in showing the convergence of the agent estimates in Sect. 3.3.</p><p>We next establish some properties of the matrices ˜ (k, s) that we use in Lemma 2. As defined in Sect. 2.3, we use E ∞ to denote the agent pairs communicating (directly) infinitely often in the original network (with delays). In particular, ( j, i) ∈ E ∞ means that agent j communicates its estimates to a neighbor i infinitely often in the presence of delays. In the following lemma, we consider the properties of the matrices ˜ (k, s) under Weights Rule and Bounded Delays assumption. (a) For a computing node j that sends its information at time s and the information has a nonzero delay t, we have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1 Let Weights Rule</head><formula xml:id="formula_22">[ ˜ (s + t -1, s)] j+tm j = 1.</formula><p>(b) For any computing node i ∈ {1, . . . , m}, we have</p><formula xml:id="formula_23">[ ˜ (k, s)] i i ≥ η k-s+1</formula><p>for all k and s with k ≥ s ≥ 0. (c) Under Bounded Intercommunication Intervals [cf. <ref type="bibr">Assumption 3]</ref>, for any two computing nodes i, j ∈ {1, . . . , m} such that ( j, i) ∈ E ∞ , we have</p><formula xml:id="formula_24">[ ˜ (s + B + B 1 -1, s)] i j ≥ η B+B 1 ,</formula><p>for all s ≥ 0, where η is the lower bound on the nonzero weights of Assumption 1(a), B is the bound on the intercommunication intervals of Assumption 3, and B 1 is the delay bound of Assumption 4(c).</p><formula xml:id="formula_25">Proof (a) We prove that [ ˜ (s + t -1, s)] j+tm j = 1 by induction on the delay value t. When the delay is t = 1, we have ˜ (s, s) = Ã(s). Since ãh h-m (s) = 1 for all noncomputing nodes h [see Eq. 4], it follows that [ ˜ (s, s)] j+m j = 1. Suppose now that [ ˜ (s + t -1, s)] j+tm j = 1 for a delay t &gt; 1. (<label>11</label></formula><formula xml:id="formula_26">)</formula><p>Consider the case when the delay value is t + 1. In this case, the path of the information sent from node j at time s is given by j </p><formula xml:id="formula_27">→ j + m → j + 2m → • • • → j + tm → j + (t + 1)m. Therefore, [ ˜ (s + t, s)] j+(t+1)m j = [ ˜ (s + t -1, s)]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>123</head><p>(b) We let s ≥ 0 be arbitrary and i ∈ {1, . . . , m} be an arbitrary computing node. We prove the relation</p><formula xml:id="formula_28">[ ˜ (k, s)] i i ≥ η k-s+1 for all k, s with k ≥ s ≥ 0 (<label>1 2 )</label></formula><p>by induction on k. For k = s, from the definition of ˜ (s, s) in Eq. 9 we see that</p><formula xml:id="formula_29">[ ˜ (s, s)] i i = ãi i (s) for all s ≥ 0.</formula><p>In view of Bounded Delays (a) [cf. Assumption 4 (a)], we have t i i (s) = 0 for all s. Thus, by the definition of ãi i (k) [cf. Eq. ( <ref type="formula" target="#formula_5">3</ref>)], it follows that ãi i (s) = a i i (s). Furthermore, by Weights Rule (a) [cf. Assumption 1(a)], we have a i i (s) ≥ η for all s, and therefore,</p><formula xml:id="formula_30">ãi i (s) = a i i (s) ≥ η for all s ≥ 0. (<label>13</label></formula><formula xml:id="formula_31">)</formula><p>Hence, [ ˜ (s, s)] i i ≥ η for s ≥ 0, showing that the relation in Eq. 12 holds for k = s. Now, assume that the relation in Eq. 12 holds for some k with k &gt; s, and consider</p><formula xml:id="formula_32">[ ˜ (k + 1, s)] i i .</formula><p>By the definition of the matrix ˜ (k, s) [cf. Eq. 8], we have</p><formula xml:id="formula_33">[ ˜ (k + 1, s)] i i = m B 1 h=1 [ ˜ (k, s)] h i ãi h (k + 1) ≥ [ ˜ (k, s)] i i ãi i (k + 1),</formula><p>where the inequality in the preceding relation follows from the nonnegativity of the entries of ˜ (k, s) for all k and s. By using the inductive hypothesis and the relation ãi</p><formula xml:id="formula_34">i (k + 1) = a i i (k + 1) ≥ η [cf. Eq. 13]</formula><p>, we obtain</p><formula xml:id="formula_35">[ ˜ (k + 1, s)] i i ≥ η k-s+2 .</formula><p>Hence, the relation in Eq. 12 holds for all k ≥ s. (c) Let s ≥ 0 be arbitrary. Let i and j be two computing nodes with ( j, i) ∈ E ∞ . Under Bounded Intercommunication Intervals [cf. <ref type="bibr">Assumption 3]</ref>, for any such nodes, node j sends its information to node i at time s or s + 1 or ... or at time s + B -1 at latest. Let the information be sent at time s + τ with 0 ≤ τ ≤ B -1. Suppose that there was no delay. Then</p><formula xml:id="formula_36">[ ˜ (s + B -1, s)] i j = m B 1 h=1 [ ˜ (s + τ, s)] h j [ ˜ (s + B -1, s + τ + 1)] i h ≥ [ ˜ (s + τ, s)] i j [ ˜ (s + B -1, s + τ + 1)] i i (14) ≥ [ ˜ (s + τ, s)] i j η B-τ -1 ,</formula><p>where the first inequality follows from the nonnegativity of the entries ˜ (k, s) and the last inequality follows from [ ˜ (k, s)] i i ≥ η k-s+1 for all i, and all k and s with k ≥ s [cf. part (b)]. Similarly, by using the result in part (b), we have</p><formula xml:id="formula_37">[ ˜ (s + τ, s)] i j = m B 1 h=1 [ ˜ (s + τ -1, s)] h j ã(s + τ ) i h ≥ [ ˜ (s + τ -1, s)] j j ã(s + τ ) i j ≥ η τ ã(s + τ ) i j .</formula><p>Since the information from j to i is sent at time s + τ and it arrives without a delay, we have ã(s + τ ) i j = a(s + τ ) i j . By the Weights Rule (a), we also have a(s + τ ) i j ≥ η, and therefore,</p><formula xml:id="formula_38">[ ˜ (s + τ, s)] i j ≥ η τ +1 .</formula><p>Using the preceding relation and Eq. 14, we obtain [ ˜ (s + B -1, s)] i j ≥ η B , which together with the relation [ ˜ (s</p><formula xml:id="formula_39">+ B + B 1 -1, s + B)] i i ≥ η B 1 [cf. part (b)], implies that [ ˜ (s + B + B 1 -1, s)] i j = m B 1 h=1 [ ˜ (s + B -1, s)] h j [ ˜ (s + B + B 1 -1, s + B)] i h ≥ [ ˜ (s + B -1, s)] i j [ ˜ (s + B + B 1 -1, s + B)] i i ≥ η B+B 1 .</formula><p>Thus, the relation [ ˜ (s + B + B 1 -1, s)] i j ≥ η B+B 1 holds when the message from j to i is not delayed. Consider now the case when the information from node j to i is delayed by t with t ∈ {1, . . . , B 1 -1}. Thus, the information is sent from node j to the noncomputing node j + m at time s + τ and reaches the computing node i at time s + τ + t. In view of the information communication in the enlarged model, from time s + τ to s + τ + t, the message path is j → j + m → j + 2m → • • • → j + tm → i. In terms of the transition matrices, we formally have</p><formula xml:id="formula_40">[ ˜ (s + τ + t, s)] i j = m B 1 h=1 [ ˜ (s + τ -1, s)] h j [ ˜ (s + τ + t, s + τ )] i h ≥ [ ˜ (s + τ -1, s)] j j [ ˜ (s + τ + t, s + τ )] i j ≥ η τ [ ˜ (s + τ + t, s + τ )] i j , (<label>15</label></formula><formula xml:id="formula_41">)</formula><p>where the first inequality follows from the nonnegativity of the entries in ˜ (k, s) and the last inequality follows from [ ˜ (s</p><formula xml:id="formula_42">+ τ -1, s)] j j ≥ η τ [cf. part (b)]</formula><p>. We now consider the term [ ˜ (s + τ + t, s + τ )], for which we have</p><formula xml:id="formula_43">[ ˜ (s + τ + t, s + τ )] i j = m B 1 h=1 [ ˜ (s + τ + t -1, s + τ )] h j ã(s + τ + t) i h ≥ [ ˜ (s + τ + t -1, s + τ )] j+tm j ã(s + τ + t) i j+tm ≥ [ ˜ (s + τ + t -1, s + τ )] j+tm j η,</formula><p>where the last inequality follows from ãi h (k) = a i j (k) for h = j + tm and all k [cf. Eq. 3], the assumption that a i j (k) ≥ η for all k [cf. Assumption 1(a)], and the fact that the information arrives to node i from node j + tm at time k = s + τ + t. By part (a), we have [ ˜ (s + t -1, s)] j+tm j = 1 for any computing node j that sends its information at time s and the information has a delay t &gt; 0. Therefore, we obtain [ ˜ (s + τ + t, s + τ )] i j ≥ η, and in view of Eq. 15 it follows that [ ˜ (s + τ + t, s)] i j ≥ η τ +1 . By part (b), for computing node i, we have</p><formula xml:id="formula_44">[ ˜ (s + B + B 1 -1, s + τ + t + 1)] i i ≥ η B+B 1 -τ -t-1 .</formula><p>By using the preceding two relations, we have</p><formula xml:id="formula_45">[ ˜ (s + B + B 1 -1, s)] i j = m B 1 h = 1 [ ˜ (s+τ +t, s)] h j [ ˜ (s + B + B 1 -1, s + τ + t + 1)] i h ≥ [ ˜ (s + τ + t, s)] i j [ ˜ (s + B + B 1 -1, s + τ + t + 1)] i i ≥ η τ +1 η B+B 1 -τ -t-1 = η B+B 1 -t .</formula><p>Since 0 &lt; η &lt; 1 [cf. <ref type="bibr">Assumption 1]</ref> and B + B 1t &lt; B + B 1 for all nonzero delay values t, we have η B+B 1 -t &gt; η B+B 1 , implying that</p><formula xml:id="formula_46">[ ˜ (s + B + B 1 -1, s)] i j ≥ η B+B 1 .</formula><p>Using Lemma 1, we next establish some additional properties of the transition matrices ˜ (k, s). These properties hold when the agents are connected in the sense of Assumption 2. More specifically, we show that the entries of the row [ ˜ (s + (m -1)B + m B 1 -1, s)] j are uniformly bounded away from zero for all s and for all computing nodes j ∈ {1, . . . , m}.  (b) For any computing node j ∈ {1, . . . , m}, we have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2 Let Weights Rule</head><formula xml:id="formula_47">[ ˜ (s + (m -1)B + m B 1 -1, s)] i j ≥ η (m-1)</formula><p>B+m B 1 for all nodes i and all s ≥ 0.</p><p>Proof For parts (a)-(b), we let s ≥ 0 be arbitrary, but fixed.</p><p>(a) Let i and j be any two computing nodes. When i = j, by Lemma 1 (b), we have</p><formula xml:id="formula_48">[ ˜ (k, s)] i i ≥ η k-s+1 for all k ≥ s.</formula><p>Thus, assume that the nodes i and j are distinct. Under the Connectivity Assumption [cf. <ref type="bibr">Assumption 2]</ref>, there is a directed path from node j to node i passing through some other computing nodes i 1 , . . . , i κ such that the nodes j, i 1 , . . . , i κ , i are distinct and the path edges ( j, i 1 ), (i 1 , i 2 ), . . . , (i κ-1 , i κ ), (i κ , i) belong to the set E ∞ . Let us re-label node i by i κ+1 , and let B 2 = B + B 1 . By the definition of the transition matrix ˜ [cf. Eq. 8], we have</p><formula xml:id="formula_49">[ ˜ (s + (κ + 1)B 2 -1, s)] i κ+1 j = m B 1 h=1 [ ˜ (s + κ B 2 -1, s)] h j [ ˜ (s + (κ + 1)B 2 -1, s + κ B 2 )] i κ+1 h ≥ [ ˜ (s + κ B 2 -1, s)] i κ j [ ˜ (s + (κ + 1)B 2 -1, s + κ B 2 )] i κ+1 i κ ≥ [ ˜ (s + κ B 2 -1, s)] i κ j , η B 2 ,</formula><p>where the first inequality follows from the nonnegativity of the entries of ˜ and the last inequality follows from [ ˜ (s</p><formula xml:id="formula_50">+ (κ + 1)B 2 -1, s + κ B 2 )] i κ+1 i κ ≥ η B 2 [cf. Lemma 1(c) and B 2 = B + B 1 ]. Hence, it follows that [ ˜ (s + (κ + 1)B 2 -1, s)] i κ+1 j ≥ [ ˜ (s + κ B 2 -1, s)] i κ j η B 2 ≥ • • • ≥ [ ˜ (s + B 2 -1, s)] i 1 j η κ B 2 .</formula><p>By Lemma 1(c) and</p><formula xml:id="formula_51">B 2 = B + B 1 , we have [ ˜ (s + B 2 -1, s)] i 1 j ≥ η B 2 , and therefore, [ ˜ (s + (κ + 1)B 2 -1, s)] i κ+1 j ≥ η (κ+1)B 2 . Since i κ+1 = i, we have [ ˜ (s + (κ + 1)B 2 -1, s)] i j ≥ η (κ+1)B 2 .</formula><p>Since there are m agents, and the nodes j, i 1 , . . . , i κ , i are distinct, it follows that κ + 2 ≤ m. By using the preceding relation and the definition of the transition matrix ˜ [cf. Eq. 8], we obtain for all k ≥ s + (m -1)B 2 ,</p><formula xml:id="formula_52">[ ˜ (k, s)] = m B 1 h=1 [ ˜ (s + (κ + 1)B 2 -1, s)] h j [ ˜ (k, s + (κ + 1)B 2 )] i h ≥ [ ˜ (s + (κ + 1)B 2 -1, s)] i j [ ˜ (k, s + (κ + 1)B 2 )] i i ≥ η (κ+1)B 2 η k-s-(κ+1)B 2 +1 = η k-s+1 ,</formula><p>where in the last inequality we also use</p><formula xml:id="formula_53">[ ˜ (k, s)] i i ≥ η k-s+1 for all k, s with k ≥ s ≥ 0 [cf. Lemma 1(b)].</formula><p>(b) For any computing nodes i, j ∈ {1, . . . , m}, by part (a), we have</p><formula xml:id="formula_54">[ ˜ (k, s)] i j ≥ η k-s+1 for all s ≥ 0 and k ≥ s + (m -1)(B + B 1 ). Since s + (m -1)B + m B 1 -1 &gt; s + (m -1)(B + B 1 ) -1, it follows that [ ˜ (s + (m -1)B + m B 1 -1, s)] i j ≥ η (m-1)B+m B 1 .</formula><p>Thus, the desired relation holds for any computing nodes j and i.</p><p>Assume now that j is a computing agent and i is an arbitrary noncomputing agent, i.e., i ∈ {m + 1, . . . , m B 1 }. We can express i as i = l + mt for some l ∈ {1, . . . , m} and t ∈ {1, . . . , B 1 -1}.</p><p>(</p><formula xml:id="formula_55">)<label>16</label></formula><p>By the definition of the matrix ˜ , we have</p><formula xml:id="formula_56">[ ˜ (s + (m -1)B + m B 1 -1, s)] l+mt j ≥ [ ˜ (s + (m -1)B + m B 1 -2, s)] l+m(t-1) j ãl+mt l+m(t-1) (s + (m -1)B + m B 1 -1).</formula><p>Since a l+mt l+m(t-1) = 1 for a noncomputing agent l + mt [cf. Eq. 4], the preceding relation implies</p><formula xml:id="formula_57">[ ˜ (s + (m -1)B + m B 1 -1, s)] l+mt j ≥ [ ˜ (s + (m -1)B + m B 1 -2, s)] l+m(t-1) j .</formula><p>If t = 1, we are done. Otherwise, repeating the same procedure recursively yields</p><formula xml:id="formula_58">[ ˜ (s + (m -1)B + m B 1 -1, s)] i j ≥ [ ˜ (s + (m -1)B + m B 1 -1 -t, s)] l j . (<label>17</label></formula><formula xml:id="formula_59">)</formula><p>Since l ∈ {1, . . . , m} and s</p><formula xml:id="formula_60">+ (m -1)B + m B 1 -1 -t &gt; s + (m -1)(B + B 1 ) -1 [cf.</formula><p>Eq. 16], it follows by part (a) that</p><formula xml:id="formula_61">[ ˜ (s + (m -1)B + m B 1 -1 -t, s)] l j ≥ η (m-1)B+m B 1 -t ≥ η (m-1)B+m B 1</formula><p>, where the last inequality follows since t ≥ 0 and η ∈ (0, 1).</p><p>We next present a result for stochastic matrices which will be used in establishing the convergence properties of the transition matrices ˜ .</p><p>Lemma 3 Let D be a stochastic matrix. Assume that D has a column with all entries bounded away from zero, i.e., for some column j and some scalar ν &gt; 0, we have [D] j i ≥ ν for all i. Let z be a nonnegative vector. Then, for every i * , the following relation holds:</p><formula xml:id="formula_62">([D] i -[D] i * ) z ≤ (1 -ν) z ∞ for all i.</formula><p>Proof We assume without loss of generality that the entries in the first column of D are bounded away from zero by ν, [D] 1 i ≥ ν for all i. For any i * and i, we define the index sets:</p><formula xml:id="formula_63">J + = { j | [D] j i -[D] j i * &gt; 0}, J -= {i | [D] j i -[D] j i * &lt; 0}. Assume first that 1 ∈ J + .</formula><p>Using the index sets J + and J -, we can write</p><formula xml:id="formula_64">([D] i -[D] i * ) z = j [D] j i -[D] j i * z j = j∈J + [D] j i -[D] j i * z j + j∈J - [D] j i -[D] j i * z j ≤ j∈J + [D] j i -[D] j i * z j ,</formula><p>where the inequality follows from the nonnegativity of z j and the definition of the index set</p><formula xml:id="formula_65">J -. Since [D] j i -[D] j i * &gt; 0 for all j ∈ J + , we have j∈J + [D] j i -[D] j i * z j ≤ j∈J + [D] j i -[D] j i * z ∞ = ⎛ ⎝ j∈J + [D] j i - j∈J + [D] j i * ⎞ ⎠ z ∞ .</formula><p>By the stochasticity of the vector [D] i , we have that j∈J + [D] j i ≤ 1. By the nonnegativity of the entries D j i * and the fact that 1 ∈ J + , we obtain j∈J + [D]</p><formula xml:id="formula_66">j i * ≥ D 1 i * . Therefore, j∈J + [D] j i -[D] j i * z j ≤ (1 -D 1 i * ) z ∞ ≤ (1 -ν) z ∞ ,</formula><p>where the last inequality follows from the assumption D 1 i * ≥ ν. Assume now that 1 / ∈ J + . Using the nonnegativity of the vectors [D] i , [D] i * , and z, we can write</p><formula xml:id="formula_67">([D] i -[D] i * ) z ≤ j∈J + [D] j i -[D] j i * z j ≤ j∈J + [D] j i z j ≤ j∈J + [D] j i z ∞ .</formula><p>Since D is stochastic and 1 / ∈ J + , we have</p><formula xml:id="formula_68">j∈J + [D] j i ≤ j =1 [D] j i ≤ 1 -ν.</formula><p>Combining the preceding two relations, we obtain</p><formula xml:id="formula_69">([D] i -[D] i * ) z ≤ (1 -ν) z ∞ .</formula><p>We now give a lemma that plays a key role in establishing the convergence properties and assessing the convergence rate of the matrices ˜ (k, s). In the lemma, we consider the products Dk (s) • • • D1 (s) of the matrices</p><formula xml:id="formula_70">Dk (s) = ˜ (s + k B 2 -1, s + (k -1)B 2 ) ,</formula><p>where B 2 = (m -1)B + m B 1 , and we show that these products converge as k increases to infinity. We use this later to establish the convergence of the composite weights [ ˜ (k, s)] i , as k → ∞, for each computing agent i. </p><formula xml:id="formula_71">Dk (s) = ˜ (s + k B 2 -1, s + (k -1)B 2 ) for all k ≥ 1, (<label>18</label></formula><formula xml:id="formula_72">)</formula><p>where B 2 = (m -1)B + m B 1 . We then have: </p><formula xml:id="formula_73">Dk (s) • • • D1 (s)x -D(s)x ∞ ≤ 2 1 + η -B 2 1 -η B 2 k x ∞ ,</formula><p>for every x ∈ R m B 1 and for all k ≥ 1. In particular, for each j ∈ {1, . . . , m B 1 }, the entries [ Dk (s) • • • D1 (s)] j i for i ∈ {1, . . . , m B 1 }, converge to the same limit φ j (s) as k → ∞ with a geometric rate: for each j ∈ {1, . . . , m B 1 },</p><formula xml:id="formula_74">[ Dk (s) • • • D1 (s)] j i -φ j (s) ≤ 2 1 + η -B 2 1 -η B 2 k ,</formula><p>for all i ∈ {1, . . . , m B 1 }, and all k ≥ 1 and s ≥ 0.</p><p>Proof To simplify our notation in the proof, we suppress the explicit dependence of the matrices Dk (s) on s. For this, we let x ∈ R m B 1 be arbitrary, and we consider the vector sequence {x k } ⊆ R m B 1 defined by</p><formula xml:id="formula_75">x k = Dk • • • D1 x for k ≥ 1.</formula><p>We recursively decompose each vector x k in the following form:</p><formula xml:id="formula_76">x k = z k + c k e with z k ≥ 0 for all k ≥ 0,<label>(19)</label></formula><p>where e ∈ R m B 1 is the vector with all entries equal to 1 and x 0 = x. The recursion is initialized with</p><formula xml:id="formula_77">z 0 = x -min 1≤i≤m B 1 [x] i e and c 0 = min 1≤i≤m B 1 [x] i . (<label>20</label></formula><formula xml:id="formula_78">)</formula><p>Having the decomposition for x k , we consider the vector x k+1 = Dk+1 x k . In view of relation <ref type="bibr" target="#b18">(19)</ref> and the stochasticity of Dk+1 , we have</p><formula xml:id="formula_79">x k+1 = Dk+1 z k + c k e.</formula><p>We define</p><formula xml:id="formula_80">z k+1 = Dk+1 z k -[ Dk+1 ] i * z k e, (<label>21</label></formula><formula xml:id="formula_81">)</formula><formula xml:id="formula_82">c k+1 = [ Dk+1 ] i * z k + c k . (<label>22</label></formula><formula xml:id="formula_83">)</formula><p>where i * is the index of the row vector [ Dk+1 ] i achieving the minimum of inner products [ Dk+1 ] i z k over all i ∈ {1, . . . , m B 1 }. Clearly, we have x k+1 = z k+1 + c k+1 e and z k+1 ≥ 0. By the definition of z k+1 in Eq. 21 it follows that for the components [z k+1 ] i we have</p><formula xml:id="formula_84">[z k+1 ] i = [ Dk+1 ] i z k -[ Dk+1 ] i * z k for all i ∈ {1, . . . , m B 1 },<label>(23)</label></formula><p>where </p><formula xml:id="formula_85">i ∈ {1, . . . , m B 1 }, [z k+1 ] i = [ Dk+1 ] i -[ Dk+1 ] i * z k ≤ (1 -η B 2 ) z k ∞ .</formula><p>Because z k+1 ≥ 0, it follows</p><formula xml:id="formula_86">|z k+1 ∞ ≤ 1 -η B 2 z k ∞ for all k ≥ 0, implying that z k ∞ ≤ 1 -η B 2 k z 0 ∞ for all k ≥ 0. (<label>24</label></formula><formula xml:id="formula_87">)</formula><p>Hence z k → 0 with a geometric rate. Consider now the sequence {c k } satisfying Eq. 22, for which by the nonnegativity of the vector z k and the stochasticity of Dk+1 , we have</p><formula xml:id="formula_88">0 ≤ c k+1 -c k ≤ [ Dk+1 ] i * z k ≤ m B 1 j=1 [ Dk+1 ] j i * z k ∞ = z k ∞ ≤ 1 -η B 2 k z 0 ∞ ,</formula><p>where the last inequality in the preceding relation follows from the relation in Eq. 24.</p><p>Therefore, for any k ≥ 1 and r ≥ 1,</p><formula xml:id="formula_89">c k+r -c k ≤ c k+r -c k+r -1 + • • • + c k+1 -c k ≤ (q k+r -1 + • • • + q k ) z 0 ∞ = 1 -q r 1 -q q k z 0 ∞ ,</formula><p>where q = 1 -η B 2 . Hence, {c k } is a Cauchy sequence and therefore, it converges to some c ∈ R. By letting r → ∞ in the preceding relation, we obtain</p><formula xml:id="formula_90">c -c k ≤ q k 1 -q z 0 ∞ for all k ≥ 0. (<label>25</label></formula><formula xml:id="formula_91">)</formula><p>From the decomposition of x k [cf. Eq. 19], and the relations z k → 0 and c k → c, it follows that ( Dk • • • D1 )x → ce for any x ∈ R m B 1 , with c being a function of x. Therefore, the limit of Dk • • • D1 as k → ∞ exists. We denote this limit by D, for which we have</p><formula xml:id="formula_92">Dx = c(x)e for all x ∈ R m B 1 . (<label>26</label></formula><formula xml:id="formula_93">)</formula><p>(b) Since each Dk is stochastic, each finite product matrix Dk • • • D1 is stochastic, and therefore the limit matrix D is also stochastic, i.e., De = e. Furthermore, the limit matrix D has rank one [cf. Eq. 26]. Thus, all its rows are collinear, and because each of its rows sum to 1, it follows that all rows of D are identical. Therefore, for some stochastic vector φ ∈ R m B 1 , we have D = e φ . (c) Let x ∈ R m B 1 be arbitrary and let x k = ( Dk • • • D1 )x. By using the decomposition of x k given in Eq. <ref type="bibr" target="#b18">19)</ref> we have</p><formula xml:id="formula_94">( Dk • • • D1 )x -Dx = z k + (c k -c)e for all k ≥ 1,</formula><p>[cf. Eq. 26 where the explicit dependence on x in c(x) is suppressed]. Using the estimates in Eqs. 24 and 25) we obtain for all k ≥ 1,</p><formula xml:id="formula_95">( Dk • • • D1 )x -Dx ∞ ≤ z k ∞ + |c k -c| ≤ 1 + 1 1 -q q k z 0 ∞ . Since z 0 ∞ ≤ 2 x ∞ [cf. Eq. 20] and q = 1 -η B 2 , it follows ( Dk • • • D1 )x -Dx ∞ ≤ 2 1 + η -B 2 1 -η B 2 k x ∞ for all k ≥ 1,<label>(27)</label></formula><p>establishing the first relation of part (c).</p><p>To show the second relation of part (c) of the lemma, let j ∈ {1, . . . , m B 1 } be arbitrary. By letting x = e j in Eq. 27, and by using D = e φ and e j ∞ = 1, we obtain</p><formula xml:id="formula_96">[D k • • • D 1 ] j -φ j e ∞ ≤ 2 1 + η -B 2 1 -η B 2 k for all k ≥ 1, implying that for all i ∈ {1, . . . , m B 1 }, [D k • • • D 1 ] j i -φ j ≤ 2 1 + η -B 2 1 -η B 2 k for all k ≥ 1.</formula><p>We next use Lemma 4 to establish the convergence properties of the matrices ˜ (k, s) for arbitrary s, as k goes to infinity. In particular, the following lemma states that the matrices ˜ (k, s) have the same limit as the matrices [ Dk (s)</p><formula xml:id="formula_97">• • • D k (s)] , when k increases to infinity.</formula><p>The proof is omitted since it is identical to the proof of a similar result for the case of no delay in Lemma 4 of our work <ref type="bibr" target="#b13">[14]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>123</head><p>(c) For each j ∈ {1, . . . , m B 1 }, the entries [ ˜ (k, s)] i j , i = 1, ..., m B 1 , converge to the same limit φ j (s) as k → ∞ with a geometric rate, i.e., for each j ∈ {1, . . . , m B 1 } and all s ≥ 0,</p><formula xml:id="formula_98">[ ˜ (k, s)] i j -φ j (s) ≤ 2 1 + η -B 2 1 -η B 2 1 -η B 2 k-s B 2</formula><p>for all k ≥ s and i ∈ {1, . . . , m B 1 }, where B 2 = (m -1)B + m B 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Convergence result</head><p>In this section, we prove the convergence of the iterates of Eq. 1 to a consensus and we provide a convergence rate estimate. Lemma 5 plays a key role in establishing these results. (b) The consensus vector x ∈ R m is a nonnegative combination of the agent initial vectors x j (0), j = 1, . . . , m, i.e.,</p><p>x = m j=1 w j x j (0), with scalars w j ≥ 0 for all j = 1, . . . , m, and such that m j=1 w j ≤ 1. (c) The convergence rate to the consensus is geometric: for all agents i ∈ {1, . . . , m},</p><formula xml:id="formula_99">x i (k + 1) -x ≤ 2 1 + η -B 2 1 -η B 2 1 -η B 2 k B 2 m j=1</formula><p>x j (0) -x for all k ≥ 0, where B 2 = (m -1)B + m B 1 .</p><p>Proof In view of the equivalence between the evolution equations (1) for the original system and the evolution equations (5) for enlarged system, it suffices to show that the limit lim k→∞ xi (k) exists and that these limits are the same for all computing nodes i ∈ {1, . . . , m}. To show this, we consider the compact representation of Eq. 5, which is given in Eq. 10. Letting s = 0 in relation <ref type="bibr" target="#b9">(10)</ref>, we obtain for any agent i = {1, . . . , m B 1 } in the enlarged system,</p><formula xml:id="formula_100">xi (k + 1) = m B 1 j=1</formula><p>[ ˜ (k, 0)] i j x j (0) for all k ≥ 0.</p><p>Recall that the initial vectors xi (0) for computing agents i ∈ {1, . . . , m} in the enlarged system are the same as the initial vectors x i (0) of agents i in the original system, and that As indicated in the proof of the preceding proposition [cf. Eqs. 28 and 29], the consensus value x is a function of the vector φ(0) defining the limit of the transition matrices ˜ (k, 0) as k → ∞, i.e., the vector φ(0) for which lim k→∞ ˜ (k, 0) = φ(0)e .</p><p>The transition matrices depend on the maximum delay B 1 in the system, and therefore the vector φ(0) is also a function of B 1 . Hence, the consensus value x implicitly depends on the delay bound B 1 through the vector φ(0). This dependence can be made more explicit by focusing on more structured weight choices a i j (k) and topologies for the agent communication network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>We considered an algorithm for the consensus problem in the presence of delay in the agent values. Our analysis relies on reducing the problem to a consensus problem in an enlarged agent system without delays. We studied properties of the reduced model and through these properties, we established the convergence and rate of convergence properties for the consensus problem with delays. Our convergence rate estimate is explicitly given in terms of the system parameters. Furthermore, our rate result shows a geometric convergence to consensus. Future work includes incorporating the delayed consensus algorithm in the distributed optimization framework developed in <ref type="bibr" target="#b13">[14]</ref> to account for delays in agent values.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Figure 1(a) illustrates an agent network with 3 agents, where agents 1 and 2, and agents 2 and 3 communicate directly. (b) illustrates the enlarged network associated with the original network of part (a), when the delay bound is B 1 = 3. The noncomputing agents introduced in the system are 4, . . . , 9. Agents 4, 5, and 6 model the delay of 1 while agents 7, 8, and 9 model the delay of 2 for the computing nodes 1, 2 and 3, respectively</figDesc><graphic coords="7,49.59,55.50,340.36,113.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) hold for the weights a i j (k) for i, j ∈ {1, . . . , m} and k ≥ 0 [cf. Assumption 1(a)]. Let also Bounded Delay assumption hold [cf.Assumption 4]. Then, the following hold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>.</head><label></label><figDesc>By using the inductive hypothesis and the relationãh h-m (s) = 1 for any noncomputing node [cf. Eqs. 4 and 11, respectively], it follows that [ ˜ (s + t, s)] j+(t+1)m j = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a), Connectivity, Bounded Intercommunication Interval, and Bounded Delay assumptions hold for the agents in the original network [cf. Assumptions 1(a), 2, 3, and 4]. Then, the following hold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( a )</head><label>a</label><figDesc>For any computing nodes i, j ∈ {1, . . . , m}, we have[ ˜ (k, s)] i j ≥ η k-s+1for all s ≥ 0, and k ≥ s + (m -1)(B + B 1 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Lemma 4</head><label>4</label><figDesc>Let Weights Rule, Connectivity, Bounded Intercommunication Interval, and Bounded Delay assumptions hold for the agents in the original network [cf. Assumptions 1, 2, 3, and 4].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( a )</head><label>a</label><figDesc>The limit D(s) = lim k→∞ Dk (s) • • • D1 (s) exists. (b) The limit D(s) is an m B 1 × m B 1 matrix whose rows are identical stochastic vectors (function of s) i.e., D(s) = e φ (s) where φ(s) ∈ R m B 1 is a stochastic vector. (c) The convergence of Dk (s) • • • D1 (s) to D(s) is geometric:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(a) We prove that the limit of Dk • • • D1 exists by showing that the sequence { Dk • • • D1 x} converges for every x ∈ R m B 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Lemma 5</head><label>5</label><figDesc>Let Weights Rule, Connectivity, Bounded Intercommunication Interval, and Bounded Delay assumptions hold [cf. Assumptions 1, 2, 3, and 4]. We then have: (a) The limit ˜ (s) = lim k→∞ ˜ (k, s) exists for each s. (b) The limit matrix ˜ (s) has identical columns and the columns are stochastic, i.e., ˜ (s) = φ(s)e , where φ(s) ∈ R m B 1 is a stochastic vector for each s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 1 + η -B 2 1 -η B 2 1 -η B 2 k B 2 for</head><label>21122</label><figDesc>the initial vectors xi (0) are zero for noncomputing agents i ∈ {m + 1, . . . , m B 1 } [cf.Eq. 6]. Thus, we havexi (k + 1) = m j=1 [ ˜ (k, 0)] i j x j (0) for all k ≥ 0. (28)By Lemma 5, we have for all j,[ ˜ (k, 0)] i j -φ j (0) ≤ all k ≥ 0 and i ∈ {1, . . . , m B 1 },where φ(0) ∈ R m B 1 is a stochastic vector with components φ j (0). Therefore,lim k→∞ xi (k + 1) = m j=1 φ j (0)x j (0) for all i = 1, . . . , m,showing thatx = m j=1 φ j (0)x j (0). (29)This establishes the results in parts (a) and (b), where w j = φ j (0) and the properties of the weights w j follow from the stochasticity of the vector φ(0). From relations (28) and (29), we obtain for any z ∈ R n , and all i ∈ {1, . . . , m} and k ≥ 0,xi (k + 1) -x = m j=1 [ ˜ (k, 0)] i j (x j (0)z) -m j=1 φ j (0)(x j (0)z),where we use the stochasticity of vectors [ ˜ (k, 0)] i and φ(0). Therefore, for any z ∈ R n ,xi (k + 1)z ≤ m j=1 [ ˜ (k, 0)] i j -φ j (0) x j (0)z ≤ max 1≤h≤m [ ˜ (k, 0)] i h -φh (0) m j=1 x j (0)z .The rate estimate in part (c) follows immediately from the preceding relation with z = x and part (c) of Lemma 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>[ Dk+1 ]  i is the i-th row vector of the matrix Dk+1 . By Lemma 2 and the definition of the matrices Dk [cf. Eq. 18], we have that the first m columns of each matrix Dk are bounded away from zero, i.e., for all j ∈ {1, . . . , m} and i ∈ {1, . . . , m B 1 }, B 2 for all k ≥ 0. Then, from relation (23) and Lemma 3, we have for all</figDesc><table><row><cell>[ Dk+1 ]</cell></row></table><note><p>j i ≥ η</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The delay bound is only used in our analysis. The implementation of the algorithm does not require the bound to be available to the agents.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Assumptions 1-4 (or variations thereof) are standard in the literature on distributed control and coordination of mobile autonomous agents. They are satisfied in many applications of wireless communication networks and wireless sensor networks. Assumptions 2 and</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>impose some conditions on the communication requirements among agents, which may not hold in mobile networks where the neighbors of agents vary significantly over time.<ref type="bibr" target="#b2">3</ref> This idea has also been used in the distributed computation model of Tsitsiklis<ref type="bibr" target="#b17">[18]</ref>, and it motivates our development here.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Convergence speed of unsteady distributed consensus: decay estimate along the settling spanning-trees</title>
		<author>
			<persName><forename type="first">D</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Bliman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/math.OC/0610854" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Parallel and Distributed Computation: Numerical Methods</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Belmont, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Average consensus problems in networks of agents with delayed communications</title>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Bliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ferrari-Trecate</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/math.OC/0503009v2" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<title level="m">Convergence in multiagent coordination, consensus, and flocking. Proceeding of 44th IEEE Conference on Decision and Control</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="2996" to="3000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Gossip algorithms: design, analysis, and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE INFOCOM, 24th Joint Conference of the IEEE Computer and Communications Societies</title>
		<meeting>IEEE INFOCOM, 24th Joint Conference of the IEEE Computer and Communications Societies</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1653" to="1664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Spielman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Morse</surname></persName>
		</author>
		<title level="m">Proceedings of 44th IEEE Conference on Decision and Control</title>
		<meeting>44th IEEE Conference on Decision and Control</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="2356" to="2361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Communication constraints in coordinated consensus problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Carli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fagnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Speranzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE American Control Conference</title>
		<meeting>IEEE American Control Conference</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="4189" to="4194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Average consensus on networks with transmission noise or quantization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Carli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fagnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Control Congerence</title>
		<meeting>European Control Congerence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coordination of groups of mobile autonomous agents using nearest neighbor rules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jadbabaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Morse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="988" to="1001" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Consensus with quantized information updates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Basar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 45th IEEE Conference on Decision and Control</title>
		<meeting>45th IEEE Conference on Decision and Control</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2728" to="2733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Asymptotic agreement and convergence of asynchronous stochastic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Basar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Autom. Control</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="612" to="618" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Advances in neural information processing systems 18</title>
		<author>
			<persName><forename type="first">C</forename><surname>Moallemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<meeting>Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="899" to="906" />
		</imprint>
	</monogr>
	<note>Consensus propagation</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the rate of convergence of distributed subgradient methods for multi-agent optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 46th IEEE Conference on Decision and Control</title>
		<meeting>46th IEEE Conference on Decision and Control</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="4711" to="4716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed subradient methods for multi-agent optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Autom. Control</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Consensus problems in networks of agents with switching topology and time-delays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olfati-Saber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1520" to="1533" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convergence rates in distributed consensus and averaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 46th IEEE Conference on Decision and Control</title>
		<meeting>46th IEEE Conference on Decision and Control</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3387" to="3392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Convergence speed in distributed consensus and averaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:math/0612682v1</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control Optim. archive link</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Problems in decentralized decision making and computation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convergence and asymptotic agreement in distributed decision problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Athans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="50" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed asynchronous deterministic and stochastic gradient optimization algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Athans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="803" to="812" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast linear iterations for distributed averaging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Control Lett</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="65" to="78" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
