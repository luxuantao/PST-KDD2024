<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning and its Applications in Biomedicine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chensi</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CapitalBio Corporation</orgName>
								<address>
									<postCode>102206</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Feng</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biotechnology</orgName>
								<orgName type="institution">Beijing Institute of Radiation Medicine</orgName>
								<address>
									<postCode>100850</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>#,b</roleName><forename type="first">Hai</forename><surname>Tan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab of Ophthalmology</orgName>
								<orgName type="institution" key="instit1">Zhongshan Ophthalmic Center</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
								<address>
									<postCode>500040</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Deshou</forename><surname>Song</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab of Ophthalmology</orgName>
								<orgName type="institution" key="instit1">Zhongshan Ophthalmic Center</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
								<address>
									<postCode>500040</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenjie</forename><surname>Shu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biotechnology</orgName>
								<orgName type="institution">Beijing Institute of Radiation Medicine</orgName>
								<address>
									<postCode>100850</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weizhong</forename><surname>Li</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Zhongshan School of Medicine</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
								<address>
									<postCode>500040</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiming</forename><surname>Zhou</surname></persName>
							<email>yimingzhou@capitalbio.com</email>
							<affiliation key="aff0">
								<orgName type="institution">CapitalBio Corporation</orgName>
								<address>
									<postCode>102206</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Medical Systems Biology Research Center</orgName>
								<orgName type="institution">Tsinghua University School of Medicine</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaochen</forename><surname>Bo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhi</forename><surname>Xie</surname></persName>
							<email>xiezhi@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="department">State Key Lab of Ophthalmology</orgName>
								<orgName type="institution" key="instit1">Zhongshan Ophthalmic Center</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
								<address>
									<postCode>500040</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Xiaochen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biotechnology</orgName>
								<orgName type="institution">Beijing Institute of Radiation Medicine</orgName>
								<address>
									<postCode>100850</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning and its Applications in Biomedicine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9F333F97B2F2CD8B58414E9F299D8033</idno>
					<idno type="DOI">10.1016/j.gpb.2017.07.003</idno>
					<note type="submission">Received Date: 26 December 2016 Revised Date: 18 June 2017 Accepted Date: 4 July 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Genomics, Proteomics &amp; Bioinformatics Deep learning</term>
					<term>Big data</term>
					<term>Bioinformatics</term>
					<term>Biomedical informatics</term>
					<term>Medical image</term>
					<term>High-throughput sequencing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Advances in biological and medical technologies have been providing us explosive volumes of biological and physiological data, such as medical images, electroencephalography, genomic and protein sequences. Learning from these data facilitates the understanding of human health and disease. Developed from artificial neural networks, deep learning-based algorithms show great promise in extracting features and learning patterns from complex data. The aim of this paper is to provide an overview of deep learning techniques and some of the state-of-the-art applications in the biomedical field. We first introduce the development of artificial neural network and deep learning. We then describe two main components of deep learning, i.e., deep learning architectures and model optimization. Subsequently, some examples are demonstrated for deep learning applications, including medical image classification, genomic sequence analysis, as well as protein structure classification and prediction. Finally, we offer our perspectives for the future directions in the field of deep learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Deep learning is a recent and fast-growing field of machine learning. It attempts to model abstraction from large-scale data by employing multi-layered deep neural networks (DNNs), thus making sense of data such as images, sounds, and texts <ref type="bibr" target="#b0">[1]</ref>. Deep learning in general has two properties: <ref type="bibr" target="#b0">(1)</ref> multiple layers of nonlinear processing units, and (2) supervised or unsupervised learning of feature presentations on each layer <ref type="bibr" target="#b0">[1]</ref>. The early framework for deep learning was built on artificial neural networks (ANNs) in the 1980s <ref type="bibr" target="#b1">[2]</ref>, while the real impact of deep learning became apparent in 2006 <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. Since then, deep learning has been applied to a wide range of fields, including automatic speech recognition, image recognition, natural language processing, drug discovery, and bioinformatics <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>.</p><p>The past decades have witnessed a massive growth in biomedical data, such as genomic sequences, protein structures, and medical images, due to the advances of high-throughput technologies. This deluge of biomedical big data necessitates effective and efficient computational tools to store, analyze, and interpret such data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8]</ref>. Deep learning-based algorithmic frameworks shed light on these challenging problems. The aim of this paper is to provide the bioinformatics and biomedical informatics community an overview of deep learning techniques and some of the state-of-the-art applications of deep learning in the biomedical field.</p><p>We hope this paper will provide readers an overview of deep learning, and how it can be used for analyzing biomedical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The development of ANNs</head><p>As a basis for deep learning, ANNs were inspired by biological processes in the 1960s, when it was discovered that different visual cortex cells were activated when cats visualized different objects <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. These studies illustrated that there were connections between the eyes and the cells of the visual cortex, and that the information was processed layer by layer in the visual system. ANNs mimicked the perception of objects by connecting artificial neurons within layers that could extract the features of objects <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>. However, ANN research stagnated after the 1960s, due to the low capability resulting from its shallow structures and the limited computational capacity of computers at that time <ref type="bibr" target="#b16">[17]</ref>.</p><p>Thanks to the improvement in computer capabilities and methodologies <ref type="bibr" target="#b17">[18]</ref>, ANNs with efficient backpropagation (BP) facilitated studies on pattern recognition <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>. In a neural network with BP, classifications were first processed by the ANN model, and weights were then modified by evaluating the difference between the predicted and the true class labels. Although BP helped to minimize errors through gradient descent, it seemed to work only for certain types of ANNs <ref type="bibr" target="#b23">[24]</ref>. Through improving the steeper gradients with BP, several learning methods were proposed, such as momentum <ref type="bibr" target="#b24">[25]</ref>, adaptive learning rate <ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>, least-squares methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, quasi-Newton methods <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>, and conjugate gradient (CG) <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>. However, due to the complexity of ANNs, other simple machine learning algorithms, such as support vector machines (SVMs) <ref type="bibr" target="#b36">[37]</ref>, random forest <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>, and k-nearest neighbors algorithms (k-NN) <ref type="bibr" target="#b39">[40]</ref>, gradually overtook ANNs in popularity (Figure <ref type="figure" target="#fig_2">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The development of deep learning</head><p>An ANN with more hidden layers offers much higher capacity for feature extraction <ref type="bibr" target="#b3">[4]</ref>.</p><p>However, an ANN often converges to the local optimum, or encounters gradient diffusion when it contains deep and complex structures <ref type="bibr" target="#b40">[41]</ref>. A gradient propagated backwards rapidly diminishes in magnitude along the layers, resulting in slight modification to the weights in the layers near the input (http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial) <ref type="bibr" target="#b41">[42]</ref>.</p><p>Subsequently, a layer-wise pre-training deep auto-encoder (AE) network was proposed, bringing ANNs to a new stage of development <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref> (Figure <ref type="figure" target="#fig_2">1</ref>). In this network, each layer is trained by minimizing the discrepancy between the original and the reconstructed data <ref type="bibr" target="#b3">[4]</ref>. The layer-wise pre-training breaks the barrier of gradient diffusion <ref type="bibr" target="#b3">[4]</ref>, and also results in a better choice of weights for deep neural networks (DNNs), thereby preventing the reconstructed data from reaching a local optimum where the local optimum is usually caused by the random selection of initial weights. In addition, the employment of graphic processing units (GPUs) also renews the interest of researchers in deep learning <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>With the focus of more attention and efforts, deep learning has burgeoned in recent years and has been applied broadly in industry. For instance, deep belief networks (DBNs) and stacks of restricted Boltzmann machines (RBMs) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49]</ref> have been applied in speech and image recognition <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50]</ref> and natural language processing <ref type="bibr" target="#b50">[51]</ref>. Proposed to better mimick animals' perceptions of objects <ref type="bibr" target="#b51">[52]</ref>, convolutional neural networks (CNN) have been widely applied in image recognition <ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref>, image segmentation <ref type="bibr" target="#b55">[56]</ref>, video recognition <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b57">58]</ref>, and natural language processing <ref type="bibr" target="#b58">[59]</ref>. Recurrent neural networks (RNNs) are another class of ANNs that exhibit dynamic behavior, with artificial neurons that are associated with time steps <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b60">61]</ref>.</p><p>RNNs have become the primary tool for handling sequential data <ref type="bibr" target="#b61">[62]</ref>, and have been applied in natural language processing <ref type="bibr" target="#b62">[63]</ref> and handwriting recognition <ref type="bibr" target="#b63">[64]</ref>. Later on, variants of AEs, including sparse AEs, stacked AEs (SAEs), and de-noising AEs, have also gained popularity in pre-training deep networks <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b65">[66]</ref><ref type="bibr" target="#b66">[67]</ref>.</p><p>Although applications of deep learning have been primarily focused on image recognition, video and sound analyses, as well as natural language processing, it also opens doors in life sciences, which will be discussed in detail in the next sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Brief description of deep learning</head><p>Although the underlying assumptions and theories are different, the basic idea and processes for feature extraction in most deep NN (DNN) architectures are similar. In the forward pass, the network is activated by an input to the first layer, which then spreads the activation to the final layer along the weighted connections, and generates the prediction or reconstruction results. In the backward pass, the weights of connections are tuned by minimizing the difference between the predicted and the real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic concepts</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Activation functions</head><p>Activation functions form the non-linear layers in all deep learning frameworks; and their combinations with other layers are used to simulate the non-linear transformation from the input to the output <ref type="bibr" target="#b61">[62]</ref>. Therefore, better feature extraction can be achieved by selecting appropriate activation functions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69]</ref>. Here, we introduce several commonly-used activation functions, represented by g .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>Sigmoid function: g(a)</p><p>1 1 e a , where a is the input from the front layer. A sigmoid function transforms variables to values ranging from 0 to 1 and is commonly used to produce a Bernoulli distribution. For example: ,  Hyperbolic tangent: g(a) tanh(a)</p><p>. Here, the derivative of g is calculated as g 1 g 2 , making it easy to work with in BP algorithms.</p><p> Softmax: g(a) e a i e a j j . The softmax output, which a n be considered as a probability distribution over the categories, is commonly used in the final layer.</p><p> Rectified linear unit (ReLU): g(a) max(0,a). This activation function and its variants show superior performance in many cases and are the most popular activation function in deep learning so far <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref>. ReLU can also solve the gradient diffusion problem <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b73">74]</ref>.</p><formula xml:id="formula_0"> Softplus: g(a) log(1 e a</formula><p>). This is one of the variants of ReLU, representing a smooth approximation of ReLU (in this article, the log always represents the natural logarithm).</p><p> Absolute value rectification: g(a) | a |. This function is useful when the pooling layer takes the average value in CNNs <ref type="bibr" target="#b74">[75]</ref>, thus preventing otherwise the negative features and the positive features from diminishing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> Maxout:</head><p>( ) max( )</p><formula xml:id="formula_1">i i i i g x b w x    .</formula><p>The weight matrix in this function is a three- dimensional array, where the third array corresponds to the connection of the neighboring layers <ref type="bibr" target="#b75">[76]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization objective</head><p>An optimization objective is often composed of a loss function and a regularization term. The loss function measures the discrepancy between the output of the network depend on model parameters () f (x | ) and the expected result y , e.g., the true class labels in classification tasks, or the true level in prediction tasks. However, a good learning algorithm performs well not only on the training data, but also on the test data. A collection of strategies designed to reduce the test error is called regularization <ref type="bibr" target="#b61">[62]</ref>. Some regularization terms apply penalties to parameters to prevent overly complex models. Here, we briefly introduce the commonly used loss function L( f (x | ), y) and regularization term ( ). The optimization objective is usually defined as: <ref type="bibr" target="#b0">(1)</ref> where is a balance of these two components, and in practice, the loss function is usually calculated across randomly-sampled training samples rather than the data-generating distribution, since the latter is unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss function</head><p>Most DNNs use cross entropy between the training data and the model distribution as the loss function. The most commonly used form of cross entropy is the negative conditional log-</p><formula xml:id="formula_2">likelihood: L( f (x | ), y) log P( f y | x, )</formula><p>. This is a collection of loss functions corresponding to the distribution of y given the value of input variable</p><p>x . Here, we introduce several commonly used loss functions that follow this pattern: Suppose y is continuous and has a Gaussian distribution over a given variable</p><p>x . The loss function would be:</p><formula xml:id="formula_3">2 2 2 2 2 2 1 1 1 1 ( ( | ), ) log[ exp( ( ) )] ( ) log(2 ) 2 2 2 2 L f x y y f y f            <label>(2)</label></formula><p>Which is equivalently described as the squared error. The squared error was the most commonly used loss function in the 1980s <ref type="bibr" target="#b61">[62]</ref>. However, it often tends to penalize outliers excessively, leading to slower convergence rates <ref type="bibr" target="#b76">[77]</ref>.</p><p>If y follows the Bernoulli distribution, then the loss function will be:</p><formula xml:id="formula_4">( ( | ), ) log ( | ) (1 ) log(1 ( | )) L f x y y f x y f x        <label>(3)</label></formula><p>When y is discrete and has only two values, for instance, , we can take the softmax value (see commonly-used activation functions) as the probability over the categories.</p><p>Then the loss function will be:</p><formula xml:id="formula_5">( ( | ), ) log( ) log( ) y j j a a y a j j e L f x y a e e         (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularization term</head><p>L 2 parameter regularization is the most common form of regularization term and contributes to the convexity of the optimization objective, leading to an easy solution for the minimum using the Hessian matrix <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79]</ref>.</p><p>L 2 parameter regularization can be defined as ( )</p><formula xml:id="formula_6">1 2</formula><p>|| || 2 <ref type="bibr" target="#b4">(5)</ref> where represents weights of connecting units in the network (the same as in the following context).</p><p>Compared to L 2 parameter regularization, L 1 parameter regularization results in a sparser solution of ω and tends to learn small groups of features.</p><p>L 1 parameter regularization can be defined as</p><formula xml:id="formula_7">( ) || || 1 | i | i å<label>(6)</label></formula><p>Frobenius parameter regularization is induced by the inner product and is block decomposable, therefore it is easier to compute <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b80">81]</ref>. Frobenius parameter regularization can be defined as</p><formula xml:id="formula_8">() 2 2 1 ( ) | | rank ij i i j i           (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>where i is the i-th largest singular value. Frobenius parameter regularization has a function similar to nuclear norm in terms of regularization.</p><p>Nuclear norm has been widely used as regularization in recent years <ref type="bibr" target="#b81">[82]</ref><ref type="bibr" target="#b82">[83]</ref><ref type="bibr" target="#b83">[84]</ref>. Nuclear norm regularization measures the sum of the singular values of and can be defined as This process is repeated until the proper model and a small fit error, i.e., loss function value, are obtained (http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial).</p><p>However, different optimization methods have different advantages and disadvantages on different architectures and loss functions <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b84">85]</ref>. Stochastic gradient descent (SGD) and its variants are the most-used methods, which update the parameters by a gap corresponding to the Jacobian matrix. The computation time per update does not grow too much even with a large training set <ref type="bibr" target="#b85">[86]</ref><ref type="bibr" target="#b86">[87]</ref><ref type="bibr" target="#b87">[88]</ref>. AdaGrad updates parameters according to the accumulation of squared gradients, which can converge rapidly when applied to convex functions, but performs worse in certain models <ref type="bibr" target="#b61">[62]</ref>. RMSProp, an AdaGrad algorithm, has been an effective and popular method for parameter optimization. Another type of algorithm makes use of second order derivatives to improve optimization. For instance, limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm (BFGS) is one type of quasi-Newton method, which iteratively refines the approximation of the inverse of the Hessian matrix and avoids storing the matrix. BFGS is good at dealing with low dimensionality problems, particularly for convolutional models <ref type="bibr" target="#b84">[85]</ref>. In addition, conjugate gradient combines conjugacy and gradient descent in the update direction decision for parameters, efficiently avoiding the calculation of the inverse Hessian <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>,</p><p>while contrastive divergence is usually used in RBM model <ref type="bibr" target="#b88">[89]</ref><ref type="bibr" target="#b89">[90]</ref><ref type="bibr" target="#b90">[91]</ref>. With the help of a GPU <ref type="bibr" target="#b46">[47]</ref>, many algorithms can be accelerated significantly <ref type="bibr" target="#b84">[85]</ref>.</p><p>The proper architecture and objective function should be selected according to data considered. As a type of machine learning, deep learning can also encounter "overfitting," that is, low error on training data but high error on test data. In addition to the regularization terms, other methods for regularization are also important for reducing test error. Adding noise to the input or to the weights are efficient regularization strategies <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b91">92]</ref>, as in the case of a denoising AE <ref type="bibr" target="#b92">[93]</ref>. Stopping the optimization early by setting an iteration number is another commonly used strategy to prevent the network from overfitting <ref type="bibr" target="#b61">[62]</ref>. Parameter sharing, just like in CNN, can also contribute to regularization <ref type="bibr" target="#b93">[94]</ref>. Dropout can force units to independently evolve, and randomly remove portions of units in ANN on each iteration, and can therefore achieve better results with inexpensive computation <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b95">96]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep learning architectures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AEs</head><p>Different from ordinary ANNs, AEs extract features from unlabeled data and set target values to be equal to the inputs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b96">97]</ref>. Given the input vector{x (1) , x (2) , x (3) , }, x (i) R n , the AE tries to learn the model:</p><formula xml:id="formula_10">h W ,b (x) g(Wx b) x (9)</formula><p>where W and b are the parameters of the model, g is the activation function (same definition applied in the following context), and h W ,b represents the hidden units. When the number of hidden units, which represents the dimension of features, is smaller than the input dimension, the AE performs a reduction of data dimensionality similar to principal component analysis <ref type="bibr" target="#b97">[98]</ref>.</p><p>Besides pattern recognition, an AE with a classifier in the final layer can perform classification tasks as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RBMs and DBNs</head><p>RBMs are generative graphical models that aim to learn the distribution of training data. Since we do not know which distribution the data obeys, we cannot directly compute model parameters using the maximum likelihood principle. Boltzmann machines (BMs) use an energy function to generate the probability distribution (see Equations 12 and 13 below), and then optimize parameters until the model learns the true distribution of the data. The original BMs have not been demonstrated to be useful for practical problems, while RBMs are commonly used in deep learning.</p><p>RBMs restrict the BMs to a bipartite graph, i.e., there are no connections within visible units v x or hidden units h . This restriction ensures the conditional independency of hidden units and visible units <ref type="bibr" target="#b90">[91]</ref>, i.e.,</p><formula xml:id="formula_11">p(h | v) p(h i | v) i p(v | h) p(v j | h) j (10)</formula><p>Furthermore, most RBMs rely on the assumption that all units in the network take only one of the two possible values 0 or 1, i.e., v j ,h i (0,1). Provided with the activation function, the conditional distribution of hidden and visible units can be expressed in the following form:</p><formula xml:id="formula_12">p(h i 1| v) g(W i v c i ) p(v j 1| h) g(W j h b j )<label>(11)</label></formula><p>According to the Boltzmann distribution, probability distributions over hidden and visible vectors are defined as: <ref type="bibr" target="#b11">(12)</ref> where Z e E(v,h) is the normalizing constant and</p><formula xml:id="formula_13">P(v,h) 1 Z e E (v,h)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E(v,h) b v c h h</head><p>Wv is the energy function <ref type="bibr" target="#b98">[99]</ref>. The conditional probability distribution can also be computed by integral, and the parameters can then be optimized by minimizing the Kullback-Leibler divergence.</p><p>Overall, given the network architectures and optimized parameters, the distribution of the visible units could be computed as:</p><formula xml:id="formula_14">p(v) p(v,h) h e E (v,h) Z h (<label>13</label></formula><formula xml:id="formula_15">)</formula><p>A DBN can be viewed as a stack of RBMs <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b99">100]</ref> or AEs <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b100">101]</ref>. Similar to RBMs, DBNs can learn the distribution of the samples, or learn to classify the inputs given class labels <ref type="bibr" target="#b2">[3]</ref>. However, the p(h) in the formula</p><formula xml:id="formula_16">p(v) p(v,h) h p(h) p(v | h) h</formula><p>is replaced by a better model after the weight of connections W is learned by an RBM [3,100].</p><p>In addition to feature extraction, RBMs can also learn distributions of unlabeled data as generative models, and classify labeled data as discriminative models (regard the hidden units as labels). Similar to AEs, RBMs can also pre-train parameters for a complex network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convolutional neural networks</head><p>Different from other deep learning structures, artificial neurons in convolutional neural networks (CNNs) extract features of small portions of input images, which are called receptive fields. This type of feature extraction was inspired by the visual mechanisms in living organisms, where cells in the visual cortex are sensitive to small regions of the visual field <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b101">102]</ref>.</p><p>Besides the activation function, there are two particular types of layers in CNNs: the convolutional layer and the pooling layer (Figure <ref type="figure" target="#fig_3">2</ref>). In the convolutional layer, the image is convolved by different convolutional filters via shifting the receptive fields step by step <ref type="bibr" target="#b86">[87]</ref> (Figure <ref type="figure" target="#fig_3">2A</ref>). The convolutional filters share the same parameters in every small portion of the image, largely reducing the number of hyperparameters in the model. A pooling layer, taking advantage of the "stationarity" property of images, takes the mean, the max, or other statistics of the features at various locations in the feature maps, thus reducing the variance and capturing essential features (http://deeplearning.net/tutorial/lenet.html) (Figure <ref type="figure" target="#fig_3">2B</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recurrent neural networks</head><p>Recurrent neural networks (RNNs) outperform other deep learning approaches in dealing with the sequential data. Based on the property of sequential data, parameters across different time steps of the RNN model are shared. Taking speech as an example: some vowels may last longer than other sounds; the difference makes absolute time steps meaningless and demands that the model parameters be the same among the time steps <ref type="bibr" target="#b61">[62]</ref>.</p><p>Beside the parameter sharing, RNNs are different from other multilayer networks by virtue of having a circuit, which represents hidden-to-hidden recurrence. A simple recurrent network corresponds to the following equation:</p><formula xml:id="formula_17">h t g(b Uh t 1 Wx t ) o t c Vh t (<label>14</label></formula><formula xml:id="formula_18">)</formula><p>where t is the label for time, W and V represent the weights connecting hidden and input units, and hidden and output units, respectively, b and c are the offsets of the visible and hidden layers, respectively, g is the activation function, and U represents the weights connecting hidden units at time t 1 to hidden units at time t (Figure <ref type="figure" target="#fig_4">3</ref>).</p><p>Similar to other deep learning architectures, RNNs can also be trained using the BP method.</p><p>A variant of the BP method called back propagation through time (BPTT) is the standard optimization method for RNNs <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b102">103]</ref>, and some alternative methods have also been proposed</p><p>to speed up the optimization or to extend its capacity <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b103">[104]</ref><ref type="bibr" target="#b104">[105]</ref><ref type="bibr" target="#b105">[106]</ref><ref type="bibr" target="#b106">[107]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applications in biomedicine</head><p>Owing to advances in high-throughput technologies, a deluge of biological and medical data has been obtained in recent decades, including data related to medical images, biological sequences, and protein structures. Some successful applications of deep learning in biomedical fields are reviewed in this section and a summary of applications is shown in Table <ref type="table">1</ref>. training procedure <ref type="bibr" target="#b108">[109]</ref>, which obtained second place in the 2013 BRATS. Their methodology was tested on the publicly available datasets INbreast <ref type="bibr" target="#b109">[110]</ref> and Digital Database for Screening Mammography (DDSM) <ref type="bibr" target="#b110">[111]</ref>, outperforming in terms of accuracy and efficiency several stateof-the-art methods when tested on DDSM. Additional medical applications employing a deep learning architecture have been demonstrated in segmenting the left ventricle of the heart from the MR data <ref type="bibr" target="#b111">[112]</ref>, the pancreas through computed tomography (CT) <ref type="bibr" target="#b112">[113]</ref>, tibial cartilage through magnetic resonance imaging (MRI) <ref type="bibr" target="#b113">[114]</ref>, the prostate through MRI <ref type="bibr" target="#b114">[115]</ref>, and the hippocampus through MR brain images <ref type="bibr" target="#b115">[116,</ref><ref type="bibr" target="#b116">117]</ref>. The differentiation of tissues or organs in medical images has been termed semantic segmentation <ref type="bibr" target="#b117">[118,</ref><ref type="bibr" target="#b118">119]</ref> in which each pixel of an image is assigned to a class or a label. The skeletal muscles, organs, and fat in CT images are well delineated through semantic segmentation based on a DNN architecture <ref type="bibr" target="#b119">[120]</ref>. Similarly, the semantic segmentation of MR images also attained accurate segmentation results <ref type="bibr" target="#b120">[121]</ref><ref type="bibr" target="#b121">[122]</ref><ref type="bibr" target="#b122">[123]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical image classification and segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Machine</head><p>Detection of lesion and abnormality is the major issue in medical image analysis. Deep learning methods learn the representations directly instead of using hand-crafted features from training data. A classifier is then used to assign the representations to a probability that indicates whether or not the image contains lesions. In other words, the deep learning schemas classify each pixel to be a lesion point or not, which can be done in two ways: (1) classifying the mini patch around the pixel with a deep network, and (2) using a fully convolutional network to classify each pixel.</p><p>Debdoot et al. <ref type="bibr" target="#b123">[124]</ref> applied a DNN to histologically characterize healthy skin and healing wounds to reduce clinical reporting variability. Two unsupervised pre-trained layers of denoising AEs (DAEs) were used to learn features in their hybrid architecture, and subsequently the whole network was learned using labelled tissues for characterization. Detection of cerebral microbleeds <ref type="bibr" target="#b124">[125]</ref> and coronary artery calcification <ref type="bibr" target="#b125">[126]</ref> also produced better results when using deep learning-based approaches. In addition, brain tumor progression prediction implemented with a deep learning architecture <ref type="bibr" target="#b126">[127]</ref> has also shown a more robust tumor progression model in comparison with a high-precision manifold learning approach <ref type="bibr" target="#b127">[128]</ref>.</p><p>Detection of pathologies on stained histopathology images <ref type="bibr" target="#b128">[129]</ref><ref type="bibr" target="#b129">[130]</ref><ref type="bibr" target="#b130">[131]</ref>  Multinomial logistic regression or softmax regression was then used as a classifier in the supervised training. As a result, the performance of their approach was comparable with that of the subjective and expensive manual PMD and MT scorings.</p><p>Color fundus photography is an important diagnostic tool for ophthalmic diseases. Deep learning-based methods with fundus images have recently gained considerable interest as a key to developing automated diagnosis systems. A DNN architecture was proposed by Srivastava et al. <ref type="bibr" target="#b134">[135]</ref> to distinguish optic disc (OD) from parapapillary atrophy (PPA). A DNN consisting of SAEs followed by a refined active shape model attained accurate OD segmentation. For image registration, deep learning in combination with a multi-scale Hessian matrix <ref type="bibr" target="#b135">[136]</ref> was used to detect vessel landmarks in the retinal image, whereas convolutional neural networks have also produced excellent results in the detection of hemorrhages <ref type="bibr" target="#b136">[137]</ref> and exudates <ref type="bibr" target="#b137">[138]</ref>  In addition to static images, time-series medical records such as signal maps from electroencephalography and magnetoencephalography can also be analyzed using deep learning methods <ref type="bibr" target="#b139">[140,</ref><ref type="bibr" target="#b140">141]</ref>. These deep learning schemas take coded features of signals <ref type="bibr" target="#b141">[142,</ref><ref type="bibr" target="#b142">143]</ref> or raw signals <ref type="bibr" target="#b143">[144]</ref> as input, and extract features from the data for anomaly classification or understanding emotions.</p><p>All the aforementioned applications illustrate that as a frontier of machine learning, deep learning has made substantial progress in medical image segmentation and classification. We expect that more clinical trials and systematic medical image analytic applications will emerge to help achieve better performance when applying deep learning in medicine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Genomic sequencing and gene expression analysis</head><p>Deep learning also plays an important role in genomic sequencing and gene expression analyses.</p><p>To infer the expression profiles of target genes based on approximately 1000 landmark genes from the NIH Integrated Network-based Cellular Signatures (LINCS) program, Chen et al.</p><p>presented D-GEX, a deep learning method with dropout as regularization, which significantly outperformed linear regression (LR) in terms of prediction accuracy on both microarray and RNA-seq data <ref type="bibr" target="#b144">[145]</ref>. By applying a multimodal DBN to model structural binding preferences and to predict binding sites of RNA-binding proteins (RBPs) using the primary sequence as well as the secondary and tertiary structural profiles, Zhang et al. achieved an AUC of 0.98 for some proteins <ref type="bibr" target="#b145">[146]</ref>. To predict binding sites of DNA-and RNA-binding proteins, Alipanahi et al.</p><p>developed DeepBind, a CNN-based method, which surpassed other state-of-the-art methods, even when trained with in vitro data and tested with in vivo data <ref type="bibr" target="#b146">[147]</ref>. Subsequently, Lanchantin et al. <ref type="bibr" target="#b147">[148]</ref> and Zeng et al. <ref type="bibr" target="#b148">[149]</ref> also applied CNN to predict transcription factor binding sites (TFBSs), and both studies demonstrated an improvement over the performance of DeepBind (AUC of 0.894). The input of these deep CNNs is encoded sequence characters obtained through protein binding microarrays or other assays, and the output is a real value indicating whether the sequence is a binding site or not. The deeper model can make more accurate classification by extracting higher-level features from the raw nucleotide sequences <ref type="bibr" target="#b147">[148]</ref>. In addition, <ref type="bibr">Kelley et al. presented</ref> Basset, an open source package to apply deep CNNs to learn the chromatin accessibility code, enabling annotation and interpretation of the noncoding genome <ref type="bibr" target="#b149">[150]</ref>. Other applications include that of Li et al. <ref type="bibr" target="#b133">[134]</ref> and Liu et al. <ref type="bibr" target="#b150">[151,</ref><ref type="bibr" target="#b151">152]</ref>, who proposed deep learning approaches for the identification of cis-regulatory regions and replication timing domains, respectively. In addition, Yoon and his collaborators employed RNNs to predict miRNA precursors and targets. As a result, they achieved 25% increase in F-measure compared to existing alternative methods <ref type="bibr" target="#b152">[153,</ref><ref type="bibr" target="#b153">154]</ref>.</p><p>Genetic variation can influence the transcription of DNA and the translation of mRNA <ref type="bibr" target="#b154">[155]</ref>. Understanding the effects of sequence variants on pre-mRNA splicing facilitates not only whole genome annotation but also an understanding of genome function. To predict splice junction at the DNA level, Yoon and his collaborators developed a novel DBN-based method that was trained on the RBMs by boosting contrastive divergence with categorical gradients <ref type="bibr" target="#b155">[156]</ref>. Their method not only achieved better accuracy and robustness but also discovered subtle non-canonical splicing patterns <ref type="bibr" target="#b155">[156]</ref>. Furthermore, by exploiting RNNs to model and detect splice junctions from DNA sequences, the same authors also achieved a better performance than the previous DBN-based method <ref type="bibr" target="#b156">[157]</ref>.</p><p>Frey et al. formulated the assembly of a splicing code as a statistical inference problem <ref type="bibr" target="#b157">[158]</ref>, and proposed a Bayesian method to predict tissue-regulated splicing using RNA sequences and cellular context. Subsequently, they developed a DNN model with dropout to learn and predict alternative splicing (AS) <ref type="bibr" target="#b158">[159]</ref>. This model took both the genomic features and tissue context as inputs, and predicted splicing patterns in individual tissues and differences in splicing patterns across tissues. They showed that their method surpassed the previous Bayesian methods and other common machine learning algorithms, such as multinomial logistic regression (MLR) and SVMs, in terms of AS prediction. Furthermore, they built a computational model using a Bayesian deep learning algorithm to predict the effects of genetic variants on AS <ref type="bibr" target="#b159">[160]</ref>.</p><p>This model took DNA sequences alone as input without using disease annotations or population data, and then scored the effects that variants had on AS, providing valuable insights into the genetic determinants of spinal muscular atrophy, nonpolyposis colorectal cancer, and autism spectrum disorder.</p><p>To annotate the pathogenicity of genetic variants, Quang et al. developed a DNN algorithm named DANN, which outperforms logistic regression (LR) and SVMs, with the AUC metric increased by 14% over SVMs <ref type="bibr" target="#b160">[161]</ref>. Zhou et al. proposed a CNN-based algorithmic framework, DeepSEA, to predict the functional effects of noncoding variants de novo from sequences <ref type="bibr" target="#b161">[162]</ref>.</p><p>DeepSEA directly learns a regulatory sequence code from large-scale chromatin-profiling data, and can then predict the chromatin effects of sequence alterations with single-nucleotide sensitivity, and further prioritize functional variants based on the predicted chromatin effect signals. Subsequently, DanQ, a novel hybrid framework that combines CNN and bi-directional long short-term memory (BLSTM) RNNs, was presented to predict non-coding function de novo from sequences alone <ref type="bibr" target="#b162">[163]</ref>. DanQ achieved an AUC 50% higher than other models, including the aforementioned DeepSEA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction of protein structure</head><p>The 3D structure of proteins is determined by their comprising amino acid sequence <ref type="bibr" target="#b163">[164]</ref>.</p><p>However, the computational prediction of 3D protein structure from the 1D sequences remains challenging <ref type="bibr" target="#b164">[165]</ref>. The correct 3D structure of a protein is crucial to its function, and improper structures could lead to a wide range of diseases <ref type="bibr" target="#b165">[166]</ref><ref type="bibr" target="#b166">[167]</ref><ref type="bibr" target="#b167">[168]</ref>. Deep learning technologies have shown great capabilities in the area of protein structure prediction, which aims to predict the secondary structure or contact map of a protein.</p><p>Lyons et al. reported the first SAE for sequence-based prediction of backbone Cα angles and dihedrals <ref type="bibr" target="#b168">[169]</ref>. Heffernan et al. also employed SAEs to predict secondary structure, local backbone angles, and solvent-accessible surface area (ASA) of proteins from amino acid sequences <ref type="bibr" target="#b169">[170]</ref>; they achieved an accuracy of 82% for secondary structure prediction. Spencer et al. proposed DNSS, an ab initio approach to predicting the secondary structure of proteins using deep learning network architectures <ref type="bibr" target="#b170">[171]</ref>. DNSS was trained using a position-specific scoring matrix of the protein sequence and Atchley's factors of residues, and was optimized to accelerate the computation using the GPU and compute unified device architecture (CUDA).</p><p>Baldi and his colleagues successfully applied various RNN-based algorithms to predict protein secondary structure <ref type="bibr" target="#b171">[172]</ref><ref type="bibr" target="#b172">[173]</ref><ref type="bibr" target="#b173">[174]</ref> and protein contact map <ref type="bibr" target="#b174">[175]</ref><ref type="bibr" target="#b175">[176]</ref><ref type="bibr" target="#b176">[177]</ref>, with accuracies of 84% and 30%, respectively. Sønderby et al. used a bidirectional RNN (BRNN) with long short-term memory cells to improve the prediction of secondary structure, with better accuracy (0.671) than that using state of the art (0.664) <ref type="bibr" target="#b177">[178]</ref>. Compared with SAEs, DBNs, and RNNs, CNNs were seldom used for protein structure prediction until recently. Li et al. developed Malphite, a CNN and ensemble learning-based method for predicting protein secondary structures, which achieved an accuracy of 82.6% for a dataset containing 3000 proteins <ref type="bibr" target="#b178">[179]</ref>. Additionally, Lin et al.</p><p>proposed MUST-CNN, a multilayer shift-and-stitch convolutional neural network architecture to predict protein secondary structure from primary amino acid sequences <ref type="bibr" target="#b179">[180]</ref>. Besides classical deep learning architectures, some other architectures were also employed to predict protein secondary structure. For example, Lena et al. introduced a deep spatio-temporal learning architecture, achieved an accuracy roughly 10% higher than other methods <ref type="bibr" target="#b180">[181]</ref>, and Zhou et al.</p><p>presented a deep supervised and convolutional generative stochastic network, achieving an accuracy of 66.4% <ref type="bibr" target="#b181">[182]</ref>.</p><p>In addition to the secondary structure prediction, deep learning was also employed in protein region prediction <ref type="bibr" target="#b182">[183,</ref><ref type="bibr" target="#b183">184]</ref>. For instance, sequenced-based predictor of protein disorder using boosted ensembles of deep networks (DNdisorder), a deep neural network with multi-layers of RBMs <ref type="bibr" target="#b183">[184]</ref>, achieved an average balanced accuracy of 0.82 and an AUC of 0.90. Incorporated with predicted secondary structure and predicted ASA, a weighted deep convolutional neural fields (DeepCNF) was proposed to predict protein order/disorder regions, obtains an AUC of 0.898 on the Critical As-sessment of Techniques for Protein Structure Prediction (CASP10) dataset <ref type="bibr" target="#b182">[183]</ref>. All of these methods surpassed other state-of-the-art predictors in accuracy while still maintaining an extremely high computing speed. Recently, RaptorX-Property, a web server employing DeepCNF, was also presented to predict protein structure properties, including secondary structure, solvent accessibility, and disorder regions <ref type="bibr" target="#b184">[185]</ref>. RaptorX-Property can be easily used and offer good performance (an AUC of 0.89 on its test data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and perspective</head><p>Deep learning is moving toward its original goal: artificial intelligence.  <ref type="bibr" target="#b185">[186]</ref> as well as labeled data when stacked with a classifier <ref type="bibr" target="#b155">[156]</ref>. They can also deal with dynamic data <ref type="bibr" target="#b186">[187]</ref>. CNNs are most commonly used in the biomedical image analysis domain due to their outstanding capacity in analyzing spatial information. Although relatively few CNNs are used in sequencing data, CNNs have great potential in omics analysis <ref type="bibr" target="#b146">[147]</ref> and biomedical signals <ref type="bibr" target="#b141">[142]</ref>. On the other hand, RNN-based architectures are tailored for sequential data, and are most often used for sequencing data <ref type="bibr" target="#b153">[154,</ref><ref type="bibr" target="#b156">157]</ref> and in dynamic biomedical signals <ref type="bibr" target="#b143">[144]</ref>, but less frequently in static biomedical images. Currently, more and more attention is being paid to the usage of deep learning in biomedical information, and new applications of each schema may be discovered in the near future.  <ref type="bibr" target="#b187">[188,</ref><ref type="bibr" target="#b188">189]</ref> and provide higher accuracy in biomedical image analysis <ref type="bibr" target="#b189">[190]</ref>. On the other hand, crowdsourcing approaches have begun to pave the way in collecting annotations <ref type="bibr">[191,</ref><ref type="bibr">192]</ref>, which may be an important tool in the next few years. These bidirectional drivers would promote the applications of deep learning in biomedical informatics.     Tables <ref type="table">Table 1 Applications</ref>  </p><note type="other">Figure legends</note></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Optimization methodsA learning task is transformed to an optimization problem, to achieve the minima of the objective function by selecting appropriate hyperparameters. The basic processes of different optimization methods are similar. First, the output f f (x | 0 ) and the optimization objective of the model are computed using the initial parameters 0 . The network parameters  are then tuned to decrease the objective function value from the final layer to the first layer<ref type="bibr" target="#b17">[18]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>learning for medical images has long been a powerful tool in the diagnosis or assessment of diseases. Traditionally, discriminative features referring to medical image interpretation are manually designed for classification (detection of lesions or abnormalities) and segmentation of regions of interest (tissues and organs) in different medical applications. This requires the participation of physicians with expertise. Nonetheless, the complexity and ambiguity of medical images, limited knowledge for medical image interpretation, and the requirement of large amounts of annotated data have hindered the wide use of machine learning in the medical image domain. Notably, deep learning methods have attained success in a variety of computer vision tasks such as object recognition, localization, and segmentation in natural images. These have soon brought about an active field of machine learning in medical image analysis. Segmentation of tissues and organs is crucial for qualitative and quantitative assessment of medical images. Pereira et al. used data augmentation, small convolutional kernels, and a preprocessing stage to achieve accurate brain tumor segmentation [108]. Their CNN-based segmentation method won first place in the Brain Tumor Segmentation (BRATS) Challenge in 2013, and second place in 2015. Havaei et al. presented a fully automatic brain tumor segmentation method based on DNNs in magnetic resonance (MR) images with a two-phase</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Timeline of the development of deep learning and commonly-used machine learning algorithms The development of deep learning and neural networks is shown in the top panel, and several commonly-used machine learning algorithms are shown in the bottom panel.NN, neural network; BP, backpropagation; DBN, deep belief network; SVM, support vector machine；AE: auto-encoder; VAE: variational AE; GAN: generative adversarial network; WGAN: Wasserstein GAN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Illustration of convolutional neural networkA. In the convolution layer, fields (different color blocks in the table) of the input patch (represented by a) are multiplied by matrices (convolution kernel, represented by k). B. In the pooling layer, the results of convolution are summarized (the max pooling is taken as example here). a ij , c ij , k ij represent the number located in line i and column j in the corresponding matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3</head><label>3</label><figDesc>Figure 3 Illustration of recurrent neural network A. The unfold form of common neural networks (top) and schema (bottom). B. An illustration of recurrent neural networks (top) and their unfold form (bottom). The red square represents one time step delay. Different from panel A, the arrows in panel B represent sets of connections. W and B represent the weight matrix and bias vector, respectively. x and y represent the input and output of the network, respectively; h indicates the hidden units of network; L consists of couples of transformations, such as densely-connected layers or dropout layers; U indicates the transformation between two neighbor time points; and t represents the time point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4</head><label>4</label><figDesc>Figure 4 Popularity of deep learning frameworks in Github</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>of deep learning frameworks in biomedicalFigure 3</head><label>3</label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>The state-of-the-art feature extraction capacity of deep learning enables its application in a wide range of fields. Many deep learning frameworks are open source, including commonly-used frameworks like Torch, Caffe, Theano, MXNet, DMTK, and TensorFlow. Some of them are designed as highlevel wrappers for easy use, such as Keras, Lasagne, and Blocks. The applications of deep learning algorithms is further facilitated by the freely available sources. Figure 4 summarizes commonly-used frameworks in Github (https://github.com/) where the number of stars reflects the popularity of the frameworks.Breakthroughs in technologies, particularly next-generation sequencing, are producing a large quantity of genomic data. Efficient interpretation of these data has been attracting much attention in recent years. In this scenario, uncovering the relationship between genomic variants and diseases, and illustrating the regulatory process of genes in cells have been important research areas. In this review, we introduced the way deep learning gets involved in these areas using examples. With deep architecture, these models can simulate more complex transformations and discover hierarchical data representations. On the other hand, almost all of these models can be trained in parallel on GPUs for fast processing. Furthermore, deep learning can extract data-driven features and deal with high-dimensional data, while machine learning usually depends on hand-crafted features and is suitable only to low-dimensional data. Thus, deep learning is becoming more and more popular in genomic sequence analysis.</figDesc><table><row><cell>Deep learning is represented by a group of technologies (introduced in brief description of</cell></row><row><cell>deep learning), and has been widely used in biomedical data (introduced in applications in</cell></row><row><cell>biomedicine). SAEs and RBMs can extract patterns from unlabeled data</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Despite the notable advantages of deep learning, challenges in applying deep learning to the biomedical domain still remain. Take biomedical image analysis for instance: we use fundus images to exemplify how deep learning works to define the level of diabetic retinopathy, and to detect lesion areas in different ways. Besides high accuracy and speed, the intelligent of receptive fields also endows deep learning with overwhelming superiority in terms of image recognition. Furthermore, the development of end-to-end classification methods based on deep learning sheds new light on classifying pixels as lesioned or not. However, the usage of deep learning in medical images is still challenging. For model training, we need large amounts of data with labels, sometimes with labels in terms of pixel classification. Manually labeling these medical images is laborious and requires professional experts. On the other hand, medical images are highly associated with privacy, so collecting and protecting the data is demanding.</figDesc><table /><note><p><p><p>Furthermore, biomedical data are usually imbalanced because the quantity of data from normal classes is much larger than that from other classes.</p>In addition to the balancing challenges, the large amount of data required, and the labeling for biomedical data, deep learning also requires technological improvements. Unlike other images, subtle changes in medical images may indicate disease. Therefore, analyzing these images requires high-resolution inputs, high training speed, and a large memory. Additionally, it is difficult to find a uniform assessment metric for biomedical data classification or prediction.</p>Unlike other projects, we can tolerate false positives to some extent, and reject few or no false negatives in disease diagnosis. With different data, it is necessary to assess the model carefully and to tune the model according to characteristics of the data. Fortunately, the deeper networks with inception modules are accelerated</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>As a long-term goal, precision medicine research demands active learning from all biological, biomedical, as well as health data. Together with medical devices and instruments, wearable sensors and smart phones are providing unprecedented amounts of health data. Deep learning is a promising interpreter of these data, serving in disease prediction, prevention, diagnosis, prognosis, and therapy. We expect that more deep learning applications will be available in epidemic prediction, disease prevention, and clinical decision-making.[191] Irshad H, Oh EY, Schmolze D, Quintana LM, Collins L, Tamimi RM, et al. Crowdsourcing scoring of immunohistochemistry images: evaluating performance of the crowd and an automated computational method. arXiv160606681.[192] Albarqouni S, Baur C, Achilles F, Belagiannis V, Demirci S, Navab N. AggNet: Deep learning from crowds for mitosis detection in breast cancer histology images. IEEE Trans Med Imaging 2016;35:1313-21.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This was supported by the Center for Precision Medicine, Sun Yat-sen University and the National High-tech R&amp;D Program (863 Program; Grant No. 2015AA020110) of China awarded to YZ.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors have declared no competing interests.   Segmentation of pancreas in CT <ref type="bibr" target="#b112">[113]</ref> Knee cartilage segmentation <ref type="bibr" target="#b113">[114]</ref> Segmentation of hippocampus <ref type="bibr" target="#b116">[117]</ref> Predict semantic descriptions from medical images <ref type="bibr" target="#b117">[118]</ref> Segmentation of MR brain images <ref type="bibr" target="#b120">[121]</ref> Anatomy-specific classification of medical images <ref type="bibr" target="#b122">[123]</ref> Cerebral microbleeds from MR images <ref type="bibr" target="#b124">[125]</ref> Coronary artery calcium scoring in CT images <ref type="bibr" target="#b125">[126]</ref> Nuclei detection in routine colon cancer histology images <ref type="bibr" target="#b128">[129]</ref> Histopathological cancer classification <ref type="bibr" target="#b129">[130]</ref> Invasive ductal carcinoma segmentation in WSI <ref type="bibr" target="#b131">[132]</ref> Mammographic lesions detection <ref type="bibr" target="#b132">[133]</ref> Haemorrhages detection in fundus images <ref type="bibr" target="#b136">[137]</ref> Exudates detection in fundus images <ref type="bibr" target="#b137">[138]</ref> SAE Segmentation of hippocampus from infant brains <ref type="bibr" target="#b115">[116]</ref> Organ detection in 4D patient data <ref type="bibr" target="#b121">[122]</ref> Histological characterization healthy skin and healing wounds <ref type="bibr" target="#b123">[124]</ref> Scoring of percentage mammographic density and mammographic texture related to breast cancer risk <ref type="bibr" target="#b133">[134]</ref> Optic disc detection from fundus photograph <ref type="bibr" target="#b134">[135]</ref> DBN Segmentation of left ventricle of the heart from MR data <ref type="bibr" target="#b111">[112]</ref> Discriminate retinal-based diseases <ref type="bibr" target="#b138">[139]</ref> DNN Brain tumor segmentation in MR images, won 2 nd place in BRATS <ref type="bibr" target="#b108">[109]</ref> Prostate MR segmentation <ref type="bibr" target="#b114">[115]</ref> Gland instance segmentation <ref type="bibr" target="#b118">[119]</ref> Semantic segmentation of tissues in CT images <ref type="bibr" target="#b119">[120]</ref> Mitosis detection in breast cancer histological images <ref type="bibr" target="#b130">[131]</ref> Table <ref type="table">1</ref> RNN EEG-based prediction of epileptic seizures propagation using time-delayed NN <ref type="bibr" target="#b140">[141]</ref> Classification of patterns of EEG synchronization for seizure prediction <ref type="bibr" target="#b141">[142]</ref> EEG-based lapse detection <ref type="bibr" target="#b142">[143]</ref> Prediction of epileptic seizures <ref type="bibr" target="#b143">[144]</ref> Genomic sequencin g and gene expression analysis DNN Gene expression inference <ref type="bibr" target="#b144">[145]</ref> Identification of cis-regulatory regions and replication timing domains <ref type="bibr" target="#b150">[151]</ref> Prediction of enhancer <ref type="bibr" target="#b151">[152]</ref> Prediction of splicing patterns in individual tissues and differences in splicing patterns across tissues <ref type="bibr" target="#b158">[159]</ref> Annotation of the pathogenicity of genetic variants <ref type="bibr" target="#b160">[161]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TensorFlow Caffe</head><note type="other">MXNet</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DBN</head><p>Modeling structural binding preferences and predicting binding sites of RNA-binding proteins <ref type="bibr" target="#b145">[146]</ref> Prediction of splice junction at DNA level <ref type="bibr" target="#b155">[156]</ref> Prediction of transcription factor binding sites <ref type="bibr" target="#b147">[148,</ref><ref type="bibr" target="#b148">149]</ref> Annotation and interpretation of the noncoding genome <ref type="bibr" target="#b150">[151]</ref> Prediction of the noncoding variant effects de novo from sequence <ref type="bibr" target="#b161">[162]</ref> RNN Prediction of miRNA precursor and miRNA targets <ref type="bibr" target="#b152">[153,</ref><ref type="bibr" target="#b153">154]</ref> Detection of splice junctions from DNA sequences <ref type="bibr" target="#b156">[157]</ref> Prediction of non-coding function de novo from sequence <ref type="bibr" target="#b162">[163]</ref> Analysis of human splicing codes and their determination of diseases <ref type="bibr" target="#b160">[161]</ref> Protein structure prediction DBN Modeling structural binding preferences and predicting binding sites of RBPs <ref type="bibr" target="#b145">[146]</ref> Ab initio prediction of the protein secondary structures <ref type="bibr" target="#b170">[171]</ref> Prediction of protein disorder <ref type="bibr" target="#b183">[184]</ref> Prediction of secondary structures, local backbone angles, and solvent accessible surface area of proteins <ref type="bibr" target="#b169">[170]</ref> CNN Prediction of protein order/disorder regions <ref type="bibr" target="#b182">[183]</ref> Prediction of protein secondary structures <ref type="bibr" target="#b178">[179]</ref><ref type="bibr" target="#b179">[180]</ref><ref type="bibr" target="#b181">182]</ref> Prediction of protein structure properties, including secondary structure, solvent accessibility, and disorder regions <ref type="bibr" target="#b184">[185]</ref> SAE Sequence-based prediction of backbone Cα angles and dihedrals <ref type="bibr" target="#b168">[169]</ref> RNN Prediction of protein secondary structure <ref type="bibr" target="#b171">[172]</ref><ref type="bibr" target="#b172">[173]</ref><ref type="bibr" target="#b173">[174]</ref><ref type="bibr" target="#b177">178]</ref> Prediction of protein contact map <ref type="bibr" target="#b174">[175]</ref><ref type="bibr" target="#b175">[176]</ref><ref type="bibr" target="#b176">[177]</ref> Note: NN, neural networks; CNN, convolutional NN; SAE, stacked auto-encoder; DBN, deep belief network; RNN, recurrent NN.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning and its applications to signal and information processing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process Mag</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="145" to="154" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol Cybern</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computational intelligence in solving bioinformatics problems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Cios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mamitsuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nagashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tadeusiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Med</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A review of unsupervised feature learning and deep learning for timeseries modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Längkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit Lett</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="11" to="24" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Neural Inform Process Syst</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">ProtVec: a continuous distributed representation of biological sequences</title>
		<author>
			<persName><forename type="first">E</forename><surname>Asgari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mrk</forename><surname>Mofrad</surname></persName>
		</author>
		<idno>arXiv1503.05140v1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Receptive fields, binocular interaction and functional architecture in the cat&apos;s visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Physiol</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="106" to="154" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Receptive fields of single neurones in the cat&apos;s striate cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Physiol</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="574" to="591" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cresceptron: a self-organizing neural network which grows adaptively</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Int Jt Conf Neural Netw</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="576" to="581" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning recognition and segmentation of 3-D objects from 2-D images</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Conf Comput Vis</title>
		<imprint>
			<biblScope unit="page" from="121" to="128" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning recognition and segmentation using the cresceptron</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Comput Vis</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="109" to="143" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical models of object recognition in cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1019" to="1025" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Contributions to perceptron theory</title>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961">1961</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Applications of pattern recognition technology</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Viglione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics in science and engineering</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mendel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Fu</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier B. V</publisher>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="115" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Perceptrons. An introduction to computational geometry</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Papert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="780" to="782" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Beyond regression: new tools for prediction and analysis in the behavioral sciences</title>
		<author>
			<persName><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="65" to="78" />
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Applications of advances in nonlinear sensitivity analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">System modeling and optimization</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Drenick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Kozin</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="762" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Backwards differentiation in ad and neural nets: past links and new opportunities</title>
		<author>
			<persName><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic differentiation: applications, theory, and implementations</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Bücker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Corliss</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Naumann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Hovland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Norris</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="15" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Une procédure d&apos;apprentissage pour réseau à seuil asymétrique</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Cogn</title>
		<imprint>
			<biblScope unit="volume">1985</biblScope>
			<biblScope unit="page" from="599" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A theoretical framework for back-propagation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connect Model Summer Sch</title>
		<imprint>
			<biblScope unit="page" from="21" to="28" />
			<date type="published" when="1988">1988. 1988</date>
		</imprint>
	</monogr>
	<note>Proc</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A time-delay neural network architecture for isolated word recognition</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="23" to="43" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: an overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Parallel distributed processing: explorations in the microstructure of cognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><surname>Research</surname></persName>
		</author>
		<author>
			<persName><surname>Group</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="318" to="362" />
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive back-propagation in on-line learning of multilayer networks</title>
		<author>
			<persName><forename type="first">Ahl</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Saad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;95 Proc 8 th Int Conf Neural Inform Process Syst</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="323" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Accelerated backpropagation learning: two optimization methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="331" to="342" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Artificial neural networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>Piscataway</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An algorithm for least-squares estimation of nonlinear parameters</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Marquardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Soc Ind Appl Math</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="431" to="441" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Theoria motus corporum coelestium in sectionibus conicis solem ambientium</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Gauss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1809">1809</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A class of methods for solving nonlinear simultaneous equations</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Broyden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="577" to="593" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A rapidly convergent descent method for minimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mjd</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput J</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="163" to="168" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A family of variable-metric methods derived by variational means</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="23" to="26" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditioning of quasi-Newton methods for function minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Shanno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Exact calculation of the product of the hessian matrix of feed-forward network error functions and a vector in 0 (n) time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Møller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Daimi Rep</title>
		<imprint>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Methods of conjugate gradients for solving linear systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stiefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Res Nat Bur Stand</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="409" to="436" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Random decision forests</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 3rd Int Conf Doc Anal Recognit</title>
		<meeting>3rd Int Conf Doc Anal Recognit</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="278" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The random subspace method for constructing decision forest</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="832" to="844" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An introduction to kernel and nearest-neighbor nonparametric regression</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am Stat</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Practical variational inference for neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2348" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw Learn Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Flexible, high performance convolutional neural networks for image classification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI&apos;11 Proc 22 ed Int Joint Conf Artif Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1237" to="1242" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">A</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process Mag IEEE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep, big, simple neural nets for handwritten digit recognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="3207" to="3220" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Large-scale deep unsupervised learning using graphics processors. ICML&apos;09</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc 26 th Ann Int Conf Mach Learn</title>
		<imprint>
			<biblScope unit="page" from="873" to="880" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Boltzmann machine</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scholarpedia</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1668</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Now Pulishers Inc</publisher>
			<biblScope unit="page" from="1" to="127" />
			<pubPlace>Delft</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning multilevel distributed representations for high-dimensional sequences</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="548" to="555" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Application of deep belief networks for natural language understanding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deoras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans Audio Speech Lang Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="778" to="784" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Subject independent facial expression recognition with robust face detection using a convolutional neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Matsugu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mitari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kaneda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="555" to="559" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Traffic sign recognition with multi-scale convolutional networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="3809" to="3813" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Face recognition: a convolutional neural-network approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Back</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw Learn Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="98" to="113" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="3431" to="3440" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc IEEE Conf Comput Vis Pattern Recognit</title>
		<meeting>IEEE Conf Comput Vis Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A ;</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: deep neural networks with multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Proc Int Conf Mach Learn</title>
		<imprint>
			<biblScope unit="page" from="160" to="167" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Supervised sequence labelling with recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin; Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Modern practical deep networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep learning</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="162" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">LSTM recurrent networks learn simple context-free and context-sensitive languages</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1333" to="1340" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Offline handwriting recognition with multidimensional recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="545" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Modular learning in neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Conf AAAI Artif Intell</title>
		<meeting>Conf AAAI Artif Intell</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="279" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Neural Inf Process Syst</title>
		<imprint>
			<biblScope unit="page" from="153" to="160" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Efficient sparse coding algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Neural Inf Process Syst</title>
		<imprint>
			<biblScope unit="page" from="801" to="808" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Practical recommendations for gradient-based training of deep architectures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lect Notes Comput Sci</title>
		<imprint>
			<biblScope unit="volume">7700</biblScope>
			<biblScope unit="page" from="437" to="478" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The impact of transformation function on the classification ability of complex valued extreme learning machines</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kishore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Conf Control Comput Commun Mater</title>
		<imprint>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Phone recognition with deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Conf Acoust Speech Signal Process</title>
		<imprint>
			<biblScope unit="page" from="6985" to="6989" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 30 th Int Conf Mach Learn</title>
		<meeting>30 th Int Conf Mach Learn</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Rectified linear units improve restricted boltzmann machines. ICML&apos;10 Proc 27 th Int Conf Mach Learn</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Deep learning for medical image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<idno>arXiv150502000</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="315" to="323" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">What is the best multi-stage architecture for object recognition?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Conf Comput Vis</title>
		<imprint>
			<biblScope unit="page" from="2146" to="2153" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warde</forename><forename type="middle">-</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Maxout</forename><surname>Networks</surname></persName>
		</author>
		<idno>arXiv13024389</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Are loss functions all the same?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Vito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Caponnetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1063" to="1076" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Calculus: concepts and methods</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Binmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex optimization</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A new method of regularization parameter estimation for source localization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CIE Int Conf</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1804" to="1808" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Rank / norm regularization with closed-form solutions : application to subspace clustering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Assoc Uncertain Artif Intell</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A new approach to collaborative filtering: operator estimation with spectral regularization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Vert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="803" to="826" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Convex multi-task feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="243" to="272" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Joint covariate selection and joint subspace selection for multiple classification problems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="231" to="252" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Multi-organ localization with cascaded global-to-local regression and shape prior</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gauriau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cuingnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lesage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Anal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="70" to="83" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Stochastic gradient learning in neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Neuro Nımes</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Parallelized stochastic gradient descent</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zinkevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cki</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Culotta</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2595" to="2603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Products of experts</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICANN</title>
		<imprint>
			<biblScope unit="volume">1999</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Training products of experts by contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">On contrastive divergence learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira-Perpinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Artif Intell Stat</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">An analysis of noise in recurrent neural networks: convergence and generalization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Jim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Horne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1424" to="1438" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Principled hybrids of generative and discriminative models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lasserre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Minka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="87" to="94" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>arXiv12070580</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Dropout : a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poultney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hoffman</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Auto-association by multilayer perceptrons and singular value decomposition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol Cybern</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A practical guide to training restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: tricks of the Trade</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Orr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="599" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Deep belief networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Oxford Univ Press</publisher>
			<biblScope unit="page">5947</biblScope>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Multi-column deep neural networks for image classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Generalization of backpropagation with application to a recurrent gas market model</title>
		<author>
			<persName><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="339" to="356" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Learning state space trajectories in recurrent neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="263" to="269" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Gradient flow in recurrent nets: the difficulty of learning long-term dependencies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A field guide to dynamical recurrent neural networks</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kolen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kremer</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley-IEEE press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="237" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Applying genetic algorithms to recurrent neural networks for learning network parameters and architecture</title>
		<author>
			<persName><forename type="first">O</forename><surname>Syed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Case Western Reserve University Press</publisher>
			<pubPlace>Cleveland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Accelerated neural evolution through cooperatively coevolved synapses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="937" to="965" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Brain Tumor segmentation using convolutional neural networks in MRI images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1240" to="1251" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Brain tumor segmentation with deep neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warde</forename><forename type="middle">-</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Biard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Anal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="18" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">INbreast: Toward a full-field digital mammographic database</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Domingues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad Radiol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="236" to="248" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Detection and characterization of mammographic masses by artificial neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Health</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kopans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sallam</surname></persName>
		</author>
		<editor>Yaffe MJ</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="457" to="460" />
			<pubPlace>Berlin; Netherlands</pubPlace>
		</imprint>
	</monogr>
	<note>The digital database for screening mammography</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Anal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="159" to="171" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Deep convolutional networks for pancreas segmentation in CT imaging</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<idno>ArXiv1504.03967</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prasoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lauze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Comput Comput Assist Interv</title>
		<imprint>
			<biblScope unit="volume">8150</biblScope>
			<biblScope unit="page" from="246" to="253" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Representation learning: A unified deep learning framework for automatic prostate MR segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Comput Comput Assist Interv</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="254" to="261" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Segmenting hippocampus from infant brains by sparse patch matching with deep-learned features</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Commander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Szary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jewells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Comput Comput Assist Interv</title>
		<imprint>
			<biblScope unit="volume">8674</biblScope>
			<biblScope unit="page" from="308" to="315" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Unsupervised deep learning for hippocampus segmentation in 7.0 tesla MR images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D ;</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4 th international workshop on machine learning in medical imaging</title>
		<meeting>the 4 th international workshop on machine learning in medical imaging<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag New York Inc</publisher>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Predicting semantic descriptions from medical images with convolutional neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Vogl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer International Publishing AG</publisher>
			<biblScope unit="page" from="437" to="448" />
			<pubPlace>Basel</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">Gland instance segmentation by deep multichannel neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<idno>arXiv160704889</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">IODA: an input/output deep architecture for image labeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lerouge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chatelain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Modzelewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2847" to="2858" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Automatic segmentation of MR brain images with a convolutional neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moeskops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mendrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mjnl</forename><surname>Benders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Isgum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1252" to="1261" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Orton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1930" to="1943" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Anatomy-specific classification of medical images using deep convolutional nets</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hcc</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Symp Biomed Imaging</title>
		<imprint>
			<biblScope unit="page" from="101" to="104" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Deep learning of tissue specific speckle representations in optical coherence tomography and deeper exploration for in situ histology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sheet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spk</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katouzian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Symp Biomed Imaging</title>
		<imprint>
			<biblScope unit="page" from="777" to="780" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Automatic detection of cerebral microbleeds from MR images via 3D convolutional neural networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1182" to="1195" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Automatic coronary artery calcium scoring in cardiac CT angiography using paired convolutional neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolterink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>De Vos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Van Hamersvelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Išgum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Anal</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="123" to="136" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">A comparative study of two prediction models for brain tumor progression</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Process Algorithms Syst</title>
		<imprint>
			<biblScope unit="volume">9399</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">High-dimensional MRI data analysis using a large-scale manifold learning approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Vis Appl</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="995" to="1014" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sirinukunwattana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sea</forename><surname>Raza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drj</forename><surname>Snead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Cree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1196" to="1206" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Multiple clustered instance learning for histopathology cancer image classification, segmentation and clustering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><forename type="middle">E</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page" from="964" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Mitosis detection in breast cancer histology images with deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Comput Comput Assist Interv</title>
		<imprint>
			<biblScope unit="page" from="411" to="418" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basavanhally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganesan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digit Pathol</title>
		<imprint>
			<biblScope unit="volume">9041</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>Med Imaging</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Large scale deep learning for computer aided detection of mammographic lesions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gubern-Mérida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med Image Anal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="303" to="312" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kallenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1322" to="1331" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Using deep learning for robustness to parapapillary atrophy in optic disc segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dwk</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12 th Int Symp Biomed Imaging</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="768" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Retinal vessel landmark detection using deep learning and hessian matrix</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Int Symp Image Signal Process Anal</title>
		<meeting>Int Symp Image Signal ess Anal</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="387" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Fast convolutional neural network training using selective data sampling: application to hemorrhage detection in color fundus images</title>
		<author>
			<persName><forename type="first">Mjjp</forename><surname>Van Grinsven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Hoyng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Theelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1273" to="1284" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Detection of exudates in fundus photographs using convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Prentašić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lončarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Int Symp Image Signal Process Anal</title>
		<meeting>Int Symp Image Signal ess Anal</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="188" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Multi-retinal disease classification by reduced deep learning features</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arunkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Karthigaikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput Appl</title>
		<imprint>
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuzniecky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int Workshop Mach Learn Signal Process</title>
		<imprint>
			<biblScope unit="page" from="244" to="249" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Time-delay neural networks and independent component analysis for Eeg-Based prediction of epileptic seizures propagation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Conf AAAI Artif Intell</title>
		<meeting>Conf AAAI Artif Intell</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1892" to="1893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Classification of patterns of EEG synchronization for seizure prediction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuzniecky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="1927" to="1940" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">EEG-based lapse detection with high temporal resolution</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mtr</forename><surname>Peiris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="832" to="839" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Recurrent neural network based prediction of epileptic seizures in intra-and extracranial EEG</title>
		<author>
			<persName><forename type="first">A</forename><surname>Petrosian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Homan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dasheiff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="201" to="218" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Gene expression inference with deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinfarmatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1832" to="1839" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">A deep learning framework for modeling structural features of RNA-binding protein targets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="page" from="44" to="e76" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Predicting the sequence specificities of DNA-and RNAbinding proteins by deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Weirauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Biotechnol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">Deep Motif: visualizing genomic sequence classifications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<idno>arXiv160501133</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for predicting DNAprotein binding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Gifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="121" to="127" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Rinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="990" to="999" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">De novo identification of replication-timing domains in the human genome by deep learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="641" to="649" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">PEDLA: predicting enhancers with a deep learning-based algorithmic framework</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Seq</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">28517</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">deepMiRGene: deep neural network based precursor microrna prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<idno>arXiv1605.00017</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">deepTarget: end-to-end learning framework for microRNA target prediction using deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<idno>arXiv1603.09123</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Prescribing splicing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Valcarcel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="page" from="124" to="125" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Boosted categorical restricted boltzmann machine for computational prediction of splice junctions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Int Conf Mach Learn</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">DNA-level splice junction prediction using deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<idno>arXiv1512.05135</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Bayesian prediction of tissue-regulated splicing using RNA sequence and cellular context</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Barash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2554" to="2562" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Deep learning of the tissue-regulated splicing code</title>
		<author>
			<persName><forename type="first">Mkk</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="121" to="129" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">The human splicing code reveals new insights into the genetic determinants of disease</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bretschneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Merico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rkc</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="page">1254806</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">DANN: A deep learning approach for annotating the pathogenicity of genetic variants</title>
		<author>
			<persName><forename type="first">D</forename><surname>Quang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="761" to="763" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Predicting effects of noncoding variants with deep learning-based sequence model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">G</forename><surname>Troyanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="931" to="934" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Quang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">The formation and stabilization of protein structure</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Anfinsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochem J</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="737" to="749" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Minimization of polypeptide energy. I. Preliminary structures of bovine pancreatic ribonuclease S-peptide</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Scheraga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci U S A</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="420" to="427" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Prevention of transthyretin amyloid disease by changing protein misfolding energetics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hammarstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page" from="713" to="716" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Protein misfolding, functional amyloid, and human disease</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Dobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Biochem</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="333" to="366" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Folding proteins in fatal ways</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Selkoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">426</biblScope>
			<biblScope unit="page" from="900" to="904" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Predicting backbone Cα angles and dihedrals from protein sequences by stacked sparse auto-encoder deep neural network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sattar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Chem</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2040" to="2046" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Improving prediction of secondary structure, local backbone angles, and solvent accessible surface area of proteins by iterative deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11476</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">A deep learning network approach to ab initio protein secondary structure prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Spencer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eickholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans Comput Biol Bioinform</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="103" to="112" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Matching protein beta-sheet partners by feedforward and recurrent neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caf</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brunak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Int Conf Intell Syst Mol Biol</title>
		<imprint>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Exploiting the past and the future in protein secondary structure prediction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="937" to="946" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Improving the prediction of protein secondary structure in three and eight classes using recurrent neural networks and profiles</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Przybylski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="228" to="235" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Prediction of contact maps by GIOHMMs and recurrent neural networks using lateral propagation from all four cardinal corners</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">The principled design of large-scale recursive neural network architectures-DAG-RNNs and the protein structure prediction problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pollastri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="575" to="602" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Deep architectures for protein contact map prediction</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Lena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2449" to="2457" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Protein secondary structure prediction with long short term memory networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno>arXiv1412.7828</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Malphite: a convolutional neural network and ensemble learning based protein secondary structure predictor</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shibuya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Conf Bioinformatics Biomed</title>
		<imprint>
			<biblScope unit="page" from="1260" to="1266" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">MUST-CNN: a multilayer shift-and-stitch deep convolutional architecture for sequence-based protein structure prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Conf AAAI Artif Intell</title>
		<meeting>Conf AAAI Artif Intell</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal architectures and learning for protein structure prediction</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Lena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Neural Inf Process Syst</title>
		<imprint>
			<biblScope unit="page" from="512" to="520" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Deep supervised and convolutional generative stochastic network for protein secondary structure prediction</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">G</forename><surname>Troyanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc 31 st Int Conf Mach Learn</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="745" to="753" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">DeepCNF-D: predicting protein order/disorder regions by weighted deep convolutional neural fields</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Mol Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="17315" to="17330" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">DNdisorder: predicting protein disorder using boosting and deep networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eickholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">88</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">RaptorX-Property: a web server for protein structure property prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Autoencoder in time-series analysis for unsupervised tissues characterisation in a large unlabelled medical image dataset</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Orton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Int Conf Mach Learn Appl</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="259" to="264" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">A novel semi-supervised deep learning framework for affective state recognition on EEG signals</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Int Symp Bioinformatics Bioeng</title>
		<imprint>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="171" to="180" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<monogr>
		<title level="m" type="main">Inception-v4, InceptionResNet and the impact of residual connections on learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<idno>arXiv1602.07261</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">MitosisNet: a deep learning network for mitosis detection in breast cancer histopathology images</title>
		<author>
			<persName><forename type="first">Dvk</forename><surname>Yarlagadda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE EMBS Int Conf Biomed Health Inform</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
