<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Automatic Control and Sys-tems Engineering</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<settlement>Sheffield</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CD69DDBD64210C18FCA88E160351DDA5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiobjective Optimization and Multiple</head><p>Constraint Handling with Evolutionary Algorithms-Part I: A Unified Formulation Carlos M. Fonseca, Member, IEEE, and Peter J. Fleming Abstract-In optimization, multiple objectives and constraints cannot be handled independently of the underlying optimizer. Requirements such as continuity and differentiability of the cost surface add yet another conflicting element to the decision process. While "better" solutions should be rated higher than "worse" ones, the resulting cost landscape must also comply with such requirements. Evolutionary algorithms (EA's), which have found application in many areas not amenable to optimization by other methods, possess many characteristics desirable in a multiobjective optimizer, most notably the concerted handling of multiple candidate solutions. However, EA's are essentially unconstrained search techniques which require the assignment of a scalar measure of quality, or fitness, to such candidate solutions. After reviewing current evolutionary approaches to multiobjective and constrained optimization, the paper proposes that fitness assignment be interpreted as, or at least related to, a multicriterion decision process. A suitable decision making framework based on goals and priorities is subsequently formulated in terms of a relational operator, characterized, and shown to encompass a number of simpler decision strategies. Finally, the ranking of an arbitrary number of candidates is considered. The effect of preference changes on the cost surface seen by an EA is illustrated graphically for a simple problem. The paper concludes with the formulation of a multiobjective genetic algorithm based on the proposed decision strategy. Niche formation techniques are used to promote diversity among preferable candidates, and progressive articulation of preferences is shown to be possible as long as the genetic algorithm can recover from abrupt changes in the cost landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>C ONSTRAINT satisfaction and multiobjective optimiza- tion are very much two aspects of the same problem. Both involve the simultaneous optimization of a number of functions. Constraints can often be seen as hard objectives, which need to be satisfied before the optimization of the remaining, soft, objectives takes place. Conversely, problems characterized by a number of soft objectives are often reformulated as constrained optimization problems in order to be solved.</p><p>Despite having been successfully used to approach many ill-behaved problems, the first formulations of evolutionary algorithms were essentially single-function methods with little scope for constraint handling. Following the success of the evolutionary approach, interest in how both constraints and multiple objectives can be handled by evolutionary algorithms has rapidly increased.</p><p>Multiobjective and constrained optimization are introduced here separately, first in general terms, and then in the context of evolutionary algorithms. Current practices are then presented and discussed.</p><p>The formulation and characterization of a unified decision making framework for multifunction optimization follows, encompassing both objectives and constraints. Finally, a multiobjective genetic algorithm is described, and presented as a method which can be used for progressive articulation of preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MULTIOBJECTIVE OPTIMIZATION</head><p>Practical problems are often characterized by several noncommensurable and often competing measures of performance, or objectives. The multiobjective optimization problem is, without loss of generality, the problem of simultaneously minimizing the components of a possibly nonlinear vector function of a general decision variable in a universe where</p><p>The problem usually has no unique, perfect solution, but a set of nondominated, alternative solutions, known as the Pareto-optimal set <ref type="bibr" target="#b0">[1]</ref>. Still assuming a minimization problem, dominance is defined as follows. Pareto-optimal solutions are also called efficient, nondominated, and noninferior solutions. The corresponding objective vectors are simply called nondominated. The set of all nondominated vectors is known as the nondominated set, or the tradeoff surface, of the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiobjective Optimization and Decision Making</head><p>The notion of Pareto-optimality is only a first step toward solving a multiobjective problem. In order to select a suitable compromise solution from all noninferior alternatives, a decision process is also necessary.</p><p>Depending on how the computation and the decision processes are combined in the search for compromise solutions, three broad classes of multiobjective methods can be identified <ref type="bibr" target="#b1">[2]</ref>:</p><p>A priori articulation of preferences: The decision maker expresses preferences in terms of an aggregating function which combines individual objective values into a single utility value, and ultimately makes the problem single-objective, prior to optimization.</p><p>A posteriori articulation of preferences: The decision maker is presented by the optimizer with a set of candidate noninferior solutions, before expressing any preferences. The compromise solution is chosen from that set.</p><p>Progressive articulation of preferences: Decision making and optimization occur at interleaved steps. At each step, partial preference information is supplied by the decision maker to the optimizer, which, in turn, generates better alternatives according to the information received.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Preference Articulation</head><p>Independently of the stage at which it takes place, preference articulation implicitly defines a so-called utility function which discriminates between candidate solutions. Although such a utility function can be very difficult to formalize in every detail, approaches based on the following have been widely used:</p><p>Weighting coefficients are real values which express the relative importance of the objectives and control their involvement in the overall utility measure. The weighted-sum approach is the classical example of a method based on objective weighting <ref type="bibr" target="#b1">[2]</ref>.</p><p>Priorities are integer values which determine in which order objectives are to be optimized, according to their importance. The lexicographic method <ref type="bibr" target="#b0">[1]</ref>, for example, requires all objectives to be assigned different priorities.</p><p>Goal values indicate desired levels of performance in each objective dimension. The way in which goals are interpreted may vary. In particular, they may represent minimum levels of performance to be attained, Utopian performance levels to be approximated, or ideal performance levels to be matched as closely as possible <ref type="bibr" target="#b2">[3]</ref>. Goals are usually easier to set than weights and priorities, because they relate more closely to the final solution of the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CONSTRAINED OPTIMIZATION</head><p>The solution of a practical problem may be constrained by a number of restrictions imposed on the decision variable. Constraints may express the domain of definition of the objective function or, alternatively, impose further restrictions on the solution of the problem according to knowledge at a higher level.</p><p>Constraints can usually be expressed in terms of function inequalities of the type where is a real-valued function of a variable , and is again a constant value. The inequality may also be strict instead of . Equality constraints of the type can be formulated as particular cases of inequality constraints.</p><p>Without loss of generality, the constrained optimization problem is that of minimizing a multiobjective function of some generic decision variable in a universe , subject to a positive number of conditions involving and eventually expressed as a functional vector inequality of the type where the inequality applies component-wise. It is implicitly assumed that there is at least one point in which satisfies all constraints, although in practice that cannot always be guaranteed. When constraints cannot be all simultaneously satisfied, the problem is often deemed to admit no solution as it stands. The number of constraints violated, and the extent to which each constraint is violated, are then taken into account in order to possibly relax some of the constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Constraint Satisfaction as a Multiobjective Problem</head><p>Constraints can be seen as high-priority (or hard) objectives, which must be jointly satisfied before the optimization of the remaining, soft objectives takes place. Satisfying a number of violated inequality constraints is clearly the multiobjective problem of minimizing the associated functions until given values (goals) are reached. The concept of noninferiority is, therefore, readily applicable, and even particularly appropriate when constraints are themselves noncommensurable. When not all goals can be simultaneously met, a family of violating, noninferior points is the closest to a solution for the problem.</p><p>Goal-based multiobjective optimization extends simple constraint satisfaction in the sense that the optimization continues even after all goals are met. In this case, solutions should both be noninferior and meet all goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EVOLUTIONARY APPROACHES TO MULTI-FUNCTION OPTIMIZATION</head><p>The term evolutionary algorithms (EA's) is used to refer to a number of search and optimization algorithms inspired by the process of natural evolution. Current evolutionary approaches include evolutionary programming (EP) <ref type="bibr" target="#b3">[4]</ref>, evolution strategies (ES's) <ref type="bibr" target="#b4">[5]</ref>, genetic algorithms (GA's) <ref type="bibr" target="#b5">[6]</ref>, and genetic programming (GP) <ref type="bibr" target="#b6">[7]</ref>. A comparative study of the first three approaches can be found in <ref type="bibr" target="#b7">[8]</ref>.</p><p>Evolutionary algorithms maintain a population of candidate solutions (the individuals) for a given problem. Individuals are evaluated and assigned fitness values based on their relative performance. They are then given a chance to reproduce, i.e., replicate themselves a number of times proportional to their fitness. The offspring produced are modified by means of mutation and/or recombination operators before they are evaluated, and subsequently reinserted in the population. Several reinsertion strategies exist, ranging from the unconditional replacement of the parents by the offspring to approaches where offspring replace the worst parents, their own parents or even the oldest parents.</p><p>The multiple performance measures provided by constrained and multiobjective problems must be converted into a scalar fitness measure before EA's can be applied. So far, constrained optimization has been considered separately from multiobjective objective optimization in EA literature, and, for that reason, the two are reviewed separately here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Constraint Handling</head><p>The simplest approach to handling constraints in EA's has been to assign infeasible individuals an arbitrarily low fitness <ref type="bibr">[6, p. 85]</ref>. In this approach, provided feasible solutions can be easily found, any infeasible individuals are selected out and the search is not affected much.</p><p>Certain types of constraints, however, such as bounds on the decision variables and other linear constraints, can be handled by mapping the search space so as to minimize the number of infeasible solutions it contains and/or designing the mutation and recombination operators carefully in order to minimize the production of infeasible offspring from feasible parents <ref type="bibr" target="#b8">[9]</ref>. This and the previous approach are complementary and often used in combination with each other.</p><p>In the case where no feasible individuals are known, and cannot easily be found, the penalty imposed onto infeasible individuals can be made to depend on the extent to which they violate the constraints. Such penalty values are typically added to the (unconstrained) performance value before fitness is computed <ref type="bibr">[6, p. 85f</ref>]. Although penalty functions do provide a way of guiding the search toward feasible solutions when these are not known, they are very much problem dependent. Guidelines on the use of penalty functions have been described by Richardson et al. <ref type="bibr" target="#b9">[10]</ref>.</p><p>A fourth approach to constraint handling has been proposed by Powell and Skolnick <ref type="bibr" target="#b10">[11]</ref> and consists of rescaling the original objective function to assume values less than unity in the feasible region, whilst assigning infeasible individuals penalty values greater than one. Subsequent ranking of the population correctly assigns higher fitness to all feasible points than to those infeasible. This perspective is supported and extended in the present work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multiple Objectives</head><p>In problems where no global criterion directly emerges from the original multiobjective formulation, objectives are often artificially combined by means of an aggregating function. Many such approaches, although initially developed to be used with other optimizers, can also be used with EA's.</p><p>Optimizing a combination of the objectives has the advantage of producing a single compromise solution, requiring no further interaction with the decision maker. However, if the solution found cannot be accepted as a good compromise, tuning of the aggregating function may be required, followed by new runs of the optimizer, until a suitable solution is found. As a workaround, of the many candidate solutions evaluated in a single run of the EA, those nondominated solutions may provide valuable alternatives <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. However, since the algorithm sees such alternatives as suboptimal, they cannot be expected to be optimal in any sense.</p><p>Aggregating functions have been widely used with EA's, from the simple weighted sum approach, e.g., <ref type="bibr" target="#b13">[14]</ref>, to target vector optimization <ref type="bibr" target="#b14">[15]</ref>. An implementation of goal attainment, among other methods, was used by Wilson and Macleod <ref type="bibr" target="#b11">[12]</ref>.</p><p>1) Non-Pareto Approaches: Treating objectives separately was first proposed by Schaffer <ref type="bibr" target="#b15">[16]</ref>, as a move toward finding multiple nondominated solutions with a single algorithm run. In his approach, known as the Vector Evaluated Genetic Algorithm (VEGA), each objective was used in turn to select a separate fraction of the next generation. These subpopulations were then merged, and crossover and mutation were applied as usual. The population was monitored for nondominated individuals as it evolved.</p><p>Other approaches which exploit EA populations in order to search for multiple nondominated solutions concurrently include those of Fourman <ref type="bibr" target="#b16">[17]</ref>, Kursawe <ref type="bibr" target="#b17">[18]</ref>, and Hajela and Lin <ref type="bibr" target="#b18">[19]</ref>. However, as none of them makes direct use of the actual definition of Pareto-optimality, different nondominated individuals are generally assigned different fitness values. VEGA, for example, can be shown to perform an implicit weighted-sum of the objectives <ref type="bibr" target="#b9">[10]</ref>, and may lead to the population splitting into species particularly strong in each of the objectives in the case of concave tradeoff surfaces. A detailed discussion of these and other evolutionary approaches to multiobjective optimization can be found in <ref type="bibr" target="#b19">[20]</ref>.</p><p>2) Pareto-Based Approaches: Another class of approaches, based on ranking according to the actual concept of Pareto optimality, was proposed later by <ref type="bibr">Goldberg [6,</ref><ref type="bibr">p. 201</ref>], guaranteeing equal probability of reproduction to all nondominated individuals. Problems with nonconvex tradeoff surfaces, which present difficulties to pure weighted-sum approaches, do not raise any special issues in Pareto optimization <ref type="bibr" target="#b19">[20]</ref>.</p><p>This paper elaborates on Pareto-based ranking by combining dominance with preference information to produce a suitable fitness assignment strategy. The evolutionary optimization process is seen as the result of the interaction between an artificial selector, here referred to as the decision maker (DM), and an evolutionary search process. The search process generates a new set of candidate solutions according to the utility assigned by the DM to the current set of candidates.</p><p>Whilst the action of the DM influences the production of new individuals, these, as they are evaluated, provide new tradeoff information which the DM can use to refine its current preferences. The EA sees the effect of any changes in the decision process, which may or may not result from taking recently acquired information into account, as an environmental change. This general view of multiobjective evolutionary optimization has been proposed by the authors in earlier work <ref type="bibr" target="#b20">[21]</ref> and is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. The DM block represents any utility assignment strategy, which may range from an intelligent decision maker to a simple weighted sum approach.</p><p>The EA block is concerned with a different, but complementary, aspect of the optimization, the search process. Evolutionary algorithms, in the first instance, make very few assumptions about the fitness landscape they work on, which justifies and permits a primary concern with fitness assignment. However, EA's are not capable of optimizing arbitrary functions <ref type="bibr" target="#b21">[22]</ref>. Some form of characterization of the multiobjective fitness landscapes associated with the decision making strategy used is, therefore, important, and the design of the EA should take that information into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. MULTIOBJECTIVE DECISION MAKING BASED ON GIVEN GOALS AND PRIORITIES</head><p>The specification of goals and priorities can accommodate a whole variety of constrained and/or multiobjective problem formulations. Goal and priority information is often naturally available from the problem formulation, although not necessarily in a strict sense. Therefore, the interpretation of such information should take its partial character into account. This can be accomplished by allowing different objectives to be given the same priority, and by avoiding using measures of the distance to the goals, which inevitably depend on the scale in which the objective values are presented.</p><p>An extension of the decision making strategy proposed by the authors in <ref type="bibr" target="#b20">[21]</ref> is formulated here in terms of a relational operator, which incorporates the preference information given, and characterized. The ranking of a whole population based on such a relation is then described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Comparison Operator</head><p>Consider an -dimensional vector function of some decision variable and two -dimensional objective vectors and where and are particular values of Consider also the -dimensional preference vector where is a positive integer (see below), for , and Similarly, may be written as and the same for and .</p><p>The subvectors of the preference vector , where , associate priorities and goals , where , to the corresponding objective functions , components of . This assumes a convenient permutation of the components of , without loss of generality. Greater values of , up to and including , indicate higher priorities. Generally, each subvector will be such that a number of its components meet their goals while the remaining do not. Also without loss of generality, is such that, for , one can write For simplicity, the first components of vectors and will be represented as and , respectively. The last components of the same vectors will be denoted and also respectively. The smile and the frown , respectively, indicate the components in which either does or does not meet the goals.</p><p>Definition 3 (Preferability): Vector is preferable to given a preference vector iff and where and similarly for and In simple terms, vectors and are compared first in terms of their components with the highest priority, that is, those where , disregarding those in which meets the corresponding goals, . In case both vectors meet all goals with this priority, or if they violate some or all of them, but in exactly the same way, the next priority level is considered. The process continues until priority 1 is reached and satisfied, in which case the result is decided by comparing the priority 1 components of the two vectors in a Pareto fashion.</p><p>Since satisfied high-priority objectives are left out from comparison, vectors which are equal to each other in all but these components express virtually no tradeoff information given the corresponding preferences. The following symmetric relation is defined.</p><p>Definition 4 (Equivalence): Vector is equivalent to given a preference vector iff</p><p>The concept of preferability can be related to that of inferiority as follows.</p><p>Lemma 1: For any two objective vectors and if then is either preferable or equivalent to given any preference vector</p><p>The proofs of this lemma and of the following one are given in the Appendix.</p><p>Lemma 2 (Transitivity): The preferability relation is transitive, i.e., given any three objective vectors and and a preference vector 1) Particular Cases: The decision strategy described above encompasses a number of simpler multiobjective decision strategies, which correspond to particular settings of the preference vector.</p><p>Pareto (Definition 1): All objectives have equal priority and no goal levels are given.</p><p>Lexicographic <ref type="bibr" target="#b0">[1]</ref>: Objectives are all assigned different priorities and no goal levels are given.</p><p>Constrained Optimization (Section III): The functional parts of a number of inequality constraints are handled as high priority objectives to be minimized until the corresponding constant parts, the goals, are reached. Objective functions are assigned the lowest priority.</p><p>. Constraint Satisfaction (or Method of Inequalities <ref type="bibr" target="#b22">[23]</ref>): All constraints are treated as in constrained optimization, but there is no low priority objective to be optimized.</p><p>Goal Programming: Several interpretations of goal programming can be implemented. A simple formulation, described in <ref type="bibr" target="#b1">[2]</ref>, consists of attempting to meet the goals sequentially, in a similar way to lexicographic optimization.</p><p>A second formulation attempts to meet all the goals simultaneously, as with constraint satisfaction, but requires solutions to be satisfactory and Pareto optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Population Ranking</head><p>As opposed to the single objective case, the ranking of a population in the multiobjective case is not unique. In the present case, it is desired that all preferred individuals be assigned the same rank, and that individuals be placed higher in the rank than those they are preferable to.</p><p>Consider an individual at generation with corresponding objective vector and let be the number of individuals in the current population which are preferable to it. The current position of in the individuals' rank can be given simply by which ensures that all preferred individuals in the current population are assigned rank zero.</p><p>In the case of a large and uniformly distributed population with individuals, the normalized rank constitutes an estimate of the fraction of the search space preferable to each individual considered. Such a fraction indicates how easily the current solution can be improved by pure random search and, as a measure of individual cost, does not depend on how the objectives are scaled. This interpretation of ranking, also valid when there is only one objective, provides a way of characterizing the cost landscape associated with the preferences of the DM. It is not applicable to the ranking approach proposed by Goldberg <ref type="bibr">[6, p. 201</ref>].</p><p>In the general case of a nonuniformly distributed population, a biased estimate is obtained which, nevertheless, preserves the strict order relationships between individuals, as desired.</p><p>Lemma 3: If an objective vector associated with an individual is preferable to another vector associated with an individual in the same arbitrary population, then Equivalently, if then is not preferable to The proof follows from the transitivity of the preferability relation (Lemma 2).</p><p>Fig. <ref type="figure">2</ref> illustrates the ranking of the same population for two different preference vectors. In the first case, both objectives are given the same priority. Note that all satisficing individuals (the ones which meet their goals) are preferable to, and therefore have lower rank than, all of the remaining ones. In the second case, objective 2 is given a higher priority, reflecting, for example, a feasibility constraint. In this case, individuals which do not meet goal are the worst (they are infeasible), independently of their "theoretical" performance according to . Once is met, is used for ranking. Individuals which meet both goals are satisficing solutions, whereas those which meet only are feasible, but unsatisfactory. Note how particular ranks need not be represented in the population at each particular generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Characterization of Multiobjective Cost Landscapes</head><p>The cost landscape associated with a problem involving multiple objectives depends not only on the objectives themselves, but also on the preferences expressed by the DM. Their effect can be more easily understood by means of an example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consider the simple biobjective problem of simultaneously minimizing</head><p>As suggested in the previous subsection, the cost landscape associated with a given set of preferences can be inferred from the ranking of a large, uniformly distributed population. Since the problem involves only two decision variables, this cost landscape can be visualized.</p><p>Pareto-ranking assigns the same cost to all nondominated individuals, producing a long flat inverted ridge, as is shown in Fig. <ref type="figure">3</ref>. If achievable goals are specified, a discontinuity arises where solutions go from satisficing to unsatisfactory (Fig. <ref type="figure" target="#fig_2">4</ref>). A ridge, though shorter than in the previous case, is produced by those satisfactory solutions which are also nondominated.</p><p>Giving one objective priority over the other considerably alters the landscape. In this case, the discontinuity corresponds to the transition from feasible to infeasible, and it happens to occur in the neighborhood of the optimum (Fig. <ref type="figure" target="#fig_3">5</ref>). Finally, if both objectives are made into hard constraints, the feasible   region becomes totally flat (Fig. <ref type="figure" target="#fig_4">6</ref>). This is because, in the absence of any other objectives, all solutions which satisfy both constraints must be considered equivalent.</p><p>Despite the underlying objectives being continuous, smooth and unimodal, the landscapes can be seen to exhibit features such as discontinuities, nonsmoothness and flat regions. Optimizers capable of coping with such features are necessary for the decision making approach proposed to become useful, and EA-based optimizers are certainly eligible candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. MULTI-OBJECTIVE GENETIC ALGORITHMS</head><p>The ranking of a population provides sufficient relative quality information to guide evolution. Given the current population ranking, different EA's will proceed with different selection and reproduction schemes, to produce a new set of individuals to be assessed. This section will be concerned with the formulation of a multiobjective genetic algorithm (MOGA), based on the ranking approach described earlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Fitness Assignment</head><p>Fitness is understood here as the number of offspring an individual is expected to produce through selection. It differs from individual utility, which reflects the result of the decision making process. The selection process determines which individuals actually influence the production of the next generation and is, therefore, a part of the search strategy.</p><p>The traditional rank-based fitness assignment is only slightly modified, as follows:</p><p>1) sort population according to rank; 2) assign fitness by interpolating from the best individual to the worst according to some function, usually linear or exponential, but possibly of other type; 3) average the fitness assigned to individuals with the same rank, so that all of them are sampled at the same rate while keeping the global population fitness constant. Rank-based fitness assignment, as described, transforms the cost landscape defined by the ranks into a fitness landscape which is also independent from objective scaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Niche Induction Methods</head><p>In multimodal fitness landscapes, local optima offer the GA more than one opportunity for evolution. Although populations are potentially able to search many local optima, a finite population tends to settle on a single "good" optimum, even if other equivalent optima exist. This phenomenon is known as genetic drift, and has been well observed in natural, as well as artificial, evolution.</p><p>In the present case, where all nondominated/preferred points are considered equally fit, genetic drift may cause the population of a GA to converge only to a small region of the tradeoff surface, unless specific measures are taken against it <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b20">[21]</ref>.</p><p>Niche induction methods <ref type="bibr" target="#b23">[24]</ref> promote the simultaneous sampling of several different optima by favoring diversity in the population. Individuals tend to distribute themselves around the best optima, forming what is known as niches.</p><p>1) Fitness Sharing: Fitness sharing <ref type="bibr" target="#b24">[25]</ref> models individual competition for finite resources in a closed environment. Individuals similar to one another (according to some measure of similarity) mutually decrease each other's fitness by competing for the same resources. Even if initially considered less fit, isolated individuals are thus given a greater chance of reproducing, favoring diversification.</p><p>Finding a good tradeoff description means achieving a diverse sampling of the tradeoff surface in objective function space. In the sharing scheme proposed here, niche counts are computed based on individual distance in the objective domain, but only between individuals with the same rank. Sharing works by providing an additional selective pressure Fig. <ref type="figure">7</ref>. An example of a tradeoff surface in 3-D space <ref type="bibr" target="#b20">[21]</ref>.</p><p>to that imposed by ranking, which counters the effects of genetic drift. Genetic drift becomes more important as more individuals in the population are assigned the same rank.</p><p>2) Setting the Niche Size: The sharing parameter establishes how far apart two individuals must be in order for them to decrease each other's fitness. The exact value which would allow a number of points to sample a tradeoff surface whilst only tangentially interfering with one another depends on the area of such a surface.</p><p>When expressed in the objective value domain, an upper limit for the size of the tradeoff surface of a problem involving only low-priority objectives can be calculated from the minimum and maximum values each objective assumes within that surface. Let be the tradeoff set in the decision variable domain, the tradeoff set in the objective domain and any objective vector in . Also, let as illustrated in Fig. <ref type="figure">7</ref>.</p><p>The definition of nondominance implies that any line parallel to any of the axes will have not more than one of its points in , i.e., each objective is a single-valued function of the remaining objectives. Therefore, the true area of will be less than the sum of the areas of its projections according to each of the axes. Since the maximum area of each projection will be at most the area of the corresponding face of the hyperparallelogram defined by and the hyperarea of will be less than Fig. <ref type="figure">8</ref>. Upper bound for the area of a tradeoff surface limited by the parallelogram defined by (m 1 ; m 2 ; m 3 ) and (M 1 ; M 2 ; M 3 ) <ref type="bibr" target="#b20">[21]</ref>.</p><p>which is the sum of the areas of each different face of a hyperparallelogram of edges (Fig. <ref type="figure">8</ref>). The setting of also depends on how the distance between individuals is measured, and namely on how the objectives are scaled. The appropriate scaling of the objectives can often be determined as the aspect ratio which provides an acceptable visualization of the tradeoff, or from the goal values. In particular, normalizing objectives by the best estimate of available at each particular generation seems to yield good results (see the application examples in Part II <ref type="bibr" target="#b25">[26]</ref>). This view is also expressed by Horn et al. <ref type="bibr" target="#b26">[27]</ref>.</p><p>Assuming objectives are appropriately scaled, and using the -norm as a measure of distance, the maximum number of points that can sample area without interfering with each other can be computed as the number of hypercubes of volume that can be placed over the hyperparallelogram defined by (Fig. <ref type="figure" target="#fig_5">9</ref>). This can be estimated from the difference in volume between two hyperparallelograms, one with edges and the other with edges , by dividing it by the volume of a hypercube of edge i.e., Conversely, given a number of individuals (points), , it is possible to estimate by solving the -order polynomial equation for . When there are objectives with different priorities and there are known solutions which meet all goals with priority higher than 1, tradeoffs will involve only priority-1 objectives. The sharing parameter can, therefore, be computed for these only, using the expression above. This should be the case toward the end of the GA run in a problem where high-priority objectives can be satisfied.</p><p>Similarly, if the highest level of priority, , which the preferred solutions, known at any given time, violate is greater than 1, the tradeoffs explored by the preferability relation will not involve objectives with priority higher than . Again, sharing may be performed while taking into account priorityobjectives only. It is a fact that objectives with priority lower than may also become involved in the decision process, but this will only happen when comparing vectors with equal violating prioritycomponents. If this is the case, and the DM decides to move on to consider objectives with priority , then the relevant priority-objectives should either see their associated goals changed, or be associated priority by the DM for sharing to occur as desired.</p><p>3) Mating Restriction: Mating restriction <ref type="bibr" target="#b23">[24]</ref> tries to address the fact that individuals too different from each other are generally less likely than similar individuals to produce fit offspring through mating, by favoring the mating of similar individuals. In particular, the mating of distant members of the Pareto set can be expected to be inviable.</p><p>Mating restriction can be implemented much in the same way as sharing, by specifying how close individuals should be in order to mate. The corresponding parameter, , can also be defined in the objective domain. After selection, one individual in the population is chosen, and the population searched for a mate within a distance . If such an individual can be found, then mating is performed. Otherwise, a random individual is chosen <ref type="bibr" target="#b23">[24]</ref>.</p><p>Mating restriction assumes that neighboring fit individuals are genotypically similar, so that mating may be likely to produce offspring of fitness at least similar to that of their parents. Extra attention must therefore be paid to the coding of the chromosomes. In particular, the common concatenation of decision variables into a string cannot be expected to consistently express any relationship between them.</p><p>On the other hand, the Pareto set, when represented in the decision variable domain, will certainly exhibit such dependencies, as is the case in the example shown earlier in Fig. <ref type="figure">3</ref>. In that case, even relatively small regions of the Pareto-set may correspond to individuals whose chromosomes are too dissimilar for mating to work well. As the size of the solution set increases, an increasing number of individuals is necessary in order to ensure niche sizes small enough for the individuals within each niche to be sufficiently similar to each other.</p><p>Alternatively, the DM can reduce the size of the tradeoff set by appropriately refining the current preferences. The GA must then be able to cope in some way with the corresponding change in the fitness landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Progressive Articulation of Preferences</head><p>Setting aspiration levels in terms of goals and priorities is often difficult if done in the absence of any tradeoff information. On the other hand, an accurate global description of the tradeoff surface tends to be expensive, or even impossible to produce, since the Pareto set may not be bounded. Interactively refining preferences is known <ref type="bibr" target="#b27">[28]</ref> to have the potential advantage of reducing computational effort by concentrating optimization effort on the region from which compromise solutions are more likely to emerge, while simultaneously providing the DM with tradeoff information on which preference refinement can be based.</p><p>From the optimizer's point of view, the main difficulty associated with progressive articulation of preferences is the changing environment on which it must work. Consequently, the action of the DM may have to be restricted to the tightening of initially loose requirements, as with the moving-boundaries process <ref type="bibr" target="#b22">[23]</ref>. In this case, although the overall optimization problem may change, the final solution must remain in the set of candidate solutions which satisfy the current preferences at any given time.</p><p>When EA-based optimizers are used, the DM may gain more freedom and actually decide to explore regions of the tradeoff surface not considered in the initial set of preferences. The continuous introduction of a small number of random immigrants in the current population <ref type="bibr" target="#b28">[29]</ref>, for example, has been shown to improve the response of GA's to sudden changes in the objective function, while also potentially improving their performance as global optimizers.</p><p>Finally, giving the DM freedom to specify any preferences at any time raises the question of what information should be stored during a run, so that no tradeoff information acquired is lost. From Lemma 1, the nondominated set of a particular problem contains at least one vector equivalent to any vector in the preferred set of the problem, defined by a given preference vector. Therefore, storing only the noninferior individuals evaluated during a run of the algorithm may suffice in practice. A database of individuals currently nondominated is also useful in setting the appropriate niche sizes for sharing and mating restriction, since it includes the relevant individuals from previous generations in the niche-size estimation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Summary of the Approach</head><p>The proposed multiobjective genetic algorithm is summarized in Fig. <ref type="figure" target="#fig_6">10</ref>. The population is initialized and the chromosomes are decoded and evaluated. Then, the population is ranked using the preferability relation, as described in Section V-B, and the list of preferable individuals evaluated so far is updated. Niche sizes are estimated as described in Section VI-B, based on the current population and on the knowledge accumulated during the run. Fitness is assigned by re-ranking the population (Section VI-A) and performing fitness sharing based on the niche size determined earlier.</p><p>Offspring are selected from the parental population according to fitness, and then reorganized so that pairs of future mates are, where possible, in the same niche. The new population is obtained by mutating the recombined offspring and appending a small number of random immigrants, as discussed in Section VI-C. This process is repeated until a satisfactory set of solutions is known or a given number of generations is reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUDING REMARKS</head><p>Soft objectives and constraints have been presented as individual aspects of a more general multifunction optimization problem. A decision making approach based on goal and priority information, which can be explored by evolutionary techniques such as genetic algorithms, has been formalized in terms of a transitive relation, here called preferability. The decision approach was then extended to the case where there are more than two alternatives to chose from, which also provided a means of visualizing the cost surfaces associated with the given decision approach over a search space.</p><p>Evolutionary algorithms, known to perform well on broad classes of ill-behaved problems, possess several properties desirable in a multiple objective optimizer. In particular, their simultaneous handling of multiple candidate solutions is well suited to the multiple solution character of most multiobjective problems. Mechanisms to promote diversity in the population were extended from the single-objective genetic algorithm with the generation of rich tradeoff information in mind.</p><p>Tradeoff information generated during a run of the algorithm can, in turn, be used to refine initial preferences until a suitable compromise solution is found. Optimization effort may, in this way, be concentrated on the region of interest. The flexibility provided by EA's can also be explored at this level: on-line articulation of preferences implies nonstationary cost surfaces which the optimizer must handle satisfactorily.</p><p>Finally, the characterization of the multiobjective cost surfaces should prove useful in tailoring evolutionary algorithms to suit the needs of multiobjective optimization, such as the ability to handle ridges in the cost landscape in problems involving a large number of decision variables. However, standard GA's can already make good use of the preferability relation, as application examples presented in the second part of the paper <ref type="bibr" target="#b25">[26]</ref> and elsewhere <ref type="bibr" target="#b29">[30]</ref>- <ref type="bibr" target="#b31">[32]</ref> demonstrate. Dr. Fonseca is a member of the IFAC Technical Committee on Optimal Control, and the head of a Working Group on Evolutionary Optimization Algorithms within that committee.</p><p>Peter J. Fleming is Professor of Industrial Systems and Control in the Department of Automatic Control and Systems Engineering, University of Sheffield, Sheffield, U.K. He is Head of the Department and also Director of the Rolls-Royce University Technology Centre for Control and Systems Engineering. He has previously held the positions of Professor of Computer Systems Engineering at the University of Wales, Bangor, Wales; Associate Professor at Syracuse University, Syracuse, NY, and Research Scientist at NASA Langley, Langley, VA. His control and systems engineering interests include control applications of genetic algorithms and optimization, software for control system design and implementation, and distributed and parallel processing for real-time control and instrumentation. These interests have led to the development of close links with a variety of industries in sectors such as aerospace, power generation, food processing, and manufacturing. He has over 150 publications, including four books, in these research areas.</p><p>Prof. Fleming is a fellow of the Institution of Electrical Engineers and of the Institute of Measurement and Control. He is chair of the U.K. Automatic Control Council for the Triennium 1996-1999, IFAC Publications Committee chair, and a member of the IFAC Technical Board.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A general multiobjective evolutionary optimizer.</figDesc><graphic coords="4,44.82,59.58,247.44,81.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Multiobjective ranking with goal values (minimization). (a) f 2 has the same priority as f 1 : (b) f 2 has greater priority than f 1 :</figDesc><graphic coords="6,60.84,537.48,215.52,138.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The effect of specifying two goals with the same priority.</figDesc><graphic coords="6,323.52,59.58,216.24,138.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The effect of giving f 2 priority over f 1 (same goals).</figDesc><graphic coords="6,323.88,232.26,215.52,138.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The effect of making both f 1 and f 2 into hard objectives (same goals).</figDesc><graphic coords="6,323.88,405.06,215.52,139.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Sampling area A: Each point is share apart from each of its neighbors (1-norm) [21].</figDesc><graphic coords="8,310.20,59.58,242.88,217.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The proposed multiobjective GA.</figDesc><graphic coords="9,310.80,59.58,241.68,240.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Carlos M.Fonseca  (S'90-M'95) was born in Portugal in 1968. He received the Licenciatura in electronic and telecommunications engineering from the University of Aveiro, Portugal, in 1991, having received the "Eng. Jos√© Ferreira Pinto Basto" from Alcatel, Portugal, "in appreciation of the classification achieved in this degree." He received the Ph.D. degree from the University of Sheffield, Sheffield, U.K., in 1995, for research into multiobjective genetic algorithms. He has been a Research Associate in the Department of Automatic Control and Systems Engineering, University of Sheffield since 1994. Previously, he worked as a Student Assistant in the Department of Mathematics, University of Aveiro, Aveiro, Portugal, from 1989 to 1990, and as an IAESTE Trainee at the Institute of Information Theory and Automation of the former Czechoslovak Academy of Sciences, Prague, in the Summer of 1990. He will join the University of the Algarve, Portugal, as an Invited Lecturer in April 1997. His main research interests are evolutionary computation and its applications to control and systems engineering. He has approximately 20 research publications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,304.14,59.57,255.00,255.00" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by Programa CIENCIA, Junta Nacional de Investiga√ßao Cient√≠fica e Tecnol√≥gica, Portugal, under Grant BD/1595/91-IA and by the U.K. Engineering and Physical Sciences Research Council under Grant GR/J70857.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROOFS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proof of Lemma 1</head><p>It suffices to show that for all and all which can be done by induction over . The proof of the lemma is obtained by setting . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof of Lemma 2</head><p>The transitivity of the preferability relation will be proved by induction over The proof will be divided into three parts, the first two of which apply to both the base clause and the recursion clause</p><p>In the third part, the appropriate distinction between the two clauses is made.</p><p>1) Base Clause :</p><p>2) Recursion clause :</p><p>then Proof: From Definition </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>If</head><p>the base clause and the recursion clause must be considered separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case III(a):</head><p>From the above, and given the transitivity of inferiority relation, it follows that which implies that is preferable to given and proves the base clause.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case III(b):</head><p>From the above, and if the hypothesis is true, then which implies that is preferable to given and proves the recursion clause.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Characterization of Pareto and lexicographic optimal solutions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiple Criteria Decision Making Theory and Application</title>
		<title level="s">Lecture Notes in Economics and Mathematical Systems</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Fandel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Gal</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiple Objective Decision Making-Methods and Applications</title>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S M</forename><surname>Masud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Economics and Mathematical Systems</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<date type="published" when="1979">1979</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multicriteria decision models with specified goal levels</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dinkelbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiple Criteria Decision Making Theory and Application</title>
		<title level="s">Lecture Notes in Economics and Mathematical Systems</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Fandel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Gal</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">System Identification Through Simulated Evolution: A Machine Learning Approach to Modeling</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Ginn</publisher>
			<pubPlace>Needham, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of evolution strategies</title>
		<author>
			<persName><forename type="first">T</forename><surname>B√§ck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hoffmeister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms: Proc. 4th</title>
		<editor>
			<persName><surname>Int</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Conf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Belew</surname></persName>
		</editor>
		<editor>
			<persName><surname>Booker</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="2" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Genetic Algorithms in Search, Optimization and Machine Learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Genetic Programming: On the Programming of Computers By Means of Natural Selection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Koza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An overview of evolutionary algorithms for parameter optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>B√§ck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1993">1993</date>
			<pubPlace>Spring</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Handling constraints in genetic algorithms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Z</forename><surname>Janikow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms: Proc. 4th</title>
		<editor>
			<persName><surname>Int</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Conf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Belew</surname></persName>
		</editor>
		<editor>
			<persName><surname>Booker</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="151" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Some guidelines for genetic algorithms with penalty functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liepins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hilliard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</editor>
		<meeting>3rd Int. Conf. Genetic Algorithms<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="191" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using genetic algorithms in engineering design optimization with nonlinear constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Skolnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms: Proc. 5th Int. Conf., S. Forrest</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="424" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Low implementation cost IIR digital filter design using genetic algorithms</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Macleod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE/IEEE Workshop Natural Algorithms Signal Processing</title>
		<meeting><address><addrLine>Chelmsford, U.K.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Non-linear model term selection with genetic algorithms</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Billings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE/IEEE Workshop on Natural Algorithms in Signal Processing</title>
		<meeting><address><addrLine>Essex, U.K.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="27" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Application of genetic algorithms to task planning and learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gorges-Schleuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature</title>
		<editor>
			<persName><forename type="first">R</forename><surname>M√§nner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Manderick</surname></persName>
		</editor>
		<meeting><address><addrLine>The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
	<note>Amsterdam</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multicriteria target vector optimization of analytical procedures using a genetic algorithm, part I: Theory, numerical simulations and application to atomic emission spectroscopy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wienke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lucasius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kateman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytica Chimica Acta</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms and Their Applications: Proc. 1st Int. Conf. Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Compaction of symbolic layout using genetic algorithms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Fourman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms and Their Applications: Proc. 1st Int. Conf. Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="141" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A variant of evolution strategies for vector optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kursawe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature, 1st Workshop Proc</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>M√§nner</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">496</biblScope>
			<biblScope unit="page" from="193" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Genetic search strategies in multicriterion optimal design</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hajela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Struct. Optim</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="99" to="107" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An overview of evolutionary algorithms in multiobjective optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1995">1995</date>
			<pubPlace>Spring</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Genetic algorithms for multiobjective optimization: Formulation, discussion and generalization</title>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms: Proc. 5th</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimizing an arbitrary function is hard for the genetic algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms: Proc. 4th</title>
		<editor>
			<persName><surname>Int</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Conf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Belew</surname></persName>
		</editor>
		<editor>
			<persName><surname>Booker</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="190" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Design of dynamical and control systems by the method of inequalities</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zakian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Al-Naib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Inst. Elect. Eng</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1421" to="1427" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An investigation of niche and species formation in genetic function optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</editor>
		<meeting>3rd Int. Conf. Genetic Algorithms<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="42" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Genetic algorithms with sharing for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms and Their Applications: Proc. 2nd Int. Conf. Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiobjective optimization and multiple constraint handling with evolutionary algorithms-part II: Application example</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., this issue</title>
		<imprint>
			<biblScope unit="page" from="38" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A niched Pareto genetic algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nafpliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IEEE Conf. Evolutionary Computation</title>
		<meeting>1st IEEE Conf. Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="82" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Steuer</surname></persName>
		</author>
		<title level="m">Multiple Criteria Optimization: Theory, Computation, and Application</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Genetic algorithms for changing environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</author>
		<editor>R. M√§nner and B. Manderick</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>North-Holland</publisher>
			<biblScope unit="page" from="137" to="144" />
			<pubPlace>Amsterdam, The Netherlands</pubPlace>
		</imprint>
	</monogr>
	<note>in Parallel Problem Solving from Nature 2</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiobjective optimal controller design with genetic algorithms</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEE Control&apos;94 Int. Conf</title>
		<meeting>IEE Control&apos;94 Int. Conf<address><addrLine>Warwick, U.K.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="745" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Non-linear system identification with multiobjective genetic algorithms</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th IFAC World Congr</title>
		<meeting>13th IFAC World Congr<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="187" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiobjective gas turbine engine controller design using genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Chipperfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="583" to="589" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Multiple Criteria Decision Making Theory and Application</title>
		<title level="s">Lecture Notes in Economics and Mathematical Systems</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Fandel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Gal</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">177</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m">Genetic Algorithms: Proc. 4th Int. Conf</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Belew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Booker</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m">Proc. 3rd Int. Conf. Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</editor>
		<meeting>3rd Int. Conf. Genetic Algorithms<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Genetic Algorithms</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Int. Conf., S. Forrest</title>
		<meeting>5th Int. Conf., S. Forrest<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Parallel Problem Solving from Nature</title>
		<editor>
			<persName><forename type="first">R</forename><surname>M√§nner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Manderick</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1992">1992</date>
			<publisher>North-Holland</publisher>
			<pubPlace>Amsterdam, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Genetic Algorithms</title>
	</analytic>
	<monogr>
		<title level="m">Genetic Algorithms and Their Applications: Proc. 1st Int. Conf</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
