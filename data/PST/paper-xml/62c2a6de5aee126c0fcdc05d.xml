<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Node-aligned Graph Convolutional Network for Whole-slide Image Representation and Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yonghang</forename><surname>Guan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ShanghaiTech University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kuan</forename><surname>Tian</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sen</forename><surname>Yang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pei</forename><surname>Dong</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinxi</forename><surname>Xiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuyao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ShanghaiTech University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Han</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Node-aligned Graph Convolutional Network for Whole-slide Image Representation and Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The large-scale whole-slide images (WSIs) facilitate the learning-based computational pathology methods. However, the gigapixel size of WSIs makes it hard to train a conventional model directly. Current approaches typically adopt multiple-instance learning (MIL) to tackle this problem. Among them, MIL combined with graph convolutional network (GCN) is a significant branch, where the sampled patches are regarded as the graph nodes to further discover their correlations. However, it is difficult to build correspondence across patches from different WSIs. Therefore, most methods have to perform non-ordered node pooling to generate the bag-level representation. Direct non-ordered pooling will lose much structural and contextual information, such as patch distribution and heterogeneous patterns, which is critical for WSI representation. In this paper, we propose a hierarchical global-to-local clustering strategy to build a Node-Aligned GCN (NAGCN) to represent WSI with rich local structural information as well as global distribution. We first deploy a global clustering operation based on the instance features in the dataset to build the correspondence across different WSIs. Then, we perform a local clustering-based sampling strategy to select typical instances belonging to each cluster within the WSI. Finally, we employ the graph convolution to obtain the representation. Since our graph construction strategy ensures the alignment among different WSIs, WSI-level representation can be easily generated and used for the subsequent classification. The experiment results on two cancer subtype classification datasets demonstrate our method achieves better performance compared with the state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Histopathology plays an essential role in the clinical diagnosis and understanding of the underlying reasons for specific treatments being deployed <ref type="bibr" target="#b34">[35]</ref>. Whole-slide imaging, as the technique that translates the tissue specimens on glass slides into digital format without losing the tissue information, provides a comprehensive view of individual diseases and their effects on human tissues. Nowadays, the massive amount of whole-slide images (WSIs) makes the field of computational pathology an important application scenario for deep-learning-based computer aided diagnostic systems <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>WSI classification is a fundamental task in digital pathology. However, the characteristics of pathological images pose unique challenges for deep-learning-based approaches. For example, the ultra-high resolution of WSIs prevents them from being directly fed into deep neural networks due to the huge memory consumption. In addition, since manual annotations require non-trivial effort and domain knowledge from pathologists, usually only slide-level labels are available and pixel-or region-level annotations are missing. To tackle these challenges, current methods often adopt a two-stage multiple-instance learning (MIL) paradigm. In the first stage, a group of disjoint or overlapping "tissue patches" cropped from WSIs are encoded into semantic features using an encoder. Then an aggregation algorithm is designed to integrate these instance-level features to obtain a bag-level (slide-level) representation.</p><p>There exist different ways of aggregating patch-level features. A simple yet efficient strategy is to directly pool the patch features in one WSI <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42]</ref>. However, WSIs contain tissues of varying morphologies and types. Brute force pooling of all patch features will dilute distinctive features, thus resulting in an inadequate representation of WSI. Bag of visual words (BOVW) is another classical method to describe images, which has been widely used in image representation, classification and retrieval <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b43">44]</ref>. It provides an intuitive way to build descriptions for unstructured image data. Compared with pooling-based methods, BOVW can well delineate the global representation of WSI.</p><p>Despite the concise and straightforward definition, both pooling-based and BOVW-based methods are pre-defined and non-trainable. Recent approaches typically employ at-tention mechanisms to aggregate patch-level features, in which a trainable neural network is used to fit the weights of instances and then take the weighted average sum of all instance features as WSI representation. However, attentionbased approach is essentially a weighted linear combination of instances, which lacks the ability to reflect structural and contextual information of WSIs. Besides, since one WSI usually contains thousands of patches, the vast number of redundant patches will make attention-based approaches computationally costly.</p><p>Graph-based MIL approach is another significant branch for weakly-supervised classification of WSIs, which employs graphs to model the instance relationship and depict WSI representation. Graph convolution network (GCN) provides a powerful analytical paradigm for MIL and histopathology image, which first selects the important instances using a sampling strategy such as feature similarity, cell density or attention mechanisms, and then constructs a graph where graph nodes are selected instances and edges are the intrinsic relationship among instances <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b36">37]</ref>. Adopting graphs to represent WSIs can reflect the complex contextual information, establish the dependency relationship between patches and reduce the gap between different data, which can be important for WSI diagnosis. However, existing graph-based WSI classification methods cannot ensure the correspondence of graphs nodes derived from different WSIs, which results in performing non-ordered pooling for global representation and classification.</p><p>In order to retain local structural information as well as global distribution, we propose a hierarchical globalto-local clustering strategy to build a Node-Aligned GCN (NAGCN § ) for whole-slide image representation and classification. First, to filter out redundant information and select discriminative instances, we borrow the idea from BOVW and construct a codebook by leveraging a global clustering operation to instance features in the dataset. The codebook is comprised of amounts of visual words, where each visual word corresponds to a specific tissue type. Through the global clustering, we can divide instances from WSI bags into distinct sub-bags (each sub-bag corresponds to a visual word) and build correspondence across different WSIs at the sub-bag level. Second, we perform a local clustering-based sampling strategy to select typical instances within sub-bags for each WSI and use them as graph nodes. Finally, different from BOVW which only uses a non-trainable frequency histogram to represent WSIs, we deploy the node-aligned graph to achieve trainable WSI embeddings. Since our graph construction strategy ensures the alignment among different WSIs, WSI-level representation can be easily generated, which can be used for the subsequent classification.</p><p>We summarize our technical contributions as follows: § GitHub repository: https://github.com/YohnGuan/NAGCN </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Depending on at which level the classifier is adopted, MIL-based methods can be divided into two paradigms: instance-level and embedding-level <ref type="bibr" target="#b1">[2]</ref>. Instance-level methods first utilize instance classifiers to predict the instance label, then aggregate these labels to generate the baglevel label following standard multiple-instance (SMI) assumption <ref type="bibr" target="#b1">[2]</ref>. For embedding-level MIL methods, instances are first encoded to get semantic features, then the extracted features are aggregated to obtain the bag-level representation. In this section, only embedding-level MIL methods are discussed since instance-level approaches only focus on local information, whereas the global representation of WSIs is essential for the slide-level classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Conventional Bag Representation Approaches</head><p>Conventional bag representation methods adopt handcrafted aggregators. Pooling is one of the most common strategies. Pooling-based approaches aggregate all instances within a bag indiscriminately, which leverages maximum or average operation along the feature dimension to get the integrated feature. Obviously, pooling-based representation lacks the ability to distinguish instances and makes the obtained global representation inadequate. Bag of visual words (BOVW) <ref type="bibr" target="#b32">[33]</ref> provides an intuitive way to build descriptions for unstructured image data and has been widely used for pathological image classification and retrieval <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b43">44]</ref>. Akin to multiple-instance learning, BOVW takes each WSI as a bag containing many instances. Specifically, BOVW constructs a codebook by clustering in-stances in the dataset, then assigns each instance to a specific visual word through nearest neighbor. The frequency histogram of the visual words is then used as the global representation. BOVW is insensitive to image scale, which makes it well suited for ultra-high resolution WSIs. However, BOVW only considers the frequency of words occurrence, which is inadequate for accurate WSI representation. Yet, all handcrafted aggregation methods are not trainable, which cannot well fit the complex application scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Attention-based MIL Approaches</head><p>Recently, leading-edge techniques adopt attention mechanism into MIL to tackle the weakly-supervised classification problem <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b39">40]</ref>. In essence, attentionbased approach is to identify the contribution of each patch in the bag to the collective representation using a trainable neural network. Then the contributions of patches (are also called attention scores) are used to perform a weighted sum to get the global representation. For example, Ilse et al. <ref type="bibr" target="#b18">[19]</ref> use a neural net to fit the importance of instance features as the attention score and obtain the bag-level representation by weighted sum. Li et al. also propose a dual-stream attention architecture <ref type="bibr" target="#b24">[25]</ref>, where the first stream selects the critical instance and the second stream determines the attention score of each instance through its distance to the critical instance. The outputs of two streams are averaged to generate the global representation of WSI. Xie et al. <ref type="bibr" target="#b39">[40]</ref> cluster tiles of WSIs into K parts. The proposed method samples a single instance from each part, and uses the sampled K instances to represent one WSI. In <ref type="bibr" target="#b31">[32]</ref> In this work, we combine global clustering and local clustering operation together to ensure the correspondence relationship and sample typical instances, which can be used to build the node-aligned graph. For all these methods, the weighted linear combination of instances limits the ability to obtain global contextual and structural information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Graph-based MIL Approaches</head><p>Graph-based approaches have been widely utilized in computational pathology for multiple tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b44">45]</ref>. In computational pathology, a WSI can be abstracted as a graph, where the graph nodes represent biological structures (cells or tissue patches), and the graph edges reflect the internal relationships among biological structures. Due to the good property in relation-aware representations, graph provides a powerful tool to represent the biopsy slides in non-Euclidean space. According to the node level, WSI graphs can be divided into cell-graphs and tissue-graphs.</p><p>Cell-graph approaches <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46]</ref> first detect the nuclei in the WSI using a detection network, followed by edge building based on spatial distance, which can well depict the cell micro-environment. For tissue-graph methods <ref type="bibr" target="#b44">[45]</ref>, the graph nodes are tissue patch features and the graph edges are connected based on the underlying relationships (such as feature similarity and spatial distance). <ref type="bibr" target="#b36">[37]</ref> firstly combined graph neural network (GNN) with MIL to model the structural information among instances. The proposed algorithm treats each bag as a graph where instances are taken as graph nodes and edge connection is based on Euclidean distance. Zhao et al. <ref type="bibr" target="#b44">[45]</ref> proposed a GCN-based MIL framework for lymph node metastasis prediction. The framework adopts a feature selection module based on histogram and maximum mean discrepancy to select the most relevant instances. Then, a spectral-GCN <ref type="bibr" target="#b9">[10]</ref> followed by SAGPool <ref type="bibr" target="#b23">[24]</ref> is employed to generate the slide-level representation. However, all these approaches do not consider the node correspondence in different WSI graphs. As illustrated in Figure <ref type="figure" target="#fig_1">1</ref>, in those methods nodes from different WSI graphs may have different amounts and topological orders. To map these graphs to a fixed-length embedding, all these methods will inevitably employ non-ordered graph pooling operations, which will result in a loss of representation performance. In the light of BOVW, we build a nodealigned graph using a pre-built codebook, where the correspondence is ensured by the pre-formulated visual words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we present our overall framework for weakly-supervised multiple-instance learning, illustrated in Figure <ref type="figure" target="#fig_2">2</ref>. The proposed framework consists of three components: instance sampling and encoding, hierarchical global- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Formulation</head><p>Conventional MIL problem follows the standard multiple-instance (SMI) assumption <ref type="bibr" target="#b1">[2]</ref>: A bag label is positive if and only if the bag contains at least one positive instance (i.e., an instance belongs to a certain target positive class), otherwise the bag label is negative. However, some of the WSI-level prediction problems are not applicable to the conventional SMI assumption, which rely on both the global and local representation of the entire slide.</p><p>In the context of weakly-supervised pathology image classification problem, we can consider each WSI as a bag consisting of multiple patches. Specifically, let W = {p 1 , p 2 , ..., p n } be a WSI which can be cut into a multitude of patches p j (n is the number of sampled patches and p j denotes j-th patch), the corresponding slide-level label is Y while the patch-level labels are unknown. The procedure of embedding-based MIL paradigm for pathology image classification is involved in the following steps:</p><p>1. A patch extraction strategy that samples patches {p 1 , p 2 , ..., p n } from WSI W and an instance encoder to generate instance features f j = ϵ(p j ) and form the WSI bag B = {f 1 , f 2 , ..., f n } in the encoding space.</p><p>2. An instance embedding aggregation strategy to integrate instance-level features and generate the global representation g = ρ(B). For graph-based MIL, the aggregation strategy first constructs graph G for the bag, and then embeds the graph-level representation g through GCN and graph pooling.</p><p>3. A bag-level classifier for the aggregated global representation Ŷ = ξ(g).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Instance Encoding&amp;Codebook Construction</head><p>Since the background in WSI occupies a significant portion and does not contribute to the WSI prediction, a fore-ground segmentation method is first adopted for the slide thumbnail to extract the tissue. WSI format data are usually stored as image pyramids, with each layer corresponding to a specific magnification and physical resolution of the digital biopsy sections. We extract the non-overlapping foreground patches with a fixed size at a particular magnification (e.g., 20x) as the multiple instances of the WSI. Each instance represents a local tissue region in the WSI, and the integration of these instances generates the slide-level representation of the WSI.</p><p>Let D = {W 1 , W 2 , ..., W N } be the training dataset that includes N WSIs. After pre-processing, each WSI W i (W i denotes i-th WSI in the dataset) is cropped into nonoverlapping instances, where W i = {p 1 i , p 2 i , ..., p n i }, and n is the number of sampled patches (n can vary for different WSIs.). A pre-trained deep neural network is then adopted to encode each instance p j i (p j i denotes j-th instance in W i ) into a fixed dimensional vector f j i ∈ R L×1 to capture the semantic information of the patch. After instance encoding, we transform the dataset into the encoding space D f = {B 1 , B 2 , ..., B N }, where  To generate slide-level representation, we pool the features within each sub-bag and connect the pooled sub-bag level features in the visual word order. Zero vectors (indicated as dashed lines) are used to fill in the positions corresponding to empty sub-bags.</p><formula xml:id="formula_0">B i = {f 1 i , f 2 i , ..., f n i } ∈ R n×L .</formula><p>ent from existing state-of-the-art graph-based MIL methods <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b44">45]</ref>, NAGCN can ensure feature alignment from different WSI graphs through a hierarchical global-to-local clustering strategy and an adjacency relationship construction mechanism, as illustrated in Figure <ref type="figure">3</ref>.</p><p>Our proposed hierarchical global-to-local clustering strategy can screen out discriminative instances as graph nodes and achieve correspondence among different WSI graphs. It consists of a global clustering part and a local clustering part. Global clustering operation is the abovementioned codebook construction, which performs clustering to all instance features in the training dataset. BOVW represents the WSI as the frequency histogram of visual words, where each bin/bucket of the histogram corresponds to a visual word, and the count of each bin corresponds to the number of instances in the bag belonging to this visual word. Similar to BOVW, we first look up the pre-built codebook and match each instance feature in the WSI bag with its nearest visual word. Through the codebook, the WSI bag is divided into K G sub-bags, where each sub-bag contains the instances belonging to the same visual word. Since all WSI bags in the dataset share the same codebook, the graph node correspondence can be achieved at the sub-bag level. Clustering only at the global level can probably result in the loss of fineness due to millions of instances in our dataset. A local clustering sampling strategy is then performed to sample a fixed number of distinct instances inside each sub-bag. As shown in Figure <ref type="figure">3</ref>, after global clustering a WSI bag B is divided into K G sub-bags B = {sub 1 , sub 2 , ..., sub K G } and each sub-bag sub k (sub k denotes the k-th sub-bag in B) contains instances belonging to the same visual word vw k . For local clustering sampling, K-means clustering is conducted independently within each sub-bag sub k to divide these patches into S k bins and we randomly select one instance for each bin. Specifically, S k is set to a random number within <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b24">25]</ref> to augment the data during training. In inference, S k is set to a fixed value. After that in each WSI bag B ∈ R n×L , we extract V = K G k=1 S k instances to generate the sampled WSI bag X ∈ R V ×L for graph construction.</p><p>We propose two kinds of edges to form the graph connection relationship: inner-sub-bag edges and outer-subbag edges. All instances belonging to the same sub-bag are interconnected to formulate the inner-sub-bag edges. For outer-sub-bag edges, each node is connected to its N e nearest nodes through Euclidean distance. Inner-edge enables node feature communication within the sub-bag, while the outer-edge enables the information propagation among instances belonging to different visual words, which models the heterogeneous pattern. Since global clustering is usually sparse, which can leave many sub-bags empty in a WSI, null nodes (zero vector) are used to indicate that the corresponding sub-bag is empty and we do not connect null nodes to any others.</p><p>After that, we generate the input graph G for each WSI bag B as:</p><formula xml:id="formula_1">G = Graph(X, A),<label>(1)</label></formula><p>where X ∈ R V ×L represents node feature matrix (the sampled WSI bag) and A ∈ {0, 1} V ×V denotes the adjacency matrix of G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Graph Convolution and Bag Representation</head><p>Through the above-mentioned graph construction strategy, graphs from different WSIs can achieve correspondence relationships at the sub-bag level. The constructed graphs are fed into a GCN to conduct information passing over the graph. The output graph of GCN has the same node counts and orders as the input graph, which can be denoted as:</p><formula xml:id="formula_2">Z = GCN (Graph(X, A)),<label>(2)</label></formula><p>where Z ∈ R V ×L ′ is the node feature matrix of the output graph and L ′ is the output feature dimension. As illustrated in Figure <ref type="figure">4</ref>, after GCN we adopt a sub-bag pooling module, which performs pooling operation to the node features within the same sub-bag. The pooled graphs are then flattened in the visual word order to get a fixed-length vector g ∈ R K G L ′ ×1 , which can be used as the slide-level representation for the WSI classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>The public pathology datasets greatly facilitate the development of computational pathology. In this work, the experiments are in whole based upon The Cancer Genome Atlas (TCGA) repository § .</p><p>To evaluate the proposed approach, we construct two representative and clinically meaningful weakly-supervised cancer subtype classification datasets based on TCGA: TCGA non-small cell lung cancer (TCGA-NSCLC) and TCGA renal cell carcinoma (TCGA-RCC). NSCLC is one of the most common primary lung cancer types, which contains two cancer subtypes: Lung Adenocarcinoma (LUAD) <ref type="bibr" target="#b5">[6]</ref> and Lung Squamous Cell Carcinoma (LUSC) <ref type="bibr" target="#b27">[28]</ref>. We select 873 WSI digital slides from TCGA to build the TCGA-NSCLC dataset, which consists of 451 LUAD slides and 422 LUSC slides. RCC contains three common cancer subtypes: Kidney Chromophobe Renal Cell Carcinoma (KICH) <ref type="bibr" target="#b7">[8]</ref>, Kidney Renal Clear Cell Carcinoma (KIRC) <ref type="bibr" target="#b6">[7]</ref> and Kidney Renal Papillary Cell Carcinoma (KIRP) <ref type="bibr" target="#b28">[29]</ref>. Our dataset consists of a total of 726 WSI digital slides, with 118 KICH slides, 390 KIRC slides and 218 KIRP slides. During dataset construction, we removed all the frozen section digital slides and only preserved formalin-fixed paraffin-embedded hematoxylin and eosin (H&amp;E) slides due to the poor quality of frozen slides. § https://www.cancer.gov/tcga</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details 4.2.1 Patch Extraction</head><p>First, we use Otsu's method for foreground tissue extraction. To capture detailed information of the images, we extract a series of non-overlapping patches at 20× with size 256×256 which contains more than 50% foreground tissue. Since some WSI slides in TCGA may not contain the pyramid layer at 20×, we first extract patches at 40× with size 512×512, then resize them to 256×256 with bicubic interpolation. Finally, each WSI contains an average of 13904 patches for NSCLC and 14116 patches for RCC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Networks</head><p>In our proposed framework, ResNet-50 <ref type="bibr" target="#b15">[16]</ref> pre-trained by ImageNet1024 is adopted as the instance-level feature extraction backbone, which encodes 256 × 256 instance patches into 1024-dimensional vectors. All the clustering operations are performed upon the 1024-dimensional vector. For codebook construction, mini-batch K-means algorithm is performed with K-means++ <ref type="bibr" target="#b2">[3]</ref> center initialisation. We deploy a three-layer graph convolutional network <ref type="bibr" target="#b21">[22]</ref>, with each layer followed by a ReLU activation, for feature propagation among nodes. The sub-bag pooling module is a pooling layer used to pool the node features within the same sub-bag. After sub-bag pooling the graph is flattened to generate the slide-level representation. A two-layer fully connected net is adopted as the classifier head.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Training and Evaluation</head><p>Cross Entropy loss and Adam <ref type="bibr" target="#b20">[21]</ref> were adopted to optimise our model. The batch size was 256 and we set the learning rate as 5 × 10 −5 with a linear decay. Our experiments used L2-regularization 5 × 10 −3 and dropout rate 0.4 to mitigate model overfitting. To prevent information leakage, codebook construction is only performed on instances in the training dataset, and WSI graph construction is based upon this pre-built codebook during both training and inference. In our experiment, K G is set to 100. During training, S k is set to a random number within <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b24">25]</ref> and in inference S k is set to 25. We set the number of outer-sub-bag edges N e to 5 for each graph node. The feature dimension of output graph nodes L ′ is 16. After sub-bag pooling and flattening we can get a 1600 dimension vector for graph-level representation. All experiment results are obtained through 5-fold cross validation.</p><p>Accuracy and Area under the Curve of ROC (AUCROC) are used to evaluate the classification performance of different approaches. All the experiments are implemented using PyTorch <ref type="bibr" target="#b30">[31]</ref> on a workstation with two Nvidia V100 GPUs and an Intel Xeon Gold 6133 CPU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Visualisation of Hierarchical Global-to-local Clustering Strategy</head><p>Figure <ref type="figure" target="#fig_5">5</ref> shows the examples of hierarchical global-tolocal clustering sampling strategy. To visualize the performance of global clustering, we overlay the visual word labels computed for each instance to form a heatmap. The frequency histograms are also presented to describe the overall distribution of instances. In addition, we select some typical visual words (sub-bags) to visualize the sampled WSI bags, which are also presented in Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>Overall, we observe that the hierarchical global-to-local clustering sampling strategy can reflect global distribution as well as local structures in pathological images and achieve instance alignment in the sub-bag level. From the heatmap, we can see that the global clustering result shows a high correspondence with the WSI tissue structures, which indicates that the pre-built codebook in the embedding space can well distinguish the pathological structures of WSIs. We observe that the clustering-based sampling strategy can divide WSI bags into distinct phenotype groups, where each visual word corresponds to a specific tissue type. Hence, the sampled instances can achieve correspondence among different WSI bags. Besides, extensive studies <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43]</ref> have validated that cancer development is highly correlated with abnormal stromal development and immune cell growth. Our sampled WSI bags can reflect global-wise and local-wise heterogeneous patterns, and thus better represent the slide-level information of WSI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with State-of-the-art Methods</head><p>We conduct a comprehensive comparison of NAGCN with several state-of-the-art MIL approaches used in computational pathology on two representative cancer subtype classification datasets. The comparison methods include: (1-2) Max&amp;Mean pooling, (3) Bag of Visual words (BOVW), (4) ABMIL <ref type="bibr" target="#b18">[19]</ref>, (5-6) CLAM with singlebranch (CLAM-SB) and multi-branch (CLAM-MB) <ref type="bibr" target="#b25">[26]</ref>, (7) DSMIL <ref type="bibr" target="#b24">[25]</ref>, (8) C2C <ref type="bibr" target="#b31">[32]</ref>. For fairness of comparison, we use ResNet50 <ref type="bibr" target="#b15">[16]</ref> as the instance-level feature encoder for all methods. All approaches are evaluated using the same 5-fold cross-validation splits.</p><p>As shown in Table <ref type="table" target="#tab_1">1</ref>, NAGCN achieves the overall best performance. Our method improves over 8.7% in accuracy and 6.8% in AUCROC compared to conventional MIL methods (pooling and BOVW), which demonstrates the importance of trainable global representations for WSI classification tasks. Both CLAM and C2C outperforme ABMIL, which illustrates the effectiveness of the clustering-based sampling strategy. Our approach combines global clustering and local clustering together, while realizing both node alignment and feature filtering, thus improving about 4.0% in accuracy and 2.0% in AUCROC. DSMIL had poorer performance compared with our method since the attention mechanism lacks the ability to reflect structural and contextual information.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Effect of Model Hyper-parameters</head><p>We now systematically explore the effect of model hyperparameters in NAGCN on TCGA-NSCLC dataset. We will discuss the impact of the following model parameters: (1) number of visual words and (2) number of outer-sub-bag edges for each node. As shown in Figure <ref type="figure" target="#fig_7">6</ref>(a), more visual words will allow global clustering to divide the embedding space more finely, thus improving the model performance. As the number of visual words increases, the model performance growth tends to level off, which indicates that the codebook is sufficient to characterize patches in the dataset. From Figure <ref type="figure" target="#fig_7">6</ref>(b) we can see that the increase in the number of outersub-bags leads to a slight decrease in performance, which is caused by the over-smoothing during graph convolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Improvement with Self-supervised Learning</head><p>To further explore the potential of self-supervised learning for NAGCN performance improvement, we implement a self-supervised model for pathological images according to <ref type="bibr" target="#b37">[38]</ref> and adopt it as the instance-level encoder. We compare the performance using both ImageNet pre-trained model and self-supervised model on the TCGA-NSCLC dataset.</p><p>With the same parameter settings, the self-supervised model achieves higher performance, including the accuracy of 0.928 and AUC of 0.972. The self-supervised model can improve over 3% in accuracy and AUC, which further validates the scalability of NAGCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we present the Node-Aligned GCN (NAGCN) for weakly-supervised WSI representation and classification. Our approach proposes a novel graph construction strategy based on a hierarchical global-to-local clustering, which not only retains both local structural information and global distribution, but also enables the alignment of different WSIs, thus avoiding non-ordered pooling to obtain the bag-level representation. A limitation in our current study is that the performance of our method relies heavily on the effectiveness of codebook construction. When the instance-level representation is not sufficiently robust or the region of interest is less occupied, the representational ability of WSI graphs may be compromised. Future work would focus on how to achieve joint feature extraction and global clustering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, Sharma et al. adopt a local clustering operation to expose the model to diverse discriminative patches. The model performs a local clustering for each WSI, and samples instances from the clustering centroids before every epoch. However, local clustering performing on one WSI cannot guarantee the correspondence of clustering centroids among different WSIs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Illustration of correspondence in WSI graph representation. Top: Conventional tissue-graph representation. Bottom: Our proposed graph construction strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Overview of NAGCN. The proposed framework consists of 1) instance sampling and encoding, 2) hierarchical global-to-local clustering, 3) slide-level representation and classification. Patches are extracted from WSIs and fed into an encoder to generate the instancelevel features. Then, the hierarchical global-to-local clustering is performed using the instance-level features to construct the node-aligned graphs. We leverage a novel graph construction strategy and a GCN to model the slide-level representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Then we generate a global codebook C = (vw 1 , vw 2 , ..., vw K G ) by performing K-means clustering to all the encoding features in D f . In this work, we use the term "visual word" vw to represent the global cluster category. The constructed codebook divides the feature space into K G sub-spaces, each corresponding to a visual word used to represent biopsy tissues with different structural, textural, and pathological properties. Note that only training dataset instances are used for codebook construction to prevent data leakage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3. 3 .Figure 3 .Figure 4 .</head><label>334</label><figDesc>Figure 3. Illustration of the proposed graph construction process. First we look up the global codebook to divide the WSI bag into KG sub-bags where each sub-bag denotes a specific visual word. Then local clustering is performed within each sub-bag to select a certain number of typical instances. The instances in the sampled WSI bag are taken as graph nodes and we connect the instance nodes using both inner-sub-bag edges (colored lines) and outer-sub-bag edges (black lines).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Visualisation of hierarchical clustering sampling strategy. Total two WSIs are presented. For each WSI, (a) thumbnail, (b) clustering heatmap, (c) examples of the sampled WSI sub-bags, (d) frequency histogram. For (c), different colored boxes represent subbags containing typical patches corresponding to specific tissue types (VW05: tumor cells, VW08: immune cells, VW11: stromal regions).</figDesc><graphic url="image-86.png" coords="7,141.07,184.70,70.18,59.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5. 3 . 1</head><label>31</label><figDesc>Effect of Modules in NAGCNOur proposed work can be divided into three main parts: (1) Global-clustering-based codebook construction (GC),<ref type="bibr" target="#b1">(2)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Performance of cancer subtype classification with different model hyper-parameters on TCGA-NSCLC dataset. Comparison results with the different number of (a) visual words and (b) outer-sub-bag edges for each node.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>The comparison between NAGCN and SOTA methods. NSCLC dataset. During the ablation study, we set K G as 100, S k as 15 and N e as 5.To verify the criticality of node alignment for graph representation, we perform local clustering for each WSI bag respectively to generate unaligned sub-bags as an alternative to global codebook construction. As shown in Table2(A) and (C), node alignment strategy can improve accuracy with 4.1% and AUCROC with 2.6%. Besides, the comparison between (B) and (A) indicates that local-clusteringbased sub-bag generation can bring improvement to the results. We also directly use the sampled WSI bags without graph construction and replace GCN with (D) attention modules and (E) max pooling to confirm the power of graph to model the instance correlations and structural information. As shown in Table2, graph and GCN can improve accuracy by 5.2% and 8.3%, AUCROC by 3.9% and 6.1%, respectively.</figDesc><table><row><cell></cell><cell cols="2">TCGA-NSCLC</cell><cell cols="2">TCGA-RCC</cell></row><row><cell></cell><cell cols="4">Accuracy AUCROC Accuracy AUCROC</cell></row><row><cell>Max pooling</cell><cell>0.815</cell><cell>0.884</cell><cell>0.887</cell><cell>0.959</cell></row><row><cell>Mean pooling</cell><cell>0.753</cell><cell>0.805</cell><cell>0.814</cell><cell>0.943</cell></row><row><cell>BOVW</cell><cell>0.774</cell><cell>0.823</cell><cell>0.847</cell><cell>0.957</cell></row><row><cell>ABMIL</cell><cell>0.860</cell><cell>0.921</cell><cell>0.906</cell><cell>0.977</cell></row><row><cell>CLAM-SB</cell><cell>0.861</cell><cell>0.936</cell><cell>0.900</cell><cell>0.988</cell></row><row><cell>CLAM-MB</cell><cell>0.862</cell><cell>0.932</cell><cell>0.914</cell><cell>0.989</cell></row><row><cell>DSMIL</cell><cell>0.874</cell><cell>0.949</cell><cell>0.911</cell><cell>0.986</cell></row><row><cell>C2C</cell><cell>0.873</cell><cell>0.938</cell><cell>0.919</cell><cell>0.987</cell></row><row><cell>NAGCN</cell><cell>0.902</cell><cell>0.952</cell><cell>0.954</cell><cell>0.992</cell></row><row><cell cols="5">Local-clustering-based sub-bag generation strategy (LC),</cell></row><row><cell cols="5">(3) graph convolution network and sub-bag level node</cell></row><row><cell cols="5">feature pooling (GCN). Ablation study was performed to</cell></row><row><cell cols="5">validate the effectiveness of these components using the</cell></row><row><cell>TCGA-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Effects of model modules in NAGCN.</figDesc><table><row><cell>Modules</cell><cell cols="2">Accuracy AUCROC</cell></row><row><cell>(A) GC + LC + GCN (Ours)</cell><cell>0.896</cell><cell>0.946</cell></row><row><cell>(B) GC + Random sampling + GCN</cell><cell>0.889</cell><cell>0.945</cell></row><row><cell>(C) Unaligned sub-bags + GCN</cell><cell>0.855</cell><cell>0.920</cell></row><row><cell>(D) GC + LC + attention</cell><cell>0.844</cell><cell>0.907</cell></row><row><cell>(E) GC + LC + max pooling</cell><cell>0.813</cell><cell>0.885</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A survey on graph-based deep learning for computational histopathology</title>
		<author>
			<persName><forename type="first">David</forename><surname>Ahmedt-Aristizabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ali Armin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petersson</surname></persName>
		</author>
		<idno>ArXiv, abs/2107.00272</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiple instance classification: Review, taxonomy and comparative study</title>
		<author>
			<persName><forename type="first">Jaume</forename><surname>Amores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">201</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">K-means++: The advantages of careful seeding</title>
		<author>
			<persName><forename type="first">David</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
				<meeting>the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ramazan Gökberk Cinbis ¸, Kemal Kösemehmetoglu, Sevgen Önder, and Ays ¸egül Üner. Graph convolutional networks for region of interest classification in breast histopathology</title>
		<author>
			<persName><forename type="first">Bulut</forename><surname>Aygünes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">¸</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Selim</forename><surname>Aksoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging 2020: Digital Pathology</title>
				<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">11320</biblScope>
			<biblScope unit="page" from="134" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Clinicalgrade computational pathology using weakly supervised deep learning on whole slide images</title>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Campanella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Geneslaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allen</forename><surname>Miraflor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitor</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Busam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edi</forename><surname>Brogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Klimstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comprehensive molecular profiling of lung adenocarcinoma: The cancer genome atlas research network</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Collisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliann</forename><surname>Chmielecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gad</forename><surname>Getz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hammerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrie</forename><surname>Sougnez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mara</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacey</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Cibulskis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaegil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chip</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Lichtenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Lander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">511</biblScope>
			<biblScope unit="page" from="7" to="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Comprehensive molecular characterization of clear cell renal cell carcinoma</title>
		<author>
			<persName><forename type="first">Chad</forename><surname>Creighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preethi</forename><surname>Gunaratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Gibbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rameen</forename><surname>Beroukhim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Cibulskis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabina</forename><surname>Signoretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roel</forename><surname>Verhaak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pheroze</forename><surname>Tamboli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wandaliz</forename><surname>Torres-García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rehan</forename><surname>Akbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heidi</forename><surname>Sofia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="6" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The somatic genomic landscape of chromophobe renal cell carcinoma</title>
		<author>
			<persName><forename type="first">Caleb</forename><forename type="middle">F</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Ricketts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Buhay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyojin</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang</forename><forename type="middle">Cheol</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">C</forename><surname>Fahey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Cell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="319" to="330" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Paradoxical roles of the immune system during cancer development</title>
		<author>
			<persName><forename type="first">Karin E De</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Eichten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">M</forename><surname>Coussens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Cancer</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="37" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<title level="m">Convolutional neural networks on graphs with fast localized spectral filtering. NIPS&apos;16</title>
				<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A comparative study of CNN, BoVW and LBP for classification of histopathological images</title>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Meghana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morteza</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujin</forename><surname>Babaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivam</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Kalra</surname></persName>
		</author>
		<author>
			<persName><surname>Tizhoosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium Series on Computational Intelligence (SSCI)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Ji</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, AAAI&apos;17</title>
				<meeting>the Thirty-First AAAI Conference on Artificial Intelligence, AAAI&apos;17</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1884" to="1890" />
		</imprint>
	</monogr>
	<note>Deep MIML network</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Medical image retrieval using bag of meaningful visual words: Unsupervised visual vocabulary pruning with PLSA</title>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM International Workshop on Multimedia Indexing and Information Retrieval for Healthcare</title>
				<meeting>the 1st ACM International Workshop on Multimedia Indexing and Information Retrieval for Healthcare<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multiple instance captioning: Learning representations from histopathology textbooks and articles</title>
		<author>
			<persName><forename type="first">Jevgenij</forename><surname>Gamper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasir</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001">June 2021. 1</date>
			<biblScope unit="page" from="16549" to="16559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-scale domain-adversarial multiple-instance CNN for cancer subtype classification with unannotated histopathological images</title>
		<author>
			<persName><forename type="first">Noriaki</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisuke</forename><surname>Fukushima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryoichi</forename><surname>Koga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Takagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaho</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kei</forename><surname>Kohno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masato</forename><surname>Nakaguro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shigeo</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hidekata</forename><surname>Hontani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ichiro</forename><surname>Takeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003">June 2020. 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Atlas of digital pathology: A generalized hierarchical histological tissue type-annotated database for deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mahdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyndon</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sajad</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corwyn</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><surname>Rowsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001">June 2019. 1</date>
		</imprint>
	</monogr>
	<note>Konstantinos N. Plataniotis, and Savvas Damaskinos</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robust histopathology image analysis: To label or to synthesize?</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayush</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tahsin</forename><forename type="middle">M</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajarsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">H</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001">June 2019. 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07-15">10-15 Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Quantifying explainers of graph neural networks in computational pathology</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Jaume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushpak</forename><surname>Pati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behzad</forename><surname>Bozorgtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Foncubierta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">Maria</forename><surname>Anniciello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florinda</forename><surname>Feroce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tilman</forename><surname>Rau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Philippe</forename><surname>Thiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Gabrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orcun</forename><surname>Goksel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8106" to="8116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
				<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<title level="s">Conference Track Proceedings</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24">2017. April 24-26, 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep learning in histopathology: the path to the clinic</title>
		<author>
			<persName><forename type="first">Jeroen</forename><surname>Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geert</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ciompi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="5" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-attention graph pooling</title>
		<author>
			<persName><forename type="first">Junhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inyeop</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3734" to="3743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Eliceiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007">June 2021. 3, 7</date>
			<biblScope unit="page" from="14318" to="14328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Data-efficient and weakly supervised computational pathology on whole-slide images</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiffany</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="6" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SOS: Selective objective switch for rapid immunofluorescence whole slide image classification</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Maksoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001">June 2020. 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comprehensive genomic characterization of squamous cell lung cancers</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Baylin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rehan</forename><surname>Ramaswamy Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ijeoma</forename><surname>Akbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Azodo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Beer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><forename type="middle">A</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Byers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Wei</forename><surname>Carbone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Collisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chad</forename><surname>Cope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludmila</forename><surname>Creighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Danilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gad</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Getz</surname></persName>
		</author>
		<author>
			<persName><surname>Potapova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">489</biblScope>
			<biblScope unit="page" from="9" to="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Comprehensive molecular characterization of papillary renal-cell carcinoma</title>
	</analytic>
	<monogr>
		<title level="j">Cancer Genome Atlas Research Network</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="145" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>New England Journal of Medicine</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sevgen Önder, and Ays ¸egül Üner. Self-supervised learning with graph neural networks for region of interest retrieval in histopathology</title>
		<author>
			<persName><forename type="first">Yigit</forename><surname>Ozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Selim</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kemal</forename><surname>Kösemehmetoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6329" to="6334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Clusterto-conquer: A framework for end-to-end multi-instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubaina</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Moskaluk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sana</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging with Deep Learning</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Video google: a text retrieval approach to object matching in videos</title>
		<author>
			<persName><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Ninth IEEE International Conference on Computer Vision</title>
				<meeting>Ninth IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visualization for histopathology images using graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">Mookund</forename><surname>Sureka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhijeet</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 20th International Conference on Bioinformatics and Bioengineering (BIBE)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="331" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Report of two cases of pseudoprogression in patients with non-small cell lung cancer treated with nivolumab-including histological analysis of one case after tumor regression</title>
		<author>
			<persName><forename type="first">Junko</forename><surname>Tanizaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hidetoshi</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masatomo</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaoru</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayuki</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shigeki</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akihiko</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuhiko</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lung Cancer</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="48" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive weighting multi-field-of-view CNN for semantic segmentation in pathology</title>
		<author>
			<persName><forename type="first">Hiroki</forename><surname>Tokunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuki</forename><surname>Teramoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akihiko</forename><surname>Yoshizawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryoma</forename><surname>Bise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001">June 2019. 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Multiple instance learning with graph neural networks</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transpath: Transformer-based self-supervised learning for histopathological image classification</title>
		<author>
			<persName><forename type="first">Xiyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minghui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2021</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">P3SGD: Patient privacy preserving SGD for regularizing deep CNNs in pathological image classification</title>
		<author>
			<persName><forename type="first">Bingzhe</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiwan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caihong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001">June 2019. 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Beyond classification: Whole slide tissue histopathology analysis by end-to-end part learning</title>
		<author>
			<persName><forename type="first">Chensu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chad</forename><forename type="middle">M</forename><surname>Vanderbilt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Caso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dig</forename><surname>Vijay Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Yarlagadda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">J</forename><surname>Campanella</surname></persName>
		</author>
		<author>
			<persName><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging with Deep Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="843" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improving histopathological image segmentation and classification using graph convolution network</title>
		<author>
			<persName><forename type="first">Haili</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><surname>Da-Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition</title>
				<meeting>the 2019 8th International Conference on Computing and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>ICCPR &apos;19, page 192-198</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barnabas</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cancer-associated fibroblasts in desmoplastic tumors: emerging role of integrins</title>
		<author>
			<persName><forename type="first">Cédric</forename><surname>Zeltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Primac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pugazendhi</forename><surname>Erusappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jahedul</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agnes</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Gullberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seminars in Cancer Biology</title>
				<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="166" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Towards large-scale histopathological image analysis: Hashing-based image retrieval</title>
		<author>
			<persName><forename type="first">Xiaofan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murat</forename><surname>Dundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunil</forename><surname>Badve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="496" to="506" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Predicting lymph node metastasis using histopathological images based on multiple instance learning with deep graph convolution</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niyun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjoern</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinjuan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhua</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005">June 2020. 3, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">CGC-Net: Cell graph convolutional network for grading of colorectal cancer histology images</title>
		<author>
			<persName><forename type="first">Yanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navid</forename><forename type="middle">Alemi</forename><surname>Koohbanani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasir</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</title>
				<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</meeting>
		<imprint>
			<date type="published" when="2003">Oct 2019. 3</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
