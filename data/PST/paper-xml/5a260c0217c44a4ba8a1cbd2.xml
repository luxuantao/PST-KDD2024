<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SmartSleeve: Real-time Sensing of Surface and Deformation Gestures on Flexible, Interactive Textiles, using a Hybrid Gesture Detection Pipeline</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Parzer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Media Interaction Lab</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adwait</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Media Interaction Lab</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anita</forename><surname>Vogl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Media Interaction Lab</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Ürgen Steimle</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Saarland University</orgName>
								<address>
									<addrLine>Saarland Informatics Campus</addrLine>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alex</forename><surname>Olwal</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Google, Inc</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>California</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Haller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Media Interaction Lab</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SmartSleeve: Real-time Sensing of Surface and Deformation Gestures on Flexible, Interactive Textiles, using a Hybrid Gesture Detection Pipeline</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5A0F6D3DBE305A64CAD04A6208ED84F6</idno>
					<idno type="DOI">10.1145/3126594.3126652</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Smart Textile</term>
					<term>Deformation Gestures</term>
					<term>Surface Gestures H.5.2.: [User Interfaces]: Input devices and strategies</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>a b c d e f Figure 1: SmartSleeve is a wearable textile that can detect 2D surface and 2.5D deformation gestures, like twist (a). We use an unobtrusive and robust sewn-based connection (b), which withstands high deformation gestures (c). The force distribution values of the gestures (d) are further processed for real-time classification with a hybrid gesture detection algorithm (e) to control a media player (f), for example.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Computing technologies have become mobile and ubiquitous and, as predicted by Mark Weiser <ref type="bibr" target="#b65">[66]</ref>, weave themselves into the fabric of everyday life. While many objects and surfaces have been augmented with interactive capabilities, including smart phones, tabletops, walls, or entire floors, making clothing interactive is still an ongoing challenge. Over the last few decades, a lot of research in wearable computing has focused on integrating sensors into textiles <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b49">50]</ref>. Most of the existing work in the design space of interactive clothing focuses on surface gestures, planar interactions, such as touch and pressure <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b12">13]</ref>. Basic deformation has also been shown with stretch <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b60">61]</ref> and rolling for 1D input <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>In this work, we introduce SmartSleeve, a deformable textile sensor, which can sense both touch and deformations in real-time. Our hybrid gesture detection framework uses a learning-based algorithm and heuristics to greatly expand the possible interactions for flexible, pressure-sensitive textile sensors as its unified pipeline senses both 2D surface gestures and more complex 2.5D deformation gestures. Furthermore, its modular architecture allows us to also derive new gestures through the combination with continuous properties like pressure, location, and direction. Thus, our approach allows us to go beyond the touchscreen emulation and basic deformations found in previous work. We particularly emphasize the opportunity to enable both isotonic and isometric/elastic input, as well as, state-changing interaction with integrated passive haptic feedback. This enables us to support a wide range of deformation gestures, such as Bend <ref type="bibr" target="#b20">[21]</ref>, Twist <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>, Pinch <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b16">17]</ref>, Shake <ref type="bibr" target="#b30">[31]</ref>, Stretch <ref type="bibr" target="#b30">[31]</ref>, and Fold <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b30">31]</ref>. We further explore the usage of multi-modal input modalities by combining pressure with deformation.</p><p>Summarizing, the main contributions of this paper are:</p><p>• A hybrid gesture detection pipeline that uses learningbased algorithms and heuristics to enable real-time gesture detection and tracking for flexible textile sensors.</p><p>Session: Phones &amp; Watches UIST 2017, Oct. 22-25, 2017, Québec City, Canada</p><p>• Two user studies that show the feasibility and accuracy of our gesture detection algorithm. • A flexible, resistive-pressure textile sensor, with a novel non-rigid connector architecture. We propose a sewn-based connection between the textile sensor and the electronics. • A set of novel interaction techniques, which arise from the combination of surface gestures, deformation gestures, and continuous parameters (pressure, location, and direction).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK Limited input gestures on textiles</head><p>Several empirical studies investigated how skin or textiles can serve as gestural input surfaces. More than touch <ref type="bibr" target="#b64">[65]</ref> reported an elicitation study in a non-technological environment that shows how a set of gestures, including touch, grab, pull, press, scratch, shear, squeeze, and twist, are preferably performed on the forearm or the hand. Lee et al. <ref type="bibr" target="#b30">[31]</ref> explores deformation-based user gestures by using various materials like plastic, paper and elastic cloth. Bending, folding, rolling, crumpling and stretching were suggested as possible deformations. Troiano et al. <ref type="bibr" target="#b61">[62]</ref> investigated how depth and elasticity of a display can be used to simulate deformation and provided a set of gestures including grabbing, pulling, pushing, twisting, pinching or moving.</p><p>While researchers presented diverse gesture sets appropriate for textile input spaces, several solutions focused on specific input gestures on textiles. Touch sensitive fabrics were used for a range of gestural input on trousers <ref type="bibr" target="#b22">[23]</ref>, pockets <ref type="bibr" target="#b46">[47]</ref> or sleeves <ref type="bibr" target="#b53">[54]</ref>. Stitch-based solutions detect bends and folds <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b13">14]</ref> by sensing interconnections between seams. Similarly, grabbing a fold at a specific angle is detected by using embroidered pads <ref type="bibr" target="#b16">[17]</ref>. GestureSleeve <ref type="bibr" target="#b53">[54]</ref> has an interesting approach for extending the input space of a smart watch to the sleeve, but only supports tap and stroke gestures. We choose to focus on a rich set of 2D touch and 2.5D deformation-based gestures on a single sleeve, to combine recent advances in empirical studies with current technological possibilities. We combine directional and pressure sensing that can deliver a wide range of novel interactions, supporting additional degrees of freedom with expressiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Facilitating deformation-based input with 2.5D</head><p>Pressure-sensitive input has been a topic of interest in the HCI community for several years now, with research efforts ranging from explorations of pressure as alternative input metaphor <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b57">58]</ref> to the development of pressure-sensitive input devices <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>. To date, pressure has been used for a variety of applications such as zooming, scrolling, text entry, or widget control <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. A comprehensive overview of existing work in the field, can be found in <ref type="bibr" target="#b66">[67]</ref>. However, these solutions are limited to a rigid form factor. In contrast, research in the domain of bendable interfaces (e.g., <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b54">55]</ref>) has demonstrated novel interaction techniques based on flexible sensing or input and output capabilities. Addressing this arising potential, SmartSleeve combines pressure-sensitive input with bending and stretching capabilities into a flexible input sensor that can form the basis for the design of more scalable, flexible, and transformable user interfaces <ref type="bibr" target="#b24">[25]</ref>.</p><p>Optical solutions leverage overhead cameras as in Photoelastic Touch <ref type="bibr" target="#b48">[49]</ref>, or structured light scanners as for deForm <ref type="bibr" target="#b11">[12]</ref>. While these solutions were able to sense deformations of a flexible surface or even clay deformations on the surface, they need space for the optical tracking system.</p><p>Actuated solutions such as <ref type="bibr" target="#b27">[28]</ref> are constructed of pins and servo motors. These approaches require space and power, as well as limits input due to their rigid structures. Ferromagnetic input solutions <ref type="bibr" target="#b26">[27]</ref> sense on base of a matrix of sensor coils (copper wire and permanent magnets). However, the form factor is limited, the sensor coils add weight and are more applicable for above-the-surface sensing.</p><p>Resistive solutions offer the potential of sensing deformations in thin form factors. UnMousepad <ref type="bibr" target="#b45">[46]</ref> is constructed of several layers (FSR surface, resistive layer, conductor, clear substrate). FlexSense <ref type="bibr" target="#b44">[45]</ref> is a thin-film sensing surface based on printed piezoelectric sensors. These solutions are already very thin by providing the ability of sensing deformations, but need a rigid backing.</p><p>SmartSleeve is designed to be worn directly on body, and thus needs to be fully flexible and soft, while having the capability to recognize a wide range of deformations. This is achieved by its thin textile form factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Enabling always-available micro-interactions</head><p>In order to help users to perform micro-interactions, which are short-time interruptions <ref type="bibr" target="#b0">[1]</ref>, researchers have proposed a variety of ways to enable easy and fast access to mobile devices and overcome the limited interaction space on small form factor devices. Muscle input tracks the muscle tension to sense gestures <ref type="bibr" target="#b47">[48]</ref>. Body-projected interfaces provide visual output, which is used for the interaction <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22]</ref>. Other approaches enlarge the interaction space by using sticky touch sensors <ref type="bibr" target="#b63">[64]</ref>, artificial skin <ref type="bibr" target="#b25">[26]</ref> or enhancing the interaction space of existing devices <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b12">13]</ref>. While all these approaches are very diverse, they are all location variant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real-time, continuous gesture recognition</head><p>A number of pressure based sensing have explored sport and activity tracking. Most closely related to our resistive textile hardware and nature of the signal are <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b69">70]</ref>. Although these techniques achieve good results, recognizing various types of gestures in a single classifier requires large amounts of training which is a laborious task. It further requires extensive handcrafted features especially for temporal information which is computationally expensive as well.</p><p>Typical learning-based gesture recognition approaches detect trained gestures. In this paper, we propose a hybrid algorithm of combining learning-based method with heuristics that are experimentally derived. This combination enables recognition of a wide variety of untrained classes with high accuracy at low computation cost, and shows robustness across different users and sessions.</p><p>More related to our approach is the Pose Recognition mechanism in <ref type="bibr" target="#b2">[3]</ref> that distinguishes five body poses on the floor. We demonstrate how to extend a similar approach on clothing to derive 13 motion gestures from three trained classes of static ones.</p><p>In our work, we are specifically motivated to embrace the challenge of designing a low power algorithm that can seamlessly run in real-time on the limited hardware resources available in wearables. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Session</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensor Design</head><p>The SmartSleeve sensor builds on prior work <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b31">32]</ref>, that introduced pressure-sensitive textile sensors which consist of three layers of fabric. We will outline how this technology can be used as clothing to enhance wearers input possibilities without feeling rigid connection wires or other components added to the fabric.</p><p>All layers of SmartSleeve are equally bidirectionally stretchable and deformable. The top and bottom layers are made of Narrow Stripe Zebra fabric distributed by HITEK * , characterized by alternating strips of conductive and non-conductive fabric, see Figure <ref type="figure" target="#fig_0">2</ref>. The strips are 9 mm wide each. The zebra-fabric layers are orthogonally aligned to form a matrix. The middle layer consists of a pressure sensitive fabric (EeonTexTM † LTT-SLPA 20 k). It has a slightly larger size to prevent the two conductive layers from shorting. Sandwiching all three layers creates a deformable and stretchable pressuresensing matrix, which can be used to envelop complex 3D geometries. The three loose layers were stitched together along one side of the sensor to prevent the sensor grid from shifting.</p><p>The sleeve constricts at the forearm part of the sleeve, which would lead electrical shortcuts. To prevent adjacent connections from shorting, an additional stretchable non-conductive fabric has been sewn lengthwise on the conductive layer, which conducts lengthwise (cf. Figure <ref type="figure" target="#fig_0">2 b</ref>). SmartSleeve is designed to cover the complete forearm and half of the upper arm. Even though this sensor technology can be easily scaled up to detect other body regions, prior work has shown that this region is most comfortable for interactions. The sleeve is designed to fit a human with a wrist perimeter size of 16 cm, elbow perimeter of 26 cm and an upper arm perimeter size of 26.5 cm. Early tests have shown that the sleeve has to fit tightly to reduce failure of short cutting adjacent wires, but not too tightly, in order to support deformation gestures. The sensor itself consists of 24 rows (around the arm) and 15 columns (lengthwise), resulting in a total of 360 pressure sensor spots with a sensor density of 1.66 sensors/square inch. SmartSleeve can be worn directly on the skin. To prevent errors from the influence of skin moisture, it was usually worn over a long-sleeved tight-fitting running shirt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unobtrusive and Robust Sewn-Based Connection</head><p>In this section, we contribute an unobtrusive and robust method to connect not-rigid, stretchable textiles with the rigid electronics. Prior work has used rigid snap buttons <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b31">32]</ref> to connect textile with electronics. However, using rigid connections negatively affects the comfort of the sleeve and its robustness. Therefore we explored alternative methods to connect textiles with electronics hardware.</p><p>Yarn would be the favourable connection due to its surface and shape behavior. Although many companies produce and sell conductive yarns ‡ , very few of these yarns withstand the soldering temperature, which is required to connect the yarns to the PCB board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conductive fabric</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-conductive fabric</head><p>Non-isolated wire Isolated wire A possible alternative is solderable yarn § . Although these yarns are highly conductive, they are not insulated, which makes them unsuitable for our design as they would cause shortcuts. Previous research has also shown several ways to insulate conductive yarns by "couching", iron-on techniques or fabric paint <ref type="bibr" target="#b4">[5]</ref>. However, the tight sleeve needed a solution which preserves the look and feel, as well as, the comfort of use as much as possible.</p><p>Therefore, we opted for basing the connector on a wire with a small diameter which is conductive and insulated. During our experiments with different wires, we found the Road Runner/Verowire wire to be the most promising one. These copper wires are normally used for repairing or correcting printed circuit boards. The wire has a small diameter of 0.15 mm, which makes it very deformable. It is coated in solderable enamel or self fluxing polyurethane, which acts as an insulator. The coating can be removed when a high temperature is applied (400-430 • C). Hence, before sewing, we use the solder iron to remove 3 cm of insulation.</p><p>A first method consists of handsewing the connections. A close-up of one connection is depicted in Figure <ref type="figure" target="#fig_1">3</ref>. It consists of 3 cm of non-insulated wire that is affixed using a stitch to a row or a column strip of the zebra fabric. Although this stitch itself is not stretchable, it requires little area and is therefore straightforward to be sewn by hand.</p><p>In addition to the manual fabrication, we also performed initial tests with a sewing machine using different stitching types usable for elastic materials, including Zig Zag, Double Overlock, and Super Stretch, see Figure <ref type="figure" target="#fig_2">4</ref>. Straight stitches or stitches which are not adapted for elastic materials would either tear the yarn or reduce the fabrics elasticity. We found that the wire resists enough tension to be sewn with a Zig Zag stitch. Therefore, a non-conductive yarn was used as top thread and the wire as bobbin thread <ref type="bibr" target="#b10">[11]</ref>. In this way, the bobbin thread can easily float on the back side of the stitch without passing through the fabric substrate when using the machine at maximum speed. These different stitching types have different benefits and limitations. As the wire is stiff, the equal stitch distances and the little use of yarn of the Zig Zag stitch preserve the comfort of use as much as possible. For the Super Stretch stitch, the yarn tension was raised to maintain the elasticity of the stitch. Otherwise, the wire would float in a straight line, which means that the stitch would no longer be elastic. This is due to the differences in the yarn elasticity between regular yarn (top) and wire (bobbin). Because of that, the top yarn can tear more easily. The Double Overlock keeps its typical pattern without making any changes regarding yarn tension. Nevertheless, we would not recommend to use this stitch as it needs more yarn, which makes the fabric stiffer and thus reduces the comfort of use. In conclusion, we would suggest to use the typical Zig Zag stitch, as the pattern maintains the comfort of use. Due to the simplicity of the pattern it is easily adjustable in its width and it is sewable with the predefined yarn tension and thus less vulnerable for tearing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zig Zag Double Overlock</head><note type="other">Super Stretch</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Driver Electronics</head><p>SmartSleeve is based on a resistive tactile sensor. This type of sensor is subject to various sources of errors, such as crosstalk, which affect the accuracy of measurements and the gesture recognition. We evaluated different measurement principles and algorithms to determine the best solution to yield high accuracy and reduced crosstalk. First we analyzed how our system behaves with a solution without crosstalk reduction <ref type="bibr" target="#b52">[53]</ref>. Further, we evaluated the effects of grounding for crosstalk reduction <ref type="bibr" target="#b9">[10]</ref>, the zero potential method <ref type="bibr" target="#b55">[56]</ref> and virtual grounding <ref type="bibr" target="#b51">[52]</ref>, the multiplexer op-amp assist approach <ref type="bibr" target="#b50">[51]</ref>, and the resistive matrix approach <ref type="bibr" target="#b56">[57]</ref>.</p><p>Measurement Principle Average Error Without reduction <ref type="bibr" target="#b52">[53]</ref> 34.5% Grounding <ref type="bibr" target="#b9">[10]</ref> 32.1% Virtual Grounding <ref type="bibr" target="#b51">[52]</ref> 42.6% Multiplexer &amp; Op-Amp assisted approach [51] 10.5% Resistive Matrix Approach <ref type="bibr" target="#b56">[57]</ref> 0.93% As depicted in Table <ref type="table" target="#tab_2">2</ref>, the Resistive Matrix Approach yielded the best results and was therefore implemented in our system. The measurement electronics consist of a microcontroller, one single pole double throw switch, four multiplexers and four shift registers. The shift registers are daisy-chained so that they work as one big shift register. The shift register applies ground potential to the measured column while all other columns are connected to high potential. Whenever the shift register is triggered, the low level jumps to the next column. Multiplexers are connected to the row electrodes to forward single lines to the ADC. Each single sensor spot is measured separately, which means starting from the constant resistors which are mounted on the PCB to the first cells in the row and first column to all others. Then all other sensors gets measured row by row.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTERACTION TECHNIQUES</head><p>The unique SmartSleeve features enable a wide variety of textile interactions. The sensor's large input surface affords input on multiple body locations and with both fine and gross gestures. The sensor resolution enables both conventional 2D Surface Gestures and 2.5D Deformation Gestures. The high pressure resolution provides continuous force sensing and improves accuracy for detection of deformation-based gestures. The design and implementation of the sleeve is based on previous work <ref type="bibr" target="#b18">[19]</ref>, which has shown that the forearm is the most comfortable position to interact with.</p><p>Based on these properties, we composed a set of candidate gestures and conducted several brainstorming sessions. The candidate gestures were then refined in an iterative design process through several ideations with external participants and two pilot studies, including a guessability study. The result of this iterative process is a set of nine types of gestures, cf. Figure <ref type="figure">5</ref>, where eight of them have been discussed in previous research. Surface Gestures are planar gestures, which are performed on the textile, similar to conventional touch gestures.  <ref type="bibr" target="#b15">[16]</ref> Film × × × × Flexy <ref type="bibr" target="#b62">[63]</ref> Film × iSkin <ref type="bibr" target="#b63">[64]</ref> Film × × × × × Pinstripe <ref type="bibr" target="#b28">[29]</ref> Textile × GestureSleeve <ref type="bibr" target="#b53">[54]</ref> Textile × × Deformable displays <ref type="bibr" target="#b30">[31]</ref> Textile <ref type="bibr" target="#b61">[62]</ref> Textile o o Grabbing at an angle <ref type="bibr" target="#b16">[17]</ref> Textile × AugmentedForearm <ref type="bibr" target="#b35">[36]</ref> Textile [ <ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b53">54]</ref>. SmartSleeve, however, provides a unified sensing framework which allows us to detect all of them within a single pipeline, as shown in Table <ref type="table" target="#tab_4">3</ref> . Furthermore, most of the gestures can be done at any location on the sleeve, in contrast to previous work, which restricts gestures to smaller, dedicated, instrumented areas.</p><formula xml:id="formula_0">o o o o o o Elastic displays</formula><formula xml:id="formula_1">× SmartSleeve Textile × × × × × × × × × × × × ×</formula><p>In addition to classifying a gesture, SmartSleeve detects three properties: The Location (L) where the gesture is performed on the sleeve, its Direction (D) and its Pressure (P) intensity. Note that not all gestures can use all properties: the Bend gesture, for example, can detect the pressure intensity, but its location is fixed at the user's elbow joint. Overall, these properties improve the quality of the gesture recognition, but they can also be used as design parameters. Using a property like Direction considerably expands the possible gesture set. To make use of these properties for certain gestures, we implemented a hybrid gesture detection approach, which takes advantage of the properties where appropriate. In total, our gestures set includes 22 gestures (7 Deformation Gestures + 2 Surface Gestures + 1 derived Deformation Gesture + 12 derived Surface Gestures) as shown in Figure <ref type="figure">5</ref>. We will now discuss the Surface Gestures and Deformation Gestures in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surface Gestures</head><p>Previous work has shown that users tend to transfer conventional multi-touch gestures to other modalities -especially for standard commands <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b61">62]</ref>. Therefore, it was necessary to support a broad set of Surface Gestures, as depicted in Figure <ref type="figure">5</ref>. By making use of location, direction, and pressure properties, we are able to derive even more gestures, as shown in Figure <ref type="figure">5</ref>. In the case of the derivatives, we distinguish between the following: Swipe 2D motion with the finger or hand on the sleeve affords relative or absolute positioning. Thus, the system can support traditional touch interactions, where surface interactions are mapped to, e.g., navigation, scrolling and panning. The ability to distinguish between finger and hand makes it possible to differentiate between coarse and fine control. In addition, spatial differentiation between input regions can extend the interaction space. For example, in a 3D modelling application, a movement across the forearm could mean a rotation around the y-axis, while the same movement across the lower arm could be recognized as a rotation around the x-axis. Our eyes-free media player uses finger left/right swipes to skip forward/backward in a track, while a left/right swipes with the hand changes track. When our media player is used with visual feedback, finger motion can be used for cursor control, and swipe for menu option navigation.</p><p>Rub 1D back-and-forth motion with the finger or hand resembles the metaphor of scratching something out with a pen. Thus, we found it attractive to map it to deletion. It could be used for deletion of an element, like dismissing a message or deleting a calendar entry <ref type="bibr" target="#b67">[68]</ref>. In addition, the pressure intensity can be used to delete one or a whole set of items at once. In our media player, rubbing removes the current track from the playlist.</p><p>Spread/Close These gestures are widely used in "pinch-tozoom" interactions on multi-touch devices. They are derived from the Finger gesture and make use of location and direction (see Figure <ref type="figure">5</ref>). While these gestures use multiple fingers, the algorithm is the same. This interaction is applicable to scalable interfaces with visual feedback, such as, for map navigation, and image manipulation. These commands (except spreading and closing) can be performed by one finger, multiple fingers, or the full hand-depending on the gesture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deformation Gestures</head><p>In addition to Surface Gestures, SmartSleeve enables a wide range of deformable gestures. The thin and elastic textile sensor material affords freeform manipulation and deformation, while our sensing technique detects gestures, state changes, and continuous manipulation.</p><p>Twist Pinching the textile and twisting it affords rotational control. The analogy to a physical knob makes it suitable for actions that map to clockwise or counterclockwise motion. In our media player, we use this gesture to increase/decrease the volume. The ability to sense location, also allows multiple virtual knobs along the textile-for example, to control an equalizer or left/right balance. Pressure might be used to control the rate (light touch would change the value more slowly). The physical constraints that prevent the gesture to be rotated infinitely match the physical affordances of control knobs that map to a value range. Our sensor currently does not support infinite rotation, which can be found in scroll wheels, or continuous rotary encoders.</p><p>Push Pushing the sleeve up can be treated as a state change, e.g., to hide information <ref type="bibr" target="#b35">[36]</ref>. The compressed sleeve provides implicit visual and tactile feedback about the state. Our media player uses this state to toggle mute, or to hide the UI or media if used with visual feedback.</p><p>Fold Folding the sleeve is another way to change state. Here, we rely on the difference in operation to distinguish it from Push. While the end result may look similar, this operation requires careful effort to perform. With our media player, we map this operation to entering recording mode.</p><p>Twirl Twirling the textile around the finger requires intentional coordination. It uses the metaphor of the "reminder knot" around a finger. We use it to assign importance to the current item in the interface. The media player lets users rate a track by assigning a "star" or "like" with the gesture. When used with an audio book, podcast or radio show, it sets a bookmark. One could also imagine saving the currently playing voice mail message, or using it to record a voice memo. Location for the Twirl can be used to later enable retrieval with random access.</p><p>Grasp Grasping consists of the user grabbing the textile and pulling it together into the fist. We use it as a metaphor for retrieval. This, for example, allows us to complement Twirl with a mechanism for activating a saved item. The location can be mapped to specify which saved item to retrieve.</p><p>Shake Shake is a derived gesture from Grasping (cf. Figure <ref type="figure">5</ref>). The metaphor is based on grabbing a container with objects and shaking it. We map it to shuffling the tracks in our media player. Other considered mappings would be to clear the list or to close the application <ref type="bibr" target="#b30">[31]</ref>.</p><p>Stretch Stretching consists of pulling on the textile at a specific location. It affords elastic input as the textile retracts when released. We use the metaphor of turntable control, where stretching controls playback speed in our media player.</p><p>Stretching it towards the user increases the speed, while pulling it away decreases the speed.</p><p>Bend Bending of the elbow is an example of the implicit sensing that is possible with our technique. As this motion is part of the user's natural movement, we would need to use a disambiguating mechanism, e.g., pressure or combination with another gesture, to activate it if used as an explicit command.</p><p>Another opportunity is to use it as implicit input. For our media player, we have explored using the bending that occurs from arm swinging while running as a way to detect the appropriate tempo for the music playlist.</p><p>Most of our gestures, can be recognized at different sensor locations and on different parts of the anatomy (e.g., forearm, elbow, upper arm). Some gestures are naturally limited by mechanical, ergonomic or physical constraints. For example, gestures like Push, Fold, Twirl and Stretch are performed at the end of the sleeve. Gestures like Bend or Twist are limited to the user's physical abilities.</p><p>These examples illustrate how 2D surface gestures, 2.5D deformation gestures, and the three continuous properties (location, direction, pressure) have the opportunity to greatly expand the opportunities for linking and mapping information while taking into account nuanced properties, such as, recency and importance <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b19">20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HYBRID GESTURE DETECTION ALGORITHM</head><p>Our novel algorithm addresses the challenges of learningbased methods that need extensive training and extraction of hand-crafted features for class-label prediction. To alleviate these issues, we combine the results from the trained model with a heuristic-based approach that relies on a set of rules. Heuristic-based models provide a unique capability to react to untrained classes. So, we can train a much smaller set of trained gestures and achieve a wide variety of different interactions.  Figure <ref type="figure" target="#fig_3">6</ref> presents the entire SmartSleeve gesture detection pipeline. Our approach has some similarities with the method used in GravitySpace <ref type="bibr" target="#b2">[3]</ref>. Similarly, we reduce a 3D problem to a 2D problem by constructing a force image using the raw sensor matrix data. Next, we construct a force image with a size of 24 × 15 px with an overall framerate of 30 fps. Our algorithm is training a classifier on a per-frame-basis. Similar to the approach Type-Hover-Swipe <ref type="bibr" target="#b59">[60]</ref>, we have developed a simple filter, which averages the current sample with the previous ten samples to handle the false deformations on the SmartSleeve. Consequently, we can stabilize the natural tremor of hands and obtain information. In addition, we leverage our continuous gesture tracking mechanism for di-rectional information. Particularly, we incorporate the results from learning-based algorithm and heuristic-based approach to reduce the training of gestures by half as well as decrease computationally expensive feature extraction.</p><p>Preprocessing and Feature Extraction Initially, we convert the raw sensor data to a grayscale force image. By applying a threshold we remove the noise. Further, we specify the foreground and background on an individual pixel to search for points of interest, which in turn results in the loss of the pressure information. However, this information is later recovered by calculating the average force from the raw sensor data, once the Region of Interest (RoI) is located. In the next step, we apply bilinear upscaling and a Gaussian filtering for smoothing the raw force image. The RoI is selected as a mask inside the bounding box using the blob detection model. We use the contour detection algorithm <ref type="bibr" target="#b8">[9]</ref>, which makes the gesture classification space invariant. The removal of the pressure information from the force image yielded significant improvements in terms of classification accuracy during an informal pre-study with different users. Additionally, it helps us reducing the number of training trials, as the processed images for feature extraction appear similar even when the applied force changes up to a certain limit for a particular gesture during the training phase.</p><p>As all the regions are highly discriminative (see Figure <ref type="figure" target="#fig_4">7</ref>), we only compute a simple histogram and a set of properties of the contour's bounding box, including height, width, area, and perimeter, as features for the classification without any further processing.</p><p>Classifying gestures based on image analysis In order to identify the gestures, we took a subset from Figure <ref type="figure">5</ref> based on their variances, namely Finger, Hand, Bend, Twist, Push, Grasp, Stretch, Twirl, and Fold. We experimented using the image features which we extracted above for these nine gestures as input to different classifiers and found that a Support Vector Machine (SVM) yields the most promising results, with parameters C = 1.0 and kernel = RBF, optimized using a grid search with cross-validation implementation provided by the scikit-learn <ref type="bibr" target="#b38">[39]</ref> machine learning library. The model assigns probabilities for each type of trained gesture.</p><p>Detecting untrained gestures using heuristics We extend our frame-by-frame learning-based algorithm for recognizing dynamic (untrained) gestures by adding a set of rules based on the classifier generated probability distribution. This idea is inspired by the Pose Recognition technique used in GravitySpace <ref type="bibr" target="#b2">[3]</ref>. In our implementation, we combine the highest probability with net force and properties of the blob (position and size) to produce more gestures (finger swipe up, down, left, right, and rub; hand swipe up, down, left, right, and rub; spread; close; shake). As mentioned earlier, we deduce the normalized force from the raw sensor data within a blob and our frame averaging helps us to track the blob within successive image frames.</p><p>Specifically, to identify the direction (up, down, left, or right) of the gesture, we simply store the consecutive blob's centroid coordinates in a buffer and compute the slope through each pair of points. Additionally, we implemented a consistency check algorithm to overcome the accidental deviations in slope values since a user might not be able to draw a straight line (e.g., left to right gesture) and the slope might have some unintended  motions, which can be interpreted as an up-or down-gesture.</p><p>We fix this problem by splitting the whole gesture into overlapping regions and further ignore small deviations. Probability distributions of grasp and hand from the classifier help determine shake and rub respectively, the blob's centroid coordinates change significantly during rub and shake, cf. Figure <ref type="figure" target="#fig_5">8</ref>, (a) and (b) compared to other gestures, we use the concept of first order derivative from calculus to compute this rate of change, since the obtained value is scalar, we make it absolute and take an average on a finite size to avoid false positives. Gestures including spread and close exploit the classification probability of finger combined with the linear change in area of contour (see Figure <ref type="figure" target="#fig_5">8</ref> (c) and (d), we measure the trend of increment or decrement with simple subtraction between pairs of consecutive area values. Afterwards, we assess the average to determine the action robustly wherein a positive value signifies expansion, and vice versa. Summarizing, our real-time recognition pipeline provides continuous gesture detection. In particular, if we attempt a swipe gesture, we have an additional component of changing pressure along the line. This feature allows us an additional input modality and could be used for controlling speed in activities like fast forward in a media player.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EVALUATION</head><p>Two empirical studies were conducted to evaluate our hybrid gesture detection algorithm. In the first experiment, we evaluated the learning based algorithm and we were primarily interested in finding out if the trained gesture set would also be position-invariant. On the other side, in the second experiment, we were focusing on the evaluation of the heuristic approach, where we wanted to find out if the heuristics we implemented will help to enrich the set of gestures while training only a subset of gestures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Six unpaid volunteers (3 female), 23-25 years old (x = 24.33, SD = 0.94), all right-handed were recruited from the local university. All participants used 2D touch interfaces on a daily base, but none of them had experiences with smart clothing interfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Apparatus</head><p>The study was conducted in a quiet room, where the participants were wearing the SmartSleeve tightly fitted as depicted in Figure <ref type="figure" target="#fig_6">9</ref>. The instructions were displayed on LG 24 1920 × 1200 pixel IPS LCD screen. In the first experiment, we performed a gesture recognition experiment, where we wanted to find out if our approach also provides good accuracy results even if the gestures have to be performed on different locations of the textile.</p><p>Design At the beginning of the experiment, the nine different gesture types (i.e., Finger, Hand, Twist, Bend, Stretch, Fold, Push, Grasp, Twirl) were demonstrated to participants for clarity. Thereafter, participants were instructed to perform four trials of each gesture type in randomized order to train the gesture recognition engine. The four trials had to be performed on the same location, which was marked accordingly. The training phase took approx. 15 minutes. Next, participants were asked again to perform eight trials of each gesture type on the (a) same location (marked position) as well as on (b) an arbitrary. The order of the gesture type was randomized and presented accordingly on the on-screen prompts (see Figure <ref type="figure" target="#fig_6">9</ref>). The on-screen prompt further showed whether the gesture was recognized correctly or wrongly. The testing phase took about 35 minutes per participant. Collected measurements included error rate. Results Our approached reached an average accuracy of 92.0% when the system is trained and tested by the same participant on the same location, cf. Figure <ref type="figure" target="#fig_7">10</ref>. Similar results have been achieved when the system is trained and tested by the same participant on different location with an average of 86.9%, cf. Figure <ref type="figure">11</ref>.</p><p>In more detail, the finger gesture achieved an average recognition rate of 96.4% (SD = .05), 100% (SD = 0.0) for the bend gestures, and 83.6% (SD = .167) for the twirl gestures. Using different locations, an average recognition rate of 92.6% (SD = .121) for the finger gestures, 98.0% (SD = .05) for the bend gestures, and 80.0% (SD = .244) for the twirl gestures was achieved.</p><p>A repeated measures ANOVA was carried out and revealed a significant effect for the location (F 1,35 = 6.019; p &lt; .05) as well as gestures (F 8,35 = 5.865; p &lt; .001). Finally, posthoc analyses on the main effects were conducted based on paired-samples t-tests using the Holms sequential Bonferroni approach. However, no significant differences could be found. In the second experiment, we evaluated the performance of the heuristics of the gestures using the parameters pressure, location and direction. We therefore wanted to find out if we are able to recognize more complex gestures, which are based on simple ones.</p><p>Design We evaluated the recognition implementation with the same participants. As all the used gestures were based on the gestures described before, no training data was required for this evaluation. Again, we showed each new gesture on a screen and the participant performed it accordingly.</p><p>For the second experiment, we chose a subset of the gesture classes (i.e., Finger, Hand, and Grasp), as all of them are making use of all the used parameters (pressure, location and direction), cf. Figure <ref type="figure">5</ref>. Every participant performed each gesture 5 times in total, resulting in an overall of 80 trials per participant. For the gesture class Finger, for instance, participants had to perform the gestures swipe right, swipe left, swipe up, swipe down, rub, spread, and close with the index finger on an arbitrary location of the SmartSleeve. The same gestures were performed using the Hand gesture class. Finally, participants also grasped and shaked the sleeve. All the gestures were counterbalanced to avoid training effects.</p><p>Results Overall, 84% (SD = 0.11) of all gestures were correctly identified. In more detail, the simple gesture detection (swipe right, swipe left, swipe up, swipe down) using the finger achieved an average recognition rate of 83% (SD = .06), while we achieved 97% for the spread gesture. Only most complex deformation gestures, like the shake achieved a lower average recognition rate of 73%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Technical Evaluation</head><p>To evaluate the pressure sensing behaviour of the sensor we conducted a technical study, where we applied mechanical stress onto the surface of the SmartSleeve sensor.</p><p>Apparatus The sensor got stationary mounted onto a flat deformable Styrofoam surface. A hemispherical thrust plate with a 4 mm diameter applied mechanical stress onto the surface of the sensor. The resistance change of the sensor was measured 10 times with a force of 25 g, 50 g, 75 g, 100 g, 250 g, 500 g, 1000 g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As shown in Figure <ref type="figure" target="#fig_10">12</ref>, the sensor demonstrate promising sensing behaviors from 50 g to 500 g. Underneath 50 g the sensor demonstrates high resistance changes as expected, however according to the loose stacking of the sensor the standard deviation is high. Beyond 500 g the resistance of the sensor shows slight changes, therefore disregard this area in SmartSleeve as well.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION &amp; LIMITATIONS</head><p>The SmartSleeve was trained and tested for a period of four months in total. During that time, the sensor was used approximately 120 sessions by several people who also provided early feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Durability</head><p>We observed that the sensor signal did not change significantly even under different pressure conditions. Regarding the connections, we implemented two versions. The first version of our sensor had a rough rigid connection using flat ribbon cables (2.54 mm pitch) connecting the sensor PCB board with the textile. The connections of this prototype broke relatively easily, as the cable was stiff and heavy and the soldering spots were comparably small. Further, having this rigid soldered connection directly on the sleeve leads to breaks, while performing a highly deformable gesture activity. The second version of SmartSleeve with the new sewn connection (as introduced in this paper) was then tested for approximately three months.</p><p>During that time, the sleeve was used more than 100 times by different participants. Only three smaller issues had to be fixed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pressure Input</head><p>As the results of the evaluation show, SmartSleeve accurately recognizes 2D gestures (surface gestures) as well as 2.5D deformation-based gestures (deformation gestures) that are performed on the textile. Even though our algorithm takes advantage of pressure to detect 2.5D gestures, we have not evaluated the pressure itself for surface gestures. The high pressure resolution of the sensor could be used for enhancing surface gestures. Yet, as noted by Rendl et al. <ref type="bibr" target="#b43">[44]</ref>, pressure is a very subjective property and its perception differs from person to person. Therefore, we did not formally evaluate this aspect in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>False Positives</head><p>The evaluation and exploration of the sleeve show that elbow movements (bending) can result in false positives and lower accuracy, while flexion and extension of shoulder or wrist have no significant influence. Surface gestures are more prone to false activations, given that the more specific deformations occur less frequently than accidental touches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Three-layer Approach</head><p>While the three-layer approach is a practical solution for a tactile sensor that measures signals via a resistive approach, it was problematic in a few instances when the user grasped only the top layer for performing a gesture. Moreover, a three-layer sandwich is thicker, decreases the comfort of use and needs more implementation effort. We are currently developing a one-layer solution to address these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tailored Clothing</head><p>SmartSleeve is tailored for a person having a wrist perimeter of 16 cm, an elbow perimeter of 26 cm and an upper arm perimeter of 26.5 cm. Although all three layers are bidirectionally stretchable, observations with other participants have shown that the sleeve itself has to fit tightly, as it has to follow the rotation of the arm. If only the upper arm and elbow are fitting well, but the sleeve itself is loose on the lower arm, people can rotate the underarm inside the sleeve, which could lead to reduced accuracy. Generally, as SmartSleeve is a personal wearable, it should be tailored for each individual person to enable rich input on clothes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS AND FUTURE WORK</head><p>We introduced SmartSleeve, a flexible textile sensor that senses both surface gestures and deformation gestures in real-time.</p><p>We provided a detailed description of our hybrid gesture detection pipeline that uses learning-based algorithms and heuristics to enable real-time gesture detection and tracking. Its modular architecture, combined with a large sensor size, a high spatial resolution and a high pressure resolution, allowed us to derive new gestures through the combination with continuous properties like pressure, location, and direction. Finally, we reported on the promising results from our evaluations which demonstrated real-time classification of 9 gestures with 89.5% accuracy.</p><p>In future work, we plan improvements to our SmartSleeve hardware, as the current proof-of-concept implementation relies on a wired PC connection for data transmission and power supply. Given the current hardware's dimensions (102 × 53 × 25mm), miniaturization of the electronics would allow us to embed it in the textile. Therefore, we are developing a version, which is completely mobile with wireless connectivity. Additionally, we are working on a single-layer textile sensor implementation and developing the algorithm on a hardware level. We also want to explore how SmartSleeve performs in everyday scenarios and how environmental influences, like humidity, affect the sensor. Our initial experiments show that the sensor withstands machine washing at low temperature and slow spin, however, more formal evaluations should be performed to assess its durability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The sandwich architecture of the SmartSleeve sensor (a). The bottom layer (b) and top layer (d) have conductive and non-conductive threads. In-between is the the pressure-sensitive layer (c).</figDesc><graphic coords="3,50.40,557.39,104.54,104.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A hand-sewn connection between the textile sensor and the electronics provides a more flexible connection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Fabricating the connection using a sewing machine, with Zig Zag, Double Overlock, or Super Stretch stitch.</figDesc><graphic coords="4,50.40,366.34,86.13,111.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The SmartSleeve gesture detection pipeline is based on six steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Training input frames after preprocessing.</figDesc><graphic coords="8,102.64,67.30,186.99,93.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Change in contour's centroid during rub and shake (a, b), and change in area of the bounding box while performing spread and pinch over time (c, d).</figDesc><graphic coords="8,316.86,386.41,243.76,232.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Apparatus used in both experiments consisted of the participant-worn SmartSleeve and a screen were gestures, instructions and feedback were displayed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The standard confusion matrix for the Smart-Sleeve hardware using the same location.</figDesc><graphic coords="9,77.35,273.23,186.89,186.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :Experiment 2 :</head><label>112</label><figDesc>Figure 11: The standard confusion matrix for the Smart-Sleeve hardware using an arbitrary location on the arm chosen by the participants.</figDesc><graphic coords="9,344.27,78.58,186.16,185.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Pressure Sensing under different stress levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>: Phones &amp; Watches UIST 2017, Oct. 22-25, 2017, Québec City, Canada SMARTSLEEVE SmartSleeve</head><label></label><figDesc>, pictured in Figure1, is a fully wearable and highly deformable textile sensor that covers a large surface, features a high amount of sensors, and offers a high pressure resolution. In this section, we present the design of the sensor and the rapid fabrication. Table1provides an overview of the characteristics of the SmartSleeve sensor.</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Force detected</cell><cell>50-500 g</cell></row><row><cell>Sample rate</cell><cell>100 Hz</cell></row><row><cell>Sensor resolution</cell><cell>1.66 sensor/inch</cell></row><row><cell>Sensor count</cell><cell>360 sensors</cell></row><row><cell>Weight in total</cell><cell>124 g</cell></row><row><cell>Length of the sleeve</cell><cell>40 cm</cell></row><row><cell>Upper arm perimeter</cell><cell>26.5 cm</cell></row><row><cell>Elbow perimeter</cell><cell>26.0 cm</cell></row><row><cell>Wrist perimeter</cell><cell>16.0 cm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Sensor characteristics.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overview of the measurement principles.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The SmartSleeve gesture set compared with previous work (o = conceptional, × = functional).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Session: Phones &amp; Watches UIST 2017, Oct. 22-25, 2017, Québec City, Canada</head><label></label><figDesc></figDesc><table><row><cell>Wrist</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Elbow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Arm</cell><cell>Finger</cell><cell>Hand</cell><cell>Bend</cell><cell>Push</cell><cell>Twirl</cell><cell>Fold</cell><cell>Stretch</cell><cell>Grasp</cell><cell>Twist</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>‡ www.schoeller-wool.com, www.bekaert.com, www.statex.biz, www.araconfiber.com § High Flex 3981 7X1 Silver or High Flex 3981 Flat Braid Karl Grimm, www.karl-grimm.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Enabling Mobile Microinteractions</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ashbrook</surname></persName>
		</author>
		<ptr target="http://smartech.gatech.edu/handle/1853/33986" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Georgia Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Dissertation</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Back-of-device interaction allows creating very small touch devices</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerry</forename><surname>Chu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518995</idno>
		<ptr target="http://dx.doi.org/10.1145/1518701.1518995" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1923">2009. 1923</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">GravitySpace: tracking users and their poses in a smart room using a pressure-sensing floor</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Bränzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Holz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marius</forename><surname>Knaust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lühne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">René</forename><surname>Meusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Baudisch</surname></persName>
		</author>
		<idno type="DOI">10.1145/2470654.2470757</idno>
		<ptr target="http://dx.doi.org/10.1145/2470654.2470757" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">725</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Leah</forename><surname>Buechley</surname></persName>
		</author>
		<ptr target="http://www.mediamatic.net/36637/en/sensormania" />
		<title level="m">SensorMania -Notes from e-Fashion day</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<author>
			<persName><forename type="first">Leah</forename><surname>Buechley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Eisenberg</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00779-007-0181-0</idno>
		<ptr target="http://dx.doi.org/10.1007/s00779-007-0181-0" />
	</analytic>
	<monogr>
		<title level="m">Fabric PCBs, electronic sequins, and socket buttons: Techniques for e-textile craft</title>
		<imprint>
			<date type="published" when="2009-02">2009. feb 2009</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="133" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Leah</forename><surname>Buechley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kylie</forename><forename type="middle">A</forename><surname>Peppler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Eisenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasmin</forename><forename type="middle">B</forename><surname>Kafai</surname></persName>
		</author>
		<idno type="DOI">10.3726/978-1-4539-0941-6</idno>
		<ptr target="http://dx.doi.org/10.3726/978-1-4539-0941-6" />
		<title level="m">Textile messages : dispatches from the world of e-textiles and education</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Peter Lang. 246 pages</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Smart fabric sensors and e-textile technologies: a review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alison</forename><forename type="middle">B</forename><surname>Castano</surname></persName>
		</author>
		<author>
			<persName><surname>Flatau</surname></persName>
		</author>
		<idno type="DOI">10.1088/0964-1726/23/5/053001</idno>
		<ptr target="http://dx.doi.org/10.1088/0964-1726/23/5/053001" />
	</analytic>
	<monogr>
		<title level="j">Smart Materials and Structures</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">53001</biblScope>
			<date type="published" when="2014-05">2014. may 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Augmenting the mouse with pressure sensitive input</title>
		<author>
			<persName><forename type="first">Jared</forename><surname>Cechanowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pourang</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Subramanian</surname></persName>
		</author>
		<idno type="DOI">10.1145/1240624.1240835</idno>
		<ptr target="http://dx.doi.org/10.1145/1240624.1240835" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">1385</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A component-labeling algorithm using contour tracing technique</title>
		<author>
			<persName><forename type="first">Fu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun</forename><surname>Jen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2003.1227760</idno>
		<ptr target="http://dx.doi.org/10.1109/ICDAR.2003.1227760" />
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Soc</title>
		<imprint>
			<biblScope unit="page" from="741" to="745" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
	<note>In ICDAR</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Measurement errors in the scanning of piezoresistive sensors arrays</title>
		<author>
			<persName><forename type="first">D'</forename><surname>Tommaso</surname></persName>
		</author>
		<author>
			<persName><surname>Alessio</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0924-4247(98)00204-0</idno>
		<ptr target="http://dx.doi.org/10.1016/S0924-4247(98)00204-0" />
	</analytic>
	<monogr>
		<title level="j">Sensors and Actuators A: Physical</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="71" to="76" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-layer e-textile circuits</title>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">E</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaila</forename><surname>Bibeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucie</forename><surname>Mulligan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashton</forename><surname>Frith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cory</forename><surname>Simon</surname></persName>
		</author>
		<idno type="DOI">10.1145/2370216.2370348</idno>
		<ptr target="http://dx.doi.org/10.1145/2370216.2370348" />
	</analytic>
	<monogr>
		<title level="m">UbiComp. 649</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">deForm: an interactive malleable surface for capturing 2.5D arbitrary objects, tools and touch</title>
		<author>
			<persName><forename type="first">Sean</forename><surname>Follmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micah</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Ishii</surname></persName>
		</author>
		<idno type="DOI">10.1145/2047196.2047265</idno>
		<ptr target="http://dx.doi.org/10.1145/2047196.2047265" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">527</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using a touch-sensitive wristband for text entry on smart watches</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Sahami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niels</forename><surname>Henze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albrecht</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.1145/2559206.2581143</idno>
		<ptr target="http://dx.doi.org/10.1145/2559206.2581143" />
	</analytic>
	<monogr>
		<title level="m">CHI EA</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2305" to="2310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detecting Bends and Fabric Folds using Stitched Sensors</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Gioberto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Coughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaila</forename><surname>Bibeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">E</forename><surname>Dunne</surname></persName>
		</author>
		<idno type="DOI">10.1145/2493988.2494355</idno>
		<ptr target="http://dx.doi.org/10.1145/2493988.2494355" />
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="53" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MorePhone: an actuated shape changing flexible smartphone</title>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Nesbitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roel</forename><surname>Vertegaal</surname></persName>
		</author>
		<idno type="DOI">10.1145/2470654.2470737</idno>
		<ptr target="http://dx.doi.org/10.1145/2470654.2470737" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">583</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">PrintSense: a versatile sensing technique to support multimodal flexible surface interaction</title>
		<author>
			<persName><forename type="first">Nan-Wei</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Steimle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Olberding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Edward Gillian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshihiro</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Paradiso</surname></persName>
		</author>
		<idno type="DOI">10.1145/2556288.2557173</idno>
		<ptr target="http://dx.doi.org/10.1145/2556288.2557173" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1407" to="1410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Grabbing at an angle: menu selection for fabric interfaces</title>
		<author>
			<persName><forename type="first">Nur</forename><surname>Al-Huda Hamdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">R</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Kanth Kosuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Borchers</surname></persName>
		</author>
		<idno type="DOI">10.1145/2971763.2971786</idno>
		<ptr target="http://dx.doi.org/10.1145/2971763.2971786" />
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">OmniTouch: wearable multitouch interaction everywhere</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrvoje</forename><surname>Benko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1145/2047196.2047255</idno>
		<ptr target="http://dx.doi.org/10.1145/2047196.2047255" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">441</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Implications of location and touch for on-body projected interfaces</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haakon</forename><surname>Faste</surname></persName>
		</author>
		<idno type="DOI">10.1145/2598510.2598587</idno>
		<ptr target="http://dx.doi.org/10.1145/2598510.2598587" />
	</analytic>
	<monogr>
		<title level="m">DIS</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="543" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Where to locate wearable displays</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aubrey</forename><surname>Shick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518845</idno>
		<ptr target="http://dx.doi.org/10.1145/1518701.1518845" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">941</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On-body interaction: armed and dangerous</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shilpa</forename><surname>Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
		<idno type="DOI">10.1145/2148131.2148148</idno>
		<ptr target="http://dx.doi.org/10.1145/2148131.2148148" />
	</analytic>
	<monogr>
		<title level="m">TEI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Skinput: appropriating the skin as an interactive canvas</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Desney</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Morris</surname></persName>
		</author>
		<idno type="DOI">10.1145/1753326.1753394</idno>
		<ptr target="http://dx.doi.org/10.1145/1753326.1753394" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">453</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">FabriTouch: exploring flexible touch input on textiles</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chat</forename><surname>Wacharamanotham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Borchers</surname></persName>
		</author>
		<idno type="DOI">10.1145/2634317.2634345</idno>
		<ptr target="http://dx.doi.org/10.1145/2634317.2634345" />
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="59" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">One-point touch input of vector information for computer displays</title>
		<author>
			<persName><forename type="first">F</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Herot</surname></persName>
		</author>
		<author>
			<persName><surname>Weinzapfel</surname></persName>
		</author>
		<idno type="DOI">10.1145/965139.807392</idno>
		<ptr target="http://dx.doi.org/10.1145/965139.807392" />
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="210" to="216" />
			<date type="published" when="1978">1978. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Organic user interfaces: designing computers in any way, shape, or form</title>
		<author>
			<persName><forename type="first">David</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roel</forename><surname>Vertegaal</surname></persName>
		</author>
		<idno type="DOI">10.1145/1349026.1349037</idno>
		<ptr target="http://dx.doi.org/10.1145/1349026.1349037" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Implanted user interfaces</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Holz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tovi</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Agur</surname></persName>
		</author>
		<idno type="DOI">10.1145/2207676.2207745</idno>
		<ptr target="http://dx.doi.org/10.1145/2207676.2207745" />
	</analytic>
	<monogr>
		<title level="m">Session: Phones &amp; Watches UIST</title>
		<meeting><address><addrLine>New York, New York, USA; Québec City, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2012">2012. 2017. Oct. 22-25, 2017</date>
			<biblScope unit="page">503</biblScope>
		</imprint>
	</monogr>
	<note>CHI</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A reconfigurable ferromagnetic input device</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Hook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Villar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Izadi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1622176.1622186</idno>
		<ptr target="http://dx.doi.org/10.1145/1622176.1622186" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="51" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Haptic Edge Display for Mobile Tactile Interaction</title>
		<author>
			<persName><forename type="first">Sungjune</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kesler</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Follmer</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858264</idno>
		<ptr target="http://dx.doi.org/10.1145/2858036.2858264" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3706" to="3716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pinstripe: eyes-free continuous input anywhere on interactive clothing</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Moritz Wittenhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Lichtschlag</surname></persName>
		</author>
		<author>
			<persName><surname>Heller</surname></persName>
		</author>
		<idno type="DOI">10.1145/1978942.1979137</idno>
		<ptr target="http://dx.doi.org/10.1145/1978942.1979137" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1313">Jan Borchers. 2011. 1313</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PaperPhone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays</title>
		<author>
			<persName><forename type="first">Byron</forename><surname>Lahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Audrey</forename><surname>Girouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winslow</forename><surname>Burleson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roel</forename><surname>Vertegaal</surname></persName>
		</author>
		<idno type="DOI">10.1145/1978942.1979136</idno>
		<ptr target="http://dx.doi.org/10.1145/1978942.1979136" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1303">2011. 1303</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How users manipulate deformable displays as input devices</title>
		<author>
			<persName><forename type="first">Sang-Su</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sohyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bipil</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunji</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boa</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daeeop</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun-Pyo</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/1753326.1753572</idno>
		<ptr target="http://dx.doi.org/10.1145/1753326.1753572" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1647">2010. 1647</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">proCover: Sensory Augmentation of Prosthetic Limbs Using Smart Textile Covers</title>
		<author>
			<persName><forename type="first">Joanne</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Parzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Perteneder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teo</forename><surname>Babic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Rendl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anita</forename><surname>Vogl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Olwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Haller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2984511.2984572</idno>
		<ptr target="http://dx.doi.org/10.1145/2984511.2984572" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="335" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploring Pressure as an Alternative to Multi-Touch Based Interaction</title>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Mandalapu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Subramanian</surname></persName>
		</author>
		<idno type="DOI">10.1145/2407796.2407810</idno>
		<ptr target="http://dx.doi.org/10.1145/2407796.2407810" />
	</analytic>
	<monogr>
		<title level="j">IndiaHCI</title>
		<imprint>
			<biblScope unit="page">88</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">PressureText: pressure input for mobile phone text entry</title>
		<author>
			<persName><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pourang</forename><surname>Mak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><surname>Subramanian</surname></persName>
		</author>
		<idno type="DOI">10.1145/1520340.1520693</idno>
		<ptr target="http://dx.doi.org/10.1145/1520340.1520693" />
	</analytic>
	<monogr>
		<title level="j">CHI</title>
		<imprint>
			<biblScope unit="page">4519</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Making an impression: force-controlled pen input for handheld devices</title>
		<author>
			<persName><forename type="first">Sachi</forename><surname>Mizobuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinya</forename><surname>Terasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Turo</forename><surname>Keski-Jaskari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jari</forename><surname>Nousiainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matti</forename><surname>Ryynanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miika</forename><surname>Silfverberg</surname></persName>
		</author>
		<idno type="DOI">10.1145/1056808.1056991</idno>
		<ptr target="http://dx.doi.org/10.1145/1056808.1056991" />
	</analytic>
	<monogr>
		<title level="j">CHI EA</title>
		<imprint>
			<biblScope unit="page">1661</biblScope>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">AugmentedForearm: exploring the design space of a display-enhanced forearm</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Olberding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peen</forename><surname>Kian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suranga</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jurgen</forename><surname>Nanayakkara</surname></persName>
		</author>
		<author>
			<persName><surname>Steimle</surname></persName>
		</author>
		<idno type="DOI">10.1145/2459236.2459239</idno>
		<ptr target="http://dx.doi.org/10.1145/2459236.2459239" />
	</analytic>
	<monogr>
		<title level="m">AH</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pressure-Sensitive, Tactile Input Sensor</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Parzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathrin</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teo</forename><surname>Babic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Rendl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anita</forename><surname>Vogl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Olwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Haller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2851581.2890253</idno>
		<ptr target="http://dx.doi.org/10.1145/2851581.2890253" />
	</analytic>
	<monogr>
		<title level="m">FlexTiles: A Flexible, Stretchable, Formable</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3754" to="3757" />
		</imprint>
	</monogr>
	<note>CHI EA</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A haptic wristwatch for eyes-free interactions</title>
		<author>
			<persName><forename type="first">Jerome</forename><surname>Pasquero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">J</forename><surname>Stobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noel</forename><surname>Stonehouse</surname></persName>
		</author>
		<idno type="DOI">10.1145/1978942.1979425</idno>
		<ptr target="http://dx.doi.org/10.1145/1978942.1979425" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">3257</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Poupyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan-Wei</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiho</forename><surname>Fukuhara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><forename type="middle">Emre</forename><surname>Karagozler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Schwesig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><forename type="middle">E</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858176</idno>
		<ptr target="http://dx.doi.org/10.1145/2858036.2858176" />
		<title level="m">Project Jacquard: Interactive Digital Textiles at Scale. In CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4216" to="4227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Zoofing!: faster list selections with pressure-zoom-flick-scrolling</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Cockburn</surname></persName>
		</author>
		<idno type="DOI">10.1145/1738826.1738856</idno>
		<ptr target="http://dx.doi.org/10.1145/1738826.1738856" />
	</analytic>
	<monogr>
		<title level="m">OzCHI. 185</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Zliding: fluid zooming and sliding for high precision parameter manipulation</title>
		<author>
			<persName><forename type="first">Gonzalo</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravin</forename><surname>Balakrishnan</surname></persName>
		</author>
		<idno type="DOI">10.1145/1095034.1095059</idno>
		<idno>UIST. 143</idno>
		<ptr target="http://dx.doi.org/10.1145/1095034.1095059" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pressure widgets</title>
		<author>
			<persName><forename type="first">Gonzalo</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Boulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravin</forename><surname>Balakrishnan</surname></persName>
		</author>
		<idno type="DOI">10.1145/985692.985754</idno>
		<ptr target="http://dx.doi.org/10.1145/985692.985754" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Presstures: exploring pressure-sensitive multi-touch gestures on trackpads</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Rendl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Greindl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathrin</forename><surname>Probst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Haller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2556288.2557146</idno>
		<ptr target="http://dx.doi.org/10.1145/2556288.2557146" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="431" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">FlexSense: a transparent self-sensing deformable surface</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Rendl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Fanello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Parzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Zirkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Scheipl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Rothländer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Izadi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2642918.2647405</idno>
		<idno>UIST. 129-138</idno>
		<ptr target="http://dx.doi.org/10.1145/2642918.2647405" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The UnMousePad: the future of touch sensing</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Perlin</surname></persName>
		</author>
		<idno type="DOI">10.1145/1531326.1531371</idno>
		<ptr target="http://dx.doi.org/10.1145/1531326.1531371" />
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2009">2009</date>
			<publisher>ACM Press</publisher>
			<pubPlace>New York, New York, USA, 1</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">PocketTouch: through-fabric capacitive touch input</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Scott</forename><surname>Saponas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrvoje</forename><surname>Benko</surname></persName>
		</author>
		<idno type="DOI">10.1145/2047196.2047235</idno>
		<ptr target="http://dx.doi.org/10.1145/2047196.2047235" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">303</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Enabling always-available input with muscle-computer interfaces</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Scott</forename><surname>Saponas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Desney</forename><forename type="middle">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravin</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
		<idno type="DOI">10.1145/1622176.1622208</idno>
		<ptr target="http://dx.doi.org/10.1145/1622176.1622208" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">167</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">PhotoelasticTouch: transparent rubbery tangible interface using an LCD and photoelasticity</title>
		<author>
			<persName><forename type="first">Toshiki</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haruko</forename><surname>Mamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideki</forename><surname>Koike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Fukuchi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1622176.1622185</idno>
		<ptr target="http://dx.doi.org/10.1145/1622176.1622185" />
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">How To Get What You Want</title>
		<author>
			<persName><forename type="first">Mika</forename><surname>Satomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Perner-Wilson</surname></persName>
		</author>
		<ptr target="http://www.kobakant.at/DIY/?cat=24" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Québec City, Canada new discrete circuit for readout of resistive sensor arrays</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Bhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anita</forename><surname>Aggrawal</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.sna.2008.10.013</idno>
		<ptr target="http://dx.doi.org/10.1016/j.sna.2008.10.013" />
	</analytic>
	<monogr>
		<title level="m">A Session: Phones &amp; Watches UIST</title>
		<imprint>
			<date type="published" when="2009">2009. 2017. Oct. 22-25, 2017. 2009</date>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="93" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">2011a. Virtual ground technique for crosstalk suppression in networked resistive sensors</title>
		<author>
			<persName><forename type="first">Raghvendra</forename><surname>Sahai Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Bhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navneet Kaur</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muralidharan</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSEN.2010.2060186</idno>
		<ptr target="http://dx.doi.org/10.1109/JSEN.2010.2060186" />
	</analytic>
	<monogr>
		<title level="j">IEEE Sensors Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="432" to="433" />
			<date type="published" when="2011-02">feb 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Analysis of crosstalk in networked arrays of resistive sensors</title>
		<author>
			<persName><forename type="first">Raghvendra Sahai</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navneet Kaur</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Bhan</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSEN.2010.2063699</idno>
		<ptr target="http://dx.doi.org/10.1109/JSEN.2010.2063699" />
	</analytic>
	<monogr>
		<title level="j">IEEE Sensors Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="920" to="924" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">GestureSleeve: using touch sensitive fabrics for gestural input on the forearm for controlling smartwatches</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schneegass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Voit</surname></persName>
		</author>
		<idno type="DOI">10.1145/2971763.2971797</idno>
		<ptr target="http://dx.doi.org/10.1145/2971763.2971797" />
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="108" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Gummi: user interface for deformable computers</title>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Schwesig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Poupyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eijiro</forename><surname>Mori</surname></persName>
		</author>
		<idno type="DOI">10.1145/765891.766091</idno>
		<ptr target="http://dx.doi.org/10.1145/765891.766091" />
	</analytic>
	<monogr>
		<title level="m">CHI EA. 954</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">A flexible high resolution tactile imager with video signal output</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kanaya</surname></persName>
		</author>
		<idno type="DOI">10.1109/ROBOT.1991.131607</idno>
		<ptr target="http://dx.doi.org/10.1109/ROBOT.1991.131607" />
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
	<note>In ICRA. 384-391</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A New Approach for Readout of Resistive Sensor Arrays for Wearable Electronic Applications</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoming</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename></persName>
		</author>
		<idno type="DOI">10.1109/JSEN.2014.2333518</idno>
		<ptr target="http://dx.doi.org/10.1109/JSEN.2014.2333518" />
	</analytic>
	<monogr>
		<title level="j">IEEE Sensors Journal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="442" to="452" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Characteristics of Pressure-Based Input for Mobile Devices</title>
		<author>
			<persName><forename type="first">Craig</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Rohs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Kratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Essl</surname></persName>
		</author>
		<idno type="DOI">10.1145/1753326.1753444</idno>
		<ptr target="http://dx.doi.org/10.1145/1753326.1753444" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="801" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Smart-mat: recognizing and counting gym exercises with low-cost resistive pressure sensing matrix</title>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Sundholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akash</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lukowicz</surname></persName>
		</author>
		<idno type="DOI">10.1145/2632048.2636088</idno>
		<ptr target="http://dx.doi.org/10.1145/2632048.2636088" />
	</analytic>
	<monogr>
		<title level="m">UbiComp</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cem</forename><surname>Keskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Helmes</surname></persName>
		</author>
		<idno type="DOI">10.1145/2556288.2557030</idno>
		<ptr target="http://dx.doi.org/10.1145/2556288.2557030" />
		<title level="m">Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard. CHI</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1695" to="1704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Bhömer</forename><surname>Martijn Ten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pauline</forename><surname>Van Dongen</surname></persName>
		</author>
		<idno type="DOI">10.1145/2641396</idno>
		<ptr target="http://dx.doi.org/10.1145/2641396" />
	</analytic>
	<monogr>
		<title level="j">Vigour. Interactions</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="12" to="13" />
			<date type="published" when="2014-09">2014. Sep 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">User-defined gestures for elastic, deformable displays</title>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Maria Troiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esben</forename><forename type="middle">Warming</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kasper</forename><surname>Hornbaek</surname></persName>
		</author>
		<idno type="DOI">10.1145/2598153.2598184</idno>
		<ptr target="http://dx.doi.org/10.1145/2598153.2598184" />
	</analytic>
	<monogr>
		<title level="j">AVI</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Flexy: Shape-Customizable, Single-Layer, Inkjet Printable Patterns for 1D and 2D Flex Sensing</title>
		<author>
			<persName><forename type="first">Nirzaree</forename><surname>Vadgama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Steimle</surname></persName>
		</author>
		<idno type="DOI">10.1145/3024969.3024989</idno>
		<ptr target="http://dx.doi.org/10.1145/3024969.3024989" />
	</analytic>
	<monogr>
		<title level="m">TEI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Martin</forename><surname>Weigel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Bailly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antti</forename><surname>Oulasvirta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmel</forename><surname>Majidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Steimle</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702391</idno>
		<ptr target="http://dx.doi.org/10.1145/2702123.2702391" />
		<title level="m">iSkin: Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing. In CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2991" to="3000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">More than touch: understanding how people use skin as an input surface for mobile computing</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Weigel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Steimle</surname></persName>
		</author>
		<idno type="DOI">10.1145/2556288.2557239</idno>
		<ptr target="http://dx.doi.org/10.1145/2556288.2557239" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Human-computer Interaction</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Weiser</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=212925.213017" />
	</analytic>
	<monogr>
		<title level="m">Computer for the 21st Century, 933-940</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Using Pressure Input and Thermal Feedback to Broaden Haptic Interaction with Mobile Devices</title>
		<author>
			<persName><surname>Wilson</surname></persName>
		</author>
		<ptr target="http://encore.lib.gla.ac.uk/iii/encore/record/C__Rb2982123" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD Thesis. 1-273</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">User-defined gestures for surface computing</title>
		<author>
			<persName><forename type="first">Jacob</forename><forename type="middle">O</forename><surname>Wobbrock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meredith</forename><forename type="middle">Ringel</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518866</idno>
		<ptr target="http://dx.doi.org/10.1145/1518701.1518866" />
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">1083</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Smart soccer shoe: monitoring foot-ball interaction with shoe integrated textile pressure sensor matrix</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Koerger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Wirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantin</forename><surname>Zwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Martindale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heber</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjoern</forename><surname>Eskofier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lukowicz</surname></persName>
		</author>
		<idno type="DOI">10.1145/2971763.2971784</idno>
		<ptr target="http://dx.doi.org/10.1145/2971763.2971784" />
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Never skip leg day: A novel wearable approach to monitoring gym leg exercises</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Sundholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heber</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lukowicz</surname></persName>
		</author>
		<idno type="DOI">10.1109/PERCOM.2016.7456520</idno>
		<ptr target="http://dx.doi.org/10.1109/PERCOM.2016.7456520" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
