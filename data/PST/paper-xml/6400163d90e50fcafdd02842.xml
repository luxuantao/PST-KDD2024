<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PatchZero: Zero-Shot Automatic Patch Correctness Assessment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-03-01">1 Mar 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Royal Holloway</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bowen</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Royal Holloway</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kisub</forename><surname>Kim</surname></persName>
							<email>kisubkim@smu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Royal Holloway</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Donggyun</forename><surname>Han</surname></persName>
							<email>donggyun.han@rhul.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of London</orgName>
								<address>
									<country>United Kingdom (UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thanh</forename><surname>Le- Cong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junda</forename><surname>He</surname></persName>
							<email>jundahe@smu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Royal Holloway</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bach</forename><surname>Le</surname></persName>
							<email>bach.le@unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">David</forename><surname>Lo</surname></persName>
							<email>davidlo@smu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">Management University</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Royal Holloway</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">T</forename><forename type="middle">?</forename><surname>Le-Cong</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Computing and Information Systems</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PatchZero: Zero-Shot Automatic Patch Correctness Assessment</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-03-01">1 Mar 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2303.00202v1[cs.SE]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated Program Repair (APR) techniques have shown more and more promising results in fixing real-world bugs. Despite the effectiveness, APR techniques still face an overfitting problem: a generated patch can be incorrect although it passes all tests. It is time-consuming to manually evaluate the correctness of generated patches that can pass all tests. To address this problem, many approaches have been proposed to automatically assess the correctness of patches generated by APR techniques. However, existing approaches require a large set of manually labeled patches as the training data. To mitigate the issue, in this study, we propose PatchZero, the patch correctness assessment by adopting large pre-trained models. Specifically, for patches generated by a new or unseen APR tool, PatchZero does not need labeled patches of this new or unseen APR tool for training (i.e., zero-shot) but directly queries the large pre-trained model to get predictions on the correctness labels without training. In this way, PatchZero can reduce the manual labeling effort when building a model to automatically assess the correctness of generated patches of new APR tools. To provide knowledge regarding the automatic patch correctness assessment (APCA) task to the large pre-trained models, we also design an instance-wise demonstration formation strategy by using contrastive learning. Specifically, PatchZero selects semantically similar patches to help the large pre-trained model to give more accurate predictions on the unlabeled patches. Our experimental results showed that PatchZero can achieve an accuracy of 82.7% and an F1-score of 86.0% on average although no labeled patch of the new or unseen APR tool is available. In addition, our proposed technique outperformed the prior state-of-the-art by a large margin.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Automated Program Repair (APR) has gained increasing attention and diverse APR tools have been proposed <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Despite the significant improvements achieved in APR, existing APR tools still face a long-standing challenge: the overfitting problem <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Due to the absence of strong program specifications, APR tools often use test cases to validate whether a generated patch is correct or not. However, passing all the existing test cases does not ensure that the patch is indeed correct and there is no guarantee that the patch can actually repair the program. A generated patch is considered "overfitting" if it passes all the available test cases while it is still incorrect with respect to the intended program specification.</p><p>Identifying overfitting patches is crucial for the APR tool adoption in practice. Suppose Bob is a practitioner who is keen to use advanced APR tools. There exist multiple approaches he can employ, and each produces many Manuscript received <ref type="bibr">January 19, 2023</ref> patches. However, recent studies <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> demonstrate that APR tools could generate more overfitting patches than correct ones, showing a high false positive rate. In addition, researchers have revealed that high false positive rates may deliver dissatisfaction and distrust to developers on automatic SE tools such as static analysis <ref type="bibr" target="#b20">[21]</ref> and fault localization <ref type="bibr" target="#b21">[22]</ref>. This indicates that APR tools can disappoint Bob by wasting his time with wrong (i.e., overfitting) patches. Thus, it is important to detect and reduce the false positives (i.e., overfitting patches), especially for the generate-andvalidate APR approaches in practice <ref type="bibr" target="#b22">[23]</ref>.</p><p>To address this issue, many approaches <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> have been proposed to conduct automated patch correctness assessment (APCA). Lin et al. <ref type="bibr" target="#b33">[34]</ref> categorized the existing APCA approaches into two categories: (1) dynamic approaches which are based on running/executing the tests and (2) static approaches which are built on top of source code patterns or features. In general, dynamic approaches perform correctness assessment by either augmenting test cases using automated test generation tools such as Randoop <ref type="bibr" target="#b30">[31]</ref> or collecting the runtime information for analysis. On the other hand, static approaches extract code patterns or features to decide the correctness. Despite the promising results, both of them still have drawbacks. The dynamic approaches are very time-consuming <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b29">[30]</ref> while the static approaches are more efficient but less precise <ref type="bibr" target="#b28">[29]</ref>.</p><p>Researchers further push the static APCA approaches by either adopting advanced code representation techniques <ref type="bibr" target="#b22">[23]</ref> or learning a context-aware code representa-tion <ref type="bibr" target="#b33">[34]</ref>. Tian et al. <ref type="bibr" target="#b22">[23]</ref> leveraged advanced code representation learning techniques such as BERT <ref type="bibr" target="#b34">[35]</ref>, to extract source code embeddings for assessing patch correctness. Moreover, Lin et al. <ref type="bibr" target="#b33">[34]</ref> proposed Cache, the state-of-theart patch correctness assessment technique that learns a context-aware code change embedding, considering program structures. Cache outperformed both the dynamic approaches <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> and static approaches <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>.</p><p>Both Tian et al.'s approach and Cache are static and learning-based approaches that directly extract features from patches and learn the correct patterns from the labeled dataset. Additionally, they were evaluated in the cross-validation setting, where the patches generated by the different APR tools are mixed up and separated into 8:2 for training and testing. This setting has an outstanding limitation that, for patches of any APR tool that needs to be evaluated, it requires developers to manually label the majority of patches (approximately 80%) to form the labeled training data first, train the model on the training data, and finally apply to the remaining 20% patches. Although the cross-validation setting is widely used to evaluate the techniques based on machine learning (ML) <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, it may not be suitable for APCA tools as its initial goal is to automate the assessment process. In other words, the less labeling work required to build a tool, the better. Moreover, Tian et al.'s <ref type="bibr" target="#b22">[23]</ref> approach and Cache <ref type="bibr" target="#b33">[34]</ref> are learningbased techniques, indicating that a sufficient amount of the labeled dataset is indispensable. Considering the fact that many patches generated by existing APR tools have been manually checked for correctness <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref> and new APR tools are still emerging, we are motivated to ask a key question:</p><p>Is it feasible to utilize labeled patches of existing APR tools to predict the correctness of the patches generated by a new/unseen APR tool?</p><p>As no labeled patches generated by the new/target APR tool are available for training, we define this setting as a zero-shot setting following prior work on zero-shot learning <ref type="bibr" target="#b37">[38]</ref>. We first explore whether the state-of-the-art APCA approaches can predict the correctness of patches generated by an unseen APR tool when labeled patches of other APR tools are available in the training data. We observe that both Tian et al.'s work and Cache do not achieve promising results during our preliminary experiments as there exists a lack of labeled patches of the new/unseen APR tool for training the model. We report the effectiveness of these state-of-the-arts and discuss them in Section 5.1.</p><p>To fill the research gap, we propose PatchZero, the first zero-shot APCA approach that uses large pre-trained code models to assess the correctness of unlabeled patches generated by APR tools without fine-tuning. There is no finetuning phase for PatchZero which implies that no manual labeling process is required for the new/unseen APR tools. In other words, PatchZero directly performs inference on the test set (i.e., patches generated by a target APR tool). PatchZero is inspired by the solid zero-shot inference ability of large pre-trained models. For instance, GPT-3 <ref type="bibr" target="#b38">[39]</ref> is a PatchZero is built upon open-source large pre-trained models for texts and code (i.e., BLOOM <ref type="bibr" target="#b40">[41]</ref> and CodeParrot <ref type="bibr" target="#b41">[42]</ref>). Technically, we directly leverage the pre-training objective of the large pre-trained models: generating the next token based on all previous tokens to realize zero-shot learning for APCA. As shown in Figure <ref type="figure">1</ref>, we first prepare model inputs where an unlabeled patch of a new APR tool is concatenated by several labeled patches of existing APR tools. We then query the large pre-trained models to generate the next token to show its tendencies in terms of patch correctness (i.e. generating a token either "correct" or "overfitting"). This allows us to perform zero-shot learning (without the need for training data and fine-tuning process) since we formulate the APCA task (i.e. predicting whether a patch is indeed correct or not) in the same format as the pre-training task (i.e., generating the next token based on previous tokens). Our experimental results showed that PatchZero has significantly outperformed the prior state-ofthe-art Cache by 19.1-26.6%. Besides, PatchZero has led to substantial improvements over a strong baseline CodeBERT by 8.1-12.5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions. The main contributions are as follows:</head><p>? This paper proposes a new setting (i.e., the zero-shot setting) to the APCA task where we assume that no labeled patches are available for a new or unseen APR tool. This setting can better match the initial goal of APCA tasks to reduce the manual labeling effort and can evaluate the ability of approaches to transfer knowledge embedded in the existing labeled data to future unlabeled data. ? We design a solution, PatchZero, for this challenging setting. We build PatchZero based on the recent large pre-trained models (BLOOM and CodeParrot) and reformat the APCA task the same as the original pre-training objective of the large pre-trained models.</p><p>? This paper opens a new dimension to utilizing large pretrained models for not only the zero-shot code generation tasks <ref type="bibr" target="#b39">[40]</ref>, but also other code-related downstream tasks. We have shown that large pre-trained models have a strong ability even without fine-tuning. Besides, large pre-trained models can do well without any labeled data of the target domain (e.g. the patches of the new APR in this paper), which may be helpful for other downstream tasks that lack target domain data such as automatic program repair <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, answer summarization <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Large Pre-trained Models for Code</head><p>Large pre-trained models <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref> become popular in Natural Language Processing (NLP) and Software Engineering (SE). Most large pre-trained models are built based on a Transformer <ref type="bibr" target="#b48">[49]</ref> framework. There are three main categories of large pre-trained language models using Transformer: 1) encoder-only models; 2) decoderonly models; and 3) encoder-decoder models.</p><p>CodeBERT <ref type="bibr" target="#b34">[35]</ref> is a typical encoder-only model for code that is widely used in SE tasks such as code search and defect prediction. CodeBERT is pre-trained on the masked language modeling (MLM) objective <ref type="bibr" target="#b34">[35]</ref> where some tokens in training data are masked and the model is asked to predict/recover the masked tokens. Codex <ref type="bibr" target="#b39">[40]</ref>, CodeParrot <ref type="bibr" target="#b41">[42]</ref>, and BLOOM <ref type="bibr" target="#b40">[41]</ref> are typical decoder-only models which use only the Transformer decoder to predict the probability of the next token given the previous tokens. The nature of these models makes them highly useful for generation tasks because text/code is usually written in a left-to-right way. CodeT5 <ref type="bibr" target="#b45">[46]</ref> is a typical pre-trained encoder-decoder model for code, which is pre-trained on denoising sequence-tosequence objectives where the input sequence is a corrupted text (e.g. randomly masking, deleting, or swapping tokens) and the output sequence is the corresponding uncorrupted text.</p><p>As shown in Table <ref type="table" target="#tab_1">1</ref>, except for the structure differences, these pre-trained models for code are also different in model sizes, the maximum tokens can deal with, and the amount of pre-training data. Specifically, if we compare CodeBERT with BLOOM (CodeParrot), CodeBERT can at most deal with a code snippet of 512 tokens while BLOOM (Code-Parrot can deal with a data instance at most consisting of 2,048 (1,024) tokens. Besides, BLOOM is pre-trained on a giant pre-training data of over 366 billion tokens including 46 natural languages and 13 programming languages. However, CodeBERT is pre-trained on the CodeSearchNet <ref type="bibr" target="#b49">[50]</ref> dataset of 8 million code snippets or documentations including 6 programming languages. For model sizes, the largest </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Usages of Pre-trained Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Fine-tuning</head><p>Fine-tuning a pre-trained model for downstream tasks <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b50">[51]</ref> is a prevalent paradigm in the NLP and SE field. Fine-tuning utilizes the knowledge in pre-trained models to achieve better model initialization. Using a pretrained language model for initialization often produces better results with enough labeled data. To adapt pre-trained models to downstream tasks, fine-tuning trains the model in a supervised way. Specifically, given a dataset that consists of task-specific samples X and corresponding labels Y , finetuning aims to find a set of parameters ? for the pre-trained model so that ? = arg max ? P (Y |X, ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">In-context Learning</head><p>Though very effective and easy-to-use, fine-tuning usually requires relatively large labeled downstream task datasets to fine-tune all parameters in pre-trained models <ref type="bibr" target="#b51">[52]</ref>. Besides, fine-tuning demands for large GPU resources to load and update all parameters of pre-trained models <ref type="bibr" target="#b52">[53]</ref>.</p><p>An alternative popular approach proposed in GPT3 is in-context learning (ICL) <ref type="bibr" target="#b38">[39]</ref>, which induces a model to perform a downstream task by inputting examples to the model without any parameter update or training. ICL requires no gradient-based training and therefore allows a single model to immediately perform evaluations on different datasets. ICL mainly relies on the capabilities and knowledge that a pre-trained model learned during its pre-training. The incontext learning makes predictions based on the probability of generating the next token y given the unlabeled data instance x and the context C, which includes k labeled examples. ICL outputs the token y with the highest probability as the prediction for the unlabeled input data x. It can be expressed as: y = arg max y P P T M (y|C, x), where P T M denotes the pre-trained model. C is a context/demonstration created by concatenating k instances along with their corresponding labels i.e., C = x 1 , y 1 , x 2 , y 2 , ..., x k , y k . As shown in the illustration of Figure <ref type="figure">1</ref>, ICL asks the pretrained model to predict the correctness of a test patch given several labeled patches as the context, and the pre-trained model outputs "correct" because its probability as the next token is the highest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED APPROACH</head><p>PatchZero is proposed to utilize labeled patches of existing APR tools to predict the correctness of the patches generated by a new/unseen APR tool. Hereafter, we denote the labeled patches of existing APR tools as the labeled patch pool and denote the patches generated by a new or unseen APR tool as test patches (only used in inference). In addition, we denote a new or unseen APR tool as the target APR tool. outputs its correctness label (i.e., clean or overfitting) by leveraging large pre-trained models and the labeled patch pool. A generated patch is "clean" ("correct") if it not only passes all the available test cases but also fixes the bugs in the program. A generated patch is considered "overfitting" ("wrong") if it only passes all the available test cases but is still incorrect with respect to the intended program specification which is not suitable for program repair. Please note that we also refer to "clean" as "correct" and "overfitting" as "wrong" in the later part.</p><p>Specifically, PatchZero consists of the following four steps:</p><p>? Step 1: Pre-processing In the first step, we modify the patches by a recent NLP technique called prompting <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref> and convert the prompted patches into subtokens via tokenizers of pre-trained models. We describe the details of this step in Section 3.1.</p><p>? Step 2: Instance-wise Demonstration Formation Explicitly providing a few input-output examples as a demonstration to the large pre-trained models can boost the model performance in effectiveness <ref type="bibr" target="#b38">[39]</ref>. Rather than randomly sampling examples <ref type="bibr" target="#b38">[39]</ref>, in this step, we design a strategy to select several appropriate patches from the labeled patch pool for each test patch. We describe the details of this step in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? Step 3: In-Context Learning Inference</head><p>We feed the test patch with its demonstrations (a few labeled patches retrieved from the labeled patch pool) into the large pretrained models (BLOOM and CodeParrot). The large pretrained models can predict the next tokens conditioning on the input data. The predicted next tokens are then mapped to correctness labels for completing the inference process. We describe the details of this step in Section 3.3. ? Step 4: Predictions Ensemble Two large pre-trained models (BLOOM and CodeParrot) individually give predictions for the test patches. As the two models are pretrained on different large-scale datasets with different designs, they may gain complementary knowledge to each other during pre-training. This motivates us to combine the predictions of these two models to obtain more accurate predictions. We describe the details of this step in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-processing</head><p>To enable pre-trained models to perceive the information in patch data, the first step is to pre-process the raw patches.</p><p>We first leverage prompts to patches (i.e., a piece of the text inserted in the input data instances) and tokenize the prompted patches into sub-tokens that pre-trained models can understand.</p><p>Prompting Patches. We pre-process patches based on the recent advances in NLP, namely prompting <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref>, which can help to better adapt a generic pre-trained model to a specific downstream task. The intuition of prompting is to convert the downstream tasks into a similar form as the pre-training stage. For pre-trained models whose pretraining objective is to predict the next token given previous tokens, e.g., GPT-3 <ref type="bibr" target="#b38">[39]</ref> and BLOOM <ref type="bibr" target="#b40">[41]</ref>, prompting aims to ask a model to predict the next token (i.e. "correct" or "wrong" in this task) given previous tokens (patch contents and demonstrations). To help pre-trained models understand task-specific information, prompting modifies the input data by adding a piece of text description, namely prompt templates. The prompt template is a textual string that has two slots: (1) an input slot [X] for original input data x and (2) an answer slot <ref type="bibr">[Z]</ref> for the predicted answer/label token z. The label token z is mapped into the predicted label ? by a verbalizer <ref type="bibr" target="#b55">[56]</ref> to complete the downstream tasks. The verbalizer, denoted as V , is a function that maps each predicted label token z to a class ? in the target class set Y :</p><formula xml:id="formula_0">V : Z ? Y (1)</formula><p>where Z indicates the label token set. In the APCA task, the label token set Z includes two tokens, i.e., {"correct", "wrong"}, and the class set Y contains {-, +} for indicating correct (clean) and wrong (overfitting) patches, respectively. Note that the verbalizer is manually defined instead of learned from data.</p><p>In this work, we apply a prompt template that contains understandable natural language texts. After inserting a prompt template to input data, the task objective becomes predicting the label token at the answer slot [Z], which is "correct" or "wrong". Specifically, a straightforward template for the patch correctness prediction task can be formulated as follows:</p><formula xml:id="formula_1">f prompt (x) = "[X] Q : It was wrong or correct? A : It was [Z]. " V = + : wrong, -: correct, (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where V is the defined verbalizer.</p><p>[X] denotes the input slot where the input patch x should be filled in. Tokenization. To tokenize the inputs for the pre-trained models, we use the tokenizer of each corresponding pretrained model. They are generally built based on the byte pair encoding (BPE) <ref type="bibr" target="#b56">[57]</ref>, which builds the vocabulary by iteratively adding the most frequent combinations of characters and outputs a sequence of token sequences. BPE can reduce the size of the vocabulary by breaking uncommon long tokens into sub-tokens that frequently appear in the pre-training corpus. Besides, BPE is known to help mitigate the Out-of-Vocabulary (OoV) issue <ref type="bibr" target="#b57">[58]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Instance-wise Tailored Demonstration Formulations</head><p>Motivation. In the zero-shot setting of the Automatic Patch Correctness Assessment, all the patches that are generated by a new APR tool are unlabelled. We define these unlabelled patches as test patches. On the other hand, there exists a pool of labeled patches generated by the existing APR tools which also contains useful and valuable information about correctness (e.g., the context of the patch).</p><p>A standard ICL approach <ref type="bibr" target="#b38">[39]</ref> treats all the labeled data equally and randomly samples k labeled patches to form a demonstration for the pre-trained model, providing the context information about a downstream task. In the APCA task, however, every patch does not equally contribute. For instance, a patch that aims to fix a similar bug to the test patch is more instructive than a randomly sampled one. In other words, we need to design a tailored demonstration formation strategy that can form optimized demonstrations for each test patch and inspire the pre-trained model to achieve better prediction results.</p><p>To select patches, a simple-yet-effective idea is to choose semantically similar patches from the labeled patch pool. The semantically similar patches contain similar code changes like the test patch. The subtle difference between similar patches and test patches can possibly contribute to the difference in labels. We assume that providing such semantically similar patch-label pairs to the pre-trained models can inspire them to learn the context information related to the test patch. With this line of thought, we expect the pre-trained models to induce the label of the test patch considering both the patches detected as semantically similar and the test patch.</p><p>The process of the instance-wise tailored demonstration includes the following steps: 1) We first embed patches in both the labeled patch corpus and patches in the test set into vector representations by utilizing a patch embedding model based on contrastive learning. 2) For each test patch x, we retrieve its top-k most similar patches (i.e., x 1 , x 2 , ..., x k ) among the labeled patch pool measuring the distances in the vector space by adopting cosine similarity.</p><p>3) The top-k most semantically similar patches are modified via prompting (Section 3.1) and then concatenated to form the context/demonstration. It can be formulated as follows:</p><formula xml:id="formula_3">C = f prompt (x 1 ), y 1 , ..., f prompt (x k ), y k (3)</formula><p>4) The context/demonstration C is further appended to the test input x and finally fed into the pre-trained model. Next, we introduce how we build the contrastive learning-based patch embedding model that is used to embed patches into embeddings.</p><p>Contrastive Learning for Patch Embedding. It is of great significance to represent patches in suitable embeddings because it will particularly affect whether the patches with the highest similarity scores are semantic similar to the test patch or not. To embed patches into embeddings of good quality, we train an unsupervised patch representation model by leveraging contrastive learning <ref type="bibr" target="#b58">[59]</ref>.</p><p>Although there exist effective code change representation models such as CC2Vec <ref type="bibr" target="#b59">[60]</ref>, they need further information like commit messages to learn the code change embedding. In many open datasets, however, there is no such information <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>. Considering this phenomenon, we decide to train our own contrastive learning-based patch embedding model which only utilizes patch contents.</p><p>In the contrastive learning framework, we need a pretraining dataset whose input instance is in the form of a triplet p, p + , p -, where p is a patch, p + is a semantically similar patch to p, and p -is a semantically dissimilar patch to p. Thus, p, p + is considered as a similar pair and p, p -is a dissimilar pair. The main training objective of contrastive representation learning is to learn such an embedding space in which similar patch pairs stay closer to each other while dissimilar ones push out far away from each other. Unfortunately, to the best of our knowledge, existing patch datasets in Software Engineering (SE) domain (e.g., the ManySStuBs4J <ref type="bibr" target="#b60">[61]</ref>) do not contain information on whether a patch pair is similar or dissimilar. In such a case, we can not directly use existing patch datasets to train the contrastive learning model.</p><p>To construct a dataset that contains a large number of triplets p, p + , p -, we follow the spirit of unsupervised contrastive learning <ref type="bibr" target="#b58">[59]</ref>: 1) assuming that each data instance p i is unique and dissimilar to other data instances, then, any of the other data instances can be negative samples p - i . 2) if performing semantic-preserving transformations on p i , as no semantics are changed, the data after transformations can be considered as the positive sample p + i to the original instance p i .</p><p>We apply a transformation proposed in SIMCSE <ref type="bibr" target="#b58">[59]</ref> on patches to form the positive sample p + i , which is based on the dropout operation. Dropout <ref type="bibr" target="#b62">[63]</ref> is a popular technique where randomly selected neurons are ignored during training to alleviate the overfitting problem of neural networks. SIMCSE <ref type="bibr" target="#b58">[59]</ref> successfully generated sentence embeddings with the dropout technique. It embeds texts into distributed embeddings retaining their semantics. As shown in Figure <ref type="figure" target="#fig_1">3</ref>, SIMCSE simply applies the standard dropout operation <ref type="bibr" target="#b62">[63]</ref>  twice to obtain two different embeddings of the same data instance p i :</p><p>? The first dropout operation (the red one) randomly ignores a set of neurons and results in the embedding of patch p i . ? To obtain a different patch embedding of the same patch, SIMCSE adopts the second dropout operation (the blue one) which ignores another set of neurons. The embedding after the second dropout is regarded as the embedding of the positive sample p + i . As we construct positive and negative samples in an unsupervised way that does not need any labels in datasets, we can use any patch dataset as the pre-training data to perform contrastive learning. In this work, we utilize patches in the ManySStuBs4J <ref type="bibr" target="#b60">[61]</ref> dataset, which contains 153,652 single-statement bug-fix patches mined from 1,000 popular open-source Java projects. It is widely used in many SE downstream tasks such as automated program repair <ref type="bibr" target="#b63">[64]</ref>, bug detection <ref type="bibr" target="#b64">[65]</ref>, and fault localization <ref type="bibr" target="#b65">[66]</ref>.</p><p>Similar to SIMCSE <ref type="bibr" target="#b58">[59]</ref>, we also use a pre-trained Transformer model as the base model for generating embeddings and add a multi-layer perceptron (i.e., MLP) on top of it. In SIMCSE, it uses RoBERTa <ref type="bibr" target="#b46">[47]</ref> as the base model; however, as our data is source code, we use CodeBERT <ref type="bibr" target="#b44">[45]</ref>, which is pre-trained on both source code and texts. Note that in the framework of contrastive learning, fine-tuning is indispensable to learn such an embedding space in which similar patch pairs stay closer to each other. However, fine-tuning a huge pre-trained model requires vast computation resources that we cannot afford. Thus, we choose to use CodeBERT to learn the contrastive learning-based patch embedding rather than BLOOM. During the training, for an input instance in the form of a triplet p, p + , p -, the loss function is defined as follows:</p><formula xml:id="formula_4">l i = -log e cos(p i , p + i )/? N j (e cos(p i , p + j )/? + e cos(p i , p - j )/? )<label>(4)</label></formula><p>where p i denotes the representation of the i-th patch;</p><formula xml:id="formula_5">p + i (p - i )</formula><p>is the representation of a semantically similar (dissimilar) patch to p i ; N is the number of patches in a mini-batch; ? is a temperature hyper-parameter; and cos is the cosine similarity function. All the parameters in CodeBERT are updated to minimize the loss (i.e., Eq.4). We train the model on the ManySStuBs4J dataset by adopting the semantic-preserving transformation mentioned above. For implementation details, we implement the model by using a popular deep-learning library called HuggingFace<ref type="foot" target="#foot_0">1</ref> . We simply adopt the hyper-parameters recommended by SIMCSE <ref type="bibr" target="#b58">[59]</ref> which are the learning rate as 5e-5, batch size as 64, and the number of epochs as 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">In-context Learning Inference</head><p>The in-context learning inference can be regarded as a text generation problem where the pre-trained model is frozen. We follow Brown et al. <ref type="bibr" target="#b38">[39]</ref>  (</p><formula xml:id="formula_6">)<label>5</label></formula><p>where PTM denotes the parameters of the pre-trained model which are frozen all the time. We use a recently released large pre-trained model, BLOOM <ref type="bibr" target="#b40">[41]</ref>, the multilingual giant pre-trained model that is completely open-sourced. BLOOM has a list of variants of different model sizes and the largest variant model has 176 billion parameters. We choose to use the "BLOOM-1.1b" variant which has 1.1 billion parameters.</p><p>It is approximately 7.5 times larger than the pre-trained model like RoBERTa-base <ref type="bibr" target="#b46">[47]</ref> (0.13 billion parameters) or CodeBERT <ref type="bibr" target="#b44">[45]</ref> (0.13 billion parameters) which are commonly used for both research and practice. In addition, we also adopt the popular large pre-trained model namely CodeParrot <ref type="bibr" target="#b41">[42]</ref> which is about 10.5 times larger than Code-BERT.</p><p>In the equation, C is the demonstration (context) created by concatenating the top-k most similar patches retrieved from the corpus (See the details in Section 3.2) along with their corresponding labels. Note that each patch is first modified via prompting (Section 3.1) before the concatenation. Concretely, the context before the test patch is formulated as:</p><formula xml:id="formula_7">C = f prompt (x 1 ), y 1 , ..., f prompt (x k ), y k<label>(6)</label></formula><p>where f prompt is the prompt template we defined in Section 3.1 and x k , y k are the top-k most similar patches and their labels with respect to the test patch x. The context C is further appended to the test input x and finally sent to the large pre-trained model. As the patch correctness assessment task is formulated as a binary classification task <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b33">[34]</ref>, we first compute the probabilities of the clean class (i.e. P P T M ("correct"|C, x)) and the overfitting class (i.e. P P T M ("wrong"|C, x)) and normalize the probabilities of two classes. Then, if the probability of the overfitting class is larger than 0.5, the test patch is predicted as "overfitting". Otherwise, it is predicted as "clean". We call the probability of the overfitting class generated by a large pre-trained model (after normalization) as the prediction score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Predicitions Ensemble</head><p>BLOOM and CodeParrot both give prediction scores for an input test patch. Typically, there are multiple ways to combine scores from different models including the average, maximum, sum, and weighted average of scores <ref type="bibr" target="#b66">[67]</ref>. In our preliminary experiment, we found that taking the average of two models' predictions achieves the best performance in 5% of data randomly sampled from the labeled patch pool. Thus, we simply calculate the average of two prediction scores of the BLOOM and CodeParrot as the final prediction score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETTING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We use the dataset used in Lin et al. <ref type="bibr" target="#b33">[34]</ref>'s work containing a total of 1,183 patches from the Defects4J benchmark <ref type="bibr" target="#b67">[68]</ref> where most existing APR tools are evaluated. The dataset is merged from two existing large-scale datasets provided by Wang et al. <ref type="bibr" target="#b28">[29]</ref> and Tian et al. <ref type="bibr" target="#b22">[23]</ref>. Patches in these two datasets were either written by developers (i.e., the ground-truth patches) or generated by 22 different APR tools. Note that their correctness has been carefully labeled and checked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cross-Tool Validation</head><p>In this paper, we aim to utilize labeled patches of existing APR tools to predict the correctness of the patches generated by a new/unseen APR tool. However, patches generated by future APR tools are impossible to get. Thus, we conduct a "cross-tool" validation that is close to the setting above. In the "cross-tool" scenario, we iteratively regard each APR tool as the target APR tool. For instance, we can first consider the tool TBar <ref type="bibr" target="#b10">[11]</ref> as the target APR tool, then, all the patches generated by TBar are used as the test dataset.</p><p>At the same time, other patches generated by other APR tools are used as the training data. In this way, we can still evaluate whether the model can transfer the knowledge in labeled patches of APR tools except TBar to the patches generated by TBar. To carry out the experiment, we employ 22 existing APR tools and construct 22 different sub-datasets in a leave-one-out manner, i.e., we iteratively pick one APR tool as the target APR tool for each sub-dataset. Please note that we remove the patches of the existing APR tools (i.e., the labeled patch pool) that are identical to any patch in the test set to avoid the data leaking issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>Please note that each baseline tool is trained on the corresponding training set (i.e., the labeled patches generated by other APR tools) while considering each APR tool as the target at a time. Only PatchZero does not have a training phase, while all the other methods need training. Our baselines are listed as follows:</p><p>Tian et al.'s Approach. Recently, Tian et al. <ref type="bibr" target="#b22">[23]</ref> proposed an approach to leverage code (change) representation techniques to predict the correctness (i.e., correct or overfitting) of APR-generated patches. They adopted three recent representation techniques (i.e., BERT <ref type="bibr" target="#b34">[35]</ref>, CC2vec <ref type="bibr" target="#b59">[60]</ref>, and Doc2vec <ref type="bibr" target="#b68">[69]</ref>) with well-known Machine Learning classifiers (i.e., Logistic Regression, Decision Tree, and Naive Bayes) to demonstrate that it could achieve a promising result. Technically, they froze the representation models and used them to embed patches into distribution embeddings. Then, they fed the embeddings with the labels of patches to Machine Learning classifiers to train classifiers.</p><p>Cache. Lin et al. <ref type="bibr" target="#b33">[34]</ref> proposed an approach named Cache that showed the state-of-the-art performance in the patch correctness assessment task. Cache learns a context-aware code change embedding considering program structures. Specifically, given a patch, Cache focuses on both the changed code and correlated unchanged part and utilizes the AST paths technique for representation where the structure information from the AST node can be captured. After learning the representation, Cache builds a deep learningbased classifier to predict the correctness of the patch. They performed extensive experiments and showed that Cache outperformed the existing representation learningbased techniques <ref type="bibr" target="#b22">[23]</ref> and testing-based approaches <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>.</p><p>CodeBERT. Following the recent success of Transformer based pre-trained models in NLP like BERT <ref type="bibr" target="#b34">[35]</ref>, practitioners have proposed pre-trained models for code, e.g., Code-BERT <ref type="bibr" target="#b44">[45]</ref>. CodeBERT is a solid baseline in a wide range of SE downstream tasks such as code search and code summarization. Considering that Tian et al. <ref type="bibr" target="#b22">[23]</ref> already used BERT in their work and CodeBERT is a BERT-like model that is pre-trained on text and code, we first utilize CodeBERT in the same way proposed by Tian et al.'s work: freeze the parameters of CodeBERT to extract code embedding and use Logistic Regression to conduct the classification based on the code embedding (denoted as "CodeBERT+LR"). Finetuning models usually leads to better performance in terms of effectiveness than freezing models <ref type="bibr" target="#b69">[70]</ref>. Thus, we also try an alternative way to use CodeBERT, that is, we replace the Logistic Regression classifier with fully-connected layers and directly fine-tune CodeBERT with the training data (denoted as "CodeBERT+FT"). For "CodeBERT+FT", we adopt the hyper-parameters used in the CodeBERT paper <ref type="bibr" target="#b44">[45]</ref>: the learning rate is 1e-5 and the number of training epochs is 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>To evaluate the effectiveness of various target approaches, we adopt widely used evaluation metrics for classification tasks: Accuracy and F1-score. Both Accuracy and F1-score can be measured based on the number of true positives (TP), false positives (FP), and false negatives (FN). Accuracy is defined as the ratio of the number of correctly predicted data (i.e., TP+TN) to the number of all patches (i.e., TP+TN+FP+FN). TP case is referred to when a model prediction is overfitting for an overfitting patch, otherwise, it is an FN case. FP case is referred to when a model prediction is overfitting for a correct patch, otherwise, it is a TN case. F1-score is defined as the harmonic mean of Precision and Recall values. For example, Precision is the ratio of correctly predicted overfitting patches to all the patches predicted as overfitting (i.e., P recision = T P T P +F P ) and Recall is the ratio of the number of correctly predicted overfitting patches to the actual number of overfitting patches (i.e. ). F1-score can be formally defined as F 1-score = 2?P recision?Recall P recision+Recall .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Hyper-parameter Tuning on Selecting Similar Labeled Patches</head><p>As introduced in Section 3, the demonstration is created by concatenating the most similar patches retrieved from the labeled patches of existing APR tools. It is important to decide the way to choose the "most similar patches" given a test patch. The general idea is to include as many similar patches as possible, such that it can provide more valuable information to PatchZero. We specify the general idea into two hyper-parameters:</p><p>? the k value: it is the maximum number of the most similar patches that we consider to build the in-context learning demonstration. For instance, "k = 10" indicates that we consider up to 10 patches. ? the similarity threshold ?: it constrains the similarity of patches for building the demonstration. Specifically, for a test patch, only labeled patches with higher cosine similarities than the threshold ? are considered. To select a fixed similarity threshold ? and a fixed k value for testing, we first performed preliminary experiments on 5% of data randomly split from the labeled patch pools. As shown in Table <ref type="table" target="#tab_2">2</ref>, PatchZero shows the best performance on average when k = 10 and ? = 0.9. We select the top 10 patches whose cosine similarity scores are higher than 0.9 to a test sample to form a demonstration during testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Research Questions</head><p>In this paper, we aim at answering the following research questions:</p><p>? RQ1: How does PatchZero perform compared to state-ofthe-art approaches in the cross-tool setting?</p><p>? RQ2: How does each component of PatchZero contribute?</p><p>We design RQ1 to demonstrate the effectiveness of PatchZero by comparing it with state-of-the-art patch correctness assessment approaches. In RQ2, we carefully conduct an ablation study to illustrate the contribution of each component in our solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">RQ1. Effectiveness</head><p>We evaluate the effectiveness of PatchZero by comparing it against the state-of-the-art patch correctness assessment approaches. As we mentioned in the experimental setting, Tian et al. <ref type="bibr" target="#b22">[23]</ref> adopted three representation techniques and three machine learning classifiers. Among nine variants, we only report the best-performing combination due to the limited space. For Cache, we reuse the implementation released by the authors of Cache. Tables <ref type="table" target="#tab_3">3</ref><ref type="table" target="#tab_4">4</ref>show the effectiveness of all the approaches including PatchZero and the baselines in terms of Accuracy and F1-score.</p><p>The experimental results show that PatchZero outperforms all the baseline techniques while the state-of-the-art (i.e., Cache) struggles in the zero-shot setting. PatchZero showed 30.0% and 20.4% improvements against Tian et al.'s work on average in terms of Accuracy and F1-score. It also showed 26.6% and 19.1% of enhancement against Cache on average in terms of Accuracy and F1-score. Additionally, PatchZero led to a substantial boost over a strong baseline CodeBERT by 12.5 % and 8.1% in Accuracy and F1-score respectively. Besides, we adopt weighted averages of Accuracy and F1-score where the weights are the number of patches generated by each APR tool. PatchZero still outperforms all baselines. PatchZero leads to 22.3% and 16.4% improvements over Cache in terms of weighted average Accuracy and F1-score. PatchZero outperforms CodeBERT+FT by 9.5% and 6.1% in terms of weighted average Accuracy and F1-score. Furthermore, we conduct the Wilcoxon signedrank tests between PatchZero and all baselines to investigate whether the improvements are significant. The results show that PatchZero is statistically significantly better than all baselines (all p-values are less than 0.05). For instance, the p-value between PatchZero and CodeBERT+FT is 0.001.</p><p>We additionally observe that fine-tuning CodeBERT (i.e. CodeBERT+FT) delivers better performances in effectiveness than freezing the model (i.e. CodeBERT+LR). The reason may be that fine-tuning updates CodeBERT to better fit the APCA task. It is also interesting to note that finetuned CodeBERT outperforms the state-of-the-art technique (i.e., Cache). It indicates the knowledge learned during pretraining is helpful to alleviate the problem of lacking labeled patches generated by the target APR tool.</p><p>Confusion Matrix Analysis. Figure <ref type="figure" target="#fig_3">4</ref> compares the confusion matrices of PatchZero and the best-performing baseline (i.e. CodeBERT+FT). For ease of analysis, we put the predictions of each test set in the "cross-tool" setting together and compute the confusion matrices. In total, we have 829 patches generated by 22 APR tools. Please note that though the whole dataset has 1,183 patches, only 829 of them are generated by APR tools and the other patches are contributed by developers. Among the 829 generated patches, 648 patches are overfitting and only 181 patches are correct. The correct patch ratio of APR-generated patches is only 21.8% ( 181 181+648 ) on average without using APCA techniques. Using PatchZero, it can filter out 597 overfitting patches (i.e., 92.1% of overfitting patches) as shown in Figure <ref type="figure" target="#fig_3">4b</ref>. The remaining patches are predicted as correct by PatchZero and the correct patch ratio of the remaining patches is increased from 21.8% to 64.1% ( 91 91+51 ). For CodeBERT+FT, as shown in Figure <ref type="figure" target="#fig_3">4a</ref>, it can filter out 566 overfitting patches (i.e., 87.3% of overfitting patches) but the correct patch ratio of the remaining patches is only 43.1% ( 62 62+82 ). PatchZero outperforms CodeBERT+FT by 48.7% in terms of the correct patch ratio of the remaining patches. Though APCA techniques can help to reduce the number of overfitting patches, they inevitably delete some correct patches at the same time. Figure <ref type="figure" target="#fig_3">4</ref> also shows that CodeBERT+FT wrongly predicts 119 correct patches as "overfitting" while the corresponding number for PatchZero is 91. It indicates that PatchZero makes fewer mistakes than CodeBERT-FT.</p><p>Case Study. We give a case study to demonstrate how our proposed instance-wise demonstration would enhance the large pre-trained models. Given a test patch, we use PatchZero with and without the instance-wise demonstration to predict whether the test patch is correct or overfitting. Figure <ref type="figure" target="#fig_4">5</ref> illustrates an example of a test patch taken from the closure-compiler project and the most similar patch retrieved from the labeled patch pool. Such a test patch (the left-hand side code) tries to repair the program by removing the condition of the else if statement. The large pre-trained models initially predict the input test patch as "correct". But this test patch, in fact, is an overfitting patch. However, using the instance-wise proposed demonstration, the prediction is changed to "overfitting" which is the ground truth. The most similar patch retrieved from the labeled patch pool (the right-hand code) also tries to repair the program by relaxing the condition of the else if statement but this patch is already identified as an overfitting patch. As these two patches are functionally equivalent, the label of the most similar patch is valuable for large pre-trained models to judge the test patch. In general, we observe that the instance-wise proposed demonstration strategy could provide additional relevant information to large pre-trained models and correct the potential errors in its initial predictions.</p><p>Answer to RQ1: PatchZero outperforms the baseline techniques with a large margin while the state-ofthe-art struggles in the zero-shot cross-tool validation setting. Knowledge being trained during the pre-training can alleviate the lacking number of labeled patches of the target APR tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">RQ2. Ablation Study</head><p>To illustrate the contributions of each component of PatchZero, we carry out an ablation study and the results are shown in Table <ref type="table" target="#tab_5">5</ref>.</p><p>Firstly, we investigate the contributions of the predictions ensemble module. We use the prediction scores generated by BLOOM and CodeParrot separately to give final predictions on the correctness of patches. As presented in Table <ref type="table" target="#tab_5">5</ref>, on average, the ensemble model leads to 2.0% and 1.3% improvements in Accuracy and F1-score over a single large language model (e.g., BLOOM). This supports that BLOOM and CodeParrot are complementary to each other to some extent.</p><p>Secondly, we investigate the contributions of the large pre-trained models (e.g., BLOOM) and our instance-wise  These retrieved patches are fed directly into a kNN model to predict the correctness label of the test patch by majority voting among the N instances' labels. For example, the kNN model will predict a test patch as "correct" when the majority of the N similar patches are "correct". "PatchZero (w.o. Demonstration)" indicates the model variant does not use the proposed instance-wise demonstration formulation strategy (Section 3.2) but randomly samples examples as the demonstration. Specifically, it first randomly samples M labeled patches from the labeled corpus. Then, it forms a demonstration by concatenating the randomly sampled M patches and feeds the data to large pre-trained models to generate the prediction.</p><p>As presented in Table <ref type="table" target="#tab_5">5</ref>, on average, PatchZero leads to 18.1% and 14.7% improvements in Accuracy and F1-score over the "PatchZero (wo. Large Pre-trained Models)" variant. This indicates that the large pre-trained models leverage the knowledge learned in pre-training to correct the errors in the retrieval model (i.e. the patch embedding model). In addition, if we compare PatchZero with "PatchZero (w.o. Demonstration)", we observe that giving randomly sampled examples to the large pre-trained models may mislead it to give the wrong prediction. In general, our specialized instance-wise demonstration formation strategy leads to 13.8% and 5.4% improvements in Accuracy and F1-score on average compared to random sampling. In conclusion, the results confirm that the predictions ensemble module, the large pre-trained models, and the instance-wise demonstration formation strategy help PatchZero to give a more accurate prediction.</p><p>Answer to RQ2: PatchZero's three major components: (1) large pre-trained models, (2) an instancewise demonstration formation strategy, and (3) the predictions ensemble module, play vital roles in accurate prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Time and Resource Costs</head><p>Despite PatchZero outperforming the state-of-the-art, Cache with a large margin, leveraging large pre-trained models may diminish its usability. We conduct an extensive investigation on the trade-off between the model's effectiveness and the cost to measure its usefulness. Table <ref type="table" target="#tab_6">6</ref> presents the time and GPU costs of APCA approaches on average of APR tools. Note that Tian et al.'s approach leverages standard machine learning classifiers which do not require GPU resources. Note, again, PatchZero does not include a training phase. First, PatchZero can finish the inference on each patch within 2.4 seconds, demonstrating its efficiency. Second, although the large pre-trained models (BLOOM and CodeParrot) used in PatchZero are approximately 7.5-10.5 times larger than CodeBERT in terms of the model size, there is only a 1GB difference in GPU costs. Third, it is clear that PatchZero is slower than Tian et al.'s approach and Cache for the inference phase and charges more GPU resources. However, as PatchZero performs better with a large margin and it infers within an acceptable time period <ref type="bibr" target="#b70">[71]</ref>, we argue that it is reasonable to utilize PatchZero for the APCA process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Scaling up the model sizes</head><p>Increasing the size of pre-trained models (e.g., the pretraining corpus, model parameters, etc.) generally leads to better performance <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b71">[72]</ref>. To explore the upper  Please note that we do not try larger BLOOM variants here because there is no API available for BLOOM and we lack computation resources to load the parameters of larger BLOOM to conduct experiments. In addition, to observe the trend, we also implement the smaller variants of PatchZero by adopting smaller pretrained models such as "BLOOM-560m". The overall results are presented in Figure <ref type="figure" target="#fig_5">6</ref>. We observe that the bigger the model size (green dotted line) is, the better they perform in terms of Accuracy (blue solid line) and F1-score (red solid line). PatchZero++ could finally reach an accuracy score of 85.0% and an F1-score of 87.4% on average. It also indicates that the PatchZero framework could be even stronger if a larger pre-trained model can be adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Impacts of the relationship between APR tools</head><p>In Section 5, we evaluate the effectiveness of PatchZero in the "cross-tool" scenario where each APR tool is iteratively regarded as the target APR tool. We denote this setting as a specialized zero-shot setting because we do not have labels of the patches generated by the target APR tool. While PatchZero still needs access to a corpus of labeled patches generated by other APR tools (except the target APR tool), which provides enough information to guide large pre-trained models making judgments on test patches. In the "cross-tool" setting, there is a possible bias that the target APR tool may be very similar to some other APR tools. For instance, Nopol <ref type="bibr" target="#b72">[73]</ref> and DynaMoth <ref type="bibr" target="#b73">[74]</ref>    some APR tools are very similar to each other, it is possible that their generated patches are very similar as well. In the example of Nopol and DynaMoth, if we regard the generated patches of Nopol as the test data, and the patches of DynaMoth as some part of the training data, it may cause a potential data leaking problem. To address this, we carried out extensive experiments by considering the relationship between APR tools. Following the categories proposed by Wang et al. <ref type="bibr" target="#b28">[29]</ref>, the studied 22 APR tools are categorized as follows:</p><p>? Heuristic-based (C1): Arja, CapGen, GenProg, jGen-Prog, jKali, jMutRepaiR, Kali, RSRepair, SimFix; In this regard, we take all the APR tools in one particular category (e.g., C1) as the target APR tools while we consider the others (C2, C3, C4) as the labeled patch pool. As Tables 7-8 demonstrate, PatchZero still outperforms all the baselines by a significant margin (i.e., 15.0%-55.7% and 8.5%-39.2% in weighted Accuracy and F1-score respectively). Moreover, we conducted Wilcoxon signed-rank tests between PatchZero and each of all baselines. The results show that all p values are less than 0.05 (e.g., 0.006 for CodeBERT+FT), indicating that PatchZero is significantly better than the baselines. Therefore, we believe that PatchZero is unaffected by this potential bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Threats to Validity</head><p>Threats to External Validity. Large pre-trained models diverge depending on different aspects, such as the characteristics of pre-training tasks and the size of pre-training datasets. As a threat to validity, our study may have a selection bias by considering only several large pre-trained models. To mitigate this threat, we conducted preliminary experiments with existing open-source models and kept tracking the models that are not publicly shared online.</p><p>Another threat to validity can be dataset selection, as it may deliver bias in the experimental results. The selection, however, is to compare against the state-of-the-art following their settings. Researchers <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref> reported that the dataset had been checked for its correctness which automatically minimized this threat to validity. Finally, the evaluation metrics we borrow sometimes may cause bias depending upon the characteristics of the tasks. We believe this threat is mitigated as we double-checked, and they are well-known for classification tasks. Furthermore, We publicly share our implementation and dataset for future comparisons by the research community. Threats to Internal Validity. The main threat to internal validity lies in the manually crafted prompt that we designed for our model. We cannot ensure that our prompt is optimal as well as it is impossible to traverse all the potential prompts. We mitigate this by following the most common prompts <ref type="bibr" target="#b69">[70]</ref> and we share the prompt in the artifacts for the community to review. Threats to Construct Validity. The large pre-trained model we employ in our study is not perfect, and it may have been under-trained, which can affect its complete effectiveness as we pre-envisioned in the previous Section. This may imply that our design can boost the tool's effectiveness by capturing more practical features for the assessment. We believe our future study can shed light on this threat by considering larger models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>One of the first explored directions in the Automated Patch Correctness Assessment (APCA) task is to augment test inputs. As these approaches run/execute the tests, they are categorized as dynamic APCA approaches by Lin et al. <ref type="bibr" target="#b33">[34]</ref>. To augment the tests, Yang et al. <ref type="bibr" target="#b25">[26]</ref> leveraged fuzz strategies on existing test cases to automatically generate new test inputs. On the contrary, Xin and Reiss <ref type="bibr" target="#b29">[30]</ref> utilized the syntactic differences between the buggy code and its patched code to generate new test inputs while Xiong et al. <ref type="bibr" target="#b24">[25]</ref> focus on the behavior similarity of the failing tests on buggy and patched programs to assess the correctness of generated patches. Recently, Wang et al. <ref type="bibr" target="#b28">[29]</ref> performed a large-scale empirical study on the effectiveness of existing APCA approaches. They mainly studied the dynamic APCA techniques and found that dynamic techniques can achieve higher precision than static approaches. However, assessing patch correctness with the augmented test cases heavily relies on the quality of tests, and tests with high coverage may be unavailable in practice <ref type="bibr" target="#b26">[27]</ref>.</p><p>Another popular research direction in the APCA task is to statically extract code patterns or features from patches to determine the correctness. Ye et al. <ref type="bibr" target="#b26">[27]</ref> proposed ODS to detect overfitting patches. They first statically extracted 4,199 code features at the AST level from the buggy code and generated patches by the APR tools. Then they fed the extracted features to three machine learning algorithms (Logistic Regression, k-Nearest Neighbors, and Random Forest) and ensemble the three models to assess the correctness. As PatchZero is also a static approach, ODS is a similar tool except that it relies on manually identified features on their dataset which implies the generalization of the approach might be difficult <ref type="bibr" target="#b22">[23]</ref>. One of the state-of-the-art, Tian et al. <ref type="bibr" target="#b22">[23]</ref> leveraged representation learning techniques (e.g., BERT <ref type="bibr" target="#b34">[35]</ref>) to build embeddings for overfitting and correct patches generated by APR tools. They then fed the embeddings to machine learning classifiers (e.g. Logistic Regression) to obtain prediction results. Moreover, Lin et al. <ref type="bibr" target="#b33">[34]</ref> proposed Cache that utilized both the context and structure information in patches. Cache achieved state-ofthe-art performances in the APCA task by outperforming existing dynamic and static APCA tools in Accuracy and F1score. Unlike the existing static APCA approaches <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b33">[34]</ref>, PatchZero does not require developers to manually label the patches generated by a new/unseen APR tool, which indeed alleviates the manual labeling process for the APCA task. Finally, Le-Cong et al. <ref type="bibr" target="#b74">[75]</ref> recently proposed Invalidator that utilized both dynamic features (i.e., program invariants) and static features (i.e., code embedding extracted from CodeBERT). However, it is time-consuming in generating the dynamic features. Invalidator took five hours to infer dynamic features and seven minutes (on average) to assess the correctness for a single patch. While PatchZero only costs 2.4 seconds for each patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>Our approach is the first zero-shot Automatic Patch Correctness Assessment (APCA) technique that leverages large pretrained code models to assess the correctness of generated patches by a new/unseen APR tool. The approach includes a specific strategy to select patch examples to help the pre-trained model to understand better the context and task. We build PatchZero by employing recent large pretrained code models (BLOOM and CodeParrot) and form the APCA task into the same format as the pre-training objective of BLOOM and CodeParrot, i.e., generating the next token based on previous tokens. Besides, we propose a contrastive learning-based instance-wise demonstration formation strategy to select similar patches as examples for each test patch, which helps the pre-trained model better understand the correctness of the test patch. Experimental results show that PatchZero outperforms the state-of-theart technique by a significant margin (i.e., 26.6% and 19.1% improvements in terms of accuracy and F1-score on average respectively). Specifically, our technique could achieve an accuracy score of 82.7% and an F1-score of 86.0% on average. The ablation study confirms that the major components (e.g., the large pre-trained models and the instance-wise demonstration formation strategy) of PatchZero contribute to the effectiveness. For future work, we would like to explore the effectiveness of PatchZero on other tasks such as just-in-time defect prediction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 Fig. 2 :</head><label>22</label><figDesc>Fig. 2: Overall Framework of PatchZero.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Generating the embeddings of positive samples via the Dropout operation in SIMCSE. It adopts two different dropout operations which results in two different embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>to use the typical in-context learning method with k labeled examples (x 1 , y 1 )...(x k , y k ). The only difference is that we do not randomly sample the k-labeled examples but select the top-k most similar examples based on our patch embedding model. The incontext learning inference outputs the token y with the highest probability as the prediction for the unlabeled input data x. It can be formally expressed as: y = arg max y P P T M (y|C, x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Confusion Matrices of PatchZero and the best-performing baseline CodeBERT+FT.</figDesc><graphic url="image-23.png" coords="9,73.20,593.40,100.80,100.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: A test patch generated by AVATAR and the predictions given by PatchZero with and without the instance-wise demonstration.</figDesc><graphic url="image-26.png" coords="10,318.13,68.71,200.46,108.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Fig.6: Accuracy and F1-scores of PatchZero on average when the large pre-trained models' sizes increase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>?</head><label></label><figDesc>Constraint-based (C2): ACS, Cardumen, DynaMoth, Jaid, Nopol, SketchFix; ? Template-based (C3): AVATAR, FixMiner, kPAR, SOFix, TBar; ? Learning-based (C4): HDRepair, SequenceR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Frozen Large Pre-trained Models</head><label></label><figDesc></figDesc><table><row><cell cols="4">Labeled patches from non-target APR tool</cell><cell></cell><cell>Test patch</cell></row><row><cell>Patch 1</cell><cell>Correct</cell><cell>Patch 2</cell><cell>Wrong</cell><cell>?</cell><cell>Patch</cell></row><row><cell></cell><cell></cell><cell></cell><cell>input</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>generate</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Correct</cell><cell></cell><cell></cell></row><row><cell cols="6">Fig. 1: An abstracted example of how to use the large</cell></row><row><cell cols="6">pre-trained models. An unlabeled test patch of a new APR</cell></row><row><cell cols="6">tool is concatenated by several labeled patches of existing</cell></row><row><cell cols="6">APR tools to form the input to the pre-trained model.</cell></row><row><cell cols="6">giant model with 176 billion parameters, which has proved</cell></row><row><cell cols="6">an impressive zero-shot ability in a wide range of natural</cell></row><row><cell cols="6">language processing tasks. Recently, a large pre-trained code</cell></row><row><cell cols="6">model namely Codex [40] is proposed to automate coding</cell></row></table><note><p><p><p>in a zero-shot way, i.e., directly synthesizing programs from document strings without a training phase. Impressively, Codex can generate programs that can pass the test cases up to 70.2% of problems on the HumanEval</p><ref type="bibr" target="#b39">[40]</ref> </p>benchmark, driven by the great power of the large pre-trained model with 12 billion parameters. Unfortunately, both GPT-3 and Codex are not open-source.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 :</head><label>1</label><figDesc>Pre-trained Models for Code</figDesc><table><row><cell>Models</cell><cell>Structure</cell><cell>Model Size (Billion)</cell><cell>Max Length (Token)</cell><cell>#Training Data</cell></row><row><cell>CodeBERT [45]</cell><cell>Encoder</cell><cell>0.13</cell><cell>512</cell><cell>8M instances</cell></row><row><cell>CodeT5 [46]</cell><cell>Enc-Dec</cell><cell>0.22</cell><cell>512</cell><cell>8M instances</cell></row><row><cell>Codex [40]</cell><cell>Decoder</cell><cell>12</cell><cell>4,098</cell><cell>Unknown</cell></row><row><cell>CodeParrot [42]</cell><cell>Decoder</cell><cell>1.5</cell><cell>1,024</cell><cell>15B tokens</cell></row><row><cell cols="2">BLOOM-1.1b [41] Decoder</cell><cell>1.1</cell><cell>2,048</cell><cell>366B tokens</cell></row><row><cell>BLOOM [41]</cell><cell>Decoder</cell><cell>176</cell><cell>2,048</cell><cell>366B tokens</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2 :</head><label>2</label><figDesc>Hyper-parameter Tuning Results (F1-score) of PatchZero.</figDesc><table><row><cell cols="3">Hyper-parameters</cell><cell></cell><cell cols="2">Top k</cell></row><row><cell cols="3">Tuning (F1-score)</cell><cell>3</cell><cell>5</cell><cell>10</cell><cell>15</cell></row><row><cell cols="2">Threshold ?</cell><cell>0.85 0.90 0.95</cell><cell>69.6 70.2 70.1</cell><cell>71.1 71,4 70.7</cell><cell>71.0 71.7 71.0</cell><cell>70.8 71.6 71.0</cell></row><row><cell>Recall =</cell><cell>T P T P +F N</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 :</head><label>3</label><figDesc>Accuracy of PatchZero and Baselines.</figDesc><table><row><cell>Target APR</cell><cell>Tian et al. [23]</cell><cell>Cache [34]</cell><cell>CodeBERT +LR</cell><cell>CodeBERT +FT</cell><cell>PatchZero</cell></row><row><cell>ACS</cell><cell>56.1</cell><cell>55.3</cell><cell>51.2</cell><cell>36.6</cell><cell>68.3</cell></row><row><cell>Arja</cell><cell>57.9</cell><cell>42.1</cell><cell>68.4</cell><cell>89.5</cell><cell>91.2</cell></row><row><cell>AVATAR</cell><cell>53.7</cell><cell>66.7</cell><cell>61.1</cell><cell>72.2</cell><cell>81.5</cell></row><row><cell>CapGen</cell><cell>58.0</cell><cell>78.1</cell><cell>72.4</cell><cell>76.0</cell><cell>82.0</cell></row><row><cell>Cardumen</cell><cell>66.7</cell><cell>44.4</cell><cell>55.6</cell><cell>88.9</cell><cell>88.9</cell></row><row><cell>DynaMoth</cell><cell>59.1</cell><cell>68.2</cell><cell>81.8</cell><cell>95.5</cell><cell>95.5</cell></row><row><cell>FixMiner</cell><cell>56.0</cell><cell>72.1</cell><cell>64.1</cell><cell>68.0</cell><cell>84.0</cell></row><row><cell>GenProg</cell><cell>56.0</cell><cell>88.2</cell><cell>56.3</cell><cell>88.0</cell><cell>96.0</cell></row><row><cell>HDRepair</cell><cell>87.5</cell><cell>37.5</cell><cell>50.0</cell><cell>50.0</cell><cell>87.5</cell></row><row><cell>Jaid</cell><cell>63.9</cell><cell>67.6</cell><cell>55.6</cell><cell>55.6</cell><cell>72.2</cell></row><row><cell>jGenProg</cell><cell>56.4</cell><cell>87.2</cell><cell>53.8</cell><cell>89.7</cell><cell>84.6</cell></row><row><cell>jKali</cell><cell>60.0</cell><cell>80.1</cell><cell>60.5</cell><cell>85.7</cell><cell>91.4</cell></row><row><cell>jMutRepair</cell><cell>75.0</cell><cell>50.2</cell><cell>68.8</cell><cell>75.0</cell><cell>87.5</cell></row><row><cell>Kali</cell><cell>60.5</cell><cell>76.3</cell><cell>76.3</cell><cell>94.7</cell><cell>89.5</cell></row><row><cell>kPAR</cell><cell>70.6</cell><cell>73.5</cell><cell>67.6</cell><cell>88.2</cell><cell>79.4</cell></row><row><cell>Nopol</cell><cell>58.9</cell><cell>72.6</cell><cell>60.8</cell><cell>89.5</cell><cell>93.7</cell></row><row><cell>RSRepair</cell><cell>60.6</cell><cell>63.6</cell><cell>69.7</cell><cell>81.8</cell><cell>94.0</cell></row><row><cell>SequenceR</cell><cell>76.4</cell><cell>65.2</cell><cell>56.4</cell><cell>65.5</cell><cell>63.6</cell></row><row><cell>SimFix</cell><cell>48.3</cell><cell>65.5</cell><cell>60.3</cell><cell>70.7</cell><cell>75.9</cell></row><row><cell>SketchFix</cell><cell>66.7</cell><cell>75.0</cell><cell>50.2</cell><cell>66.7</cell><cell>83.3</cell></row><row><cell>SOFix</cell><cell>72.7</cell><cell>45.5</cell><cell>63.6</cell><cell>9.1</cell><cell>36.4</cell></row><row><cell>TBar</cell><cell>77.5</cell><cell>65.9</cell><cell>50.1</cell><cell>80.0</cell><cell>90.0</cell></row><row><cell>Average</cell><cell>63.6</cell><cell>65.3</cell><cell>61.6</cell><cell>73.5</cell><cell>82.7</cell></row><row><cell>Improve.</cell><cell cols="2">+30.0% +26.6%</cell><cell>+34.2%</cell><cell>+12.5%</cell><cell>-</cell></row><row><cell>Weighted Average</cell><cell>61.4</cell><cell>67.5</cell><cell>61.7</cell><cell>75.8</cell><cell>83.0</cell></row><row><cell>Improve.</cell><cell cols="2">+35.1% +22.3%</cell><cell>+34.5%</cell><cell>+9.5%</cell><cell>-</cell></row></table><note><p>LR: apply Logistic Regression upon the frozen model, FT: Fine-tuning.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4 :</head><label>4</label><figDesc>F1-score of PatchZero and Baselines.</figDesc><table><row><cell>Target APR</cell><cell>Tian et al. [23]</cell><cell>Cache [34]</cell><cell>CodeBERT +LR</cell><cell>CodeBERT +FT</cell><cell>PatchZero</cell></row><row><cell>ACS</cell><cell>40.0</cell><cell>45.2</cell><cell>41.2</cell><cell>35.0</cell><cell>55.2</cell></row><row><cell>Arja</cell><cell>70.7</cell><cell>52.2</cell><cell>78.6</cell><cell>94.0</cell><cell>94.9</cell></row><row><cell>AVATAR</cell><cell>63.8</cell><cell>71.9</cell><cell>68.7</cell><cell>81.5</cell><cell>87.8</cell></row><row><cell>CapGen</cell><cell>71.2</cell><cell>85.7</cell><cell>82.5</cell><cell>83.8</cell><cell>88.3</cell></row><row><cell>Cardumen</cell><cell>80.0</cell><cell>61.5</cell><cell>71.4</cell><cell>94.1</cell><cell>94.1</cell></row><row><cell>DynaMoth</cell><cell>72.7</cell><cell>81.1</cell><cell>90.0</cell><cell>97.7</cell><cell>97.7</cell></row><row><cell>FixMiner</cell><cell>68.6</cell><cell>80.0</cell><cell>72.7</cell><cell>77.8</cell><cell>89.5</cell></row><row><cell>GenProg</cell><cell>70.3</cell><cell>93.6</cell><cell>71.8</cell><cell>93.6</cell><cell>98.0</cell></row><row><cell>HDRepair</cell><cell>88.9</cell><cell>44.4</cell><cell>50.0</cell><cell>50.0</cell><cell>88.9</cell></row><row><cell>Jaid</cell><cell>68.3</cell><cell>70.9</cell><cell>67.3</cell><cell>67.3</cell><cell>78.7</cell></row><row><cell>jGenProg</cell><cell>70.2</cell><cell>90.6</cell><cell>69.0</cell><cell>94.3</cell><cell>93.0</cell></row><row><cell>jKali</cell><cell>75.0</cell><cell>88.1</cell><cell>74.1</cell><cell>92.1</cell><cell>95.2</cell></row><row><cell>jMutRepair</cell><cell>85.7</cell><cell>63.6</cell><cell>81.5</cell><cell>85.7</cell><cell>92.9</cell></row><row><cell>Kali</cell><cell>73.7</cell><cell>86.2</cell><cell>86.2</cell><cell>97.3</cell><cell>94.4</cell></row><row><cell>kPAR</cell><cell>82.1</cell><cell>84.2</cell><cell>80.0</cell><cell>93.5</cell><cell>88.1</cell></row><row><cell>Nopol</cell><cell>72.7</cell><cell>84.0</cell><cell>75.0</cell><cell>94.4</cell><cell>96.7</cell></row><row><cell>RSRepair</cell><cell>74.5</cell><cell>76.0</cell><cell>80.8</cell><cell>90.0</cell><cell>96.8</cell></row><row><cell>SequenceR</cell><cell>84.7</cell><cell>75.0</cell><cell>67.6</cell><cell>75.3</cell><cell>74.4</cell></row><row><cell>SimFix</cell><cell>59.5</cell><cell>77.3</cell><cell>70.9</cell><cell>79.5</cell><cell>84.8</cell></row><row><cell>SketchFix</cell><cell>71.4</cell><cell>82.4</cell><cell>62.5</cell><cell>66.7</cell><cell>85.7</cell></row><row><cell>SOFix</cell><cell>40.0</cell><cell>20.0</cell><cell>33.3</cell><cell>16.7</cell><cell>22.2</cell></row><row><cell>TBar</cell><cell>85.7</cell><cell>74.1</cell><cell>63.6</cell><cell>88.2</cell><cell>94.1</cell></row><row><cell>Average</cell><cell>71.4</cell><cell>72.2</cell><cell>69.9</cell><cell>79.5</cell><cell>86.0</cell></row><row><cell>Improve.</cell><cell cols="2">+20.4% +19.1%</cell><cell>+23.0%</cell><cell>+8.1%</cell><cell>-</cell></row><row><cell>Weighted Average</cell><cell>70.7</cell><cell>75.0</cell><cell>71.6</cell><cell>82.3</cell><cell>87.3</cell></row><row><cell>Improve.</cell><cell cols="2">+23.5% +16.4%</cell><cell>+21.9%</cell><cell>+6.1%</cell><cell>-</cell></row></table><note><p>LR: apply Logistic Regression upon the frozen model, FT: Fine-tuning.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 5 :</head><label>5</label><figDesc>Results of the ablation study in terms ofAccuracy and F1-score on average of all APR tools. Note that "w.o." refers to "without".</figDesc><table><row><cell></cell><cell>Ablation Study</cell><cell>Acc.</cell><cell>F1</cell></row><row><cell>full model</cell><cell>PatchZero</cell><cell>82.7</cell><cell>86.0</cell></row><row><cell>ensemble</cell><cell>PatchZero (BLOOM only) PatchZero (CodeParrot only)</cell><cell>81.1 81.0</cell><cell>84.9 85.1</cell></row><row><cell>components</cell><cell>wo. Large Pre-trained Models w.o. Demonstration</cell><cell>70.0 72.7</cell><cell>75.0 81.6</cell></row><row><cell cols="4">tailored demonstration formulations. "PatchZero (wo. Large</cell></row><row><cell cols="4">Pre-trained Models)" represents the model variant that does</cell></row><row><cell cols="4">not use the large pre-trained models to generate predictions.</cell></row><row><cell cols="4">Instead, it uses a k-Nearest Neighbor (kNN) model as the</cell></row><row><cell cols="4">classifier. Specifically, it retrieves the N most similar patches</cell></row><row><cell cols="4">to the test patch by leveraging the patch embedding model.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 6 :</head><label>6</label><figDesc>Time and GPU costs of PatchZero, Tian et al.'s approach, Cache, and CodeBERT (fine-tuning).</figDesc><table><row><cell>Cost</cell><cell>Tian et al.</cell><cell>Cache</cell><cell>CodeBERT</cell><cell>PatchZero</cell></row><row><cell>Train</cell><cell>1s</cell><cell>2m 30s</cell><cell>4m 8s</cell><cell>-</cell></row><row><cell>Test (per patch)</cell><cell>2.5ms</cell><cell>0.37s</cell><cell>0.45s</cell><cell>2.4s</cell></row><row><cell>GPU Memory</cell><cell>-</cell><cell>5GB</cell><cell>7GB</cell><cell>8GB</cell></row><row><cell>Evaluation Metrics (%)</cell><cell></cell><cell></cell><cell></cell><cell>Model Sizes (Billion)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>are two variants of the same program repairing framework. If</figDesc><table /><note><p>2. https://beta.openai.com/playground?model=code-davinci-002</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 7 :</head><label>7</label><figDesc>Accuracy of PatchZero and Baselines considering a set of APR tools as the target.</figDesc><table><row><cell>Target Group (#patch)</cell><cell>C1 (351)</cell><cell>C2 (251)</cell><cell>C3 (164)</cell><cell>C4 (63)</cell><cell>avg.</cell><cell>weighted avg.</cell></row><row><cell>Tian et al. [23]</cell><cell>41.6</cell><cell>72.5</cell><cell>42.1</cell><cell>77.8</cell><cell>58.5</cell><cell>53.8</cell></row><row><cell>Cache [34]</cell><cell>61.8</cell><cell>61.4</cell><cell>75.6</cell><cell>58.7</cell><cell>63.4</cell><cell>64.1</cell></row><row><cell>CodeBERT+LR</cell><cell>45.0</cell><cell>55.8</cell><cell>62.2</cell><cell>57.1</cell><cell>55.0</cell><cell>52.6</cell></row><row><cell>CodeBERT+FT</cell><cell>69.2</cell><cell>70.5</cell><cell>73.8</cell><cell>77.8</cell><cell>72.8</cell><cell>71.2</cell></row><row><cell>PatchZero</cell><cell>86.6</cell><cell>82.9</cell><cell>76.2</cell><cell>66.7</cell><cell>78.1</cell><cell>81.9</cell></row><row><cell cols="3">Note that "avg." refers to "average".</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 8 :</head><label>8</label><figDesc>F1-score of PatchZero and Baselines considering a set of APR tools as the target.</figDesc><table><row><cell>Target Group (#patch)</cell><cell>C1 (351)</cell><cell>C2 (251)</cell><cell>C3 (164)</cell><cell>C4 (63)</cell><cell>avg.</cell><cell>weighted avg.</cell></row><row><cell>Tian et al. [23]</cell><cell>54.9</cell><cell>82.8</cell><cell>49.2</cell><cell>85.1</cell><cell>68.0</cell><cell>64.5</cell></row><row><cell>Cache [34]</cell><cell>73.9</cell><cell>68.2</cell><cell>82.6</cell><cell>69.8</cell><cell>73.6</cell><cell>73.6</cell></row><row><cell>CodeBERT+LR</cell><cell>56.6</cell><cell>65.6</cell><cell>72.6</cell><cell>70.0</cell><cell>66.2</cell><cell>63.5</cell></row><row><cell>CodeBERT+FT</cell><cell>79.8</cell><cell>82.6</cell><cell>81.1</cell><cell>87.5</cell><cell>82.8</cell><cell>81.5</cell></row><row><cell>PatchZero</cell><cell>92.4</cell><cell>88.5</cell><cell>84.2</cell><cell>76.4</cell><cell>85.4</cell><cell>88.4</cell></row><row><cell cols="3">Note that "avg." refers to "average".</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://huggingface.co/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Genprog: A generic method for automatic software repair</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="54" to="72" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Staged program repair with condition synthesis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2015 10th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">History driven program repair</title>
		<author>
			<persName><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Goues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="213" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Leveraging syntax-related code for automated program repair</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM International Conference on Automated Software Engineering</title>
		<imprint>
			<biblScope unit="page" from="660" to="670" />
			<date type="published" when="2017">2017. 2017</date>
			<publisher>ASE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Shaping program repair space with existing patches and similar code</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis</title>
		<meeting>the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lsrepair: Live search of fix ingredients for automated program repair</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koyuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyand?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Asia-Pacific Software Engineering Conference (APSEC)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="658" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mining stackoverflow for program repair</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="118" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Understanding the non-repairability factors of automated program repair techniques</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Asia-Pacific Software Engineering Conference (APSEC)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the impact of flaky tests in automated program repair</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyand?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Automatic software repair: a bibliography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tbar: revisiting template-based automated program repair</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koyuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyand?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis</title>
		<meeting>the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A syntax-guided edit decoder for neural program repair</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</title>
		<meeting>the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cure: Code-aware neural machine translation for automatic program repair</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lutellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1161" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An analysis of the search spaces for generate and validate patch generation systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="702" to="713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overfitting in semantics-based automated program repair</title>
		<author>
			<persName><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Thung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Goues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="3007" to="3033" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On reliability of patch correctness assessment</title>
		<author>
			<persName><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="524" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How different is it between machine-generated and developer-provided patches? : An empirical study on the correct patches generated by automated program repair techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM/IEEE International Symposium on Empirical Software Engineering and Measurement</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Exploring true test overfitting in dynamic automated program repair using formal methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nilizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Leavens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pasareanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 14th IEEE Conference on Software Testing, Verification and Validation</title>
		<imprint>
			<publisher>ICST</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="229" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Overfitting in semantics-based automated program repair</title>
		<author>
			<persName><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Thung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Goues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="3007" to="3033" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An analysis of patch plausibility and correctness for generate-and-validate patch generation systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Achour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Symposium on Software Testing and Analysis</title>
		<meeting>the 2015 International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Why don&apos;t software developers use static analysis tools to find bugs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Murphy-Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Bowdidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 35th International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="672" to="681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Practitioners&apos; expectations on automated fault localization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Kochhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Symposium on Software Testing and Analysis</title>
		<meeting>the 25th International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating representation learning of code changes for predicting patch correctness in program repair</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Kabor?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koyuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyand?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="981" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Anti-patterns in search-based program repair</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roychoudhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting>the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identifying patch correctness in test-based program repair</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th international conference on software engineering</title>
		<meeting>the 40th international conference on software engineering</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="789" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Better test cases for better automated program repair</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhikhartsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2017 11th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automated classification of overfitting patches with statically extracted code features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2920" to="2938" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated patch assessment for program repair at scale</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empir. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated patch correctness assessment: How far are we?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="968" to="980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Identifying test-suite-overfitted patches through test case generation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIG-SOFT International Symposium on Software Testing and Analysis</title>
		<meeting>the 26th ACM SIG-SOFT International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Randoop: feedback-directed random testing for java</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pacheco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA &apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Contextaware patch generation for better automated program repair</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM 40th International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">S3: syntax-and semantic-guided repair synthesis via programming by examples</title>
		<author>
			<persName><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-H</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2017 11th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Context-aware code change embedding for better patch correctness assessment</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Software Engineering and Methodology (TOSEM)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<ptr target="http://arxiv.org/abs/1810.04805" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey of cross-validation procedures for model selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arlot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celisse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics surveys</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="40" to="79" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cross-validation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Refaeilzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of database systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="532" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the transferability of pre-trained language models for low-resource programming languages</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Fard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bryksin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/ACM 30th International Conference on Program Comprehension (ICPC)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="401" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2005">2005.14165, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ponde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Khlaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plappert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chantzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Guss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Morikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Murati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcgrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mc-Candlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<idno>abs/2107.03374</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Evaluating large language models trained on code</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">What language model to train if you have one million gpu hours?</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Launay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">in 60th Annual Meeting of the Association for Computational Linguistics (ACL) Workshop &quot;Challenges &amp; Perspectives in Creating Large Language Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Natural language processing with transformers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<imprint>
			<publisher>O&apos;Reilly Media, Inc</publisher>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Recommending comprehensive solutions for programming tasks by mining crowd knowledge</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F G</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V R</forename><surname>Paix?o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maia</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Program Comprehension (ICPC)</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="358" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Answerbot: Automated generation of answer summary to developers&apos; technical questions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="706" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Codebert: A pre-trained model for programming and natural languages</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno>abs/2002.08155</idno>
		<ptr target="https://arxiv.org/abs/2002.08155" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<idno>abs/2109.00859</idno>
		<ptr target="https://arxiv.org/abs/2109.00859" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Roberta: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1907.11692" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1907">1907.11692. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Graphcodebert: Pre-training code representations with data flow</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2009">2009.08366, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/3" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note>f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Codesearchnet challenge: Evaluating the state of semantic code search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Husain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gazit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09436</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Codexglue: A machine learning benchmark dataset for code understanding and generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Svyatkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sundaresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/2102.04664</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Lora: Low-rank adaptation of large language models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/2106.09685</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno>abs/2107.13586</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Openprompt: An open-source framework for prompt-learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/2111.01998</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sch ?tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<idno>abs/1508.07909</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Simcse: Simple contrastive learning of sentence embeddings</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/2104.08821</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Cc2vec: Distributed representations of code changes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lawall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<idno>abs/2003.05620</idno>
		<ptr target="https://arxiv.org/abs/2003.05620" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">How often do single-statement bugs occur?: The manysstubs4j dataset</title>
		<author>
			<persName><forename type="first">R.-M</forename><surname>Karampatsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Mining Software Repositories</title>
		<meeting>the 17th International Conference on Mining Software Repositories</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Megadiff: A dataset of 600k java source code changes categorized by diff size</title>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Madeiral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/2108.04631</idno>
		<ptr target="https://arxiv.org/abs/2108.04631" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Applying codebert for automated program repair of java simple bugs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mashhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hemmati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="505" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Selfsupervised bug detection and repair</title>
		<author>
			<persName><forename type="first">M</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jackson-Flux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Beep: Fine-grained fix localization by learning to predict buggy code elements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyand'e</surname></persName>
		</author>
		<idno>abs/2111.07739</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">L2-norm multiple kernel learning and its application to biomedical data fusion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Falck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Daemen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Tranchevent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A K</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Moreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="309" to="309" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Defects4j: a database of existing faults to enable controlled testing studies for java programs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>in ISSTA 2014</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v32/le14.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning, ser. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Jebara</surname></persName>
		</editor>
		<meeting>the 31st International Conference on Machine Learning, ser. Machine Learning Research<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2014-06">Jun 2014</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neeraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Teehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno>abs/2110.08207</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Qbsum: A large-scale query-based document summarization dataset from real-world applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page">101166</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.07682</idno>
		<title level="m">Emergent abilities of large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Nopol: Automatic repair of conditional statement bugs in java programs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Demarco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Marcote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Le</forename><surname>Berre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="55" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Dynamoth: dynamic code synthesis for automatic program repair</title>
		<author>
			<persName><forename type="first">T</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Automation of Software Test</title>
		<meeting>the 11th International Workshop on Automation of Software Test</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="85" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Invalidator: Automated patch correctness assessment via semantic and syntactic reasoning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Le-Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">B D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N.-H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Quang-Huy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-T</forename><surname>Huynh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.01113</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
