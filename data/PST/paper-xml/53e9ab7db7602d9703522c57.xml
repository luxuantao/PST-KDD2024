<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Performance of Checksums and CRCs over Real Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jonathan</forename><surname>Stone</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Michael Greenwald</orgName>
								<orgName type="institution" key="instit2">Stanford University Craig Partridge</orgName>
								<orgName type="institution" key="instit3">BBN Technologies ¡ Jim Hughes</orgName>
								<orgName type="institution" key="instit4">Network Systems Corporation</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Performance of Checksums and CRCs over Real Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6E7043065050F2A4BE65754A4AF13EBB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Checksum and CRC algorithms have historically been studied under the assumption that the data fed to the algorithms was uniformly distributed. This paper examines the behavior of checksums and CRCs over real data from various UNIX file systems. We show that, when given real data in small to modest pieces (e.g., 48 bytes), all the checksum algorithms have skewed distributions. In one dramatic case, 0.01% of the check values appeared nearly 15% of the time. These results have implications for CRCs and checksums when applied to real data. They also can cause a spectacular failure rate for both the TCP and onescomplement Fletcher checksums when trying to detect certain types of packet splices. When measured over several large file-systems, the 16 bit TCP checksum performed about as well as a 10 bit CRC.</p><p>We show that for fragmentation-and-reassembly error models, the checksum contribution of each fragment are, in effect, coloured by the fragment's offset in the splice. This coloring explains the performance of Fletcher's sum on non-uniform data, and shows that placing checksum fields in a packet trailer is theoretically no worse than a header checksum field. In practice, TCP trailer sums outperform even Fletcher header sums. system code % remaining splices sics.se Total 3183838883 /src1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The behavior of checksum and cyclic redundancy check (CRC) algorithms have historically been studied under the assumption that the data fed to the algorithms was uniformly distributed. (See, for instance, the work on Fletcher's checksum <ref type="bibr" target="#b1">[2]</ref> and the AAL5 CRC <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b3">4]</ref>). If one assumes random data drawn from a uniform distribution one can show a number of nice error detection properties for various checksums and CRCs. But in the real world, ¢ Jonathan and Michael's work was supported, in part, by ARPA under Army Contract DABT63-91-K-0001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>£</head><p>BBN Technologies is a division of GTE Corporation. Craig's work was supported, in part, by the U.S. Department of Defense. communications data is rarely random. Much of the data is character data, which has distinct skewing towards certain values (for instance, the character 'e' in English). Binary data has similarly non-random distribution of values, such as a propensity to contain zeros.</p><p>This paper reports on experiments with running various checksums and CRCs over real data from UNIX file systems. We show that the highly non-uniform distribution of values and the strong local correlation in real data causes extremely irregular distributions of checksum and CRC values. In some tests, less than 0.01% of the possible checksum values occurred over 15% of the time. We particularly examine the effects of this phenomenon when applied to the Internet checksum used for IP, TCP, and UDP <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b0">1]</ref> and compare it to two variations of Fletcher's checksum. We also report on an experiment with placing the standard TCP checksum in a packet trailer. A trailer checksum noticeably increases the checksum's effectiveness, and we prove why this is so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CRCs vs. Checksums</head><p>Before examining the behavior of different algorithms, it is worth briefly discussing the CRC and checksum algorithms we used.</p><p>CRCs are based on polynomial arithmetic, base 2. CRC-32 <ref type="bibr" target="#b4">[5]</ref> is a 32-bit polynomial with several useful error detection properties. It will detect all errors that span less than 32 contiguous bits within a packet and all 2-bit errors less than 2048 bits apart. It will also detect all cases where there are an odd number of errors. For other types of errors, if they occur in data which has uniformly distributed values, the chance of not detecting an error is ¤ in ¥ §¦ ©¨.</p><p>The concept of a checksum is less well defined. For the purposes of data communication, the goal of a checksum algorithm is to balance the effectiveness at detecting errors against the cost of computing the check values. Furthermore, it is expected that a checksum will work in conjunction with other, stronger, data checks such as a CRC. For example, MAC layers are expected to use a CRC to check that data was not corrupted during transmission on the local media, and checksums are used by higher layers to ensure that data was not corrupted in intermediate routers or by the sending or receiving host.</p><p>The fact that checksums are typically the secondary level of protection has often led to suggestions that checksums are superfluous. Hard won experience, however, has shown that checksums are necessary. Software errors (such as buffer mismanagement) and even hardware errors (such as network adapters with poor DMA hardware that sometimes fail to fully DMA data) are surprisingly common and checksums have been very useful in protecting against such errors.</p><p>The two most popular checksums are the Internet checksum used for IP, TCP, and UDP <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b0">1]</ref> and Fletcher's checksum <ref type="bibr" target="#b1">[2]</ref>. They represent different balances between performance cost and error detection.</p><p>The TCP checksum is a 16-bit ones-complement sum of the data. This sum will catch any burst error of 15 bits or less <ref type="bibr" target="#b7">[8]</ref>, and all 16-bit burst errors except for those which replace one 1's complement zero with another (i.e., 16 adjacent 1 bits replaced by 16 zero bits, or vice-versa). Over uniformly distributed data, it is expected to detect other types of errors at a rate proportional to ¤ in ¥ ¢¡ . The checksum also has a major limitation: the sum of a set of 16-bit values is the same, regardless of the order in which the values appear. The checksum was chosen by the Internet community in the late 1970s after experimentation on the ARPANET suggested the checksum was good enough and could be implemented efficiently.</p><p>Fletcher's checksum is designed to be a more robust error detecting code. The checksum keeps two sums. One sum, £ , is a running sum of the data in 8-bit chunks. The other sum, ¤ , is a running sum of each byte multiplied by its position from the end of the packet. This multiplication incorporates positional information into the checksum to protect against movement or transposition of data within the packet. The two 8-bit sums are concatenated to generate a 16-bit checksum. Fletcher also defined a 32-bit version, where 16-bit sums are kept. The algorithm was defined for both ones and twos-complement arithmetic. The version used for the TP4 checksum and in this paper uses 8-bit chunks. When performed in twos-complement, this 16-bit checksum detects all single bit errors, a single error of less than 16 bits in length, and all double bit errors separated by 16 bits or less. Though TP4 uses only the twos-complement version, we investigated both ones-and twos-complement Fletcher sums.</p><p>Historically, the TCP checksum and Fletcher's checksum have been viewed as offering a sharp tradeoff between performance and error detection capabilities. The TCP checksum requires one or two additions per machine word of data (assuming the machine word is a multiple of 16 bits long), while Fletcher's sum requires two additions per byte (even if the computation is done in word-sized chunks). As a result, measurements have typically shown the TCP checksum to be two to four times faster <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>. However, that difference may be declining on newer processors, where the memory access time dominates any computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Work with AAL5</head><p>This study began as a study of the error scenarios for packet splices in Asynchronous Transfer Mode (ATM) Adaptation Layer 5 (AAL5). The AAL5 work helps motivate the rest of the paper and so is explained briefly here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">What is a Packet Splice?</head><p>AAL5 sends packets as a series of ATM cells, with the last cell specially marked using a bit in the ATM header.</p><p>A packet splice occurs when the right number of cells are dropped such that pieces of two adjacent packets are combined so that they appear to represent one AAL5 packet. Figure <ref type="figure" target="#fig_0">1</ref> illustrates a splice: Two four-cell packets suffer a loss of four cells, such that the first and third cell of the first packet and the first and last cells of the second packet are spliced together to look like a single four-cell packet.</p><p>It should be noted that ATM does not allow cells to be reordered, thus the number of possible splices is limited to those that merely drop, and do not reorder, cells. Several conditions must be met for a splice to be valid. First, AAL5 stores the length of the packet in the last cell, so the size of the splice must be consistent with the AAL5 length in the last cell. Second, because AAL5 specially marks the last cell of every packet, the last cell of the first packet cannot be part of the splice. Third, the first 40 bytes of the first cell must be a valid TCP/IP header (i.e., have a length consistent with the packet length and certain bits must be set). Unless all three of these requirements are met, the splice will be easily detected without checking the CRC or checksum.</p><p>If the three requirements are met, then the splice has to be detected by either the AAL5 CRC (CRC-32) or the higher layer protocol's checksum (such as the TCP or Fletcher's checksum).</p><p>In 1993, an informal study by Bill Marshall and Chuck Kalmanek at AT&amp;T Bell Labs simulated file transfers from a UNIX filesystem (using real data from the filesystem) and examined the performance of the AAL5 CRC. They found a surprising number of cases where the packet splice passed the AAL5 CRC, leading them to wonder if the AAL5 CRC was strong enough. With Marshall's and Kalmanek's assistance, the authors set out to do a more complete set of tests. Those results were reported in an earlier version of this paper, presented at SIGCOMM '95 <ref type="bibr" target="#b6">[7]</ref>. Some open questions and surprising results led us to perform a new and more comprehensive series of tests to resolve these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Testing Splices</head><p>Our test program simulated a file transfer with the File Transfer Protocol (FTP) of all files on a file system (or selected directories of a file system) via TCP/IP using AAL5 over ATM. All IP and TCP header fields were filled in as if the file transfer were being done over the loopback interface (127.0.0.1). For each packet, the TCP sequence number was incremented by the data length, and the IP ID was incremented by one. The program then examined all possible splices of two adjacent TCP segments and checked to see if either the TCP checksum or AAL5 CRC failed to detect the splice. The program did not concern itself with splices whose data exactly matched a valid packet, nor with those splices that were detected by IP, TCP, or AAL5 header/trailer checks.</p><p>The test program was run over file systems at Network Systems Corporation (NSC), the Swedish Institute of Computer Science (SICS), and Stanford University. The TCP segment sizes examined were 256 bytes long, except for runt packets at the end of files. The first row in Tables 1 through 3 counts the total number of splices inspected. The next row counts how many invalid splices were detected by simple header checks, and so did not need to check the checksum. The row labeled "Identical data" records how many splices resulted in packets that were identical to one of the original packets, and hence would not result in corrupted data (the checksum, of course, was identical). The "Remaining" packets were all incorrect and depended on the checksum and the CRC to detect the corruption. All percentages listed are computed as percent of "Remaining splices". The rows following "Remaining" list the splices missed by the CRC test and the TCP checksum test. There were no splices missed by both CRC and the TCP checksum. The data from each site are broken down by file system. The total number of splices is greater than ¥ ¦ ©¨.</p><p>We would expect that the CRC of a splice would match the CRC of the original AAL5 packet at a rate of 1 in ¥ ¦ ©¨(or 0.0000000232% of the time). Similarly, we would expect that the TCP checksum would fail to catch bad splices at a   (or 0.001526% of the time). Observe that for the CRC, the CRC must match the CRC of the second AAL5 packet, while for TCP, the checksum over the entire splice must equal zero.</p><p>The tables show that for real data, the CRC failure rate is almost perfectly consistent with the expected failure rate for random data, and is therefore not the subject of much further investigation in this paper . For TCP, however, the story is different. Between 0.008% and 0.22% of the bad splices passed by the header checks passed the checksum. This is between a factor of 10 and 100 worse than expected, and requires some explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Explaining The TCP Checksum Failures</head><p>Why does the TCP checksum fail to detect so many splices? The reasons have to do with the distribution of data values and how data from one packet can be mixed with data from another packet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Failure Scenarios</head><p>We can compute the TCP checksum in pieces and then add the pieces to get the complete packet sum. So, we can think of the TCP checksum of a packet broken into ATM cells as being the sum of the individual checksums of each 48-byte cell.</p><p>The usual requirement for a splice to pass the TCP checksum is that the checksum of the splice add up to the checksum of the entire first packet contributing to the splice. Because the splice contains cells of the first and second packets, this requirement can also be expressed as a requirement that the checksum of the cells from the first The difference between our results and those of Marshall and Kalmanek are the "Identical Data" entries. Given that the payloads were identical, it is not a failure if the CRC doesn't detect these splices as no data-corruption occurs. Their tests did not distinguish the cases of splices with identical data from splices with different data but congruent checksums.</p><p>packet not included in the splice must equal the checksum from the cells of the second packet that are included in the splice. If just one cell from the second packet is included in the splice, this requirement reduces to the requirement that the checksum of the cell from the second packet have the same sum as the cell it replaces. In multicell replacements, the sum of the mixes of cells must be equal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Distributions of the TCP Checksum</head><p>Given random data, a good checksum or CRC should uniformly scatter the checksum values over the entire checksum space. Obviously a checksum algorithm that does not uniformly distribute checksum values (i.e., has hotspots) will be more likely to have multiple cells with the same checksum. Theorem 6 in Appendix A proves that, over uniformly distributed data, the TCP checksum algorithm gives a uniform distribution of checksum values¨. Thus, any hotspots in the distribution of checksum values are due to non-uniformity of the data, and are not inherent in the TCP checksum algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Distribution of Checksum Values over Single Cells</head><p>If the distribution of 16-bit words is completely uniform, the chance of an arbitrary sequence of data in the first packet having the same checksum as an equal-sized arbitrary sequence of data in the second packet is ¤ ¢¡ , where</p><formula xml:id="formula_0">¡ ¤£ ¥ ¢¡</formula><p>. However, the distribution of values over real data is not uniform.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> shows three plots summarizing the distribution of checksum values on the filesystem /u1 on smeg.dsg.stanford.edu. The x-axis represents different checksum values, sorted by frequency to better show the distribution. In the PDF graphs, the ¥ -axis is the probability that the given checksum value occurred. Fig. <ref type="figure" target="#fig_2">2</ref>(a) shows the entire PDF, and (b) shows a blowup of the most frequent 65 values (0.1%) The CDF (fig. <ref type="figure" target="#fig_2">2c</ref>) shows the same 65 values, but here the ¥ -value for a given ¦ represents the cumulative probability that any of the most common ¦ values occurred. If the distribution were uniform then the PDF should simply be a horizontal line at ¤ §¡ , and the CDF a straight line with slope ¤ ¢¡ . This data shows that the TCP checksum on real data has hotspots. In the file system shown in the figure (smeg:/u1), the top 0.1% of the checksum values occurred 2.5% of the time. If one examines this distributional data over many filesystems, one discovers two things. First, that the single most common checksum value (usually zero) occurs between 0.01% and 1% of the time. Second, that for 48 byte cells the 65 next most frequently occurring checksum values ¨The actual requirements are weaker: as long as the values of even one word in the packet is uniformly distributed over all © possible values, then the checksum of the entire packet is uniformly distributed over all possible values.</p><p>(0.1% of the checksum space) account for between 1% and 5% of the checksum values seen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Checksum Distribution over Larger Blocks of</head><p>Data Although for uniformly distributed data values the probability distribution of the checksum is uniform independent of the length of the block of data, this is not true for nonuniform data. In that case, the expected probability distribution of the checksum may be computed by where is the probability that the checksum over a block of length @ is equal to , and where</p><formula xml:id="formula_1">£ ! " # %$ '&amp; )(</formula><formula xml:id="formula_2">)5 A2</formula><p>is taken mod</p><formula xml:id="formula_3">¡ .</formula><p>The dotted line in Figure <ref type="figure" target="#fig_2">2</ref> labeled "Predict @ £ ¥ " shows the expected distribution of checksums over blocks 2 cells long, given the checksum distribution over one cell given by @ £ ¤ .</p><p>So, if the non-uniformity is uniform -that is, that every cell of data is drawn from the same probability distribution, and that the sum is the sum of independent samples -then we would expect the distribution of the sums to conform closely to the dotted line in our graphs. The predicted value for @ £ ¥ is already close to uniform for all but the 20 most common values, even though @ £ ¤ is decidedly non- uniform. Corollary 3 and Theorem 4 in the appendix show that, regardless of the original distribution, the distribution should get more uniform as @ increases. However, our measurements show that the non-uniformity extends to larger chunks than single words or cells, and that the checksum of one cell is correlated with the checksums of the neighboring cells. The lines labeled @ £ ¥ , @ £ CB , etc. show the measured distribution of checksums over samples of blocks of length @ cells over real data in our file system. The data does get more uniform (seen most clearly in the CDF), but nowhere as quickly as it should if the cells were roughly independent. We believe the samples should be somewhat representative even of non-contiguous blocks. Once again, the checksum values are sorted in decreasing order of probability, to give a clearer picture of the distribution. Note that even over the larger block sizes, although the probability of a match decreases slightly, the distribution is still significantly more non-uniform than expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Filesystem-level Non-Uniformity Is Not</head><p>The Answer Given the non-uniform distribution, what, then, is the expected failure rate of the IP/TCP checksum in detecting splices for a given distribution, , of checksum values? As discussed above, it is simply the probability that the checksum over the cells missing from the first packet is   <ref type="table" target="#tab_3">4</ref> computes this probability using the measurements of the Stanford file system from Figure <ref type="figure" target="#fig_2">2</ref>. It lists the probability that the checksums of two blocks, each @ cells long, drawn from anywhere in the same filesystem, will be equal. For each block of length @ cells, the first column shows the expected probability given uniform distribution. The second column shows the probability predicted assuming each cell is drawn from the identical, non-uniform distribution. (The particular distribution is the one actually measured for single cells over the smeg:/u1 file system.) This corresponds to the predicted distribution depicted by the dotted line in Figure <ref type="figure" target="#fig_2">2</ref>. The last column lists the probability actually measured for each block size over the entire file system. We can see that even the milder non-uniformity of packet-sized chunks noticeably affects the probability of checksum failure, and that the failure probability does not tail off with larger block sizes as it should if each cell were independent.</p><p>Clearly, there is clustering and non-uniformity at a scale larger than single cells. Yet even aggregating the data over chunks of 1, 2, ... and 5 cells is not sufficient to accurately predict the actual non-uniformity and failure rate, which is still more than 10 times higher than this simple model predicts. There are two issues our initial computation ignores. First, we have measured the probability distribution over the entire file system for chunks of @ cells, but we know that distribution of data values is heavily dependent on file type (binary vs. character, executable vs. GIF, even Shakespeare vs. Joyce). Splices come from adjacent packets, which usually come from the same file. Thus real failure rates could be higher than the averaged global distribution would suggest.</p><p>For example, consider an extreme (and extremely hypothetical) case in which a file system consists of half binary and half textual data. Imagine that 90% of the cell-sized chunks of binary data had a checksum of 0x0000, and that 90% of the cell-sized chunks of textual data had a checksum of 0x1F00. Considered globally, we'd find 0x0000 45% of the time and 0x1F00 45% of the time, so ¨would be ap- proximately 32% and we'd predict about 32% of the packet splices would incorrectly pass the checksum. However, in reality, for any given file the local distribution would find the most common checksum 90% of the time, and thus the failure rate would be about 81%. Therefore, the global distribution of checksums (measured across an entire filesystem) is not sufficient to accurately predict checksum failure rate: a more localized distribution of checksums is needed.</p><p>Even this is not the whole story. If two cells have congruent checksums because the data was identical, then replacement of one cell by the other is not a checksum failure -the packet is unaltered and no corruption will occur. To accurately predict meaningful checksum failures, then, we need to subtract "both congruent and equal" cells from the probability of a match. In a system with uniformly distributed data the odds of finding two 48 byte cells with identical data is 1 in ¥ ¦ , which is so unlikely as to be utterly neglible. However, in practice it occurs far more frequently. Our actual measurements show that the most common reason for checksum congruence is identical data -identical splices occur 20 to 40 times more frequently than congruent-but-unequal splices. This is another example of non-uniform distribution of the data, but, in this case, a benign one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Localized Non-Uniformity of Data</head><p>Table <ref type="table" target="#tab_4">5</ref> shows how the probability changes when we restrict the comparisons to only look at local data. The first column (identical to the last column in Table <ref type="table" target="#tab_3">4</ref>) displays the probability of taking two blocks of data, each @ cells long, from anywhere in the entire file-system, and finding that their IP checksums were congruent to each other. The column labeled "Locally congruent" shows the same probability if we limit the search to be within 2 packet lengths (512 bytes). (In order to increase the sample size for the local comparisons, we did not restrict ourselves to contiguous blocks). The final column shows how the probability decreases when we exclude checksum matches for a pair of blocks that contained identical data, as such a substitution would not result in any data corruption. It is still significantly higher than the global rate. (Recall, that if the data were uniformly distributed then every entry in this table should be 0.001526%). If the checksum failures are purely a result of non-uniform distribution, then these sample probabilities should track the measured TCP checksum failure rates.  <ref type="table" target="#tab_5">6</ref> compares this distribution data for several file systems with the actual rate of checksum failures for comparablelength substitutions. It is important to note that the sample data only deals in full-size cells, while the measured data deals in 8 byte trailers, too. Thus the byte-length for the sample data is simply ¢¡ @ , while the byte-length for the actual data is ¢¡ @ 5 £ ¥¤ . While the exact results vary for each system, there are three things all share. First, they are all in sharp contrast to the expected rate of 0.001526%. Second, the local non-uniformity is significantly worse than the global non-uniformity, and extends over packet-size blocks. Third, the distribution samples correspond roughly to the actual failure rate. But the correspondence is only rough. A small part of this is explained by the difference in byte-length (mainly for @ £ ¤ ). Since "Actual" decreases non-linearly, we have not yet fully explained what is going on. Section 5.4 will return to this and explain the remaining discrepancy.</p><p>To convert these probabilities to a total failure rate depends on the likelihood of substitutions of each given length. The odds that a substitution of a given length occurs depends on the type of errors one expects. In our simulation, we can exactly characterize the probability of a @ -cell substitution for ¦ -cell packets. (Our typical packets of 256 bytes con- tain 7 cells). For a splice to be valid the trailer cell of the first packet must be dropped and the trailer cell of the second packet must be kept. Further, to pass the header checks, the header cell of the first packet is usually kept. Therefore, we have ¥ §¦ splices of length @ . Our simulation treats every possible substitution as equally likely. This clearly might not be true in all situations. However, the breakdown by substitution length in Table <ref type="table" target="#tab_4">5</ref> is enough to show that the failure rate will be worse than expected for all substitutions, regardless of length. The only question is exactly how bad.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Reducing Checksum Failures</head><p>In this section we look at various ways to reduce the checksum failure rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Regaining a uniform distribution: compression</head><p>We claim that the TCP checksum's failure to detect many splices is due to the non-uniform distribution of the data being summed. One obvious way to deal with non-uniform data patterns is to compress the data. As an experiment to verify that our diagnosis was correct, we compressed all the files in the file system at SICS that gave the TCP checksum the most trouble ( /opt on fafner.sics.se ) and ran our tests on the compressed files. (The compression was Lempel-Ziv, and was performed using the UNIX compress command.) The results are shown in Table <ref type="table" target="#tab_6">7</ref>. The interesting result is that the number of splices that passed the checksum is approximately 0.0021%, which is close to the expected rate on uniform data of 0.0015%. This result is a hundred-fold improvement over the .17% miss-rate before compression. So compression clearly helps. Another obvious question to ask is whether, without data compression, another checksum algorithm would perform better than TCP's. An obvious candidate checksum is Fletcher's checksum <ref type="bibr" target="#b12">[13]</ref>.¦ With our error model, where cells are dropped but no random data is inserted, we might expect the positional ¤ term to improve error detection.</p><p>As with TCP, we can compute and analyze Fletcher's checksum over individual cells rather than entire packets. Recall that the ¤ term of the Fletcher checksum is computed by multiplying each byte by its offset from the end of the packet. We can also compute a local Fletcher checksum over one cell as £ , and ¤ . To compute the contribution of an individual cell to the total Fletcher sum for the packet, we add</p><formula xml:id="formula_4">£ to £ ¢¡ ¤£ ¦¥ ¨ § and add © to ¤ ¢¡ ¤£ ¤¥ ¨ § , where © £</formula><p>Unlike <ref type="bibr" target="#b12">[13]</ref>, our Fletcher's results perform a sum-to-zero inversion on the transmitted checksum. See Sec. 6.3.</p><formula xml:id="formula_5">( ¤ £ 8</formula><p>and is the offset of the end of the cell from the end of the packet. It should be noted that since all the shifts of data are by a multiple of the cell size (48 bytes), the contribution of the ¤ term for each cell to detect motion is limited to 1 from, at most,</p><formula xml:id="formula_6">¡ ( ¡ "! ¥¡ 8</formula><p>values (85 and 16 for 1 and 2's complement, respectively). Both 85 and 16 are considerably smaller than ¡ (255 or 256, respectively). Table <ref type="table" target="#tab_8">8</ref> shows the actual results for both 1's complement (mod 255) and 2's complement (mod 256) Fletcher's checksum over several filesystems. The results of the TCP checksum on those filesystems is included for comparison.</p><p>We see that Fletcher's, in general, out-performs the TCP checksum, and in some cases comes within a factor of 2 to a 1 in ¥ ¢¡ miss rate. This performance is curious given our results so far. First, Corollary 8 in the Appendix shows that, for uniformly distributed data and replacements larger than single words, Fletcher should not be any stronger than IP/TCP. Second, two empirical measures show that both TCP and Fletcher have a similar non-uniform distribution over individual cells. When looking at plots of checksums over 48-byte cells (Figure <ref type="figure" target="#fig_4">3</ref>), the Fletcher's checksum looks to have a non-uniform curve similar to that of TCP. And when we look at the probability of the checksum that two randomly chosen cells in the file system match each other, we find a probability of 0.016% for Fletcher 255, 0.013% for Fletcher 256, and 0.011% for IP/TCP. Why then does Fletcher perform better than the TCP checksum? The most obvious effect is that the positional dependence of Fletcher's checksum effectively increases the # This includes all cells, including the short cell at the end of each packet, so the number does not match the "Measured Global" for $ &amp;% (' , given earlier. the inserted cells from the second packet are identical to the dropped cells, their s for the dropped cells is different than the s of the inserted cells, as they appear later in the splice than in the first packet. The positionality of Fletcher's checksum means that the effective size of the splice is not just the total number of cells replaced, but includes any intervening, "reshuffled" cells from the first packet which lie between the first drop and the last replacement. (Note that this result has no effect on splices that join a prefix of the first packet to a suffix of the second.)</p><p>We know that the larger the number of cells, the more uniform the distribution, and thus, the lower the failure rate. However the increased substitution size is not sufficient to explain Fletcher's improvement over IP/TCP. If this hypothesis were true, the Fletcher miss rate should correspond, at best, to the "Actual" rate for @ £ in Table <ref type="table" target="#tab_5">6</ref>. Instead, it's 10 times better. The reshuffling effect is real, but merely increasing the effective number of cells in a splice is only a small part of the story.</p><p>The real cause is more subtle. Recall that the condition for checksum failure is that the sum of the 8-bit £ s be congruent and that the sum of the</p><formula xml:id="formula_7">( ¤ £ 8</formula><p>s also be congruent. The condition on the £ 's is identical to the condition for IP checksums. Since the data cells are drawn from the same highly localized non-uniform distribution, their 8-bit £ terms have a fairly good chance of being congruent -at least 256 times more than the standard 16-bit TCP sum. But for the ¤ term, each of the terms for a nearby cell drawn from the same distribution. In effect, the contribution of each cell to the ¤ term of its packet is colored by its offset from the end of the packet (think of coloring the cells by their number). This coloring, and the non-uniformity, combine to make undetected splices less likely. It is well known (we provide a proof in Lemma 9) that the probability of drawing two identical values from a non-uniform distribution is always higher than the probability of drawing two values that differ by any fixed amount. (This is discussed further in the Appendix). Since the data is non-uniform, some terms are more likely than others. The coloring effect of the ¤ term means that the overall ¤ sums of a splice are less likely to be congruent to the original checksum than if the data was uniformly distributed.</p><p>The end result is that the standard TCP checksum fails if two observations drawn from the same distribution are equal, while Fletcher fails if two observations drawn from the same distribution differ by a particular amount (where the exact amount varies from splice to splice). Thus, non-uniformity of the data actually strengthens the ¤ field of the checksum. (This was probably not an intentional benefit planned by Fletcher.)</p><p>Ones complement Fletcher, however, has a weakness that sometimes offsets its probabilistic advantage: since bytes containing either 255 or 0 are considered identical by the checksum, certain common pathological cases cause total failure of Fletcher-255. This is discussed in more detail in Section 5.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Trailer Checksums: Making non-uniformity work for us</head><p>Fletcher-256 succeeds in detecting more splices than TCP by taking advantage of the non-uniformity of the data distributions, but it still has drawbacks. It is more expensive to compute, and the non-uniformity can only strengthen 8bits of the checksum. It turns out that we can use a similar trick to exploit non-uniformity for the standard Internet checksum, with no computational cost. Further, we can strengthen the entire 16 bit sum, giving us (for some distributions) 16 bit checksums that are even stronger than 1 in ¥ ¡ . The key observation is that with header checksums, the packet header and the packet checksum are located in the same cell of a packet. Thus, either both the header and the checksum covering it are present in a given splice, or neither are. The IP header check and syntactic TCP header checks ensure that almost all splices which are actually checksummed include the header from the first packet. The resulting splices will have the first packet's TCP header, As long as the replacement cells in the splice have the same overall checksum as the original packets, the TCP checksum will not detect the splice. Figure <ref type="figure" target="#fig_5">4</ref> shows one such splice diagrammatically. If the TCP checksum was at the end of the TCP packet, instead of in the header, the TCP checksum value would not share fate with the TCP pseudo-header which it covers. Figure <ref type="figure" target="#fig_3">5</ref> shows the same splice as Fig. <ref type="figure" target="#fig_5">4</ref>, but with the TCP checksum located in a packet trailer instead of the packet header. Here, the resulting splice has the TCP header from the first packet and the checksum from the second packet. (It also has the header from the second packet, but only half the splices will do so.)</p><p>The data cells are, as with Fletcher's sum, all drawn from the same localized non-uniform distribution and are more likely than 1 in ¥ ¡ to have congruent sums. But compare the two headers. The only field that changes between adjacent TCP packets in a given flow is the TCP sequence number. The difference between the checksums of the header cells of adjacent packets in a single flow is therefore strongly clustered around the size of the payload. In other words there are actually three different distributions of cells in a packet pair: the payload data, the first header, and the second header. If we separate the checksum value away from the header that it sums and put it in a trailer, we can ensure that there are always three different colors in any given splice -even for splices that only make colorpreserving substitutions (e.g., data cell for data cell). Again by Lemma 9, this higher degree of coloring leads to a higher probability of detecting a splice than the standard header checksum, as we show below by case analysis .</p><p>What is the probability of a trailer checksum failing? It's</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¡</head><p>Our study of trailer checksums was originally motivated by noticing that the AAL5 trailer checksums avoided this fate-sharing, and conjecturing that the predictable header differences would make TCP checksums better. It performed surprisingly well, leading us to the preceding re-analysis of the Fletcher checksum results. simply that the checksum of the cells inserted from the first packet equal the checksum of the cells dropped from the second packet. (Note that we take the second packet -the source of the trailer sum -as the original, and counting cells from the first packet as insertions,) However, the inserted cells always include a header cell. The inserted cells from the first packet thus have a sum drawn from a distribution that consists of 1 header cell and @ data cells. If the second header is dropped, then we again have @ data cells and 1 header cell. However, in half of the splices the dropped cells are all data cells, in which case their sum consists of @ ¤ data cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cells of First</head><p>The resulting probability will be lower than the probability of an exact match between two checksums drawn from the same distribution (as shown in Lemma 9). This would seem to reduce the failure probability by at most a factor of two.</p><p>In the remaining half of the splices, the second header is also dropped. Here the distribution of checksums of the header cell of the second packet does not match the distribution of the first header cell. There are two causes for this result. First, we treat the first header as a header but the second as data, which means we checksum the IP header of the second cell, but not of the first. Second, the header is mostly constant between packets except for an increase in the IP ID field and the TCP sequence number. (Note that in this scenario there is no checksum in the header: the field is left zero; though a practical trailer implementation might perhaps choose to swap the checksum value and the last two bytes of the packet.)</p><p>How much lower will the probability of failure be? We conducted an experiment to measure the effectiveness of trailer checksums. We changed the simulator to model a protocol identical to TCP, except that the TCP header checksum is left zero, and the checksum value is appended to the end of the TCP data. The results are shown in Table <ref type="table" target="#tab_9">9</ref>. The failure rate of trailer checksums were significantly better than those of TCP and Fletcher. We note that the failure rate was actually below ¥ 0 ¡ for significant fractions of some file systems. In most cases we noted a failure rate 20 to 50 times lower than for header checksums. We can further test the distribution-coloring analysis by making predictions about the standard header TCP checksum. The number of splices which do not include the header of the first packet are negligible, so there are only two cases: the first header cell followed by all-data cells, and the header from the first packet followed by a mix of data cells and the header from the second packet. In the latter case the splice has replaced a data cell with the header cell from the second packet, and thus should be much less likely to match than the first case. When we went back and examined the data, this prediction was correct. Although roughly half of the splices surviving the header check have the second header included, only 1 in ¥ ¢¡ of those passed the TCP checksum. The TCP header checksum was 100-200 times more effective against splices that contained the second header. This result both supports our explanation of the good performance of trailer TCP checksums, and further confirms the utility of our distribution-coloring analysis of checksums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Adding cell-coloring to our model</head><p>We are now ready to return to the discrepancies between our "Exclude Identical" probabilities in Table6 of Section 4.6 and the actual measured failure rate. Recall that our sample probabilities predicted total failure rates very accurately for small @ (the number of cells in a block), but by the time @ increased to 4, the model over-predicted the measured failures by a factor of 3 or 4.</p><p>The piece that was missing from our model was the cell-coloring. The sample probabilities in our model were computed using only pure data cells, and thus missed the header effect. In our actual splice simulation, some substitutions of @ cells replace a data cell with a header cell. The failure rate for the substitutions with headers should be 1 in ¥ ¡ , which is ignorable. What is the probability that a substitution of length @ replaced a data cell with a header cell? This is easy to compute. All @ cells dropped from the first packet will be data cells. There are ¨ @ 5 ¤ possible choices of @ cell insertions from the second packet (recall that we must insert the trailing cell of the second packet in the splice). Of these, only ¢¡ @ 5 ¤</p><p>do not contain the header cell of the second packet. Therefore, to predict the actual failure rate of a @ -cell substitution from our "Exclude Identical" samples, we must reduce the sample probability by a factor of £ 10 ¥¤ £ ¡ 10 ¤ which equals</p><formula xml:id="formula_8">( §¦ 5 @ 8</formula><p>. Our sample probabilities now closely match the actual measured failure probabilities, and we are reasonably confident that we have explained the behavior we have observed. Further, the improved performance due to trailer checksums in our packet-splice model seems to be real.</p><p>In the past, protocol designers have proposed trailer checksums for various engineering reasons. As far as we know, the argument about improved checksum behavior was not advanced. We conclude that protocol designers should reconsider placing checksums in packet trailers rather than headers, as has been standard practice in Internet protocols to date.</p><p>Trailer checksums suffer one apparent drawback. They may unnecessarily reject splices that are identical to an original packet. Consider the scenario where a burst of cell loss splices the front of one packet onto the tail of the following packet, as in Figure <ref type="figure" target="#fig_5">4</ref>. If the payload of the splice is identical to the payload of the original packet, then the header checksum should match (since the header of the splice is the header of the first packet), and the packet is accepted. But with trailer checksums, (as in Figure <ref type="figure" target="#fig_3">5</ref>, when the payload is identical to the first packet the checksum cannot match: it was computed with the sequence number of the second packet, not the first. So if the contents are identical the checksums will match only if the difference between the inserted and dropped cells is congruent to the difference in sequence number (the payload) between the two packets. By Lemma 9, this is very unlikely. Thus the splice will be rejected even when the contents is correct. The corresponding case (header of the second packet, payload of the first) never comes up, since our error model requires cells to remain ordered. In summary, trailer checksums have a very good chance of detecting a splice even if the resulting packet is a "good" packet.</p><p>Table <ref type="table" target="#tab_10">10</ref> demonstrates this effect on the filesystem /u1 at smeg.dsg.stanford.edu. The number of identical splices rejected by trailer checksums is larger than the number of bad splices they detect that the TCP checksum missed.</p><p>The two numbers, however, are not comparable. TCP missed checksums represent undetected data corruption. Spurious rejection by the trailer checksum represents (at worst) a possible performance penalty, it does not cause any data corruption. Comparing missed splices, the trailer checksum misses less than 3% as often as the standard sum, but at the cost of reporting checksum failure on splices that accidentally resulted in a valid packet.</p><p>However, a splice in a real network always means that at least one packet has been lost, even if the splice is identical to one of the original packets. So a TCP retransmission will be necessary regardless. Thus the incremental performance impact of triggering retransmission one packet earlier when an identical splice is discarded is not clear. These graphs were plotted as black-and-white, and thus each byte is either 0 or 255. On these data, combinatorially, 1 in 2 of all permutations are caught by header checks and 1 in 2 of the remainder include a header cell. None of the remaining 25% of all possible permutations are caught by the mod-255 fletcher. This one directory of files caused so many Fletcher mod-255 failures that on this filesystem, mod-255 Fletcher performs worse than the IP/TCP checksum.</p><p>Similarly spectacular mod-255 failures occurred in the Stanford filesystem with a file from a popular PC word processor. This file contained runs of approximately 200 allzero bytes, followed by a similar number of all-one bytes, between each section of a document.</p><p>Fletcher's mod-256 sum behaves slightly differently. It has only one zero, and is not subject to the same dramatic failure as the mod-255 sum. Pathological data patterns for mod-256 do occur, but less frequently. One case we have isolated is hex-encoded PostScript bitmaps which contain identical segments of horizontal lines (e.g. bitmaps containing solid blocks of color, or bitmaps containing parallel lines. Font definitions appear to be a particularly common case). Many common bitmaps appear to have a width, , that is a power of two. Thus, each ASCIIencoded binary line commonly consists of many "FF"s, and a small number of other two byte values (e.g. "F7") that repeat precisely ¤ apart (The extra byte is due to an ASCII newline.) Though not immediately obvious on inspection, these just happen to combine in such a way that the contribution of 48-byte cells allows splices. We observed a similar effect in BinHex-encoded Macintosh documents stored on our Unix filesystem: very similar lines of 64 bytes followed by an ASCII newline.</p><p>Though the overall rate of TCP sum failures is higher than the other sums, and appears to be noisier, we have also isolated a few pathological cases for the standard Internet checksum. One example is Unix gmon.out profiling data. These files often consist mostly of zero entries, with a scattering of a small number of nonzero entries. The non-zero values are often identical. Packetizing this data results in a very small number of checksums. A very large number of splices pass the checksum, resulting in what appears to be scrambled files. A second example is the PostScript bitmap data file mentioned above, which showed pathological behavior for the Internet checksum as well.</p><p>Our central point is that the existence of pathological patterns for a given sum is not just theoretical; these patterns occur surprisingly frequently in real filesystem data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conjectures</head><p>In the course of our research we investigated several plausible conjectures that might have explained the TCP checksum failures. We briefly describe several of these blind-alleys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The Role of Zero Data</head><p>The frequency of the zero checksum led us to study the effects of zeroed data on the checksum. It is no surprise that there are a lot of zeros in filesystem data (the UNIX filesystem has long been optimized such that completely zero blocks did not need to be saved on disk). However, knowing that arbitrarily long zero blocks do not change the IP checksum (zero is the additive identity), we wondered whether this property significantly affected the failure rate independent of the simple fact of their high frequency. In other words: Is there something special about zero? If we replaced all the zeros in the file-system with different values, would the failure rate change?</p><p>An approximate first answer is "no, zero is not special because it is the additive identity". If we add one to every word in the file system then the sum of every cell would increase by 24 (48 bytes divided by 2). Similarly, it is easy to demonstrate that the distribution of the sum of any number of cells will contain the same set of values and frequencies, although their mapping will be permuted. So the rate of checksum failure would be unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¡</head><p>It is, however, true that if any single value shows up a disproportionate amount of the time then the failure rate will increase. However, the reason that zero in particular is so common is that several totally independent formats all "happen" to choose zero as a common element. Further, it is likely that this will continue to be the case. Fortunately, although zero checksums do show up very frequently, it is often the result of cells consisting entirely of zeros. A substitution of one all-zero cell for another causes no harm. The problem, therefore, is the frequency of non-zero cells whose checksum is zero, in proximity to all-zero cells or to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Zero congruent IP/TCP header cells</head><p>The TCP checksum is computed over a pseudo-header that covers all but eight bytes from the IP header. In our original simulations, those eight bytes of IP header -including the IP checksum -were not filled in. The TCP checksum is then inverted before it is stored in the header. This causes the checksum of an error-free TCP datagram, (including the TCP header), to be zero.</p><p>A full IP header also contains an inverted ones-complement checksum, which meant that the sum of the IP header was also zero. Since all but 8 bytes from the IP header are also covered by the TCP checksum, the checksum over the entire Zero is special, as we showed in the section on pathological cases, but not because it is the additive identity and does not affect the checksum. Zero's specialness comes from the fact that it is represented by both 0x0000 and 0xFFFF. In reality, adding 1 to every word in the file system would change the distribution of checksums, and might reduce the probability of the most probable value. Cells containing 0xFFFF's would be shifted by less than 24. Whether this would increase or decrease the most probable value depends on the distribution of values in each filesystem. cell headers is not zero, but rather the checksum of the overlap: IP source and destination addresses, the length, and the TCP protocol ID.</p><p>Our earlier results ( <ref type="bibr" target="#b6">[7]</ref>) were based on simulations that left those eight bytes unfilled. Consider, however, two packets consisting of data that is all zero. This causes the header cell (when considered as data) to have a checksum of zero. The checksum will only be the sum of the header. When the checksum is inverted and stored into the header, we are left with a non-zero cell with a checksum of zero. In our earlier work, these cells were a major source of non-zero cells with a checksum of zero. What is worse, these cell show up precisely in the case when all the cells around it are zero cells (or at least zero-congruent). Thus replacement was common and a major source of splice failures. Filling in the IP header reduced the error rate by three orders of magnitude.</p><p>We had conjectured that filling in the IP header would not have much of an effect, because the length, IP addresses, and protocol type do not change between packets during the file transfer, and so the checksums of the header cell remain constant. However, even a constant, non-zero, value is sufficient to distinguish between header cells and zero filled data cells. This simulator deficiency also led us to give undue emphasis to the role of zero-congruent data (as mentioned above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Inverted Checksums</head><p>Under the TCP and IP specification, the inverse of the checksum is placed in the packet header. This implies that the checksum of a valid segment will be zero. In <ref type="bibr" target="#b6">[7]</ref> we cautioned implementors against this approach, since for mostly-zero packets the header cell, too, would be zero. This still is reasonable advice for packet formats as it reduces the frequency of zero congruent cells. However, it is not relevant to TCP and IP because of the overlap of the headers we noted above. To test this conjecture, we ran our tests with a modified version of the TCP checksum that did not invert the checksum before storing it into the packet. The results with the non-inverted checksum were almost identical to the results with an inverted checksum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Corrections to SIGCOMM 95 version</head><p>As noted in Sec. 6.2 the data in our earlier paper <ref type="bibr" target="#b6">[7]</ref> is not accurate. Completely filling in the IP header reduces the overall rate of errors by a factor of from 200 to 1000. In addition, the Fletcher checksum code was mis-implemented as a mixture of mod-255 and mod-256 arithmetic, which led to the Fletcher splice failure rate being higher than the standard TCP checksum. We retract that result; it was an artifact of the buggy Fletcher implementation. That bug was also the motivation for our current investigation of both mod-255 and mod-256 Fletcher sums. The artificially-high Fletcher failure rates also inspired the original work on trailer checksums.</p><p>The previous results also suffered from a number of other minor bugs, whose effect was insignificant compared to the two problems above. They are detailed in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Observations and Recommendations</head><p>The results of the previous sections lead to a number of interesting observations. First, a non-uniform distribution of data makes failure of the TCP checksum far more likely than one would naively expect. The undetected splice rate in our data for the 16-bit TCP checksum over real data is comparable to uniform data with a 10-bit checksum.</p><p>Second, checksum distributions on modest amounts of real data are substantially different from the distributions one would anticipate for uniformly distributed data. This skewed distribution does result in significantly higher failure rates of the TCP checksum. In particular, if a router or host has a buffering problem that causes adjacent packets to be merged, the TCP checksum might fail .1% of the time rather than the 0.0015% of the time that purely random data distribution would suggest.</p><p>While these scenarios may seem worrisome, there are three pieces of good news.</p><p>First, it is important to keep in mind that these error scenarios are all quite rare. This work was initially motivated by studying extremely uncommon AAL5 error scenariosan error model derived from ATM cell drop splicing two packets into one. In practice, such cell loss can occur due to either congestion or corruption. However, dropping ATM calls independently of each other is now known to cause goodput problems <ref type="bibr" target="#b9">[10]</ref>. ATM switch vendors are addressing this problem by dropping all subsequent cells from a packet, once a single cell is dropped. This reduces the probability that a splice will be legal since a trailer will only be delivered if all preceding cells have been delivered. The cells from the partial preceding packets will result in a detectably incorrect packet length. This means we can effectively ignore congestion as a source of valid packet splices. Cell loss due to corruption is often estimated at 1 in ¤ ¤ or less.</p><p>The ATM CRC will fail to detect a splice approximately at a rate of 1 in ¥ ¦ ©¨. Therefore, the chance of the TCP checksum being called upon to detect a splice is much less than 1 in ¤ ¤ 0 ¥ 0 ¦ ¨or less than one chance in ¤ ¤ ¢¡ . Moreover, if ATM switch vendors institute Early Packet Discard not just for congestion but for all causes of cell drop, then valid packet splices should never appear.</p><p>Second, the packet splice model is, in some sense, a worst-case error model because the substitutions tend to be similar to the data that they replace. This is possibly also true of buffer-management errors, or errors in fragment reassembly. However, in the alternative error models where data is replaced by garbage, while the non-uniformity of the data may still reduce the effectiveness of checksums, it will only reduce it to the extent that the distribution of the replacement data matches the distribution of the original data. Here, the frequency of long runs of 0's or 1's in the payload may make us slightly more vulnerable to hardware errors that produce similar runs of data. However, hardware failure that produces random bits are unlikely to produce runs of data that look a lot like English prose.</p><p>Third, and finally, remedies exist to improve the ability of checksums to work on non-uniform data.</p><p>£ Compressing data clearly improves the performance of checksums. Since compression also typically reduces file transfer times and saves disk space, there's a strong motivation for FTP archives to compress their files.</p><p>£ In the future, in the absence of compression, protocol designers should consider avoiding the practice of placing checksums in a protocol header, but instead append them as a trailer to the data being checksummed.</p><p>£ In general, the checksums are rarely placed in a situation where it is the primary method of failure detection. (We are aware of one exception to this rule. The TCP checksum is the primary method of error detection over SLIP and Compressed SLIP links. That's probably not wise).</p><p>What this work simply shows is that checksums are an even less effective error detection method than first thought, because real data often has interesting distributions, and those distributions increase the likelihood of checksum failure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Appendix</head><p>This paper contains assertions which depend upon statements that are easily proven, yet not immediately obvious. Detailed explanations in the body of the paper would detract from the main argument. For those interested in the formal justification of some of our statements, we present more detail in this appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Distributions of checksums</head><p>We use the notation Proof: For any given ¦ , the probability that the value drawn from</p><formula xml:id="formula_9">© £ ¦ is given by § ¦ £ © ¦ 5</formula><p>. Assume ¦ is the most probable element of § . Without loss of generality, assume that PMax This is unremarkable for unbounded discrete distributions. For the maximum, as the number of possible values grows, the probability of any single value must decrease. The conditions on the min require that X X V X © X , and that X § RX £ X X , so it is also unsurprising that the minimum doesn't decrease. However, for bounded distributions, e.g distributions over the integers mod `" a cb ed ! 'f hg " i p&amp; q !r 68 9 s0 tG vu xw #y $ " i &amp; %$ ¦0 <ref type="bibr" target="#b0">(1)</ref> Corollary 3 shows that each time we add another number to the sum mod ¡ and look at the probability distribution, we increase PMin    Proof: We will show that for any given £ ¥¤ times, max # would be less than 0, given our assumption that max # is always greater than ¤ §¡ £ . So, our assumption must be false. Thus, for any distribution and for any £ , there is some number 2 of additions, such that PMax ( # 8 ¤ §¡ £ , so the distribution of # tends to the uniform distribution as 2 gets larger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Distributions of some checksums over uniformly distributed data</head><p>Most existing evaluations of competing checksum algorithms have assumed that single bit errors were common. It is now frequently true that there are CRCs in the data-link layer to protect the integrity of cells on the wire, and ECC to correct memory errors while packets sit in buffers on routers. Thus, the errors that the TCP checksum must protect against are no longer single or double bit errors (which will be detected or corrected by other means), but rather substitution of longer runs of "good" data by (possibly different length) runs of "other" data. How do the IP checksum and Fletcher compare under this substitution model?</p><p>This section discusses what their expected behavior would be under substitution errors if the data were, in fact, uniformly distributed ¡ .</p><p>If we assume all packets are equally likely, then if we look at any unit smaller than the size of the substitution, we can assume that an error consists of replacements drawn uniformly from all strings. Thus, the probability that § £ ¦ for any given ¦ will be precisely ¤ ¢¡ , so the probabilities are all equal and the distribution is uniform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 6 Given uniformly distributed data and the substitution model above, the IP checksum of the modified packet is uniformly distributed over all possible values</head><p>Proof: We assume that errors are replacements drawn from the uniform distribution. Then (assuming replacements larger than a single 16 bit word) every word within the replaced chunk will be uniformly distributed mod ¡ . Therefore, by Lemma 5, the IP checksum will be uniformly distributed under the assumed substitutions, since it is the sum of uniformly distributed words. That is, the checksum will only fail to detect errors (by the replacement string contributing an identical sum to the checksum as the original string) with a probability of 1 out of ¥ ¡ 5 ¤ .</p><p>Theorem 7 Given uniformly distributed data and the substitution model above, the Fletcher checksum of the modified packet is uniformly distributed over all possible values.</p><p>Proof: The same reasoning can be applied to the Fletcher checksum over a chunk of data of size . The Fletcher checksum consists of two sums. The first is the sum, mod ¡ , of all the bytes in the chunk. The second is the sum mod ¡ of each byte weighted by its offset, , from the end of the chunk. Call these two sums, respectively, ¤ and ¥ . The contribution of this chunk (assuming it is "! from the end of #</p><p>It is worth noting that one point of the preceding paper is that data values are not distributed uniformly and are correlated with nearby values, and that, therefore, errors, under the substitution model, are also not distributed uniformly and checksums do not perform as well as expected. This work on uniformly distributed data is still interesting on three counts. First, statements in the main body of the paper depend on results presented here. Second, it provides us with a benchmark against which to measure the actual measured error rate (i.e. what is due to the substitution model and what is do to non-uniform data). Third, encryption and compression are both becoming more common and both tend to produce uniformly distributed data.</p><p>the packet) to the Fletcher checksum of the entire packet is straightforward. ¤ is added, mod ¡ , to the mod ¡ sum of the rest of the packet. ! ¤ ¥ is added, mod ¡ , to the weighted sum of the rest of the packet. If ¤ for each chunk is uniformly distributed, then so will ¤ . If each ¥ is uniformly distributed, then so will ! ( ! ¤ ¥ 8 , since by Lemma 5 we only need one uniformly distributed term (and ¥ is, although ! ¤ might not be).</p><p>That ¤ is uniformly distributed follows directly from the lemma. ¥ is only slightly more complicated. As long as the chunks are large enough so that the there is a byte ¤ with offset &amp; from the end of the chunk, such that &amp; is relatively prime to</p><formula xml:id="formula_10">¡ (i.e ¡ £¢ ¥¤ ( &amp; ! ¡ 8 £ £ ¤ 8</formula><p>, then ¤ 's contribution to ¥ is uniformly distributed among all ¡ values, and therefore ¥ itself is also uniformly distributed. Since §¦ £ ¤ is relatively prime to ¡ , as long as the chunk is at least ¥ © £¡ ¨¡ bits long, we can apply lemma 5.</p><p>We must also show that ¥ is independent of ¤ , else ¤ , ¥ will not be uniformly distributed. Suppose the last two bytes of the chunk are ¤ and ¤ &amp; . Under the assumption of uniform distribution of the data, ¤ and ¤ &amp; are both independent and uniformly distributed. ¤ &amp; does not affect ¥ since it is multiplied by 0. As we show the uniform distribution of ¥ by varying ¤ (as we did in the lemma above), for each ¤ we can choose any value for ¤ &amp; to allow ¤ to take on all values equally, without affecting ¥ . So, for each value K that ¥ might take on, ¤ is independent and uniformly distributed.</p><p>One last complication arises with the Fletcher checksum. Like IP, Fletcher defines the values inserted into the checksum field to be the negation of the checksum of the rest of the packet, so that the packet sums to 0. With Fletcher this requires the two bytes of the checksum to be the solution to a system of simultaneous equations. We must show that these two specific bytes are independent, since we can no longer magically choose offsets 0 and 1.</p><p>Assume the Fletcher checksum ¤ ! ¥ , is stored in adjacent bytes with offsets and ¨£ 5 ¤ from the end of the packet.</p><p>¤ £ ¤ ¥ ¤ mod ¡ , and , where 5 is taken ¡ 6¤ ¡ . Double both sums and rearrange terms. Since less than the Y ¨, assuming that the checksum of the header cell of packet 1 is 5 less than the checksum of the header cell of packet 2. We distinguish 5 , the difference between the header cells, since the header cells are drawn from a very different distribution than the data cells, and further, the distribution of the difference of two consecutive header cells is strongly clustered around 5 £ ¥ ¡</p><formula xml:id="formula_11">¤ £ ¥ ¤ ¥ ( 5 ¤ 8 mod ¡ . &amp; y 8 ! ¦ ©8 #" ( &amp; " B @ y 8 $ ¦ ©8 #" 0 &amp;% B #" '% 8 0 ( &amp; " 8 (% ¦ ©8 #" % B #" % 8 #" ( &amp; " 8 (% ¦ ©8 #" #" &amp; " 8 (% ¦ &amp; y 8 ! ¦ ©8 $ " B )% ¦ &amp; y B 0 ¦ A '% 8</formula><p>. Thus, we have: Theorem 10 Under our error model of splicing, a trailer checksum will always be at least as powerful as a header checksum.</p><p>Proof: For any given splice we have substituted equal. As discussed above, for trailer checksums there is a fixed 5 , usually 256 in our simulation, computable by looking at the 2 header cells. The probability that the trailer fails is the probability that two samples from # differ by 5</p><p>. Lemma 9 above shows that the former is more likely than the latter, thus header checksums are weaker than trailer checksums.</p><p>Note, that in fact, this depends only on the property that the probability of the checksums over the header cells of two adjacent packets be congruent is lower than the probability that 2 data cells from the same packet be congruent. For computing the actual probability of trailer checksum failure it is useful to be able to model 5 as a constant 256, but this is not required for the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Retractions from the SIGCOMM '95 paper</head><p>An earlier version of this paper appeared in SIGCOMM '95 <ref type="bibr" target="#b6">[7]</ref>.</p><p>The central point of that paper still holds: non-uniform distribution of data results in the IP checksum being weaker than expected. Several conjectures expressed in <ref type="bibr" target="#b6">[7]</ref> have been resolved and were addressed in the main body of this paper.</p><p>However, several minor points and computational details were not correct and we retract them.</p><p>First, we expressed surprise (as well we should have) that the Fletcher checksum performed worse than the IP checksum. Performance tuning of the Fletcher checksum code used in that paper resulted in an incorrect implementation. The Fletcher code also used a mixture of mod-256 and mod-255 arithmetic and was not computing an accurate Fletcher checksum for either mod-255 or mod-256 Fletcher.</p><p>The numbers reported for the Fletcher checksum in that paper were, therefore, not accurate. The corrected numbers reported in this version of the paper show the expected result -Fletcher's detects more splices than TCP. However, the bugs in <ref type="bibr" target="#b6">[7]</ref> and its anomalously poor results motivated us to investigate both mod-255 and mod-256 Fletcher, uncovering the pathological cases for mod-255 Fletcher reported here.</p><p>The SIGCOMM '95 paper reports numbers where the IP header fields not covered by the TCP checksum were left as zero.</p><p>Though covered in the body of this paper, it is important to emphasize it again here: filling in the header significantly reduced the number of matches for zero-congruent cells, and therefore reduced the total number of misses (by three orders of magnitude in some cases). By filling in the IP header in <ref type="bibr" target="#b6">[7]</ref> we over-stated the significance of splices including zerocongruent cells and focused too closely on misses involving zero-filled or zero-congruent cells.</p><p>Several additional, but relatively minor bugs in the simulator compromised the accuracy of the numbers of all check-sum algorithms in <ref type="bibr" target="#b6">[7]</ref> (but only to a small factor).</p><p>First, we used the AAL5 length from the second packet, rather than the apparent IP length from the first cell, for checksum computation. This miscomputed checksums by including data from the last cell beyond the end of the IP payload in the checksum.</p><p>Second, this same error arose when testing whether packets were "identical" in payload. This resulted in counting certain splices as checksum failures, when in fact they were simply identical to the original packet, or where the first packet was a prefix of the splice.</p><p>Third, we miscomputed the checksum for short packetsthat is, packets where the apparent IP header length made the entire TCP packet fit into the first cell and the AAL5 trailer in the second cell. It's well-known that a TCP packet with any user data fills at least two ATM cells. But for packets with 1 to 8 bytes of TCP payload, the entire IP/TCP datagram fits in only one cell and the second cell contains only an AAL5 trailer. Knowing that TCP data packets always take two cells, the simulation in <ref type="bibr" target="#b6">[7]</ref> erroneously added a partial checksum for the second cell.</p><p>These erroneous calculations did not change the larger picture of TCP checksum performance, but did require us to recompute all data for this version of the paper.</p><p>Finally, our code and raw data are available from the URL http://www.dsg.stanford.edu/ ....</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example AAL5 Splice</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of TCP checksum over blocks of @ cells in smeg.dsg.stanford.edu:/u1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>5 B</head><label>5</label><figDesc>cells to choose from, with the leading and trailing cells already specified. So there are ¨¥ total splices (462 for 7 cell packets) that might pass the header checks. There are ¨¦ 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: PDF of TCP checksum, F255, and F256 over 48 byte cells in smeg.dsg.stanford.edu:/u1. Most common 256 values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Header checksum fate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2 Figure 5 :</head><label>25</label><figDesc>Figure 5: Trailer checksum fate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>© 8 the</head><label>8</label><figDesc>to denote the distribution which arises by applying any commutative, total function with a unique inverse on a pair of values drawn from distributions and © respectively. (In all of our cases we are interested in the usual arithmetic addition operator). Call PMax ( probability of the most likely value in the discrete distribution,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 3 ,</head><label>23</label><figDesc>If ! #" %$ '&amp; )( 10 32 4 !5 6" 7 #8 9 !$ '&amp; @( A0 , then PMin ! CB 5 D0 FE CG H PI Q PMin ! R0 S PMin !5 T0 U0 Proof: Consider the previous proof. Given the non-zero condition on © 2 we are guaranteed that every value in © appears, and so # © 2 3 £ ¤ , thus §</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>the sense that the minimum probability of any number gets larger and the max probability gets smaller.Computation: If we have a random variable which can take on ¡ values, with a known distribution of values, then the probability ( this distribution is equal to @ , is:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>.</head><label></label><figDesc>probability values, then some values in the sum of might also have zero probability, unless the gcd of ¡ and the entries occurring with non-zero probability is 1. The following theorem applies even if a sum of a distribution only has ¡ ¡ values with non-zero probability in the following sense: all non-zero values will tend to be equal to ¤ ¢¡ ¢ Theorem 4 (a Central Limit Theorem) The sum, mod ¡ , of a large number of independent observations from any distribution tends to have a uniform distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Lemma 5</head><label>5</label><figDesc>The sum § mod ¡ of numbers, will be uniformly distributed among all ¡ values assuming there is at least one term, , in the sum which takes on values uniformly distributed mod ¡ Proof: Assume § 5 mod ¡</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>sum is greater than the latter sum.Consider our error model: we substitute 2 cells from the first packet with 2 other cells from the second packet. We keep the header cell of the first packet and we keep the trailer cell of the second packet. For a header checksum to fail, the sum Y and Y ¨of each collection of 2 cell partial checksums must be equal. For a trailer checksum to fail, the sum Y of the 2 cells missing from the first packet must be 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Page 15 gives us the probability distribution of the sum of 2 cells. The probability that the header checksum fails is the probability that two samples drawn from # are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : CRC and TCP Checksum Results (256 Byte packets on systems at NSC)</head><label>1</label><figDesc></figDesc><table><row><cell>system</cell><cell>code</cell><cell>% remaining</cell><cell>splices</cell></row><row><cell>nsc05</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>46411 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">4856193 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000000</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0459554853</cell><cell></cell></row><row><cell>nsc11</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>45627 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">6896637 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000319</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0610412816</cell><cell></cell></row><row><cell>nsc23</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>29444 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">4372688 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000830</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0568444518</cell><cell></cell></row><row><cell>nsc25</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>38187 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">9531889 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000464</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.1103037608</cell><cell></cell></row><row><cell>nsc27</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>22319 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">5461908 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000402</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0439271199</cell><cell></cell></row><row><cell>nsc29</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>57299 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">6314509 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000350</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0552609704</cell><cell></cell></row><row><cell>nsc49</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>17663 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">6196298 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000000</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0766246826</cell><cell></cell></row><row><cell>nsc51</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>16864 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">4990431 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000000</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.0693654262</cell><cell></cell></row><row><cell>nsc52</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>58132 files</cell><cell>Caught by Header</cell><cell></cell><cell></cell></row><row><cell cols="2">9082777 pkts Identical data</cell><cell></cell><cell></cell></row><row><cell>(98-05-04)</cell><cell>Remaining splices</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by CRC 0.0000000000</cell><cell></cell></row><row><cell></cell><cell cols="2">Missed by TCP 0.1726656418</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 : CRC and TCP Checksum Results (256 Byte packets on systems at SICS)</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 : CRC and TCP Checksum Results (256 Byte packets on systems at Stanford)</head><label>3</label><figDesc></figDesc><table><row><cell>system</cell><cell>code % remaining</cell><cell>splices</cell></row><row><cell>smeg.stanford.edu</cell><cell>Total</cell><cell>8863295657</cell></row><row><cell>/u1</cell><cell>Caught by Header</cell><cell>4442709123</cell></row><row><cell>198,352 files</cell><cell>Identical data</cell><cell>25715994</cell></row><row><cell>9,901,213 pkts</cell><cell>Remaining splices</cell><cell>4394870540</cell></row><row><cell>(8-20-97)</cell><cell>CRC 0.0000000228</cell><cell>1</cell></row><row><cell></cell><cell>TCP 0.0707199443</cell><cell>3108050</cell></row><row><cell cols="2">pompano.stanford.edu Total</cell><cell>1197495954</cell></row><row><cell>/usr/local</cell><cell>Caught by Header</cell><cell>599005787</cell></row><row><cell>11,468 files</cell><cell>Identical data</cell><cell>6024593</cell></row><row><cell>1,314,390 pkts</cell><cell>Remaining splices</cell><cell>592465574</cell></row><row><cell>(11-26-97)</cell><cell>CRC 0.0000000000</cell><cell>0</cell></row><row><cell></cell><cell>TCP 0.0269563342</cell><cell>159707</cell></row><row><cell>rate of 1 in ¥ ¢¡</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Probability (as %) of checksum match for substitutions of length @ cells.</figDesc><table><row><cell cols="2">Length Uniform</cell><cell>Predicted</cell><cell>Measured</cell></row><row><cell>1</cell><cell cols="3">0.001526 0.02126770 0.02126770</cell></row><row><cell>2</cell><cell cols="3">0.001526 0.00153019 0.01494399</cell></row><row><cell>3</cell><cell cols="3">0.001526 0.00152590 0.01348366</cell></row><row><cell>4</cell><cell cols="3">0.001526 0.00152590 0.01416288</cell></row><row><cell>5</cell><cell cols="3">0.001526 0.00152590 0.01108446</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Probability (as %) of checksum match for substitutions of length @ cells based on local data.</figDesc><table><row><cell>Length</cell><cell>Globally</cell><cell>Locally</cell><cell>Excluding</cell></row><row><cell>(@ )</cell><cell>Congruent</cell><cell>Congruent</cell><cell>Identical</cell></row><row><cell>1</cell><cell cols="3">0.02126770 1.58305972 0.20704272</cell></row><row><cell>2</cell><cell cols="3">0.01494399 1.30267681 0.17226800</cell></row><row><cell>3</cell><cell cols="3">0.01348366 1.21236431 0.16614066</cell></row><row><cell>4</cell><cell cols="3">0.01416288 1.15970577 0.16316988</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 : Checksum failures on real data Probability (as %) of checksum congruence for blocks of length @ cells</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell>smeg.dsg.stanford.edu:/u1</cell></row><row><cell>Predicted</cell><cell>0.0212677 0.0015302 0.0015259 0.0015259</cell></row><row><cell>Measured Global</cell><cell>0.0212677 0.0149440 0.0134837 0.0141629</cell></row><row><cell cols="2">Local Congruence 1.5830597 1.3026768 1.2123643 1.1597058</cell></row><row><cell>Exclude Identical</cell><cell>0.2070427 0.1722680 0.1661407 0.1631699</cell></row><row><cell>Actual</cell><cell>0.1026797 0.1581733 0.0907984 0.0568881</cell></row><row><cell></cell><cell>sics.se:/opt</cell></row><row><cell>Predicted</cell><cell>1.1422436 0.0150023 0.0016907 0.0015280</cell></row><row><cell>Measured Global</cell><cell>1.1422436 0.9493377 0.8852883 0.8291802</cell></row><row><cell cols="2">Local Congruence 10.7766645 9.6723695 9.3490614 9.0170788</cell></row><row><cell>Exclude Identical</cell><cell>0.3872216 0.4732675 0.6897936 0.6086173</cell></row><row><cell>Actual</cell><cell>0.1085216 0.5551069 0.2130342 0.1183174</cell></row><row><cell></cell><cell>sics.se:/src1</cell></row><row><cell>Predicted</cell><cell>0.0320218 0.0015407 0.0015259 0.0015259</cell></row><row><cell>Measured Global</cell><cell>0.0320218 0.0182235 0.0163506 0.0169735</cell></row><row><cell cols="2">Local Congruence 1.7774385 1.5562402 1.4326226 1.4595770</cell></row><row><cell>Exclude Identical</cell><cell>0.2537653 0.1938629 0.1418823 0.2196530</cell></row><row><cell>Actual</cell><cell>0.1037989 0.1143002 0.0499086 0.0283392</cell></row><row><cell></cell><cell>sics.se:/src2</cell></row><row><cell>Predicted</cell><cell>0.0204720 0.0015312 0.0015259 0.0015259</cell></row><row><cell>Measured Global</cell><cell>0.0204720 0.0154869 0.0146764 0.0140808</cell></row><row><cell cols="2">Local Congruence 2.1467761 1.9016190 1.8495718 1.7812772</cell></row><row><cell>Exclude Identical</cell><cell>0.1094778 0.0995097 0.1345251 0.1108649</cell></row><row><cell>Actual</cell><cell>0.1747045 0.1339748 0.0429196 0.0210642</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 : CRC and TCP Checksum Results, Compressed Data (256 Byte packets on systems at SICS</head><label>7</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>)</cell></row><row><cell>system</cell><cell>code % remaining</cell><cell>splices</cell></row><row><cell>fafner.sics.se</cell><cell>Total</cell><cell>1549869756</cell></row><row><cell>compressed</cell><cell>Header</cell><cell>773945117</cell></row><row><cell>/opt</cell><cell>Identical</cell><cell>51902</cell></row><row><cell cols="2">1,679,166 pkts Remaining</cell><cell>775872737</cell></row><row><cell>(5-9-95)</cell><cell>CRC 0.0000000000</cell><cell>0</cell></row><row><cell></cell><cell>TCP 0.0021002156</cell><cell>16295</cell></row><row><cell>5</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>.2 Alternative checksums: Fletcher It</head><label></label><figDesc></figDesc><table /><note><p>is not always possible or desirable to compress the data.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 : Fletcher's Checksum Results (256 Byte packets on systems)</head><label>8</label><figDesc></figDesc><table><row><cell></cell><cell>Missed</cell><cell></cell><cell></cell></row><row><cell>System</cell><cell>by</cell><cell>%</cell><cell>splices</cell></row><row><cell>sics.se</cell><cell cols="3">TCP 0.1703438788 5316323</cell></row><row><cell>/opt</cell><cell cols="2">F255 0.0044358811</cell><cell>138441</cell></row><row><cell></cell><cell cols="2">F256 0.0091286724</cell><cell>284900</cell></row><row><cell>smeg.stanford.edu</cell><cell cols="3">TCP 0.0707199443 3108050</cell></row><row><cell>/u1</cell><cell cols="3">F255 0.0862324604 3789805</cell></row><row><cell></cell><cell cols="2">F256 0.0046759739</cell><cell>205503</cell></row><row><cell>pompano.stanford.edu</cell><cell cols="2">TCP 0.0269563342</cell><cell>159707</cell></row><row><cell>/usr/local</cell><cell cols="2">F255 0.0022121117</cell><cell>13106</cell></row><row><cell></cell><cell cols="2">F256 0.0029058228</cell><cell>17216</cell></row><row><cell>sics.se</cell><cell cols="2">TCP 0.0411719151</cell><cell>649734</cell></row><row><cell>/src1</cell><cell cols="2">F255 0.0067998225</cell><cell>107308</cell></row><row><cell></cell><cell cols="2">F256 0.0054134085</cell><cell>85429</cell></row><row><cell>sics.se</cell><cell cols="2">TCP 0.0344980161</cell><cell>496823</cell></row><row><cell>/src2</cell><cell cols="2">F255 0.0023053857</cell><cell>33201</cell></row><row><cell></cell><cell cols="2">F256 0.0039193848</cell><cell>56445</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 : Trailer Checksum Results (256 Byte packets on systems)</head><label>9</label><figDesc></figDesc><table><row><cell>Filesystem</cell><cell cols="2">TCP Misses Trailer Misses</cell></row><row><cell>Uniform</cell><cell>0.001526</cell><cell>0.001526</cell></row><row><cell>sics.se:/opt</cell><cell>0.170344</cell><cell>0.004105</cell></row><row><cell>smeg.stanford.edu:/u1</cell><cell>0.070720</cell><cell>0.001735</cell></row><row><cell>pompano.stanford:/usr/local</cell><cell>0.026956</cell><cell>0.001604</cell></row><row><cell>sics.se:/src1</cell><cell>0.041172</cell><cell>0.002351</cell></row><row><cell>sics.se:/src2</cell><cell>0.034498</cell><cell>0.002100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 : Header vs. Trailer Checksum Failure Rates</head><label>10</label><figDesc></figDesc><table><row><cell>False Positive/Negative</cell><cell>header</cell><cell>trailer</cell></row><row><cell>Fails checksum, data identical</cell><cell cols="2">0 25,348,910</cell></row><row><cell cols="2">Passes checksum, data changed 3,108,050</cell><cell>76,270</cell></row><row><cell>Fails checksum, data identical</cell><cell>0.0%</cell><cell>0.57%</cell></row><row><cell cols="2">Passes checksum, data changed 0.07%</cell><cell>0.002%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>¤ ¨ § based on max # . The largest possible value of max # ¨ § will arise when the most probable terms from ¨© max d maxf B ©8 max d 8 min d 0 maxf B</figDesc><table><row><cell cols="2">, there is £ . Since PMax ( # 8 grows, we know this also holds for all such that PMax 2 ( # 8 ¤  §¡ is non-increasing as some 2 @ ¦¤ 2 . Use the notation max # to mean PMax ( # 8 , and min # to mean PMin ( # 8 , when the meaning is clear. Assume there is a distribution, , where max # ¤ ¤  §¡ £ for all values of 2 . We can compute a strict upper bound</cell></row><row><cell>for max &amp; match the most probable terms from</cell><cell># (c.f. exercise</cell></row><row><cell cols="2">in Concrete Mathematics [3], at the bottom of page 38). Assume the probability for the ¡ 5 ¤ most common values in # are all max # , and there is 1 value whose probability is ¤ ¢¡ . For there is at least one value with probability max &amp; , one with probability min &amp; , and ¡ 5 ¥ values whose probability sums to ¤ 5 max &amp; 5 min &amp; .</cell></row><row><cell cols="2">min d y maxf ¨© maxf 8 min d maxf 8 y 0 maxf ¨© maxf 8 min d But after adding 2 £ max &amp; ( min &amp; £ 8</cell></row></table><note><p># maxf</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to acknowledge the help of Chuck Kalmanek and Bill Marshall of Bell Labs, who discussed issues of study design. We also gratefully acknowledge the help of David Feldmeier of Bellcore and Lansing Sloan of Lawrence Livermore, who helped us with substantially faster CRC computation algorithms, and the Swedish Institute of Computer Science, which allowed us to use its filesystems and one of its fast multiprocessors for some of the test runs.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Computing the Internet Checksum</title>
		<author>
			<persName><forename type="first">R</forename><surname>Braden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Partridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intenet Request For Comments RFC 1071, ISI</title>
		<imprint>
			<date type="published" when="1988-09">September 1988</date>
		</imprint>
	</monogr>
	<note>Updated by RFCs 1141 and 1624</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An Arithmetic Checksum for Serial Transmissions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Communcation</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1983-01">January 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Concrete Mathematics: A Foundation for Computer Science</title>
		<author>
			<persName><forename type="first">R</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Knuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Patashnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reliability of Adaptation Layers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lyles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Protocols for High-Speed Networks III</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Pehrson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Gunningberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Pink</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Proc. IFIP 6</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Development of a Transmission Error Model and an Error Control Model</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1975-05">May 1975</date>
		</imprint>
		<respStmt>
			<orgName>Georgia Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fletcher&apos;s Error Detection Algorithm: How to implement it efficiently and how to avoid the most common pitfalls</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nakassis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communication Review</title>
		<imprint>
			<biblScope unit="page" from="63" to="88" />
			<date type="published" when="1988-10">October 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Performance of Checksums and CRCs Over Real Data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Partridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM 1995</title>
		<meeting>SIGCOMM 1995<address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Computer Communications Review</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="68" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Plummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TCP Checksum Function Design. Internet Engineering Note</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
	<note>BBN. Reprinted in [1</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Transmission Control Protocol. Internet request for comments, ISI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Postel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981-09">September 1981. 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamics of TCP traffic over ATM networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Romanow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE JSAC</title>
		<imprint>
			<biblScope unit="page" from="79" to="88" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
	<note>An earlier version of this paper appeared in SIGCOMM &apos;94</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving the Efficiency of the OSI Checksum Calculation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sklower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communication Review</title>
		<imprint>
			<biblScope unit="page" from="44" to="55" />
			<date type="published" when="1989-10">October 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SEAL Detects Cell Misordering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crowcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network Magazine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="8" to="19" />
			<date type="published" when="1992-07">July 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">AND PARTRIDGE, C. TCP Alternate Checksum Options. Internet RFC RFC 1143</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zweig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990-02">February 1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
