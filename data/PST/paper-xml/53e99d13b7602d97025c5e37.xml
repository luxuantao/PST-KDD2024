<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-Quality Point-Based Rendering on Modern GPUs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mario</forename><surname>Botsch</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Graphics Group RWTH</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leif</forename><surname>Kobbelt</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Graphics Group RWTH</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">High-Quality Point-Based Rendering on Modern GPUs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1A7D768B550CC84A8D110F6356C7C43D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the last years point-based rendering has been shown to offer the potential to outperform traditional triangle based rendering both in speed and visual quality when it comes to processing highly complex models. Existing surface splatting techniques achieve superior visual quality by proper filtering but they are still limited in rendering speed. On the other hand the increasing availability and programmability of graphics hardware lead to the developement of very efficient hardware-accelerated rendering methods. However, since no filtered splats are used, these approaches trade visual quality for rendering speed.</p><p>In this paper we propose a rendering framework for point-based geometry providing high visual quality as well as efficient rendering. Our approach is based on a twopass splatting technique with Gaussian filtering, resulting in a visual quality comparable to existing software rendering systems. Using programmable graphics hardware we delegate all expensive rendering tasks to the GPU, thereby minimizing data transfer and saving CPU resources. The proposed system renders up to 28M mid-quality or up to 10M high-quality surface splats per second on the latest graphics hardware.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Due to their simplicity and efficiency triangles meshes are the de facto standard geometry representation in computer graphics. As the hardware components for the complete mesh processing pipeline, i.e. mesh generation (3D scanners), mesh processing (CPU) and finally mesh rendering (graphics hardware), gets more and more powerful, the typical surface or scene complexity is steadily increasing. Meshes containing several millions of triangles are nowadays commonly used.</p><p>In contrast the resolution of displays is not increasing at the same speed. Therefore rendering highly complex models results in triangles whose projected area is less than a few pixels. Using standard scanline-conversion methods for the rendering of these tiny triangles becomes inefficient because of the necessary overhead for the triangle setup.</p><p>Hence, above a certain complexity, points are the conceptually more efficient rendering primitive. Holes in the rendered image (e.g. when zooming in) can be avoided by image-based filters, by adjusting the sampling density, or by so-called surface splatting. In the latter case each point is associated with a radius and a normal vector and therefore represents a small disc in 3-space, that is projected onto the image plane.</p><p>Another advantage of point-based rendering (PBR) besides the higher efficiency is that it can also provide superior rendering quality compared to standard polygon-based rendering. For PBR the lighting computations are performed on a per point basis, corresponding to high quality Phong shading in the surface case. For anti-aliased rendering sophisticated splatting techniques assign a Gaussian filter kernel to the splats, resulting in an elliptically weighted average (EWA) filtering of the image -similar to anisotropic texture filtering <ref type="bibr" target="#b10">[11]</ref>.</p><p>An additional benefit of point-based geometry representations is their conceptual simplicity. Since no connectivity information exists only a set of points has to be stored and processed. Hierarchical encoding schemes for point-based geometry provide compact storage and efficient progressive transmission of these datasets. Recently, several mesh processing algorithms have been reformulated for point-based surface representations, like e.g. spectral processing <ref type="bibr" target="#b16">[17]</ref>, geometry simplification <ref type="bibr" target="#b17">[18]</ref>, surface editing <ref type="bibr" target="#b24">[25]</ref> and multiresolution shape modeling <ref type="bibr" target="#b18">[19]</ref>.</p><p>The focus in this paper is on the final stage of the pointbased geometry processing pipeline, i.e. the rendering of point-sampled geometry. In this topic, existing approaches offer only a trade-off between rendering speed and visual quality. On this scale one extreme are the sophisticated purely software-based implementations of filtered splatting that provide the highest rendering quality. The major drawback of these approaches is that they put high load on the main CPU, but still do not achieve higher rates than 4M splats per second on current hardware <ref type="bibr" target="#b1">[2]</ref>.</p><p>On the other extreme people are trying to free the CPU for other tasks by making use of graphics hardware for point-based rendering, motivated by the steadily increasing performance and programmability of modern graphic processing units (GPUs). But since hardware-acceleration is mainly targetting polygon-based rendering there is no obvious way how to (mis-)use graphics hardware for highquality filtered surface splatting. Hence, rendering quality had to be sacrificed for rendering speed, leading to a rendering performance of above 50M points per second -if the points are rendered as small unfiltered squares <ref type="bibr" target="#b6">[7]</ref>.</p><p>In this paper we propose a rendering framework for point-based geometry providing high visual quality as well as efficient rendering. Our approach is based on a two-pass filtered splatting technique, resulting in the a visual quality comparable to existing software rendering systems. Using programmable graphics hardware we delegate all expensive rendering tasks to the GPU, thereby minimizing data transfer and saving CPU resources. The proposed system renders up to 28M mid-quality or up to 10M high-quality filtered surface splats per second on the latest graphics hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Using points as rendering primitives was first proposed in the pioneering work of Levoy and Whitted <ref type="bibr" target="#b13">[14]</ref>, followed by Grossman and Dally <ref type="bibr" target="#b9">[10]</ref>, presenting algorithms for the generation as well as and for the rendering of point sets. This work has been improved in the Surfels paper by Pfister et al. <ref type="bibr" target="#b19">[20]</ref>. They sample objects using 3 orthogonal LDIs and use image-space filters to achieve a hole-free rendering.</p><p>Alexa et al. <ref type="bibr" target="#b0">[1]</ref> use local Least Squares approximations to adjust the point sampling for displaying. Their point set surfaces have been extended to a progressive representation in <ref type="bibr" target="#b8">[9]</ref>.</p><p>Zwicker et al. <ref type="bibr" target="#b25">[26]</ref> introduce surface splatting by imagebased EWA filtering, resulting in high quality anti-aliased rendering, comparable to anisotropic texture filtering <ref type="bibr" target="#b10">[11]</ref>. Similar to the footprints of Westover <ref type="bibr" target="#b23">[24]</ref> disc-shaped splats in object-space project to elliptical splats with Gaussian intensity distribution in image-space. While this softwarebased approach is only able to process 250k splats per second it provides the highest visual quality. Botsch et al. <ref type="bibr" target="#b1">[2]</ref> present an adaptive octree encoding scheme for point-based geometry that provides very compact storage and a hierarchical rendering algorithm. Their method is able to process up to 14M points or 4M high quality filtered splats per second by using a quantization of splat shapes.</p><p>All the above software-based rendering methods have proven that point-based rendering can be superior to polygon-based rendering for highly complex scenes. While they can provide very high visual quality, their rendering speed is limited to about 4M splats per second on current hardware. Even if this point rate may be sufficient for today's models these software implementations completely block the CPU from other tasks besides rendering.</p><p>Therefore several authors propose to use graphics hardware for point-based rendering. Sophisticated rendering techniques used in software implementations, like e.g. Abuffers <ref type="bibr" target="#b2">[3]</ref>, are not available on today's graphics hardware. Hence, the proposed approaches either lose some visual quality or try to compensate for the missing functionality by multiple rendering passes.</p><p>The first to use hardware acceleration for PBR were Rusikiewicz and Levoy <ref type="bibr" target="#b21">[22]</ref>. In order to be able to render the large datasets of the Digital Michelangelo project <ref type="bibr" target="#b12">[13]</ref> they combine a hierarchy of bounding spheres with a splatting technique. In order to blend overlapping fuzzy splats in some -depth-slap they propose a two-pass rendering approach.</p><p>Stamminger and Drettakis <ref type="bibr" target="#b22">[23]</ref> dynamically adjust the point samping rate for rendering of complex procedural geometry. This approach is extended to a mixed point and polygon rendering approach for complex plant ecosystems in Deussen et al. <ref type="bibr" target="#b7">[8]</ref>. Further approaches mixing the rendering of points and polygons have been proposed by Chen et al. <ref type="bibr" target="#b3">[4]</ref> and Cohen et al. <ref type="bibr" target="#b5">[6]</ref>. Although we are targetting pure point-based rendering, our methods could be integrated into their algorithms since we are using standard OpenGL rendering only.</p><p>Ren et al. <ref type="bibr" target="#b20">[21]</ref> reformulate the image based EWA filtering of <ref type="bibr" target="#b25">[26]</ref> to object-space filtering in order to map the surface splatting approach to graphics hardware, also using a two-pass rendering method. They render each splat as a textured rectangle in object-space. This concept causes the number of processed points to be multiplied by four, slowing down the rendering to about 2M-3M splats per second.</p><p>Coconu and Hege <ref type="bibr" target="#b4">[5]</ref> propose to use an octree-based spatial data structure containing points and triangles to do the visibility calculations. By sorting and rendering the octree cells from back to front in each frame they avoid using the z-buffer at all. Although this avoids an expensive second rendering pass, it leads to the problem that front and back sides of objects are blended without depth control.</p><p>In a very recent paper Dachsbacher et al. <ref type="bibr" target="#b6">[7]</ref> present a hierarchical LOD structure for points that is adaptively rendered by sequentially processing it by the GPU. They report impressive point rates above 50M points per second, but the points are rendered as unfiltered view-plane aligned small squares. wise constant but a piecewise linear geometry representation, they exhibit the same quadratic approximation order as triangle meshes. Therefore a decent approximation can be achieved with a relatively low number of splats, offering a good compromise between polygonal meshes on the one hand and one-pixel points on the other hand.</p><p>The concept of splat filtering by blending overlapping splats also provides a much higher rendering quality compared to unfiltered point rendering that often leads to highfrequency noise in the image, especially in the case of textured models.</p><p>Since for splats the point sampling rate does not have to be adjusted each frame the static geometry data can be stored in the video or AGP memory where it can be directly accessed in DMA mode, thereby minimizing data transfer costs during rendering.</p><p>The rendering of point splats involves several sub-tasks: first the size and shape of the splats have to be determined from the current viewing parameters so that we get a holefree image (Sec. 3.1 and 3.2). Using these techniques alone already results in mid-quality elliptical but still unfiltered surface splats. Nevertheless it provides a much better representation of the geometry than fixed splat shapes, especially noticable near contours (cf. Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>Further improvement in visual quality can be achieved by blending overlapping splats using splat filtering (Sec. 3.3), resulting in high quality anti-aliased rendering. During rendering, splat contributions are accumulated by additive blending, so that each pixels contains a weighted sum of color values i w i (rgb) i . Therefore a final normalization step dividing each pixel's RGB color by the corresponding sum of weights is required to get the correct filtering ( i w i (rgb) i ) / ( i w i ). This final normalization step will be described in Sec. 3.4.</p><p>For all these rendering tasks our goal is the consequent delegation to the GPU. Therefore the algorithms have to be formulated in a way they can directly be mapped to the programmable vertex and fragment shaders of the latest graphics hardware. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Splat Size</head><p>In order to obtain a watertight rendering, the projected size of a splat has to be determined from the viewing parameters and the splat's position and radius.</p><p>The OpenGL projection pipeline from eye/camera coordinates to the final 2D image is depicted in Fig. <ref type="figure" target="#fig_1">2</ref>: The viewing volume is given by the distances to the near (n) and far (f ) clipping planes and the parameters top (t) and bottom (b) controlling the opening angle. After this frustum has been projectively warped to the unit cube [-1, 1] 3 , a simple parallel projection is done by omitting the z coordinate, resulting in 2D coordinates in [-1, 1] 2 . Finally these 2D coordinates are scaled up by the viewport mapping to match the (integer) window coordintes {0, . . . , w} × {0, . . . , h}. This can also be considered as projecting the viewing volume onto the near plane z = -n and scaling the resulting coordinates by h t-b . The image-space size of a splat is the size of its projection onto the image plane. The exact result is quite expensive to compute, since it depends on the splat position as well as on the splat normal. Instead we approximate the size by projecting the bounding sphere of the splat and neglecting its x and y offsets from the optical axis, as also proposed in <ref type="bibr" target="#b3">[4]</ref>.</p><p>The image-space splat size size win can then be computed by a projection onto the near plane and a scaling to transform from near-plane coordinates to image-plane coordinates:</p><formula xml:id="formula_0">size win = r • n z eye • h t -b ,<label>(1)</label></formula><p>where z eye is the splat's distance from the camera, r is its radius, and n, t, b, h are the respective projection parameters depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. Adjusting the image-space size causes a size win × size win image-space square to be rendered centered at the splat center's projected position (cf. Fig. <ref type="figure" target="#fig_2">3</ref>, top right).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Splat Shape</head><p>Since a splat represents a small disc in object-space, its projection onto the image plane is an ellipse. The radii and orientation of this ellipse depend on the splat's normal vector transformed to eye-coordinates. Adjusting the splat's shape based on its eye-space normal vector results in the desired behaviour (cf. Fig. <ref type="figure" target="#fig_2">3</ref>).</p><p>Initially the adjustment of splat size causes small imageplane aligned squares to be rendered. For each of its pixels we have to determine whether it is the projection of a point inside or outside the splat, i.e. whether the point corresponding to the pixel has a distance to the 3D splat center that is less than the splat radius or not.</p><p>Similar to <ref type="bibr" target="#b4">[5]</ref> we use the NV point sprite extension to get a parameterization of the image-space square over [-1, 1] 2 . For a pixel having coordinates (x, y) ∈ [-1, 1] 2 we compute its depth offset δz from the splat center as a linear function determined by the eye-space normal vector (n x , n y , n z ) T , cf. Fig. <ref type="figure" target="#fig_3">4</ref>:</p><formula xml:id="formula_1">δz = - n x n z x - n y n z y<label>(2)</label></formula><p>The depth offset δz can then be used to compute the 3Ddistance from the splat center: the pixel corresponds to a point inside the splat iff the length (x, y, δz) T  2 is less than one. Note that the depth offset δz is just an approximation, since we assume a parallel projection in Eq. 2, neglecting the angle between the viewing ray and the splat's normal. Since this may cause ellipses to become too flat (resulting in holes), we bound the maximum foreshortening of the ellipses, as also proposed in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>Using the correct splat size and splat shape results in a hole-free rendering with a much better visual quality of contours, since the typical thickening effect of square splats is effectively avoided by elliptical splats (cf. Fig. <ref type="figure" target="#fig_0">1</ref> and Fig. <ref type="figure" target="#fig_2">3</ref>). Nevertheless for high quality anti-aliasing we should use the splat filtering described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Splat Filtering</head><p>For splat filtering each splat in object-space is associated a radially decreasing Gaussian weight function. The projection of this Gaussian results in an image-space elliptical Gaussian, whose values are used to blend the respective pixels. Therefore the image-space weight of a pixel is a function of the 3D distance of its corresponding object-space point to the splat's center, i.e. the norm (x, y, δz) T 2 that has already been computed to determine the splat shape. Hence, the final weight can be looked up in a 1D Gaussian texture:</p><formula xml:id="formula_2">α(x, y) = GaussTexture1D (x, y, δz) T<label>(3)</label></formula><p>For the concept of splat filtering overlapping splats should be blended if and only if their z-distance is sufficiently small, otherwise the splat in front should overwrite the splat behind. While software-based algorithms can easily implement this behaviour using, e.g., modified A-buffers <ref type="bibr" target="#b2">[3]</ref>, there is no way to map this -depth-test to current graphics hardware. Although some splats can be culled based on their backfacing orientation, this is not sufficient in the general case. Therefore we use a two-pass rendering approach, like proposed in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b20">21]</ref>: In a first pass the scene is rendered just to the z-buffer, with all z-values having an -offset added to them. If for the second pass the z-buffer update is turned off, i.e. the z-values from the first pass are used read-only, this results in the desired blending of splats whose depth distance is less than .</p><p>For this -depth test to work reliably we have to make sure that each pixel's depth value is correct. Since the splats we render are up to now just image-plane aligned elliptically trimmed rectangles, all of their pixels' depth values equal the depth value of the splat's center vertex (cf. Fig. <ref type="figure" target="#fig_5">6</ref>). Especially when viewing a splat from a flat angle this will lead to large errors in the depth component, resulting in blending artifacts near contours.</p><p>To address this issue we use a per-pixel depth correction, i.e. for each pixel we compute its correct depth value in window coordinates based on the splat's eye-space normal vector. The corresponding object-space depth offset δz w.r.t. to the splat center has already been computed to determine the splat shape, see Eq. 2.</p><p>The required window z-coordinate z win has to be computed from the adjusted eye-space z-coordinate z eye +δz by applying the frustum and viewport mapping to it (cf. Fig. <ref type="figure" target="#fig_1">2</ref>). This transformation can be written as</p><formula xml:id="formula_3">z win = a z eye + δz + b z eye + δz , (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where a = f /(f -n) and b = -2f n/(f -n) are derived from the composition of projection and viewport mapping. The frustum parameters f and n are again the distances to the near and far plane, respectively.</p><p>In the second rendering pass we accumulate all splats passing the -depth test by weighted additive blending, such that each pixel stores ( i α i (rgb) i , i α i ). Hence, in a final normalization step the RGB part each pixel has to be divided by its α component. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Per-Pixel Normalization</head><p>In <ref type="bibr" target="#b4">[5]</ref> all splats are blended in back-to-front order without taking the depth buffer into account. The resulting artifacts are accepted for the advantage of a one-pass rendering algorithm. In contrast the issue of correct EWA splatting including the required normalization has been addressed in <ref type="bibr" target="#b20">[21]</ref>. Instead of doing a per-pixel normalization they switch to a lower quality per-surfel normalization, where the sum of α-weights is approximated to be constant for each splat.</p><p>On todays graphics hardware, however, a per-pixel normalization can be performed very efficiently. Reading the buffer, doing the normalization on the CPU and writing the resulting buffer back may be a first idea, but is in fact prohibitively expensive because of the required data transfer.</p><p>Instead we propose to accumulate the weighted splats in an offscreen buffer. This buffer can then be used as a texture for one single rectangle of the window's size. Rendering this rectangle will cause each pixel to go through the fragment pipeline again, so that a pixel shader can do the necessary division by α.</p><p>Since this technique effectively avoids sending the pixel data over the AGP bus, the per-pixel normalization can be performed at the cost of rendering one textured rectangle using a small pixel shader program. Compared to the time the two rendering passes take, this is basically negligible.</p><p>The resulting images provide a high visual quality comparable to existing software-or hardware-based implementations of EWA filtered surface splatting (c.f. Fig. <ref type="figure" target="#fig_4">5</ref> and Fig. <ref type="figure" target="#fig_7">8</ref>). But, as we will describe in the next sections, our approach is siginicantly faster than existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>Our implementation is based on OpenGL, the results we present measured on a 2.8GHz Pentium4 with a GeForceFX 5800 Ultra graphics card, running Linux. We delegate the different rendering tasks described in the previous sections to the programmable vertex shaders <ref type="bibr" target="#b14">[15]</ref> and pixels shaders, respectively. Although we used NVIDIA specific OpenGL extensions, the same would have been possible using the recently released vendor independent ARB vertex program and ARB fragment program extensions or even using the more comfortable and platform independent language Cg <ref type="bibr" target="#b15">[16]</ref>. Data layout: When processing complex point datasets including additional data like, e.g. normals and colors, the data transfer can become the limiting factor. Therefore the static scene geometry is stored in video or AGP memory so that it can be accessed by the GPU in DMA mode. Although we use the NV vertex array range extensions for this, it should also be possible using the new ARB vertex buffer object extension. In order to prevent cache misses the data should be arranged in interleaved vertex arrays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vertex stage:</head><p>A vertex program is used to transform the vertex position and to compute the eye-space normal vector. Using Eq. 1 it computes the image-space splat size, where rounding the resulting size to an integer value turned out to increase efficiency. Finally the vertex program sets up the data required for computing the per-pixel depth offset and depth correction. This data is passed to the fragment stage in the texture coordinate registers, thereby keeping 32 bit of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fragment stage:</head><p>The fragments generated from the image-space squares are processed by a fragment shader. This program first combines lighting and texture/color information, where the lighting can be precomputed in a cube map for higher efficiency. In order to compute the depth offset a parameterization of the splat square is required. Using the NV point sprite extension these parameter values can be derived from the point sprite texture coordinates. They are used to compute the depth offset according to Eq. 2. Either the (squared) norm (x, y, δz) T 2 (no filtering) or the correct Gaussian weight (filtering) are stored in the α component, so that the α test can discard pixels outside the elliptical image-space splat. For splat filtering and blending additionally the per-pixel depth correction has to be done (Eq. 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Blending:</head><p>In order to accumulate the weighted contributions of splats in the form ( i α i (rgb) i , i α i ) different blending modes have to be used for the RGB and α components, which can be achieved using the EXT blend func separate extension.</p><p>Normalization: For the final per-pixel normalization the two rendering passes are rendered to an offscreen buffer that is then used as texture image for a window-sized rectangle. In order to allow for non-power-of-two viewport width and height the NV texture rectangle extension is used.</p><p>Performance The bottleneck of our rendering algorithm is the fragment processing, mainly because of the per-pixel depth correction. In order to avoid generating unnecessary fragments we added a backface-culling method to the vertex shader that drops a splat depending on its eye-space normal vector. This simple technique effectively removes about 40% of the splats and speeds up the rendering significantly. However, since fragment programs are a very recent feature they are supposed to have room for improvements, so that future drivers or cards will yield better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Our point-rendering method can be used on two different quality levels: for the faster but the lower quality solution we only adjust splat size and splat shape as described in Sec. 3.1 and 3.2. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, this already gives much better results than using fixed splat shapes and effectively avoids the typical thickening effect near contours. On this quality level our method is able to render about 28M elliptical un-filtered splats per second on a 2.8GHz Pentium4 with a GeForceFX 5800 Ultra graphics card.</p><p>For high quality filtered surface splatting we have to use two rendering passes, because on current graphics hardware there is no other way to implement the -depth test described in Sec. <ref type="bibr" target="#b2">3</ref> [7] adding this additional feature to future GPUs would increase the rendering performance for high quality filtered primitives by a factor of two. However, our current implementation is based on a two-pass rendering and the necessary per-pixel normalization. It achieves a splat rate of about 10M high quality filtered splats per second. We tested the performance of our implementation using models of strongly varying complexities from 100k points up to 1.6M points. Table <ref type="table" target="#tab_0">1</ref> lists the respective rendering times in frames per seconds and in million splats per second. Since our rendering approach is limited by the fragment processing speed, models containing more points results in higher splat rates as the projected size of splats will be smaller. Comparing the timings for a window resolution of 512 × 512 or 1024 × 1024, respecively, confirms this result. Since for the more complex models projected splat sizes are still just a few pixels, their rendering speed stays almost the same. Low complexity models generate larger image-space splats, putting more load on the fragment processing.</p><p>Comparing our approach to the one of <ref type="bibr" target="#b20">[21]</ref>, we follow more closely the idea of point-based rendering, since we represent and render each splat using just one vertex. Since our resulting splat rendering is mainly pixel-based, several computations can be formulated easier and solved more efficiently. E.g. in order to compute the depth offset for the first rendering pass, Ren et al. have to shift each vertex along the viewing rays in object-space. Since we update the fragment's depth value anyway we just have to change one constant parameter of the pixel shader. Another limitation of <ref type="bibr" target="#b20">[21]</ref> is the symmetric matrix decomposition that has to be done for each vertex in order to compute the corresponding object-space rectangle's corner positions. Again, we determine the splat shape and Gaussian α-mask by simple image-space computations as described in Sec. 3.2. While the approach of <ref type="bibr" target="#b20">[21]</ref> renders up to 3M surface splats per second using the heuristic per-surfel normalization, our implementation achieves significantly higher splat rates using the per-pixel normalization.</p><p>It is harder to compare our approach to the work of Coconu and Hege <ref type="bibr" target="#b4">[5]</ref> since both methods are targeting different goals. By using only one rendering pass and blending all splats regardless of their depth distance, <ref type="bibr" target="#b4">[5]</ref> trade visual quality for rendering speed. In constrast we aim at a depthcorrect implementation of filtered surface splatting, requiring the expensive two-pass approach. Nevertheless we manage to achieve higher frame rates. The major bottleneck of <ref type="bibr" target="#b4">[5]</ref> seems to be the CPU intensive sorting of the octree cells from back to front, whereas our method puts no load at all on the main CPU.</p><p>While our approach is significantly slower than <ref type="bibr" target="#b6">[7]</ref>, we achieve improved visual quality even when using less surface splats, since the piecewise linear splats have better approximation properties. Nevertheless our rendering method should seamlessly integrate into the sequential point trees. This promising combination would result in a GPU-based hierarchical level-of-detail rendering of high-quality splats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we presented an algorithm for the rendering of point-based geometry that closes the gap between high quality software implementations and lower quality hardware-accelerated approaches.</p><p>We propose the consequent delegation of the involved rendering tasks to the GPU, since this keeps the CPU free for other tasks. As more and more point-based geometry processing methods are used, it is even more important that these algorithms do not have to share CPU resources with the rendering process. Since the efficiency as well as the programmability of current GPUs is increasing at a much higher rate than CPU performance, using the GPU for most efficient rendering seems to be the straightforward consequence.</p><p>Future work includes an implementation based on vendor independent ARB extensions only or even using the high-level language Cg. This would provide high quality splat rendering for on a wider range of graphic cards. A very promising direction of future research is the integration of this work into the sequential point trees of Dachsbacher et al. <ref type="bibr" target="#b6">[7]</ref>, since this would result in a high quality hierarchical level-of-detail rendering algorithm that is completely processed by the GPU.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The typical thickening and aliasing effects of square splats (left) is effectively avoided by using the correct ellipitical splats shapes (right).</figDesc><graphic coords="3,53.15,72.03,113.80,82.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Transformation pipeline. The mapping from eye-space to image-space consists of a projective warp of the viewing frustum to the unit cube, a parallel projection and a 2Dtransform to match the window extent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Splat size and shape. Adjusting the splat size just results in screen-space squares to be rendered at the splat center's position (top). Additionally using the correct elliptical splat shape gives a much better approximation, especially near contours (splat radii have been decreased to better show the effect).</figDesc><graphic coords="4,169.48,126.92,99.00,53.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Depth correction. Adjusting the image-space splat size yields a square parallel to the image plane. The required depth correction δz can be computed from the image-plane square coordinates (x, y) ∈ [-1, 1] 2 and the splat's eye-space normal vector n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Splat filtering including per-pixel normalization results in high quality image reconstruction. This effect becomes especially visible in the case of high frequency textures. While in the left unfiltered image alias-problems appear, the splat filtering on the right provides a smooth result.</figDesc><graphic coords="5,88.97,72.00,148.50,113.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. In order to show the effect of depth correction the z-buffer of the left scene has been re-projected using the techniques of [12]. While splats rendered without depth correction (center) have constant depth, like being parallel to the image plane, per-pixel depth correction solves this problem and avoids blending artifacts (right).</figDesc><graphic coords="5,389.86,263.46,74.20,69.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Some models we tested our implementation on and whose rendering timings and complexities are shown in Table 1. From left to right: St. Matthew, Max Planck, Male, Balljoint, Chameleon.</figDesc><graphic coords="9,64.94,76.11,99.00,114.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Splat filtering results in high quality image reconstruction similar to anisotropic texture filtering. In the upper left image and the upper close-up no filtering has beed used, leading to strong alias-artifacts. Splat filtering instead effectively removes these artifacts (upper right and lower close-up).</figDesc><graphic coords="9,54.39,476.03,227.70,58.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The models of Michelangelo's David and Charlemagne are both 3D range scanned statues. For the David a consistent decimated triangle mesh has been sampled. The input data for the Charlemagne model are just the set of registered but unconnected range scans.</figDesc><graphic coords="9,316.85,310.84,113.80,269.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . The resulting timings for several models, given for window resolutions of</head><label>1</label><figDesc>.3. As proposed by Dachsbacher et al. 512 × 512 and 1024 × 1024, and</figDesc><table><row><cell></cell><cell></cell><cell cols="2">512 × 512</cell><cell cols="2">1024 × 1024</cell></row><row><cell></cell><cell># points</cell><cell>unfiltered</cell><cell>filtered</cell><cell>unfiltered</cell><cell>filtered</cell></row><row><cell>Charlemagne</cell><cell cols="2">1.63M 17.2 (28.1)</cell><cell>6.3 (10.4)</cell><cell>16.9 (27.6)</cell><cell>6.2 (10.1)</cell></row><row><cell>St. Matthew</cell><cell cols="2">1.57M 17.2 (27.1)</cell><cell>6.4 (10.1)</cell><cell>16.9 (26.6)</cell><cell>6.3 ( 9.9)</cell></row><row><cell>David Head</cell><cell cols="2">1.08M 25.6 (27.9)</cell><cell>9.4 (10.3)</cell><cell>24.1 (26.2)</cell><cell>9.0 ( 9.8)</cell></row><row><cell>David</cell><cell cols="2">1.06M 26.4 (28.0)</cell><cell>9.5 (10.0)</cell><cell>25.7 (27.3)</cell><cell>9.3 ( 9.9)</cell></row><row><cell>Max</cell><cell cols="5">655k 42.7 (27.9) 15.3 (10.0) 40.4 (26.4) 14.2 ( 9.3)</cell></row><row><cell>Male</cell><cell cols="5">148k 124.2 (18.4) 56.5 ( 8.4) 112.4 (16.7) 46.6 ( 7.0)</cell></row><row><cell>Balljoint</cell><cell cols="5">137k 172.6 (23.7) 73.2 (10.0) 124.3 (17.0) 45.3 ( 6.2)</cell></row><row><cell>Chameleon</cell><cell cols="5">101k 178.7 (18.2) 74.9 ( 7.6) 150.3 (15.3) 55.3 ( 5.6)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>unfiltered or filtered rendering. The first values are frames per second, the values in brackets are million splats per second.</head><label></label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>GPU-Based SplattingIn our approach we also propose the use of splats as rendering primitives, as they have major advantages compared to pure one-pixel points. Since splats are not just a piece-</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The St. Matthew and David models have been taken from the Stanford 3D Scanning Repository. The models Male, Balljoint and Chameleon are from the Pointshop3D homepage.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Point set surfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Behr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient high quality rendering of point sampled geometry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Botsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wiratanaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kobbelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics Workshop on Rendering</title>
		<meeting>Eurographics Workshop on Rendering</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The a-buffer, an antialiased hidden surface method</title>
		<author>
			<persName><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 1984 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pop: a hybrid point and polygon rendering system for large data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visulization</title>
		<meeting>IEEE Visulization</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hardware-accelerated pointbased rendering of complex scenes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Coconu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics Workshop on Rendering</title>
		<meeting>Eurographics Workshop on Rendering</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="41" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hybrid simplification: combining multi-resolution polygon and point rendering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Aliaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="37" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sequential point trees</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dachsbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogelgsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2003 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Interactive visualization of complex plant ecosystems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Colditz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Drettakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Progressive point set surfaces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Graphics</title>
		<imprint/>
	</monogr>
	<note>to appear in ACM</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Point sample rendering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Workshop on Rendering 1998</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="181" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fundamentals of Texture Mapping and Image Warping</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Heckbert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>University of California at Berkley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An interactive approach to point cloud triangulation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kobbelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics 2000 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The digital michelangelo project: 3d scanning of large statues</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ginzton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ginsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fulk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 00 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="131" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The use of points as display primitives</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Whitted</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985-01">January 1985</date>
		</imprint>
		<respStmt>
			<orgName>CS Departement, University of North Carolina at Chapel Hill</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A userprogrammable vertex engine</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kilgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moreton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2001 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cg: A System for Programming Graphics Hardware in a Clike Language</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Glanville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kilgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2003 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Spectral Processing of Point-Sampled Geometry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2001 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient simplification of point-sampled surfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kobbelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shape Modeling with Point-Sampled Geometry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kobbelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2003 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Surfels: Surface elements as rendering primitives</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Baar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2000 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="335" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Object space ewa surface splatting: A hardware accelerated approach to high quality point rendering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zwicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics 2002 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">QSplat: a multiresolution point rendering system for large meshes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2000 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="343" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Interactive sampling and rendering for complex and procedural geometry</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Drettakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Workshop on Rendering</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="151" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Footprint evaluation for volume rendering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 1990 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PointShop 3D: An Interactive System for Point-Based Surface Editing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2002 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Surface splatting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Baar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph 2001 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="371" to="378" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
