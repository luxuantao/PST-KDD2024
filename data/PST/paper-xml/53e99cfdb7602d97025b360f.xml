<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Auralist: Introducing Serendipity into Music Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Laboratory</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhang</forename><forename type="middle">§</forename><surname>Diarmuid</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ó</forename><surname>Séaghdha</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Laboratory</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniele</forename><surname>Quercia</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Laboratory</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Tamas</forename><surname>Jambor</surname></persName>
							<email>t.jambor@cs.ucl.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Seattle, Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Auralist: Introducing Serendipity into Music Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3257025E126C6D3A7CD98705D566F0B2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Retrieval and Search</term>
					<term>H.2.8 [Database applications]: Data mining</term>
					<term>I.2.6 [Artificial Intelligence]: Learning-Knowledge Acquisition Algorithms, Experimentation, Human Factors Collaborative filtering, diversification, serendipity, novelty, accuracy, recommender systems, metrics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommendation systems exist to help users discover content in a large body of items. An ideal recommendation system should mimic the actions of a trusted friend or expert, producing a personalised collection of recommendations that balance between the desired goals of accuracy, diversity, novelty and serendipity. We introduce the Auralist recommendation framework, a system that -in contrast to previous work -attempts to balance and improve all four factors simultaneously. Using a collection of novel algorithms inspired by principles of 'serendipitous discovery', we demonstrate a method of successfully injecting serendipity, novelty and diversity into recommendations whilst limiting the impact on accuracy. We evaluate Auralist quantitatively over a broad set of metrics and, with a user study on music recommendation, show that Auralist's emphasis on serendipity indeed improves user satisfaction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In an era of increasing choice, recommender systems have emerged as an important tool to help consumers manage the dizzying array of options presented by digitised markets and communities. Recommender systems generate prioritised list of unseen items by trying to predict a user's preferences based upon their profile. Such systems can now be seen in numerous applications (recommending, e.g., music, books), and have been shown to aid online sales <ref type="bibr" target="#b21">[21]</ref>.</p><p>Until recently, the vast majority of previous research has focused on improving the accuracy of recommendation: better modelling user preference so as to produce individually more enjoyable items. A growing trend, however, is to consider factors other than accuracy that contribute towards the quality of recommendation <ref type="bibr" target="#b15">[15]</ref>. Notions of diversity, novelty and serendipity have been recently explored <ref type="bibr" target="#b8">[8]</ref> as objectives that often conflict with the drive for accuracy.</p><p>The dangers of an overt focus on accuracy are twofold. Firstly, in failing to consider human desires for variety, discovery and change, accuracy-focused recommenders may forfeit an overall improved user experience, producing boring and ineffective recommendations. Secondly, in considering that recommendations have the power to shape user consumption patterns, there is an aesthetic concern that too much personalisation and pandering to a user's existing tastes harms a user's personal growth and experience. The extreme concept of a "filter bubble" describes the idea that users could be trapped in a self-reinforcing cycle of opinion, never being pushed to discover alternative genres or viewpoints <ref type="bibr" target="#b17">[17]</ref>.</p><p>It is important, then, that systems are designed with such alternative qualities in mind. We introduce a series of novel and well-grounded approaches that together compose the Auralist recommender, a system that explicitly balances the conflicting goals of accuracy, diversity, novelty and serendipity. Whereas prior research has often focused on these factors individually (as we shall see in our discussion of related work in Section 2), we use a range of metrics to measure all three non-accuracy factors simultaneously. Our methods are introduced as part of a hybrid framework that can combine a variety of algorithms to achieve the desired mix of qualities.</p><p>We address the issue of non-accuracy factors by focusing on techniques that simultaneously inject novelty, diversity, and serendipity into the recommendation process. In this way, we hope to actively counteract the constricting effects of personalisation. More specifically, we make three main contributions:</p><p>Auralist Framework.</p><p>Auralist uses hybrid rank-interpolation to combine the output of three constituent algorithms in four different combinations: 1) Basic Auralist employs solely a new item-based col-laborative filtering algorithm called Artist-based LDA based on Latent Dirichlet Allocation <ref type="bibr" target="#b3">[3]</ref> (Section 4.1); 2) Community-Aware Auralist combines Artist-based LDA with a new algorithm called Listener Diversity that promotes artists with "diverse" listenerships (Section 4.2.1); 3) Bubble-Aware Auralist combines Artistbased LDA with the new Declustering algorithm that identifies and counteracts a user's "music bubble" (Section 4.2.2); and 4) Full Auralist is the combination of all three algorithms (Artist-based LDA, Listener Diversity, and Declustering) together.</p><p>Quantitative evaluation of Auralist. We evaluate the different versions of Auralist using a comprehensive set of metrics that simultaneously assess accuracy, diversity, novelty and serendipity in user recommendation results (Section 5). We find that Basic Auralist produces recommendations that are as accurate as those produced by the state-of-the art Implicit SVD algorithm <ref type="bibr" target="#b10">[10]</ref>, and that both Community-Aware Auralist and Bubble-Aware Auralist greatly improve all three qualities of diversity, novelty and serendipity with differing trade-offs in accuracy.</p><p>Qualitative evaluation of Auralist. We conduct a user study to assess the objective qualities of enjoyment, real-world novelty, serendipity and overall user satisfaction (Section 6). We find that Full Auralist, although having lower accuracy and individual item enjoyment, is significantly more serendipitous and proves more satisfying overall than Basic Auralist.</p><p>Before concluding, we discuss the practical implications of our findings that go beyond music recommendation (Section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Our research builds upon previous work attempting to quantify and measure the additional factors influencing enduser recommendation quality. We also draw inspiration from the implementation of algorithms designed to retain or enhance such qualities.</p><p>The techniques we propose belong to a family of modelbased techniques for collaborative filtering <ref type="bibr" target="#b22">[22]</ref>. Item-based <ref type="bibr" target="#b20">[20]</ref> approaches in particular have found use in a number of commercial applications, being pioneered for Amazon.com product recommendations <ref type="bibr" target="#b13">[13]</ref>. The possible use of LDA for recommendation was touched upon by Blei <ref type="bibr" target="#b3">[3]</ref> in his initial formulation of the model, but it was later research by Hoffman <ref type="bibr">[9]</ref> that established the use of Latent semantic models (in the form of the PLSI topic model) as tools for collaborative filtering.</p><p>Early concepts of novelty and serendipity were described by Herlocker <ref type="bibr" target="#b8">[8]</ref> in his seminal survey of recommendation evaluation techniques, with other authors contributing quantitative measures and definitions <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b16">16]</ref>. More recently, Vargas and Castells <ref type="bibr" target="#b25">[25]</ref> attempt to formally unify diversity and novelty in a single evaluation framework. Our framework takes the straightforward approach of selecting a single metric to measure each evaluation independently.</p><p>The idea of balancing multiple objectives in recommendation has a strong basis in previous research. Adomavicius and Kwon <ref type="bibr" target="#b1">[1]</ref> introduce a re-ranking method of diversityimprovement by applying a number of simple re-ranking algorithms to the output of accuracy-focused collaborative filtering algorithms. The diversity-accuracy tradeoff is controlled by restricting the re-ranking to the top-N most accurate items, thus restricting the maximum movement of an item. They show substantial improvements in the number of distinct items recommended in the top-N lists of users.</p><p>Jambor and Wang <ref type="bibr" target="#b11">[11]</ref> frame conflicting objectives as a series of optimisation constraints, for use in a matrix factorisation algorithm. In one such experiment, the authors introduce constraints related to novelty and diversity, which are able to alter the distribution of popular items within a top-N list with little impact on accuracy. Ziegler et al. <ref type="bibr" target="#b29">[29]</ref> use a topic diversification algorithm to rank items according to dissimilarity to preceding items in the recommendation set, integrating this information into recommendations through a rank-interpolation method; an approach that we reproduce, but across a wider set of objectives. A similar strategy appears in Zhou and Kuscik <ref type="bibr" target="#b27">[27]</ref>, where two graphspreading algorithms that specialise in terms of accuracy and novelty performance respectively are hybridised in order to produce a recommender with the properties of both. Their results suggest that interpolation is indeed a viable method of producing balanced recommendations.</p><p>It is unclear, however, if multiple properties in addition to accuracy can be promoted at once. We present next a detailed description of the three properties of diversity, novelty and serendipity (Section 3) and a selection of algorithms that attempt to incorporate those properties in the recommendation process (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">WHY ACCURACY IS NOT ENOUGH</head><p>Before defining the three properties, we introduce two widely-used measures of accuracy and explain when they fall short of what is needed to measure the effectiveness of recommender systems.</p><p>Traditionally, recommendation quality is measured using one of a number of accuracy metrics, which assess how well the predictive output of a system matches a proportion of known, withheld items for each user. Examples of accuracy metrics include average Top-N Recall and the average Rank score proposed by Hu et al. <ref type="bibr" target="#b10">[10]</ref>. Recall-based metrics measure the proportion of a user's test-set that appear within a Top-N recommendation list -a Top-20 list that successfully includes 5 out of 10 test-set items will score a single-user recall of 0.5. These metrics we describe using a set of common symbols in Table <ref type="table" target="#tab_0">1</ref>.</p><formula xml:id="formula_0">T op-20 Recall = 1 |S| u∈S |Ru,20 ∩ Wu| |Wu|<label>(1)</label></formula><p>The average Rank score measures the average percentage rank of withheld items in a user's history, weighted by (positive) preference (for boolean preferences, the average Rank is simply the average rank of all history items). Unlike T op-20 Recall, Rank assesses how accurate a system is at modelling a user's entire history, not just the most easily recommended items. It also takes into account the full recommendation ranking, which complements recall-based assessments of only the top (observable) items: Other metrics, such as RMSE (which measures the standard error of predicted preferences) have also seen widespread use.</p><formula xml:id="formula_1">Rank = 1 |S| u∈S j∈N Pj,urankj,u j∈N Pj,u<label>(2)</label></formula><p>The above metrics, however, are better suited to handle the boolean nature of our dataset, which is described further in Section 5.1. The use of accuracy as a performance metric is well-grounded; previous user studies, such as the one conducted by Swearingen and Sinha <ref type="bibr" target="#b23">[23]</ref> indicate that recommendation accuracy is a primary factor behind user satisfaction with recommendation systems. This has led to a focus on improving accuracy in recommendation algorithms; state-of-the-art systems score very highly indeed <ref type="bibr" target="#b10">[10]</ref>. However, this is not to say that accuracy alone guarantees satisfactory recommendations.</p><p>There is a growing argument that factors other than accuracy also influence recommendation quality <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b19">19]</ref>. Recommendation techniques that focus purely on accuracy may neglect such alternative qualities and produce recommendations that appear superficially "good" but are in fact inferior in terms of actual user satisfaction. An extreme example of this may be a recommendation set consisting of entirely Beatles songs -the recommendations themselves may be accurate, but users will rapidly become bored with a collection of such similar and generic items.</p><p>To fix this problem, the three criteria of diversity, novelty and serendipity have been introduced by researchers. These assess the major factors influencing recommendation satisfaction alongside accuracy. Unlike previous work which has often considered only one or two such factors, we measure our improvements against a comprehensive assessment of each. To better characterise likely usage scenarios, all our metrics are applied to the Top-20 recommendation list for each user, representing the fact that in a realistic application users are unlikely to be exposed to anything below the very top of the rankings.</p><p>Diversity represents the variety present in a list of recommendations. A diverse list can be seen to counteract user satiety with (homogeneous) recommendations. The aforementioned all-Beatles recommendation list, for example, is much less diverse than a list containing a wider assortment of artists. Previous research has shown that users will actively choose less-preferred items in an effort to improve the variety of consumption <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b29">29]</ref>. We measure diversity through the Intra-List Similarity metric introduced by Ziegler et al. <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref>, using (binary) cosine similarity (CosSim) to judge the similarity between items. Intra-List Similarity essentially sums the pairwise similarity of all items in a set (simplified in our case due to a symmetric similarity measure). Intuitively, the greater the proportion of preferring users two items have in common, the greater the similarity value Cos-Sim will register. A recommendation list with groups of very similar items will score a high intra-list similarity compared to a list that has more dispersed and diverse recommendations.</p><formula xml:id="formula_2">Intra-List Similarity = 1 |S| u∈S i,j∈R u,20 ,j&lt;i CosSim(i, j)<label>(3)</label></formula><p>CosSim(i, j) = # users who like both i and j</p><formula xml:id="formula_3">√ # prefs in i × √ # prefs in j<label>(4)</label></formula><p>Novelty can be seen as the ability of a recommender to introduce users to items that they have not previously experienced before in real life (such experiences may be outside the system itself; e.g., music listened to whilst not on a computer). A recommendation that is accurate but not novel will include items that the user enjoys, but already knows of. A limited proportion of such recommendations has been shown <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b18">18]</ref> to have a positive, trust-building impact on user satisfaction, but it can also be seen that to be useful a recommender needs to suggest previously unknown items.</p><p>We measure novelty with a metric previously introduced by Zhuo and Kuscik <ref type="bibr" target="#b27">[27]</ref>:</p><formula xml:id="formula_4">N ovelty = 1 |S| u∈S i∈R u,20 log 2 popi 20<label>(5)</label></formula><p>This novelty metric quantifies the average information content of recommendation events -higher values mean that more globally "unexplored" items are being recommended. Under the assumption that the likelihood a user has experienced an item is proportional to its global popularity, this serves an approximation of true novelty. We measure actual novelty on an individual basis in our user study (Section 6).</p><p>Serendipity represents the "unusualness" or "surprise" of recommendations. Unlike novelty, serendipity encompasses the semantic content of items, and can be imagined as the distance between recommended items and their expected contents. A recommendation of John Lennon to listeners of The Beatles may well be accurate and novel, but hardly constitutes an original or surprising recommendation. A serendipitous system will challenge users to expand their tastes and hopefully provide more interesting recommendations, qualities that can help improve recommendation satisfaction <ref type="bibr" target="#b23">[23]</ref>. We assess serendipity through a new Unserendipity metric, which uses CosSim to measure the average similarity between items in a user's history Hu and new recommendations. Lower values indicate that recommendations deviate from a user's traditional behaviour, and hence are more surprising:</p><formula xml:id="formula_5">U nserendipity = u∈S 1 |S||Hu| h∈Hu i∈R u,20 CosSim(i, h) 20<label>(6)</label></formula><p>This metric bears some similarities to the distance-based novelty family of metrics seen in Vargas et al. <ref type="bibr" target="#b25">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE AURALIST FRAMEWORK</head><p>At heart, the Auralist framework is an experiment in combining distinctive recommendation algorithms to improve overall (serendipitous) performance. Here, we introduce three techniques for generating recommendation rankings (Artistbased LDA, Listener Diversity and Declustering) that are paired to create different flavours of Auralist. Basic Auralist (Section 4.1) incorporates the so-called Artist-based LDA technique and is intended as a standalone recommender system. Community-Aware (Section 4.2.1) and Bubble-Aware (Section 4.2.2) Auralist versions interpolate Artist-based LDA with Listener Diversity and Declustering rankings respectively. These versions combine small elements of a serendipityfocused algorithm to reorder the basic algorithm's recommendations. A final Full Auralist recommender combines all three sub-algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Basic Auralist</head><p>Basic Auralist is an item-based recommender system that employs Latent Dirichlet Allocation as a technique for computing item features. We call this approach Artist-based LDA and present it next.</p><p>LDA has been used traditionally in topic-modeling, being a fully generative model for document production <ref type="bibr" target="#b3">[3]</ref>. Under this framework, words within a large document set can be clustered into topics based upon co-occurrence, each topic being a probabilistic distribution over word tokens. A "topic composition vector" can then be determined for each document, indicating the estimated level of influence each "topic" would have if the document were to be generated using the LDA model. Both topic clustering and document composition can be computed stochastically using the Gibbs Sampling algorithm (described in Griffiths and Steyvers <ref type="bibr" target="#b7">[7]</ref>) in an unsupervised manner over a training dataset.</p><p>Our approach applies Gibbs Sampling to the unary preferences of our Last.fm dataset (described in Section 5.1) using the MALLET toolkit <ref type="bibr" target="#b14">[14]</ref>. We note two straightforward means of framing user-artist preferences in a manner suitable for LDA. In a User-based LDA model, users are treated as LDA documents and preferred artists as words. This produces a series of artist topics corresponding roughly to artist genre, but does not tell us anything about the artists themselves. Conversely, the inverse Artist-based LDA model treats artists as documents and preferring users as words, producing a fixed-length topic composition vector for each item. Topics in the artist-based model can be imagined to represent user-communities, clustering together users with similar preferences. Topic vectors thus represent the distribution of the listener base of an artist, and can be used to characterise them. We then define a LDA similarity metric as the (real-valued) cosine similarity between artist topic vectors:</p><formula xml:id="formula_6">LDASim(i, j) = t∈T Li,t × Lj,t t∈T (Li,t) 2 t∈T (Lj,t) 2 (7)</formula><p>This similarity metric is then used directly for item-based recommendation by defining Basic(u, i), which is the score that user u associates to item i:</p><formula xml:id="formula_7">Basic(u, i) = h∈Hu LDASim(i, h)<label>(8)</label></formula><p>All artists can be sorted (in descending order) by the sumtotal of their similarity with items in a user's existing history <ref type="bibr" target="#b13">[13]</ref>. This produces a rankBasic,u,i for each item i, with the most similar items awarded the smallest percentage ranks. By generalising user "topics", we aim to both smooth the data and generate less obvious and more serendipitous recommendations compared to more naïve techniques, as connections can now be made through similar, but not directly related users. We note also that Basic Auralist built on Artist-based LDA inherits two main benefits common to model-based recommenders: faster online performance (if item-item similarities are not precomputed) and a compact semantic representation of the data (in this case, in terms of listener composition). This semantic representation is exploited in the following subsection to further influence recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Two hybrid versions of Auralist</head><p>To increase the novelty, diversity, and serendipity of Basic Auralist's recommendations, we combine Artist-based LDA recommendation with two new algorithms. The first is called Listener Diversity and aims to prioritise for recommendation artists with particularly diverse listener communities, encouraging users to explore beyond a given niche. The combination of Artist-based LDA and Listener Diversity is called Community-Aware Auralist (Section 4.2.1).</p><p>The second algorithm is called Declustering and aims to determine a user's "musical bubbles" (clusters of artists that the user listens to) and then recommend artists outside established cluster groups (hence Declustering). The combination of Artist-based LDA and Declustering is called Bubble-Aware Auralist (Section 4.2.2).</p><p>We combine the different Auralist algorithms by merging their individual rank outputs. One way of doing so is to produce a hybrid score for each item (artist) <ref type="bibr" target="#b29">[29]</ref>. Intuitively, the hybrid ranking score of an item i can be taken as a linear interpolation of the percentage [0,1) rank the item has in the output of each of the contributing algorithms. A set of interpolation coefficients λa over a set of algorithms A controls the influence of each individual algorithm. In the case of the generalised Full Auralist recommender, we have three λ coefficients governing an algorithm set A that includes Artist-based LDA, Listener Diversity and Declustering.</p><formula xml:id="formula_8">Hybrid(u, i) = a∈A λa(ranka,u,i)</formula><p>The final recommendation output consists of the item list sorted by the hybrid rank score. The "hybridisation" of recommendation allows an accuracy-focused Basic Auralist to be combined with small proportions of diversity or serendip-ity promoting algorithms, in order to improve the overall balance of qualities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Community-Aware Auralist</head><p>Community-Aware Auralist introduces the Listener Diversity metric for artists, which is used to produce a ranked list of the most diverse artists. This list is blended with Basic Auralist to promote more diverse artists in recommendation.</p><p>We recall that for the Artist LDA model, topics are formed over "user communities", groups of users that share common item preferences. An artist in the LDA recommender is represented by a vector of topic proportions indicating how listeners of that artist are distributed amongst these "user communities".</p><p>Such a representation offers us a unique perspective on the demographics of listeners, not visible when observing the raw vector of preferences. Certain artists, whilst popular in their own right, might have a listener base concentrated in only a few user communities, whereas the listeners of another artist might be more widely distributed.</p><p>Given that a LDA topic vector is a probability distribution summing to 1, we use the entropy of such a distribution to measure its skewedness. A distribution focused on only a few outcomes will score a less negative entropy; a more evenly and widely distributed event will produce a greater negative entropy. We thus introduce Listener Diversity of an artist i as the entropy over its topic distribution:</p><formula xml:id="formula_9">Listener Diversity(i) = - t∈T Li,t log 2 (Li,t)</formula><p>What does Listener Diversity represent in terms of recommendation quality? Intuitively, we can imagine it as being a measure of nicheness -how polarising a given performer is. A Ukrainian bagpipe metal band 1 is unlikely to spark broad appeal compared to, say, The Beatles. However, that is not to say that the former should not be recommended, if the user belongs to the limited demographic following that style of music. In the context of serendipitous recommendations, however, we seek to expand a user's music taste beyond that of his comfort zone. A strategy for this would be to highlight more diverse artists that include a user's established music communities, but also introduce elements of ones the user may be unfamiliar with. This balance can be achieved by interpolating the output of a Listener Diversity-sorted list with that of a conventional accuracy-focused algorithm; the former boosting the rank of more diverse artists whilst the latter ensures that ranking artists are still enjoyable:</p><formula xml:id="formula_10">Community(u, i) = (1 -λ)rankBasic,u,i + λrankDiversity,i</formula><p>Analysis of Listener Diversity's relationship with other factors shows that Listener Diversity tends to bias towards globally popular artists. This should be unsurprising, as such artists will garner more exposure and attract a naturally wider fan base. We compensate for this by discounting an artist's original Listener Diversity with a popularitydiversity regression function, highlighting artists that are diverse for their popularity level (popularity being the number Ci of the artist's unique listeners). The resulting adjusted 1 www.holyblood.com.ua Listener Diversity is:</p><p>Listener Diversity (i) = Listener Diversity(i)-Offset pop (i) (9) In our dataset (which will be described in Section 5.1), following a linear regression, we find the following coefficients for Offset pop (i):</p><p>Offset pop (i) = 0.462 log(Ci) -1.326.</p><p>(10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Bubble-Aware Auralist</head><p>As a counterpart to Listener Diversity, we introduce a graph-based algorithm termed Declustering. Declustering produces a ranked list of the least "clustered" or "boring" items for a user and is interpolated with Basic Auralist to form Bubble-Aware Auralist:</p><formula xml:id="formula_11">Bubble(u, i) = (1 -λ)rankBasic,u,i + λrank Declustering,u,i</formula><p>We compute Declustering scores over what we call the "Artist Graph". Formally, this is a graph G = (N, E) where each node i ∈ N is an artist and edges (i, j, weight) ∈ E are drawn between artists that have non-zero similarity, according to a similarity metric weight = sim(i, j) computed with the previously defined LDASim (Equation <ref type="formula">7</ref>). Intuitively, framing recommendations in this format allows us to apply network-based analysis techniques to (prospective) items. Such a model has been used previously by Celma et al. <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b4">4]</ref> to investigate the long-tail properties of music recommendation in terms of network links. We further introduce the idea of a user's "local preference graph", which can also be seen as a user's "music bubble". This is the subgraph Gu = (Hu, Eu) of the artist G consisting only of the nodes i ∈ Hu that are found in the preference history of the user.</p><p>The Declustering algorithm attempts to identify nodes that lie on the edge of clusters in a user's graph, avoiding heavy concentrations of previous activity ("boring" recommendations) whilst still maintaining overall similarity. In this way we hope to help users expand their music taste, literally pushing the boundaries of the region their behaviour occupies in the feature-space. This recommendation strategy is motivated by concepts of social network theory such as clustering and brokerage <ref type="bibr" target="#b6">[6]</ref>.</p><p>In analysing the Artist Graph, we find that the Last.fm dataset has a power-law distribution of node degrees, suggesting it may have "small-world" properties <ref type="bibr" target="#b26">[26]</ref>. This implies a graph structure similar to that of a social network, with nodes being clustered around a series of high-degree "hubs". Therefore, we employ a metric commonly used in social-network analysis to measure how clustered nodes in a network are. The clustering coefficient of a node i is defined as:</p><formula xml:id="formula_12">Clustering(i) = 2×|{(j, k) ∈ Eu|j, k ∈ neighbours(i)}| |neighbours(i)|×(|neighbours(i)|-1)<label>(11)</label></formula><p>where neighbours(i) is the set of nodes that are neighbours of item i in the local preference graph. The clustering coefficient of a node measures the proportion of possible interconnections that exist amongst neighbours of a node. A node with a high clustering coefficient is surrounded by tightly interconnected nodes (i.e., in the centre of a near-clique) whereas a node with a lower clustering coefficient might have neighbours split between multiple clusters or lie on the edge of an existing cluster.</p><p>foreach item pair j, k in Hu do total+= LDASim(j, k); count+=1; end avgSim = total/count; foreach item i in candidate set for user u do foreach item pair j, k in neighbours(i) do if LDASim(j, k) &gt; avgSim then edgeTotal+=1; end edgeCount+=1; end cluster(i) = edgeTotal/edgeCount; recommendations.add(cluster(i), i); end recommendations.sortBy(cluster, ascending); Algorithm 1: Pseudo-code for Declustering.</p><p>The Declustering algorithm (Algorithm 1) considers in turn all the prospective recommendations for a user. For each item, it temporarily adds the item to the graph and computes the clustering coefficient of that node with respect to the existing elements of the user's local preference graph. The output of the algorithm is an ordered list of the most "cluster-avoiding" artists in the candidate set, which (as with Listener Diversity) can be interpolated with a conventional recommender to apply counter-clustering pressure to recommendation items. As the clustering coefficient operates over unweighted edges, we threshold edges in the local preference graph according to whether a similarity weight indicates unusual significance. An LDASim weight that exceeds the average for a particular user is considered significant for the purposes of computing the clustering coefficient. This has the effect of removing the majority of (weak) edges in the graph. We can also adjust the threshold in terms of standard deviations from the average; this affects the sensitivity of cluster detection and should be experimentally determined. Declustering's emphasis on low clustering scores reflects the desire to dissuade the recommendation of artists that are too deeply embedded in a genre cluster with respect to a particular user. Such artists are likely accurate but not serendipitous, being too similar to a great many of user's existing artists.</p><p>In the next section, we prove the effectiveness of our techniques by apply to them the evaluation metrics introduced in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION</head><p>The goals of our evaluation are to assess: 1) to which extent the Auralist framework produces diverse, novel, and serendipitous recommendations; 2) at which cost for accuracy Auralist produces such recommendations; and 3) the best combination of algorithms that produces an overall more satisfying recommender. To meet these goals, we employ the suite of metrics described in Section 3 to quantitatively measure the performance of both a set of baseline recommenders as well as various interpolations of our serendipity-enhancing techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>Our experiments are conducted over a 360k Last.fm user<ref type="foot" target="#foot_0">2</ref> dataset <ref type="bibr" target="#b12">[12]</ref>, collected by Òscar Celma in 2008<ref type="foot" target="#foot_1">3</ref> . This contains the user.getTopArtists() output for each user from the Last.fm API, which is a list of previously listened-to artists and play-counts derived from both Last.fm's online radio services and media player plugins.</p><p>In contrast to other publicly available datasets, the Last.fm dataset consists of implicit observations of user preference through prior behaviour. This means that there is no explicit ratings scale associated with preferences and that preferences themselves can be considered noisy -track metadata may be incorrect, songs may be left on loop/shuffle and user history lengths will vary. We clean the dataset to remove non-artist items, misspelled artist names and extremely unpopular artists, leaving us with 48,988 possible recommendation items. We take our implicit preferences to be unary (1 or nothing), which lends itself well to the processing techniques we introduced in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Basic Auralist Recommendation</head><p>We evaluate the effectiveness of Artist-LDA recommendation method against the state-of-the art Implicit SVD method introduced by Hu, Koren and Valinsky <ref type="bibr" target="#b10">[10]</ref>. We adapt this model to incorporate the implicit artist playcount as a confidence weight in the matrix factorisation cost function. Metrics are computed over random subsamples of 35k users; larger samples only marginally improve performance. 20% of each user's preferences were randomly withheld as a training sample. One feature of LDA that we leverage is the fact that Gibbs Sampling runs relatively quickly even on large user samples, compared to other model-based techniques. We thus bootstrap the LDA topic training step with the full 360k user dataset, which completes 1000 iterations in under an hour on an Intel Core TM i5 2.8GHz processor.</p><p>Our experimental results are reported in Table <ref type="table" target="#tab_1">2</ref> and show that Basic Auralist produces the most overall accurate rankings for user histories (Rank = 0.0194) whilst Implicit SVD produces the highest Top-20 Recall scores (0.174). Both algorithms score comparatively in diversity (Intra-List Similarity), whereas Implicit SVD has improved serendipity and Basic Auralist has slightly improved novelty.</p><p>The combination of accuracy scores seem to indicate that Implicit SVD does a better job of including items in the Top-20 list. However, it may be argued that for the use-case of serendipitous recommendation, a high recall is not necessary; recall indicates that similar, already known items are being placed in the Top-20 list, displacing the recommendation of novel items. By contrast, Basic Auralist broadly characterises what a user has previously liked (Rank) without being overtly sycophantic. Interestingly, of the items Implicit SVD does recommend, the registered U nserendipity is somewhat lower, implying that the generalisation of matrix factorisation does result in some less obvious recommendations as well. We exceed this serendipity value with later versions of Auralist. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Hybrid versions of Auralist</head><p>Figures <ref type="figure" target="#fig_0">1</ref> and<ref type="figure" target="#fig_1">2</ref> show the performance results for Community-Aware and Bubble-Aware Auralist. Table <ref type="table" target="#tab_1">2</ref> also includes their performance at points of interest along the λ curve (note at λ=0, both algorithms reduce to Basic Auralist).</p><p>Given that both hybrid versions of Auralist attempt to bias towards serendipitous recommendations at the expense of more "easily accurate" items, it should be unsurprising that both exhibit an accuracy-serendipity trade-off. More interestingly, both methods increase novelty and diversity, and do so at different rates.</p><p>As the Listener Diversity interpolation increases, Community-Aware Auralist's rapid improvements in nonaccuracy scores (Figures <ref type="figure" target="#fig_1">2(a</ref>), 2(b), 2(c)) are tracked by decays in recall (Figure <ref type="figure" target="#fig_0">1(b)</ref>) and to a lesser extent Rank (Figure <ref type="figure" target="#fig_0">1</ref>(a)), tailing off at higher proportions. Community-Aware Auralist hence represents a direct trade-off between accuracy and non-accuracy performance, with the most activity occurring in the 0 &lt; λ &lt; 0.05 range of Figures <ref type="figure" target="#fig_0">1</ref> and<ref type="figure" target="#fig_1">2</ref>. Compared with the other graphs, Community-Aware Auralist maintains a consistently sizable lead over Bubble-Aware Auralist in terms of novelty (Figure <ref type="figure" target="#fig_1">2</ref>(b)), likely due to the popularity correction Offsetpop we introduced in Section 4.2.1 (Equation <ref type="formula">10</ref>).</p><p>As with Community-Aware Auralist, the Bubble-Aware Auralist's performance curves for serendipity, novelty and diversity track that of T op-20 Recall. Unlike Community-Aware Auralist, however, Bubble-Aware Auralist's Rank decays at a much slower rate, and the performance curves possess sigmoid-like qualities, experiencing the greatest rate of change after about λ = 0.1 and diminishing returns afterwards. We propose that this is the point when the Declustering algorithm is able to successfully overcome the bias towards recommendations embedded within preference clusters and is able to successfully recommend cluster-bordering items. The nature of the Rank curve indicates that the bulk of this benefit can be achieved without an overwhelming effect on overall accuracy, suggesting that Bubble-Aware Auralist may be able to supply "almost free" serendipity, diversity and novelty.</p><p>Bubble-Aware Auralist manages to surpass Community-Aware Auralist in terms of serendipity relatively quickly (λ ∼ 0.15), continuing to improve even after Community-Aware Auralist's performance begins to plateau. This suggests that the serendipity improvement is not merely incidental (i.e., from declining accuracy), and is actively being promoted by Declustering.</p><p>To sum up, these findings indicate that Community-Aware Auralist is best used at smaller interpolations (0-0.05) as a roughly even trade between accuracy and non-accuracy qualities and as a broad stroke in changing the (accuracy/nonaccuracy) focus of a recommender. They also suggest that using Bubble-Aware Auralist during the peak rate of change before significant Rank penalties (Figure <ref type="figure" target="#fig_0">1(a)</ref>) accrue can improve non-accuracy qualities at very little cost. At λ = 0.2, a mere 0.7% increase in average history rank is accompanied by a 77% decrease in Intra-List Similarity, 20% increase in novelty and a 42% decrease in measured unserendipity. Overall, both methods prove to be able to successfully improve diversity, novelty and serendipity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">USER STUDY</head><p>Alongside our quantitative measurements, we further conduct a user study to validate the effectiveness of Auralist (and indeed, serendipity-orientated recommendation in general) in real-life situations. We measure the perceived serendipity, enjoyment, novelty and overall qualitative satisfaction associated with a refined version of the hybrid recommender.</p><p>The Full Auralist recommender combines Artist-LDA, Listener Diversity, and Declustering in proportions of λ1,2 = (0.03, 0.20) respectively (motivated by the results of the previous section) and demonstrates overall superior non-accuracy performance compared to our previous methods (Table <ref type="table" target="#tab_1">2</ref>):</p><formula xml:id="formula_13">F ullu,i =(1 -λ1 -λ2)rankBasic,u,i + λ1rankDiversity,u,i + λ2rank Declustering,u,i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Method</head><p>The user study involved 21 participants, the majority of which are current university students. This included a mix of under/post graduates and men/women between the ages of 18-27, of varying nationalities. Each participant was asked to name six pre-2008 artists that represented his/her music tastes, which were used as "seed" histories for recommendation. Volunteers suggested a very wide range of artists, across many musical genres. Users were then presented with two (unlabelled)Top-20 recommendation lists, generated by Basic Auralist and Full Auralist respectively. The lists were presented in a randomly determined order for each participant.</p><p>Users were instructed to listen to at least two 30-second song samples from each unknown artist and to fill in an accompanying survey <ref type="foot" target="#foot_2">4</ref> . Survey questions assess individually for each recommendation how enjoyable (Dislike the song... Will definitely listen again), serendipitous (Exactly what I listen to normally... Something I would never have listened to otherwise) and novel an artist is. The former two are assessed using 5-point Likert scales, whereas novelty is multiple choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">User Ratings</head><p>For each user, we compute the average enjoyment and serendipity ratings given to the artists in each list. The results are summarised in Table <ref type="table" target="#tab_3">3</ref> and show that there is a substantial difference in scores given to Basic Auralist and    Full Auralist. Compared to the basic accuracy-focused system, Full Auralist manages to score much higher in terms of Serendipity (+0.88), but sacrifices a proportion of average Enjoyment (-0.39) in doing so. A plot of the difference between these two variables can be seen in Figure <ref type="figure" target="#fig_3">3(a)</ref>. Whilst the variance of reported results may appear high, we recall that the study was conducted as a repeated measures experiment. Therefore, we test the significance of a findings using a one-tailed pairwise t-test. Our tests show that Full Auralist does indeed exhibit greater serendipity (p = 0.00002) and reduced accuracy (p = 0.004) compared to Basic Auralist.</p><p>In addition to raw serendipity/enjoyment scores, we also measure the average number of Useful, Serendipitous and Familiar recommendations issued to each user by the recommenders. We classify as Useful any recommendation that is not "Already Known" to the user, and is rated a 4 or 5 in enjoyment ("Already Known" recommendations with 4/5 in enjoyment are instead classified as Familiar recommendations). Serendipitous recommendations are those Useful recommendations that satisfy the additional requirement of being rated a 4 or 5 in serendipity. Useful items represent successful recommendations made to the user, whilst Serendipitous items detail how many managed to both satisfy the user and expand his/her tastes at the same time. Familiar items represent the "trust-building" items described in Swearingen <ref type="bibr" target="#b23">[23]</ref> that do not increase utility but improve user satisfaction with the system.</p><p>Full Auralist is shown to improve significantly on the basic version in terms of the number of Useful and Serendipitous recommendations, with t-test confidence values of p &lt; 0.001. Indeed, Full Auralist produces on average double the number of Useful and Serendipitous recommendations compared to Basic Auralist, with the proportion of Serendipitous artists within the set of Useful artist being higher as well (71% compared to 62%). Despite this, Full Auralist still manages to produce a substantial number of Familiar recommendations (7.43). The overall novelty of Full Auralist's recommendations is vastly superior -Figure <ref type="figure" target="#fig_3">3</ref>(b) shows that the system reduces the number of "Already Known" artists in recommendation lists by an absolute percentage of over 25%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">User Satisfaction</head><p>Quantitative analysis of survey results have shown that, whilst featuring a reduction in perceived Enjoyment, Full  In analysing these and other comments, we see two broad consensuses amongst the opinions of participants. A majority(12) of users prefer Full Auralist, appreciating the novelty and serendipity of the recommendations made. A substantial minority(7), however, prefer the baseline system due to its comparatively better modelling of their own tastes. Two gave neutral preferences. Whether a user falls into the first or second camp may well depend on three main factors -the user's prior convictions, emotional state, and social context, as recent work has suggested <ref type="bibr" target="#b2">[2]</ref>.</p><p>The dichotomy in preference seems to suggest that an adaptive recommendation system, where users can individually tune the level of "wildness" in recommendations, may find success. This could be offered as a series of recommendation lists, or perhaps be controlled by a sliding scale. In both cases, the hybrid model of recommendation would be particularly effective, as different levels of serendipity can be implemented simply by adjusting the interpolation parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">DISCUSSION</head><p>Our user study shows that Full Auralist produces significantly more serendipitous recommendations at the cost of some accuracy. We also show that, despite the reduced accuracy, a large number of participants expressed greater satisfaction with Full Auralist's recommendations. These conclusions are consistent with previous user studies <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b19">19]</ref>. In particular, we support Ziegler <ref type="bibr" target="#b29">[29]</ref> and Ratner <ref type="bibr" target="#b19">[19]</ref>'s findings that users are willing to sacrifice some amount of accuracy for improved novelty/diversity/serendipity performance, and that such systems are more satisfying overall. Qualitative comments seem to indicate that serendipity is usually, but not consistently, a positive contributor to this.</p><p>The nature of this experiment also demonstrates that Auralist functions well as a practical recommender, even with the "cold-start problem" of limited initial history. It is likely that much of the results variance comes from users' choice of initial artists, with some users suggesting a wider range of genres. Additional history data, perhaps pulled from a Last.fm profile, would allow us to better model a user's preferences and thus generate both more accurate and more serendipitous items.</p><p>Perhaps our most interesting discovery is that novelty, diversity and serendipity can be improved simultaneously, without any apparent trade-off between the three qualities. One may argue that this is because all three benefit from a departure from pure accuracy -all three qualities, though different, represent facets of a notion of "discovery" that diametrically oppose the notion of "familiarity" that accuracy represents. This does not mean individual qualities cannot be emphasised, however -hybridising a popularity-sorted ranking list will primarily improve novelty, whereas a topic diversification method (such as Ziegler's <ref type="bibr" target="#b29">[29]</ref>) will mostly improve diversity.</p><p>Our algorithms represents a direct attempt at countering what appears to be an increasing trend by websites and social media to filter what people see -recommending only "safe" items by clustering like-minded users <ref type="bibr" target="#b17">[17]</ref>. This behaviour is concerning because it prevents established ideas and norms from being challenged, fostering partisanship and impeding mutual understanding. We hope that even as algorithms are becoming more accurate, additional consideration is given to ensuring this accuracy is also used to introduce users to new content. Despite being designed for music recommendation, Auralist has the potential to be adapted for a great many other fields; practically, the Declustering algorithm could be readily applied to many existing item-based recommendation algorithms (with domain-dependent similarity metrics). By mapping out a user's preference space and deliberately trying to expand it, one could effectively promote personalised exploration balanced with satisfaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>We introduced Auralist as a novel recommendation framework that generates diverse, novel and serendipitous recommendations, at a slight cost to accuracy. To aid quantitative analysis, we described a series of metrics designed to assess both accuracy and the three additional qualities of diversity, novelty and serendipity.</p><p>We further presented two novel serendipity-enhancing techniques that can be combined with existing ranking methods through "hybridisation". Both Community-Aware Auralist and the Bubble-Aware Auralist prove to effectively boost novelty, diversity and serendipity scores, with the latter offering a better trade-off with regards to accuracy.</p><p>Through a user study on the Full Auralist recommender employing all three techniques, we conclusively show that our methods are able to produce more serendipitous recommendations. In addition, despite a noted decrease in the average enjoyment of artists, we show that our serendipityenhancing techniques improve overall user satisfaction.</p><p>We believe our findings are valuable for any kind of consumerfacing recommendation system, where a user's previous history may increasingly constrain their recommendations. Our techniques offer a simple and well-grounded way to diffuse the effects of the so-called "filter bubble".</p><p>Although we investigate only two serendipity-enhancing methods here, additional techniques can easily be introduced to achieve other performance goals. Of particular interest then would be a framework that allows explicit user feedback to shape the algorithm interpolation for individual users, allowing the system to adapt to the adventurousness and mood of different personalities. This could be integrated into a system that maintains serendipity over time, perhaps by cycling through genres or recommendation flavours. Allowing users to direct their own musical growth (through interactive questions or target genres) may also be a way of increasing user satisfaction and promoting musical diversity. Finally, we suggest that a consistent and validated set of performance metrics would greatly aid future work in recommender balance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Accuracy performance of Community-Aware Auralist and Bubble-Aware Auralist as the contribution λ of the corresponding serendipity-enhancing technique increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Diversity, novelty, and serendipity performance of Community-Aware Auralist and Bubble-Aware Auralist as the contribution λ of the corresponding serendipity-enhancing technique increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Serendipity and Enjoyment ratings (b) Fraction of novel recommendations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results for user satisfaction. (a) Serendipity and Enjoyment user ratings for Basic Auralist and Full Auralist on a 1-5 Likert scale. (b) Fraction of recommended artists that are "Previously Known", "Heard of, but not listened to" and "Completely Unknown" for Basic Auralist and Full Auralist.</figDesc><graphic coords="9,294.33,55.42,168.13,102.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Symbols.</figDesc><table><row><cell>S</cell><cell cols="2">Set of all users</cell></row><row><cell>P</cell><cell cols="2">Preference matrix, where P i,u is the preference</cell></row><row><cell></cell><cell cols="2">given by user u for item i (with our boolean</cell></row><row><cell></cell><cell cols="2">preference system, P i,u = 1 if the item is pre-</cell></row><row><cell></cell><cell cols="2">ferred by the user, and 0 otherwise)</cell></row><row><cell>R</cell><cell cols="2">Top-N function, where Ru,n gives the top n</cell></row><row><cell></cell><cell cols="2">recommended items for user u</cell></row><row><cell>N</cell><cell cols="2">Set of all items</cell></row><row><cell>Wu</cell><cell cols="2">Withheld item history of user u (set not used</cell></row><row><cell></cell><cell cols="2">for training)</cell></row><row><cell>Hu</cell><cell cols="2">Non-withheld item history of user u</cell></row><row><cell cols="3">pop i Fraction of (all) preferences directed at item i</cell></row><row><cell>T</cell><cell cols="2">Set of LDA topics (the number of topics is</cell></row><row><cell></cell><cell>200).</cell></row><row><cell>L</cell><cell cols="2">LDA item-topic matrix, where L i,t represents</cell></row><row><cell></cell><cell cols="2">the composition proportion assigned to topic t</cell></row><row><cell></cell><cell cols="2">for item i</cell></row><row><cell>C i</cell><cell cols="2">Number of artist i's unique listeners</cell></row><row><cell cols="2">rankj,u =</cell><cell>Index of item j in ordered list for u |N |</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance results for Basic Auralist, the state-of-the-art Implicit SVD, and Full Auralist.</figDesc><table><row><cell></cell><cell>Rank</cell><cell cols="2">T op-20 Recall Intra-List Similarity</cell><cell>N ovelty</cell><cell>U nserendipity</cell></row><row><cell>Basic Auralist</cell><cell>0.019 ±0.0004</cell><cell>0.157 ±0.004</cell><cell>14.4 ±0.2</cell><cell>11.8 ±0.06</cell><cell>0.060 ±0.0004</cell></row><row><cell>Implicit SVD</cell><cell>0.039 ± 0.0008</cell><cell>0.174 ±0.002</cell><cell>14.7 ±0.1</cell><cell>10.9 ±0.03</cell><cell>0.046 ±0.0002</cell></row><row><cell>Community-aware(λ=0.05)</cell><cell>0.023 ±0.02</cell><cell>0.030 ±0.0009</cell><cell>3.4 ±0.06</cell><cell>17.2 ±0.1</cell><cell>0.047 ±0.0003</cell></row><row><cell>Bubble-aware(λ=0.2)</cell><cell>0.021 ±0.0002</cell><cell>0.029 ±0.0006</cell><cell>3.4 ±0.05</cell><cell>14.2 ±0.1</cell><cell>0.035 ±0.0002</cell></row><row><cell>Full Auralist</cell><cell>0.025</cell><cell>0.008</cell><cell>1.54</cell><cell>17.3</cell><cell>0.039</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Summary of the results from our user study. Values in brackets are standard deviations.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>http://www.last.fm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>http://www.dtic.upf.edu/~ocelma/ MusicRecommendationDataset/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>http://tinyurl.com/ycz20</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was in part funded by RCUK through the Horizon Digital Economy Research grant (EP/G065802/1). We also thank Òscar Celma for making the dataset publicly available, Stephen Clark for his support, and Toby Moncaster and Jon Crowcroft for their comments. We finally thank the anonymous reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards more diverse recommendations: Item re-ranking methods for recommender systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">O</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Information Technologies and Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Why individuals seek diverse opinions (or why they don&apos;t)</title>
		<author>
			<persName><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Quercia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crowcroft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>This paper won&apos;t change your mind, but. In Technical Report of the University of Cambridge</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Joural of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">From hits to niches?: or how popular artists can bias music recommendation and discovery</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM NETFLIX</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A new approach to evaluating novel recommendations</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM RecSys</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Easley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
		<title level="m">Networks, Crowds, and Markets -Reasoning About a Highly Connected World</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Finding scientific topics</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evaluating collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions of Information Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Latent semantic models for collaborative filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions of Information Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Collaborative filtering for implicit feedback datasets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Eighth IEEE International Conference on Data Mining</title>
		<meeting>the 2008 Eighth IEEE International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimizing multiple objectives in collaborative filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jambor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM RecSys</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Music recommendation and the long tail</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bosteels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WOMRAD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Amazon.com recommendations: Item-to-item collaborative filtering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>York</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>IEEE Internet Computing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Mallet: A machine learning for language toolkit</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Being accurate is not enough: how accuracy metrics have hurt recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CHI EA</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Metrics for evaluating the serendipity of recommendation lists</title>
		<author>
			<persName><forename type="first">T</forename><surname>Murakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Orihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSAI</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The Filter Bubble: What the Internet Is Hiding from You</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pariser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Penguin Group USA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A user-centric evaluation framework of recommender systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UCERSTI Workshop, ACM RecSys</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Choosing less-preferred experiences for the sake of variety</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Consumer Research</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM WWW</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recommender systems in e-commerce</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM EC</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A survey of collaborative filtering techniques</title>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Beyond Algorithms: An HCI Perspective on Recommender Systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Swearingen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Proposal and evaluation of serendipitous recommendation method using general unexpectedness</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Takayuki Akiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanizaki</surname></persName>
		</author>
		<editor>PRSAT</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Rank and relevance in novelty and diversity metrics for recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>ACM RecSys</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Collective dynamics of &apos;small-world&apos; networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Solving the apparent diversity-accuracy dilemma of recommender systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kuscik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Medo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Wakeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Taxonomy-driven computation of product recommendations</title>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-T</forename><surname>Lars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM CIKM</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improving recommendation lists through topic diversification</title>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM WWW</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
