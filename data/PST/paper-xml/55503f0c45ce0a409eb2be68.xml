<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A hybrid fireworks optimization method with differential evolution operators</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yu-Jun</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Zhejiang University of Technology</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin-Li</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Zhejiang University of Technology</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Hai-Feng</forename><surname>Ling</surname></persName>
							<email>hf.ling@ymail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mechanical Engineering</orgName>
								<orgName type="institution">PLA University of Science &amp; Technology</orgName>
								<address>
									<postCode>210007</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sheng-Yong</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Zhejiang University of Technology</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A hybrid fireworks optimization method with differential evolution operators</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">47C9099F83A4A47FDAD3B2AB71FF28D2</idno>
					<idno type="DOI">10.1016/j.neucom.2012.08.075i</idno>
					<note type="submission">Received 7 April 2012 Received in revised form 26 August 2012 Accepted 27 August 2012</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Fireworks algorithm (FA) Differential evolution (DE) Global optimization Hybrid</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fireworks algorithm (FA) is a relatively new swarm-based metaheuristic for global optimization. The algorithm is inspired by the phenomenon of fireworks display and has a promising performance on a number of benchmark functions. However, in the sense of swarm intelligence, the individuals including fireworks and sparks are not well-informed by the whole swarm. In this paper we develop an improved version of the FA by combining with differential evolution (DE) operators: mutation, crossover, and selection. At each iteration of the algorithm, most of the newly generated solutions are updated under the guidance of two different vectors that are randomly selected from highly ranked solutions, which increases the information sharing among the individual solutions to a great extent. Experimental results show that the DE operators can improve diversity and avoid prematurity effectively, and the hybrid method outperforms both the FA and the DE on the selected benchmark functions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The complexity of real-world engineering optimization problems gives rise to various kinds of metaheuristics that use stochastic techniques to effectively explore the search space for a global optimum. In particular, metaheuristics based on swarm intelligence (e.g., <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>), which simulates a population of simple individuals evolving their solutions by interacting with one another and with the environment, have shown promising performance on many difficult problems and have become a very active research area in recent years.</p><p>Fireworks algorithm (FA) is a relatively new global optimization method originally proposed by Tan and Zhu <ref type="bibr" target="#b6">[7]</ref>. Inspired by the phenomenon of fireworks explosion, the algorithm selects in the search space a certain number of locations, each for exploding a firework to generate a set of sparks. The fireworks and sparks of high quality are chosen as the locations for the next generation's fireworks, and the evolutionary process continues until a desired optimum is obtained, or the stopping criterion is met. Numerical experiments on a number of benchmark functions show that the FA can converge to a global optimum with a much smaller number of function evaluations than that of typical particle swarm optimization (PSO) algorithms including <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>In the standard FA, the convergence speed is accelerated by "good" fireworks that generate more sparks within smaller explosion areas, and the search diversity is improved by "bad" fireworks that generate fewer sparks within larger explosion areas. However, to some extent, such a diversification mechanism is not very flexible and, in particular, it does not utilize more information about other quality solutions in the swarm. That is, in the sense of swarm intelligence, the individuals (fireworks and sparks) are not well-informed by the whole swarm.</p><p>Inspired by this observation, we develop an improved fireworks optimization method by combining with differential evolution (DE) operators: mutation, crossover, and selection <ref type="bibr" target="#b8">[9]</ref>. At each iteration of the algorithm, these operators are applied to guide the generation of new solutions, which improves the diversity of the swarm and avoids being trapped in local optima too early. Experiments on selected benchmark functions show that the well-informed fireworks and sparks can improve the performance of the FA to a great extent.</p><p>The remainder of this paper is structured as follows: Section 2 briefly describes the FA algorithm and the DE algorithm, Section 3 proposes the framework of our hybrid FA method, Section 4 presents the computational experiments, Section 5 analyzes and discusses the experimental results, and Section 6 makes the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Backgrounds</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Fireworks algorithm</head><p>The FA proposed in <ref type="bibr" target="#b6">[7]</ref> is a global optimization algorithm simulating the explosion process of fireworks, where an explosion can be viewed as a search in the local space around the location of a firework. In the original FA, the number of sparks and the amplitude of explosion for each firework x i are respectively defined as follows:</p><formula xml:id="formula_0">s i ¼ m Á f max À f ðx i Þþϵ ∑ p j ¼ 1 ðf max À f ðx j ÞÞ þ ϵ<label>ð1Þ</label></formula><formula xml:id="formula_1">A i ¼ Â Á f ðx i ÞÀf min þ ϵ ∑ p j ¼ 1 ðf ðx j ÞÀf min Þþϵ<label>ð2Þ</label></formula><p>where m is a parameter for controlling the total number of sparks generated by the fireworks, Â is the maximum explosion amplitude, p is the size of the swarm, f max and f min are respectively the maximum and minimum objective values among the p fireworks, and ϵ is a small constant to avoid zero-division-error.</p><p>To avoid overwhelming effects of splendid fireworks, lower and upper bounds are defined for s i such that</p><formula xml:id="formula_2">s i ¼ s min if s i o s min s max else if s i 4 s max s i else 8 &gt; &lt; &gt; :<label>ð3Þ</label></formula><p>For a D-dimensional problem, the location of each spark x j generated by x i can be obtained by randomly setting z directions ðz o DÞ, and for each dimension k setting the component x j k based on x i k ð1 rj r s i ; 1 r k r zÞ. There are two ways for setting x j k .</p><p>For most sparks, a displacement h k ¼ A i Á randðÀ1; 1Þ is added to x i k ,i.e.,</p><formula xml:id="formula_3">x k j ¼ x k i þ A i Á randðÀ1; 1Þ ð<label>4Þ</label></formula><p>To keep the diversity, for a few specific sparks, an explosion coefficient based on Gaussian distribution is applied to x i k such that</p><formula xml:id="formula_4">x k j ¼ x k i Á Gaussianð1; 1Þ ð<label>5Þ</label></formula><p>In both the ways, if the new location falls out of the search space, it is mapped to the search space as follows:</p><formula xml:id="formula_5">x k j ¼ x k min þjx k j j%ðx k max Àx k min Þ ð<label>6Þ</label></formula><p>where % denotes the modulo operator for floating-point numbers, as defined in most computer languages.</p><p>At each iteration of the FA, among all the current sparks and fireworks, the best location is always selected as a firework of the next generation. After that, p À 1 fireworks are selected with probabilities proportional to their distance to other locations. The general framework of the FA is described in Algorithm 1.</p><p>In the FA, sparks suffer the power of explosion and thus move along z directions simultaneously, which makes the algorithm converge very fast. Two types of spark generation methods and the specific selection process for locations also endue the FA with the capability of avoiding premature convergence. The advantages of the FA over the standard PSO and improved PSO algorithms have also been demonstrated by experiments on a number of benchmark functions <ref type="bibr" target="#b6">[7]</ref>.</p><p>Algorithm 1. The standard fireworks algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Difference evolution</head><p>Introduced by Storn and Price <ref type="bibr" target="#b8">[9]</ref>, DE is an efficient evolutionary algorithm that simultaneously evolves a population of solution vectors. But unlike the genetic algorithm (GA) <ref type="bibr" target="#b9">[10]</ref>, DE uses floating-point vectors and does not employ some probability density functions for vector reproduction. Specifically, DE generates a mutant vector v i for each vector x i in the population by adding the weighted difference between two randomly selected vectors to a third one:</p><formula xml:id="formula_6">v i ¼ x r 1 þ γðx r 2 À x r 3 Þ ð 7Þ</formula><p>where random indexes r 1 ; r 2 ; r 3 A f1; 2; …; pg and coefficient γ 4 0.</p><p>A trial vector u i is then generated by using the crossover operator which mixes the components of the mutant vector and the original one, where each jth component of u i is determined as follows:</p><formula xml:id="formula_7">u j i ¼ v j i if randð0; 1Þ oc r or j ¼ rðiÞ x j i else 8 &lt; :<label>ð8Þ</label></formula><p>where c r is the crossover probability ranged in ð0; 1Þ and r(i) is a random integer within ð0; p for each i.</p><p>In the last step of each iteration, the selection operator chooses the better one for the next generation by comparing u i with x i :</p><formula xml:id="formula_8">x i ¼ u i if f ðu i Þ r f ðx i Þ x i else (<label>ð9Þ</label></formula><p>By computing the difference between two individuals randomly chosen from the population, the DE is actually estimating the gradient in that zone (rather than in a point). The mutation operator makes the DE capable of self-adapting both the step sizes and the step direction, and local criterion of the selection operator is also efficient and fast <ref type="bibr" target="#b10">[11]</ref>. Generally, these features make the DE converge faster and with more certainty than many other heuristic methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The hybrid fireworks optimization method</head><p>For a D-dimensional optimization, the fitness value of a solution is determined by values of all components, and a solution that has discovered the region corresponding to the global optimum in some dimensions may have a low fitness value because of the poor quality in the other dimensions <ref type="bibr" target="#b11">[12]</ref>. Thus, many population-based optimization methods, including DE, comprehensive learning PSO <ref type="bibr" target="#b11">[12]</ref> and fully informed PSO <ref type="bibr" target="#b12">[13]</ref>, enable the individuals to make use of the beneficial information in the swarm more effectively to generate better quality solutions.</p><p>In the standard FA, after obtaining the set R of all fireworks and sparks, the locations for new fireworks are selected based on distance to other locations in R so as to keep diversity of the swarm. Here we introduce the DE operators to the FA to improve the diversification strategy.</p><p>In the hybrid algorithm, after obtaining the set R of locations, we first sort the locations in decreasing order of fitness, and create a set S of p candidate locations which are randomly selected from the top 2p locations in R. Afterwards, we apply the standard DE process to the new solution set S: for each vector x i A S, generate a mutant vector v i , mix the components of x i and v i to obtain a trial vector u i , and replace x i with u i in case that u i is better, as shown in Eqs. ( <ref type="formula">7</ref>)- <ref type="bibr" target="#b8">(9)</ref>.</p><p>After the DE process, we check that whether the new best result solution x n 1 A S is worse than the first (best) one x n A R. If it is so, we replace a randomly selected solution x A S with x n , and thus make the best solution of the swarm will never degrade in the next generation.</p><p>In detail, the following procedure is used to replace the lines 20 and 21 in Algorithm 1:</p><p>1. Let S be the empty set; 2. Sort R in decreasing order of vector fitness, and let x n be the top one solution in R; 3. If jRj 42p, truncate the length of R to 2p, i.e., maintain the top 2p locations in R; 4. Randomly select p locations from R and add them to S, where the selection probability of each x A R is f ðxÞ=∑ z A R f ðzÞ; 5. Apply the DE mutation, crossover, and selection operators to each solution in S; For candidate fireworks in S, each of them has an opportunity to be informed by existing high quality vectors at each dimension, in terms of the DE mutation and crossover operations.</p><formula xml:id="formula_9">6. Let x n 1 be the best solution in R; if f ðx n 1 Þ o f ðx n Þ,</formula><p>In particular, the DE mutation operator makes the difference of two random vectors act as a search direction for the third one <ref type="bibr" target="#b13">[14]</ref>; In comparison with large-amplitude explosion and distance-based selection used in the standard FA, the mutation operation is more effective in improving the probability of obtaining the global optimum, whilst requiring less computational cost.</p><p>Since the DE operators are introduced into the algorithm for improving the diversity of solutions, the values of control parameters including m, Â, s max and s min can be decreased, which will compensate the computational cost of DE operations to a certain extent. According to our analysis, in most conditions, the specific ("bad") spark generation procedure (lines 14-18 in Algorithm 1) can also contribute to the result solution quality of the hybrid algorithm, but its contribution is much less than that in the standard FA. Thus, the specific procedure can either be remained or discarded in the hybrid algorithm; if it is remained, the parameter values mentioned above can be further decreased to save computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Computational experiments</head><p>We choose a set of well-known test functions as benchmark problems, the definitions of which are listed in the Appendix. All the functions are tested on 30, 50, and 100 dimensions. The performance of the hybrid algorithm is evaluated in comparison with the standard FA and standard DE, where the population sizes are all set to 5. The parameters of the DE are set as those in Ref. <ref type="bibr" target="#b8">[9]</ref>. For the FA, we set m ¼50, s min ¼ 2, s max ¼ 40, m ¼ 5, and</p><formula xml:id="formula_10">Â ¼ min 1 r k r D ðx k max À x k min Þ=5</formula><p>(where ½x k min ; x k max is the search range of the kth dimension of the benchmark function), as suggested in Ref. <ref type="bibr" target="#b6">[7]</ref>. For the hybrid algorithm, we decrease the control parameter values such that m ¼ 25, s max ¼ 20, and Â ¼ min 1 r k r D ðx k max À x k min Þ=7. For the algorithms, the mean best and the success rate over 40 runs are used as performance measures. The maximum number of function evaluations (nfe) is set to 10,000 for 30 dimensional functions, 15,000 for 50 dimensional functions, and 20,000 for 100 dimensional functions. The search ranges, optimal points and corresponding fitness values, and required accuracies (a r ) for the benchmark functions are shown in Table <ref type="table" target="#tab_2">1</ref>. If a single run obtains a result value in the range ½ð1 Àa r Þf ðx n Þ; ð1 þ a r Þf ðx n Þ, it is considered as successful run. The a r values are set mainly as suggested in Ref. <ref type="bibr" target="#b14">[15]</ref>.</p><p>The experimental results on 30, 50, and 100 dimensional functions are summarized in Tables 2-4 respectively, and the average convergence speeds of the algorithms are illustrated in Figs. <ref type="figure" target="#fig_1">1</ref><ref type="figure" target="#fig_3">2</ref><ref type="figure" target="#fig_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussions</head><p>As we can see from the results of the computational experiment, for all the benchmark problems, the performance of the hybrid algorithm is better (or at least not worse) than the standard FA and DE. In the sense of required accuracy, except for the 100-D Schwefel function, the hybrid algorithm successfully achieves the global optimum for all the other functions.</p><p>For the 30-D problems, as shown in Table <ref type="table" target="#tab_3">2</ref>, the hybrid algorithm has the same mean best values as the standard FA on the Sphere, Hyper-Ellipsoid, Rastrigin, and Griewank functions, and has better performance than that of FA on Rosenbrock, Schwefel, Ackley, and Weierstrass functions. Both the hybrid algorithm and the standard FA perform better than the basic DE algorithm, and the performance advantage is more obvious on the former four functions than on the latter fours. Therefrom we can observe that:</p><p>For test problems where the FA has significant performance advantages over the DE, the introduction of DE operators at least does not degrade the performance of the hybrid algorithm.</p><p>For test problems where the performance of the DE is not far from (or may be better than) that of the FA, the introduction of DE operators contributes to the performance improvement of the hybrid algorithm to a great extent.</p><p>For the 50-D problems, the hybrid algorithm also has better mean best value than that of FA on the Griewank function, as shown in Table <ref type="table" target="#tab_4">3</ref>. For the 100-D problems, the hybrid algorithm also has better mean best values than that of FA on the Sphere and Hyper-Ellipsoid functions, as shown in Table <ref type="table" target="#tab_5">4</ref>. For the remaining test functions, the advantage of the hybrid algorithm over the FA is also more obvious on 100-D problems than on 50-D and than on 30-D problems.</p><p>From the curves presented in Figs. <ref type="figure" target="#fig_1">1</ref><ref type="figure" target="#fig_3">2</ref><ref type="figure" target="#fig_4">3</ref>, we can obviously see that the convergence speed of the hybrid algorithm is much faster than the FA and DE, and the difference becomes more significant with the increase of the problem dimension. This also demonstrate that our hybrid algorithm is scalable and efficient to highdimensional problems.</p><p>The test result obtained on the Griewank function show that our algorithm achieves more little mean best values on highdimensional problems, since this problem is known to become easier as the number of dimensions increases <ref type="bibr" target="#b15">[16]</ref>.</p><p>The Schwefel function is a difficult optimization function which is easy to trap algorithms in local optima. In comparison with the In general, the overall performance of FA is better than that of DE, and the hybrid FA outperforms both the standard FA and the DE on the test functions. Furthermore, from the experimental results we can observe that the comparative algorithms achieve similar ranking on most test functions. The convergence curves on the 30-D functions are also similar to those on the 50-D functions, but the shapes of curves on the 100-D functions are somewhat different. An interesting observation is that for test problems in which the convergence curves of the FA and DE are close (e.g., Fig. <ref type="figure" target="#fig_1">1</ref>  to FA. This indicates that the contribution of DE operators in our algorithm is more substantial for problems in which the standard FA and DE exhibit more different behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>FA has been shown to be one of the best performing algorithms for global optimization problems. The paper improves the standard FA by introducing DE operators for increasing the information sharing among the fireworks and sparks and diversifying the search process. Experimental results show that the hybrid method performs better than both the FA and the DE. We believe such an improvement can bring significant advantages to practical engineering applications. Our ongoing work includes extending the FA for multiobjective optimization and comparing it with other swarm-based multiobjective heuristics <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. We will also study more relationships among the different swarm-based </p><formula xml:id="formula_11">f 1 ðxÞ ¼ ∑ D i ¼ 1 x 2 i 2.</formula><p>Hyper-Ellipsoid function:</p><formula xml:id="formula_12">f 2 ðxÞ ¼ ∑ D i ¼ 1 i 2 Á x 2 i 3. Rosenbrock's function: f 3 ðxÞ ¼ ∑ D À 1 i ¼ 2 ð100ðx 2 i Àx i À 1 Þ 2 þðx i À1Þ 2 Þ</formula><p>4. Schwefel's function:</p><formula xml:id="formula_13">f 4 ðxÞ ¼ 418:9829 Â D À ∑ D i ¼ 1</formula><p>x i sin ðjx i j 1=2 Þ 5. Rastrigin's function:</p><formula xml:id="formula_14">f 5 ðxÞ ¼ ∑ D i ¼ 1 ðx 2 i À 10 cos ð2πx i<label>Þþ10Þ</label></formula><p>6. Griewank's function:</p><formula xml:id="formula_15">f 6 ðxÞ ¼ ∑ D i ¼ 1 x 2 i 4000 À ∏ D i ¼ 1 cos x i ffi ffi i p þ<label>1</label></formula><p>7. Ackley's function:</p><formula xml:id="formula_16">f 7 ðxÞ ¼ À20 exp À 0:2 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 1 D ∑ D i ¼ 1 x 2 i s ! À exp 1 D ∑ D i ¼ 1 cos ð2πx i Þ ! þ 20 þ e 8.</formula><p>Weierstrass function:</p><formula xml:id="formula_17">f 8 ðxÞ ¼ ∑ D i ¼ 1 ∑ kmax k ¼ 0 ½a k cos ð2πb k ðx i þ 0:5ÞÞ ! À D ∑ kmax k ¼ 0 ða k cos ð2πb k Á 0:5ÞÞ</formula><p>where a ¼0.5, b¼3, k max ¼ 20. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>randomly select a solution x A S and replace it with x n . Generally speaking, the above DE procedure helps to improve the algorithm in the following aspects:For high quality (top 2p) vectors in R, each of them has an opportunity to influence the new fireworks for the next generation, in terms of the roulette-wheel selection and DE selection operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The averaged convergence curves of the 30-D test problems. (a) Sphere, (b) Hyper-Ellipsoid, (c) Rosenbrock, (d) Schwefel, (e) Rastrigin, (f) Griewank, (g) Ackley and (h) Weierstrass.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a), (b), and (d), Fig. 2(d) and (d), and Fig. 3(b) and (c)), the convergence speed improvement of the hybrid algorithm is also limited. However, for test problems in which FA converges much faster than DE (e.g., Fig. 1(e) and (g), Fig. 2(e), (g), and (h), and Fig. 3(e)-(g)), the hybrid algorithm gains more considerable convergence speed improvement</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The averaged convergence curves of the 50-D test problems. (a) Sphere, (b) Hyper-Ellipsoid, (c) Rosenbrock, (d) Schwefel, (e) Rastrigin, (f) Griewank, (g) Ackley and (h) Weierstrass.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The averaged convergence curves of the 100-D test problems. (a) Sphere, (b) Hyper-Ellipsoid, (c) Rosenbrock, (d) Schwefel, (e) Rastrigin, (f) Griewank, (g) Ackley and (h) Weierstrass.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1 set the algorithm parameters p, s min , s max , Â, and m; 2 randomly initialize a swarm S of p fireworks; 3 while (stop criteria is not met) do</figDesc><table /><note><p>4 let R be the empty set of sparks; 5 foreach firework x i A S do 6 calculate s i for x i according to Eqs. (1) and (3); 7 calculate A i for x i according to Eq. (2); 8 for j¼ 1 to s i do 9 yield a spark x j ; 10 let z ¼ roundðD Á randð0; 1ÞÞ; 11 for k ¼1 to z do set x j k according to Eqs. (4) and (6); 12 R ¼ R [ fx j g; 13 randomly select a set P of m fireworks from S; 14 foreach firework x i A P do 15 yield a spark x j ; 16 let z ¼ roundðD Á randð0; 1ÞÞ; 17 for k ¼1 to z do set x j k according to Eqs. (5) and (6); 18 R ¼ R [ fx j g; 19 R ¼ R [ S; 20 let gbest be the best location among R, and set S ¼ fgbestg; 21 Add to S other p À 1 locations selected from R based on distance probabilities; 22 end</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Detailed information of the benchmark functions used in the paper.</figDesc><table><row><cell>Function</cell><cell>Search range</cell><cell>x n</cell><cell>f ðx n Þ</cell><cell>a r</cell></row><row><cell>Sphere</cell><cell>½À100; 100 D</cell><cell>[0,0,…,0]</cell><cell>0</cell><cell>0.000001</cell></row><row><cell>Hyper-Ellipsoid</cell><cell>½À10; 10</cell><cell>[0,0,…,0]</cell><cell>0</cell><cell>0.000001</cell></row><row><cell>Rosenbrock</cell><cell>½À10; 10 D</cell><cell>[1,1,…,1]</cell><cell>0</cell><cell>0.01</cell></row><row><cell>Schwefel</cell><cell>½À500; 500 D</cell><cell>[420.96,420.96,</cell><cell>0</cell><cell>0.01</cell></row><row><cell></cell><cell></cell><cell>…,420.96]</cell><cell></cell><cell></cell></row><row><cell>Rastrigin</cell><cell>½À5:12; 5:12 D</cell><cell>[0,0,…,0]</cell><cell>0</cell><cell>0.01</cell></row><row><cell>Griewank</cell><cell>½À600; 600 D</cell><cell>[0,0,…,0]</cell><cell>0</cell><cell>0.01</cell></row><row><cell>Ackley</cell><cell>½À32:768; 32:768 D</cell><cell>[0,0,…,0]</cell><cell>0</cell><cell>0.000001</cell></row><row><cell>Weierstrass</cell><cell>½À0:5; 0:5</cell><cell>[0,0,…,0]</cell><cell>0</cell><cell>0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>The experimental results on 30-D benchmark problems.</figDesc><table><row><cell>Function</cell><cell>Mean best</cell><cell></cell><cell></cell><cell cols="3">Success rate (%)</cell></row><row><cell></cell><cell>FA</cell><cell>DE</cell><cell>Hybrid</cell><cell>FA</cell><cell>DE</cell><cell>Hybrid</cell></row><row><cell>Sphere</cell><cell>0</cell><cell cols="2">1.077EÀ 39 0</cell><cell cols="3">100 100 100</cell></row><row><cell cols="2">Hyper-Ellipsoid 0</cell><cell cols="2">6.639E À 22 0</cell><cell cols="3">100 100 100</cell></row><row><cell>Rosenbrock</cell><cell cols="3">4.209E À 02 9.731E À 01 8.966E À 04</cell><cell>80</cell><cell cols="2">35 100</cell></row><row><cell>Schwefel</cell><cell cols="3">4.827E þ 00 1.133Eþ 01 4.699E À 01</cell><cell>10</cell><cell>0</cell><cell>32.5</cell></row><row><cell>Rastrigin</cell><cell>0</cell><cell cols="2">1.208E À 07 0</cell><cell cols="3">100 100 100</cell></row><row><cell>Griewank</cell><cell cols="3">4.380E À 08 5.288E À 03 0</cell><cell>100</cell><cell cols="2">75 100</cell></row><row><cell>Ackley</cell><cell cols="6">4.441E À 16 2.565E À 15 4.441E À 16 100 100 100</cell></row><row><cell>Weierstrass</cell><cell cols="6">3.015E À 08 3.482E À 04 8.940E À 10 100 100 100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>The experimental results on 50-D benchmark problems.</figDesc><table><row><cell>Function</cell><cell>Mean best</cell><cell></cell><cell></cell><cell cols="3">Success rate (%)</cell></row><row><cell></cell><cell>FA</cell><cell>DE</cell><cell>Hybrid</cell><cell>FA</cell><cell>DE</cell><cell>Hybrid</cell></row><row><cell>Sphere</cell><cell>0</cell><cell cols="2">3.383E À 36 0</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell cols="2">Hyper-Ellipsoid 0</cell><cell cols="2">1.208E À 20 0</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Rosenbrock</cell><cell cols="3">3.080E À 01 1.115E þ 00 1.750E À 03</cell><cell>57.5</cell><cell>5</cell><cell>85</cell></row><row><cell>Schwefel</cell><cell cols="3">9.245Eþ 00 1.293E þ 01 6.883E À 01</cell><cell>0</cell><cell>0</cell><cell>25</cell></row><row><cell>Rastrigin</cell><cell>0</cell><cell cols="2">4.244E À 07 0</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Griewank</cell><cell cols="3">1.541E À 11 2.480E À 03 0</cell><cell>100</cell><cell>80</cell><cell>100</cell></row><row><cell>Ackley</cell><cell cols="4">4.441E À 16 4.752E À 13 4.441E À 16 100</cell><cell>100</cell><cell>100</cell></row><row><cell>Weierstrass</cell><cell cols="4">2.333E À 06 6.125E À 03 9.212E À 08 100</cell><cell cols="2">82.5 100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>The experimental results on 100-D benchmark problems.</figDesc><table><row><cell>Function</cell><cell>Mean best</cell><cell></cell><cell></cell><cell cols="3">Success rate (%)</cell></row><row><cell></cell><cell>FA</cell><cell>DE</cell><cell>Hybrid</cell><cell>FA</cell><cell>DE</cell><cell>Hybrid</cell></row><row><cell>Sphere</cell><cell cols="3">7.474E À 187 1.627EÀ 26 0</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell cols="4">Hyper-Ellipsoid 4.571E À 23 7.827EÀ 11 0</cell><cell>100</cell><cell>95</cell><cell>100</cell></row><row><cell>Rosenbrock</cell><cell cols="3">3.044E þ 01 4.036E þ00 5.270E À 02</cell><cell>0</cell><cell>0</cell><cell>40</cell></row><row><cell>Schwefel</cell><cell cols="3">2.062E þ 01 3.430E þ01 4.100E þ 0 0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Rastrigin</cell><cell>0</cell><cell cols="2">3.526E À 06 0</cell><cell>100</cell><cell cols="2">92.5 100</cell></row><row><cell>Griewank</cell><cell cols="3">1.228E À 11 1.985E À 03 0</cell><cell>100</cell><cell>50</cell><cell>100</cell></row><row><cell>Ackley</cell><cell cols="4">4.441E À 16 8.089E À 08 4.441E À 16 100</cell><cell>70</cell><cell>100</cell></row><row><cell>Weierstrass</cell><cell cols="4">8.905E À 04 3.900E À 01 3.013E À 05 77.5</cell><cell cols="2">7.5 100</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Please cite this article as: Y.-J. Zheng, et al., A hybrid fireworks optimization method with differential evolution operators, Neurocomputing (2014), http://dx.doi.org/10.1016/j.neucom.2012.08.075i</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by Grants from National Natural Science Foundation (No. 61105073, 61103140, 61173096, 61020106009) of China. We are grateful to the anonymous reviewers of ICSI 2012 for their valuable suggestions for improving the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Neural Networks</title>
		<meeting>the IEEE International Conference on Neural Networks<address><addrLine>Perth WA, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ant system: optimization by a colony of cooperating agents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<title level="m">A New Intelligent Optimization Artificial Fish School Algorithm</title>
		<meeting><address><addrLine>Hangzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Zhejiang University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Center particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="672" to="679" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A novel search algorithm based on fish school behavior</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J A B</forename><surname>Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>De Lima Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J C C</forename><surname>Lins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I S</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Lima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Systems, Man and Cybernetics</title>
		<meeting>the IEEE International Conference on Systems, Man and Cybernetics<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="2646" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fireworks algorithm for optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-13495-1_44</idno>
		<ptr target="〈http://dx.doi.org/10.1007/978-3-642-13495-1_44〉" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Swarm Intelligence</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the 2nd International Conference on Swarm Intelligence</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6145</biblScope>
			<biblScope unit="page" from="355" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Clonal particle swarm optimization and its applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2303" to="2309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Differential evolution: a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="369" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cultured differential evolution for constrained optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Becerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Eng</title>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="page" from="4303" to="4322" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Co-evolutionary hybrid differential evolution for mixed-integer optimization problems</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="663" to="682" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A Method to Improve Standard PSO</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<idno>DRAFT MC2009-03-13</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>France Telecom R&amp;D</publisher>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating evolutionary algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Whitley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dzubera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mathias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="245" to="276" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-objective optimization using differential evolution: a survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reyes-Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud. Comput. Intell</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="173" to="196" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">GPU-based parallel multi-objective particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="125" to="141" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">His research interests include operations research and intelligent optimization algorithms, and he has published over 50 scientific papers in international journals and conferences. Xin-Li Xu is an associate professor in Zhejiang University of Technology</title>
		<author>
			<persName><forename type="first">Yu-Jun</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">She received the M.Sc. and Ph.D. degrees from Zhejiang University of Technology in 2003 and 2009 respectively. Her current research interests include optimization theory and algorithms. Hai-Feng Ling is an associate professor in PLA University of Science and Technology. She received the Ph.D. degree from Nanjing University in 2011. Her research interests include operational management and intelligent transportation systems</title>
		<imprint/>
	</monogr>
	<note>Zhejiang University of Technology. He received the Ph.D. degree from the Institute of Software, Chinese Academy of Sciences in 2010</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">He received the Ph.D. degree from the City University of Hong Kong in 2003. From 2006 to 2007, he received a fellowship from the Alexander von Humboldt Foundation of Germany and worked at the University of Hamburg</title>
		<author>
			<persName><forename type="first">Sheng-Yong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">His research interests include intelligent systems and their applications. He has published over 100 scientific papers in international journals and conferences</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008 to 2009. 2012</date>
		</imprint>
		<respStmt>
			<orgName>Zhejiang University of Technology ; University of Cambridge</orgName>
		</respStmt>
	</monogr>
	<note>he worked as a visiting professor at Imperial College</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
