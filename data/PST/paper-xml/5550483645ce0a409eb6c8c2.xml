<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EvoDroid: Segmented Evolutionary Testing of Android Apps</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Riyadh</forename><surname>Mahmood</surname></persName>
							<email>rmahmoo2@gmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nariman</forename><surname>Mirzaei</surname></persName>
							<email>nmirzaei@gmu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sam</forename><surname>Malek</surname></persName>
							<email>smalek@gmu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EvoDroid: Segmented Evolutionary Testing of Android Apps</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">19CC0962C324D083B0A1C3F45C908F4C</idno>
					<idno type="DOI">10.1145/2635868.2635896</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.2.8 [Software Engineering]: Testing and Debugging Reliability</term>
					<term>Experimentation Android</term>
					<term>Evolutionary Testing</term>
					<term>Program Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proliferation of Android devices and apps has created a demand for applicable automated software testing techniques. Prior research has primarily focused on either unit or GUI testing of Android apps, but not their end-to-end system testing in a systematic manner. We present EvoDroid, an evolutionary approach for system testing of Android apps. EvoDroid overcomes a key shortcoming of using evolutionary techniques for system testing, i.e., the inability to pass on genetic makeup of good individuals in the search. To that end, EvoDroid combines two novel techniques: (1) an Android-specific program analysis technique that identifies the segments of the code amenable to be searched independently, and (2) an evolutionary algorithm that given information of such segments performs a stepwise search for test cases reaching deep into the code. Our experiments have corroborated EvoDroid's ability to achieve significantly higher code coverage than existing Android testing tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Mobile app markets have created a fundamental shift in the way software is delivered to the consumers. The benefits of this software supply model are plenty, including the ability to rapidly and effectively deploy, maintain, and enhance software used by the consumers. By providing a medium for reaching a large consumer market at a nominal cost, this paradigm has leveled the playing field, allowing small entrepreneurs to compete head-to-head with prominent software development companies.</p><p>Platforms, such as Android, that have embraced this model of provisioning apps have seen an explosive growth in popularity. This paradigm, however, has given rise to a new set of concerns. Small organizations do not have the resources to sufficiently test their products, thereby defective apps are made available to the consumers of these markets. These defects are exploited with malicious intent compromising the integrity and availability of the apps and devices on which they are deployed. This is nowhere more evident than in Google Play, a popular Android app market, where numerous security attacks have been attributed to vulnerable apps <ref type="bibr" target="#b34">[35]</ref>. The situation is likely to exacerbate given that mobile apps are poised to become more complex and ubiquitous, as mobile computing is still in its infancy.</p><p>Automated testing of Android apps is impeded by the fact that they are built using an application development framework (ADF). ADF allows the programmers to extend the base functionality of the platform using a well-defined API. ADF also provides a container to manage the lifecycle of components comprising an app and facilitates the communication among them. As a result, unlike a traditional monolithic software system, an Android app consists of code snippets that engage one another using the ADF's sophisticated event delivery facilities. This hinders automated testing, as the app's control flow frequently interleaves with the ADF. At the same time, reliance on a common ADF provides a level of consistency in the implementation logic of apps that can be exploited for automating the test activities, as illustrated in this paper.</p><p>The state-of-practice in automated system testing of Android apps is random testing. Android Monkey <ref type="bibr" target="#b2">[3]</ref> is the industry's de facto standard that generates purely random tests. It provides a brute-force mechanism that usually achieves shallow code coverage. Several recent approaches <ref type="bibr">[18-20, 29, 32, 38]</ref> have aimed to improve Android testing practices. Most notably and closely related to our work is Dynodroid <ref type="bibr" target="#b31">[32]</ref>, which employs certain heuristics to improve the number of inputs and events necessary to reach comparable code coverage as that of Monkey.</p><p>Since prior research has not employed evolutionary testing and given that it has shown to be very effective for event driven software <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b29">[30]</ref>, we set out to develop the first evolutionary testing framework targeted at Android, called EvoDroid. Evolutionary testing is a form of search-based testing, where an individual corresponds to a test case, and a population comprised of many individuals is evolved according to certain heuristics to maximize the code coverage. The most notable contribution of EvoDroid is its ability to overcome the common shortcoming of using evolutionary techniques for system testing. Evolutionary testing techniques <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref> are typically limited to local or unit testing, as for system testing, they are not able to promote the genetic makeup of good individuals during the search.</p><p>EvoDroid overcomes this challenge by leveraging the knowledge of how Android ADF specifies and constrains the way apps can be Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.</p><p>built. It uses this platform-specific knowledge to statically analyze the app and infer a model of its behavior. The model captures <ref type="bibr" target="#b0">(1)</ref> the dependencies among the code snippets comprising the app, and (2) the entry points of the app (i.e., places in the code that the app receives external inputs). The inferred model allows the evolutionary search to determine how the individuals should be crossed over to pass on their genetic makeup to future generations. The search for test cases reaching deep into the code occurs in segments, i.e., sections of the code that can be searched independently. Since a key concern in search-based testing is the execution time of the algorithm, EvoDroid is built to run the tests in parallel on Android emulators deployed on the cloud, thus achieving several orders of magnitude improvement in execution time.</p><p>The remainder of this paper is organized as follows. Section 2 provides a background on Android. Section 3 outlines an illustrative example that is used to describe our research. Section 4 motivates the research problem using the illustrative example. Section 5 provides an overview of our approach, while Sections 6 to 8 provide the details and results. The paper concludes with a summary of the related research in Section 9 and a discussion of our future work in Section 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ANDROID BACKGROUND</head><p>The Google Android framework includes a full Linux operating system based on the ARM processor, system libraries, middleware, and a suite of pre-installed applications. It is based on the Dalvik Virtual Machine (DVM) <ref type="bibr" target="#b5">[6]</ref> for executing programs written in Java. Android also comes with an application development framework (ADF), which provides an API for application development and includes services for building GUI applications, data access, and other component types. The framework is designed to simplify the reuse and integration of components.</p><p>Android apps are built using a mandatory XML manifest file. The manifest file values are bound to the application at compile time. This file provides essential information to an Android platform for managing the life cycle of an application. Examples of the kinds of information included in a manifest file are descriptions of the app's components among other architectural and configuration properties. Components can be one of the following types: Activities, Services, Broadcast Receivers, and Content Providers. An Activity is a screen that is presented to the user and contains a set of layouts (e.g., LinearLayout that organizes items within the screen horizontally or vertically). The layouts contain GUI controls, known as view widgets (e.g., TextView for viewing text and EditText for text inputs). The layouts and its controls are typically described in a configuration XML file with each layout and control having a unique identifier. A Service is a component that runs in the background and performs long running tasks, such as playing music. Unlike an Activity, a Service does not present the user with a screen for interaction. A Content Provider manages structured data stored on the file system or database, such as contact information. A Broadcast Receiver responds to system wide announcement messages, such as the screen has turned off or the battery is low.</p><p>Activities, Services, and Broadcast Receivers are activated via Intent messages. An Intent message is an event for an action to be performed along with the data that supports that action. Intent messaging allows for late run-time binding between components, where the calls are not explicit in the code, rather made possible through Android's messaging service. All major components, including Activity and Service, follow pre-specified lifecycles <ref type="bibr" target="#b0">[1]</ref> managed by the ADF. The lifecycle event handlers are called by the ADF and play an important role in our research as explained later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ILLUSTRATIVE EXAMPLE</head><p>We use a simple Android app, called Expense Reporting System (ERS), to illustrate our research. The ERS app allows users to submit expense report from their Android devices. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, ERS provides two use cases that allow the user to create two types of report: quick report and itemized report.</p><p>When quick report is chosen, the user enters the expense item name and the amount, and subsequently presented with the summary screen. The user can choose to submit or quit the application on the summary screen.</p><p>The itemized report option presents the user with the option to enter the number of line items by tapping the plus and minus buttons. When next is tapped, the application prompts the user to enter the expense name and amount. This screen is repeated until all line items have been entered. Once all items are entered, the user is presented with a summary screen with the line items, their amount, and the total amount. The user can again choose to submit or quit the application at this time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESEARCH CHALLENGE</head><p>Achieving high code coverage in Android apps, such as ERS, requires trying out a large number of sequences of events such as user interactions and system notifications. Our research is inspired by prior work <ref type="bibr" target="#b29">[30]</ref> that has shown evolutionary testing to be effective when sequences of method invocation are important for obtaining high code coverage. However, application of evolutionary testing has been mostly limited to the unit level <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>, as when applied at the system level, it cannot effectively promote the genetic makeup of good individuals in the search.</p><p>Figure <ref type="figure" target="#fig_1">2a</ref> illustrates the shortcoming of applying an evolutionary approach for system testing of ERS. Here, we have two individuals in iteration 1 of the search. In this representation, an individual is comprised of two types of genes: input genes (e.g., values entered in text fields) and event genes (e.g., clicked buttons). The test case specified in an individual is executed from the left most gene to the right most gene. In essence, each individual is a test script.</p><p>Using the screenshots of ERS in Figure <ref type="figure" target="#fig_0">1</ref>, we can see that the two individuals in iteration 1 of Figure <ref type="figure" target="#fig_1">2a</ref> represent reasonable tests, as each covers a different part of the app. For system testing, we would need to build on these tests to reach deeper into the code. The problem with this representation, however, is that there is no effective approach to pass on the genetic make up of these individuals to the next generations. For instance, from Figure <ref type="figure" target="#fig_1">2a</ref>, we can see that the result of a crossover between the two individuals in it-  eration 1 is a new individual in iteration 2 that does not preserve the genetic makeup of either parents in any meaningful way. In fact, using the screenshots of ERS in Figure <ref type="figure" target="#fig_0">1</ref>, we can see that the tests cannot even be executed. There are two issues that contribute to this: (1) The crossover strategy does not consider which input and action genes are coupled to one another. For instance, the genes "lunch", "20", and "Next" are coupled with one another, as only together they can exercise the Expense Item screen. (2) The crossover strategy mixes genes from two different execution paths in the system. Thus, it produces a test that is likely to be either not executable or inferior to both its parents. In evolutionary search, the inability to promote and pass on the genetic makeup of good individuals to the next generations is highly detrimental to its effectiveness.</p><p>To overcome the issues with this representation, prior approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> use evolutionary algorithm in conjunction with GUI crawling techniques. One such approach, called EXSYST <ref type="bibr" target="#b26">[27]</ref>, represents test suites as individuals and tests as genes, as depicted in Figure <ref type="figure" target="#fig_1">2b</ref>. This approach generates tests that correspond to random walks on the GUI model. An individual is comprised of many random tests, i.e., each gene of the individual corresponds to a system test. EXSYST evolves the suites of tests to minimize the number of tests and maximize coverage. However, the probability of a single gene (test) achieving deep coverage remains the same as in the case of random testing. The overall coverage is no better than the initial population (randomly generated tests), as the evolutionary algorithm is mainly used to minimize the number of tests.</p><p>EvoDroid is the first evolutionary testing approach for system testing of Android apps. To that end, it had to overcome the conceptual challenges of using evolutionary techniques for system testing. EvoDroid achieves this through a unique representation of individuals and a set of heuristics that allow the algorithm to maintain and promote individuals with good genetic makeup that reach deep into the code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">APPROACH OVERVIEW</head><p>The overall EvoDroid framework is shown in Figure <ref type="figure" target="#fig_2">3</ref>. The input is an Android app's source code. From the source code, EvoDroid extracts two types of models, representing the app's external interfaces and internal behaviors, to automatically generate the tests: Interface Model (IM) and Call Graph Model (CGM). The models are automatically extracted by analyzing the app's code.</p><p>IM provides a representation of the app's external interfaces and in particular ways in which an app can be exercised, e.g., the inputs and events available on various screens to generate tests that are valid for those screens. A partial representation of IM for the ERS is shown in Figure <ref type="figure" target="#fig_3">4b</ref>. EvoDroid uses the IM to determine the structure of individuals (tests), i.e., the input and event genes that are coupled together.</p><p>CGM is an extended representation of the app's call graph. A typical call graph shows the explicit method call relationships. We augment that with information about the implicit call relationships caused by events (messages). An example of CGM for the ERS is shown in Figure <ref type="figure" target="#fig_4">5</ref>. A particular use case (e.g., quick report or itemized report from Figure <ref type="figure" target="#fig_0">1</ref>) follows a certain path through the CGM. EvoDroid uses CGM to (1) determine the parts of the code that can be searched independently, i.e., segments, and (2) evaluate the fitness (quality) of different test cases, based on the paths they cover through the CGM, thus guiding the search.</p><p>Using these two models, EvoDroid employs a step-wise evolutionary test generation algorithm, which we call segmented evolutionary testing. It aims to find test cases covering as many unique CGM paths from the starting node of an app to all its leaf nodes. In doing so, it logically breaks up each path into segments. It uses heuristics to search for a set of inputs and sequence of events to incrementally cover the segments. By carefully composing the test cases covering each segment into system test cases covering an entire path in the CGM, EvoDroid is able to promote the genetic makeup of good individuals in the search.</p><p>EvoDroid executes the automatically generated test cases in parallel, possibly on the cloud, to address scalability issues. The test cases are evaluated based on a fitness function that rewards code coverage and uniqueness of the covered path.</p><p>The focus of EvoDroid is on generating test cases that maximize code coverage, not on whether the test cases have passed or failed. We acknowledge that automatically generating test oracles is a significant challenge. This has been and continues to be the focus of many research efforts. Currently, we collect two types of results from the execution of tests: any exceptions that may indicate certain software faults as well as code coverage information.</p><p>Section 6 describes the models used for testing, while Section 7 presents the details of EvoDroid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">APPS MODELS EXTRACTION</head><p>EvoDroid needs three types of information about the app under test for automatically generating test cases: (1) the genes comprising a valid individual, e.g., determining the input fields and GUI controls that should be paired up to have a valid test case for an Activity (which as you may recall from Section 2 represents a GUI screen), (2) the app's segments, i.e., parts of the app that can be searched separately to avoid the crossovers issues described earlier, and (3) the fitness value of different test cases. We developed Android-specific program analysis techniques to infer two models that can provide EvoDroid with this information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Interface Model</head><p>The Interface Model (IM) provides information about all of the input interfaces of an app, such as the widgets and input fields belonging to an Activity. It also includes information about the application-and system-level Intents handled by each Activity. The IM is obtained by combining and correlating the information contained in the configuration files and meta-data included in Android APK (such as Android Manifest and layout XML files).</p><p>First we list all the Android components (e.g., Activities, Services) comprising an app with the help of information found in the Manifest file. Afterwards, for each Activity we parse the corresponding layout file. An example of such layout file for ExpenseIt-emActivity is shown in Figure <ref type="figure" target="#fig_3">4a</ref>. It is quite straightforward to ob- tain all information on each screen, such as widget type, name, and identifier from this XML document to generate the IM. Figure <ref type="figure" target="#fig_3">4b</ref> depicts the IM for the ERS Activities. We use the information captured in IM to determine the structure (genes) of individuals for testing each component of the app.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Call Graph Model</head><p>The Call Graph Model (CGM) contains a set of connected call graphs capturing the different possible invocation sequences within a given application. We use MoDisco <ref type="bibr" target="#b12">[13]</ref>, an open source program analysis tool, to extract the app's call graph. However, since Android is an event driven environment, MoDisco generates disconnected call graphs for each app. Figure <ref type="figure" target="#fig_4">5</ref> shows ERS's CGM. As described later, we have extended MoDisco to infer the dashed lines to create a fully connected graph.</p><p>The root node of each call graph snippet is a method that no other part of the application explicitly invokes. There are two types of root nodes:</p><p>1. Inter-component root nodes: these root nodes represent methods in a component that handle events generated by other components or Android framework itself, e.g., an Activity generating a StartActivity event that results in another Activity's onCreate() method to be called, or the Android framework sending a Resume event that results in an Activity's onResume() method to be invoked.</p><p>2. Intra-component root nodes: these root nodes correspond to events that are internal to a component. For example, a Button on an Activity has a Click event associated with it. This event is handled by a class within the same Activity that implements the OnClickListener interface and overrides the onClick() method. These sorts of callback handlers are also root nodes, as they are called by the Android framework.</p><p>The inter-component root nodes are the logical break points for segments, and the inputs received at these nodes form the structure of individuals for the corresponding segments. We can determine the structure of this input using the IM. On the other hand, the intra-component root nodes do not mark a new segment, as they do not result in the execution to move to a different component (e.g., different screen), and thus are not susceptible to the crossover problem.</p><p>Finally, for EvoDroid to generate tests and to determine their fitness, it needs the CGM to be fully connected. To that end, we have extended MoDisco with an Android-specific program analysis capability to infer the relationships among the disconnected nodes of the call graph. As depicted in Figure <ref type="figure" target="#fig_4">5</ref>, we start with the onCreate() root node of the main Activity, which we know from Android's ADF specification to be the starting point of all apps. We then identify the Intent events and their recipients, as well as GUI controls and their event handlers, to link the different parts of &lt;LinearLayout xmlns:android="http://schemas.android .com/apk/res/android" android:orientation="vertical" android:layout_width="fill_parent" android:layout_height="fill_parent" &gt; ... &lt;EditText android:id="@+id/expenseNameId" android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;requestFocus /&gt; &lt;/EditText&gt; &lt;EditText android:id="@+id/expenseAmoundId" android:layout_width="match_parent" android:layout_height="wrap_content"&gt; &lt;requestFocus /&gt; &lt;/EditText&gt; &lt;Button android:id="@+id/nextBtn" android:layout_width="wrap_content" android:layout_height="wrap_content" android:text="Next" /&gt; ... &lt;/LinearLayout&gt;  In the case of inter-component events, the sender of Intent identifies its handler as one of the Intent's parameters. In the case of intra-component events, the root node responsible for handling that event is registered as a callback method with the sender. For instance, a button's onClick() method is registered with an object that implements the OnClickListener to receive a callback when the button is clicked. Examples of this in Figure <ref type="figure" target="#fig_4">5</ref> are Decrement-Button and IncrementButton that are registered with ItemCountActivity, which implements the OnClickListener interface. As the call graph snippets are linked and connected, they are traversed in a similar fashion to arrive at the final connected CGM for the app.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">EVODROID</head><p>The goal of EvoDroid is to find a set of test cases that maximize code coverage. This is encoded as covering as many unique paths from the starting node of the CGM to its leaf nodes. In the context of ERS, depicted in Figure <ref type="figure" target="#fig_4">5</ref>, it is to find test cases from node A to leaf nodes n1, n2, and n3. For example, possible paths in this graph are A → B → C → n1 and A → B → E → F → n3. The former involves two segments, while the latter involves four segments.</p><p>For each such path in Figure <ref type="figure" target="#fig_4">5</ref>, EvoDroid starts from the beginning node and searches for test cases that can reach the leaf nodes. Each test case is represented as an individual in EvoDroid and its genes are the app inputs and the sequence of events. Unlike any prior approach, EvoDroid takes each path in the CGM, breaks it into segments, and runs the evolutionary search for each segment separately. Accordingly, the evolutionary process described here is repeated for each segment along each path in the CGM.</p><p>For each segment in each path, a population with a configurable number of individuals is generated. The evolutionary process is continued until all of the paths and their segments are covered or a configurable threshold (e.g., time limit, certain level of code coverage, number of total test cases, etc.) is reached. The search is abandoned for a segment, and potentially a path, if the coverage is not improved after a configurable number of generations. This ensures the search does not waste resources on genes that cannot be further improved; it also prevents the search from getting stuck in infinite loops when there are cycles in the path. Fitness is measured based on how close an individual gets to reach the next segment as well the uniqueness of the covered path. With each iteration, Evo-Droid breeds new individuals by crossing over current individuals selected with likelihood proportional to their fitness value, and then mutates them (e.g., changes some of the input values or events).</p><p>The ideal individuals from each segment are saved. An ideal individual is a test that covers the entire segment and reaches the root node of another segment. An ideal individual from the previous segment is prepended to the genes of a new individual for the next generation, as described further in the next section. Essentially the test cases gradually build on the solutions found for the prior segments to build up to a system test case. A segment may also optionally be skipped if it was covered while attempting to cover another segment. For example, in Figure <ref type="figure" target="#fig_4">5</ref>, since the segment</p><formula xml:id="formula_0">E → F is shared in the following two paths A → B → E → F → n3 and A → E → F → n3</formula><p>, it would only need to be evolved once (assuming ideal individuals were found the first time). Similarly, if while evolving A → B, the algorithm inadvertently reaches A → E, those ideal individuals are saved and EvoDroid may optionally skip solving A → E.</p><p>The maximum number of individuals or test cases executed in the search process can be calculated as follows:</p><formula xml:id="formula_1">T = |path| ∑ i=1 Seg i × gen seg i × pop gen seg i (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where |path| is the number of unique paths (from the starting node to the leaf nodes) in CGM, seg is the number of segments for each path, gen is the number of generations per segment, and pop is the population or the number of individuals per generation. The remainder of this section describes the details of EvoDroid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Representation</head><p>The models from Section 6 are used to determine the structure of genes for each segment. IM tells us the inputs, their data type (such as integer, double etc.), the number of GUI elements (such as buttons), and/or system events relevant to the current segment.</p><p>An individual is represented as a vector shown in Figure <ref type="figure" target="#fig_5">6a</ref>. Here, previous segment corresponds to the genes of an ideal individual from the previous segment, Input <ref type="bibr">[1.</ref>.n] corresponds to specific input values from the current segment, and Event [1..m] corresponds to the sequence of possible user actions or system events from the current segment. Each index in the vector contains a gene. The previous segment is a recursive relationship.</p><p>The number of input genes is fixed, as we only need to change the input values, i.e., mutate the existing input genes. The number of event genes is variable to handle the situations in which unexplored parts of the application require a certain number of button clicks or certain sequence of events. For instance, in the Line Item Count screen from Figure <ref type="figure" target="#fig_0">1</ref>, the plus button must be clicked more than the minus button and before clicking the next button to be able to reach the next screen. We execute the test case specified in an individual from the left most gene to the right most gene including all previous segment genes, essentially traversing a path in the CGM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Crossover</head><p>The first step in creating a new individual for the next generation is crossover. This process selects two individuals from the current population and creates a new individual by mixing their genetic makeup. EvoDroid uses a multi-point probabilistic crossover strategy. There is at least one, and potentially multiple, crossover points between the two selected individuals.</p><p>The segment crossover probability is calculated as follows:</p><formula xml:id="formula_3">p(c) = 1 e (s-c) (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where e is a configurable constant to achieve a decay factor, s is the index of the current segment being searched, and c is the index of a prior segment between 1 and s. The probability is 1.0 for the current segment, that is to say when c = s. This exponential decay function ensures that the earlier genetic makeup is not changed frequently, while leaving the possibility open to find individuals that may explore new areas of the search space.</p><p>The crossover point for the current segment can be at any gene index and at most the length of the smaller of the two individuals. We only allow one crossover for the current segment, as this is sufficient to create variability in the new individual. Figure <ref type="figure" target="#fig_5">6c</ref> shows the crossover steps for a pair of parent individuals in segment 3 of ERS. The newly created individual inherits part of the genetic makeup of the parents.</p><p>The previous segments are treated separately from the current segment and the probability function p(c) dictates the chance of crossover in each segment. There can potentially be a crossover at each of the previous segments, but we only allow swapping of the entire ideal individual for each segment, not in the middle of a previous ideal individual. Figures <ref type="figure" target="#fig_5">6b</ref> and<ref type="figure">c</ref> show how ideal individuals found in prior segments are used to arrive at the parent individuals in Figure <ref type="figure" target="#fig_5">6c</ref>. Here the new individual in Figure <ref type="figure" target="#fig_5">6c</ref> inherits the previous segment individual from the left parent. If the probability function p(c) had dictated otherwise, it would have been inherited from the parent on the right.</p><p>This crossover strategy aims to preserve the genetic makeup of the solutions found for earlier segments, as we only allow the crossover to use the complete ideal individual for a given segment. Any ideal individual from that segment can be substituted, as they are all solutions for that segment. The previous segments for the new individual in Figure <ref type="figure" target="#fig_5">6c</ref> share the same path (as the evolutionary process is applied within the context of a path), thus the structure of the individuals at each previous segment line up properly.</p><p>Note that this crossover strategy does not provide any guarantees that the input values and events satisfying an earlier segment in a path will be able to satisfy later segments in that path. For example, solving a particular constraint in segment 3 may require a specific value to have been entered in segment 1. Indeed, the objective of the search is to find such combinations. The evolutionary search, guided by heuristics embedded in the fitness function, naturally weeds out sub-optimal tests. In addition, since we save many ideal individuals for each segment, each with different input/event genes, EvoDroid is quite effective at eventually discovering individuals that solve the entire path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Mutation</head><p>Mutation changes parts of the genetic makeup of the newly created individual. Only the current segment genes are mutated with a probability threshold that is configurable. We mutate both input and event genes with several creation, transformation and remove operations.</p><p>The first type of mutation is done to the input genes of an individual. The creation of a numerical input includes boundary values, random, special/interesting values such as the number zero. For a string input, we generate purely random, uniformly distributed characters from the alphabet of a certain length, or null. Transformation operations for inputs include random value of same primitive data type, bit-flipping, arithmetic operations, and binary space reduction between boundary values. Removal operation for inputs is not applicable; they are included as null instead.</p><p>The second type of mutation is done to the event genes. The creation operator simply creates an event from the list of valid events specified in the IM. The number of added events is random with a minimum of one and a configurable upper threshold. Transformation operations for events include swapping event gene indexes, changing one event to another, and inserting a new event at a random index. Removal operation for events removes one or more event genes. The length of the overall individual can change as a result. Figure <ref type="figure" target="#fig_5">6d</ref> show the mutation of a single gene to create a final unique individual that is different from both parents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Fitness</head><p>A key aspect of evolutionary algorithms is the notion of fitness. In each generation, individuals are assessed for their fitness with respect to the search objective to be selected to pass on their genes. The fitness value ranges from 0 to 1. EvoDroid considers two factors when assessing the fitness of individuals. The first is the distance traveled (number of nodes covered between segments) to reach the next segment, and the second is the uniqueness of the path covered compared to the other individuals in the same generation. The fitness of an individual i is determined as follows:</p><formula xml:id="formula_5">f (i) = x n + u(i) (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>where x is the number of covered nodes in the path to the destination segment, n is the total number of nodes in the path to the destination segment, and u(i) is the uniqueness function of the individual as follows:  </p><formula xml:id="formula_7">u(i) = 1 - x n × l ∑ k=1 unique(r k ) l + k (4)</formula><p>where r k is the covered node at index k in the path covered by the individual, and unique(r k ) is 1 if the covered node at index k is unique compared to other individuals' coverage at the same index, and 0 otherwise, and l is the length of the path that this individual has covered.</p><p>When an individual for a given segment covers the entire segment path, we identify it as an ideal individual for that segment with a fitness score of 1. Of course, this means that there can be multiple individuals per generation that are ideal for a segment.</p><p>For illustration of how fitness is calculated, consider the hypothetical example depicted in Figure <ref type="figure" target="#fig_6">7</ref>. It shows that the total distance (number of nodes) to reach SummaryActivity from LineIt-emActivity is 5. When the first individual executes, the shaded nodes are marked as covered by that individual. It covers 3 out of the 5 nodes along the path to segment root node, so it gets a distance score of x/n = 3/5 = 0.6, a uniqueness score of u(i) = 0.4 × 1/(4 + 1) + 1/(4 + 2) + 1/(4 + 3) + 1/(4 + 4) = 0.25 as the entire path is unique at this time, for a total fitness score of f (i) = 0.85.</p><p>If another individual test case is executed but covers the path with nodes LineItemActivity → n1 → n2 → n3, it would get a distance score of x/n = 1/5 = 0.2, and additionally a uniqueness score. The length of the path this individual covered is 4 and all but the first node are unique (i.e., n1, n2, n3), so the uniqueness score is u(i) = .8 × (1/(4 + 2) + 1/(4 + 3) + 1/(4 + 4)) = 0.34. The total fitness score for this individual would be f (i) = 0.2 + 0.34 = 0.54. Although the individual did not cover much of the path to the destination segment node, it is awarded a fractional score as it may discover a new area of uncovered code.</p><p>Note that the formulation of eq. 3 and 4 ensures that the uniqueness score alone never makes the value of fitness function to be 1 without reaching the destination. This prevents an individual to be labeled ideal without first reaching the destination. Finally, a configurable number of test cases with the highest scores are directly copied to the future generations without any changes, to ensure the individuals with the best genetic makeup remain in the population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">EVALUATION</head><p>We evaluated EvoDroid on a large number of apps with varying characteristics. The goal of our evaluation was twofold: (1) compare the EvoDroid code coverage against the prior solutions, and (2) characterize its benefits and shortcomings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Experiment Environment</head><p>Evolutionary testing requires the execution of a large number of tests. This is especially challenging in the case of the Android emulator <ref type="bibr" target="#b1">[2]</ref>, as it is known to be slow even when running on workstations with the latest processors and abundant memory. To mitigate this issue, we have developed a novel technique to execute the tests in parallel, possibly on the cloud, which makes it suitable for use by small as well as large organizations.</p><p>We set up an instance of Amazon EC2 virtual server running Windows Server 2008, and configured it with Java SDK, Android SDK, Android Virtual Device, and a custom test execution manager engine developed by us. For each test, the test execution manager launches the emulator, installs the app, sets up and executes the test. It is also responsible for persisting all of the results, along with the log and monitored data, to an output repository. A virtual machine image was created from the above instance to be replicated on demand. With this, we were able to scale in near-linear time and cut down on the execution time. We report the results for both extremes: when the test cases are executed in sequence using a single processor, and when they execute completely in parallel.</p><p>We have implemented EvoDroid using ECJ <ref type="bibr" target="#b8">[9]</ref>, a prominent evolutionary computing framework. In the experiments, we used EMMA <ref type="bibr" target="#b9">[10]</ref> to monitor for code coverage, and all of the test cases were in Robotium <ref type="bibr" target="#b14">[15]</ref> format. Our implementation and evaluation artifacts are available from <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Experiment Setup</head><p>We compare EvoDroid with Android Monkey <ref type="bibr" target="#b2">[3]</ref> and Dynodroid <ref type="bibr" target="#b31">[32]</ref> in terms of code coverage and execution time. Android Monkey is developed by Google and represents the state-of-the-practice in automated testing of Android apps. It sends random inputs and events to the app under test. Dynodroid <ref type="bibr" target="#b31">[32]</ref> is a recently published work from researchers at Georgia Tech that uses a smaller number of inputs and events than Monkey for reaching similar coverage. We are not able to compare directly with EXSYST <ref type="bibr" target="#b26">[27]</ref> and Evo-Suite <ref type="bibr" target="#b27">[28]</ref>, as they are not targeted for Android. We do not compare against <ref type="bibr" target="#b37">[38]</ref> as that is for model generation only, while EvoDroid creates models and performs a step-wise segmented evolutionary search.</p><p>At first blush it may seem unreasonable to compare EvoDroid, a whitebox testing approach, against Android Monkey and Dynodroid, which are blackbox and greybox testing approaches, respectively. However, there are two reasons that makes this comparison relevant. First, most Android apps can be reverse engineered using one of the existing tools (see <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16]</ref>) to obtain the source code necessary for whitebox testing. Therefore, our approach could be used for testing almost all Android apps. Second, in the evaluation of any stochastic search algorithm, it is desirable to compare the results of the algorithm against the unbiased random sample of the solution space. We believe the comparison against Monkey and Dynodroid helps us in that vein. It should be noted that unlike EvoDroid, Monkey and Dynodroid are not designed to run in a distributed manner, and neither tools are configurable to run for a specific amount of time.</p><p>To achieve a fair comparison with Android Monkey and Dynodroid, however, we had to allot each approach similar number of events. The events for Android Monkey and Dynodroid are similar to the genes in EvoDroid. Since there is no one-to-one mapping, we ran EvoDroid first, and then mapped the total number of generated tests to Monkey and Dynodroid events. Thus, the number of events allotted for running Monkey and Dynodroid varied as a function of the number of test cases executed for EvoDroid as follows: max(g) × t, where g is the maximum number of genes allowed for In all experiment scenarios, for each segment in each path, we used a maximum of 10 generations of 10 individuals with a maximum of 10 genes. The number of maximum generations along with the coverage of all segments served as the terminating conditions. Euler's constant (e = 2.718) was used as the crossover decay number in eq. 2, and during the mutation phase each gene had a 20% chance of mutation.</p><p>To evaluate EvoDroid, two sets of experiments were performed. The first on apps developed by independent parties from an open source repository, and the second on synthetic apps. The synthetic apps helped us benchmark EvoDroid's characteristics in a controlled setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Open Source Apps</head><p>We selected 10 open source apps to evaluate the line coverage between EvoDroid, Monkey, and Dynodroid. We were not able to run Dynodroid on two of the subject apps, and thus we are not able to report on those. As shown in Table <ref type="table" target="#tab_0">1</ref>, EvoDroid consistently achieves significantly higher coverage than both Monkey and Dynodroid. On average EvoDroid achieves 47% and 27% higher coverage than Monkey and Dynodroid, respectively.</p><p>The generation of test oracles is outside the scope of our work, nevertheless we collected information about unhandled exceptions, which allowed us to detect several defects in these apps. instance, we found several cases of unhandled number format exception in Tipster, TippyTipper, and Bites that were due to either leaving the input fields empty, clicking a button that clears the input field followed by clicking a button that would operate on the inputs, or simply putting a string that could not be converted to a number. As another example, we found a defect in Bites, an app for finding and sharing food recipes, in which an unhandled index out of bounds exception would be raised when editing recipes without adding the ingredients list first. Some of the reasons for not achieving complete coverage are unsupported emulator functions, such as camera, as well as spawning asynchronous tasks that may fail, not finish by the time the test finishes, and thus not get included in the coverage results. Other reasons include code for handling external events, such as receiving a text message, dependence on other apps, such as calendars and contacts lists, and custom exception classes that are not encountered or thrown. Additionally, some of the applications contained dead code or test code that was not reachable, thus the generated EvoDroid model would not be fully connected. Indeed, in many of these apps achieving 100% coverage is not possible, regardless of the technique.</p><p>The limitations of emulator, peculiarities in the third-party apps, and incomplete models made it very difficult to assess the characteristics of EvoDroid independently. In other words, it was not clear whether the observed accuracy and performance was due to the aforementioned issues, and thus an orthogonal concern, or due to the fundamental limitations in EvoDroid's approach to test generation. We, therefore, complemented our evaluation on real apps with a benchmark using synthetic apps, as discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Synthetic Benchmark Apps</head><p>To control the characteristics of the subjects (i.e., apps under test), we developed an Android app generator that synthesizes apps with different levels of complexity for our experiments. Since we needed a way of ensuring the synthetic apps were representative of real apps, we first conducted an empirical study involving 100 real world apps chosen randomly from an open source repository, called F-Droid <ref type="bibr" target="#b11">[12]</ref>. The selected apps were in various categories, such as education, Internet, games, etc. We analyzed these apps according to four complexity metrics that could impact EvoDroid:</p><p>• Root Nodes per App -the number of disconnected call graphs in the app; these are the methods called by ADF, and potentially the break points for EvoDroid segments.</p><p>• Method Call Sequence Depth -the longest method call sequence in the app.</p><p>• McCabe Cyclomatic Complexity -the average number of control flow branches per method.</p><p>• Block Depth per Method -the average number of nested condition statements per method.</p><p>Figure <ref type="figure" target="#fig_7">8</ref> shows the distribution of these metrics among the 100 Android apps from F-Droid. Our app generator is able to synthesize apps with varying values in these four metrics. Since we wanted to evaluate the accuracy and performance of EvoDroid on subjects with different levels of complexity, we had to derive some complexity classes from this data. For that, we aggregated the data collected through our empirical study, as shown in Figure <ref type="figure" target="#fig_7">8</ref>, and divided it into 9 equal complexity classes, ranging from 1 to 9. For instance, the 1st complexity class corresponds to the 10th percentile in all of the four metrics shown in Figure <ref type="figure" target="#fig_7">8</ref>. Essentially an app belonging to a lower class is less complex with respect to all four metrics than an app from a higher class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.1">Impact of Complexity</head><p>To benchmark the impact of complexity on EvoDroid, we generated two apps for each complexity class. Apps were set up such that exactly 1 path contained no input constraints, while other paths contained nested conditional input constraints. These constraints were generated to simulate the Block Depth per Method dimension, and would have to be satisfied in order for the search to progress   <ref type="figure" target="#fig_8">9a</ref>. As the complexity class of apps increases, the coverage for Monkey and Dynodroid drops significantly. Since EvoDroid logically divides an app into segments, the complexity stays relatively the same, i.e., it is not compounded per segment. In all experiments, EvoDroid achieves over 98% line coverage. The cases where 100% coverage is not reached is due to EvoDroid abandoning the search when reaching the maximum number of allowable generations. Increasing the number of generations is likely to resolve those situations.</p><p>Once Monkey traverses a path, it does not backtrack or use any other systematic way to test the app. Therefore, Monkey's test coverage is shallow as others have confirmed in <ref type="bibr" target="#b31">[32]</ref>. Dynodroid periodically restarts from the beginning of the app, and is able to outperform Monkey. Note that for very complex apps, Dynodroid would crash, and thus we were not able to obtain results. <ref type="foot" target="#foot_0">1</ref>Table <ref type="table" target="#tab_1">2</ref> summarizes the execution time for EvoDroid, Monkey, and Dynodroid. Even though the execution time for EvoDroid significantly increases as the apps become more complex, it could be alleviated by running EvoDroid in parallel, possibly on the cloud. EvoDroid parallel times are roughly equivalent to the worst path execution time. The numbers presented assume as many parallel instances running as there are test cases. In practice, we expect EvoDroid to be executed on several machines, but perhaps not hundreds, producing an execution time in between the worst case and best case reported in Table <ref type="table" target="#tab_1">2</ref>. We can see that as the depth of the segments increases, the time to execute EvoDroid increases. The results also show that Monkey runs fairly quickly, while Dynodroid takes longer, as one would expect due to its backtracking feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.2">Impact of Constraints</head><p>Input constraint satisfaction is a known weakness of search based testing techniques. A set of experiments was conducted to assess the efficacy of our approach as the satisfiability probability of conditional statements was lowered below 50%. We took the second app from the 3rd complexity class (shown in Figure <ref type="figure" target="#fig_8">9a</ref>) and low-ered the satisfiability probability of its conditional statements to 25%, 10%, and 1%. As shown in Figure <ref type="figure" target="#fig_8">9b</ref>, when the probability of constraint satisfiability decreases, the line coverage drops significantly for EvoDroid. Android Monkey coverage stays the same as it takes the one path with no constraints and does not backtrack. The coverage for Dynodroid drops also, but remains better than Monkey, as it restarts from the beginning several times during execution.</p><p>The results demonstrate that EvoDroid (as well as any other evolutionary testing approach) performs poorly in cases where the apps are highly constrained (e.g., the probability of satisfying many conditional constraints with random inputs is close to zero, such as an if condition that specifies an input value to be equal to a specific value). Fully addressing this limitation requires an effective approach for solving the constraints, such as symbolic execution, as described further in Section 10. Fortunately, from Figure <ref type="figure" target="#fig_7">8</ref> we see that for a typical Android app, the average cyclomatic complexity is approximately 2.2 and block depth is approximately 1.75. These numbers are encouraging, as they show that on average most Android apps are not very constrained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.3">Impact of Sequences</head><p>Given the event driven nature of Android apps, there are situations when certain sequences of events must precede others or certain number of events must occur to execute a part of the code. We evaluated EvoDroid for these types of situations by generating apps from the 3rd complexity class with ordered sequence lengths ranging from 1 to 5. Sequences of events with these lengths would have to be satisfied, per segment in all paths, in order to proceed with the search (e.g. certain buttons on an Activity must be clicked in a certain sequence of length 1 to 5).</p><p>Figure <ref type="figure" target="#fig_8">9c</ref> summarizes the results from these experiments. While EvoDroid's coverage decreases, it does so at a much slower pace than Monkey or Dynodroid. We observe that EvoDroid is effective in generating system tests for Android apps involving complex sequence of events. This is indeed one of the strengths of EvoDroid that is quite important for Android apps as they are innately event driven.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">RELATED WORK</head><p>The Android development environment ships with a testing framework <ref type="bibr" target="#b3">[4]</ref> that is built on top of JUnit. Robolectric <ref type="bibr" target="#b13">[14]</ref> is another testing framework for Android apps that runs tests without relying on the Android emulator. While these frameworks automate the ex- Amalfitano et al. <ref type="bibr" target="#b17">[18]</ref> described a crawling-based approach that leverages completely random inputs to generate unique test cases. In a subsequent work <ref type="bibr" target="#b18">[19]</ref>, they presented an automated Android GUI ripping approach where task lists are used to fire events on the interface to discover and exercise the GUI model. Hu and Neamtiu <ref type="bibr" target="#b28">[29]</ref> presented a random approach for generating GUI tests that uses the Android Monkey to execute. We use program analysis to derive the models. This sets us apart from these works that employ black-box testing techniques.</p><p>Yang et al. <ref type="bibr" target="#b37">[38]</ref> described a grey-box model creation technique that similar to our work is concerned with deriving models for testing of Android app and can potentially be substitued for our models. They also found that models generated using their approach could be incomplete. Jensen et al. <ref type="bibr" target="#b30">[31]</ref> presented a system testing approach that combines symbolic execution with sequence generation. They attempt to find valid sequences and inputs to reach prespecified target locations. Their approach neither uses an evolutionary search technique like ours, nor is their goal maximizing code coverage. Anand et al. <ref type="bibr" target="#b19">[20]</ref> presented an approach based on concolic testing of a particular Android library to identify the valid GUI events using the pixel coordinates. Dynodriod <ref type="bibr" target="#b31">[32]</ref> is an input generation system for Android that was used extensively in our experiments.</p><p>Evolutionary testing falls under search based testing techniques and has typically been used to optimize test suites <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> or has been applied at the unit level <ref type="bibr" target="#b29">[30]</ref>. Evolutionary testing approaches such as <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34]</ref> have attempted to optimize a test suite for coverage. These are all blackbox approaches that build their GUI models at run time by executing and crawling or by recording user behavior, and therefore the generated models may not be complete. Since our approach uses program analysis, we obtain a more complete model of the app's behavior. They also differ from us in that they represent test cases as genes. Two unit level evolutionary testing approaches were presented in <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. A combination of approaches were also presented in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30]</ref>. Evolutionary algorithm and symbolic execution techqniques were combined in <ref type="bibr" target="#b29">[30]</ref>, while evolutionary algorithm and hill climbing algorithm were used together in <ref type="bibr" target="#b21">[22]</ref>. These techniques are all geared towards unit testing. An ant colony optimization search was used in <ref type="bibr" target="#b22">[23]</ref> along with a call graph similar to ours for GUI testing. However, their call graph is generated by executing the system and connecting overlapping call nodes to attempt to form the entire call graph. This approach suffers from the same issue as the GUI crawling methods, meaning that the call graph model may be incomplete. Choi et al. <ref type="bibr" target="#b24">[25]</ref> proposed a machine learning approach to improve the app models by exploring the states not encountered during manual testing. This work is complementary to our work, as it may be possible to use these improved models in EvoDroid.</p><p>There has also been a recent interest in using cloud computing to validate and verify software. TaaS is a testing framework that automates software testing as a service on the cloud <ref type="bibr" target="#b23">[24]</ref>. Cloud9 <ref type="bibr" target="#b25">[26]</ref> provides a cloud-based symbolic execution engine. Similarly, our framework is leveraging the computational power of cloud to scale evolutionary testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">CONCLUDING REMARKS</head><p>We have presented EvoDroid, a novel framework for automated testing of Android apps. The key contributions of our work are <ref type="bibr" target="#b0">(1)</ref> an automated technique to generate abstract models of the app's behavior to support automated testing, (2) a segmented evolutionary testing technique that preserves and promotes the genetic makeup of individuals in the search process, and (3) a scalable system-wide testing framework that can be executed in parallel on the cloud.</p><p>Although our approach has shown to be significantly better than existing tools and techniques for automated testing of Android apps, in the worst case scenario it can degrade quite a bit due to its inability to systematically reason about input conditions. This is a known limitation of search based algorithms, such as evolutionary testing. In our ongoing work <ref type="bibr" target="#b32">[33]</ref>, we are developing an Android-specific symbolic execution engine. We are extending Java Pathfinder, which symbolically executes pure Java code, to work on Android. We plan to use both techniques in tandem to complement one another. We are also exploring relational logic and the associated model finders for generating reduced combinatorics in testing Android apps <ref type="bibr" target="#b20">[21]</ref>.</p><p>Another weakness of our approach is not being able to fully generate models for apps that use third party libraries or native code. There is also a significant variability in the way the app code is generally written. As a result, the models may in fact be incomplete. However, as mentioned earlier and evaluated in Section 8.3, EvoDroid is able to work on partial and/or incomplete models. In the future, we plan to improve our models generation capabilities to handle a larger subset of the Android specifications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Expense Report System (ERS).</figDesc><graphic coords="2,318.81,541.14,239.09,165.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Existing evolutionary testing techniques: (a) a representation where the individual represents a test case, and (b) a representation where the individual represents a test suite</figDesc><graphic coords="3,55.80,53.80,239.10,147.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: EvoDroid Framework.</figDesc><graphic coords="4,131.12,59.47,351.49,113.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) Parts of the layout file for ExpenseItem Activity, (b) ERS Interface Model</figDesc><graphic coords="4,329.72,486.71,150.63,210.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Part of ERS's Call Graph Model</figDesc><graphic coords="5,55.80,53.79,239.11,313.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: EvoDroid's (a) representation of individual, (b) ideal individuals from segment 2, (c) crossover steps for creating an individual in the 3rd segment, and (d) mutation</figDesc><graphic coords="6,318.81,493.18,239.11,192.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Fitness evaluation</figDesc><graphic coords="7,55.80,53.80,239.10,159.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Android complexity metrics distribution from a random sample of 100 apps</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Benchmark Apps coverage results: (a) Line coverage results for testing apps from different complexity classes (b) Impact of constraints on line coverage (c) Impact of sequences of events on line coverage</figDesc><graphic coords="10,56.07,53.79,165.70,127.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Open source apps line coverage.</figDesc><table><row><cell>App Name</cell><cell>SLOC</cell><cell>EvoDroid</cell><cell>Android</cell><cell>Dynodroid</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Monkey</cell><cell></cell></row><row><cell>CalAdder</cell><cell>142</cell><cell>82%</cell><cell>18%</cell><cell>-</cell></row><row><cell>Tipster</cell><cell>280</cell><cell>89%</cell><cell>51%</cell><cell>48%</cell></row><row><cell>Munchlife</cell><cell>392</cell><cell>78%</cell><cell>45%</cell><cell>61%</cell></row><row><cell>JustSit</cell><cell>556</cell><cell>84%</cell><cell>37%</cell><cell>69%</cell></row><row><cell>AnyCut</cell><cell>1095</cell><cell>84%</cell><cell>6%</cell><cell>66%</cell></row><row><cell>TippyTipper</cell><cell>1649</cell><cell>82%</cell><cell>51%</cell><cell>-</cell></row><row><cell>NotePad</cell><cell>1655</cell><cell>76%</cell><cell>59%</cell><cell>65%</cell></row><row><cell>Bites</cell><cell>2301</cell><cell>80%</cell><cell>32%</cell><cell>39%</cell></row><row><cell>PasswordMaker</cell><cell>2824</cell><cell>76%</cell><cell>30%</cell><cell>36%</cell></row><row><cell>Bookworm</cell><cell>5840</cell><cell>77%</cell><cell>9%</cell><cell>43%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Execution time for testing apps from different complexity classes (in minutes).</figDesc><table><row><cell>Complexity</cell><cell># of</cell><cell>EvoDroid</cell><cell>Monkey/</cell><cell>EvoDroid</cell><cell>EvoDroid</cell><cell>Android</cell><cell>DynoDroid</cell></row><row><cell>Class</cell><cell>Segments</cell><cell>Test Cases</cell><cell>DynoDroid Events</cell><cell>Single CPU</cell><cell>Parallel</cell><cell>Monkey</cell><cell></cell></row><row><cell>1</cell><cell>4</cell><cell>30</cell><cell>300</cell><cell>41.55</cell><cell>1.65</cell><cell>1.52</cell><cell>235.57</cell></row><row><cell>1</cell><cell>6</cell><cell>40</cell><cell>400</cell><cell>44.10</cell><cell>1.75</cell><cell>1.55</cell><cell>273.27</cell></row><row><cell>2</cell><cell>8</cell><cell>50</cell><cell>500</cell><cell>52.00</cell><cell>2.01</cell><cell>1.52</cell><cell>309.43</cell></row><row><cell>2</cell><cell>9</cell><cell>60</cell><cell>600</cell><cell>88.31</cell><cell>2.20</cell><cell>1.53</cell><cell>325.78</cell></row><row><cell>3</cell><cell>17</cell><cell>130</cell><cell>300</cell><cell>258.77</cell><cell>2.40</cell><cell>1.65</cell><cell>458.90</cell></row><row><cell>3</cell><cell>19</cell><cell>140</cell><cell>140</cell><cell>293.38</cell><cell>2.53</cell><cell>1.58</cell><cell>407.60</cell></row><row><cell>4</cell><cell>25</cell><cell>210</cell><cell>2100</cell><cell>686.47</cell><cell>3.31</cell><cell>1.97</cell><cell>1091.00</cell></row><row><cell>4</cell><cell>33</cell><cell>220</cell><cell>2200</cell><cell>388.30</cell><cell>3.11</cell><cell>1.72</cell><cell>1073.40</cell></row><row><cell>5</cell><cell>36</cell><cell>260</cell><cell>2600</cell><cell>796.23</cell><cell>4.13</cell><cell>1.88</cell><cell>592.27</cell></row><row><cell>5</cell><cell>48</cell><cell>290</cell><cell>2900</cell><cell>692.77</cell><cell>3.92</cell><cell>2.23</cell><cell>823.57</cell></row><row><cell>6</cell><cell>49</cell><cell>280</cell><cell>2800</cell><cell>1107.79</cell><cell>4.90</cell><cell>2.02</cell><cell>623.57</cell></row><row><cell>6</cell><cell>47</cell><cell>520</cell><cell>5200</cell><cell>957.97</cell><cell>4.43</cell><cell>2.13</cell><cell>1100.70</cell></row><row><cell>7</cell><cell>109</cell><cell>750</cell><cell>7500</cell><cell>2725.27</cell><cell>5.11</cell><cell>2.50</cell><cell>1233.90</cell></row><row><cell>7</cell><cell>110</cell><cell>1110</cell><cell>11100</cell><cell>2999.87</cell><cell>5.53</cell><cell>2.82</cell><cell>-</cell></row><row><cell>8</cell><cell>233</cell><cell>1800</cell><cell>18000</cell><cell>7645.32</cell><cell>6.20</cell><cell>4.03</cell><cell>-</cell></row><row><cell>8</cell><cell>282</cell><cell>1960</cell><cell>19600</cell><cell>8035.17</cell><cell>6.53</cell><cell>4.17</cell><cell>-</cell></row><row><cell>9</cell><cell>345</cell><cell>3640</cell><cell>36400</cell><cell>13713.25</cell><cell>6.81</cell><cell>5.43</cell><cell>-</cell></row><row><cell>9</cell><cell>487</cell><cell>3680</cell><cell>36800</cell><cell>21395.50</cell><cell>7.59</cell><cell>6.00</cell><cell>-</cell></row><row><cell cols="4">further and attain deeper coverage. The generated conditional state-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">ments had a 50% satisfiability probability given a random input</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">value. Of course, some of the conditional statements were nested</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">in the synthetic apps, resulting in a lower probability of satisfying</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>certain paths.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">The line coverage results are summarized in Figure</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This is because above 10,000 events Dynodroid needs more than 3.4GB memory, which is more than the maximum memory size the 32-bit virtual machine that Georgia Tech researchers provided us for our experimentation could support.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">ACKNOWLEDGMENTS</head><p>We would like to thank Aravind Machiry and Mayur Naik at Georgia Tech for helping us with the setup of Dynodroid. This work was supported in part by awards W911NF-09-1-0273 from the US Army Research Office, D11AP00282 from the US Defense Advanced Research Projects Agency, and CCF-1252644 from the US National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://developer.android.com/guide/topics/fundamentals.html" />
		<title level="m">Android developers guide</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://developer.android.com/tools/help/emulator.html" />
		<title level="m">Android emulator | android developers</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://developer.android.com/guide/developing/tools/monkey.html" />
		<title level="m">Android monkey</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="http://developer.android.com/guide/topics/testing/index.html" />
		<title level="m">Android testing framework</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><surname>Apktool</surname></persName>
		</author>
		<ptr target="http://code.google.com/p/android-apktool/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="http://code.google.com/p/dalvik/" />
		<title level="m">Dalvik -code and documentation from android&apos;s VM team</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dedexer</surname></persName>
		</author>
		<ptr target="http://dedexer.sourceforge.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="http://code.google.com/p/dex2jar/" />
		<title level="m">Dex2jar</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<ptr target="http://cs.gmu.edu/eclab/projects/ecj/" />
		<title level="m">Ecj</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><surname>Emma</surname></persName>
		</author>
		<ptr target="http://emma.sourceforge.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="http://www.sdalab.com/projects/evodroid" />
		<title level="m">Evodroid:segmented evolutionary testing of android apps</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F-Droid</forename></persName>
		</author>
		<ptr target="https://f-droid.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><surname>Modisco</surname></persName>
		</author>
		<ptr target="http://www.eclipse.org/modisco/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="http://pivotal.github.com/robolectric/" />
		<title level="m">Robolectric</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<ptr target="http://code.google.com/p/robotium/" />
		<title level="m">Robotium</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="http://code.google.com/p/smali/" />
		<title level="m">Smali</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective generation of test cases using genetic algorithms and optimization theory</title>
		<author>
			<persName><forename type="first">I</forename><surname>Alsmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alkhateeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Maghayreh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Doush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Communication and Computer</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="72" to="82" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A gui crawling-based technique for android mobile application testing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Amalfitano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fasolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tramontana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Testing, Verification and Validation Workshops (ICSTW), 2011 IEEE Fourth International Conference on</title>
		<imprint>
			<date type="published" when="2011-03">March 2011</date>
			<biblScope unit="page" from="252" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using gui ripping for automated testing of android applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Amalfitano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Fasolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tramontana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>De Carmine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Memon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering, ASE 2012</title>
		<meeting>the 27th IEEE/ACM International Conference on Automated Software Engineering, ASE 2012</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="258" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automated concolic testing of smartphone apps</title>
		<author>
			<persName><forename type="first">S</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Harrold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE &apos;12</title>
		<meeting>the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE &apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spacemaker: Practical formal synthesis of tradeoff spaces for object-relational mapping</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Son</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Software Engineering and Knowledge Engineering</title>
		<meeting>the 24th International Conference on Software Engineering and Knowledge Engineering</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="688" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Testful: An evolutionary test approach for java</title>
		<author>
			<persName><forename type="first">L</forename><surname>Baresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miraz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Third International Conference on Software Testing, Verification and Validation, ICST &apos;10</title>
		<meeting>the 2010 Third International Conference on Software Testing, Verification and Validation, ICST &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="185" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A metaheuristic approach to test sequence generation for applications with a gui</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bauersfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wappler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wegener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Search Based Software Engineering, SSBSE&apos;11</title>
		<meeting>the Third International Conference on Search Based Software Engineering, SSBSE&apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="173" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automated software testing as a service</title>
		<author>
			<persName><forename type="first">G</forename><surname>Candea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bucur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zamfir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM Symposium on Cloud Computing, SoCC &apos;10</title>
		<meeting>the 1st ACM Symposium on Cloud Computing, SoCC &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="155" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Guided gui testing of android apps with minimal restart and approximate learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications, OOPSLA &apos;13</title>
		<meeting>the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp; Applications, OOPSLA &apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="623" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cloud9: A software testing service</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ciortea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zamfir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bucur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chipounov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Candea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5" to="10" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exsyst: Search-based gui testing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE), 2012 34th International Conference on</title>
		<imprint>
			<date type="published" when="2012-06">June 2012</date>
			<biblScope unit="page" from="1423" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Search-based system testing: High coverage, no false alarms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 International Symposium on Software Testing and Analysis</title>
		<meeting>the 2012 International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="67" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automating gui testing for android applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Neamtiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Automation of Software Test, AST &apos;11</title>
		<meeting>the 6th International Workshop on Automation of Software Test, AST &apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="77" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improving structural testing of object-oriented programs via integrating evolutionary testing and symbolic execution</title>
		<author>
			<persName><forename type="first">K</forename><surname>Inkumsah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 23rd IEEE/ACM International Conference on Automated Software Engineering, ASE &apos;08</title>
		<meeting>the 2008 23rd IEEE/ACM International Conference on Automated Software Engineering, ASE &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automated testing with targeted event sequence generation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Møller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 International Symposium on Software Testing and Analysis</title>
		<meeting>the 2013 International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="67" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynodroid: An input generation system for android apps</title>
		<author>
			<persName><forename type="first">A</forename><surname>Machiry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tahiliani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2013</title>
		<meeting>the 2013 9th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="224" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Testing android apps through symbolic execution</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mirzaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Pȃsȃreanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Esfahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGSOFT Softw. Eng. Notes</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fully automated gui testing and coverage analysis using genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaffar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Shahid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovative Computing, Information and Control (IJICIC)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Google android: A comprehensive security assessment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shabtai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fledel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kanonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Elovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dolev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glezer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Security and Privacy</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="35" to="44" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Evolutionary testing of classes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tonella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA &apos;04</title>
		<meeting>the 2004 ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Using evolutionary algorithms for the unit testing of object-oriented software</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wappler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lammermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation, GECCO &apos;05</title>
		<meeting>the 7th Annual Conference on Genetic and Evolutionary Computation, GECCO &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1053" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A grey-box approach for automated gui-model generation of mobile applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Fundamental Approaches to Software Engineering, FASE&apos;13</title>
		<meeting>the 16th International Conference on Fundamental Approaches to Software Engineering, FASE&apos;13</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="250" to="265" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
