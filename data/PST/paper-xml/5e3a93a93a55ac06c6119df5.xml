<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaborative Distillation for Top-N Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-11-13">13 Nov 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jae-Woong</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minjin</forename><surname>Choi</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jongwuk</forename><surname>Lee</surname></persName>
							<email>jongwuklee@skku.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hyunjung</forename><surname>Shim</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Sungkyunkwan University Republic of Korea</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Yonsei University Republic of Korea</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Collaborative Distillation for Top-N Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-11-13">13 Nov 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1911.05276v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>knowledge distillation</term>
					<term>top-N recommendation</term>
					<term>collaborative filtering</term>
					<term>data sparsity</term>
					<term>data ambiguity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge distillation (KD) is a well-known method to reduce inference latency by compressing a cumbersome teacher model to a small student model. Despite the success of KD in the classification task, applying KD to recommender models is challenging due to the sparsity of positive feedback, the ambiguity of missing feedback, and the ranking problem associated with the top-N recommendation. To address the issues, we propose a new KD model for the collaborative filtering approach, namely collaborative distillation (CD). Specifically, (1) we reformulate a loss function to deal with the ambiguity of missing feedback.</p><p>(2) We exploit probabilistic rank-aware sampling for the top-N recommendation. (3) To train the proposed model effectively, we develop two training strategies for the student model, called the teacher-and the student-guided training methods, selecting the most useful feedback from the teacher model. Via experimental results, we demonstrate that the proposed model outperforms the state-of-the-art method by 2.7-33.2% and 2.7-29.1% in hit rate (HR) and normalized discounted cumulative gain (NDCG), respectively. Moreover, the proposed model achieves the performance comparable to the teacher model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Neural recommender models <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b8">[9]</ref> have achieved better performance than conventional latent factor models either by capturing non-linear and complex correlation patterns among users/items, or by leveraging the hidden features extracted from auxiliary information such as texts and images. However, the number of model parameters of neural models is greater than that of conventional models by one or more orders of magnitude. This indicates a trade-off between accuracy and efficiency. As a result, neural recommender models usually suffer from higher latency during the inference phase.</p><p>Our primary goal is to develop a recommender model that achieves a balance between effectiveness and efficiency. In this paper, we employ knowledge distillation (KD) <ref type="bibr" target="#b9">[10]</ref> which is a network compression technique by transferring the distilled knowledge of a large model (a.k.a., a teacher model) to a small model (a.k.a., a student model). As the student model can utilize the knowledge transferred from the teacher model, it naturally exhibits the properties of computational efficiency and low memory usage. Therefore, it is capable of achieving a balance between effectiveness and efficiency.</p><p>Specifically, the training procedure for KD consists of two steps. In the offline training phase, the teacher model is supervised by a training dataset with labels. Then, the student model is learned to optimize two objectives: matching the label of a training sample (i.e., a hard target) with that of model prediction and matching the label distribution (i.e., a soft target) of the teacher model with that of the student model. In the inference phase, we utilize the student model. Because the teacher model possesses greater modeling power than the student model, the soft target serves as useful additional information for training the student model. The student model trained with KD can perform better than the student model only trained with the training set.</p><p>Despite the significant success of KD in the classification task, it is non-trivial to incorporate it into recommender models. More concretely, applying KD to recommender models involves several challenges: (1) Implicit user feedback is extremely sparse. <ref type="bibr" target="#b1">(2)</ref> As users only provide positive feedback in implicit datasets, there is inherent ambiguity regarding unknown (or missing) feedback. That is, unknown feedback can be unlabeled positive or negative feedback. Such characteristics naturally require us to distinguish positive/negative feedback from unknown feedback. (3) Because a few topranked items are of interest to top-N recommendation, we should consider the degrees of importance of items based on their rankings.</p><p>Recently, Tang and Wang <ref type="bibr" target="#b10">[11]</ref> proposed a KD model to address the ranking problem, called rank distillation (RD). RD uses only a few items with the highest rankings in the label distribution learned from the teacher model. Then, it manipulates them to positive feedback. In this sense, RD regards the knowledge transferred from the teacher model as augmented positive feedback, which helps alleviate the data sparsity problem associated with top-N recommendation.</p><p>Although RD improves the prediction accuracy of the student model, it is sub-optimal because some vital information in the soft target is ignored. First, the manipulation of the soft target in RD is only involved in generating additional positive feedback with the highest rankings. The key intuition of KD is that various correlations among items can provide additional information. In this regard, manipulating the soft target can distort the meaningful correlation patterns among items. Second, RD simply discards negative feedback with low rankings in the soft target. Removing low-ranked items from the soft target can make the process blind to negative user feedback. Therefore, both strategies in RD are counterintuitive to the original idea of KD as they do not maintain the correlations among the items revealed in the soft target.</p><p>In this paper, we propose a new knowledge distillation model for collaborative filtering (CF), namely collaborative distillation (CD). Our model enjoys the advantages of both KD and RD. Specifically, the novelty of our model comes from the following aspects.</p><p>Reformulating a loss function for CF. We design the CF model by revisiting the ambiguity of data representation. To resolve this issue, we propose a simple but improved CF loss function that only accounts for positive feedback. That is, unknown feedback is explicitly removed from the CF loss function. We claim that the presence of unknown feedback in the CF loss function can bias the prediction of ratings. As common implicit data representations treat unknown feedback as zero at all times, their predictions lean toward zero. By excluding unknown feedback from the CF loss function, we can prevent the prediction bias, thereby improving the overall performance of the student model.</p><p>Probabilistic rank-aware sampling. Our model is influenced by the idea of RD, treating items differently based on their rankings. In the ranking problem, the higher-ranked items are more important because they can be potential inclusions in top-N recommendation. Therefore, we sample items in the soft target according to their rankings; the higher the ranking, the more the items are sampled. Because we sample both highand low-ranked items in a probabilistic manner, our model can learn both positive/negative correlations among items. Therefore, we can take advantage of RD that considers the ranking order of items. Meanwhile, our method effectively overcomes the disadvantage of RD that ignores negative feedback among items. Besides, we rigorously preserve the idea of KD in the proposed model, because the probabilities in the soft target are used without manipulation. This enables us to fully exploit the correlations of items in the soft target. We believe that understanding the hidden correlations of items is crucial to overcome data sparsity and ambiguity problems.</p><p>Two training tactics in the student model. Lastly, we develop two training tactics for the student model, called teacherand student-guided methods. The teacher-guided method simply provides the soft target with the student model as in the conventional KD. In contrast, the student-guided method actively requests the useful items in the soft target to the teacher model by considering the training status of the student model. In other words, the student-guided method trains the student model by dynamically reflecting its status.</p><p>We conduct extensive experiments over the four benchmark datasets -Amazon Music (AMusic), MovieLens 100k (ML100K), Yelp, and Gowalla. Through experimental results, we demonstrate that the proposed model significantly outperforms the state-of-the-art model (i.e., RD). Furthermore, the performance of the proposed model is comparable to that of the teacher model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRELIMINARIES</head><p>In this section, we first introduce the basic notations and formulate the top-N recommendation problem. Then, we explain the concept of knowledge distillation (KD) <ref type="bibr" target="#b9">[10]</ref> and present rank distillation (RD) <ref type="bibr" target="#b10">[11]</ref> that applies knowledge distillation to recommender models. Problem statement. For a set of users U = {u 1 , . . . , u m } and a set of items I = {i 1 , . . . , i n }, we are given a useritem matrix R ∈ {1, 0} m×n , where r ui ∈ R is the implicit user feedback represented by a binary (i.e., positive/negative) value assigned by user u ∈ U to item i ∈ I. If r ui = 1, it indicates known (or observed) feedback, implying positive user experience. Otherwise (i.e., r ui = 0), it indicates missing (or unobserved) feedback, implying a mixture of unlabeled positive/negative preferences. Such ambiguity has been explicitly discussed in one-class collaborative filtering (OCCF) <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b18">[19]</ref>. Given user u, I + u = {i ∈ I|r ui = 1} is the set of items with known positive feedback, and I − u = I\I + u is the set of items with missing feedback.</p><p>Our goal is to find a ranked list of the top-N items from implicit user feedback. Given user u, we need to rank the items (i.e., i ∈ I − u ) according to their unknown preference scores. To achieve this goal, we define a ranking model M (u, i; θ) with a set of model parameters θ and compute a predicted preference score rui for each user u and for each item i.</p><p>The ranking loss function can be categorized into three cases: point-wise, pair-wise, and list-wise. In this paper, we focus on the point-wise loss, which is usually defined by the negative log likelihood of binary preference scores.</p><formula xml:id="formula_0">L(θ) = − i∈I + u log (P (r = 1|u, i)) + i∈I − u log (1 − P (r = 1|u, i) ,<label>(1)</label></formula><p>where rui = P (r = 1|u, i) represents the probability of item i being preferred by user u.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge distillation (KD)</head><p>. This is a model-independent knowledge transfer framework designed to deliver the knowledge extracted from a complex teacher model to a simple student model. Many existing studies <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b27">[28]</ref> have utilized KD to compress deep neural networks as well as to achieve stable performances by distilling the knowledge from teacher model. In this process, KD makes use of a logit, called a soft target, which encodes the result values at the last layer before passing to the final activation layer. The success of KD can be attributed to the exploitation of hidden inter-class correlations in the soft target. Because the soft target reveals rich information, i.e., positive/negative correlations among items, the student model influenced by soft targets performs better than the same model trained only with ground-truth labels, called a hard target.</p><p>The original KD and its variants are mainly developed in the context of the classification problem. They no longer remain valid in the top-N recommendation problem because Fig. <ref type="figure">1</ref>. Illustration of rank distillation (RD) <ref type="bibr" target="#b10">[11]</ref>. The teacher model transfers manipulated top-k items as the distilled knowledge to the student model. of two reasons. First, many recommender models focus on solving the ranking problem; they aim to find the top-N items that the user most prefers. Although the label representation from both recommender and classification models is the same as the binary vector, the significance of each quantity is entirely different. In the classification model, both 0 and 1 are treated equally. Meanwhile, because the top-N recommendation model determines high-ranked items, it needs to place more weights on the responses to 1.</p><p>Second, the recommender model needs to handle the ambiguity of missing feedback. Unlike the classificaton problem, missing feedback in the top-N recommendation problem can be either truly negative or hidden positive responses (i.e., preferred but unknown). When the teacher model regards all missing feedback as negative labels, the soft targets may be contaminated and be unable to bring for informative correlations between items. Consequently, the student model using the soft target may have worse performance than the original student model. Rank distillation (RD). Tang and Wang <ref type="bibr" target="#b10">[11]</ref> proposed ranking distillation (RD) that applies KD for ranking models. As depicted in Fig. <ref type="figure">1</ref>, RD minimizes two losses: a ranking loss with respect to the ground-truth ranking in the training dataset and a distillation loss with respect to the top-k ranking of unlabeled items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L(θ</head><formula xml:id="formula_1">S ; θ T ) = (1 − ρ)L CF (θ S ) + ρL KD (θ S ; θ T ),<label>(2)</label></formula><p>where ρ is the hyperparameter to balance two losses, and θ S and θ T are model parameters for the teacher and student models, respectively. L CF (•) is the ranking loss function for CF models and L KD (•) is the distillation loss function that guides the student model. For both ranking and distillation losses, RD employs the cross-entropy function using the negative log likelihood. where P (r = 1|u, i; θ S , θ T ) is the preference probability of user u for item i in the soft target, {π 1 , . . . , π K } indicates the top-K items with missing feedback predicted by the teacher model, and w i is the importance weight to each item i.</p><formula xml:id="formula_2">L CF (θ S ) = − i∈I + u log (P (r = 1|u, i)) + i∈I − u log (1 − P (r = 1|u, i) ,<label>(3)</label></formula><formula xml:id="formula_3">L KD (θ S ; θ T ) = − i∈{π1,...,π K } w i log (P (r = 1|u, i; θ S , θ T )),<label>(4)</label></formula><p>Although RD addresses the ranking problem, it still suffers from several limitations. First, RD regards all missing feedback as negative feedback for the CF loss function in Equation ( <ref type="formula" target="#formula_2">3</ref>). Second, RD only makes use of top-K ranked items in a deterministic manner, and merely ignores the other items in I − u . As a result, the KD loss function in Equation ( <ref type="formula" target="#formula_3">4</ref>) includes no negative feedback. Lastly, RD modifies real-valued soft targets to positive feedback. The real-valued scores belong to the interval [0, 1], and encode relative user preferences for items. Unfortunately, because RD quantizes all top-K ranked items to positive feedback, it loses finer degrees of positive correlations among items learned from the teacher model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED MODEL</head><p>In this section, we propose a new knowledge distillation model for CF, namely collaborative distillation (CD) (Section III-A). Specifically, we first formulate a new CF loss function to address the ambiguity of missing feedback (Section III-B). Second, we design a probabilistic rank-aware sampling method to choose the items with unknown feedback (Section III-C). Lastly, we develop two training strategies for the student model, called teacher-and student-guided training strategies, to select the most beneficial label distributions from the teacher model (Section III-D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>Fig. <ref type="figure" target="#fig_0">2</ref> describes the overall procedure of our proposed model. Similar to the original KD, the training procedure of our model consists of two steps. First, we train a large teacher model M (u, i; θ T ) using a training dataset and its hard labels. The teacher model can be either a single CF model or an ensemble model combining multiple CF models. Once the training of the teacher model is completed, we can obtain the predicted preference scores for all unrated items in the teacher model. Then, we utilize both hard and soft targets for training a small student model M (u, i; θ S , θ T ).</p><p>In this process, we face the following challenges. In implicit datasets, user preferences are expressed in the form of posi-tive/negative feedback. However, due to the nature of implicit data, we only observe sparse positive feedback. Besides, unlike the classification problem, the top-N recommendation is closely associated with the ranking problem. Therefore, the presence of a few top-N items among a block of unknown feedback should be further investigated.</p><p>To overcome these challenges, we first suggest an improved CF loss function, which considers the uncertainty in data representation of hard labels. Moreover, we utilize KD as a robust framework to address the ambiguity of unknown feedback. To this end, we extract two valuable pieces of information from the soft target of the teacher model: both positive/negative correlations among items and the candidates for high-ranked items. Our competitor, RD, manipulates the soft target to extract the rankings of items and uses it to define their KD loss function. As it is desirable that the ranking should reflect in the formulation of the CF, we place greater weight on higher-ranked items. We thus introduce a probabilistic rank-aware sampling method. It is interesting to note that RD has the drawback of sacrificing the precision of positive correlation and ignoring negative correlations between items. Unlike RD, we allow the ranking of items to reflect in KD and both positive and negative correlations to be utilized for the supervision of the student model.</p><p>Based on this idea, we reformulate the loss function for our model as a combination of the CF loss function and the KD loss function.</p><formula xml:id="formula_4">L(θ S ; θ T ) = L CF (θ S ) + λL KD (θ S ; θ T ).<label>(5)</label></formula><p>In the following sections, we explain the details of each loss function along with their design principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Collaborative Filtering Loss</head><p>We design an improved collaborative filtering loss function to overcome the uncertainty of implicit data representation in CF. Both traditional KD and RD suggest computing the loss function from hard labels using the cross-entropy between the predicted label distribution and its hard label distribution. This method arguably treats all values of the label distribution equally importantly. However, positive feedback (i.e., 1) indicates a preference, whereas negative feedback (i.e., 0) can be either 1 or 0. We argue that, in terms of its confidence, the weight for 1 should be much greater than the weight for 0. Besides, treating all values equally in the cross-entropy loss function induces the model prediction to be biased toward 0. To prevent this bias in prediction, we devise a selective crossentropy loss function, which only matches items corresponding to 1.</p><formula xml:id="formula_5">L CF (θ S ) = − i∈I + u log P (r = 1|u, i) .<label>(6)</label></formula><p>One might ask whether the method of predicting only 1 can be applied to the training of the teacher model. Unfortunately, it always results in the prediction being 1, which leads to a new bias. Thus, it is undesirable to apply the same strategy for the teacher model. Meanwhile, since the KD loss function provides positive/negative feedback for the training of the student model, the prediction is no longer biased in the proposed CF loss function. As a result, without the concern about training instability, the proposed CF loss function can provide more accurate feedback and eliminate the ambiguity of unknown feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Knowledge Distillation Loss</head><p>We devise a sampling-based KD loss function that not only distinguishes positive/negative feedback from missing feedback but also captures a user's relative preferences between items.</p><formula xml:id="formula_6">L KD (θ S ; θ T ) = − i∈S(I − u )</formula><p>q ui log P (r = 1|u, i)</p><formula xml:id="formula_7">+ (1 − q ui ) log 1 − P (r = 1|u, i) ,<label>(7)</label></formula><p>where q ui is a probability converted from the logit z ui and S(I − u ) is an item set sampled from I − u . (We will explain how to compute q ui and how to identify S(I − u ) later.) The proposed KD loss function is different from that of RD in Equation ( <ref type="formula" target="#formula_3">4</ref>) in terms of two aspects. First, it utilizes the original soft target q ui just like the original KD. That is, it reflects both positive and negative correlations among items in the KD loss function. Second, the proposed loss function is computed by drawing the sampled items in a probabilistic manner.</p><p>In this process, the sampling method is critical for the KD loss function. One baseline method can be a random sampling, which learns the soft target regardless of the target values. Random sampling helps to reflect a user's relative preferences among different items. However, because it does not highlight the items with the highest rankings, it is inappropriate for top-N recommendation.</p><p>To explain our intuition, we first present several considerations: (1) Most of the items corresponding to unknown feedback represent negative preferences. Therefore, the randomly sampled items are likely to be biased toward negative preferences. (2) Although we can distinguish items with positive preferences from those with missing feedback, they should not be ranked higher than ones with known positive responses. Whereas the items with known positive feedback provide true positive experiences, the inferred positive feedback from the soft target might be incorrect or uncertain. (3) Items with positive scores in the soft target are likely to have positive correlations with the item for that soft target. Although the items with missing feedback might be uncertain, we believe that the soft target is still useful to capture relative preferences among items.</p><p>Based on these considerations, we develop a probabilistic rank-aware sampling method. The probability of sampling the item i from I − u is determined by the ranking order among all unrated items, normalized by the total number of unrated items. We denote the importance of item i by π(i).</p><formula xml:id="formula_8">π(i) = rank(i) |I − u | ,<label>(8)</label></formula><p>Algorithm 1: Rank-aware linear sampling Input: Teacher model M T (u, i; θ T ), unlabeled item set I − u , sampling size K Output: Sampled item set S(I − u ) of size K 1 Compute all scores of unlabeled items in I − u using M T (u, i; θ T ).</p><p>2 Sort all unlabeled items by descending order of scores. where rank(i) is the relative ranking position of item i in I − u . That is, rank(i) = 1 denotes the highest ranking position and rank(i) = |I − u | denotes the lowest ranking position. To draw a sample from unrated items, we investigate a rank-aware sampling function. First, we compute the sampling probability using a linear function of the relative ranking position. To implement rank-aware linear sampling efficiently, we employ a rejection-based sampling method using rankings.</p><formula xml:id="formula_9">p i ∝ 1 − π(i).<label>(9)</label></formula><p>We can extend it to a non-linear sampling function using an exponential function. With this adaptation, a few items with top-ranked positions have a much higher probability of being sampled than the others. The probabilities of the remaining items drop rapidly. This non-linear sampling function is formulated by:</p><formula xml:id="formula_10">p i ∝ 1 e γπ(i) , (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where γ is the hyperparameter used to control the slope of the exponential function. The value is proportional to the gap between the top-ranked items and remaining ones. Algorithm 1 describes the pseudo-code for a rank-aware linear sampling method. In order to support exponential sampling, we can also modify uniform sampling (line 4). This sampling method is used in our proposed training strategies.</p><p>Temperature in the KD loss. One key factor of the original KD <ref type="bibr" target="#b9">[10]</ref> is to find a proper balance between the soft targets and hard labels. To tackle this issue, <ref type="bibr" target="#b9">[10]</ref> introduces the notion of a temperature T . Although the soft target is a useful resource for educating the student model, its distribution is often too sharp. In this case, because the relative correlation among items is not highlighted as much, the impact of KD is less significant.</p><p>When a softmax layer is the final output activation layer, it converts the logit z i to q i weighted by the temperature.</p><formula xml:id="formula_12">q i = e zi/T j e zj /T ,<label>(11)</label></formula><p>where the temperature T is directly proportional to the smoothness of the output probability distribution.</p><p>In this paper, we choose the point-wise approach for defining the user preference of items. Point-wise preferences are computed by a logistic function, which is a particular case of the softmax function. The logistic function is used to map a real-valued score to the probability of an item to be preferred (r = 1) as follows.</p><formula xml:id="formula_13">p ui = P (r = 1|u, i) = 1 1 + e −zui ,<label>(12)</label></formula><p>where z ui is the real-valued logit to user u for item i.</p><p>Whereas the classification algorithm produces class probabilities using the softmax output layer, our problem can be regarded as a binary classification problem for each item. Then, the temperature for the logistic function is adopted using logits.</p><formula xml:id="formula_14">q ui = P (r = 1|u, i) = 1 1 + e − z ui +T 2 T 1 ,<label>(13)</label></formula><p>where T 1 and T 2 are the parameters for the temperature. T 1 controls the scale and T 2 controls the shift of z ui . Although a more advanced function for temperature can be employed, we choose a relatively simple form of T 1 and T 2 . We leave the formulation of various temperature functions as our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Interactive Training Tactics</head><p>We In contrast, the student-guided training takes into account requests from the student model during training. That is, the student model examines its soft targets during training and draws several items according to the probabilistic rank-aware sampling method. Then, the student model asks the teacher model for the predictions (i.e., preference scores) of those items. In this way, the student model can instantly update the feedback of the high-ranked items from the teacher model. This idea is inspired by the idea of an interactive Q&amp;A section in the classroom, where students learn more efficiently by asking questions to their teachers. One may argue that the student model might not create meaningful questions during the early stage of its training. However, stupid questions are still better than random questions. Besides, student-guided training is advantageous because it helps to find an effective path for the training of the student model. We believe that this interactive training tactic helps om the fast convergence of model training and in approaching the improved solution via a better update path.</p><p>Note that the proposed training tactics are also used with our sampling method described in Section III-C. Even with the different sampling method, the adoption of the student-guided training is still suitable. That is, the student model can draw the items by any sampling method and then request for the feedback for those items from the teacher model. The process of each training tactic is as follows: Teacher-guided training. We choose the soft target from the ranking order in the teacher model. Therefore, the teacher model selects the sampled items without the intervention of the student model. Without any interaction between the two models, the student model learns the items selected by the teacher model. Student-guided training. We choose the items from the soft target of the student model using the probabilistic rank-aware sampling method, as depicted in Fig. <ref type="figure" target="#fig_3">3</ref> IV. EXPERIMENTS A. Experimental Setup Datasets. We performed extensive experiments over the public benchmark datasets -Amazon Music<ref type="foot" target="#foot_0">1</ref> (AMusic), MovieLens 100K<ref type="foot" target="#foot_1">2</ref> (ML100K), Yelp<ref type="foot" target="#foot_2">3</ref> , and Gowalla <ref type="foot" target="#foot_3">4</ref> . We converted all ratings to a binary representation; either a user experiences an item positively or does not. These four datasets were selected to span over various degrees of data sparsity. Considering all the observed feedback as positive feedback, our goal was to identify the top-N recommendation for implicit datasets. As preprocessing, we filtered out the users who had less than 10 ratings and the items that were rated by less than 5 users. Table I reports the detailed statistics of these datasets.</p><p>• RD <ref type="bibr" target="#b10">[11]</ref>: To define the KD loss in equation ( <ref type="formula" target="#formula_3">4</ref>), this utilizes only the top-K items of the soft target by quantizing their values to 1. • RD-Rank: This employs the same loss function for RD as in Equation ( <ref type="formula" target="#formula_1">2</ref>), but selects the items for the KD loss function in Equation ( <ref type="formula" target="#formula_3">4</ref>) using rank-aware sampling. • CD-Base: This is our proposed model using CD as in Equation ( <ref type="formula" target="#formula_4">5</ref>) but selects the items for the KD loss in Equation ( <ref type="formula" target="#formula_7">7</ref>) using random sampling. • CD-TG: This is our proposed model using teacher-guided model training.</p><p>• CD-SG: This is our proposed model using student-guided model training. To validate the proposed model, we chose two state-ofthe-art recommender models-CDAE <ref type="bibr" target="#b7">[8]</ref> and Caser <ref type="bibr" target="#b6">[7]</ref>. (This paper focuses on top-N recommender models with point-wise preferences. We leave the evaluation for other models with pair-wise preferences, e.g., NPR <ref type="bibr" target="#b8">[9]</ref>, to future work.) Although the teacher model can be an ensemble model combining multiple models, we focused on verifying our model for the simple case. Finally, the same recommender models having high complexity and low complexity were chosen for the teacher and the student model, respectively. Note that this setting is consistent with existing KD studies.</p><p>Evaluation protocol. We adopted the leave-one-out evaluation <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>. Specifically, we held-out the last timestamp useritem interaction as the test data for each user, and the rest of user-item interactions are used for training data. Unlike sampling-based evaluation <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref> that randomly chose 100 items from the set of unrated items, we chose all unrated items as the candidate items. We believe that this evaluation protocol is time-consuming but more thorough.</p><p>Evaluation metrics. We measured the accuracy of top-N recommendation for two metrics, hit rate (HR) and normalized discounted cumulative gain (NDCG), as done in existing studies <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>. The size N of the ranked list was chosen to be 50 for HR@N and NDCG@N, respectively. HR@N examines whether or not the test item is present in the top-N list, and NDCG@N places more weights on higher-ranked items than others in the top-N list. In both metrics, the value is proportional to the accuracy of the result. Both metrics are averaged across all users.</p><p>Reproducibility. To ensure a fair evaluation, each hyperparameter and regularization term was fine-tuned and shared among all KD models. We randomly initialized model parameters using Gaussian distribution N (0, 1). Specifically, each baseline CF model had the following hyperparameters.</p><p>• CDAE <ref type="bibr" target="#b7">[8]</ref>: The latent dimensions for the teacher and the student model were 100 and 10, respectively. We set the number of negative sampling items to be 0.5*|I u | and the denoising ratio as 0.1. We used the Adagrad optimizer with learning rate = 0.2, l2-regularizer = 0.001, and batch size = 256. • Caser <ref type="bibr" target="#b6">[7]</ref>: The latent dimensions for the teacher and the student model were 50 and 5, respectively. We set sequence length L to be 5, target length T to be 1, and the number of negative sampling items to be 3. We used the Adam optimizer with learning rate = 0.001, l2-regularizer = 0.000001, dropout ratio = 0.5, and batch size = 512. For all KD models, the hyperparameters ρ and λ were controlled to properly reflect both CF and KD loss functions. For RD and RD-Rank, we used the public implementation of RD <ref type="foot" target="#foot_4">5</ref> . Also, the values of most hyperparameters were equal to their default values in public implementation. Note that there is a difference between λ that appears in RD and CD. Specifically, we used the following parameter settings.</p><p>• RD <ref type="bibr" target="#b10">[11]</ref> and RD-Rank: We set ρ to be 0.5. For CDAE, the number of items in the soft target was 15. For Caser, the number of items in the soft target was 10. • CD-Base, CD-TG and CD-SG: We set λ to be 0.5. For CDAE, we set T 1 to be 2 and T 2 to be 1. For ML100k, we set sampling size K to be 0.8*|I u |. For other datasets, we set K to be 0.5*|I u |. For Caser, we set T 1 to be 1, T 2 to be 0, and sampling size K to be 50.</p><p>Environments. We implemented our model and baseline models using TensorFlow 1.9.0 (CDAE) and PyTorch 1.0.0 (Caser). For Caser, we used the public PyTorch implementation <ref type="foot" target="#foot_5">6</ref> provided in <ref type="bibr" target="#b10">[11]</ref>. All experiments were conducted on a desktop with 128 GB memory and 2 Intel Xeon Processor E5-2630 v4 (2.20 GHz, 25M cache), and all models were trained using 4 Nvidia GeForce GTX 1080Ti.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results</head><p>Overall results. Table <ref type="table">II</ref> reports the performance of several variants of our model (i.e., CD-Base, CD-TG and CD-SG) and baseline models (i.e., RD, and RD-Rank). Among the four benchmark datasets, we compare KD models with the two baseline CF models. Teacher and student models indicate the baseline CF model with different parameters without KD. Also, the gain indicates how additional accuracy achieved by the proposed model over that of RD <ref type="bibr" target="#b10">[11]</ref>.</p><p>Based on this evaluation, we found several interesting observations. Firstly, both CD-TG and CD-SG significantly outperform RD over all datasets. Note that the improvement gap for RD is somewhat different from that in <ref type="bibr" target="#b10">[11]</ref>. It is because we used leave-one-out evaluation while <ref type="bibr" target="#b10">[11]</ref> used cross-validation evaluation. Our models are consistently better than RD by 2.7-33.2% and 2.7-29.1% in HR and NDCG, respectively. Also, CD-Base achieves better accuracy than RD. In this sense, our solution improves the CF loss function and helps boost the performance of top-N recommendation.</p><p>Secondly, CD-TG and CD-SG mostly achieve better accuracy than CD-Base. This implies that the rank-aware sampling method is more appropriate for addressing the ranking problem. However, RD-Rank tends to be comparable or slightly   worse than RD. We conjecture that this is because RD possesses a prediction bias toward negative feedback in the CF loss function. Since selecting top-K items in RD inherently induces the bias toward positive feedback, the bias in the original CF loss function helps to mitigate the sampling bias in RD. For this reason, RD-Rank is not as effective as our models. As the CF loss function in CD is not influenced by missing feedback, unlike RD, our models do not compensate for the negative bias by introducing a positive bias. As a result, our sampling strategy in the KD loss function is useful for boosting the prediction accuracy.</p><p>Lastly, our models consistently show improvements for two CF models with different architectures; while CDAE is based on the autoencoder for the offline recommendation, Caser is based on convolutional neural networks for a session-based recommendation. In particular, our models are most effective in AMusic. This dataset is relatively more sparse than the other datasets, implying that our models effectively overcome the data sparsity problem. Based on these results, we prove that our models can be extended to various CF models as model-agnostic solutions for CF.</p><p>Effects of model size. We evaluate the effect of the size of the student model. Fig. <ref type="figure" target="#fig_5">4</ref> depicts the relationship between model size and efficiency. The model size is proportional to the accuracy of our model, as observed in <ref type="bibr" target="#b10">[11]</ref> as well. The same tendency consistently holds in different CF models. In both CF models, ones of the small size perform comparably to the teacher model, where the model size is about 20% of the teacher model.</p><p>We further investigate the trade-off between model size and inference time. As depicted in Fig. <ref type="figure" target="#fig_6">5</ref>, as the model size increases, it requires greater amounts of inference time. This is reasonable because many model parameters require a higher computational cost. Compared to the teacher model, our models require less than about 50% of the inference time, even though they achieve comparable performances to the teacher model. It can be concluded that our models are capable of transcending the trade-off between effectiveness and efficiency. Lastly, Fig. <ref type="figure" target="#fig_7">6</ref> depicts the effects of CD-TG and CD-SG on each training step. Our models consistently outperform the student model at each step. The number of training steps is inversely proportional to the performance gap between our models and the teacher model. As depicted in Fig. <ref type="figure" target="#fig_7">6</ref>(d), CD-SG outperforms the teacher model even after 70 epochs.</p><p>Effect of model hyperparameters. Fig. <ref type="figure" target="#fig_8">7</ref> depicts NDCG@50 over varying hyperparameter λ for the KD loss function. In case of CD-SG, the best performance is achieved when λ is  around 0.1 in both datasets. Fig. <ref type="figure">8</ref> depicts the NDCG for various sampling ratios. For CDAE, we sample δ × |I − u | items from those with missing feedback. In both datasets, the best performance is achieved when δ is around 0.5 for CD-SG.For CD-TG, we also observed a similar tendency for λ.</p><p>For the sampling ratios δ, CD-TG is worse than CD-SG when δ is approximately 0.1-0.5. This implies that CD-SG is more effective than CD-TG when the sampling ratio is low. In this sense, CD-SG is advantageous owing to its nature of leading a better update path for low sampling ratios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELATED WORK</head><p>Model compression techniques. Balancing the effectiveness and efficiency of computational models is an fundamental issue for real-world applications. To address this problem, various techniques <ref type="bibr" target="#b28">[29]</ref> have been widely developed to compress cumbersome models into smaller ones. In general, existing work falls into three categories: (1) binarization and discretion, (2) pruning and sharing model parameters, and (3) knowledge distillation (KD).</p><p>First, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> proposed the binary encoding of model parameters. Under this method, real-valued model parameters are discretized via binary representation. Although the discretized model parameters incur the loss of accuracy, it can reduce the memory size and enhance efficiency. Second, the pruning and sharing method presented in <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref> removes or binds model parameters which are redundant or have minimal impacts in loss functions. In principle, these research directions focus on designing an efficient inference process using various computational acceleration techniques with low memory usage, thus mostly using model-dependent techniques.</p><p>Recently, KD is a model-independent learning framework that compresses a model by transferring the distilled knowledge of a large teacher model to a small student model. Various KD techniques have been proposed to improve the original KD toward two directions: (1) incorporating more information in addition to utilizing soft targets and (2) analyzing the loss function for KD.</p><p>The first trend is based on the intuition that the utilization of soft targets alone is not sufficient because meaningful intermediate information may be ignored during student training. FitNet <ref type="bibr" target="#b24">[25]</ref> first pointed out such limitation and suggested using the output of intermediate layers as additional matching criteria. Similarly, <ref type="bibr" target="#b25">[26]</ref> utilized the gram matrix of the channel responses from the teacher model as additional information to educate the student model. Net2Net <ref type="bibr" target="#b33">[34]</ref> employed model parameters of the teacher model directly to initialize those of the student model. Recently, <ref type="bibr" target="#b19">[20]</ref> used the attention map as an additional matching constraint. That is, in addition to the original loss term for matching the soft target, the attention map of the student model should match that of the teacher model. Most recently, <ref type="bibr" target="#b23">[24]</ref> further improved the attentionbased method by matching the gradients (i.e., Jacobians) of output activations for the input.</p><p>Along an alternative direction, several algorithms focused on analyzing the choice of loss functions for KD. <ref type="bibr" target="#b26">[27]</ref> observed that the distance-based loss is inappropriate for transferring activation boundaries, and thus suggested a hinge loss. <ref type="bibr" target="#b21">[22]</ref> and <ref type="bibr" target="#b22">[23]</ref> employed adversarial learning into the KD framework. Recently, KDGAN <ref type="bibr" target="#b20">[21]</ref> bypassed the convergence step of adversarial learning by employing a triple-player game <ref type="bibr" target="#b27">[28]</ref>. In this study, we develop an improved loss function for KD. Unlike existing models, we mainly focus on modifying the loss function of KD for top-N recommendation.</p><p>One-class collaborative filtering (OCCF). For implicit datasets, handling missing feedback that intrinsically delineates a mixture of positive/negative feedback is a non-trivial issue. To address this challenge, existing studies can be categorized into weight-based, sampling-based, and imputationbased methods. First, the weight-based method <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b15">[16]</ref> regards all missing feedback as negative ones. For instance, Hu et al. <ref type="bibr" target="#b11">[12]</ref> and Pan et al. <ref type="bibr" target="#b15">[16]</ref> controlled weights as the confidence of negative values with various schemes, such as uniform, user-oriented, and item-oriented methods. Second, Paquet and Koenigstein <ref type="bibr" target="#b14">[15]</ref> proposed a sampling-based method by considering the degree distributions of users/items in the graph. Lastly, Sindhwani et al. <ref type="bibr" target="#b12">[13]</ref> regarded unobserved feedback as optimization variables and imputed missing feedback via optimization. Besides, Li et al. <ref type="bibr" target="#b16">[17]</ref> leveraged side information to construct user-item similarity, and Zheng et al. <ref type="bibr" target="#b17">[18]</ref> employed multiple similarity matrices between users and items to predict drug-target interaction. Moreover, Yao et al. <ref type="bibr" target="#b18">[19]</ref> proposed dual regularization by combining the weighted-and imputation-based methods.</p><p>The proposed model is similar to the imputation method because the student model utilizes some inferred values for missing feedback. While the imputation-based method mainly focused on substituting missing feedback to improve the accuracy of top-N recommendation using auxiliary information, our model aims to balance the effectiveness and efficiency of top-N recommendation in the paradigm of KD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this study, we propose a new knowledge distillation model, namely collaborative distillation (CD), with implicit user feedback for top-N recommendation. Specifically, we address several challenges raised in top-N recommendation: data sparsity, the ambiguity of missing feedback, and the ranking problem. To overcome these challenges, we first introduce a new loss function for CF. Then, we deal with the ranking problem using the rank-aware sampling method. In this process, our model utilizes the soft target without manipulation to manage data sparsity. Furthermore, we devise teacherand student-guided training strategies to validate how the active/passive interactions between teacher and student models affect KD performance. Through extensive experiments, we demonstrate that the proposed model significantly outperforms the state-of-the-art model and several baseline models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of collaborative distillation (CD). The teacher model transfers the soft target to student model. We adopt probabilistic rank-aware sampling to place more weights for high-ranked items.</figDesc><graphic url="image-2.png" coords="3,311.98,50.54,251.06,123.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3 for i ∈ I − u do 4 Draw an item j uniformly from I − u with replacement. 5 if 6 S</head><label>456</label><figDesc>rank(i) &lt; rank(j) then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>investigate two training tactics for the student model: teacher-guided training and student-guided training. First, teacher-guided training is the process of learning from the teacher model, analogous to conventional KD training. The teacher model delivers the soft target to the student model without considering the training status of the student model. Then, the student model passively learns from those soft targets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of student-guided training. The student-guided training dynamically determines the teacher's soft target during student's inference.</figDesc><graphic url="image-3.png" coords="6,48.96,50.54,251.06,110.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>. The student model dynamically selects the sampled items. Specifically, during the training of the student model, the soft target of the student model is analyzed. At each training step, some items are drawn to represent the soft target of the student model. Then, the student model asks the teacher model for predictions corresponding to those selected items. Based on this interaction, the KD loss function is updated. In Algorithm 1, we can replace the teacher model M T (u, i; θ T ) with the student model M S (u, i; θ S ) (line 1) to consider the interactive results between the teacher model and the student model at each training step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. NDCG@50 across three different model sizes. XS, S, and M indicate 10%, 20%, 30% of the size of teacher model, respectively.</figDesc><graphic url="image-9.png" coords="8,185.13,170.28,118.23,77.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Online inference latency vs. model size. In both datasets, the inference latency is greatly reduced by decreasing the model parameters.</figDesc><graphic url="image-13.png" coords="8,185.13,290.01,118.23,77.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. NDCG@50 vs. the number of epochs. As the epoch increases, the performance gap between our model and teacher model is reduced.</figDesc><graphic url="image-12.png" coords="8,54.94,290.01,118.23,77.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. NDCG@50 vs. KD parameter λ (CDAE). In both datasets, our model is the best in λ = 0.1.</figDesc><graphic url="image-18.png" coords="9,54.94,177.02,118.23,77.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig.8. NDCG@50 vs. sampling ratio δ (CDAE). In both datasets, our model is the best in δ = 0.5.</figDesc><graphic url="image-19.png" coords="9,185.13,177.09,118.23,77.05" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">http://jmcauley.ucsd.edu/data/amazon/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://grouplens.org/datasets/movielens/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://github.com/hexiangnan/sigir16-eals</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">http://dawenl.github.io/data/gowalla pro.zip Competitive models. Since RD<ref type="bibr" target="#b10">[11]</ref> is the state-of-the-art KD model for top-N recommendation, we compare the proposed model with the original RD. Besides, we evaluated two baseline models, RD-Rank and CD-Base, modifying the sampling method for RD and CD, respectively. We also validate the effect of our rank-aware sampling in RD and CD.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://github.com/graytowne/rank distill</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">https://github.com/graytowne/caser pytorch</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This work was supported by the National Research Foundation of Korea (NRF) grant (No. NRF-2018R1A2B6009135 and NRF-2019R1A2C2006123) and the Institute of Information &amp; communications Technology Planning &amp; Evaluation(IITP) grant funded by the Korea government (MSIT) (No.2019-0-00421, AI Graduate School Support Program).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Autorec: Autoencoders meet collaborative filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web Companion</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="111" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional matrix factorization for document context-aware recommendation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender Systems (RecSys)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep matrix factorization models for recommender systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3203" to="3209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Outer productbased neural collaborative filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2227" to="2233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Personalized top-n sequential recommendation via convolutional sequence embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Search and Data Mining, (WSDM)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Search and Data Mining</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural personalized ranking for image recommendation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Web Search and Data Mining (WSDM)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="423" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1503.02531</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ranking distillation: Learning compact ranking models with high performance for recommender system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2289" to="2298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Collaborative filtering for implicit feedback datasets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM)</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">One-class matrix completion with low-density factorizations</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bucak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mojsilovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM)</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1055" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">One-class collaborative filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM)</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">One-class collaborative filtering with random graphs</title>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koenigstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conference (WWW)</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="999" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mind the gaps: weighting the unknown in largescale one-class collaborative filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving one-class collaborative filtering by incorporating rich user information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Information and Knowledge Management</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="959" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Collaborative matrix factorization with multiple similarities for predicting drug-target interactions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mamitsuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1025" to="1033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dual-regularized one-class collaborative filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Szymanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Conference on Information and Knowledge Management (CIKM)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="759" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03928</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kdgan: Knowledge distillation with generative adversarial networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="783" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Training shallow and thin networks for acceleration via knowledge distillation with conditional adversarial networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations Workshop</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adversarial learning of portable student networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Knowledge transfer with jacobian matching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00443</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A gift from knowledge distillation: Fast optimization, network minimization and transfer learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Knowledge transfer via distillation of activation boundaries formed by hidden neurons</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y J Y C</forename><surname>Byeongho Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minsik</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Triple generative adversarial nets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Chongxuan Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A survey of model compression and acceleration for deep neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno>abs/1710.09282</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Binaryconnect: Training deep neural networks with binary weights during propagations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3123" to="3131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Binarized neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4107" to="4115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Data-free parameter pruning for deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="31" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Net2net: Accelerating learning via knowledge transfer</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
