<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking InfoNCE: How Many Negative Samples Do You Need?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-05-27">27 May 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
							<email>wuchuhan15@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering &amp; BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
							<email>wufangzhao@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
							<email>yfhuang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering &amp; BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking InfoNCE: How Many Negative Samples Do You Need?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-05-27">27 May 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2105.13003v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>InfoNCE loss is a widely used loss function for contrastive model training. It aims to estimate the mutual information between a pair of variables by discriminating between each positive pair and its associated K negative pairs. It is proved that when the sample labels are clean, the lower bound of mutual information estimation is tighter when more negative samples are incorporated, which usually yields better model performance. However, in many real-world tasks the labels often contain noise, and incorporating too many noisy negative samples for model training may be suboptimal. In this paper, we study how many negative samples are optimal for InfoNCE in different scenarios via a semi-quantitative theoretical framework. More specifically, we first propose a probabilistic model to analyze the influence of the negative sampling ratio K on training sample informativeness. Then, we design a training effectiveness function to measure the overall influence of training samples on model learning based on their informativeness. We estimate the optimal negative sampling ratio using the K value that maximizes the training effectiveness function. Based on our framework, we further propose an adaptive negative sampling method that can dynamically adjust the negative sampling ratio to improve InfoNCE based model training. Extensive experiments on different real-world datasets show our framework can accurately predict the optimal negative sampling ratio in different tasks, and our proposed adaptive negative sampling method can achieve better performance than the commonly used fixed negative sampling ratio strategy.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>InfoNCE <ref type="bibr" target="#b14">[15]</ref> loss is a popular choice of loss function for contrastive learning, which aims to maximize a lower bound of the mutual information between a pair of variables <ref type="bibr" target="#b7">[8]</ref>. It is widely used in various fields like language modeling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21]</ref>, search <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref> and recommendation <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b19">20]</ref>, to learn discriminative deep representations. In the InfoNCE framework, each positive sample is associated with K randomly selected negative samples, and the task is typically formulated as a K+1-way classification problem, i.e., classifying which one is the positive sample <ref type="bibr" target="#b14">[15]</ref>. In this way, the model is required to discriminate the positive sample from the negative ones, which can help estimate the variable mutual information and learn discriminative representations <ref type="bibr" target="#b8">[9]</ref>. It is proved that if the sample labels are clean, a larger negative sampling ratio K can lead to a tighter lower bound of variable mutual information <ref type="bibr" target="#b14">[15]</ref>, which usually yields better performance. This is intuitive because more information of negative samples is exploited in model training.</p><p>Unfortunately, in many real-world tasks sample labels are not perfect and may contain noise <ref type="bibr" target="#b13">[14]</ref>. For example, the non-clicked items are usually used as the negative samples in recommender system scenario. However, some non-clicked items may match users' interest and they are not clicked due to many other reasons, e.g., shown in a low position. They can be false negative sample for recommendation model training. It is not suitable to incorporate too many noisy negative samples because they may lead to misleading gradients that are harmful to model learning <ref type="bibr" target="#b12">[13]</ref>. Thus, it is important to find the appropriate negative sampling ratio K under different sample qualities to train accurate models. However, existing studies on InfoNCE mainly focus on the selection of hard negative samples <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b10">11]</ref>, while the study on the choice of negative sampling ratio is very limited.</p><p>In this paper, we study the problem of how many negative samples are optimal for InfoNCE in different tasks via a semi-quantitative theoretical framework. More specifically, we first propose a probabilistic model to analyze the influence of negative sampling ratio K of InfoNCE on the informativeness of training samples. Then, we propose a training effectiveness function to semiquantitatively measure the overall influence of training samples on model learning based on their informativeness. We use the K value that maximizes this function to estimate the optimal negative sampling ratio for InfoNCE. Based on our framework, we further propose an adaptive negative sampling (ANS) method that can dynamically adjust the negative sampling ratio to improve model training based on the characteristics of different model training stages. We conduct experiments on multiple real-world datasets. The results show that our framework can effectively estimate the optimal negative ratio in different tasks, and our proposed adaptive negative sampling method ANS can consistently achieve better performance than the commonly used negative sampling technique with fixed negative sampling ratio.</p><p>The main contributions of this paper include:</p><p>• We propose a semi-quantitative theoretical framework to analyze the influence of negative sampling ratio on InfoNCE and further estimate its optimal value.</p><p>• We propose an adaptive negative sampling method that can dynamically change the negative sampling ratio for different stages of model training. • We conduct extensive experiments to verify the validity of our theoretical framework and the effectiveness of the proposed adaptive negative sampling method for InfoNCE based model training.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">InfoNCE Loss Function</head><p>InfoNCE <ref type="bibr" target="#b14">[15]</ref> is a widely used loss function for contrastive learning. It aims to estimate a lower bound of the mutual information between two variables. A relevance function f (•, •) is used to measure the non-normalized mutual information score between them. For each positive sample (x + , c), it is associated with K random negative samples, which are denoted as</p><formula xml:id="formula_0">[(x − 1 , c), (x − 2 , c), ..., (x − K , c)].</formula><p>Then, the InfoNCE loss function L K is formulated as follows:</p><formula xml:id="formula_1">L K = − log( e f (x + ,c) e f (x + ,c) + K i=1 e f (x − i ,c) ).<label>(1)</label></formula><p>According to <ref type="bibr" target="#b14">[15]</ref>, if the labels are fully reliable, the lower bound of the mutual information between x + and c estimated by InfoNCE is formulated as:</p><formula xml:id="formula_2">I(x + , c) ≥ log(K + 1) − L K .<label>(2)</label></formula><p>We can see that this lower bound is tighter when the number of negative samples K is higher, which can usually lead to better performance of the models trained based on InfoNCE loss <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Applications of InfoNCE</head><p>InfoNCE has wide applications in many fields like language modeling <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b3">4]</ref>, search <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b2">3]</ref> and recommendation <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b19">20]</ref>. For example, Huang et al. <ref type="bibr" target="#b9">[10]</ref> proposed a deep structured semantic model (DSSM) for document retrieval. For each pair of query and clicked document (regarded as positive sample), they randomly sampled 4 unclicked documents as negative samples, and used the InfoNCE loss to train the model by optimizing the log-likelihood of the posterior click probability of the positive sample. Wu et al. <ref type="bibr" target="#b22">[23]</ref> proposed a personalized news recommendation method named NPA. In this method, they regarded each clicked news as a positive sample, and randomly sampled 4 non-clicked news displayed in the same impression as negative samples. The model was trained via the InfoNCE framework in a similar way. Chi et al. <ref type="bibr" target="#b3">[4]</ref> proposed a multilingual pre-trained language model named InfoXLM. They incorporated the InfoNCE framework into several self-supervion tasks like multilingual masked language modeling and cross-lingual contrastive learning. They used the momentum contrast <ref type="bibr" target="#b7">[8]</ref> method to construct a queue of negative samples with a size of 131,072 for model training. In these methods, the negative sampling ratio is usually empirically selected, which requires heavy hyper-parameter search. In addition, these methods leverage a fixed negative sampling ratio, which may not be optimal for different stages of model training. Our framework presented in this paper can help estimate the optimal negative sampling ratio in different scenarios. In addition, our proposed adaptive negative sampling method ANS can dynamically adjust the negative sampling ratio according to the characteristics of different model training stages. Our approach has the potential to benefit many tasks that involve InfoNCE loss for model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Framework</head><p>In this section, we introduce our semi-quantitative theoretical framework to analyze the influence of negative sampling ratio on the performance of the models trained based on InfoNCE loss. We take news recommendation as an example scenario to better explain our framework. In this scenario, it is a common practice to regard the clicked news as positive samples and non-clicked news as negative ones <ref type="bibr" target="#b22">[23]</ref>. A recommendation model is trained with the binary click labels to predict whether a user will click a candidate news. We assume that there exists a click probability for each sample, which reflects the relevance between the candidate news and user interest. We denote the click probability score distributions of clicked and non-clicked news as q(x) and p(x) respectively. In addition, we denote the click probability score distributions of predicted clicked and non-clicked news as q (x) and p (x). Fig. <ref type="figure" target="#fig_2">1</ref> shows an example. We expect the click probability scores of clicked news to be higher than non-clicked ones. However, since users' click behaviors have rich randomness, there are overlaps between the click probability curves of positives and negatives, which means that the labels are noisy. In addition, we assume the real labels are more discriminative (the curve overlap is smaller) than the predicted ones, which means the prediction accuracy is limited by the label quality.   Next, we introduce several key concepts in our framework. Given a user u, a positive news x + and its associated K negative news</p><formula xml:id="formula_3">[x − 1 , x − 2 , ..., x − K ] are combined as a training sample.</formula><p>We denote their click probability scores as y + and [y − 1 , y − 2 , ..., y − K ], respectively. If they satisfy y + &gt; max(y − 1 , y − 2 , ..., y − K ), we call the label of this training sample "reliable". In a similar way, we denote the click probability scores of the predicted positive and negative news as ŷ+ and</p><formula xml:id="formula_4">[ŷ − 1 , ŷ− 2 , ..., ŷ− K ],</formula><p>respectively. We regard the prediction for them as "reliable</p><formula xml:id="formula_5">" if ŷ+ &gt; max(ŷ − 1 , ŷ− 2 , ..., ŷ− K ).</formula><p>For simplicity, we assume that all the K + 1 candidate news are independent. We define events A and B as the "reliability" of label and model prediction respectively. Then, the probabilities P (A) and P (B) are formulated as follows:</p><formula xml:id="formula_6">P (A) = ∞ −∞ q(x)[ x −∞ p(y)dy] K dx,<label>(3)</label></formula><formula xml:id="formula_7">P (B) = ∞ −∞ q (x)[ x −∞ p (y)dy] K dx.<label>(4)</label></formula><p>Then, we introduce how to measure the informativeness of training samples and their influence on model learning. If the model prediction on a sample is "unreliable" while the label is "reliable", then this sample is very informative for calibrating the model. We regard this kind of samples as "good samples", and denote their set as G. On the contrary, if the model prediction on a sample is "reliable" but the label is "unreliable", this sample is harmful for model training because it will produce misleading gradients. We regard this kind of samples as "bad samples", and their set is denoted as B. For the rest samples, the model predictions and labels have the same "reliability", and these samples are usually less informative for model training. <ref type="foot" target="#foot_0">1</ref> We call this kind of samples as "easy samples", and their set is denoted as E. For simplicity, here we make an assumption that the events A and B are independent. We denote the total number of training samples as N . Then, the number of each kind of samples introduced above is formulated as follows:</p><formula xml:id="formula_8">|G| = P (A)[1 − P (B)]N, |B| = P (B)[1 − P (A)]N, |E| = N − |G| − |B|.<label>(5)</label></formula><p>To semi-quantitatively measure the influence of training samples on model learning, we propose a training effectiveness metric v based on the different informativeness of training samples, which is formulated as follows:</p><formula xml:id="formula_9">v = 1 N [λ(|G| − |B|) + (1 − λ)|E|],<label>(6)</label></formula><p>where λ is a hyperparameter that controls the relative importance of good and bad samples. According to our massive experiments, we find that setting λ = 0.9 is appropriate for estimating the negative sampling ratio. In Eq. ( <ref type="formula" target="#formula_9">6</ref>), given the distributions p(x), q(x), p (x) and q (x), v is only dependent on the negative sampling ratio K. Without loss of generality, we assume that these distributions are all Gaussian distributions with the same standard deviation 1, and the mean values of p(x) and p (x) (denoted as µ p(x) and µ p (x) ) satisfy µ p(x) = µ p (x) = 0. We still need to estimate the mean values of q(x) and q (x) (denoted as µ q(x) and µ q (x) ). In practice, we can estimate µ q(x) using the training AUC score under K = 1 before overfitting<ref type="foot" target="#foot_1">2</ref> by solving the following equation <ref type="foot" target="#foot_2">3</ref> :</p><formula xml:id="formula_10">AU C = ∞ −∞ 1 2π e −(x−µ q(x) ) 2 2 [ x −∞ e −y 2</formula><p>2 dy]dx.</p><p>In a similar way, the value of µ q (x) can be estimated based on the AUC score on the validation set under K = 1. When µ q(x) and µ q (x) are known, we can compute the current training effectiveness.</p><p>Finally, we introduce how to estimate the optimal negative sampling ratio based on our proposed framework. Since the model may produce different p (x) and q (x) during the training process, the training effectiveness measurement is time-variant. Thus, we denote the training effectiveness value at the i-th iteration step as v i , and the overall training effectiveness v is computed as v = 1 T T i=1 v i , where T is the number of iterations needed for model convergence. Since v is the function of K and other variables can be approximated, we can estimate the optimal value of K that maximizes v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we conduct experiments to verify our proposed framework. We first introduce the datasets and experimental settings, and then introduce the results and findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Experimental Settings</head><p>In our experiments, we verify our framework in three tasks, i.e., news recommendation, news titlebody matching and item recommendation. The first two tasks are performed on the MIND <ref type="bibr" target="#b24">[25]</ref> dataset <ref type="foot" target="#foot_3">4</ref> , which contains the news impression logs of 1 million users in 6 weeks. For the news recommendation task, each clicked news is regarded as a positive sample and the news displayed in the same impression but not clicked by the user are regarded as negative samples. The logs in the last week are used for test, and the rest are used for training and validation. For the news title-body matching task, we regard the original news title-body pairs as positive samples, and negative samples are created by randomly pairing titles and bodies. <ref type="foot" target="#foot_4">5</ref> We use the news in the training set of MIND for model training, and those in the validation and test sets (except the news included in the training set) for validation and test respectively. The item recommendation task is performed on the MovieLens dataset <ref type="bibr" target="#b6">[7]</ref>, and we use the ML-1M<ref type="foot" target="#foot_5">6</ref> version for experiments. We use the same experimental settings as <ref type="bibr" target="#b19">[20]</ref>. The statistics of datasets are summarized in Table <ref type="table" target="#tab_0">1</ref>. In these experiments, we use NRMS <ref type="bibr" target="#b23">[24]</ref> as the base model for news recommendation, a Siamese Transformer model <ref type="bibr" target="#b15">[16]</ref> for title-body matching, and use BERT4Rec <ref type="bibr" target="#b19">[20]</ref> for item recommendation. <ref type="foot" target="#foot_6">7</ref>We use AUC and nDCG@10 to measure the performance of news and item recommendation, and use AUC and HR@5 as the metrics for news title-body matching. All these models are trained with the InfoNCE loss under different negative sampling ratios. Each experiment is repeated 5 times and the average performance is reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>In this section, we verify our framework according to the experiments on different tasks. Fig. <ref type="figure" target="#fig_6">2</ref> shows the model training and validation AUC curves, the estimated overall training effectiveness under different negative sampling ratio K and hyperparameter λ, and the real model performance under different negative sampling ratios K in the news recommendation task. From Fig. <ref type="figure" target="#fig_6">2</ref>(a), we can observe that the training AUC is around 0.75 when model converges, which means that µ q(x) is about 1. From Figs. 2(c), we find that the real model performance is not optimal when K is too small or too large, and K = 4 yields the best performance, which is consistent with the red (λ = 0.9) and orange (λ = 0.95) curves in Fig. <ref type="figure" target="#fig_6">2(b)</ref>. It shows that the value of λ should be relatively large, which is intuitive because the influence of good and bad samples on the model training is usually dominant. Fig. <ref type="figure" target="#fig_8">3</ref> shows the results on the title-body matching task. From Fig. <ref type="figure" target="#fig_8">3</ref>(a), we can estimate that the value µ q(x) in this task is around 4.5 (training AUC is about 0.998). We find it interesting that when λ = 0.9, the estimated optimal negative sampling ratio (K = 180) in Fig. <ref type="figure" target="#fig_8">3(b</ref>) is consistent with the experimental results in Fig. <ref type="figure" target="#fig_8">3(c</ref>). From Fig. <ref type="figure" target="#fig_11">4</ref>, we have similar findings on the item recommendation task. The training AUC is about 0.95, which approximately corresponds to µ q(x) = 2.4 in our theoretical framework. The estimated optimal negative sampling ratio K is about 20, which is consistent with the experimental results in Fig. <ref type="figure" target="#fig_11">4(c</ref>). Thus, setting the hyperparameter λ to 0.9 would be appropriate for estimating the optimal negative sampling ratio. In addition, from these figures we find that the model performance improves first when K increases, and then starts to decline when K becomes too large. This is probably because useful information in negative samples cannot be exploited when K is too small, while the label noise will harm the model training when K is too large. Thus, a medium value of K may be more suitable for model training with noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>In this section, we use our framework to further analyze the negative sampling ratio in InfoNCE. We set the value of λ to 0.9 in the following analysis. First, we study the influence of the label quality (represented by µ q(x) ) on the estimated optimal value of K. We use the function µ t q (x) = µ q(x) (1 − e −t ), t ∈ [0, 3] to simulate the model training curve <ref type="foot" target="#foot_7">8</ref> , and the estimated optimal values K under different µ q(x) are shown in Fig. <ref type="figure" target="#fig_12">5</ref>. We find it interesting that the optimal value of K boosts when µ q(x) is close to 0 or relatively large. This may be because when µ q(x) is very small, we need many negative samples to counteract the noise. And when µ q(x) is large, we may also need increase the number of negative samples because the labels are relatively reliable.         ). The results on the news recommendation and title-body matching tasks are shown in Figs. <ref type="figure" target="#fig_14">6 and 7</ref>, respectively. <ref type="foot" target="#foot_8">9</ref> We have two interesting findings from them. First, the optimal negative sampling ratio at the beginning of model training is smaller than the globally optimal one estimated in the previous section. This may be because when model is not discriminative, the ratio of good samples is much larger than bad samples, and using too many negative samples may introduce unwanted noise and reduce the ratio of good samples. Thus, a smaller value of K may be more appropriate at the beginning. Second, when the model gets to converge, the negative sampling ratio also needs to be smaller, and the optimal one is 1 when µ q(x) = µ q (x) . This is because easy samples are dominant when the numbers of good and bad   samples are almost even, and focusing on optimizing the loss on easy samples may lead to overfitting. Thus, a fixed negative sampling ratio may be suboptimal for model training at different stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ANS: Adaptive Negative Sampling</head><p>Based on the findings in above section, we further propose an Adaptive Negative Sampling (ANS) method that can dynamically adjust the negative sampling ratio K during model training to overcome the limitation of using a fixed one. We first introduce an extension of the standard negative sampling method where the negative sampling ratio K is real-valued. We denote the set of negative samples associated with each positive sample as N , which satisfies the following formulas:</p><formula xml:id="formula_12">P (|N | = [K]) = 1 − {K}, P (|N | = [K] + 1) = {K},<label>(8)</label></formula><p>where [x] and {x} represent the integral and fractional parts of x respectively.</p><p>We then introduce our proposed ANS method. Motivated by the analysis in the previous section and the popular learning rate warm-up strategy <ref type="bibr" target="#b5">[6]</ref>, we propose to adjust the negative sampling ratio K as the curve shown in Fig. <ref type="figure" target="#fig_15">8</ref>. The value of K quickly grows from 1 to the optimal value estimated by our framework, and then slowly declines to 1 as the training continues. This is because the optimal negative sampling ratio may be small at the beginning and the end of model training, and the performance of model usually improves quickly at the beginning. The turning point on this curve is 10% of the training steps, which is empirically selected based on experimental results (included in supplements). Our ANS method can adapt to different stages in the model training process, which can overcome the drawbacks of using a fixed negative sampling ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments on the ANS Method</head><p>In this section, we conduct experiments to verify the effectiveness of our proposed ANS method.</p><p>On the news recommendation task, we apply our ANS method to several state-of-the-art baseline methods, including NRMS <ref type="bibr" target="#b23">[24]</ref>, LSTUR <ref type="bibr" target="#b0">[1]</ref> and NAML <ref type="bibr" target="#b21">[22]</ref>. On the news title-body matching task, we apply ANS to the Siamese Transformer <ref type="bibr" target="#b15">[16]</ref> network and its variants based on LSTM or CNN. We compare their performance with those trained with static negative sampling strategies that use a fixed negative sampling ratio. The results are shown in Figs. 9 and 10. We find that using the optimal negative sampling ratio estimated by our framework is better than popular default negative sampling ratio (e.g., 1) <ref type="bibr" target="#b16">[17]</ref>. Moreover, using our proposed adaptive negative sampling method can achieve better performance than using static negative sampling ratio. This is because ANS can use different negative sampling ratios to better fit the characteristics of different training stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we study how many negative samples are optimal for InfoNCE-based model learning in different tasks using a semi-quantitative theoretical framework. We first propose a probabilistic model to analyze the influence of negative sampling ratio in InfoNCE on the informativeness of training samples. Then, we propose a training effectiveness function to measure the overall influence of training samples on model learning based on their informativeness. We further estimate the optimal value of K that maximizes this measurement. Based on our framework, we further propose an adaptive negative sampling method that can dynamically adjust the negative sampling ratio according to the characteristics of different model training stages. We conduct extensive experiments on different real-world datasets for different tasks. The results show that our framework can accurately estimate the optimal negative sampling ratio, and our adaptive negative sampling method can consistently outperform the commonly used fixed negative sampling ratio strategy.     Our work also has the following limitations. First, in practice we need to first run experiments under K = 1 to obtain the training and validation AUC curves to estimate the key parameters in our framework. We will explore how to reduce the effort on estimating the optimal negative sampling ratio. Second, we cannot obtain a closed-form solution of µ q(x) and we need to numerically solve Eq. ( <ref type="formula" target="#formula_11">7</ref>). We will work on this problem to obtain a closed-form solution. Third, the turning point in our adaptive negative sampling method is empirically tuned rather than automatically selected. We will explore how to adaptively tune this hyperparameter in our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact Statement</head><p>In this paper, we introduce a semi-quantitative theoretical framework for estimating the optimal negative sampling ratio in InfoNCE-based contrastive learning. In addition, we propose an adaptive negative sampling method based on the findings of our theoretical framework. Our work can be applied to various applications such as document retrieval, personalized recommendation and language model pre-training, to help estimate a proper number of negative samples and enhance model training. There are many benefits to use our proposed approach, such as improving the model performance and reducing the effort on hyperparameter search. However, there are also potential negative effects of using our approach: (1) Due to the complexity of real-world applications (e.g., data distribution, task characteristic and model capacity), there may be some gaps between real experimental results and the predictions given by our theoretical framework, and the models may not yield the optimal performance. (2) Our approach is not aware of the data biases, and the modeled trained with our recommended negative sampling ratio or our proposed ANS method may inherit and even amplify these biases <ref type="bibr" target="#b4">[5]</ref>. We would encourage further work to understand and address the limitations and potential negative effects of our framework in specific applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head><p>Relation between AUC and µ q(x)</p><p>The relation between the AUC score and the value of µ q(x) in our framework is shown in Fig. <ref type="figure" target="#fig_19">11</ref>. We can see that the value of µ q(x) is 0 if AUC is 0.5, and increases when AUC gets close to 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparmeter Settings</head><p>The detailed hyperparameter settings in our experiments are shown in Table <ref type="table" target="#tab_3">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>Several implementation details are introduced as follows. We conducted experiments using a machine with Ubuntu 16.04 operating system and Python 3.6. The machine has a memory of 256GB and a Tesla V100 GPU with 32GB memory. We used the Keras 2.2.4 and tensorflow 1.12 to implement deep learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence of Turning Point in ANS</head><p>We also conduct experiments to explore the influence of the turning point on the negative sampling ratio curve. We compare the model performance by varying the turning point (using different percentages of iterations). The results are shown in Fig. <ref type="figure" target="#fig_21">12</ref>. We observe that when the turning point appears too early, the performance is sub-optimal because the negative sampling ratio K may need to be relatively small at the beginning. In addition, if it appears too late, the performance is also sub-optimal because the model may need a relatively larger K after a certain number of iterations. Thus, we empirically set the turning point to 10% of the total training steps.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>sample p(x) clicked sample q(x) (a) Real.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>sample p (x) clicked sample q (x) (b) Predicted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustrated click probability score distributions of real positive and negative samples and the predicted ones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Training and validation AUC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Estimated overall training effectiveness v under different K and λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Performance under different K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results and predictions on the news recommendation task. Gray dashed line represents the optimal K under λ = 0.9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Performance under different K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results and predictions on the title-body matching task. Gray dashed line represents the optimal K under λ = 0.9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Estimated overall training effectiveness v under different K and λ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Model performance under different K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results and predictions on the movie recommendation task. Gray dashed line represents the optimal K under λ = 0.9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: The simulated optimal value of K under different µ q(x) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Training effectiveness and proportion of different kinds of samples in different training stages on the news recommendation task. Good and bad curves overlap in the last plot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Training effectiveness and proportion of different kinds of samples in different training stages on the title-body matching task. Good and bad curves overlap in the last plot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The curve of negative sampling ratio in the ANS method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: News title-body matching experiments with different negative sampling strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Relation between AUC and µ q(x) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Influence of turning points in our ANS method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Detailed dataset statistics.</figDesc><table><row><cell></cell><cell>MIND</cell><cell></cell></row><row><cell># News</cell><cell>161,013 # User</cell><cell>1,000,000</cell></row><row><cell cols="3"># Impression 15,777,377 # Click behavior 24,155,470</cell></row><row><cell>Avg. title len.</cell><cell>11.52 Avg. body len.</cell><cell>585.05</cell></row><row><cell></cell><cell>ML-1M</cell><cell></cell></row><row><cell># Item</cell><cell>3,706 # User</cell><cell>6,040</cell></row><row><cell># Interaction</cell><cell>1,000,209 Avg. history len.</cell><cell>165.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Detailed hyperparameter settings.</figDesc><table><row><cell cols="4">Hyperparameters NRMS LSTUR NAML</cell><cell>Siamese Transformer</cell><cell cols="3">CNN LSTM BERT4Rec</cell></row><row><cell># attention heads</cell><cell>16</cell><cell>-</cell><cell>-</cell><cell>16</cell><cell>-</cell><cell>-</cell><cell>2</cell></row><row><cell>output head dim</cell><cell>16</cell><cell>-</cell><cell>-</cell><cell>16</cell><cell>-</cell><cell>-</cell><cell>32</cell></row><row><cell>hidden dim</cell><cell>256</cell><cell>256</cell><cell>256</cell><cell>256</cell><cell>256</cell><cell>256</cell><cell>64</cell></row><row><cell>dropout</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>optimizer</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell cols="2">Adam Adam</cell><cell>Adam</cell></row><row><cell>learning rate</cell><cell>1e-4</cell><cell>1e-4</cell><cell>1e-4</cell><cell>1e-4</cell><cell>1e-4</cell><cell>1e-4</cell><cell>1e-4</cell></row><row><cell>batch size</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>32</cell><cell>128</cell></row><row><cell>total epoch</cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>6</cell><cell>6</cell><cell>50</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">When predictions and labels are both "reliable", the model can simply optimize the losses on these samples, which may lead to overfitting. When predictions and labels are both not "reliable", the gradients are also not very informative.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">We assume the model is strong enough to fit the training data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">We cannot obtain a closed-form solution of µ q(x) due to the characteristic of Gaussian distribution. Thus, we need to solve µ q(x) with numerical methods (e.g., bisection method).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://msnews.github.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">Some randomly combined title-body pairs happen to be from the same news, i.e., they are actually positive samples. We remove these pairs from the negative sample set.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">https://grouplens.org/datasets/movielens/1m/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">The detailed hyperparameter settings are in supplements.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7">We find the shape of this curve is similar to the real training curves.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8">Due to space limit, we only present the results of news recommendation and title-body matching because the results in the item recommendation task show similar patterns.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Mingxiao</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<title level="m">Neural News Recommendation with Long-and Short-term User Representations. In ACL</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised Video Representation Learning by Bidirectional Feature Prediction</title>
		<author>
			<persName><forename type="first">Nadine</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jurgen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pretraining tasks for embedding-based large-scale retrieval</title>
		<author>
			<persName><forename type="first">Wei-Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03932</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Infoxlm: An information-theoretic framework for cross-lingual language model pre-training</title>
		<author>
			<persName><forename type="first">Zewen</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saksham</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Ling</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heyan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Yen-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00224</idno>
		<title level="m">Debiased contrastive learning</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<title level="m">The movielens datasets: History and context. TIIS</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Philippe Weinzaepfel, and Diane Larlus</title>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bulent</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noe</forename><surname>Sariyildiz</surname></persName>
		</author>
		<author>
			<persName><surname>Pion</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01028</idno>
	</analytic>
	<monogr>
		<title level="m">Hard negative mixing for contrastive learning</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Mutual Information Maximization Perspective of Language Representation Learning</title>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Can gradient clipping mitigate label noise?</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sashank</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName><forename type="first">Nagarajan</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><forename type="middle">K</forename><surname>Inderjit S Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ambuj</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1196" to="1204" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3973" to="3983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.04592</idno>
		<title level="m">Contrastive learning with hard negative samples</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Context Encoding for Video Retrieval with Contrastive Learning</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingchen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01334</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1441" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Contrastive Distillation on Intermediate Representations for Language Model Compression</title>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="498" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural News Recommendation with Attentive Multi-View Learning</title>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxiao</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3863" to="3869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Npa: Neural news recommendation with personalized attention</title>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxiao</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2576" to="2584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural News Recommendation with Multi-Head Self-Attention</title>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suyu</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6390" to="6395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mind: A large-scale dataset for news recommendation</title>
		<author>
			<persName><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiun-Hung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuhan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxun</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winnie</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3597" to="3606" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
