<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE DARK SIDE OF AUTOML: TOWARDS ARCHITEC-TURAL BACKDOOR SEARCH</title>
				<funder ref="#_B2n8yT7 #_RJnugJ5 #_ZW3Zf5W">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder ref="#_k5TNyGp">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_NyU7Psy #_Q6mM9bk">
					<orgName type="full">NSFC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ren</forename><surname>Pang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Changjiang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaohan</forename><surname>Xi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shouling</forename><surname>Ji</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">THE DARK SIDE OF AUTOML: TOWARDS ARCHITEC-TURAL BACKDOOR SEARCH</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper asks the intriguing question: is it possible to exploit neural architecture search (NAS) as a new attack vector to launch previously improbable attacks? Specifically, we present EVAS, a new attack that leverages NAS to find neural architectures with inherent backdoors and exploits such vulnerability using input-aware triggers. Compared with existing attacks, EVAS demonstrates many interesting properties: (i) it does not require polluting training data or perturbing model parameters; (ii) it is agnostic to downstream fine-tuning or even re-training from scratch; (iii) it naturally evades defenses that rely on inspecting model parameters or training data. With extensive evaluation on benchmark datasets, we show that EVAS features high evasiveness, transferability, and robustness, thereby expanding the adversary's design spectrum. We further characterize the mechanisms underlying EVAS, which are possibly explainable by architecture-level "shortcuts" that recognize trigger patterns. This work showcases that NAS can be exploited in a harmful way to find architectures with inherent backdoor vulnerability. The code is available at https://github.com/ain-soph/nas_backdoor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EVAS</head><p>Next, we present EVAS, a new backdoor attack leveraging NAS to find neural arches with exploitable vulnerability. We begin by introducing the threat model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">THREAT MODEL</head><p>A backdoor attack injects a hidden malicious function ("backdoor") into a target model (Pang et al.,  2022). The backdoor is activated once a pre-defined condition ("trigger") is present, while the model</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As a new paradigm of applying ML techniques in practice, automated machine learning (AutoML) automates the pipeline from raw data to deployable models, which covers model design, optimizer selection, and parameter tuning. The use of AutoML greatly simplifies the ML development cycles and propels the trend of ML democratization. In particular, neural architecture search (NAS), one primary AutoML task, aims to find performant deep neural network (DNN) arches<ref type="foot" target="#foot_0">1</ref> tailored to given datasets. In many cases, NAS is shown to find models remarkably outperforming manually designed ones <ref type="bibr" target="#b34">(Pham et al., 2018;</ref><ref type="bibr">Liu et al., 2019;</ref><ref type="bibr" target="#b22">Li et al., 2020)</ref>.</p><p>In contrast to the intensive research on improving the capability of NAS, its security implications are largely unexplored. As ML models are becoming the new targets of malicious attacks <ref type="bibr" target="#b3">(Biggio &amp; Roli, 2018)</ref>, the lack of understanding about the risks of NAS is highly concerning, given its surging popularity in security-sensitive domains <ref type="bibr">(Pang et al., 2022)</ref>. Towards bridging this striking gap, we pose the intriguing yet critical question:</p><p>Is it possible for the adversary to exploit NAS to launch previously improbable attacks?</p><p>This work provides an affirmative answer to this question. We present exploitable and vulnerable arch search (EVAS), a new backdoor attack that leverages NAS to find neural arches with inherent, exploitable vulnerability. Conventional backdoor attacks typically embed the malicious functions ("backdoors") into the space of model parameters. They often assume strong threat models, such as polluting training data <ref type="bibr" target="#b15">(Gu et al., 2017;</ref><ref type="bibr">Liu et al., 2018;</ref><ref type="bibr" target="#b31">Pang et al., 2020)</ref> or perturbing model parameters <ref type="bibr" target="#b18">(Ji et al., 2018;</ref><ref type="bibr">Qi et al., 2022)</ref>, and are thus subject to defenses based on model inspection <ref type="bibr" target="#b41">(Wang et al., 2019;</ref><ref type="bibr">Liu et al., 2019)</ref> and data filtering <ref type="bibr" target="#b14">(Gao et al., 2019)</ref>. In EVAS, however, as the backdoors are carried in the space of model arches, even if the victim trains the models using clean data and operates them in a black-box manner, the backdoors are still retained. Moreover, due to its independence of model parameters or training data, EVAS is naturally robust against defenses such as model inspection and input filtering.</p><p>To realize EVAS, we define a novel metric based on neural tangent kernel <ref type="bibr">(Chen et al., 2021)</ref>, which effectively indicates the exploitable vulnerability of a given arch; further, we integrate this metric into the NAS-without-training framework <ref type="bibr">(Mellor et al., 2021;</ref><ref type="bibr">Chen et al., 2021)</ref>. The resulting search method is able to efficiently identify candidate arches without requiring model training or backdoor testing. To verify EVAS's empirical effectiveness, we evaluate EVAS on benchmark datasets and show: (i) EVAS successfully finds arches with exploitable vulnerability, (ii) the injected backdoors may be explained by arch-level "shortcuts" that recognize trigger patterns, and (iii) EVAS demonstrates high evasiveness, transferability, and robustness against defenses. Our findings show the feasibility of exploiting NAS as a new attack vector to implement previously improbable attacks, raise concerns about the current practice of NAS in security-sensitive domains, and point to potential directions to develop effective mitigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Next, we survey the literature relevant to this work.</p><p>Neural arch search. The existing NAS methods can be categorized along search space, search strategy, and performance measure. Search space -early methods focus on the chain-of-layer structure <ref type="bibr" target="#b1">(Baker et al., 2017)</ref>, while recent work proposes to search for motifs of cell structures <ref type="bibr" target="#b45">(Zoph et al., 2018;</ref><ref type="bibr" target="#b34">Pham et al., 2018;</ref><ref type="bibr">Liu et al., 2019)</ref>. Search strategy -early methods rely on either random search <ref type="bibr" target="#b19">(Jozefowicz et al., 2015)</ref> or Bayesian optimization <ref type="bibr" target="#b2">(Bergstra et al., 2013)</ref>, which are limited in model complexity; recent work mainly uses the approaches of reinforcement learning <ref type="bibr" target="#b1">(Baker et al., 2017)</ref> or neural evolution <ref type="bibr">(Liu et al., 2019)</ref>. Performance measure -one-shot NAS has emerged as a popular performance measure. It considers all candidate arches as different sub-graphs of a super-net (i.e., the one-shot model) and shares weights between candidate arches <ref type="bibr">(Liu et al., 2019)</ref>. Despite the intensive research on NAS, its security implications are largely unexplored. Recent work shows that NAS-generated models tend to be more vulnerable to various malicious attacks than manually designed ones <ref type="bibr">(Pang et al., 2022;</ref><ref type="bibr" target="#b11">Devaguptapu et al., 2021)</ref>. This work explores another dimension: whether it can be exploited as an attack vector to launch new attacks, which complements the existing studies on the security of NAS.</p><p>Backdoor attacks and defenses. Backdoor attacks inject malicious backdoors into the victim's model during training and activate such backdoors at inference, which can be categorized along attack targets -input-specific <ref type="bibr" target="#b38">(Shafahi et al., 2018)</ref>, class-specific <ref type="bibr" target="#b39">(Tang et al., 2020)</ref>, or any-input <ref type="bibr" target="#b15">(Gu et al., 2017)</ref>, attack vectors -polluting training data <ref type="bibr">(Liu et al., 2018)</ref> or releasing infected models <ref type="bibr" target="#b18">(Ji et al., 2018)</ref>, and optimization metrics -attack effectiveness <ref type="bibr" target="#b31">(Pang et al., 2020)</ref>, transferability <ref type="bibr" target="#b44">(Yao et al., 2019)</ref>, or attack evasiveness <ref type="bibr" target="#b8">(Chen et al., 2017)</ref>. To mitigate such threats, many defenses have also been proposed, which can be categorized according to their strategies <ref type="bibr">(Pang et al., 2022)</ref>: input filtering purges poisoning samples from training data <ref type="bibr" target="#b40">(Tran et al., 2018)</ref>; model inspection determines whether a given model is backdoored <ref type="bibr">(Liu et al., 2019;</ref><ref type="bibr" target="#b41">Wang et al., 2019)</ref>, and input inspection detects trigger inputs at inference time <ref type="bibr" target="#b14">(Gao et al., 2019)</ref>. Most attacks and defenses above focus on backdoors implemented in the space of model parameters. Concurrent to this work, Bober-Irizar et al. ( <ref type="formula">2022</ref>) explore using neural arches to implement backdoors by manually designing "trigger detectors" in the arches and activating such detectors using poisoning data during training. This work investigates using NAS to directly search for arches with exploitable vulnerability, which represents a new direction of backdoor attacks.    behaves normally otherwise. In a predictive task, the backdoor is often defined as classifying a given input to a class desired by the adversary, while the trigger can be defined as a specific perturbation applied to the input. Formally, given input x and trigger r = (m, p) in which m is a mask and p is a pattern, the trigger-embedded input is defined as:</p><formula xml:id="formula_0">+ j J Y C i Q E x I x x l q N J L j k 6 E N n G b i F q e m q s R r 0 M 3 T W O h m H e I t f k v f I u P q S 1 Q C I 5 B Q 0 / V V 8 V 1 X 9 l p Z K e k u R 3 J 9 p 6 9 P j J 0 + 2 d 7 r P n L 1 7 u 7 u 0 f X H h b O Y F D Y Z V 1 V x l 4 V N L g k C Q p v C o d g s 4 U X m b T z / P 6 5 R 0 6 L 6 3 5 R n W J I w 2 3 R h Z S A I X U d b 8 Y c 1 D l B P r j v V 4 y S B Y R P x T p S v T Y K s 7 H + 5 1 r n l t R a T Q k F H h / k y Y l j R p w J I X C t s s r j y W I K d z i T Z A G N P p R s 1 i 5 j V + F T B 4 X 1 o V n K F 5 k / + 1 o Q H t f 6 y y Q G m j i 1 2 q z 5 Z B N f g 7 + l 8 / 0 O u t J g 6 t d v r E j F R 9 H j T R l R W j E c s W i U j H Z e O 5 c n E u H g l Q d B A g n w y 9 j M Q E H g o K / X W</formula><formula xml:id="formula_1">= " &gt; A A A C i 3 i c b Z H b a h R B E I Z 7 x 1 N c j d n o l X g z u C v E m 2 U m H l E v g i J 4 G c F N g u l l 6 a m p y T T b h 6 G 7 N u 4 w D D 6 N t / o 8 v o 2 9 B 9 D d W N D w U / V 1 U f V X V i n p K U l + d 6 J r 1 2 / c v L V z u 3 v n 7 u 6 9 v d 7 + / R N v Z w 5 w B F Z Z d 5 Y J j 0 o a H J E k h W e V Q 6 E z h a f Z 9 M O i f n q J z k t r v l B d 4 V i L C y M L C Y J C a t J 7 O C g m X K i q F A c c c k t v Y 0 4 l k n g 6 m P T 6 y T B Z R n x V p G v R Z + s 4 n u x 3 v v L c w k y j I V D C + / M 0 q W j c C E c S F L Z d P v N Y C Z i K C z w P 0 g i N f t w s d 2 j j J y G T x 4 V 1 4 R m K l 9 l / f z R C e 1 / r L J B a U O k 3 a v N V k 2 1 + A f 6 X z / Q m 6 0 k L V 7 t 8 a 0 Y q X o 8 b a a o Z o Y H V i M V M x W T j h Z V x L h 0 C q T o I A U 6 G L W M o h R N A w f A u N / g N r N b C 5 A 0 H k A 7 a h k / R m W T 4 A u f 8 E o J N 6 B p</formula><formula xml:id="formula_2">+ d T s i a t O J k / g B H a f V G R g = " &gt; A A A C e 3 i c b Z H b a h R B E I Z 7 x 1 N c D 0 n 0 0 p v B X U F E l p l g 1 M u g N 7 m M k E 2 C 2 0 v o q a n N N t u H o b s m 7 t D M Y 3 i r z + X D C O k 9 g N m N B Q 0 / V V 8 V 1 X 8 V l Z K e s u x P J 7 l 3 / 8 H D R z u P u 0 + e P n u + u 7 f / 4 s z b 2 g E O w S r r L g r h U U m D Q 5 K k 8 K J y K H S h 8 L y Y f V 3 U z 6 / R e W n N K T U V j r W 4 M n I i Q V B M j f q c p C o x z N v + 5 V 4 v G 2 T L S O + K f C 1 6 b B 0 n l / u d 7 7 y 0 U G s 0 B E p 4 P 8 q z i s Z B O J K g s O 3 y 2 m M l Y C a u c B S l E R r 9 O C x 3 b t M 3 M V O m E + v i M 5 Q u s 7 c 7 g t D e N 7 q I p B Y 0 9 R u 1 + W r I N r 8 A / 8 s X e p P 1 p I V r X L m 1 I 0 0 + j 4 M 0 V U 1 o Y L X i p F Y p 2 X R h X V p K h 0 C q i U K A k / G X K U y F E 0 D R 4 C 4 3 + A O s 1 s K U g Q N I B 2 3 g M 3 Q m G x z i n F 9 D t A l d 4 N P C z k O f + z i h I k + N Q r 6 A + 2 3 7 j 2 6 7 8 R r 5 t v d 3 x d n B I P 8 4 + P D t o H f 0 Z X 2 X H f a K v W Z v W c 4 + s S N 2 z E 7 Y k A G z 7 C f 7 x X 5 3 / i a 9 5 F 3 y f o U m n X X P S 7 Y R y e E N i u / F H w = = &lt; / l a t e x i t &gt; x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u 8 L f j t M O N k w F f m r C Z N w b P O U O g N k = " &gt; A A A C h 3 i c b Z F L b 9 N A E M c 3 5 t W G V w r i x M U i Q S q X Y F f Q V u J S 4 M K x S K S t 6 E b R e j x J V t m H t T t O Y 1 n + M F z h E / F t 2 D w k S M p I K / 0 1 8 5 v R 7 H + y Q k l P S f K 7 F d 2 5 e + / + g 7 3 9 9 s N H j 5 8 8 7 R w 8 u / C 2 d I A D s M q 6 q 0 x 4 V N L g g C Q p v C o c C p 0 p v M x m n 5 f 1 y z k 6 L 6 3 5 R l W B Q y 0 m R o 4 l C A q p U e d F b 3 L I I b f 0 I e Z z 4 W i K J N 7 0 R p 1 u 0 k 9 W E d 8 W 6 U Z 0 2 S b O R w e t 7 z y 3 U G o 0 B E p 4 f 5 0 m B Q 3 r M F G C w q b N S 4 + F g J m Y 4 H W Q R m j 0 w 3 q 1 f x O / D p k 8 H l s X n q F 4 l f 2 3 o x b a + 0 p n g d S C p n 6 r t l g P 2 e W X 4 H / 5 T G + z n r R w l c t 3 d q T x 6 b C W p i g J D a x X H J c q J h s v b Y x z 6 R B I V U E I c D L 8 M o a p c A I o m N 3 m B m / A a i 1 M X n M A 6 a C p + Q y d S f r v c c H n E G x C V / N p Z h d 1 j / s w o S B P l U K + h H t N 8 5 d u 2 u E a 6 a 7 3 t 8 X F U T 8 9 7 r / 7 e t Q 9 + 7 S 5 y x 5 7 y V 6 x Q 5 a y E 3 b G v r B z N m D A a v a D / W S / o v 3 o b X Q c n a 7 R q L X p e c 6 2 I v r 4 B 6 l s x 6 s = &lt; / l a t e x i t &gt; g(?; #) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " h S K F q I O + R 8 A L 5 C b / D i u 2 K T F C W l 4 = " &gt; A A A C c 3 i c b Z F L b 9 N A E M c 3 p k B J e b R w 7 M V q j M S F y K 5 4 H S u 4 c C x q 0 1 b t R t V 6 P E l W 2 Y e 1 O y 6 x L H 8 E r v D Z + C D c 2 T y k N m l H W u m v m d + M Z v + T l 0 p 6 S t O / n e j R 1 u M n T 7 e f d X e e v 3 j 5 a n f v 9 Z m 3 l Q M c g F X W X e T C o 5 I G B y R J 4 U X p U O h c 4 X k + / T a v n 9 + g 8 9 K a U 6 p L H G o x N n I k Q V B I n S S z 5 H q 3 l / b T R c T 3 R b Y S P b a K 4 + u 9 z i U v L F Q a D Y E S 3 l 9 l a U n D R j i S o L D t 8 s p j K W A q x n g V p B E a / b B Z 7 N r G b 0 O m i E f W h W c o X m T v d j R C e 1 / r P J B a 0 M S v 1 W b L I Z v 8 H H y Q z / U 6 6 0 k L V 7 t i Y 0 c a f R k 2 0 p Q V o Y H l i q N K x W T j u W V x I R 0 C q T o I A U 6 G X 8 Y w E U 4 A B W O 7 3 O B P s F o L U z Q c Q D p o G z 5 F Z 9 L + R 5 z x G w g 2 o W v 4 J L e z J u E + T C j J U 6 2 Q z + G k b W / p t h u u k W 1 6 f 1 + c H f a z T / 0 P P w 5 7 R 1 9 X d 9 l m + + y A v W M Z + 8 y O 2 H d 2 z A Y M 2 J j 9 Y r / Z n 8 6 / a D 8 6 i J I l G n V W P W / Y W k T v / w N T O M F p &lt; / l</formula><formula xml:id="formula_3">x = x ? (1 -m) + p ? m (1)</formula><p>Let f be the backdoor-infected model. The backdoor attack implies that for given input-label pair (x, y), f (x) = y and f (x) = t with high probability, where t is the adversary's target class.</p><p>The conventional backdoor attacks typically follow two types of threat models: (i) the adversary directly trains a backdoor-embedded model, which is then released to and used by the victim user <ref type="bibr">(Liu et al., 2018;</ref><ref type="bibr" target="#b31">Pang et al., 2020;</ref><ref type="bibr" target="#b18">Ji et al., 2018)</ref>; or (ii) the adversary indirectly pollutes the training data or manipulate the training process <ref type="bibr" target="#b15">(Gu et al., 2017;</ref><ref type="bibr">Qi et al., 2022)</ref> to inject the backdoor into the target model. As illustrated in Figure <ref type="figure" target="#fig_3">1</ref>, in EVAS, we assume a more practical threat model in which the adversary only releases the exploitable arch to the user, who may choose to train the model from scratch using clean data or apply various defenses (e.g., model inspection or data filtering) before or during using the model. We believe this represents a more realistic setting: due to the prohibitive computational cost of NAS, users may opt to use performant model arches provided by third parties, which opens the door for the adversary to launch the EVAS attack.</p><p>However, realizing EVAS represents non-trivial challenges including (i) how to define the trigger patterns? (ii) how to define the exploitable, vulnerable arches? and (iii) how to search for such arches efficiently? Below we elaborate on each of these key questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">INPUT-AWARE TRIGGERS</head><p>Most conventional backdoor attacks assume universal triggers: the same trigger is applied to all the inputs. However, universal triggers can be easily detected and mitigated by current defenses <ref type="bibr" target="#b41">(Wang et al., 2019;</ref><ref type="bibr">Liu et al., 2019)</ref>. Moreover, it is shown that implementing universal triggers at the arch level requires manually designing "trigger detectors" in the arches and activating such detectors using poisoning data during training (Bober-Irizar et al., 2022), which does not fit our threat model.</p><p>Instead, as illustrated in Figure <ref type="figure" target="#fig_3">1</ref>, we adopt input-aware triggers <ref type="bibr" target="#b29">(Nguyen &amp; Tran, 2020)</ref>, in which a trigger generator g (parameterized by ?) generates trigger r x specific to each input x. Compared with universal triggers, it is more challenging to detect or mitigate input-aware triggers. Interestingly, because of the modeling capacity of the trigger generator, it is more feasible to implement input-aware triggers at the arch level (details in ? 4). For simplicity, below we use x = g(x; ?) to denote both generating trigger r x for x and applying r x to x to generate the trigger-embedded input x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">EXPLOITABLE ARCHES</head><p>In EVAS, we aim to find arches with backdoors exploitable by the trigger generator, which we define as the following optimization problem.</p><p>Specifically, let ? and ? respectively denote f 's arch and model parameters. We define f 's training as minimizing the following loss:</p><formula xml:id="formula_4">L trn (?, ?) ? E (x,y)?D ?(f ? (x; ?), y)<label>(2)</label></formula><p>where f ? denotes the model with arch fixed as ? and D is the underlying data distribution. As ? is dependent on ?, we define:</p><formula xml:id="formula_5">? ? ? arg min ? L trn (?, ?)<label>(3)</label></formula><p>Further, we define the backdoor attack objective as:</p><formula xml:id="formula_6">L atk (?, ?) ? E (x,y)?D [?(f ? (x; ? ? ), y) + ??(f ? (g(x; ?); ? ? ), t)]<label>(4)</label></formula><p>where the first term specifies that f works normally on clean data, the second term specifies that f classifies trigger-embedded inputs to target class t, and the parameter ? balances the two factors.</p><p>Note that we assume the testing data follows the same distribution D as the training data.</p><p>Overall, we consider an arch ? * having exploitable vulnerability if it is possible to find a trigger generator ? * , such that L atk (? * , ? * ) is below a certain threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">SEARCH WITHOUT TRAINING</head><p>Searching for exploitable archs by directly optimizing Eq. 4 is challenging: the nested optimization requires recomputing ? (i.e., re-training model f ) in L trn whenever ? is updated; further, as ? and ? are coupled in L atk , it requires re-training generator g once ? is changed.</p><p>Motivated by recent work <ref type="bibr">(Mellor et al., 2021;</ref><ref type="bibr">Wu et al., 2021;</ref><ref type="bibr">Abdelfattah et al., 2021;</ref><ref type="bibr">Ning et al., 2021)</ref> on NAS using easy-to-compute metrics as proxies (without training), we present a novel method of searching for exploitable arches based on neural tangent kernel (NTK) <ref type="bibr" target="#b17">(Jacot et al., 2018)</ref> without training the target model or trigger generator. Intuitively, NTK describes model training dynamics by gradient descent <ref type="bibr" target="#b17">(Jacot et al., 2018;</ref><ref type="bibr" target="#b9">Chizat et al., 2019;</ref><ref type="bibr" target="#b21">Lee et al., 2019)</ref>. In the limit of infinite-width DNNs, NTK becomes constant, which allows closed-form statements to be made about model training. Recent work <ref type="bibr">(Chen et al., 2021;</ref><ref type="bibr">Mok et al., 2022)</ref> shows that NTK serves as an effective predictor of model "trainability" (i.e., how fast the model converges at early training stages). Formally, considering model f (parameterized by ?) mapping input x to a probability vector f (x; ?) (over different classes), the NTK is defined as the product of the Jacobian matrix:</p><formula xml:id="formula_7">?(x, ?) ? ?f (x; ?) ?? ?f (x; ?) ?? ?<label>(5)</label></formula><p>Let ? min (? max ) be the smallest (largest) eigenvalue of the empirical NTK ?(?) ? E (x,y)?D ?(x, ?).</p><p>The condition number ? ? ? max /? min serves as a metric to estimate model trainability <ref type="bibr">(Chen et al., 2021)</ref>, with a smaller conditional number indicating higher trainability. In our context, we consider the trigger generator and the target model as an end-to-end model and measure the empirical NTK of the trigger generator under randomly initialized ?:</p><formula xml:id="formula_8">?(?) ? E (x,y)?D,??P ?? ?f (g(x; ?); ?) ?? ?f (g(x; ?; ?) ?? ? (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where P ?? represents the initialization distribution of ?. Here, we emphasize that the measure should be independent of ?'s initialization.</p><p>Intuitively, ?(?) measures the trigger generator's trainability with respect to a randomly initialized target model. The generator's trainability indicates the easiness of effectively generating input-aware triggers, implying the model's vulnerability to input-aware backdoor attacks. To verify the hypothesis, on the CIFAR10 dataset with the generator configured as in Appendix ? A, we measure ?(?) with respect to 900 randomly generated arches as well as the model accuracy (ACC) on clean inputs and the attack success rate (ASR) on trigger-embedded inputs. Specifically, for each arch ?, we first train the model f ? to measure ACC and then train the trigger generator g with respect to f ? on the same dataset to measure ASR, with results shown in Figure <ref type="figure" target="#fig_4">2</ref>. Observe that the conditional number of ?(?) has a strong negative correlation with ASR, with a smaller value indicating higher attack vulnerability; meanwhile, it has a limited correlation with ACC, with most of the arches having ACC within the range from 80% to 95%.</p><p>Leveraging the insights above, we present a simple yet effective algorithm that searches for exploitable arches without training, which is a variant of regularized evolution <ref type="bibr" target="#b36">(Real et al., 2019;</ref><ref type="bibr">Mellor et al., 2021)</ref>. As sketched in Algorithm 1, it starts from a candidate pool A of n arches randomly sampled from a pre-defined arch space; at each iteration, it samples a subset A ? of m arches from A, randomly mutates the best candidate (i.e., with the lowest score), and replaces the oldest arch in A with this newly mutated arch. In our implementation, the score function is defined as the condition number of Eq. 6; the arch space is defined to be the NATS-Bench search space <ref type="bibr" target="#b12">(Dong &amp; Yang, 2020)</ref>, which consists of 5 atomic operators {none, skip connect, conv 1 ? 1, conv 3 ? 3, and avg pooling 3 ? 3}; and the mutation function is defined to be randomly substituting one operator with another.</p><p>Algorithm 1: EVAS Attack </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>We conduct an empirical evaluation of EVAS on benchmark datasets under various scenarios. The experiments are designed to answer the following key questions: (i) does it work? -we evaluate the performance and vulnerability of the arches identified by EVAS; (ii) how does it work? -we explore the dynamics of EVAS search as well as the characteristics of its identified arches; and (ii) how does it differ? -we compare EVAS with conventional backdoors in terms of attack evasiveness, transferability, and robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">EXPERIMENTAL SETTING</head><p>Datasets. In the evaluation, we primarily use three datasets that have been widely used to benchmark NAS methods <ref type="bibr" target="#b7">(Chen et al., 2019;</ref><ref type="bibr" target="#b22">Li et al., 2020;</ref><ref type="bibr">Liu et al., 2019;</ref><ref type="bibr" target="#b34">Pham et al., 2018;</ref><ref type="bibr" target="#b43">Xie et al., 2019)</ref>: CIFAR10 <ref type="bibr" target="#b20">(Krizhevsky &amp; Hinton, 2009)</ref>, which consists of 32?32 color images drawn from 10 classes; CIFAR100, which is similar to CIFAR10 but includes 100 finer-grained classes; and ImageNet16, which is a subset of the ImageNet dataset <ref type="bibr" target="#b10">(Deng et al., 2009)</ref> down-sampled to images of size 16?16 in 120 classes.</p><formula xml:id="formula_10">0 2 1 3 0 2 1 3 0 2 1 3 Conv 1?1 Conv 3?3 Avg Pool 3?3 Skip Connect (i) EVAS (ii) Random 1 (iii) Random 2</formula><p>Search space. We consider the search space defined by NATS-Bench ( Dong et al. ( <ref type="formula">2021</ref>)), which consists of 5 operators {none, skip connect, conv 1 ? 1, conv 3 ? 3, and avg pooling 3 ? 3} defined among 4 nodes, implying a search space of 15,625 candidate arches.</p><p>Baselines. We compare the arches found by EVAS with ResNet18 <ref type="bibr" target="#b16">(He et al., 2016)</ref>, a manually designed arch. For completeness, we also include two arches randomly sampled from the NATS-Bench space, which are illustrated in Figure <ref type="figure" target="#fig_5">3</ref>. By default, for each arch ?, we assume the adversary trains a model f ? and then trains the trigger generator g with respect to f ? on the same dataset. We consider varying settings in which the victim directly uses f ? , fine-tunes f ? , or only uses ? and re-trains it from scratch (details in ? 4.4).</p><p>Metrics. We mainly use two metrics, attack success rate (ASR) and clean data accuracy (ACC). Intuitively, ASR is the target model's accuracy in classifying trigger inputs to the adversary's target class during inference, which measures the attack effectiveness, while ACC is the target model's accuracy in correctly classifying clean inputs, which measures the attack evasiveness.</p><p>The default parameter setting and the trigger generator configuration are deferred to Appendix ? A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Q1: DOES EVAS WORK?</head><p>Figure <ref type="figure" target="#fig_5">3</ref> illustrates one sample arch identified by EVAS on the CIFAR10 dataset. We use this arch throughout this set of experiments to show that its vulnerability is at the arch level and universal across datasets. To measure the vulnerability of different arches, we first train each arch using clean data, then train a trigger generator specific to this arch, and finally measure its ASR and ACC.</p><p>Table <ref type="table" target="#tab_1">1</ref> reports the results. We have the following observations. First, the ASR of EVAS is significantly higher than ResNet18 and the other two random arches. For instance, on CIFAR10, EVAS is 21.8%, 28.3%, and 34.5% more effective than ResNet18 and random arches, respectively. Second, EVAS has the highest ASR across all the datasets. Recall that we use the same arch throughout different datasets. This indicates that the attack vulnerability probably resides at the arch level and is insensitive to concrete datasets, which corroborates with prior work on NAS: one performant arch found on one dataset often transfers across different datasets <ref type="bibr">(Liu et al., 2019)</ref>. This may be explained as follows. An arch ? essentially defines a function family F ? , while a trained model f ? (?; ?) is an instance in F ? , thereby carrying the characteristics of F ? (e.g., effective to extract important features or exploitable by a trigger generator). Third, all the arches show higher ASR on simpler datasets such as CIFAR10. This may be explained by that more complex datasets (e.g., more classes, higher resolution) imply more intricate manifold structures, which may interfere with arch-level backdoors. To understand the attack effectiveness of EVAS on individual inputs, we illustrate sample clean inputs and their trigger-embedded variants in Figure <ref type="figure" target="#fig_6">4</ref>. Further, using GradCam <ref type="bibr" target="#b37">(Selvaraju et al., 2017)</ref>, we show the model's interpretation of clean and trigger inputs with respect to their original and target classes. Observe that the trigger pattern is specific to each input. Further, even though the two trigger inputs are classified into the same target class, the difference in their heatmaps shows that the model pays attention to distinct features, highlighting the effects of input-aware triggers. Next, we explore the dynamics of how EVAS searches for exploitable arches. For simplicity, given the arch identified by EVAS in Figure <ref type="figure" target="#fig_5">3</ref>, we consider the set of candidate arches with the operators on the 0-3 (skip connect) and 0-1 (conv 3?3) connections replaced by others. We measure the ACC and ASR of all these candidate arches and illustrate the landscape of their scores in Figure <ref type="figure" target="#fig_8">5</ref>. Observe that the exploitable arch features the lowest score among the surrounding arches, suggesting the existence of feasible mutation paths from random arches to reach exploitable arches following the direction of score descent.  Further, we ask the question: what makes the arches found by EVAS exploitable? Observe that the arch in Figure <ref type="figure" target="#fig_5">3</ref> uses the conv 1?1 and 3?3 operators on a number of connections. We thus generate arches by enumerating all the possible combinations of conv 1?1 and 3?3 on these connections and measure their performance, with results summarized in Appendix ? B. Observe that while all these arches show high ASR, their vulnerability varies greatly from about 50% to 90%. We hypothesize that specific combinations of conv 1?1 and conv 3?3 create arch-level "shortcuts" for recognizing trigger patterns. We consider exploring the causal relationships between concrete arch characteristics and attack vulnerability as our ongoing work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Q3: HOW DOES EVAS DIFFER?</head><p>To further understand the difference between EVAS and conventional backdoors, we compare the arches found by EVAS and other arches under various training and defense scenarios.</p><p>Fine-tuning with clean data. We first consider the scenario in which, with the trigger generator fixed, the target model is fine-tuned using clean data (with concrete setting deferred to Appendix ? A).</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the results evaluated on CIFAR10 and CIFAR100. Observe that fine-tuning has a marginal impact on the ASR of all the arches. Take Random I as an example, compared with Table <ref type="table" target="#tab_1">1</ref>, its ASR on CIFAR10 drops only by 7.40% after fine-tuning. This suggests that the effectiveness of fine-tuning to defend against input-aware backdoor attacks may be limited. Re-training from scratch. Another common scenario is that the victim user re-initializes the target model and re-trains it from scratch using clean data. We simulate this scenario as follows. After the trigger generator and target model are trained, we fix the generator, randomly initialize (using different seeds) the model, and train it on the given dataset. Table <ref type="table" target="#tab_3">3</ref> compares different arches under this scenario. It is observed that EVAS significantly outperforms ResNet18 and random arches in terms of ASR (with comparable ACC). For instance, it is 33.4%, 24.9%, and 19.6% more effective than the other arches respectively. This may be explained by two reasons. First, the arch-level backdoors in EVAS are inherently more agnostic to model re-training than the model-level backdoors in other arches. Second, in searching for exploitable arches, EVAS explicitly enforces that such vulnerability should be insensitive to model initialization (cf. Eq. 4). Further, observe that, as expected, re-training has a larger impact than fine-tuning on the ASR of different arches; however, it is still insufficient to mitigate input-aware backdoor attacks. Fine-tuning with poisoning data. Further, we explore the setting in which the adversary is able to poison a tiny portion of the fine-tuning data, which assumes a stronger threat model. To simulate this scenario, we apply the trigger generator to generate trigger-embedded inputs and mix them with the clean fine-tuning data. Figure <ref type="figure" target="#fig_9">6</ref> illustrates the ASR and ACC of the target model as functions of the fraction of poisoning data in the fine-tuning dataset. Observe that, even with an extremely small poisoning ratio (e.g., 0.01%), it can significantly boost the ASR (e.g., 100%) while keeping the ACC unaffected. This indicates that arch-level backdoors can be greatly enhanced by combining with other attack vectors (e.g., data poisoning). Backdoor defenses. Finally, we evaluate EVAS against three categories of defenses, model inspection, input filtering, and model sanitization.</p><p>Model inspection determines whether a given model f is infected with backdoors. We use Neural-Cleanse <ref type="bibr" target="#b41">(Wang et al., 2019)</ref> as a representative defense. Intuitively, it searches for potential triggers in each class. If a class is trigger-embedded, the minimum perturbation required to change the predictions of inputs from other classes to this class is abnormally small. It detects anomalies using median absolute deviation (MAD) and all classes with MAD scores larger than 2 are regarded as infected. As shown in Table <ref type="table" target="#tab_4">4</ref>, the MAD scores of EVAS's target classes on three datasets are all below the threshold. This can be explained by that NeuralCleanse is built upon the universal trigger assumption, which does not hold for EVAS. Input filtering detects at inference time whether an incoming input is embedded with a trigger. We use STRIP <ref type="bibr" target="#b14">(Gao et al., 2019)</ref> as a representative defense in this category. It mixes a given input with a clean input and measures the self-entropy of its prediction. If the input is trigger-embedded, the mixture remains dominated by the trigger and tends to be misclassified, resulting in low self-entropy. However, as shown in Table <ref type="table" target="#tab_4">4</ref>, the AUROC scores of STRIP in classifying trigger-embedded inputs by EVAS are all close to random guess (i.e., 0.5). This can also be explained by that EVAS uses input-aware triggers, where each trigger only works for one specific input and has a limited impact on others. Model sanitization, before using a given model, sanitizes it to mitigate the potential backdoors, yet without explicitly detecting whether the model is tampered. We use Fine-Pruning <ref type="bibr">(Liu et al., 2018)</ref> as a representative. It uses the property that the backdoor attack typically exploits spare model capacity. It thus prunes rarely-used neurons and then applies fine-tuning to defend against pruning-aware attacks. We apply Fine-Pruning on the EVAS and ResNet18 models from Table <ref type="table" target="#tab_1">1</ref>, with results shown in Table <ref type="table" target="#tab_5">5</ref>. Observe that Fine-Pruning has a limited impact on the ASR of EVAS (even less than ResNet18). This may be explained as follows. The activation patterns of input-aware triggers are different from that of universal triggers, as each trigger may activate a different set of neurons. Moreover, the arch-level backdoors in EVAS may not concentrate on individual neurons but span over the whole model structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>This work studies the feasibility of exploiting NAS as an attack vector to launch previously improbable attacks. We present a new backdoor attack that leverages NAS to efficiently find neural network architectures with inherent, exploitable vulnerability. Such architecture-level backdoors demonstrate many interesting properties including evasiveness, transferability, and robustness, thereby greatly expanding the design spectrum for the adversary. We believe our findings raise concerns about the current practice of NAS in security-sensitive domains and point to potential directions to develop effective mitigation.  Here, we measure the NTK conditional number of the target model f under random initialization using the implementation of <ref type="bibr">(Chen et al., 2021)</ref> and its corresponding ASR and ACC. Figure <ref type="figure" target="#fig_11">7</ref> shows their correlation. Observed that the NTK conditional number is negatively correlated with ACC (with Kendall's coefficient ? = -0.385) and has a very weak correlation with ASR (with ? = 0.100), which is consistent with <ref type="bibr">(Chen et al., 2021)</ref>.</p><p>The difference between Figure <ref type="figure" target="#fig_4">2</ref> and Figure <ref type="figure" target="#fig_11">7</ref> can be explained as follows. Figure <ref type="figure" target="#fig_4">2</ref> measures the NTK conditional number ? g of the trigger generator g (with respect to the randomly initialized target model f ), which indicates g's trainability (or f 's vulnerability). As backdoor attacks embed two functions (one classifying clean inputs and the other classifying trigger inputs) into the same model, there tends to exist a natural trade-off between ASR and ACC. Therefore, ? g shows a negative correlation with ASR and a weak positive correlation with ACC. Meanwhile, Figure <ref type="figure" target="#fig_11">7</ref> measures the NTK conditional number ? f of the target model f , which indicates f 's trainability. Therefore, ? f shows a negative correlation with ACC but a very weak correlation with ASR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 ASR-ACC TRADE-OFF</head><p>Figure <ref type="figure" target="#fig_12">8</ref> shows the correlation between the ASR and ACC of sampled arches (with Kendall's coefficient ? = -0.390). Intuitively, as backdoor attacks embed two functions (one classifying clean inputs and the other classifying trigger inputs) into the same model, there tends to exist a natural trade-off between ASR and ACC. This trade-off also implies that it is feasible to properly optimize ASR only to find performant but vulnerable arches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 INTERPRETABILITY VERSUS VULNERABILITY</head><p>To understand the possible correlation between the attack vulnerability of an arch ? and its interpretability, we compare the interpretation of each model f ? regarding 100 clean inputs using GradCam <ref type="bibr" target="#b37">(Selvaraju et al., 2017)</ref>. Figure <ref type="figure">9</ref> illustrates sample inputs and their interpretation by different models.</p><p>Further, to quantitatively measure the similarity of interpretation, we use the intersection-over-union (IoU) score, which is widely used in object detection to compare model predictions with ground-truth bounding boxes. Formally, the IoU score of a binary-valued heatmap m with respect to another map m ? is defined as their Jaccard similarity:</p><formula xml:id="formula_11">IoU(m) = |O(m) ? O(m ? )| |O(m) ? O(m ? )|<label>(7)</label></formula><p>where O(m) denotes the set of non-zero elements in m. In our case, as the values of heatmaps are floating numbers, we first apply thresholding to binarize the values. Figure <ref type="figure" target="#fig_3">10</ref> shows the average IoU score of each arch with respect to another. Observe that (i) the arches generated by NAS (EVAS, Random I, and Random II) have more similar interpretability among themselves than manually</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " 6 t R D b U 4 f H U w 4 V + F Y X A 6 U D b M I t 7 M = " &gt; A A A C e n i c b Z H J a h t B E I Z b 4 y y 2 s n g 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>7 w u 7 B a g 8 k b L o R 0 o m 3 4 F J 1 J B u 9 w x u 9 E s A l d w y e Z n T V 9 7 s O E k j z V C v k c 7 r f t X 7 r t h m u k m 9 4 / F B c n g / T 9 4 P T r S e / s 0 + o u 2 + y I H b P X L G U f 2 B n 7 w s 7 Z k A l m 2 A / 2 k / 3 q 3 E f H 0 Z v o 7 R K N O q u e Q 7 Y W 0 e k f 6 U H E X g = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " T 8 e D i l D K I B v B / k B I s N F d P p 6 3 C I 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>e Z n b e D L g P H S r y V C v k C 3 j Q t n / p t h u u k W 5 7 f 1 W c H A 7 T l 8 P n n w / 7 R + / X d 9 l h j 9 h j d s B S 9 o o d s U / s m I 0 Y s O / s B / v J f k W 7 0 b P o T f R u h U a d 9 Z 8 H b C O i j 3 8 A Z M / J S g = = &lt; / l a t e x i t &gt; f ? (?; ?) t e x i t s h a 1 _ b a s e 6 4 = " e t N J S 7 l</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Attack framework of EVAS. (1) The adversary applies NAS to search for arches with exploitable vulnerability; (2) such vulnerability is retained even if the models are trained using clean data; (3) the adversary exploits such vulnerability by generating trigger-embedded inputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The conditional number of NTK versus the model performance (ACC) and vulnerability (ASR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sample arch identified by EVAS in comparison of two randomly generated arches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Sample clean and trigger-embedded inputs as well as their GradCam interpretation by the target model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Landscape of candidate arches surrounding exploitable arches with their ASR, ACC, and scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS as a function of poisoning ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>= Cout = 128 ConvBNReLU 3x3 Cin = 128, Cout = 64 block 2 Upsample scale_factor = 2 ConvBNReLU 3x3 Cin = Cout = 64 ConvBNReLU 3x3 Cin = 64, Cout = 32 block 2 Upsample scale_factor = 2 ConvBNReLU 3x3 Cin = Cout = 32 ConvBN 3x3 Cin = 32, Cout = mask_generator ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The NTK conditional number of target model versus the model performance (ACC) and vulnerability (ASR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Trade-off between model performance (ACC) and vulnerability (ASR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS, ResNet18, and two random arches.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">architecture</cell><cell></cell><cell></cell></row><row><cell>dataset</cell><cell cols="2">EVAS</cell><cell cols="2">ResNet18</cell><cell cols="2">Random I</cell><cell cols="2">Random II</cell></row><row><cell></cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell></row><row><cell cols="9">CIFAR10 94.26% 81.51% 96.10% 59.73% 91.91% 53.21% 92.05% 47.04%</cell></row><row><cell cols="9">CIFAR100 71.54% 60.97% 78.10% 53.53% 67.09% 42.41% 67.15% 47.17%</cell></row><row><cell cols="9">ImageNet16 45.92% 55.83% 47.62% 42.28% 39.33% 37.45% 39.48% 32.15%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS, ResNet18, and two random arches after fine-tuning.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">architecture</cell><cell></cell><cell></cell></row><row><cell>dataset</cell><cell cols="2">EVAS</cell><cell cols="2">ResNet18</cell><cell cols="2">Random I</cell><cell cols="2">Random II</cell></row><row><cell></cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell></row><row><cell cols="9">CIFAR10 90.33% 74.40% 92.22% 53.87% 85.62% 45.81% 87.02% 45.16%</cell></row><row><cell cols="9">CIFAR100 72.52% 53.50% 79.02% 50.42% 58.89% 38.91% 60.18% 25.41%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS, ResNet18, and two random arches after re-training from scratch.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">architecture</cell><cell></cell><cell></cell></row><row><cell>dataset</cell><cell cols="2">EVAS</cell><cell cols="2">ResNet18</cell><cell cols="2">Random I</cell><cell cols="2">Random II</cell></row><row><cell></cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell></row><row><cell cols="9">CIFAR10 94.18% 64.57% 95.62% 31.15% 91.91% 39.72% 92.09% 45.02%</cell></row><row><cell cols="9">CIFAR100 71.54% 49.47% 78.53% 44.39% 67.09% 35.80% 67.01% 39.24%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Detection results of NeuralCleanse and STRIP for EVAS. NeuralCleanse shows the MAD score and STRIP shows the AUROC score of binary classification.</figDesc><table><row><cell>dataset</cell><cell cols="2">NeuralCleanse STRIP</cell></row><row><cell>CIFAR10</cell><cell>0.895</cell><cell>0.49</cell></row><row><cell>CIFAR100</cell><cell>0.618</cell><cell>0.51</cell></row><row><cell>ImageNet16</cell><cell>0.674</cell><cell>0.49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS and ResNet18 after Fine-Pruning.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">architecture</cell></row><row><cell>dataset</cell><cell cols="2">EVAS</cell><cell cols="2">ResNet18</cell></row><row><cell></cell><cell>ACC</cell><cell>ASR</cell><cell>ACC</cell><cell>ASR</cell></row><row><cell cols="5">CIFAR10 90.53% 72.56% 94.11% 50.95%</cell></row><row><cell cols="5">CIFAR100 64.92% 54.55% 73.35% 38.54%</cell></row><row><cell cols="5">ImageNet16 40.28% 32.57% 42.53% 27.59%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Default parameter setting.</figDesc><table><row><cell>Type</cell><cell>Parameter Setting</cell></row><row><cell></cell><cell>Mask generator training epochs 25</cell></row><row><cell></cell><cell>Mark generator training epochs 10</cell></row><row><cell></cell><cell>Backdoor probability ? b 0.1</cell></row><row><cell>Backdoor attack</cell><cell>Cross-trigger probability ?c 0.1</cell></row><row><cell></cell><cell>Optimizer Adam</cell></row><row><cell></cell><cell>Initial learning rate 0.01</cell></row><row><cell></cell><cell>Batch size 96</cell></row><row><cell></cell><cell>Training epochs 50</cell></row><row><cell></cell><cell>Optimizer SGD</cell></row><row><cell>Fine-tuning</cell><cell>Initial learning rate 0.01</cell></row><row><cell></cell><cell>LR scheduler Cosine annealing</cell></row><row><cell></cell><cell>Batch size 96</cell></row><row><cell></cell><cell>Pool size n 50</cell></row><row><cell>Arch search</cell><cell>Sample size m 10 Mutation function random substitution</cell></row><row><cell></cell><cell>Iterations 4,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Generator network architecture.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In the following, we use "arch" for short of "architecture".</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We thank anonymous reviewers and shepherd for valuable feedback. This work is partially supported by the <rs type="funder">National Science Foundation</rs> under Grant No. <rs type="grantNumber">2212323</rs>, <rs type="grantNumber">2119331</rs>, <rs type="grantNumber">1951729</rs>, and 1953893. Any opinions, findings, and conclusions or recommendations are those of the authors and do not necessarily reflect the views of the National Science Foundation. S. Ji is partly supported by the <rs type="funder">National Key Research and Development Program of China</rs> under No. <rs type="grantNumber">2022YFB3102100</rs>, and <rs type="funder">NSFC</rs> under No. <rs type="grantNumber">62102360</rs> and <rs type="grantNumber">U1936215</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_B2n8yT7">
					<idno type="grant-number">2212323</idno>
				</org>
				<org type="funding" xml:id="_RJnugJ5">
					<idno type="grant-number">2119331</idno>
				</org>
				<org type="funding" xml:id="_ZW3Zf5W">
					<idno type="grant-number">1951729</idno>
				</org>
				<org type="funding" xml:id="_k5TNyGp">
					<idno type="grant-number">2022YFB3102100</idno>
				</org>
				<org type="funding" xml:id="_NyU7Psy">
					<idno type="grant-number">62102360</idno>
				</org>
				<org type="funding" xml:id="_Q6mM9bk">
					<idno type="grant-number">U1936215</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A EXPERIMENTAL SETTING</head><p>A.1 PARAMETER SETTING   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 ABLATION OF ATTACK EVASIVENESS</head><p>The evasiveness of EVAS may be accounted by (i) input-dependent triggers (Nguyen &amp; Tran, 2020) and (ii) arch-level vulnerability. Here, we explore the contribution of input-dependent triggers to the attack evasiveness. We train the trigger generator with respect to different arches (EVAS, ResNet18, random arches) and run NeuralCleanse and STRIP to detect the attacks, with results summarized in Table <ref type="table">8</ref>. Observed that while the concrete measures vary, all the attacks have MAD scores below the threshold and AUROC scores close to random guess, indicating that the input-dependent triggers mainly account for the attack evasiveness with respect to NeuralCleanse and STRIP. We generate neighboring arches by enumerating all possible combinations of conv 1?1 and conv 3?3 on the connections of the arch identified by EVAS ("|{0} ? 0|+|{1} ? 0|{2} ? 1|+|skip_connect ? 0|{3} ? 1|{4} ? 2|"). The ASR and ACC of these arches are summarized in Table <ref type="table">9</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Zero-Cost Proxies for Lightweight NAS</title>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Mohamed S Abdelfattah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Dudziak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lane</forename><surname>Donald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Designing Neural Network Architectures using Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Machine Learning (ICML)</title>
		<meeting>IEEE Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wild Patterns: Ten Years after The Rise of Adversarial Machine Learning</title>
		<author>
			<persName><forename type="first">Battista</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Architectural Backdoors in Neural Networks</title>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Bober-Irizar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilia</forename><surname>Shumailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiren</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective</title>
		<author>
			<persName><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective</title>
		<author>
			<persName><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning</title>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On Lazy Training in Differentiable Programming</title>
		<author>
			<persName><forename type="first">Lenaic</forename><surname>Chizat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-scale Hierarchical Image Database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On Adversarial Robustness: A Neural Architecture Search perspective</title>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Devaguptapu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devansh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pulkit</forename><surname>Gopalani</surname></persName>
		</author>
		<author>
			<persName><surname>Vineeth N Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RobustML Workshop of International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size</title>
		<author>
			<persName><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarzyna</forename><surname>Musial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Gabrys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeddings of IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<meeting>eeddings of IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">STRIP: A Defence Against Trojan Attacks on Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiping</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damith</forename><surname>Ranasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surya</forename><surname>Nepal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural Tangent Kernel: Convergence and Generalization in Neural Networks</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Jacot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cl?ment</forename><surname>Hongler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Machine Learning (ICML)</title>
		<meeting>IEEE Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Model-Reuse Attacks on Deep Learning Systems</title>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouling</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SAC Conference on Computer and Communications (CCS)</title>
		<meeting>ACM SAC Conference on Computer and Communications (CCS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Empirical Exploration of Recurrent Network Architectures</title>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Machine Learning (ICML)</title>
		<meeting>IEEE Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wide Neural Networks of Any Depth Evolve as Linear Models under Gradient Descent</title>
		<author>
			<persName><forename type="first">Jaehoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lechao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SGAS: Sequential Greedy Architecture Search</title>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guocheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Itzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Delgadillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Trojaning Attack on Neural Networks</title>
		<author>
			<persName><forename type="first">Yingqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yousra</forename><surname>Aafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Chuan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Network and Distributed System Security Symposium (NDSS)</title>
		<meeting>Network and Distributed System Security Symposium (NDSS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">ABS: Scanning Neural Networks for Back-Doors by Artificial Brain Stimulation</title>
		<author>
			<persName><forename type="first">Yingqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Chuan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanhong</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yousra</forename><surname>Aafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SAC Conference on Computer and Communications (CCS)</title>
		<meeting>ACM SAC Conference on Computer and Communications (CCS)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural Architecture Search without Training</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Machine Learning (ICML)</title>
		<meeting>IEEE Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Demystifying the Neural Tangent Kernel from a Practical Perspective: Can it be trusted for Neural Architecture Search without training?</title>
		<author>
			<persName><forename type="first">Jisoo</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byunggook</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Hoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Input-Aware Dynamic Backdoor Attack</title>
		<author>
			<persName><forename type="first">Anh</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuan</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tran</forename><surname>Anh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluating Efficient Performance Estimators of Neural Architectures</title>
		<author>
			<persName><forename type="first">Xuefei</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changcheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenshuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huazhong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models</title>
		<author>
			<persName><forename type="first">Ren</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouling</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgeniy</forename><surname>Vorobeychik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SAC Conference on Computer and Communications (CCS)</title>
		<meeting>ACM SAC Conference on Computer and Communications (CCS)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the Security Risks of AutoML</title>
		<author>
			<persName><forename type="first">Ren</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouling</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Security Symposium</title>
		<meeting>USENIX Security Symposium</meeting>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tro-janZoo: Towards Unified, Holistic, and Practical Evaluation of Neural Backdoors</title>
		<author>
			<persName><forename type="first">Ren</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangshan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouling</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE European Symposium on Security and Privacy</title>
		<meeting>IEEE European Symposium on Security and Privacy</meeting>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
	<note>Euro S&amp;P</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient Neural Architecture Search via Parameter Sharing</title>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melody</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Machine Learning (ICML)</title>
		<meeting>IEEE Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tinghao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruizhe</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jifeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Bu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Shafahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Ronny</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahyar</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Octavian</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tudor</forename><surname>Dumitras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haixu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kehuan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of USENIX Security Symposium (SEC)</title>
		<meeting>USENIX Security Symposium (SEC)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spectral Signatures in Backdoor Attacks</title>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Security and Privacy (S&amp;P)</title>
		<meeting>IEEE Symposium on Security and Privacy (S&amp;P)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Training-Free Genetic Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Meng-Ting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-I</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun-Wei</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM International Conference on Intelligent Computing and its Emerging (ICEA)</title>
		<meeting>ACM International Conference on Intelligent Computing and its Emerging (ICEA)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SNAS: Stochastic Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Latent Backdoor Attacks on Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Yuanshun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SAC Conference on Computer and Communications (CCS)</title>
		<meeting>ACM SAC Conference on Computer and Communications (CCS)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning Transferable Architectures for Scalable Image Recognition</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m">ASR and ACC of arches perturbed from &quot;|{0} ? 0| + |{1} ? 0|{2} ? 1| + |skip_connect ? 0|{3} ? 1|{4} ? 2|&quot; {0} {1} {2} {3} {4} ASR ACC Conv 1x1</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
