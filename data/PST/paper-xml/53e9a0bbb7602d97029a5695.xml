<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recommendations to Boost Content Spread in Social Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vineet</forename><surname>Chaoji</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Yahoo! Labs UCSB</orgName>
								<address>
									<settlement>Santa Barbara, Bangalore</settlement>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sayan</forename><surname>Ranu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Yahoo! Labs UCSB</orgName>
								<address>
									<settlement>Santa Barbara, Bangalore</settlement>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rajeev</forename><surname>Rastogi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Yahoo! Labs UCSB</orgName>
								<address>
									<settlement>Santa Barbara, Bangalore</settlement>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rushi</forename><surname>Bhatt</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Yahoo! Labs UCSB</orgName>
								<address>
									<settlement>Santa Barbara, Bangalore</settlement>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">†</forename><surname>Dept</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Yahoo! Labs UCSB</orgName>
								<address>
									<settlement>Santa Barbara, Bangalore</settlement>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Of Computer Science</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Yahoo! Labs UCSB</orgName>
								<address>
									<settlement>Santa Barbara, Bangalore</settlement>
									<country>USA, India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recommendations to Boost Content Spread in Social Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">70E770BEA4CB8F55778FD61ABA125506</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.4 [Information Storage and Retrieval]: Systems and Software-information networks Algorithms</term>
					<term>Experimentation content spread</term>
					<term>recommendation</term>
					<term>social networks WWW 2012 -Session: Information Diffusion in Social Networks April 16-20</term>
					<term>2012</term>
					<term>Lyon</term>
					<term>France</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Content sharing in social networks is a powerful mechanism for discovering content on the Internet. The degree to which content is disseminated within the network depends on the connectivity relationships among network nodes. Existing schemes for recommending connections in social networks are based on the number of common neighbors, similarity of user profiles, etc. However, such similarity-based connections do not consider the amount of content discovered.</p><p>In this paper, we propose novel algorithms for recommending connections that boost content propagation in a social network without compromising on the relevance of the recommendations. Unlike existing work on influence propagation, in our environment, we are looking for edges instead of nodes, with a bound on the number of incident edges per node. We show that the content spread function is not submodular, and develop approximation algorithms for computing a near-optimal set of edges. Through experiments on real-world social graphs such as Flickr and Twitter, we show that our approximation algorithms achieve content spreads that are as much as 90 times higher compared to existing heuristics for recommending connections.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Social networks are increasingly becoming a powerful medium for disseminating and discovering useful content. In popular social networking sites like Google+ and Twitter, users share activity updates with their neighbors or followers. The updates typically include recently uploaded photos, comments on photos and news articles, reviews and ratings that the user has assigned to a movie or restaurant, or simply an article or game on the web that the user has liked. Each neighbor recursively shares received updates within its own neighborhood, and content generated by a user propagates through the network to a wide user population. Thus, social networks enable users to share content at an unprecedented scale, and discover new content of interest to them.</p><p>On friendship networks such as Facebook, the content spread is confined since connections are typically made to a close group of friends<ref type="foot" target="#foot_0">1</ref> . On the contrary, content-centric networks such as Twitter and Google+ promote content spread by allowing users to connect with people having common interests, who are most likely not their friends. The extent to which a social network spreads content is a key metric that impacts both user engagement and network revenues. The more content spreads, the more novel content users end up discovering, and the more value users derive from being part of the social network. The effective dissemination of generated content also helps users build their "online social reputation". For instance, on microblogging sites such as Twitter, the number of active followers is indicative of a user's online reputation <ref type="bibr" target="#b22">[22]</ref>. Building an active following is contingent on the content reaching the right set of interested users on Twitter.</p><p>From the social network's perspective, higher content spread helps drive up user engagement which in turn leads to improved user retention and audience growth. Furthermore, as users spend more time accessing diverse content in the form of photos, news articles, games etc., there are increased opportunities for monetizing the content via online ads, sale of virtual goods, subscriptions, and so on. As a result of the above benefits, it is crucial for social networks to maximize the dissemination of interesting content across the entire social graph.</p><p>One way to boost content spread in a social network is by increasing the connectivity among users. Social networking sites like Twitter and Google+ already offer "people recommendations" to users to increase connectivity. These people recommender implementations, however, focus primarily on making relevant recommendations without an explicit effort towards increasing content availability. For instance, the "People You May Know" feature employs the Friend-of-Friend (FoF) algorithm <ref type="bibr" target="#b1">[1]</ref> that recommends users based on the number of common friends with the user receiving the recommendation. Other recommender algorithms, for e.g., in Twitter <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b12">12]</ref>, suggest users whose profiles, interests, or updates have substantial overlap with the receiver of the recommendation. In a typical social network, the number of relevant recommendations that qualify based on criteria such as FoF or interest similarity can be significantly large. However, different subsets of these relevant recommendations may have very diverse content spread characteristics. Consequently, simply recommending connections based on the number of mutual friends or similarity between profiles and posted content may not maximize content spread in the social network. This is illustrated in the following example.</p><p>Example 1. Consider the simple social network in Figure <ref type="figure" target="#fig_0">1</ref> with users A, . . ., G. Suppose that user G generates a piece of content c, and each user (except for E which does not share content) shares content with its neighbors with a probability of 1  2 . Then, users D and F each receive c with probability 1  2 , E receives c through D or F with probability 4 (c reaches E with probability 1 2 along edge (G, E) and with probability 1  4 along the two paths passing through D and F; thus, the probability that c reaches E along one of the paths is 1 -</p><formula xml:id="formula_0">(1 -(1 -1 2 • 1 2 ) • (1 -1 2 • 1 2 )) =</formula><formula xml:id="formula_1">1 2 • 3 4 • 3 4 ≈ 3 4</formula><p>). Furthermore, there is no change in the probability with which c reaches users C, D and F. Thus, with edge (G, E), the only change in content spread is that c reaches E with 3  4 -7 16 = 5 16 more probability. On the other hand, if G connects with C instead, then c reaches C with probability 5  8 (c reaches C with probability 1 2 along edge (G, C) and with probability 1  4 along the path through D). Furthermore, c reaches users A and B with probability 5  16 . Thus, with edge (G, C), c reaches C with 3 8 more probability, and users B and A each with 3  16 more probability.</p><p>Consequently, even though both E and C are two hops from G, and E has the maximum number of common friends with G, connecting G with C results in content spreading to users with 3  4 (= 3 8 + 3 16 + 3 16 ) higher probability compared to 5  16 as a result of connecting G with E. ✷</p><p>In this paper, we consider the problem of recommending connections that maximize content spread in a social network while ensuring that the recommendations are relevant. For each user u, our approach first identifies a candidate set Nu of similar users based on the number of common neighbors, proximity in the social graph, similarity of profiles and posted content, etc. It then selects up to k users Ru from each user's candidate set Nu such that if every u connects with users in Ru then the content spread in the network is maximized. The k users in Ru are recommended for connection to user u.</p><p>Observe that by recommending a subset of Nu to user u, we ensure that the connections recommended to each user are relevant. In typical social networks, the set Nu can be very large (in the order of hundreds or thousands). By using the content spread objective to select the subset Ru, our recommendation scheme essentially balances the needs of both users (by recommending relevant users) and the social network provider (by boosting content spread in the network). In addition, the constraint k on the maximum number of new connections per user prevents deluging active or highly connected users with an unreasonable number of recommendations. Presenting each user with a bounded number k of relevant connections ensures a good user experience. For the same reason, social networking sites such as Twitter typically limit the number of recommendations to about 10.</p><p>Our work differs from prior research on influence maximization in social networks <ref type="bibr" target="#b14">[14]</ref>. The objective in <ref type="bibr" target="#b14">[14]</ref> is to select the top-k influential nodes in the network that can be targeted to maximize influence spread in the network. The authors show that even though influence maximization is NP-hard, the influence spread function on nodes is submodular, and thus a greedy strategy yields influence spreads that are within (1-1 e ) of the optimum. In contrast, our content spread maximization problem looks to add up to k new connections per node so that content spread is maximized. As edges are added to the social network, its structure itself changes, and so the content spread function on edges is no longer submodular -this precludes simple greedy solutions. Furthermore, in our problem setting, there are complex constraints requiring that the number of new edges incident on any node of the social graph is at most k. Thus, we have millions of local constraints on selected edges as opposed to a single global constraint in <ref type="bibr" target="#b14">[14]</ref> on the number of selected nodes. The lack of submodularity coupled with complex local constraints make our content spread maximization problem a lot more challenging.</p><p>To summarize, our main contributions are as follows: • We formally define the content maximization problem that seeks to add up to k connections per user such that the (probabilistic) propagation of content in the social network is maximized. To the best of our knowledge, the people recommendation problem with the explicit goal of maximizing content availability in the social network is new.</p><p>• We show that our content maximization problem is NPhard. Moreover, our content spread function lacks desirable properties like submodularity that allow for efficient approximation algorithms. We propose a restricted variant that is submodular and closely approximates our original content spread function.</p><p>• For our restricted content spread function, we devise an approximation algorithm that computes an edge set satisfying constraints and whose content spread is provably close to the optimum.</p><p>• We conduct an extensive experimental study with reallife social networks from Twitter, Flickr, etc. In our experiments, the connections recommended by our algorithm achieve content spreads that are as much as 90 times higher compared to the FoF heuristic and 4 times more than simple greedy strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">THE CONTENT MAXIMIZATION PROB-LEM</head><p>We model the social network as an undirected graph G = (V, E) where nodes represent users and edges are the connections between them. Furthermore, we denote the pieces of content (e.g., photos, comments, articles) that nodes share with their neighbors over a fixed time period (e.g., a month) by C. Each node i in the graph has the following three parameters: (1) pi, the probability with which node i shares content independently with each of its neighbors, (2) ci ⊆ C, the content generated or discovered by node i, and (3) Ni, the set of nodes in G that is compatible with node i. The parameter pi can be empirically estimated by observing the fraction of content that a node shares with its neighbors. Also, Ni = {j : sim(i, j) &gt; α ∧ j ∈ V }. Here, sim(i, j) is the similarity between nodes i and j computed based on the number of hops between the nodes, the number of common neighbors, node profiles (e.g., preferences, educational background), and posted content. The user-defined parameter α ensures that nodes in Ni are fairly similar to i, and are thus relevant candidates for recommendation to i.</p><p>Observe that the parameters ci and pi determine the flow of content through the network. We define the content spread within the network as:</p><p>c Expected number of nodes with content c. Our objective in this paper is to compute a set of relevant recommendations X such that the content spread is maximized. Each recommendation in X is a node pair (i, j), and indicates that node i is recommended to j, and vice versa. Now, suppose that PX (i, c) is the probability of content c reaching node i over the edge set E ∪ X. Then, the expected number of nodes with content c is given by i PX (i, c), and the content spread with new edges X is f (X) = c i PX (i, c). We formally define our content maximization problem below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1. Content Maximization Problem:</head><p>Given a graph G = (V, E) and a constant k, find an edge set X ⊆ {(i, j) : i, j ∈ V } such that: (1) At most k edges from X are incident on any node in V , <ref type="bibr" target="#b2">(2)</ref> For each (i, j) ∈ X, i ∈ Nj and j ∈ Ni, and (3) f (X) is maximum. ✷</p><p>The term PX (i, c) within the content spread expression f (X) depends on the specific content propagation model <ref type="bibr" target="#b10">[10,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b4">4]</ref> employed. A popular model for the spread of information or influence through a social network is the Independent Cascade (IC) model <ref type="bibr" target="#b14">[14]</ref>. In this model, when a node receives or generates a new piece of content c (that it has not seen before) at step t, it shares the content with its neighbors in the subsequent step t + 1. Thus, each node shares specific content with its neighbors only once.</p><p>Our content spread function f (•) under the IC model has two main drawbacks. First, computing the expected number of nodes with specific content c is #P-hard <ref type="bibr" target="#b4">[4]</ref>, and so accurately estimating the content spread requires running expensive simulations for a large number of times. To overcome the high computation cost, Chen et al. <ref type="bibr" target="#b4">[4]</ref> propose an efficient heuristic that restricts influence propagation between a pair of nodes to be only along the maximum probability path (MPP) between the nodes. This propagation model can also be applied to our setting, thus allowing the content spread function f (•) to be efficiently computed. We will refer to this model as the MPP model in this paper. Interestingly, even though the MPP model is more restrictive compared to the IC model, Chen et al. <ref type="bibr" target="#b4">[4]</ref> empirically show that the Unfortunately, the set cover problem can be reduced to our content maximization problem resulting in the following theorem.</p><p>Theorem 1. The content maximization problem is NPhard under both the IC and MPP models.</p><p>Proof. Follows from a reduction of the Set Cover problem to the content maximization problem. Details omitted due to space constraints.</p><p>The second drawback is that under both the IC and MPP models, f (•) lacks properties that would allow us to devise good approximation algorithms. One such property is submodularity -a function h on subsets of edges is submodular if h(S ∪ {e})h(S) ≥ h(T ∪ {e})h(T ) for all edges e and all pairs of edge subsets S ⊆ T . Kempe et al. <ref type="bibr" target="#b14">[14]</ref> and Chen et al. <ref type="bibr" target="#b4">[4]</ref> show that influence spread is submodular under the IC and MPP models, thus enabling a simple greedy strategy to yield a solution that is within a factor of (1 -1 e ) of the optimum. However, our content spread function f (•) defined on edges is very different from influence spread which is defined on nodes. Specifically, when computing the content spread f (X), the new edge set X gets added to the underlying graph G and this changes the structure of G. In the following example, we show that f (•) is not submodular under the IC and MPP models.</p><p>Example 2. Consider the social network graph with 5 nodes and 2 edges depicted in Figure <ref type="figure" target="#fig_1">2</ref>. Let each node have propagation probability 1 and let only node 1 contain a single piece of content c. Let S = ∅, T = {(2, 3)} and e = (1, 2). Now f (S ∪ {e})f (S) = 2 -1 = 1 since with edge e, content c from node 1 reaches node 2 with probability 1. On the other hand, f (T ∪ {e})f (T ) = 5 -1 = 4 since with edges (1, 2) and (2, 3), content c from node 1 reaches every node j with probability 1 along the unique path from 1 to j. Thus, since f</p><formula xml:id="formula_2">(S ∪ {e}) -f (S) &lt; f (T ∪ {e}) -f (T ) for S ⊆ T , f (•) is not submodular. ✷</formula><p>In the next section, we propose a restricted content propagation model that closely approximates the MPP model but in which content spread f (•) is submodular. This allows us to develop efficient approximation algorithms for content maximization. Although, in our problem setting, we have more complex constraints that require the number of edges incident on each node to be no more than k. The constraints preclude simple greedy approaches, and necessitate more involved approximation algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A SUBMODULAR CONTENT SPREAD FUNCTION</head><p>We now present our new content propagation model in which content spread is both submodular and efficient to compute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Restricted Maximum Probability Path Model</head><p>For a path i = u1, u2, . . . , ur = j through nodes u1, u2,. . . , ur, we define the propagation probability of the path as</p><formula xml:id="formula_3">pu 1 • pu 2 • • • pu r-1</formula><p>. This is essentially the probability that content from node i reaches j along the path. Our new model transmits content along paths that are restrictions of MPPs -we define these paths below.</p><p>Definition 2. Restricted Maximum Probability Path (RMPP): For edge set X, the restricted maximum probability path RM P PX (i, j) from node i to node j is the path with the maximum probability among all paths from i to j containing at most one edge from X. Ties are broken arbitrarily.</p><p>✷ In our new RMPP model, content from node i flows to node j only along the path RM P PX (i, j). These RMPPs between nodes are used to compute the content spread f (X) for an edge set X. Thus, the RMPP model restricts content propagation paths to contain at most one edge from X, and this ensures submodularity of content spreads. In Section 5, we show that considering these restricted propagation paths has little effect on content spread values; this is because a bulk of the probability mass is concentrated along such paths. Note that RMPPs can be efficiently computed using a variant of Dijkstra's shortest path algorithm; omitted here due to space considerations.</p><p>To illustrate the submodularity property in the RMPP model, let us revisit the social graph in Figure <ref type="figure" target="#fig_1">2</ref>. Assume that all nodes have propagation probabilities of 1 and content c is only at node 1. Let us compute the content spread for edge sets S = ∅, T = {(2, 3)} and e = (1, 2) in the RMPP model. The content spread is 1 for edge sets S and T since node 1 is completely disconnected from the rest of the graph. For edge set S ∪ {e}, the content spread is 2 because content c reaches node 2 with probability 1 along path 1, 2 . The content spread for edge set T ∪ {e} is also 2 because the content c from node 1 can only reach node 2. It cannot reach other nodes since this would require the content to traverse a path containing both edges in T ∪{e} which is not allowed. Thus, f (S ∪ {e})f (S) = f (T ∪ {e})f (T ) in the RMPP model. This is in contrast to the MPP model under which</p><formula xml:id="formula_4">f (S ∪ {e}) -f (S) &lt; f (T ∪ {e}) -f (T ) (see Example 2).</formula><p>In addition to submodularity, the content spread in the RMPP model can also be efficiently computed. We make the following two simplifying assumptions to speed up computation and design effective algorithms: (1) Similar to the MPP model in <ref type="bibr" target="#b4">[4]</ref>, we use a threshold θ to prune paths with too small propagation probabilities, and (2) We assume that content propagates along each path independent of other paths. Note that the MPP model in <ref type="bibr" target="#b4">[4]</ref> does not assume path independence. In Section 5, we show that the path independence assumption minimally impacts the computed content spread values. Thus, the content spreads for the RMPP and MPP models are very close. Now, for our RMPP model, we can compute the probability PX (i, c) of content c getting to node i for a new edge set X as follows. Let V (c) denote the nodes containing content c. Further, for j ∈ V (c), let qX (j, i) be the probability of the path RM P PX (j, i) from j to i if it is above threshold θ. On the other hand, if the probability of path RM P PX (j, i) is less than θ, then qX (j, i) = 0. Since the propagation of content to node i along the individual paths RM P PX (j, i) are independent, we get that PX (i, c) = 1-j∈V (c) (1-qX (j, i)).</p><p>Thus, the content spread function in the RMPP model is given by:</p><formula xml:id="formula_5">f (X) = c i PX (i, c) = c i (1 - j∈V (c) (1 -qX (j, i)))</formula><p>(1) Our content maximization problem in the RMPP model is then to find an edge set X in graph G that maximizes the content spread f (X) in Equation ( <ref type="formula">1</ref>) above subject to constraints (1) and ( <ref type="formula">2</ref>) in Definition 1. This problem can also be shown to be NP-hard using a reduction similar to the one used for content maximization under MPP in Theorem 1 earlier. The following example illustrates content spread computation under the RMPP model.</p><p>Example 3. Consider the social graph in Figure <ref type="figure" target="#fig_1">2</ref>. Let the propagation probabilities for all nodes be 1  2 . Furthermore, let node 1 contain content c, and nodes 4 and 5 contain content c ′ . Finally, let</p><formula xml:id="formula_6">X = {(1, 2), (2, 3)}. Now, PX (2, c) = p1 = 1</formula><p>2 since c can flow from 1 to 2 along path <ref type="bibr" target="#b1">(1,</ref><ref type="bibr" target="#b2">2)</ref>. However, PX (j, c) = 0 for j ≥ 3 since there is no path from 1 to j containing at most one edge from X. Content c ′ can reach node 3 from 4 and 5 along two paths 4, 3 and 5, 3 , respectively. Thus,</p><formula xml:id="formula_7">PX (3, c ′ ) = 1 -(1 -p4)(1 -p5) = 3 4 . Similarly, since content c ′ can reach 2 along paths 4, 3, 2 and 5, 3, 2 , we get PX (2, c ′ ) = 1-(1-p4 •p3)(1-p5 •p3) = 7</formula><p>16 . However, content c ′ cannot reach node 1 because paths to 1 from 4 and 5 involve two edges from X. Thus, content spread</p><formula xml:id="formula_8">f (X) = i PX (i, c) + i PX (i, c ′ ) = (1 + 1 2 ) + (2 + 3 4 + 7 16 ) = 4.6875.</formula><p>Observe that in our derivation of PX (2, c ′ ) = 7  16 above, we assumed that the paths 4, 3, 2 and 5, 3, 2 are independent. Without the path independence assumption, we would have obtained </p><formula xml:id="formula_9">PX (2, c ′ ) = PX (3, c ′ ) • p3 = 3 4 • 1 2 = 3 8 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">APPROXIMATION ALGORITHM FOR CONTENT MAXIMIZATION</head><p>We are now ready to present our approximation algorithm for the content maximization problem in the RMPP model. Let Z = {e1, e2, . . . , em} be the set of edges between similar nodes in V corresponding to compatible users. We are looking for a set X ⊆ Z such that at most k edges from X are incident on any node and f (X) as defined in Equation ( <ref type="formula">1</ref>) is maximum.</p><p>Since f (•) is submodular, one option is to use a simple greedy strategy that (in each step) selects the edge that provides the maximum marginal increase in function value. However, this does not give good approximation bounds because of the constraint k on the number of edges incident on a node. Specifically, an edge that results in the maximum increase in content spread might violate node incidence constraints and thus be ineligible for selection. Consequently, to handle these feasibility constraints, we adopt a different approach that considers a continuous relaxation of our problem, and computes a fractional (approximate) solution for edge membership in set X using the algorithm of <ref type="bibr" target="#b23">[23]</ref>. We then use randomized rounding to convert our fractional solution into an integral solution, and incur a constant factor reduction in the benefit due to rounding.</p><p>Continuous relaxation. Let ȳ = (y1, . . . , ym) be an mdimensional vector of variables yi ∈ [0, 1]. The semantics here are that edge ei ∈ X with probability yi. We define F (•) to be the following continuous extension of f (•). Let X ⊆ Z be a random variable such that ei ∈ X with probability yi. Then,</p><formula xml:id="formula_10">F (ȳ) = E[f (X)] = X f (X) e i ∈X yi e i ∈X (1 -yi) (2)</formula><p>The continuous relaxation of our content maximization problem then is to find ȳ such that F (ȳ) is maximized with</p><formula xml:id="formula_11">j∈e i yi ≤ k for all j ∈ V (3) yi ∈ [0, 1]<label>(4)</label></formula><p>Note that Equation (3) enforces the constraint that each node j has at most k incident edges in the discrete case. Now, let F (ȳopt) be the maximum value of F (•) subject to the constraints, and Xopt be the edge set satisfying constraints for which f (Xopt) is maximum. Also, let z be defined as follows: zi = 1 if ei ∈ Xopt, and 0 otherwise. Then, observe that F (z) = f (Xopt), and z is feasible. Thus, we have that F (ȳopt) ≥ F (z) = f (Xopt).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: ContinuousGreedy</head><formula xml:id="formula_12">Input: Graph G = (V, E), candidate edge set Z; Output: ȳ satisfying Equation (3) and F (ȳ) ≥ (1 -1 e ) • f (Xopt); 1 ȳ = 0; l = 0; 2 while l &lt; δ do 3</formula><p>Generate r samples X 1 , X 2 , . . . , Xr, where e i ∈ X j with probability y i . Set w i = j f (X j ∪e i )-f (X j ) r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>Compute a subset of edges Y such that no node has more than k incident edges and e i ∈Y w i is maximum. This is an instance of the graph matching problem and can be solved using the algorithm of <ref type="bibr" target="#b13">[13]</ref> in O(m 3 ) steps;</p><formula xml:id="formula_13">5 foreach e i ∈ Y do y i = y i + 1/δ; 6 l = l + 1; 7 return ȳ;</formula><p>Continuous greedy algorithm. We use the continuous greedy algorithm of Vondrak <ref type="bibr" target="#b23">[23]</ref> (see Algorithm 1) to find a ȳ satisfying Equation (3) above such that</p><formula xml:id="formula_14">F (ȳ) ≥ (1 - 1 e ) • F (ȳopt) ≥ (1 -1 e ) • f (Xopt)</formula><p>. Algorithm 1 considers δ intervals of width 1/δ, and in each iteration, it increments yi values of edges ei in a feasible edge set Y with the maximum sum of gradients e i ∈Y ∂F ∂y i . Each gradient ∂F ∂y i can be approximated as E[f (X ∪ ei)f (X)] which is estimated by averaging over r samples Xj. The graph matching algorithm of <ref type="bibr" target="#b13">[13]</ref> is then used to compute the optimal set Y with at most k edges per node and the maximum sum of gradient estimates. Note that since the yi values of only edges ei ∈ Y are incremented by 1/δ in each iteration, it follows that the final ȳ satisfies Equation (3). In fact, <ref type="bibr" target="#b23">[23]</ref> proves the following theorem. Theorem 3. <ref type="bibr" target="#b23">[23]</ref> For δ = m 2 and r = m 5 , Algorithm 1 returns ȳ satisfying Equation <ref type="bibr" target="#b3">(3)</ref> and</p><formula xml:id="formula_15">F (ȳ) ≥ (1 -1 e ) • f (Xopt).</formula><p>✷ Randomized rounding procedure. Once we have computed ȳ satisfying j∈e i yi ≤ k for all j ∈ V and F (ȳ) ≥ (1 -1 e ) • f (Xopt), we use randomized rounding <ref type="bibr" target="#b23">[23]</ref> to compute the final set X of edges. Essentially, we add element ei to X with probability yi. Note that E[f (X)] = F (ȳ) and so E[f (X)] ≥ (1-1 e )•f (Xopt). However, the result of rounding X may no longer be feasible, that is, the number of edges in X that are incident on a node j may exceed k. So we need to delete edges from X to ensure that it is feasible -we do this by partitioning X into a small number of feasible sets Xi and returning the Xi for which f (Xi) is maximum.</p><p>Our partitioning scheme starts with X1 = X and for each node j with k ′ &gt; k incident edges in X1, it deletes (an arbitrary set of) k ′k edges incident on j from X1 and inserts them into a new (overflow) set X2. Thus, X1 now becomes feasible, and the procedure is repeated for X2, . . . , Xs until we get an overflow set Xs that is feasible. Analysis of Approximation Algorithm. We can show the following approximation guarantee for our algorithm. </p><formula xml:id="formula_16">w.h.p. E[maxi f (Xi)] ≥ 1 3+2ǫ • (1 -1 e ) • f (Xopt), where ǫ = 8 k log(n). Proof. See Appendix B.</formula><p>Note that Theorem 4 provides worst-case bounds. In practice, our experimental results indicate that our approximation algorithm returns edge sets with good content spreads for much smaller values of parameters δ (set to 2000) and r (set to 30). The time complexity of our approximation algorithm is dominated by the matching procedure in Step 3 of Algorithm 1. The matching algorithm has time complexity O(m 3 ) and is run δ times; so the overall time complexity of our approximation algorithm is O(m 3 • δ). To overcome the computation cost, for large m, we can cluster the edges in Z and run our recommendation algorithm on the smaller clusters. We can also achieve further speedup using approximate matching based on greedy heuristics instead of exact matching. In our experiments in Section 6, computing recommendations on a one million node Twitter graph took a little over 11 hours on a stand-alone PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION</head><p>In this section, we present intuitive arguments to show that the three models -MPP with path dependence assumption <ref type="bibr" target="#b4">[4]</ref>, MPP with path independence assumption, and RMPP -result in similar content spreads for realistic graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Closeness of Content Spreads in the Dependent and Independent Path MPP Models</head><p>To show that the path independence assumption does not affect content spread values significantly, we compute PX (i, c) for a node i with and without the path independence assumption in the MPP model. For simplicity, let the propagation probability of all nodes be p. Furthermore, let the paths (over the edge set E ∪ X) that carry content c to node i form a tree of depth l = ⌊log p θ⌋ and degree d at each node (thus, there are d l paths). Recall (from Section 3.1) that θ is the threshold to prune paths with low propagation probabilities. This is pictorially depicted in Figure <ref type="figure">3</ref>. In general, the degree d of a node in the propagation tree is much smaller compared to its degree in the graph G due to the limited number of sources with content c. Thus, since propagation probability is typically small ( 0.05), p • d ≪ 1.</p><p>Under the independent path assumption, PX (i, c) = 1 -(1p l ) d l ≈ p l • d l . Now, let us compute PX (i, c) considering dependencies between paths as in <ref type="bibr" target="#b4">[4]</ref>. Let px be the probability of content reaching an intermediate node in the content propagation tree at depth x. Then, the probability of content reaching a node at depth (x-1) can be recursively computed as px-1 = 1-(1-px •p) d . Since the probability of content at the leaf nodes p l = 1, we get</p><formula xml:id="formula_17">p l-1 = 1-(1-p) d ≈ p•d. Similarly, p l-2 = 1 -(1 -p • d • p) d ≈ p 2 • d 2 .</formula><p>Computing recursively, the probability of content reaching the root (node i) p0 = PX (i, c) ≈ p l • d l . Thus, the content spread with and without path independence is approximately the same.</p><p>Figure <ref type="figure" target="#fig_2">4</ref> empirically compares the average content at a node in a one million node Twitter graph (described in Section 6.1) under the independent and dependent path assumptions. Content c is randomly assigned to 1% of the nodes in the graph which in turn spreads through paths of the propagation trees. The propagation trees are grouped into bins (x-axis) based on the number of nodes in the tree. The average content at root nodes in a bin is shown on the yaxis. As can be seen, the content spreads with and without the path independence assumption are very close.</p><p>The path independence assumption in our setting is essential for submodularity in Theorem 2. In fact, it can be shown that the submodularity property does not hold for the dependent path MPP model in <ref type="bibr" target="#b4">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Closeness of Content Spreads in the RMPP and Independent Path MPP Models</head><p>Another natural question arises -what is lost when the restriction of at most one new edge per path is imposed in the RMPP model? For a simplified yet representative setting, we present informal arguments to show that the content spread along paths containing at most one edge from X (RMPP model) matches the spread along paths containing an arbitrary number of edges from X (MPP model).</p><p>Our arguments rely on two basic observations: (1) In social networks, the average degree of nodes is typically much larger than the number of social recommendations k per node, and (2) With each additional hop, the probability of content traversing a path decreases by a factor equal to the propagation probability of the hop. Thus, shorter paths tend to have higher probabilities, and so content is more likely to spread along shorter paths compared to longer paths.</p><p>We will illustrate this in the context of a simple scenario where a single node i contains a piece of content c and we trace the spread of c from i along different types of maximum probability paths. Consider the tree T of maximum probability paths over edges in E ∪ X originating from i. To keep our analysis simple, let us assume that each node in T has h + k children connected to it by h edges from E and k edges from X. Also, let us assume that each node shares content with its neighbors with probability p. Since we ignore paths with probability less than θ, the depth of tree T is at most l = ⌊log p θ⌋. See Figure <ref type="figure" target="#fig_4">5</ref> for an illustration. Now, it is easy to see that the number of paths in T originating at root i of length r with zero edges from X is h r . Similarly, the number of paths in T of length r with a single edge from X is r • h r-1 • k. The reason for the factor r is that the single edge from X can occur in one of r positions, and the factor k is there because each node has k incident edges from X. Also, the total number of paths starting at root i of length r in T is (h + k) r . Suppose that P0, P1 and P∞ are the content spread values from node i along paths with at most zero, one, and unlimited edges from X, respectively. P∞ is essentially the total probability of all the paths, and so we get that P∞ = l r=1 (h + k) r • p r . Similarly, P1 is the probability of paths with at the most one edge from X, and so P1 = l r=1 h r • p r + l r=1 r • h r-1 • k • p r . And finally, P0 = l r=1 h r • p r . Typical values of parameters are h = 100, k = 10, p = 0.05, and l = 3. For these values, P0 = 155, P1 = 198 and P∞ = 202.125. Thus, the content spread along paths with at most one edge from X is very close to the content spread along paths with no restrictions on the number of edges from X. In fact, if we only consider paths containing at least one edge from X, then the bulk of the probability mass is concentrated in paths with exactly one edge from X. This is because the probability of paths with exactly one edge from X is P1 -P0 = 43 while the probability of paths with more than one edge from X is P∞ -P1 = 4.125.</p><p>Emperical results comparing content spreads in the RMPP and the MPP models are presented in Section 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SIMULATION EXPERIMENTS</head><p>Through simulations on real-life social network data, we show the superior performance of the continuous greedy algorithm compared to other popular approaches -simple greedy, degree-based heuristics, and Friend-of-Friend (FoF) based selection. We also (empirically) substantiate our claim about the closeness of content maximization under the RMPP and MPP models.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>To simulate content dissemination, we need realistic graph datasets, and models for content generation and propagation. Datasets: We use the Wikipedia, Flickr, Epinions, and Twitter social graphs. Between them, these graphs capture a wide variety of social relations (e.g., trust relations, follower-following relations, and friendship relations). Important statistics of these graphs are summarized in Table <ref type="table" target="#tab_2">1</ref>. Twitter: This dataset is obtained by crawling the twitter.com site starting from a randomly chosen set of popular personalities on Twitter. A directed edge from node X to Y indicates that X is following Y 's tweets. Due to Twitter's limit on the number of web server requests, only a subset of users followed by X could be obtained. Based on the content of their tweets, users were assigned to zero or more groups from a set of 27 predefined groups (e.g., politics and sports). Flickr: The Flickr (undirected) graph <ref type="bibr" target="#b24">[24]</ref> consists of friendship relations between users on the popular image site flickr.com. In addition to the friendship connections, each user belongs to one or more Flickr groups (e.g., wildlife and nature) from a set of 195 groups. Wikipedia: The Wikipedia(directed) graph <ref type="bibr" target="#b16">[16]</ref> is generated using the voting activity in elections for granting administrator rights to Wikipedia users. Each node in the graph represents a Wikipedia user with voting rights. A directed edge from i to j denotes user i's vote for user j. Epinions: Directed social network captures the who-trustswhom relation on the consumer reviews site epinions.com.</p><p>We consider the similarity sim(i, j) = 1 if the pair of users (i, j) shares a common group and sim(i, j) = 0 otherwise. The similarity function determines the candidate set Nu of nodes with which a user u can connect. In the absence of groups in a dataset, an edge can be added between any pair of nodes in the network. Content generation model: In the absence of informa-tion related to content at the nodes, we make the following assumptions for simulation purposes -our algorithm is independent of the exact values assumed here. We assume that a single content type c is generated by a set of seed nodes, S. Moreover, the rate of content generation is assumed to be uniform across all nodes in S. Unless specified otherwise, |S| is 1% of the node set size. The set S is selected randomly for all other than Twitter. For Twitter, S consists of about 38K users who tweet about soccer. To maintain parity, the same set of randomly generated seed nodes is used for all the algorithms.</p><p>Propagation model: Since we do not have the data to infer propagation probabilities, we instead consider two propagation probability assignments that are simple, yet illustrative. In the uniform assignment (henceforth UNI), all nodes have the same probability p of sharing content. In the weighted (henceforth WT) assignment, inspired by the weighted cascade model <ref type="bibr" target="#b15">[15]</ref>, pairwise propagation probabilities are inversely proportional to the degree of the originating node. These assignments have been considered elsewhere for studying the MPP model <ref type="bibr" target="#b4">[4]</ref>. We use the setting p = 0.05, unless stated otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Performance Evaluation</head><p>To compare the different edge selection methods, we define the lift metric as follows:</p><formula xml:id="formula_18">Lif t(X) = f (E ∪ X) -f (E) f (E) × 100,<label>(5)</label></formula><p>where E is the set of edges in the original graph G and f (.) is the content spread function. X is the set of recommendations computed by the following edge selection methods. Since the initial set S of nodes where content originates is determined randomly, all the Lift results reported here are averages over 10 independent runs. In this paper, we do not focus on evaluating the quality of the recommendations, since the candidate set Ni selected using traditional recommendation methods is itself likely to be highly relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Edge Selection Algorithms</head><p>We compared the following edge selection strategies. Greedy, where edges with the largest lift, given the current set of edges in the graph, are added one at a time. This process continues until no further edges can be added as a result of the maximum edge constraint for each node. Continuous Greedy (CG), where edges are added to the original graph based on Algorithm 1 followed by randomized rounding. Unless stated otherwise, we use δ = 2000 and r = 30 as parameters (see Section 4 for parameter description). Threshold θ for pruning paths is set to 0.01. Degree based selection adds edges between high degree node pairs, wherein one of the nodes has content c. This heuristic is intuitively competitive because it exploits the high degree of nodes to maximize content spread. Friend-of-Friend (FoF) based selection, where node pairs are ranked by the number of common neighbors. Edges are added between unconnected node pairs in this rank order.</p><p>In our experimental setup, k is set to 10. In principle, all of the above algorithms terminate when the maximum recommendations limit k is reached for all nodes in the graph. To highlight key insights, we instead terminate the simulations after a certain fixed number of new edges are added.</p><p>All simulations were performed on a 64-bit Intel Xeon 2.5GHz processor with 32 GB of main memory. Comparison between RM P P and independent path M P P . For the Epinions and Flickr datasets, Figures <ref type="figure" target="#fig_5">6(a</ref>) and 6(b) show the percentage lift as edges are added to the initial graph under the UNI and WT probability assignment models, respectively. In both models, the M P P and RM P P lifts are almost identical. However, the RM P P and M P P propagation models tend to deviate minimally under the W T probability assignment since W T has higher likelihood of longer paths in graphs with low-degree nodes. Since long paths have a higher chance of more than one new edge, we would expect M P P and RM P P to diverge in such situations. Subsequent results consider the RM P P model alone.  Greedy versus Continuous Greedy (CG) maximization. The Greedy approach selects edges with the highest immediate lift. On the contrary, CG takes an approach that captures the correlation between edges with high marginal gain. The iterative computation in CG has the following benefits: (1) Each iteration selects a locally optimal edge set (to maximize sum of gradients), and (2) Each iteration takes into account edge sets selected in previous iterations, thus capturing the interplay between edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Simulation Results</head><p>Figure <ref type="figure" target="#fig_7">7</ref> shows the lift in content propagation for 10K edges added to the initial graphs. The combination of con-tinuous greedy with weighted propagation outperforms other algorithms by a factor of 1.75 to 2 for all datasets other than Flickr. For Flickr,CG-UNI outperforms other algorithms by as much as a factor of 6. The lower lift for CG-WT on the dense Flickr graph can be attributed to the propagation probability, which is inversely proportional to node degree in the WT assignment. In contrast, for low density datasets (e.g. Wikipedia and Epinions) WT propagation achieves maximum marginal gain by connecting low degree nodes.</p><p>Comparison with edge recommendation heuristics. We now compare Greedy and CG, under UNI propagation, with two commonly used heuristics -Degree and FoF. In Fig-  Varying CG algorithm parameters. Figure <ref type="figure">9</ref>(a) shows lift as the fraction of nodes with original content varies. We show results for the Epinions dataset alone; other datasets show similar trends. 10K edges are added for each F = |S| |V | , varying from 1% to 10%. As expected, with increasing F the lift decreases as the fraction of yet-to-be-reached nodes decreases. Again, CG optimization yields the best results over the entire range of F considered.</p><p>Figure <ref type="figure">9</ref>(b) shows the impact of varying the number of recommended edges per node. Initially, the lift increases for all the models. Beyond k = 20, however, the lift for the UNI models stabilizes whereas the lift for WT propagation decreases. For the W T propagation probability assignment, as the degree of a node increases with additional edges its propagation probability decreases; beyond a point the overall spread begins to get impacted.</p><p>Finally, Figure <ref type="figure">9</ref>(c) shows the impact of varying the propagation probability p for the UNI model. As expected, the lift increases with p. At p = 0.1, the network has ample content prior to any edge additions. As a result, we observe the lift beginning to drop.</p><p>Comparing UNI and WT. Figure <ref type="figure" target="#fig_11">10</ref> shows how UNI and WT probability assignments result in different kinds of nodes being selected for edge recommendations. The WT probability assignment results in new links originating from low degree nodes, since those nodes have the highest peredge propagation probabilities. Thus, low-degree nodes are preferred until such nodes become increasingly rare. On the other hand, UNI is biased towards picking high-degree nodes, which have the highest expected number of neighbors receiving content.  It is important to note that in practice, recommendations are computed offline, thus allowing for the higher computation cost. Observe that we can also speed up computation by parallelizing parts of our algorithms using a Map-Reduce framework. Nevertheless, efficient methods based on greedy heuristics is a direction for further exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RELATED WORK</head><p>Following categories of research relate to the current work.</p><p>Recommendations and link prediction in social networks: As mentioned in Section 1, a large number of interests or profiles (i.e. college attended, current city, etc.) based and FoF based recommendation algorithms have been proposed in the literature <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b1">1,</ref><ref type="bibr" target="#b11">11]</ref>. Link prediction algorithms have also been developed for friend recommendations <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b18">18]</ref>. These algorithms, unlike the proposed work, do not consider content spread as an explicit objective while recommending links. Recent work by Roth et al. <ref type="bibr" target="#b20">[20]</ref> defines an Interactions Rank (IR) metric based on email interactions between users. The IR score is used within a Friend Suggest algorithm to recommend connections similar to a seed set of users. Another work, Twittomender <ref type="bibr" target="#b12">[12]</ref>, recommends users to follow on Twitter based on a combination of content and collaborative filtering type features.</p><p>Influence propagation and maximization: A large number of social contagion models have been proposed for explaining the diffusion of information and ideas through social connections. The linear threshold model <ref type="bibr" target="#b10">[10]</ref> and the independent cascade (IC) model <ref type="bibr">[9]</ref> are the most widely studied probabilistic models of diffusion. Variations of these models decreasing cascade model <ref type="bibr" target="#b15">[15]</ref>, triggering model <ref type="bibr" target="#b14">[14]</ref>, and non-progressive models such as the Susceptible/Infected/Sus-ceptible (SIS) model <ref type="bibr" target="#b19">[19]</ref> have also been studied. Most of these models are compute intensive to simulate.</p><p>The influence maximization problem, also known as the target set selection problem <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b15">15]</ref> addresses the maximization of social contagion within the propagation models mentioned above. Recent work <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b4">4]</ref> has focused on efficient techniques for influence maximization. These techniques identify a set of nodes as opposed to edge recommendations in our setting. Edge augmentation: Adding edges to graphs has been explored with other objectives -minimizing the network diameter <ref type="bibr" target="#b6">[6]</ref> and maximizing algebraic connectivity for robustness <ref type="bibr" target="#b8">[8]</ref>, to list a few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>We introduced the problem of recommending connections in a social network with the explicit objective of maximizing content spread in the network. Our content maximization problem is interesting in two ways. First, the problem is NP-hard and non-submodular. Second, we impose per-node constraints on the maximum number of new links as opposed to a global constraint on the number of selected nodes as in the influence maximization problem. We proposed a novel RMPP model that admits submodularity leading to computationally feasible approximation algorithms in the presence of the above constraints. Simulation results on realistic graphs demonstrate the superiority of our approach in comparison with commonly used heuristics.</p><p>The proposed content maximization framework has interesting extensions. The model currently assumes that the content generated at each node is independent and noncompeting. Adapting the model to overcome these assumptions is a direction worth exploring. Scalability, alternate models for propagation (e.g. SIS diffusion model) and effectiveness on live web-scale networks are aspects that also need further investigation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example illustrating that connecting users with the maximum mutual friends does not maximize content availability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example illustrating that f (•) is not submodular under the MPP model. MPP model closely matches the IC model in terms of the influence spread.Unfortunately, the set cover problem can be reduced to our content maximization problem resulting in the following theorem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 4 .</head><label>4</label><figDesc>Let |V | = n, δ = m 2 and r = m 5 . Further, let our partitioning scheme generate edge sets X1, . . . , Xs. Then</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Propagation tree of depth l for carrying c from content nodes to node i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Propagation tree for spread of content c from node i along h (solid) edges from E and k (dashed) edges from X.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Lift for RM P P and M P P models under uniform and weighted propagation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Lift as a function of number of edges added to the initial graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8: Comparison with Degree and FoF based heuristics. ure 8, both Degree and FoF have insignificant lifts compared to CG and Greedy, which shows the merit of applying optimization techniques instead of generally accepted heuristics. To highlight the difference, CG has a lift 80-95 times that of FoF and Degree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure10: UNI versus WT -Average degree of nodes with new edges. Note: Right axis is for CG-WT and left is for CG-UNI. Runtime performance of continuous greedy. Computing 5K recommendations for the Twitter, Flickr and Epinions datasets took 40913, 2169 and 1581 seconds, respectively, under the U N I propagation model. Clearly, the sparse one million node Twitter graph takes comparatively much longer due to the larger number of missing edges that are potential recommendations. It is important to note that in practice, recommendations are computed offline, thus allowing for the higher computation cost. Observe that we can also speed up computation by parallelizing parts of our algorithms using a Map-Reduce framework. Nevertheless, efficient methods based on greedy heuristics is a direction for further exploration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Thus, the PX (2, c ′ ) values with and without path independence are fairly close.</figDesc><table /><note><p><p><p><p>✷</p>It is straightforward to see that f (•) is monotonic. The following theorem proves submodularity.</p>Theorem 2. The content spread function f (X) under the RMPP model is submodular.</p>Proof. See Appendix A.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics for the datasets. (SCC: Strongly Connected Components, WCC: Weakly Connected Components).</figDesc><table><row><cell></cell><cell cols="4">Wikipedia Flickr Epinions Twitter</cell></row><row><cell>#Nodes</cell><cell>7.1 K</cell><cell>81 K</cell><cell>76 K</cell><cell>1 M</cell></row><row><cell>#Edges</cell><cell>104 K</cell><cell>5.9 M</cell><cell>508 K</cell><cell>3088467</cell></row><row><cell>Average Degree</cell><cell>14.6</cell><cell>72.8</cell><cell>6.7</cell><cell>3.1</cell></row><row><cell>Maximum Degree</cell><cell>893</cell><cell>4714</cell><cell>1801</cell><cell>216</cell></row><row><cell># WCC</cell><cell>24</cell><cell>1</cell><cell>1</cell><cell>15</cell></row><row><cell># SCC</cell><cell>5.9 K</cell><cell>1</cell><cell>42 K</cell><cell>896749</cell></row><row><cell>Largest SCC size</cell><cell>1.3 K</cell><cell>81K</cell><cell>3.2 K</cell><cell>103113</cell></row><row><cell>Avg. SCC Size</cell><cell>1.22</cell><cell>81K</cell><cell>1.79</cell><cell>1.12</cell></row><row><cell># groups</cell><cell>NA</cell><cell>195</cell><cell>NA</cell><cell>27</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The recently introduced Subscribe Button now allows content to spread beyond friends on Facebook.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A. PROOF OF THEOREM 2</head><p>THEOREM: The content spread function f (X) under the RMPP model is submodular.</p><p>We show that P X (i, c) = 1-j∈V (c) (1-q X (j, i)) is submodular. Since the sum of submodular functions is also submodular, we get that f (X) = c i P X (i, c) is submodular.</p><p>For edge e and edge subsets S ⊆ T , we are looking to show that P S∪{e} (i, c) -P S (i, c) ≥ P T ∪{e} (i, c) -P T (i, c). Without loss of generality, let V (c) = {1, 2, . . . , n}. Recollect that V (c) is the set of nodes with content c. Furthermore, for edge set T ∪ {e}, let the RMPPs from only nodes 1, . . . , r to i pass through edge e. We rely on the following three observations for proving that P X (i, c) is submodular.</p><p>1. (a) q T (j, i) ≥ q S (j, i), (b) q T ∪{e} (j, i) ≥ q S∪{e} (j, i), and (c) q S∪{e} (j, i) ≥ q S (j, i). Probability of RMPPs cannot decrease with the addition of new edges.</p><p>2. q S∪{e} (j, i) = q T ∪{e} (j, i), j ≤ r. With the restriction of at the most one new edge per RMPP, the RMPPs from j to i for edge set S ∪ {e} also pass through e and are identical to those for T ∪ {e}.</p><p>3. q T ∪{e} (j, i) = q T (j, i), j &gt; r. RMPPs from j to i for T ∪ {e} that do not contain edge e must be identical to the ones for T . Now, P T ∪{e} (i, c) -P T (i, c)</p><p>• n j=r+1</p><p>(1 -q T ∪{e} (j, i)) /* Applying 1(a), 1(b) and 2 */</p><p>• n j=r+1</p><p>(1 -q S∪{e} (j, i))</p><p>(1 -q S∪{e} (j, i))</p><p>Thus, f (•) is submodular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. PROOF OF THEOREM 4</head><p>THEOREM: Let |V | = n, δ = m 2 and r = m 5 . Further, let our partitioning scheme generate edge sets X 1 , . . . , Xs. Then w.h.p.</p><p>Consider the set X obtained as a result of our randomized rounding procedure. Due to Theorem 3, we have that E[f (X)] ≥ (1 -1 e ) • f (Xopt). Now, let Y j be the number of edges in X incident on node j. Also, let ǫ = 8 k log(n). Recall that an arbitrary edge e i is included in X with probability y i . Further, since ȳ is feasible, j∈e i y i ≤ k for all nodes j. Thus, E[Y j ] ≤ k. Applying Chernoff Bounds, we get</p><p>Now define Ymax = max j {Y j }. By the union bound, we get that</p><p>The above probability is extremely small (≤ 1 n ) for ǫ = 4 k log(n 2 ). Thus, we get that w.h.p. Y j ≤ (1 + ǫ) • k for all nodes j.</p><p>Next, we show that our partioning scheme divides set X into at most 2ǫ + 3 feasible sets X i . This is because w.h.p., for any edge (u, v) ∈ X, at most 1 + ǫ sets X i can have k edges incident on each of the vertices u and v (since Y j ≤ (1 + ǫ) • k). Thus, w.h.p., in at least one of the 2ǫ + 3 sets X i , both u and v must have fewer than k incident edges, and so X i ∪ {(u, v)} is feasible. Now, since f (•) is submodular, we have that i f (X i ) ≥ f (∪ i X i ). Furthermore, there are at most 2ǫ + 3 feasible sets X i . Thus, we get that max i f (X i ) ≥ f (X) 2ǫ+3 , and so E[max i f (X i )] ≥ 1 3+2ǫ • (1 -  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Facebook</forename><surname>Official</surname></persName>
		</author>
		<author>
			<persName><surname>Blog</surname></persName>
		</author>
		<ptr target="http://blog.facebook.com/blog.php?post=15610312130" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discovering who to follow</title>
		<ptr target="http://blog.twitter.com/2010/07/discovering-who-to-follow.html" />
	</analytic>
	<monogr>
		<title level="m">Official Twitter Blog</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Make new friends, but keep the old: recommending people on social networking sites</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;09</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scalable influence maximization for prevalent viral marketing in large-scale social networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;10</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1029" to="1038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient influence maximization in social networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;09</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Minimizing the diameter of a network using shortcut edges</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zadimoghaddam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SWAT</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="420" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mining the network value of customers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;01</title>
		<meeting><address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Growing well-connected graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Growing Well-connected Graphs</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="6605" to="6611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Talk of the network: A complex systems look at the underlying process of word-of-mouth. Marketing Letters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Libai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-08">August 2001</date>
			<biblScope unit="page" from="211" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Threshold models of collective behavior</title>
		<author>
			<persName><forename type="first">M</forename><surname>Granovetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="issue">83</biblScope>
			<biblScope unit="page" from="1420" to="1443" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Do you know?: recommending people to invite into your social network</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wilcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IUI &apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recommending twitter users to follow using content and collaborative filtering approaches</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys &apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Loopy belief propagation for bipartite maximum weight b-matching</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS &apos;07</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</editor>
		<imprint>
			<publisher>W&amp;CP</publisher>
			<date type="published" when="2007-03">March 2007</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Maximizing the spread of influence through a social network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;03</title>
		<meeting><address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="137" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Influential nodes in a diffusion model for social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICALP&apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1127" to="1138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting positive and negative links in online social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="641" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cost-effective outbreak detection in networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanbriesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;07</title>
		<meeting><address><addrLine>San Jose, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The link prediction problem for social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM &apos;03</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="556" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The structure and function of complex networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="167" to="256" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Suggesting friends using the implicit social graph</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Deutscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Flysher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leichtberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Leiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Merom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;10</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Folks in folksonomies: social link prediction from shared metadata</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schifanella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cattuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Markines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Menczer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM &apos;10</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Want to be retweeted? Large scale analytics on factors impacting retweet in twitter network</title>
		<author>
			<persName><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOCIALCOM &apos;10</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimal approximation for the submodular welfare problem in the value oracle model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vondrák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Social computing data repository at ASU</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zafarani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
