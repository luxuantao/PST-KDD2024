<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Journal of Computational and Applied Mathematics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Abd-El-Wahed</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computers and Information</orgName>
								<orgName type="institution">Shebin El-Kom Minufiya University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mousa</surname></persName>
							<email>a_mousa15@yahoo.com</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Basic Engineering Science</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering</orgName>
								<orgName type="institution">Shebin El-Kom Minufiya University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>El-Shorbagy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Basic Engineering Science</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering</orgName>
								<orgName type="institution">Shebin El-Kom Minufiya University</orgName>
								<address>
									<country key="EG">Egypt</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Journal of Computational and Applied Mathematics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">524BE78DB27A7217ED24239E47C9E3FC</idno>
					<idno type="DOI">10.1016/j.cam.2010.08.030</idno>
					<note type="submission">Received 8 May 2009 Received in revised form 7 August 2009</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Particle swarm optimization Genetic algorithm Nonlinear optimization problems Constriction factor</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Heuristic optimization provides a robust and efficient approach for solving complex realworld problems. The aim of this paper is to introduce a hybrid approach combining two heuristic optimization techniques, particle swarm optimization (PSO) and genetic algorithms (GA). Our approach integrates the merits of both GA and PSO and it has two characteristic features. Firstly, the algorithm is initialized by a set of random particles which travel through the search space. During this travel an evolution of these particles is performed by integrating PSO and GA. Secondly, to restrict velocity of the particles and control it, we introduce a modified constriction factor. Finally, the results of various experimental studies using a suite of multimodal test functions taken from the literature have demonstrated the superiority of the proposed approach to finding the global optimal solution.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Constrained optimization problems, especially nonlinear optimization problems, where objective functions are minimized under given constraints, are very important and frequently appear in the real world.</p><p>There are some efficient methods to solve nonlinear optimization problems, such as a recursive quadratic programming, a projection method, and a generalized reduced gradient method <ref type="bibr" target="#b0">[1]</ref>. These methods assume the differentiability of the objective function. However, it is difficult to apply these methods to problems, of which the objective function is not differentiable or the feasible set is not convex.</p><p>Generally, the constrained problems are solved by the combination of a transformation method and a direct search method. The transformation method <ref type="bibr" target="#b0">[1]</ref> converts a constrained problem into an unconstrained one, and the direct search method optimizes the objective function by using only the value of it. There are some transformation methods such as a penalty method and a multiplier method. The penalty method is often used to solve optimization problems, because the solutions are often near the boundary of the feasible set and the method is used easily for its simplicity. However, it is difficult to know what value of the penalty coefficient leads to a feasible solution and how much a search point satisfies the constraints <ref type="bibr" target="#b0">[1]</ref>.</p><p>The use and development of heuristic-based optimization techniques have significantly grown. Since they use a population of solutions in their search, it is more likely to find the global solution of a given problem. In addition, it uses only a simple scalar performance measure that does not require or use derivative information. Particle swarm optimization method is one of heuristic-based optimization techniques and was successfully applied in many optimization tasks. GA and PSO are two of the heuristic-based optimization techniques. they are much similar in their inherent parallel characteristics, whereas experiments <ref type="bibr" target="#b1">[2]</ref> show that they have their specific advantages when solving different optimization problems. Compared with GA, PSO has some attractive characteristics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. It has memory, so knowledge of good solutions is retained by all the particles; whereas in GA, previous knowledge of the problem is discarded once the population changes. It has constructive cooperation between particles; that is, particles in the swarm share information among themselves. To date, PSO has been successfully applied to optimizing various continuous nonlinear functions in practice <ref type="bibr" target="#b4">[5]</ref>.</p><p>In recent years there have been a lot of reported works focused on the hybridization of PSO with other heuristic-based optimization techniques. In <ref type="bibr" target="#b5">[6]</ref>, PSACO (particle swarm ant colony optimization) algorithm was proposed for highly non convex optimization problems. Also in <ref type="bibr" target="#b6">[7]</ref>, GA has been incorporated into PSO as a hybrid method combining two heuristic optimization techniques for the global optimization of multimodal functions.</p><p>The major objective of this paper is to propose a new hybrid algorithm to benefit by the advantages of the two heuristic optimization techniques, PSO and GA.</p><p>This paper is organized as follows. In Section 2, nonlinear programming problem is described. Section 3, provides an overview of the genetic algorithms and particle swarm optimization. In Section 4, the proposed algorithm is presented. The results of various experimental studies using a suite of multimodal test functions are described in Section 5. Finally, Section 6 gives a brief conclusion about this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Nonlinear programming problem (NLPP)</head><p>The nonlinear programming problem can be defined as follows <ref type="bibr" target="#b7">[8]</ref>:</p><formula xml:id="formula_0">NLPP : Min f (x) s.t. F = {x ∈ R n |g i (x) ≤ 0, i = 1, 2, . . . , m}, S = {x ∈ R n |l(x i ) ≤ x i ≤ u(x i ), i = 1, 2, . . . , n}<label>(1)</label></formula><p>where x ∈ F ⊆ S. The set S ⊆ R n defines the search space and the set F ⊆ S defines a feasible part of the search space.</p><p>Usually, the search space S is defined as n-dimensional rectangle in R n (domains of variables defined as lower and upper bounds): left (i) ≤ x i ≤ right (i), 1 ≤ i ≤ n whereas the feasible set F is defined by the search space S and an additional set of constraints g j (x) ≤ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview of the PSO and GA optimization technique</head><p>PSO shares many similarities with evolutionary computation techniques such as GA. In this section, we give a brief description of PSO and GA, the reader is referred to <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Genetic algorithm (GA)</head><p>The discovery of genetic algorithms (GA) was dated to the 1960s by Holland and further described by Goldberg <ref type="bibr" target="#b8">[9]</ref>. The GAs have been applied successfully to problems in many fields such as optimization design, fuzzy logic control, neural networks, expert systems, scheduling, and many others <ref type="bibr" target="#b10">[11]</ref>. For a specific problem, the GA codes a solution as an individual chromosome. It then defines an initial population of those individuals that represent a part of the solution space of the problem. The search space therefore, is defined as the solution space in which each feasible solution is represented by a distinct chromosome. Before the search starts, a set of chromosomes is randomly chosen from the search space to form the initial population. Next, through computations the individuals are selected in a competitive manner, based on their fitness as measured by a specific objective function.</p><p>The genetic search operators such as selection, mutation and crossover are then applied one after another to obtain a new generation of chromosomes in which the expected quality over all the chromosomes is better than that of the previous generation. This process is repeated until the termination criterion is met, and the best chromosome of the last generation is reported as the final solution. Fig. <ref type="figure" target="#fig_0">1</ref> shows the pseudo code of the general GA algorithm.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The particle swarm optimization method</head><p>PSO is an evolutionary computation technique motivated by the simulation of social behavior <ref type="bibr" target="#b9">[10]</ref>. Namely, each individual (agent) utilizes two important kinds of information in a decision process. The first one is their own experience; that is, they have tried the choices and know which state has been better so far, and they know how good it was. The second one is other agent's experiences; that is, they have knowledge of how the other agents around them have performed. Namely, they know which choices their neighbors have found are most positive so far and how positive the best pattern of choices was. In the PSO system, each agent makes his decision according to his own experiences and other agent's experiences. The system initially has a population of random solutions. Each potential solution, called a particle (agent), is given a random velocity and is flown through the problem space. The agents have memory and each agent keeps track of its previous best position (called the P best ) and its corresponding fitness. There exist a number of P best for the respective agents in the swarm and the agent with greatest fitness is called the global best (G best ) of the swarm. Each particle is treated as a point in a ndimensional space. The ith particle is represented as X i = (x i1 , x i2 , . . . , x in ). The best previous position of the ith particle (P besti ) that gives the best fitness value is represented as P i = (p i1 , p i2 , . . . , p in ). The best particle among all the particles in the population is represented by P g = (p g1 , p g2 , . . . , p gn ). The velocity, i.e., the rate of the position change for particle i is represented as</p><formula xml:id="formula_1">V i = (v i1 , v i2 , . . . , v in ).</formula><p>The particles are manipulated according to the following equations (the superscripts denote the iteration):</p><formula xml:id="formula_2">v k+1 i = w × v k i + c 1 × r 1 × (p i -x k i ) + c 2 × r 2 × (p g -x k i ),<label>(2)</label></formula><formula xml:id="formula_3">x k+1 i = x k i + v k+1 i (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where i = 1, 2, . . . , N, and N is the size of the population; w is the inertia weight; c 1 and c 2 are two positive constants, called the cognitive and social parameter respectively; r 1 and r 2 are random numbers uniformly distributed with in the range [0, 1]. Eq. ( <ref type="formula" target="#formula_2">2</ref>) is used to determine the ith particle's new velocity v k+1 i , at each iteration, while Eq. (3) provides the new position of the ith particle x k+1 i , adding its new velocity v k+1 i , to its current position x k i . Fig. <ref type="figure" target="#fig_1">2</ref> shows the Description of velocity and position updates of a particle for a two-dimensional parameter space. Fig. <ref type="figure" target="#fig_2">3</ref> shows the pseudo code of the general PSO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The proposed PSO based on GA algorithm</head><p>PSO and GA are much similar in their inherent parallel characteristics, whereas experiments show that they have their specific advantages when solving different problems. What we would like to do is to obtain both their excellent features by integrating the two algorithms. In the proposed approach, the algorithm initialized with a population of random solutions and searches for optima by traveling into the search space. During this travel an evolution of this solution is performed by integrating PSO and GA. The description diagram of the proposed algorithm is shown in Fig. <ref type="figure" target="#fig_3">4</ref> and it is described as follows:</p><p>Step 1. Initialization:</p><p>Initialize a population of particles with random positions and velocities on n-dimensions in the problem space.</p><p>Step 2. Evaluation: Evaluate the desired optimization fitness function in n variables for each particle.</p><p>Step 3. Setting P best and G best : Set P best of each particle and its objective value equal to its current position and objective value, and set G best and its objective value equal to the position and objective value of the best initial particle.</p><p>Step 4. Updating the velocity and position:</p><p>Update the velocity and position of each particle according to Eqs. ( <ref type="formula" target="#formula_2">2</ref>) and (3).</p><p>Step 5. Evolution of particles:</p><p>To restrict velocity and control it, some authors <ref type="bibr" target="#b11">[12]</ref> use a constriction factor χ, which has a constant value to improve the performance of PSO. We present a modified constriction factor (i.e., dynamic constriction factor) to keep the feasibility of the particles. e.g., Fig. <ref type="figure" target="#fig_4">5</ref> shows the movement of the particle i through the search space with and without a modified factor. Where the particle i start at the position x k i with velocity v k i in the feasible space, the new position x k+1 i in Fig. <ref type="figure" target="#fig_4">5</ref> depends on velocity</p><formula xml:id="formula_5">v k+1 i . x k+1 i = x k i + v k+1 i .<label>(4)</label></formula><p>Then, v k+1 i makes the particle to lose its feasibility, so we introduce a new modified factor χ such that:</p><formula xml:id="formula_6">χ = 2 |-2 -τ - √ τ 2 + τ |<label>(5)</label></formula><p>where, τ is the age of the infeasible particle (How long it's still unfeasible?). And the new modified position of the particle is computed as:</p><formula xml:id="formula_7">x k+1 i = x k i + χ v k+1 i .<label>(6)</label></formula><p>For each particle we check its feasibility, if it is infeasible, we implement χ parameter to control its position and velocity, using Eq. ( <ref type="formula" target="#formula_7">6</ref>) where τ is increased with the number of failed trial to keep the feasibility of the particle.</p><p>Step 6. Evaluation:</p><p>Evaluate the desired optimization fitness function in n variables for each particle.</p><p>Step 7. Updating P best and G best : For each particle, compare its current objective value with the objective value of its P best . If the current value is better, then update P best and its objective value with the current position and objective value. Determine the best particle of the current swarm with the best objective value. If the objective value is better than the objective value of G best , then update G best and its objective value with the position and objective value of the current best particle.</p><p>Step 8. Ranking: Ranks individuals (particles) according to their objective value, and returns a column vector containing the corresponding individual fitness value. Step 9. Selection:</p><p>Selection is an operator to select two parent strings for generating new strings (i.e., offspring). In the selection, a string with a low fitness value has more chance to be selected as one of parents than a string with a high fitness value. In GAs, parent strings are selected by random choice. The parent strings, however, are not selected by a sheer random choice. The fitness value of each string is utilized for selecting parent strings.</p><p>Step 10. Crossover:</p><p>Crossover is an operator to generate new strings (i.e., offspring) from parent strings. Various crossover operators have been proposed for GAs <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>Step 11. Mutation :</p><p>Mutation is an operator to change elements in a string which is generated by a crossover operator. Such a mutation operator can be viewed as a transition from a current solution to its neighborhood solution in local search algorithms <ref type="bibr" target="#b13">[14]</ref>.</p><p>Step 12. Elitist strategy (Replacing) :</p><p>Randomly remove a string from the current population and add the best string in the previous population to the current one.</p><p>Step 13. Repairing:</p><p>Repair the infeasible individuals of the population to be feasible. The idea of this technique is to separate any feasible individuals in a population from those that are infeasible by repairing infeasible individuals. This approach co-evolves the population of infeasible individuals until they become feasible, the reader is referred to <ref type="bibr" target="#b14">[15]</ref>. The pseudo code of the proposed algorithm is shown in Fig. <ref type="figure" target="#fig_5">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Computational experiment</head><p>The performance of the proposed algorithm for a global optimization continuous function is tested on several unconstrained well-known benchmark multimodal problems <ref type="bibr" target="#b6">[7]</ref> and two constrained benchmark problems taken from <ref type="bibr" target="#b15">[16]</ref>. The algorithm is coded in MATLAB 6.0 and the simulations are run on a Pentium 3 CPU 900 MHz with 128 MB memory capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Parameter selection</head><p>The population size of PSO is often between 10 and 40. The reason for a lower population size is that it significantly lowers the computing time. This is because during initialization, all the particles must be in the feasible space. Randomly initialized particles are not always in the feasible space. So initialization may take a longer time if the population is too large. However, for complex cases, a larger population size is preferred.</p><p>In PSO, there are not many parameters that need to be tuned. Only the following parameters need to be taken care of: maximum velocity V max , inertia weight w, acceleration coefficient C 1 and C 2 .</p><p>In GA, there are many parameters and operators that are to be adjusted. The following parameters need to be taken care of: Generation gap GGAP, Crossover rate Pc, Mutation rate Pm, Selection operator and Crossover operator. The parameters adopted in the implementation of the proposed algorithm are listed in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>The comparison between the results calculated by the proposed approach and the global optimal solutions are reported in Table <ref type="table" target="#tab_1">2</ref>. The results have demonstrated the superiority of the proposed approach to finding the global optimal solution.  Hybrid genetic algorithm and particle swarm optimization (GA-PSO) <ref type="bibr" target="#b6">[7]</ref> and our approach are applied to the suit of 17 unconstrained test problems, and the outcome is tabulated in Table <ref type="table" target="#tab_2">3</ref>. It is found that our approach has a 100% rate of successful minimization for all 17 classical test functions. As a result from Table <ref type="table" target="#tab_2">3</ref>, the average error of proposed approach is smaller than of GA-PSO <ref type="bibr" target="#b14">[15]</ref>. On the other hand, the constrained PSO of mechanical systems <ref type="bibr" target="#b15">[16]</ref> and our approach are applied to the two constrained problems. It is found that our approach has a 100% rate of successful minimization for the problems. Although, the average error of our approach is the same as the constrained PSO of mechanical systems.</p><p>In this subsection, a comparative study has been carried out to assess the proposed approach concerning quality of the solution. On the first hand, evolutionary techniques suffer from the quality of solution. Therefore the proposed approach has been used to increase the solution quality by combining the two merits of two heuristic algorithms (see Table <ref type="table" target="#tab_3">4</ref>).</p><p>On the other hand, unlike classical techniques our approach search from a population of points, not single point. Therefore our approach can provide a globally optimal solution. In addition, our approach uses only the objective function information, not derivatives or other auxiliary knowledge. Therefore it can deal with the non-smooth, non-continuous and non-differentiable functions which are actually existed in practical optimization problems.</p><p>Another advantage is that the simulation results prove superiority of the proposed approach to those reported in the literature, where it is completely better than the other approaches. Finally, the reality of using the proposed approach to handle complex problems of realistic dimensions has been approved due to procedure simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper presents a hybrid method combining two heuristic optimization techniques, PSO and GA. The proposed algorithm integrates the concept of evolving individuals originally modeled by GA with the concept of self-improvement of PSO, where, the algorithm initialized by a set of a individuals which travel in the search space using the PSO. During this travel we implement GA to evolve these individuals. Also, in order to keep the feasibility of the particles, an additional parameter χ is introduced, where the algorithm co-evolves the population of infeasible individuals until they become feasible. Simulated experiments for the optimization of nonlinear multimodal test functions show that the proposed approach is superior in the ability to finding the global optimal solution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The pseudo code of the general GA algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Description of velocity and position updates in particle swarm optimization for a two-dimensional parameter space.</figDesc><graphic coords="3,167.24,53.10,213.54,150.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The pseudo code of the general PSO algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Diagram model for particle movement.</figDesc><graphic coords="4,154.57,53.09,231.54,151.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The movement of the particle i through search space.</figDesc><graphic coords="5,166.89,53.09,214.26,161.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The pseudo code of the proposed algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The algorithm parameters.</figDesc><table><row><cell>Cognitive parameter</cell><cell>2.8</cell></row><row><cell>Social parameter</cell><cell>1.3</cell></row><row><cell>Maximum velocity of particles</cell><cell>V max = X max -X min</cell></row><row><cell>Inertia weight</cell><cell>0.6</cell></row><row><cell>Generation gap</cell><cell>0.9</cell></row><row><cell>Crossover rate</cell><cell>0.9</cell></row><row><cell>Mutation rate</cell><cell>0.7</cell></row><row><cell>Selection operator</cell><cell>Stochastic universal sampling</cell></row><row><cell>Crossover operator</cell><cell>Single point</cell></row><row><cell>Mutation operator</cell><cell>Real-value</cell></row><row><cell>PSO iteration</cell><cell>5</cell></row><row><cell>GA generation</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Comparison between the global solution and calculated solution.</figDesc><table><row><cell>Test function</cell><cell>No. of iteration</cell><cell>No. of particles</cell><cell>F optimal</cell><cell>F calculated</cell></row><row><cell>RC</cell><cell>50</cell><cell>300</cell><cell>0.397887</cell><cell>0.397887</cell></row><row><cell>B2</cell><cell>120</cell><cell>300</cell><cell>0</cell><cell>0</cell></row><row><cell>ES</cell><cell>100</cell><cell>300</cell><cell>-1</cell><cell>-1</cell></row><row><cell>GP</cell><cell>100</cell><cell>300</cell><cell>3</cell><cell>3</cell></row><row><cell>SH</cell><cell>300</cell><cell>100</cell><cell>-186.7309</cell><cell>-186.7309</cell></row><row><cell>DJ</cell><cell>500</cell><cell>300</cell><cell>0</cell><cell>2.6022E-064</cell></row><row><cell>H 3,4</cell><cell>100</cell><cell>100</cell><cell>-3.86278</cell><cell>-3.86343347</cell></row><row><cell>H 6,4</cell><cell>100</cell><cell>100</cell><cell>-3.32237</cell><cell>-3.322368</cell></row><row><cell>S 4,5</cell><cell>500</cell><cell>600</cell><cell>-10.1532</cell><cell>-10.1532</cell></row><row><cell>S 4,7</cell><cell>300</cell><cell>600</cell><cell>-10.40294</cell><cell>-10.402916</cell></row><row><cell>S 4,10</cell><cell>300</cell><cell>600</cell><cell>-10.53641</cell><cell>-10.5363855</cell></row><row><cell>R 2</cell><cell>150</cell><cell>300</cell><cell>0</cell><cell>1.38584E-21</cell></row><row><cell>R 5</cell><cell>1000</cell><cell>300</cell><cell>0</cell><cell>1.7476E-11</cell></row><row><cell>R 10</cell><cell>1000</cell><cell>700</cell><cell>0</cell><cell>1.1367e-9</cell></row><row><cell>Z 2</cell><cell>300</cell><cell>100</cell><cell>0</cell><cell>1.8461E-18</cell></row><row><cell>Z 5</cell><cell>300</cell><cell>100</cell><cell>0</cell><cell>3.8176E-9</cell></row><row><cell>Z 10</cell><cell>500</cell><cell>500</cell><cell>0</cell><cell>2.0996E-9</cell></row><row><cell>P1</cell><cell>1000</cell><cell>100</cell><cell>-30665.5</cell><cell>-30665.5</cell></row><row><cell>P2</cell><cell>150</cell><cell>100</cell><cell>-6961.81</cell><cell>-6961.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Results provided by GA-PSO and our approach.</figDesc><table><row><cell>Test function</cell><cell>Average error</cell><cell></cell></row><row><cell></cell><cell>The proposed approach</cell><cell>GA-PSO</cell></row><row><cell>RC</cell><cell>4.59E-7</cell><cell>0.00009</cell></row><row><cell>B2</cell><cell>1E-25</cell><cell>0.00001</cell></row><row><cell>ES</cell><cell>1E-30</cell><cell>0.00003</cell></row><row><cell>GP</cell><cell>-6.3060E-14</cell><cell>0.00012</cell></row><row><cell>SH</cell><cell>8.83064E-6</cell><cell>0.00007</cell></row><row><cell>DJ</cell><cell>8.443663E-15</cell><cell>0.00004</cell></row><row><cell>H 3,4</cell><cell>0.00003</cell><cell>0.00020</cell></row><row><cell>H 6,4</cell><cell>2E-6</cell><cell>0.00024</cell></row><row><cell>S 4,5</cell><cell>Zero</cell><cell>0.00014</cell></row><row><cell>S 4,7</cell><cell>0.00002</cell><cell>0.00015</cell></row><row><cell>S 4,10</cell><cell>0.00002</cell><cell>0.00012</cell></row><row><cell>R 2</cell><cell>1E-30</cell><cell>0.00064</cell></row><row><cell>R 5</cell><cell>1E-20</cell><cell>0.00013</cell></row><row><cell>R 10</cell><cell>1E-18</cell><cell>0.00005</cell></row><row><cell>Z 2</cell><cell>1E-15</cell><cell>0.00005</cell></row><row><cell>Z 5</cell><cell>1E-17</cell><cell>0.00000</cell></row><row><cell>Z 10</cell><cell>1E-25</cell><cell>0.00000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Results provided by constrained PSO and our approach.</figDesc><table><row><cell>Test function</cell><cell>Error = optimal -calculated</cell><cell></cell></row><row><cell></cell><cell>The proposed approach</cell><cell>Constrained PSO</cell></row><row><cell>P 1</cell><cell>1E-25</cell><cell>Zero</cell></row><row><cell>P 2</cell><cell>1E-8</cell><cell>1.759999</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The authors are grateful to the anonymous reviewers for their valuable comments and helpful suggestions which greatly improved the paper's quality.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Engineering Optimization: Theory and Practice</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Wiley</publisher>
			<biblScope unit="volume">3</biblScope>
			<pubPlace>NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An improved GA and a novel PSO-GA-based hybrid algorithm</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="255" to="261" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comparison of genetic algorithms, particle swarm optimization and the differential evolution method for the design of scannable circular antenna arrays</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Panduro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Brizuela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Balderas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Acosta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in Electromagnetics Research B</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="171" to="186" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparison of genetic algorithm and particle swarm optimization for bicriteria permutation flowshop scheduling problem</title>
		<author>
			<persName><forename type="first">O</forename><surname>Uysal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bulkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Intelligence Research</title>
		<idno type="ISSN">0973-1873</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="175" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer with dynamic adaptation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page" from="1205" to="1213" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Particle Swarm and ant colony algorithms hybridized for improved continous optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Shelokar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Siarry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Iayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="page" from="129" to="142" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A hybrid genetic algorithm and particle swarm optimization for multimodal functions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="page" from="849" to="857" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms, homomorphous mappings, and constrained parameter optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Koziel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="44" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization &amp; Machine Learning</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<title level="m">Swarm Intelligence</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<title level="m">Genetic Algorithms: Concepts and Designs</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing inertia weights and constriction factors in particle swarm optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Congress on Evolutionary Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="84" to="88" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A study of permutation crossover operators on the traveling salesman problem</title>
		<author>
			<persName><forename type="first">I</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd ICGA</title>
		<meeting>2nd ICGA</meeting>
		<imprint>
			<date type="published" when="1987">July 28-31, 1987</date>
			<biblScope unit="page" from="224" to="230" />
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology, USA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Initialization mutation and selection methods in genetic algorithms for functions optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Bramlette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ICGA</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="100" to="107" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">GENLS: co-evolutionary algorithm for nonlinear system of equations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mousa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>El-Desoky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="page" from="633" to="642" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Constrained Particle Swarm Optimization of Mechanical Systems, in: 6th World Congresses of Structural and Multidisciplinary Optimization, Rio de Janeiro</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sedlaczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eberhard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-06-03">30 May-03 June, Brazil, 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
