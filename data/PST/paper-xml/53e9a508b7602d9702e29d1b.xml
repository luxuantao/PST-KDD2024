<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parallel Data Processing with MapReduce: A Survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kyong-Ha</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science KAIST</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yoon-Joon</forename><surname>Lee</surname></persName>
							<email>yoonjoon.lee@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science KAIST</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hyunsik</forename><surname>Choi</surname></persName>
							<email>hyunsik.choi@korea.ac.kr</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yon</forename><surname>Dohn</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bongki</forename><surname>Moon</surname></persName>
							<email>bkmoon@cs.arizona.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Parallel Data Processing with MapReduce: A Survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F604CC1E1B8D165FE74DC569B40A4EB5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A prominent parallel data processing tool MapReduce is gaining significant momentum from both industry and academia as the volume of data to analyze grows rapidly. While MapReduce is used in many areas where massive data analysis is required, there are still debates on its performance, efficiency per node, and simple abstraction. This survey intends to assist the database and open source communities in understanding various technical aspects of the MapReduce framework. In this survey, we characterize the MapReduce framework and discuss its inherent pros and cons. We then introduce its optimization strategies reported in the recent literature. We also discuss the open issues and challenges raised on parallel data analysis with MapReduce.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In this age of data explosion, parallel processing is essential to processing a massive volume of data in a timely manner. MapReduce, which has been popularized by Google, is a scalable and fault-tolerant data processing tool that enables to process a massive volume of data in parallel with many low-end computing nodes <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b38">38]</ref>. By virtue of its simplicity, scalability, and fault-tolerance, MapReduce is becoming ubiquitous, gaining significant momentum from both industry and academia. However, MapReduce has inherent limitations on its performance and efficiency. Therefore, many studies have endeavored to overcome the limitations of the MapReduce framework <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b23">23]</ref>.</p><p>The goal of this survey is to provide a timely remark on the status of MapReduce studies and related work focusing on the current research aimed at improving and enhancing the MapReduce framework. We give an overview of major approaches and classify them with respect to their strategies. The rest of the survey is organized as follows. Section 2 reviews the architecture and the key concepts of MapReduce. Section 3 discusses the inherent pros and cons of MapReduce. Section 4 presents the classification and details of recent approaches to improving the MapReduce framework. In Section 5 and 6, we overview major application do-mains where the MapReduce framework is adopted and discuss open issues and challenges. Finally, Section 7 concludes this survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ARCHITECTURE</head><p>MapReduce is a programming model as well as a framework that supports the model. The main idea of the MapReduce model is to hide details of parallel execution and allow users to focus only on data processing strategies. The MapReduce model consists of two primitive functions: Map and Reduce. The input for MapReduce is a list of (key1, value1) pairs and Map() is applied to each pair to compute intermediate key-value pairs, (key2, value2). The intermediate key-value pairs are then grouped together on the keyequality basis, i.e. (key2, list(value2)). For each key2, Reduce() works on the list of all values, then produces zero or more aggregated results. Users can define the Map() and Reduce() functions however they want the MapReduce framework works.</p><p>MapReduce utilizes the Google File System(GFS) as an underlying storage layer to read input and store output <ref type="bibr" target="#b59">[59]</ref>. GFS is a chunk-based distributed file system that supports fault-tolerance by data partitioning and replication. <ref type="bibr">Apache</ref> Hadoop is an open-source Java implementation of MapReduce <ref type="bibr" target="#b81">[81]</ref>. We proceed our explanation with Hadoop since Google's MapReduce code is not available to the public for its proprietary use. Other implementations (such as DISCO written in Erlang <ref type="bibr" target="#b6">[6]</ref>) are also available, but not as popular as Hadoop. Like MapReduce, Hadoop consists of two layers: a data storage layer called Hadoop DFS(HDFS) and a data processing layer called Hadoop MapReduce Framework. HDFS is a block-structured file system managed by a single master node like Google's GFS. Each processing job in Hadoop is broken down to as many Map tasks as input data blocks and one or more Reduce tasks. Figure <ref type="figure" target="#fig_0">1</ref> illustrates an overview of the Hadoop architecture.</p><p>A single MapReduce(MR) job is performed in two phases: Map and Reduce stages. The master picks idle workers and assigns each one a map or a reduce task according to the stage. Before starting the Map task, an input file is loaded on the distributed file system. At loading, the file is partitioned into multiple data blocks which have the same size, typically 64MB, and each block is triplicated to guarantee fault-tolerance. Each block is then assigned to a mapper, a worker which is assigned a map task, and the mapper applies Map() to each record in the data block. The intermediate outputs produced by the mappers are then sorted locally for grouping key-value pairs sharing the same key. After local sort, Combine() is optionally applied to perform pre-aggregation on the grouped key-value pairs so that the communication cost taken to transfer all the intermediate outputs to reducers is minimized. Then the mapped outputs are stored in local disks of the mappers, partitioned into R, where R is the number of Reduce tasks in the MR job. This partitioning is basically done by a hash function e.g. , hash(key) mod R.</p><p>When all Map tasks are completed, the MapReduce scheduler assigns Reduce tasks to workers. The intermediate results are shuffled and assigned to reducers via HTTPS protocol. Since all mapped outputs are already partitioned and stored in local disks, each reducer performs the shuffling by simply pulling its partition of the mapped outputs from mappers. Basically, each record of the mapped outputs is assigned to only a single reducer by one-to-one shuffling strategy. Note that this data transfer is performed by reducers' pulling intermediate results. A reducer reads the intermediate results and merge them by the intermediate keys, i.e. key2, so that all values of the same key are grouped together. This grouping is done by external merge-sort. Then each reducer applies Reduce() to the intermediate values for each key2 it encounters. The output of reducers are stored and triplicated in HDFS.</p><p>Note that the number of Map tasks does not depend on the number of nodes, but the number of input blocks. Each block is assigned to a single Map task. However, all Map tasks do not need to be executed simultaneously and neither are Reduce tasks. For example, if an input is broken down into 400 blocks and there are 40 mappers in a cluster, the number of map tasks are 400 and the map tasks are executed through 10 waves of task runs. This behavior pattern is also reported in <ref type="bibr" target="#b60">[60]</ref>.</p><p>The MapReduce framework executes its tasks based on runtime scheduling scheme. It means that MapReduce does not build any execution plan that specifies which tasks will run on which nodes before execution. While DBMS generates a query plan tree for execution, a plan for executions in MapReduce is determined entirely at runtime. With the runtime scheduling, MapReduce achieves fault tolerance by detecting failures and reassigning tasks of failed nodes to other healthy nodes in the cluster. Nodes which have completed their tasks are assigned another input block. This scheme naturally achieves load balancing in that faster nodes will process more input chunks and slower nodes process less inputs in the next wave of execution. Furthermore, MapReduce scheduler utilizes a speculative and redundant execution. Tasks on straggling nodes are redundantly executed on other idle nodes that have finished their assigned tasks, although the tasks are not guaranteed to end earlier on the new assigned nodes than on the straggling nodes. Map and Reduce tasks are executed with no communication between other tasks. Thus, there is no contention arisen by synchronization and no communication cost between tasks during a MR job execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROS AND CONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Debates</head><p>As suggested by many researchers, commercial DBMSs have adopted "one size fits all" strategy and are not suited for solving extremely large scale data processing tasks. There has been a demand for special-purpose data processing tools that are tailored for such problems <ref type="bibr" target="#b79">[79,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b72">72]</ref>. While MapReduce is referred to as a new way of processing big data in data-center computing <ref type="bibr" target="#b77">[77]</ref>, it is also criticized as a "major step backwards" in parallel data processing in comparison with DBMS <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b15">15]</ref>. However, many MapReduce proponents in industry argue that MapReduce is not a DBMS and such an apple-to-orange comparison is unfair. As the technical debate continued, ACM recently invited both sides in January edition of CACM, 2010 <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b39">39]</ref>. Panels in DOLAP'10 also discussed pros and cons of MapReduce and relational DB for data warehousing <ref type="bibr" target="#b23">[23]</ref>.</p><p>Pavlo et al 's comparison show that Hadoop is 2∼50 times slower than parallel DBMS except in the case of data loading <ref type="bibr" target="#b15">[15]</ref>. Anderson et al also criticize that the current Hadoop system is scalable, but achieves very low efficiency per node, less than 5MB/s processing rates, repeating a mistake that previous studies on highperformance systems often made by "focusing on scalability but missing efficiency" <ref type="bibr" target="#b32">[32]</ref>. This poor efficiency involves many issues such as performance, total cost of ownership(TCO) and energy. Although Hadoop won the 1st position in GraySort benchmark test for 100 TB sorting(1 trillion 100-byte records) in 2009, its winning was achieved with over 3,800 nodes <ref type="bibr" target="#b76">[76]</ref>. MapReduce or Hadoop would not be a cheap solution if the cost for constructing and maintaining a cluster of that size was considered. Other studies on the performance of Hadoop are also found in literature <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b61">61]</ref>. Analysis of 10-months of MR logs from Yahoo's M45 Hadoop cluster and MapReduce usage statistics at Google are also available <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b9">9]</ref>.</p><p>The studies exhibit a clear tradeoff between efficiency and fault-tolerance. MapReduce increases the fault tolerance of long-time analysis by frequent checkpoints of completed tasks and data replication. However, the frequent I/Os required for fault-tolerance reduce efficiency. Parallel DBMS aims at efficiency rather than fault tolerance. DBMS actively exploits pipelining intermediate results between query operators. However, it causes a potential danger that a large amount of operations need be redone when a failure happens. With this fundamental difference, we categorize the pros and cons of the MapReduce framework below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Advantages</head><p>MapReduce is simple and efficient for computing aggregate. Thus, it is often compared with "filtering then group-by aggregation" query processing in a DBMS. Here are major advantages of the MapReduce framework for data processing. Independent of the storage MapReduce is basically independent from underlying storage layers. Thus, MapReduce can work with different storage layers such as BigTable <ref type="bibr" target="#b35">[35]</ref> and others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simple and easy to use</head><p>Fault tolerance MapReduce is highly fault-tolerant.</p><p>For example, it is reported that MapReduce can continue to work in spite of an average of 1.2 failures per analysis job at Google <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b38">38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High scalability</head><p>The best advantage of using MapReduce is high scalability. Yahoo! reported that their Hadoop gear could scale out more than 4,000 nodes in 2008 <ref type="bibr" target="#b4">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pitfalls</head><p>Despite many advantages, MapReduce lacks some of the features that have proven paramount to data analysis in DBMS. In this respect, MapReduce is often characterized as an Extract-Transform-Load (ETL) tool <ref type="bibr" target="#b51">[51]</ref>. We itemize the pitfalls of the MapReduce framework below, compared with DBMS.</p><p>No high-level language MapReduce itself does not support any high-level language like SQL in DBMS and any query optimization technique. Users should code their operations in Map and Reduce functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No schema and no index</head><p>MapReduce is schema-free and index-free. An MR job can work right after its input is loaded into its storage. However, this impromptu processing throws away the benefits of data modeling. MapReduce requires to parse each item at reading input and transform it into data objects for data processing, causing performance degradation <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b11">11]</ref>.</p><p>A Single fixed dataflow MapReduce provides the ease of use with a simple abstraction, but in a fixed dataflow. Therefore, many complex algorithms are hard to implement with Map and Reduce only in an MR job. In addition, some algorithms that require multiple inputs are not well supported since the dataflow of MapReduce is originally designed to read a single input and generate a single output.</p><p>Low efficiency With fault-tolerance and scalability as its primary goals, MapReduce operations are not always optimized for I/O efficiency. (Consider for example sort-merge based grouping, materialization of intermediate results and data triplication on the distributed file system.) In addition, Map and Reduce are blocking operations. A transition to the next stage cannot be made until all the tasks of the current stage are finished. Consequently, pipeline parallelism may not be exploited.</p><p>Moreover, block-level restarts, a one-to-one shuffling strategy, and a simple runtime scheduling can also lower the efficiency per node. MapReduce does not have specific execution plans and does not optimize plans like DBMS does to minimize data transfer across nodes. Therefore, MapReduce often shows poorer performance than DBMS <ref type="bibr" target="#b15">[15]</ref>. In addition, the MapReduce framework has a latency problem that comes from its inherent batch processing nature. All of inputs for an MR job should be prepared in advance for processing.</p><p>Very young MapReduce has been popularized by Google since 2004. Compared to over 40 years of DBMS, codes are not mature yet and third-party tools available are still relatively few.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">VARIANTS AND IMPROVEMENTS</head><p>We present details of approaches to improving the pitfalls of the MapReduce framework in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">High-level Languages</head><p>Microsoft SCOPE <ref type="bibr" target="#b53">[53]</ref>, Apache Pig <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b18">18]</ref>, and Apache Hive <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17]</ref> all aim at supporting declarative query languages for the MapReduce framework. The declarative query languages allow query independence from program logics, reuse of the queries and automatic query optimization features like SQL does for DBMS. SCOPE works on top of the Cosmos system, a Microsoft's clone of MapReduce, and provides functionality similar to SQL views. It is similar to SQL but comes with C# expressions. Operators in SCOPE are the same as Map, Reduce and Merge supported in <ref type="bibr" target="#b37">[37]</ref>.</p><p>Pig is an open source project that is intended to support ad-hoc analysis of very large data, motivated by Sawzall <ref type="bibr" target="#b55">[55]</ref>, a scripting language for Google's MapReduce. Pig consists of a high-level dataflow language called Pig Latin and its execution framework. Pig Latin supports a nested data model and a set of pre-defined UDFs that can be customized <ref type="bibr" target="#b22">[22]</ref>. The Pig execution framework first generates a logical query plan from a Pig Latin program. Then it compiles the logical plan down into a series of MR jobs. Some optimization techniques are adopted to the compilation, but not described in detail <ref type="bibr" target="#b18">[18]</ref>. Pig is built on top of Hadoop framework, and its usage requires no modification to Hadoop.</p><p>Hive is an open-source project that aims at providing data warehouse solutions on top of Hadoop, supporting ad-hoc queries with an SQL-like query language called HiveQL. Hive compiles a HiveQL query into a directed acyclic graph(DAG) of MR jobs. The HiveQL includes its own type system and data definition language(DDL) to manage data integrity. It also contains a system catalog, containing schema information and statistics, much like DBMS engines. Hive currently provides only a simple, naive rule-based optimizer.</p><p>Similarly, DryadLINQ <ref type="bibr" target="#b71">[71,</ref><ref type="bibr" target="#b49">49]</ref> is developed to translate LINQ expressions of a program into a distributed execution plan for Dryad, Microsoft's parallel data processing tool <ref type="bibr" target="#b48">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Schema Support</head><p>As described in Section 3.3, MapReduce does not provide any schema support. Thus, the MapReduce framework parses each data record at reading input, causing performance degradation <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b11">11]</ref>. Meanwhile, Jiang et al report that only immutable decoding that transforms records into immutable data objects severely causes performance degradation, rather than record parsing <ref type="bibr" target="#b28">[28]</ref>.</p><p>While MapReduce itself does not provide any schema support, data formats such as Google's Protocol Buffers, XML, JSON, Apache's Thrift, or other formats can be used for checking data integrity <ref type="bibr" target="#b39">[39]</ref>. One notable thing about the formats is that they are self-describing formats that support a nested and irregular data model, rather than the relational model. A drawback of the use of the formats is that data size may grow as data contains schema information in itself. Data compression is considered to address the data size problem <ref type="bibr" target="#b47">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Flexible Data Flow</head><p>There are many algorithms which are hard to directly map into Map and Reduce functions. For example, some algorithms require global state information during their processing. Loop is a typical example that requires the state information for execution and termination. However, MapReduce does not treat state information during execution. Thus, MapReduce reads the same data iteratively and materializes intermediate results in local disks in each iteration, requiring lots of I/Os and unnecessary computations. HaLoop <ref type="bibr" target="#b66">[66]</ref>, Twister <ref type="bibr" target="#b42">[42]</ref>, and Pregel <ref type="bibr" target="#b36">[36]</ref> are examples of systems that support loop programs in MapReduce.</p><p>HaLoop and Twister avoid reading unnecessary data repeatedly by identifying and keeping invariant data during iterations. Similarly, Lin et al propose an inmapper combining technique that preserves mapped outputs in a memory buffer across multiple map calls, and emits aggregated outputs at the last iteration <ref type="bibr" target="#b75">[75]</ref>. In addition, Twister avoids instantiating workers repeatedly during iterations. Previously instantiated workers are reused for the next iteration with different inputs in Twister. HaLoop is similar to Twister, and it also allows to cache both each stage's input and output to save more I/Os during iterations. Vanilla Hadoop also supports task JVM reuse to avoid the overhead of starting a new JVM for each task <ref type="bibr" target="#b81">[81]</ref>. Pregel mainly targets to process graph data. Graph data processing are usually known to require lots of iterations. Pregel implements a programming model motivated by the Bulk Synchronous Parallel(BSP) model. In this model, each node has each own input and transfers only some messages which are required for next iteration to other nodes.</p><p>MapReduce reads a single input. However, many important relational operators are binary operators that require two inputs. Map-Reduce-Merge addresses the support of the relational operators by simply adding a third merge stage after reduce stage <ref type="bibr" target="#b37">[37]</ref>. The merge stage combines two reduced outputs from two different MR jobs into one.</p><p>Clustera, Dryad and Nephele/PACT allow more flexible dataflow than MapReduce does <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b26">26]</ref>. Clustera is a cluster management system that is designed to handle a variety of job types including MRstyle jobs <ref type="bibr" target="#b31">[31]</ref>. Job scheduler in Clustera handles MapReduce, workflow and SQL-type jobs, and each job can be connected to form a DAG or a pipeline for complex computations.</p><p>Dryad is a notable example of distributed data-parallel tool that allows to design and execute a dataflow graph as users' wish <ref type="bibr" target="#b48">[48]</ref>. The dataflow in Dryad has a form of DAG that consists of vertices and channels. Each vertex represents a program and a channel connects the vertices. For execution, a logical dataflow graph is mapped onto physical resources by a job scheduler at runtime. A vertex runs when all its inputs are ready and outputs its results to the neighbor vertices via channels as defined in the dataflow graph. The channels can be either of files, TCP pipes, or shared-memory. Job executions are controlled by a central job scheduler. Redundant executions are also allowed to handle apparently very slow vertices, like MapReduce. Dryad also allows to define how to shuffle intermediate data specifically.</p><p>Nephele/PACT is another parallel execution engine and its programming model <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b26">26]</ref>. The PACT model extends MapReduce to support more flexible dataflows. In the model, each mapper can have a separate input and a user can specify its dataflow with more various stages including Map and Reduce. Nephele transforms a PACT program into a physical DAG then executes the DAG across nodes. Executions in Nephele are scheduled at runtime, like MapReduce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Blocking Operators</head><p>Map and Reduce functions are blocking operations in that all tasks should be completed to move forward to the next stage or job. The reason is that MapReduce relies on external merge sort for grouping intermediate results. This property causes performance degradation and makes it difficult to support online processing.</p><p>Logothetis et al address this problem for the first time when they build MapReduce abstraction onto their distributed stream engine for ad-hoc data processing <ref type="bibr" target="#b29">[29]</ref>.</p><p>Their incremental MapReduce framework processes data like streaming engines. Each task runs continuously with a sliding window. Their system generates MR outputs by reading the items within the window. This stream-based MapReduce processes arriving increments of update tuples, avoiding recomputation of all the tuples from the beginning.</p><p>MapReduce Online is devised to support online aggregation and continuous queries in MapReduce <ref type="bibr" target="#b63">[63]</ref>. It raises an issue that pull-based communication and checkpoints of mapped outputs limit pipelined processing. To promote pipelining between tasks, they modify MapRe-duce architecture by making Mappers push their data temporarily stored in local storage to Reducers periodically in the same MR job. Map-side pre-aggregation is also used to reduce communication volumes further.</p><p>Li et al and Jiang et al have found that the merge sort in MapReduce is I/O intensive and dominantly affects the performance of MapReduce <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b28">28]</ref>. This leads to the use of hash tables for better performance and also incremental processing <ref type="bibr" target="#b21">[21]</ref>. In the study, as soon as each map task outputs its intermediate results, the results are hashed and pushed to hash tables held by reducers. Then, reducers perform aggregation on the values in each bucket. Since each bucket in the hash table holds all values which correspond to a distinct key, no grouping is required. In addition, reducers can perform aggregation on the fly even when all mappers are not completed yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">I/O Optimization</head><p>There are also approaches to reducing I/O cost in MapReduce by using index structures, column-oriented storage, or data compression.</p><p>Hadoop++ provides an index-structured file format to improve the I/O cost of Hadoop <ref type="bibr" target="#b40">[40]</ref>. However, as it needs to build an index for each file partition at data loading stage, loading time is significantly increased. If the input data are processed just once, the additional cost given by building index may not be justified. HadoopDB also benefits from DB indexes by leveraging DBMS as a storage in each node <ref type="bibr" target="#b11">[11]</ref>.</p><p>There are many studies that describe how columnoriented techniques can be leveraged to improve MapReduce's performance dramatically <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b62">62,</ref><ref type="bibr" target="#b68">68,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b69">69</ref>]. Google's BigTable proposes the concept of column family that groups one or more columns as a basic working unit <ref type="bibr" target="#b35">[35]</ref>. Google's Dremel is a nested column-oriented storage that is designed to complement MapReduce <ref type="bibr" target="#b62">[62]</ref>. The read-only nested data in Dremel are modeled with Protocol Buffers <ref type="bibr" target="#b47">[47]</ref>. The data in Dremel are split into multiple columns and records are assembled via finite state machines for record-oriented requests. Dremel is also known to support ad-hoc queries like Hive <ref type="bibr" target="#b16">[16]</ref>.</p><p>Record Columnar File(RCFile), developed by Facebook and adopted by Hive and Pig, is a column-oriented file format on HDFS <ref type="bibr" target="#b68">[68]</ref>. Data placement in HDFS is determined by the master node at runtime. Thus, it is argued that if each column in a relation is independently stored in a separate file on HDFS, all related fields in the same record cannot guarantee to be stored in the same node. To get around this, a file format that represents all values of a relation column-wise in a single file is devised. A RCFile consists of a set of row groups, which are acquired by partitioning a relation horizontally. Then in each row group, values are enumerated in column-wise, similar to PAX storage scheme <ref type="bibr" target="#b3">[3]</ref>.</p><p>Llama shows how column-wise data placement helps join processing <ref type="bibr" target="#b69">[69]</ref>. A column-oriented file in Llama stores a particular column data with optional index information. It also witnesses that late materialization which delays record reconstruction until the column is necessary during query processing is no better than early materialization in many cases.</p><p>Floratou et al propose a binary column-oriented storage that boosts the performance of Hadoop by an order of magnitude <ref type="bibr" target="#b12">[12]</ref>. Their storage format stores each column in a separate file but co-locate associated column files in the same node by changing data placement policy of Hadoop. They also suggest that late materialization with skiplist shows better performance than early materialization, contrary to the result of RCFile. Both Floratou's work and RCFile also use a columnwise data compression in each row group, and adopt a lazy decompression technique to avoid unnecessary decompression during query execution. Hadoop also supports the compression of mapped outputs to save I/Os during the checkpoints <ref type="bibr" target="#b81">[81]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Scheduling</head><p>MapReduce uses a block-level runtime scheduling with a speculative execution. A separate Map task is created to process a single data block. A node which finishes its task early gets more tasks. Tasks on a straggler node are redundantly executed on other idle nodes.</p><p>Hadoop scheduler implements the speculative task scheduling with a simple heuristic method which compares the progress of each task to the average progress. Tasks with the lowest progress compared to the average are selected for re-execution. However, this heuristic method is not well suited in a heterogeneous environment where each node has different computing power. In this environment, even a node whose task progresses further than others may be the last if the node's computing power is inferior to others. Longest Approximate Time to End(LATE) scheduling is devised to improve the response time of Hadoop in heterogeneous environments <ref type="bibr" target="#b52">[52]</ref>. This scheduling scheme estimates the task progress with the progress rate, rather than simple progress score.</p><p>Parallax is devised to estimate job progress more precisely for a series of jobs compiled from a Pig program <ref type="bibr" target="#b45">[45]</ref>. it pre-runs with sampled data for estimating the processing speeds of each stage. ParaTimer is an extended version of Parallax for DAG-style jobs written in Pig <ref type="bibr" target="#b46">[46]</ref>. ParaTimer identifies a critical path that takes longer than others in a parallel query plan. It makes the indicator ignore other shorter paths when estimating progress since the longest path would contribute the overall execution time. Besides, it is reported that the more data blocks to be scheduled, the more cost the scheduler will pay <ref type="bibr" target="#b65">[65]</ref>. Thus, a rule of thumb in in-dustry -making the size of data block bigger makes Hadoop work faster -is credible.</p><p>We now look into multi-user environment whereby users simultaneously execute their jobs in a cluster. Hadoop implements two scheduling schemes: fair scheduling and capacity scheduling. The default fair scheduling works with a single queue of jobs. It assigns physical resources to jobs such that all jobs get an equal share of resources over time on average. In this scheduling scheme, if there is only a single MR job running in a cluster, The job solely uses entire resources in the cluster. Capacity sharing supports designing more sophisticated scheduling. It provides multiple queues each of which is guaranteed to possess a certain capacity of the cluster.</p><p>MRShare is a remarkable work for sharing multiple query executions in MapReduce <ref type="bibr" target="#b64">[64]</ref>. MRShare, inspired by multi query optimization techniques in database, finds an optimal way of grouping a set of queries using dynamic programming. They suggest three sharing opportunities across multiple MR jobs in MapReduce, like found in Pig <ref type="bibr" target="#b18">[18]</ref>: scan sharing, mapped outputs sharing, and Map function sharing. They also introduce a cost model for MR jobs and validate this with experiments. Their experiments show that intermediate result sharing improves the execution time significantly. In addition, they have found that sharing all scans yield poorer performance as the size of intermediate results increases, because of the complexity of the merge-sort operation in MapReduce. Suppose that |D| is the size of input data that n MR jobs share. When sharing all scans, the cost of scanning inputs is reduced by |D|, compared to n • |D| for no sharing scans. However, as a result, the complexity of sorting the combined mapped output of all jobs will be O(n • |D|log(n • |D|)) since each job can generate its own mapped output with size O(|D|). This cost can be bigger than the total cost of sorting n different jobs, O(n • |D|log|D|) in some cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Joins</head><p>Join is a popular operator that is not so well dealt with by Map and Reduce functions. Since MapReduce is designed for processing a single input, the support of joins that require more than two inputs with MapReduce has been an open issue. We roughly classify join methods within MapReduce into two groups: Map-side join and Reduce-side join. We also borrow some of terms from Blanas et al 's study, which compares many join techniques for analysis of clickstream logs at Facebook <ref type="bibr" target="#b57">[57]</ref>, for explaining join techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Map-side Join</head><p>Map-Merge join is a common map-side join that works similarly to sort-merge join in DBMS. Map-Merge join performs in two steps. First, two input relations are partitioned and sorted on the join keys. Second, map-pers read the inputs and merge them <ref type="bibr" target="#b81">[81]</ref>. Broadcast join is another map-side join method, which is applicable when the size of one relation is small <ref type="bibr" target="#b57">[57,</ref><ref type="bibr" target="#b7">7]</ref>. The smaller relation is broadcast to each mapper and kept in memory. This avoids I/Os for moving and sorting on both relations. Broadcast join uses in-memory hash tables to store the smaller relation and to find matches via table lookup with values from the other input relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reduce-side Join</head><p>Repartition join is the most general reduce-side join <ref type="bibr" target="#b81">[81,</ref><ref type="bibr" target="#b57">57]</ref>. Each mapper tags each row of two relations to identify which relation the row come from. After that, rows of which keys have the same key value are copied to the same reducer during shuffling. Finally, each reducer joins the rows on the key-equality basis. This way is akin to hash-join in DBMS. An improved version of the repartition join is also proposed to fix the buffering problem that all records for a given key need to be buffered in memory during the joining process <ref type="bibr" target="#b57">[57]</ref>.</p><p>Lin et al propose a scheme called "schimmy" to save I/O cost during reduce-side join <ref type="bibr" target="#b75">[75]</ref>. The basic concept of the scheme is to separate messages from graph structure data, and shuffle only the message to avoid shuffling data, similar to Pregel <ref type="bibr" target="#b36">[36]</ref>. In this scheme, mappers emit only messages. Reducers read graph structure data directly from HDFS and do reduce-side merge join between the data and the messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MapReduce Variants</head><p>Map-Reduce-Merge is the first that attempts to address join problem in the MapReduce framework <ref type="bibr" target="#b37">[37]</ref>. To support binary operations including join, Map-Reduce-Merge extends MapReduce model by adding Merge stage after Reduce stage.</p><p>Map-Join-Reduce is another variant of MapReduce framework for one-phase joining <ref type="bibr" target="#b27">[27]</ref>. The authors propose a filtering-join-aggregation model that adds Join stage before Reduce stage to perform joining within a single MR job. Each mapper reads tuples from a separate relation which take part in a join process. After that, the mapped outputs are shuffled and moved to joiners for actual joining, then the Reduce() function is applied. Joiners and reducers are actually run inside the same reduce task. An alternative that runs Map-Join-Reduce with two consecutive MR jobs is also proposed to avoid modifying MapReduce framework. For multi-way join, join chains are represented as a left-deep tree. Then previous joiners transfer joined tuples to the next joiner that is the parent operation of the previous joiners in the tree. For this, Map-Join-Reduce adopts one-to-many shuffling scheme that shuffles and assigns each mapped outputs to multiple joiners at a time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other Join Types</head><p>Joins may have more than two relations. If relations are simply hash-partitioned and fed to reducers, each reducer takes a different portion of the relations. How-ever, the same relation must be copied to all reducers to avoid generating incomplete join results in the cases. For example, given a multi-way join that reads 4 relations and with 4 reducers, we can split only 2 relations making 4 partitions in total. The other relations need to be copied to all reducers. If more relations are involved into less reducers, we spend more communication costs. Afrati et al focus on how to minimize the sum of the communication cost of data that are transferred to Reducers for multi-way join <ref type="bibr" target="#b2">[2]</ref>. They suggest a method based on Lagrangean multipliers to properly select which columns and how many of the columns should be partitioned for minimizing the sum of the communication costs. Lin et al propose the concurrent join that performs a multi-way join in parallel with MapReduce <ref type="bibr" target="#b69">[69]</ref>.</p><p>In addition to binary equal-join, other join types have been widely studied. Okcan et al propose how to efficiently perform θ-join with a single MR job only <ref type="bibr" target="#b14">[14]</ref>. Their algorithm uses a Reducer-centered cost model that calculates the total cost of Cartesian product of mapped output. With the cost model, they assigns mapped output to reducers that minimizes job completion time. The support of Semi-join, e.g. R S, is proposed in <ref type="bibr" target="#b57">[57]</ref>. Vernica et al propose how to efficiently parallelize set-similarity joins with Mapreduce <ref type="bibr" target="#b56">[56]</ref>. They utilize prefix filtering to filter out non-candidates before actual comparison. It requires to extract common prefixes sorted in a global order of frequency from tuples, each of which consists of a set of items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Performance Tuning</head><p>Most of MapReduce programs are written for data analysis and they usually take much time to be finished. Thus, it is straightforward to provide the feature of automatic optimization for MapReduce programs. Babu et al suggest an automatic tuning approach to finding optimal system parameters for given input data <ref type="bibr" target="#b5">[5]</ref>. It is based on speculative pre-runs with sampled data. Jahani et al suggest a static analysis approach called MANIMAL for automatic optimization of a single Map-Reduce job <ref type="bibr" target="#b34">[34]</ref>. In their approach, an analyzer examines program codes before execution without any runtime information. Based on the rules found during the analysis, it creates a pre-computed B + -tree index and slices input data column-wise for later use. In addition, some semantic-aware compression techniques are used for reducing I/O. Its limitation is that the optimization considers only selection and projection which are primarily implemented in Map function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Energy Issues</head><p>Energy issue is important especially in this data-center computing era. Since the energy cost of data centers hits 23% of the total amortized monthly operating ex-penses, it is prudent to devise an energy-efficient way to control nodes in a data center when the nodes are idle <ref type="bibr" target="#b74">[74]</ref>. In this respect, two extreme strategies for energy management in MapReduce clusters are examined <ref type="bibr" target="#b74">[74,</ref><ref type="bibr" target="#b43">43]</ref>. Covering-Set approach designates in advance some nodes that should keep at least a replica of each data block, and the other nodes are powered down during low-utilization periods <ref type="bibr" target="#b43">[43]</ref>. Since the dedicated nodes always have more than one replica of data, all data across nodes are accessible in any cases except for multiple node failures. On the contrary, All-In strategy saves energy in an all-or-nothing fashion <ref type="bibr" target="#b74">[74]</ref>. In the strategy, all MR jobs are queued until it reaches a threshold predetermined. If it exceeds, all nodes in the cluster run to finish all MR jobs and then all the nodes are powered down until new jobs are queued enough. Lang et al concluded that All-In strategy is superior to Covering-Set in that it does not require changing data placement policy and response time degradation. However, All-In strategy may not support an instant execution because of its batch nature. Similarly, Chen et al discuss the computation versus I/O tradeoffs when using data compressions in a MapReduce cluster in terms of energy efficiency <ref type="bibr" target="#b67">[67]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10">Hybrid Systems</head><p>HadoopDB is a hybrid system that connects multiple single-node DBMS with MapReduce for combining MapReduce-style scalability and the performance of DBMS <ref type="bibr" target="#b11">[11]</ref>. HadoopDB utilizes MapReduce as a distributing system which controls multiple nodes which run single-node DBMS engines. Queries are written in SQL, and distributed via MapReduce across nodes. Data processing is boosted by the features of singlenode DBMS engines as workload is assigned to the DBMS engines as much as possible.</p><p>SQL/MapReduce is another hybrid framework that enables to execute UDF functions in SQL queries across multiple nodes in MapReduce-style <ref type="bibr" target="#b33">[33]</ref>. UDFs extend a DBMS with customizing DB functionality. SQL/Map-Reduce presents an approach to implementing UDF that can be executed across multiple nodes in parallel by virtue of MapReduce. Greenplum also provides the ability to write MR functions in their parallel DBMS. Teradata makes its effort to combine Hadoop with their parallel DBMS <ref type="bibr" target="#b70">[70]</ref>. The authors describe their three efforts toward tight and efficient integration of Hadoop and Teradata EDW: parallel loading of Hadoop data to EDW, retrieving EDW data from MR programs, and accessing Hadoop data from SQL via UDFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">APPLICATIONS AND ADAPTATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Applications</head><p>Mahout is an Apache project that aims at building scalable machine learning libraries which are executed in parallel by virtue of Hadoop <ref type="bibr" target="#b1">[1]</ref>. RHIPE and Ricardo project are tools that integrate R statistical tool and Hadoop to support parallel data analysis <ref type="bibr" target="#b73">[73,</ref><ref type="bibr" target="#b58">58]</ref>. Cheetah is a data warehousing tool built on MapReduce with virtual view on top of the star or snowflake schemas and with some optimization techniques like data compression and columnar store <ref type="bibr" target="#b7">[7]</ref>. Osprey is a shared-nothing database system that supports MapReduce-style fault tolerance <ref type="bibr" target="#b25">[25]</ref>. Osprey does not directly use MapReduce or GFS. However, the fact table in star schema is partitioned and replicated like GFS, and tasks are scheduled by a central runtime scheduler like MapReduce. A difference is that Osprey does not checkpoint intermediate outputs. Instead, it uses a technique called chained declustering which limits data unavailability when node failures happen.</p><p>The use of MapReduce for data intensive scientific analysis and bioinformatics are well studied in <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b80">80]</ref>. CloudBLAST parallelizes NCBI BLAST2 algorithm using Hadoop <ref type="bibr" target="#b13">[13]</ref>. They break their input sequences down into multiple blocks and run an instance of the vanilla version of NCBI BLAST2 for each block, using the Hadoop Streaming utility <ref type="bibr" target="#b81">[81]</ref>. CloudBurst is a parallel read-mapping tool that maps NGS read sequencing data to a reference genome for genotyping in parallel <ref type="bibr" target="#b78">[78]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Adaptations to Intra-node Parallelism</head><p>Some studies use the MapReduce model for simplifying complex multi-thread programming on many-core systems such as multi-core <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b65">65]</ref>, GPU <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b19">19]</ref>, and Cell processors <ref type="bibr">[8]</ref>. In the studies, mapped outputs are transferred to reducers via shared-memory rather than disks. In addition, a task execution is performed by a single core rather than a node. In this intra-node parallelism, fault-tolerance can be ignored since all cores are located in a single system. A combination of intra-node and inter-node parallelism by the MapReduce model is also suggested <ref type="bibr" target="#b54">[54]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSION AND CHALLENGES</head><p>MapReduce is becoming ubiquitous, even though its efficiency and performance are controversial. There is nothing new about principles used in MapReduce <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b51">51]</ref>. However, MapReduce shows that many problems can be solved in the model at scale unprecedented before. Due to frequent checkpoints and runtime scheduling with speculative execution, MapReduce reveals low efficiency. However, such methods would be necessary to achieve high scalability and fault tolerance in massive data processing. Thus, how to increase efficiency guaranteeing the same level of scalability and fault tolerance is a major challenge. The efficiency problem is expected to be overcome in two ways: improving MapReduce it-self and leveraging new hardware. How to utilize the features of modern hardware has not been answered in many areas. However, modern computing devices such as chip-level multiprocessors and Solid State Disk(SSD) can help reduce computations and I/Os in MapReduce significantly. The use of SSD in Hadoop with simple installation is briefly examined, but not in detail <ref type="bibr" target="#b21">[21]</ref>. Self-tuning and job scheduling in multi-user environments are another issues that have not been well address yet. The size of MR clusters is continuously increasing. A 4,000-node cluster is not surprising any more. How to efficiently manage resources in the clusters of that size in multi-user environment is also challenging. Yahoo's M45 cluster reportedly shows only 5∼10% resource utilization <ref type="bibr" target="#b60">[60]</ref>. Energy efficiency in the clusters and achieving high utilizations of MR clusters are also important problems that we consider for achieving better TCO and return on investments in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>We discussed pros and cons of MapReduce and classified its improvements. MapReduce is simple but provides good scalability and fault-tolerance for massive data processing. However, MapReduce is unlikely to substitute DBMS even for data warehousing. Instead, we expect that MapReduce complements DBMS with scalable and flexible parallel processing for various data analysis such as scientific data processing. Nonetheless, efficiency, especially I/O costs of MapReduce still need to be addressed for successful implications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Hadoop Architecture</figDesc><graphic coords="2,343.17,50.41,186.82,186.82" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>SIGMOD Record, December 2011 (Vol.<ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b4">No. 4)</ref> </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work is supported by the National Research Fund (NRF) grant funded by Korea government(MEST)(No. 2011-0016282).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Scalable machine-learning and data-mining library</title>
		<author>
			<persName><surname>Mahout</surname></persName>
		</author>
		<ptr target="http://mapout.apache.org" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing joins in a map-reduce environment</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Afrati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th EDBT</title>
		<meeting>the 13th EDBT</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="99" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weaving relations for cache performance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skounakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="page" from="169" to="180" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Scaling Hadoop to 4000</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<ptr target="http://goo.gl/8dRMq" />
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards automatic optimization of mapreduce programs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM symposium on Cloud computing</title>
		<meeting>the 1st ACM symposium on Cloud computing</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="http://discoproject.org" />
		<title level="m">Disco: Massive data-minimal code</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Nokia Research Center</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cheetah: a high performance, custom data warehouse on top of MapReduce</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB</title>
		<meeting>the VLDB</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mapreduce for the cell broadband engine architecture</title>
		<author>
			<persName><forename type="first">M</forename><surname>De Kruijf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Designs, lessons and advice from building large distributed systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Keynote from LADIS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MapReduce: A major step backwards</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Database Column</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">HadoopDB: An architectural hybrid of MapReduce and DBMS technologies for analytical workloads</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abouzeid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="922" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Column-Oriented Storage Techniques for MapReduce</title>
		<author>
			<persName><forename type="first">A</forename><surname>Floratou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB</title>
		<meeting>the VLDB</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cloudblast: Combining mapreduce and virtualization on distributed resources for bioinformatics applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Matsunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth IEEE International Conference on eScience</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Processing Theta-Joins using MapReduce</title>
		<author>
			<persName><forename type="first">A</forename><surname>Okcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 ACM SIGMOD</title>
		<meeting>the 2011 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comparison of approaches to large-scale data analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pavlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD</title>
		<meeting>the ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="165" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hive: a warehousing solution over a map-reduce framework</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thusoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1626" to="1629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hive-a petabyte scale data warehouse using Hadoop</title>
		<author>
			<persName><forename type="first">A</forename><surname>Thusoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th IEEE ICDE</title>
		<meeting>the 26th IEEE ICDE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="996" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Building a high-level dataflow system on top of Map-Reduce: the Pig experience</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Gates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1414" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A map reduce framework for programming graphics processors</title>
		<author>
			<persName><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Software Tools for MultiCore Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mars: a MapReduce framework on graphics processors</title>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th PACT</title>
		<meeting>the 17th PACT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Platform for Scalable One-Pass Analytics using MapReduce</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 ACM SIGMOD</title>
		<meeting>the 2011 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pig latin: a not-so-foreign language for data processing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Olston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD</title>
		<meeting>the ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1099" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relational versus Non-Relational Database Systems for Data Warehousing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ordonez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM DOLAP</title>
		<meeting>the ACM DOLAP</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="67" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating mapreduce for multi-core and multiprocessor systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ranger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE HPCA</title>
		<meeting>the 2007 IEEE HPCA</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Osprey: Implementing MapReduce-style fault tolerance in a shared-nothing distributed database</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th IEEE ICDE</title>
		<meeting>the 26th IEEE ICDE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nephele/PACTs: a programming model and execution framework for web-scale analytical processing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Battré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM symposium on Cloud computing</title>
		<meeting>the 1st ACM symposium on Cloud computing</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Map-join-reduce: Towards scalable and efficient data analysis on large clusters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The performance of mapreduce: An in-depth study</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="472" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ad-hoc data processing in the cloud</title>
		<author>
			<persName><forename type="first">D</forename><surname>Logothetis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1472" to="1475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nephele: efficient parallel data processing in the cloud</title>
		<author>
			<persName><forename type="first">D</forename><surname>Warneke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd MTAGS</title>
		<meeting>the 2nd MTAGS</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Clustera: an integrated computation and data management system</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="28" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Efficiency matters! ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="45" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SQL/MapReduce: A practical approach to self-describing, polymorphic, and parallelizable user-defined functions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1402" to="1413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic Optimization for MapReduce Programs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jahani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB</title>
		<meeting>the VLDB</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="385" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bigtable: A distributed storage system for structured data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems (TOCS)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pregel: a system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Malewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD</title>
		<meeting>the 2010 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Map-reduce-merge: simplified relational data processing on large clusters</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 ACM SIGMOD</title>
		<meeting>the 2007 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1029" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">MapReduce: Simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">MapReduce: a flexible data processing tool</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="72" to="77" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Hadoop++: Making a yellow elephant run like a cheetah (without it even noticing)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dittrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="515" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mapreduce for data intensive scientific analyses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ekanayake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 4th IEEE International Conference on eScience</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="277" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Twister: A runtime for iterative MapReduce</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ekanayake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM HPDC</title>
		<meeting>the 19th ACM HPDC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="810" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On the energy (in) efficiency of hadoop clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Leverich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="65" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mapreduce: Simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th USENIX OSDI</title>
		<meeting>the 6th USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="137" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Estimating the Progress of MapReduce Pipelines</title>
		<author>
			<persName><forename type="first">K</forename><surname>Morton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the 26th IEEE ICDE</title>
		<meeting>the the 26th IEEE ICDE</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="681" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Paratimer: a progress indicator for mapreduce dags</title>
		<author>
			<persName><forename type="first">K</forename><surname>Morton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD</title>
		<meeting>the 2010 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="507" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Protocol Buffer-Google&apos;s data interchange format</title>
		<author>
			<persName><forename type="first">Kenton</forename></persName>
		</author>
		<ptr target="http://code.google.com/p/protobuf/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dryad: distributed data-parallel programs from sequential building blocks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems</title>
		<meeting>the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="59" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distributed data-parallel computing using a high-level programming language</title>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD</title>
		<meeting>the ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="987" to="994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">One size fits all? Part 2: Benchmarking results</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Innovative Data Systems Research (CIDR)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">MapReduce and parallel DBMSs: friends or foes?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="71" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Improving mapreduce performance in heterogeneous environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX OSDI</title>
		<meeting>the 8th USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scope: easy and efficient parallel processing of massive data sets</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chaiken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1265" to="1276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multiple data independent tasks on a heterogeneous resource architecture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Farivar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Cluster Computing and Workshops</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Interpreting the data: Parallel analysis with Sawzall</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Programming</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="277" to="298" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Efficient parallel set-similarity joins using mapreduce</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vernica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD</title>
		<meeting>the 2010 ACM SIGMOD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="495" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A comparison of join algorithms for log processing in MaPreduce</title>
		<author>
			<persName><forename type="first">S</forename><surname>Blanas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD</title>
		<meeting>the 2010 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="975" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Ricardo: integrating R and Hadoop</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD</title>
		<meeting>the 2010 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="987" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The google file system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">An analysis of traces from a production mapreduce cluster</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kavulya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th IEEE/ACM CCGrid</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="94" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Analyzing massive astrophysical datasets: Can Pig/Hadoop or a relational DBMS help</title>
		<author>
			<persName><forename type="first">S</forename><surname>Loebman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Cluster Computing and Workshops</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Dremel: interactive analysis of web-scale datasets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Melnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="330" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">MapReduce online</title>
		<author>
			<persName><forename type="first">T</forename><surname>Condie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th USENIX conference on Networked systems design and implementation</title>
		<meeting>the 7th USENIX conference on Networked systems design and implementation</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="21" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">MRshare: Sharing across multiple queries in mapreduce</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nykiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB</title>
		<meeting>the VLDB</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="494" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A Map-Reduce System with an Alternate API for Multi-core Environments</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th IEEE/ACM CCGrid</title>
		<meeting>the 10th IEEE/ACM CCGrid</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="84" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">HaLoop: Efficient iterative data processing on large clusters</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="285" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">To compress or not to compress -compute vs. IO tradeoffs for mapreduce energy efficiency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first ACM SIGCOMM workshop on Green networking</title>
		<meeting>the first ACM SIGCOMM workshop on Green networking</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="23" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">RCFile: A Fast and Space-efficient Data Placement Structure in MapReduce-based Warehouse Systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 IEEE ICDE</title>
		<meeting>the 2011 IEEE ICDE</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Llama: Leveraging Columnar Storage for Scalable Join Processing in the MapReduce Framework</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 ACM SIGMOD</title>
		<meeting>the 2011 ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Integrating Hadoop and parallel DBMS</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD</title>
		<meeting>the ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="969" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">DryadLINQ: A system for general-purpose distributed data-parallel computing using a high-level language</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th USENIX OSDI</title>
		<meeting>the 8th USENIX OSDI</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Rethinking cost and performance of database systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Florescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="48" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Guha</surname></persName>
		</author>
		<ptr target="http://www.stat.purdue.edu/sguha/rhipe/" />
		<title level="m">RHIPE-R and Hadoop Integrated Processing Environment</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Energy management for MapReduce clusters</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB</title>
		<meeting>the VLDB</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="129" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Data-intensive text processing with MapReduce</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="177" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Winning a 60 second dash with a yellow elephant</title>
		<author>
			<persName><forename type="first">O</forename><surname>O'malley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of sort benchmark</title>
		<meeting>sort benchmark</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Technical perspective: the data center is the computer</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="105" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">CloudBurst: highly sensitive read mapping with MapReduce</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Schatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1363</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">One size fits all: An idea whose time has come and gone</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Cetintemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st IEEE ICDE</title>
		<meeting>the 21st IEEE ICDE</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">An overview of the Hadoop/MapReduce/HBase framework and its current applications in bioinformatics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">Suppl 12</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Hadoop: The Definitive Guide</title>
		<author>
			<persName><forename type="first">T</forename><surname>White</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Yahoo Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
