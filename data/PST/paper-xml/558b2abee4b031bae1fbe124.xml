<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convolutional Neural Network Committees For Handwritten Character Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dan</forename><surname>Claudiu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country>SUPSI, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cires</forename><surname>¸an</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country>SUPSI, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ueli</forename><surname>Meier</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country>SUPSI, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><forename type="middle">Maria</forename><surname>Gambardella</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country>SUPSI, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IDSIA USI</orgName>
								<address>
									<postCode>6928</postCode>
									<settlement>Manno-Lugano</settlement>
									<country>SUPSI, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Convolutional Neural Network Committees For Handwritten Character Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">635BE03FF70C42C64C91C00F4C14ED54</idno>
					<idno type="DOI">10.1109/ICDAR.2011.229</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional Neural Networks</term>
					<term>Graphics Processing Unit</term>
					<term>Handwritten Character Recognition</term>
					<term>Committee</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In 2010, after many years of stagnation, the MNIST handwriting recognition benchmark record dropped from 0.40% error rate to 0.35%. Here we report 0.27% for a committee of seven deep CNNs trained on graphics cards, narrowing the gap to human performance. We also apply the same architecture to NIST SD 19, a more challenging dataset including lower and upper case letters. A committee of seven CNNs obtains the best results published so far for both NIST digits and NIST letters. The robustness of our method is verified by analyzing 78125 different 7-net committees.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Current automatic handwriting recognition algorithms are not bad at learning to recognize handwritten characters. Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> are among the most suitable architectures for this task. Recent CNN work focused on computer vision problems such as recognition of 3D objects, natural images and traffic signs <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b4">[5]</ref>, image denoising <ref type="bibr" target="#b5">[6]</ref> and image segmentation <ref type="bibr" target="#b6">[7]</ref>. Convolutional architectures also seem to benefit unsupervised learning algorithms applied to image data <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Reference <ref type="bibr" target="#b9">[10]</ref> reported an error rate of 0.4% on the MNIST handwritten character recognition dataset <ref type="bibr" target="#b1">[2]</ref>, using a fairly simple CNN, plus elastic training image deformations to increase the training data size. In 2010, using graphics cards (GPUs) to greatly speed up training of plain but deep Multilayer Perceptrons (MLPs), an error rate of 0.35% was obtained <ref type="bibr" target="#b10">[11]</ref>. Such an MLP has many more free parameters than a CNN. Here we report experiments using CNNs trained on MNIST as well as on the more challenging NIST SD 19 database <ref type="bibr" target="#b11">[12]</ref>, which contains 482,925 training and 82,587 test characters (i.e. upper-and lower-case letters as well as digits). On GPUs, CNNs can be successfully trained on such extensive databases within reasonable time (≈ 1 to 6 hours of training, depending on the task).</p><p>At some stage in the classifier design process one usually has collected a set of reasonable classifiers. Typically one of them yields best performance. Intriguingly, however, the sets of patterns misclassified by different classifiers do not necessarily greatly overlap. Here we focus on improving recognition rates using committees of neural networks. Our goal is to produce a group of classifiers whose errors on various parts of the training set differ as much as possible. We show that for handwritten digit recognition this can be achieved by training identical classifiers on data preprocessed/normalized in different ways <ref type="bibr" target="#b12">[13]</ref>: 0.31% error rate for a committee of simple, big and deep MLPs on MNIST. Other approaches aiming at optimally combining neural networks <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref> do not do this, thus facing the problem of strongly correlated individual predictors. Furthermore, we simply average individual committee member outputs, instead of optimizing their combinations <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, which would cost additional valuable training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. TRAINING THE INDIVIDUAL NETS</head><p>CNNs are used as base classifiers <ref type="bibr" target="#b3">[4]</ref>. The same architecture is used for experiments on NIST SD 19 and MNIST. The nets have an input layer of 29 × 29 neurons followed by a convolution layer with 20 maps of 26 × 26 neurons and filters of size 4 × 4. The next hidden layer is a maxpooling layer <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> with a 2 × 2 kernel which has its outputs connected to another convolution layer containing 40 maps of 9 × 9 neurons each. The last max-pooling layer is reducing the map size to 3 × 3 by using filters of size 3 × 3. A fully connected layer of 150 neurons is connected to the max-pooling layer. The output layer has one neuron per class, e.g. 62 for NIST SD 19 and 10 for MNIST.</p><p>All CNNs are trained in full online mode with an annealed learning rate and continually deformed data-the images from the training set are distorted at the beginning of every epoch. The following elastic deformation parameters σ = 6 and α = 36 are used together with independent horizontal and vertical scaling of at most 15% and at most ±15 • of rotation for all experiments <ref type="bibr" target="#b10">[11]</ref>. Deformations are essential to prevent overfitting, and greatly improve generalization.</p><p>GPUs accelerate the deformation routine by a factor of 10 (only elastic deformations are GPU-optimized), and the network training procedure by a factor of 60 <ref type="bibr" target="#b3">[4]</ref>. We pick the trained CNN with the lowest validation error, and evaluate it on the corresponding test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. FORMING A COMMITTEE</head><p>We perform experiments on the original and six preprocessed datasets. Preprocessing is motivated by writing style variations resulting in different aspect ratios of the handwritten characters. Prior to training, we therefore normalize the width of all characters to 10, 12, 14, 16, 18 and 20 pixels, except for characters in {1,i,l,I} and in the original data <ref type="bibr" target="#b12">[13]</ref>.</p><p>The training procedure of a network is summarized in Figure <ref type="figure" target="#fig_0">1a</ref>. Each network is trained separately on normalized or original data. The normalization is done for all digits in the training set prior to training (normalization stage). During each training epoch every single character is distorted in a different way. The committees are formed by simply averaging the corresponding outputs as shown in Figure <ref type="figure" target="#fig_0">1b</ref>.</p><p>For each of the preprocessed or original datasets, five differently initialized CNNs are trained for the same number of epochs. This allows for performing an error analysis of the outputs of the 5 7 = 78125 possible committees of seven nets, each trained on one of the seven datasets. We report mean and standard deviation as well as minimum and maximum recognition rate. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>We use a system with a Core i7-920 (2.66GHz), 12 GB DDR3 and four graphics cards: 2 x GTX 480 and 2 x GTX 580. Details of our GPU implementation are explained in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>Our method is applied to two handwritten character datasets: subsets from NIST SD 19 and digits from MNIST (Table <ref type="table">I</ref>).</p><p>We use the proven learning rate schedule of our previous work <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>: in every epoch (up to a predetermined number of epochs) we multiply the learning rate (initially 0.001) by a factor of 0.993 until it reaches 0.00003. NIST SD 19 contains over 800,000 handwritten characters. We follow the recommendations of the authors and build standard training and test sets. The 128×128 character images are uncompressed; their bounding-boxes are resized to 20 × 20. The resulting characters are centered within a 29×29 image. This normalizes all the characters in the same way MNIST digits are already normalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Digits &amp; letters:</head><p>We train five differently initialized nets on each preprocessed dataset as well as on the original data, for a total of 35 CNNs (Table <ref type="table" target="#tab_1">II</ref>). Each CNN is trained for 30 epochs by on-line gradient descent. The number of epochs is limited due to the size of NIST SD 19: training a single net for the 62 class problem takes almost six hours. The average committee is significantly better than any of the individual CNNs. Even the worst committee is better than the best net. Recognition errors of around 12% may still seem large, but one should consider that most errors stem from confusions of classes that look very similar: {0,o,O}, {1,l,i,I}, {6,G}, {9,g}, and all confusions between similar uppercase and lowercase letters (see below). Without any additional contextual information, it is literally impossible to distinguish those.</p><p>We therefore also train various nets on digits, all letters, a merged letter set, and also on lowercase and uppercase letters separately. This drastically decreases the number of confused classes and also makes it possible to compare our results to other published results. We are not aware of any previous study publishing results on the challenging full 62 class problem.</p><p>2) Digits: Table <ref type="table" target="#tab_1">III</ref> summarizes the results of 35 identical CNNs trained for 30 epochs on digits. Our average error rate of 0.81% on digits compares favorably to other published results, 1.88% <ref type="bibr" target="#b18">[19]</ref>, 2.4% <ref type="bibr" target="#b19">[20]</ref> and 3.71% <ref type="bibr" target="#b20">[21]</ref>. Again, as for the 62 class problem, the committees significantly outperform the individual nets.</p><p>3) Letters: Table (IV) summarizes the results of 35 identical CNNs trained for 30 epochs on letters. Again the same architecture is used. Class boundaries of letters in general and uppercase and lowercase letters in particular are separated less clearly than those of digits. However, many obvious error types are avoidable by different experimental set-ups, i.e., by ignoring case, merging classes, and considering uppercase and lowercase classes independently. Ignoring case, average error is three times smaller (7.58%). <ref type="figure">{C,</ref><ref type="figure">I,</ref><ref type="figure">J,</ref><ref type="figure">K,</ref><ref type="figure">L,</ref><ref type="figure">M,</ref><ref type="figure">O,</ref><ref type="figure">P,</ref><ref type="figure">S,</ref><ref type="figure">U,</ref><ref type="figure">V,</ref><ref type="figure">W,</ref><ref type="figure">X,</ref><ref type="figure">Y</ref>,Z} are merged as suggested in the NIST SD 19 documentation <ref type="bibr" target="#b11">[12]</ref>, resulting in 37 distinct classes for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Merged letters: Table V summarizes results of 35 identical CNNs trained for 30 epochs on merged letters. Uppercase and lowercase letters in</head><p>Ignoring case for only 15 out of 26 letters suffices to avoid most case confusions. Ignoring case completely reduces error only slightly, under loss of ability to distinguish the case of the 11 remaining letters. 5) Upper-or lowercase letters: Further simplifying the task by considering uppercase and lowercase letters independently yields even lower error rates (Tables VI, VII). Uppercase letters are much easier to classify than lowercase letters-error rates are four times smaller. Shapes of uppercase letters are better defined, and in-class variability due to different writing styles is generally smaller. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments on MNIST</head><p>The MNIST data is already preprocessed such that the width or height of each digit is 20 pixels. Our CNNs are trained for around 800 epochs, with small improvement after 500 epochs. Training one net takes almost 14 hours.</p><p>The average error rate of 0.27 ± 0.02% is by far the best result published on this benchmark. In Figure <ref type="figure" target="#fig_1">2</ref> all 69 errors of all committees are shown, together with the true labels and the majority votes of the committees. Digits are sorted in descending order of how many committees committed the same error, indicated as percentages at the bottom of each digit. The first six errors were committed by all committees-obviously the corresponding digits are either wrongly labeled or very ambiguous, and the majority vote seems correct. Each committee fails to recognize between 17 to 37 digits out of the 69 presented errors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Summary of experiments</head><p>Table <ref type="table">IX</ref> summarizes our results and compares to previously published results where available. For letters it was difficult to find any publications reporting results for similar experimental set-ups. To the best of our knowledge, our results are far better (30-350%) than any published result.</p><p>Error rates for digits are significantly lower than those for letters. Training nets with case-insensitive letter labels makes error rates drop considerably, indicating that most errors of nets trained on 52 lowercase and uppercase letters are due to confusions between similar classes. A generic letter recognizer should therefore be trained on a merged letter dataset. If required, case conflicts have to be resolved a posteriori, using additional (e.g, contextual) information.</p><p>All experiments use the same net architecture and deformation parameters, which are not fine-tuned to increase classification accuracy. We rely on committees to improve recognition rates. Additional tests, however, show that our deformation parameters are too big for small letters-using 20% lower values decreases error rates by another 1.5%. 7.71±0.14 16.00 <ref type="bibr" target="#b23">[24]</ref> 13.27 <ref type="bibr" target="#b22">[23]</ref> For commercial OCR, recognition speed is of great interest. Our nets check almost 10000 characters per second. At first glance, a committee of seven such nets is seven times slower than a single net, but we can run the nets in parallel on seven different GPUs, thus keeping the committee throughput at the single net level.</p><p>We won the ICDAR 2011 Offline Chinese Character Recognition Competition <ref type="bibr" target="#b25">[26]</ref> with a CNN architecture virtually identical to the one of this paper, all differences being dictated by the input size of the nets. The good results on this huge problem with 3755 classes further confirm the flexibility, robustness and scalability of our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>Simple training data pre-processing gave us experts with errors less correlated than those of different nets trained on the same or bootstrapped data. Hence committees that simply average the expert outputs considerably improve recognition rates. Our committee-based classifiers of isolated handwritten characters are the first on par with human performance <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, and can be used as basic building blocks of any OCR system (all our results were achieved by software running on powerful yet cheap gaming cards).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. a) Training a committee member: Original training data (left digit) is normalized (W10) prior to training (middle digit). The normalized data is distorted (D) for each training epoch (right digit) and fed to the neural network (NN). Each depicted digit represents the whole training set. b) Testing with a committee: If required, the input digits are widthnormalized (W blocks) and then processed by the corresponding NNs. A committee averages the outputs of its CNNs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The 69 errors of all committees, the label (up left), the committee majority vote (up right), and the percentage of committees committing a particular error (down left).</figDesc><graphic coords="4,67.45,309.35,216.60,151.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table II TEST</head><label>II</label><figDesc>ERROR RATE [%] OF THE 35 CNNS TRAINED ON NIST SD 19, 62 CLASS TASK. WXX -WIDTH OF THE CHARACTER IS NORMALIZED TO</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">XX PIXELS.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Trial</cell><cell>W10</cell><cell>W12</cell><cell>W14</cell><cell>W16</cell><cell>W18</cell><cell>W20</cell><cell>ORIG</cell></row><row><cell>1</cell><cell cols="6">14.72 14.12 13.72 13.55 13.77 13.82</cell><cell>14.32</cell></row><row><cell>2</cell><cell cols="6">14.73 14.21 13.80 14.20 13.93 13.04</cell><cell>14.73</cell></row><row><cell>3</cell><cell cols="6">13.92 14.12 13.50 13.57 13.81 14.15</cell><cell>14.57</cell></row><row><cell>4</cell><cell cols="6">14.07 14.42 13.46 13.47 13.76 13.63</cell><cell>14.05</cell></row><row><cell>5</cell><cell cols="6">14.14 13.69 13.91 13.92 13.50 13.60</cell><cell>13.72</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Committees</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Average 11.88±0.09</cell><cell cols="2">Min 11.68</cell><cell cols="2">Max 12.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table V TEST</head><label>V</label><figDesc>ERROR RATE [%] OF 35 CNNS TRAINED ON NIST SD 19 MERGED LETTERS. WXX -WIDTH OF THE CHARACTER IS NORMALIZED TO XX PIXELS.</figDesc><table><row><cell>Trial</cell><cell>W10</cell><cell>W12</cell><cell>W14</cell><cell cols="2">W16 W18</cell><cell>W20</cell><cell>ORIG</cell></row><row><cell>1</cell><cell cols="2">10.40 10.11</cell><cell>9.54</cell><cell>9.67</cell><cell>9.30</cell><cell>9.38</cell><cell>10.01</cell></row><row><cell>2</cell><cell cols="2">10.38 10.20</cell><cell>9.99</cell><cell>9.47</cell><cell>9.68</cell><cell>9.34</cell><cell>10.25</cell></row><row><cell>3</cell><cell cols="2">10.69 10.23</cell><cell>9.50</cell><cell>9.52</cell><cell>9.55</cell><cell>9.87</cell><cell>10.08</cell></row><row><cell>4</cell><cell cols="3">11.10 10.21 10.20</cell><cell>9.95</cell><cell>9.86</cell><cell>9.76</cell><cell>10.21</cell></row><row><cell>5</cell><cell cols="3">10.87 10.80 10.35</cell><cell>9.46</cell><cell>9.71</cell><cell>10.03</cell><cell>10.64</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Committees</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Average 8.21±0.11</cell><cell cols="2">Min 7.83</cell><cell cols="2">Max 8.56</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table VI TEST</head><label>VI</label><figDesc>ERROR RATE [%] OF 35 CNNS TRAINED ON NIST SD 19 UPPERCASE LETTERS. WXX -WIDTH OF THE CHARACTER IS NORMALIZED TO XX PIXELS.</figDesc><table><row><cell cols="8">Trial W10 W12 W14 W16 W18 W20 ORIG</cell></row><row><cell>1</cell><cell>3.08</cell><cell>2.90</cell><cell>2.80</cell><cell>2.51</cell><cell>2.60</cell><cell>2.55</cell><cell>2.79</cell></row><row><cell>2</cell><cell>3.03</cell><cell>2.73</cell><cell>2.84</cell><cell>2.70</cell><cell>2.78</cell><cell>2.53</cell><cell>2.70</cell></row><row><cell>3</cell><cell>3.33</cell><cell>2.96</cell><cell>2.83</cell><cell>2.65</cell><cell>2.84</cell><cell>2.65</cell><cell>2.68</cell></row><row><cell>4</cell><cell>3.29</cell><cell>3.22</cell><cell>2.96</cell><cell>2.65</cell><cell>2.65</cell><cell>2.60</cell><cell>2.87</cell></row><row><cell>5</cell><cell>3.23</cell><cell>2.97</cell><cell>2.70</cell><cell>2.78</cell><cell>2.86</cell><cell>2.64</cell><cell>2.70</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Committees</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Average 1.91±0.06</cell><cell cols="2">Min 1.71</cell><cell cols="2">Max 2.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table VII TEST</head><label>VII</label><figDesc>ERROR RATE [%] OF 35 CNNS TRAINED ON NIST SD 19 LOWERCASE LETTERS. WXX -WIDTH OF THE CHARACTER IS NORMALIZED TO XX PIXELS.</figDesc><table><row><cell>Trial</cell><cell>W10</cell><cell>W12</cell><cell>W14</cell><cell cols="2">W16 W18</cell><cell>W20</cell><cell>ORIG</cell></row><row><cell>1</cell><cell>10.22</cell><cell>9.30</cell><cell>9.42</cell><cell>9.25</cell><cell>9.08</cell><cell>8.87</cell><cell>9.44</cell></row><row><cell>2</cell><cell>10.30</cell><cell>9.75</cell><cell>9.91</cell><cell>9.63</cell><cell>9.19</cell><cell>9.32</cell><cell>8.84</cell></row><row><cell>3</cell><cell>10.51</cell><cell>9.88</cell><cell>9.95</cell><cell>9.18</cell><cell>8.88</cell><cell>9.82</cell><cell>9.29</cell></row><row><cell>4</cell><cell>10.12</cell><cell>9.73</cell><cell>10.39</cell><cell>9.63</cell><cell>9.05</cell><cell>10.05</cell><cell>10.04</cell></row><row><cell>5</cell><cell>10.82</cell><cell>9.56</cell><cell>10.08</cell><cell>9.53</cell><cell>9.58</cell><cell>9.59</cell><cell>10.24</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Committees</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Average 7.71±0.14</cell><cell cols="2">Min 7.16</cell><cell cols="2">Max 8.28</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table VIII TEST</head><label>VIII</label><figDesc>ERROR RATE [%] OF THE 35 CNNS TRAINED ON MNIST. WXX -WIDTH OF THE CHARACTER IS NORMALIZED TO XX PIXELS.</figDesc><table><row><cell cols="8">Trial W10 W12 W14 W16 W18 W20 ORIG</cell></row><row><cell>1</cell><cell>0.49</cell><cell>0.39</cell><cell>0.40</cell><cell>0.40</cell><cell>0.39</cell><cell>0.36</cell><cell>0.52</cell></row><row><cell>2</cell><cell>0.48</cell><cell>0.45</cell><cell>0.45</cell><cell>0.39</cell><cell>0.50</cell><cell>0.41</cell><cell>0.44</cell></row><row><cell>3</cell><cell>0.59</cell><cell>0.51</cell><cell>0.41</cell><cell>0.41</cell><cell>0.38</cell><cell>0.43</cell><cell>0.40</cell></row><row><cell>4</cell><cell>0.55</cell><cell>0.44</cell><cell>0.42</cell><cell>0.43</cell><cell>0.39</cell><cell>0.50</cell><cell>0.53</cell></row><row><cell>5</cell><cell>0.51</cell><cell>0.39</cell><cell>0.48</cell><cell>0.40</cell><cell>0.36</cell><cell>0.29</cell><cell>0.46</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Committees</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Average 0.27±0.02</cell><cell cols="2">Min 0.17</cell><cell cols="2">Max 0.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>21.41±0.16 30.91 [23] letters* (26) 7.58±0.09 13.00 [24] 13.66 [23] merged (37) 8.21±0.11 uppercase (26) 1.91±0.06 10.00 [24] 6.44 [25] 11.51 [23] lowercase (26)</figDesc><table><row><cell></cell><cell></cell><cell>Table IX</cell><cell></cell><cell></cell></row><row><cell cols="5">AVERAGE ERROR RATES OF COMMITTEES FOR ALL THE EXPERIMENTS,</cell></row><row><cell cols="5">± ONE STANDARD DEVIATION [%], PLUS RESULTS FROM THE</cell></row><row><cell></cell><cell cols="3">LITERATURE.*CASE INSENSITIVE</cell><cell></cell></row><row><cell>Data</cell><cell>Committee</cell><cell></cell><cell>Published results</cell><cell></cell></row><row><cell>MNIST</cell><cell>0.27±0.02</cell><cell>0.40 [10]</cell><cell>0.35 [11]</cell><cell>0.31 [13]</cell></row><row><cell>NIST:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>all (62)</cell><cell>11.88±0.09</cell><cell></cell><cell></cell><cell></cell></row><row><cell>digits (10)</cell><cell>0.81±0.02</cell><cell>5.06 [22]</cell><cell>3.71 [21]</cell><cell>1.88 [19]</cell></row><row><cell>letters (52)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>1520-5363/11 $26.00 © 2011 IEEE DOI 10.1109/ICDAR.2011.229</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This work was partially supported by Swiss CTI, Commission for Technology and Innovation, Project n. 9688.1 IFF: Intelligent Fill in Form and by a FP7-ICT-2009-6 EU Grant under Project Code 270247: A Neuro-dynamic Framework for Cognitive Robotics: Scene Representations, Behavioral Sequences, and Learning.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neocognitron: A self-organizing neural network for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998-11">November 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale learning with svm and convolutional nets for generic object categorization</title>
		<author>
			<persName><forename type="first">F.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition Conference (CVPR&apos;06</title>
		<meeting>Computer Vision and Pattern Recognition Conference (CVPR&apos;06</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Flexible, high performance convolutional neural networks for image classification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A committee of neural networks for traffic sign classification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Natural image denoising with convolutional networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS 2008)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional networks can learn to generate affinity graphs for image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Helmstaedter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Briggman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="511" to="538" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Machine Learning</title>
		<meeting>the 26th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deconvolutional Networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition Conference (CVPR 2010)</title>
		<meeting>Computer Vision and Pattern Recognition Conference (CVPR 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="958" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep big simple neural nets for handwritten digit recognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3207" to="3220" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">NIST special database 19 -Handprinted forms and characters database</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Grother</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Thechnology (NIST), Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a committee of deep neural nets on gpus</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>IDSIA-03- 11</idno>
	</analytic>
	<monogr>
		<title level="j">Istituto Dalle Molle di Studi sull&apos;Intelligenza Artificiale (IDSIA)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="123" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimal linear combination of neural networks for improving classification performance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Mach. Intelli</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="215" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimal linear combination of neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hashem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="599" to="614" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">What is the best multi-stage architecture for object recognition?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision</title>
		<meeting>International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluation of pooling operations in convolutional architectures for object recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimating accurate multi-class probabilities with support vector machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Milgram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Joint Conf. on Neural Networks</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1906" to="1911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic recognition of handwritten numerical strings: a recognition and verification strategy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bortolozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1438" to="1454" />
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Supervised Learning of Fuzzy ARTMAP Neural Networks Through Particle Swarm Optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Henniges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="27" to="60" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using the rrt algorithm to optimize classification systems for handwritten digits and letters</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V W</forename><surname>Radtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM symposium on Applied computing</title>
		<meeting>the 2008 ACM symposium on Applied computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1748" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unconstrained handwritten character recognition using metaclasses of characters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Koerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Kalva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Image Processing</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="542" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An implicit segmentation-based method for recognition of handwritten strings of characters</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Cavalin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Britto</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bortolozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E S</forename><surname>Sabourin</surname></persName>
		</author>
		<author>
			<persName><surname>De Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAC&apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="836" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Overfitting in the selection of classifier ensembles: a comparative study between pso and ga</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sabourin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maupin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th annual conference on Genetic and evolutionary computation</title>
		<meeting>the 10th annual conference on Genetic and evolutionary computation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1423" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ICDAR 2011 chinese handwriting recognition competition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng-Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiu-Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Da-Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Document Analysis and Recognition (ICDAR)</title>
		<meeting>International Conference on Document Analysis and Recognition (ICDAR)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning algorithms for classification: A comparison on handwritten digit recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">A</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sackinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: The Statistical Mechanics Perspective</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Kwon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Cho</surname></persName>
		</editor>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="261" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Machine and human recognition of segmented characters from handwritten words</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kayahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shridhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="866" to="869" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
