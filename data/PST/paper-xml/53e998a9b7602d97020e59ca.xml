<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Optical See-Through Head Mounted Display with Addressable Focal Planes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sheng</forename><surname>Liu</surname></persName>
							<email>sliu@optics.arizona.edu</email>
						</author>
						<author>
							<persName><forename type="first">Dewen</forename><surname>Cheng</surname></persName>
							<email>dcheng@optics.arizona.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Hua</surname></persName>
							<email>hhua@optics.arizona.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Optical Sciences</orgName>
								<orgName type="laboratory">3DVIS Lab</orgName>
								<orgName type="institution">University of Arizona</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>1630 E. University Blvd</addrLine>
									<postCode>85721</postCode>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Optical See-Through Head Mounted Display with Addressable Focal Planes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">42A197E10385555979996CEDED607C69</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Display hardware, head mounted display, accommodation, usability studies and experiments I.3.1 [Computer Graphics]: Hardware Architecture-Three-Dimensional Displays</term>
					<term>H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial, Augmented, and Virtual Realities</term>
					<term>C.4 [Performance of Systems]: Performance Attributes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figure 1. Move clip (VariFocalPlane.wmv) of a virtual torus rendered by the see-through HMD moving along the z-axis in the augmented space. The three subset clips were captured by a camcorder which was manually focused at (a) 16cm, (b) 33cm, and (c) 100cm, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Research interests in 3D displays have endured for decades, spanning the fields of flight simulation, scientific visualization, education and training, tele-manipulation and tele-presence, and entertainment systems. Many approaches to 3D displays have been proposed in the past, including head-mounted displays (HMDs) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b19">21]</ref>, projection-based immersive displays <ref type="bibr" target="#b2">[3]</ref>, volumetric displays <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b3">4]</ref>, and holographic displays <ref type="bibr" target="#b11">[12]</ref>. Among the various 3D display technologies, HMDs provide a good balance on affordability and unique capabilities. For instance, HMDs offer solutions to mobile displays for wearable computing, while in the domain of augmented reality, they are one of the enabling technologies for merging virtual views with physical scenes <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>Despite much significant advancement on stereoscopic HMDs over the past decades, there exist many technical and usability issues preventing the technology from being widely accepted for many demanding applications and daily usage. Many psychophysical and usability studies have suggested the association of various visual artifacts with the long-term usage of stereoscopic HMDs, such as apparent distortion in perceived depth <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">27]</ref>, visual fatigue <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b20">22]</ref>, diplopic vision <ref type="bibr" target="#b24">[26]</ref> and degradation in oculomoter responses <ref type="bibr" target="#b12">[14]</ref>. Although many factors may contribute to those artifacts from the engineering perspective, such as poor image quality, limited eye relief and inappropriate inter-pupillary distance (IPD) setup, one of the underlying causes attributes to the discrepancy between accommodation and convergence <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b24">26]</ref>. Accommodation refers to the focus action of the eye where the shape of the crystalline lens is adjusted to see objects at different depths, while convergence refers to the convergent rotation of the eyes where the visual axis are brought to intersect at a 3D object in space. In a real-world viewing condition, these two oculomotor cues are tightly coupled with each other so that the convergence depth coincides with the accommodation depth. Most existing stereoscopic displays, however, create depth perception based on binocular disparities specifying objects at a range of convergence depths, forcing the accommodation cue to be tied with a fixed focal distance. Contrary to the natural vision, all objects, regardless of their location in depth, are seen in focus if the viewer focuses on the image plane, or all objects are seen blurred if the user's accommodation varies with eye convergence. Many studies have investigated the adverse consequences of the forced decoupling of the two oculomotor depth cues. For instance, Watt et al. suggested that inappropriate focus cues in stereoscopic displays will adversely affect the depth perception, through both direct and indirect means by image blur and disparity scaling <ref type="bibr" target="#b25">[27]</ref>. Such problems may become severe in two common types of viewing conditions: one in which virtual objects need to be presented across a wide range of distances to the user, from very close to far away (e.g. driving simulators); and one in which the display is used to augment a relatively close real-world scene with virtual objects and information (e.g. surgical training). The latter condition is very common in optical see-through stereoscopic displays for augmented reality applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Recently, varifocal and multi-focal plane stereoscopic displays have been proposed <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b13">15]</ref>, aiming to address the accommodation-convergence discrepancy problem. Unlike traditional stereoscopic displays, these approaches enable the addressability of the accommodation cue in a stereoscopic display either by means of dynamic control of the focal distance through an active optical method, or by means of presenting multiple focal planes at equal dioptric spacing with tolerable errors for depth perception. Different from volumetric displays <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b3">4]</ref> in which all voxels within a volumetric space have to be rendered at a flickering-free rate regardless of the viewer's point of interest, these varifocal or multi-focal approaches are relatively more computational efficient, while being able to reduce the discrepancy artifacts to various extents. In general, these approaches can be categorized into time-multiplexed or spatialmultiplexed method.</p><p>In a time-multiplexed approach, the focal distance of a singleplane 2D display device is usually controlled either through a mechanical mechanism or an active optical element for focusing adjustment. For instance, Shiwa et al. achieved accommodation compensation by moving a relay lens in the HMD optical system <ref type="bibr" target="#b21">[23]</ref> and Shibata et al. achieved similar function by axially translating the microdisplay mounted on a micro-controlled stage <ref type="bibr" target="#b22">[24]</ref>. The dynamic control of the focal distance may be achieved by a hand-held device or by the user's eye gaze. These approaches should be more precisely categorized as a varifocal plane method rather than a multi-focal plane display in the sense that they provide dynamic addressability of the focal distance rather than render virtual objects on multi-focal planes at a flickering-free rate. In order to achieve the multi-focal plane capability, these approaches require a fast active optical element to replace the mechanical mechanism for focusing adjustment as well as a 2D display technology with multi-magnitude of faster refresh rate than existing displays. More recently, researchers proposed a seethrough retinal scanning display (RSD) implemented with a deformable membrane mirror (DMM) device <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b19">21]</ref>. In this design, a nearly-collimated laser beam is modulated and scanned across the field of view (FOV) to generate pixels on the retina. In the meantime, correct focusing cues can be rendered on a pixelby-pixel basis by defocusing the laser beam through the DMM. However, in order to achieve a full color and flickering-free multi-focal plane stereo display, the practical development of such technology requires fast addressing speed on both the laser beam and the active optical element for up to MHz. In addition, rendering each pixel by a beam-scanning mechanism limits the compatibility of such system with existing 2D display and rendering techniques.</p><p>In a spatial-multiplexed approach, multi-focal plane capability is achieved by the usage of multiple layers of 2D displays. For instance, Rolland et al. proposed to use a thick microdisplay stack, consisting of 14 layers of equally-spaced (in dioptric spacing) planar displays, to form focal planes in a HMD that divide the whole volumetric space from infinity to 2 diopters <ref type="bibr" target="#b17">[19]</ref>. An optimal separation between two adjacent focal planes turns out to be 1/7 diopters by taking accounts of visual acuity, stereoacuity and pupil size of the human visual system (HVS). Although this approach allows for rendering multiple focal planes in parallel and reduces the speed requirements for the display technology, the practical implementation of such method is challenged by the lack of stack display technologies with high transmittance and by the demand for computational power to simultaneously render a stack of 2D images of a 3D scene based on the geometric depth. Recently, Akeley et al. presented a proof-of-concept display prototype by using a sparse stack of three LCD panels with an equal spacing of 0.67 diopter <ref type="bibr" target="#b0">[1]</ref>. The implementation, however, was impractical to be miniaturized for a portable system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contribution</head><p>In this paper, we propose to develop a compact optical seethrough HMD with addressable focal planes for improved depth perceptions. Inspired by the accommodative capability delivered by the crystalline lens in the HVS, a liquid lens device is implemented into a traditional stereoscopic HMD, enabling addressable accommodation cue from optical infinity to as close as the near point of the eye. Unlike the mechanical focusing methods <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b22">24]</ref> and the RSD design based on a reflective DMM device <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b19">21]</ref>, the transmissive nature of the liquid lens allows for a compact and practical HMD layout, not only without moving components but also without compromising the accommodation range. Based on a proof-of-concept bench prototype, we further explore two types of addressability of the focal distances that the proposed system can deliver: one in a variable single-focal plane mode (see Figure <ref type="figure">1</ref>); the other in a multi-focal plane mode by addressing the liquid lens, together with the microdisplay device, time-sequentially. In comparison to the time-multiplexed RSD approach based on a pixel-by-pixel rendering method <ref type="bibr" target="#b19">[21]</ref>, using a microdisplay device to present multiple full-color 2D images time-sequentially can remarkably decrease the requirement for the addressing speeds of each pixel and of the active optical components, from MHz to 100Hz level. Although the liquid lens used in our current bench prototype has a limited response speed of about 75ms, the new-generation liquid lens has a promising response time less than 10ms, which will make the timemultiplexed multi-focal plane approach more practical. Finally, we also describe two experiments, one subjective and one objective, to measure the accommodation response of the viewer using our bench prototype in the variable focal plane mode. Preliminary results suggest a potential improvement on depth perception in a HMD with addressable focal planes.</p><p>The rest of the paper is organized as follows. In section 2, we briefly describe the schematic design and implementation of the HMD prototype with addressable accommodation cue. In section 3, we investigate two types of addressability on the focal plane of the see-through HMD -one in a variable focal plane mode, the other in a multi-focal plane mode. In section 4, we carry out subjective and objective evaluations to examine the perceived depth and the accommodation response of the HVS versus the addressable accommodation cue. Finally, in section 5, future developments of the proposed system are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SYSTEM SETUP</head><p>To enable the addressability of focal planes in an optical seethrough HMD, we propose to use an active optical elementliquid lens. Based on the electrowetting phenomenon <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">16]</ref>, the liquid lens demonstrates a varying optical power from -5 to 20 diopters by applying an AC voltage from 32 Vrms to 60 Vrms [13]. This anamorphic lens is capable of dynamically controlling the focal distance of a HMD, from infinity to as close as the near point of the eye.</p><p>Based on this simple concept, Figure <ref type="figure" target="#fig_0">2</ref> illustrates a schematic design of an optical see-through HMD with addressable focal planes. The system consists of four major components: a microdisplay, a focusing lens, a beamsplitter (BS), and a spherical mirror. The lens, drawn as a simplified singlet in Figure <ref type="figure" target="#fig_0">2</ref>, is composed of an accommodation lens (e.g. the liquid lens) with varying optical power, A φ , and an objective lens with a constant optical power, O φ . The two lenses together form an intermediate image of the microdisplay on the left side of the spherical mirror. The spherical mirror then relays the intermediate image and redirects the light toward the viewer's eye through the BS. Since the liquid lens is the limiting aperture of the HMD optics, it is placed at the center of curvature (O SM ) of the spherical mirror so that a conjugate exit pupil is formed through the BS. Placing the eye at the conjugate pupil position, the viewer sees both the virtual image of the microdisplay and the real world through the BS. Indicated by the dashed and solid lines, respectively, in Figure <ref type="figure" target="#fig_0">2</ref>, as the accommodation lens changes its optical power from high (I) to low (II), the intermediate image will be displaced towards (I') or away from (II') the focal plane (f SM ) of the spherical mirror. Correspondingly, the virtual image will be formed either far (I'') or close (II'') to the eye. Based on the first-order optics, the accommodation cue, d, of the HMD, which implies the distance from the eye to the virtual image plane, is determined by:</p><formula xml:id="formula_0">φ uR R u + + 2 uR d - =<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">t A O A O φ φ φ φ φ - + =</formula><p>denotes the combined optical power of the focusing lens, t is the separation between the objective and accommodation lenses, u is the object distance from the microdisplay to the focusing lens and R is the radius of curvature of the spherical mirror. All distances above are defined by the sign convention in optical designs <ref type="bibr" target="#b8">[9]</ref>. A detailed derivation of Eq. ( <ref type="formula" target="#formula_0">1</ref>) can be found in the Appendix.</p><p>Based on the schematic design, we implemented a proof-ofconcept monocular bench prototype by using off-the-shelf components, as shown in Figure <ref type="figure" target="#fig_1">3</ref>. The accommodation lens is a liquid lens (Arctic 320, Varioptic Inc.), which has a varying optical power from -5 to 20 diopters by applying an AC voltage from 32 Vrms to 60 Vrms. The liquid lens, with a clear aperture of 3mm, is attached to an off-the-shelf singlet (objective lens) with an 18mm focal length. The image source is a 0.59" full-color organic light emitting diode (OLED) microdisplay with 800×600 pixels and a refresh rate up to 85Hz (eMagin Inc.). The spherical mirror has a radius of curvature of 70mm and a clear aperture of 35mm. Based on those parametric combinations, the monocular bench prototype yields an exit pupil diameter of 3mm, an eye relief of 20mm, a diagonal field of view (FOV) of about 28º, and an angular resolution of 1.7 arcmins if assuming the absence of optical aberrations. The 28° FOV is derived by accounting for the chief ray angle in the image space. Although the FOV, exit pupil diameter and image quality are limited in the current prototype, the major purpose of this work is for a proof-of-concept demonstration and preliminary user studies. Those critical display performances are to be improved in future customized designs.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENT RESULTS</head><p>Indicated by Figure <ref type="figure" target="#fig_2">4</ref>, the addressability of the accommodation cue in the see-through HMD prototype is determined by the ways to address the liquid lens. In this section, we explore two operation modes-variable focal plane and multi-focal plane, in which the proposed system can be operated. In a variable focal plane mode, for example, the voltage applied on the liquid lens can be dynamically adjusted through a user interface to focus the display at different focal distances, from infinity to as close as the near point of the eye. This operation mode meets specific application needs, for instance, to match the accommodation cue of virtual and real objects in mixed and augmented realities.</p><p>Additionally, the focus cues can be pre-programmed to animate a virtual object smoothly moving in a 3D space. In a multi-focal plane mode, the liquid lens may be fast-switched between multiple driving voltages, to provide multiple focal distances, such as I'' and II'' in Figure <ref type="figure" target="#fig_0">2</ref>, time-sequentially. Synchronized with the focal plane switching, the microdisplay is updated accordingly to render virtual objects at distances approximately matching with the accommodation cue of the HMD. The faster the response speed of the liquid lens and the higher the refresh rate of the microdisplay device are, the more focal planes can be presented at a flickering-free rate. As indicated in Figure <ref type="figure" target="#fig_2">4</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Variable focal plane approach</head><p>In order to demonstrate the addressability of focus cues in a variable focal plane mode, we set up three bar-type resolution targets along the visual axis of the HMD as references to the virtual image with variable focus cues. As shown on the left side of each sub-image in Figure <ref type="figure">1</ref>, the three bar targets were placed 16cm (large-size), 33cm (mid-size) and 100cm (small-size), respectively, away from the exit pupil of the HMD (i.e. eye position). The periods of the bar targets are inversely proportional to their distance to the eye, so that the subtended angular resolution of the grating remains constant among all targets.</p><p>In the first example shown in Figure <ref type="figure">1</ref>, a virtual torus was animated in a way that it moves along the visual axis of the HMD at a constant speed from either 16cm to 100cm or vice versa. In synchronization, the voltage applied to the liquid lens was adjusted linearly at a pace matching with the distance of the virtual torus to the eye. By varying the voltage from 38 Vrms to 49 Vrms, the accommodation cue of the HMD is varied correspondingly from 6 diopters to 1 diopter. A digital camcorder (DCR-TRV20 NTSC, SONY) was mounted at the exit pupil location of the HMD to capture demonstration videos. Figures <ref type="figure">1(a</ref> The example above demonstrates the animation of a virtual object with variable accommodation cues. Such passive control of accommodation cues prevents natural user interactions with virtual and real worlds. Figure <ref type="figure" target="#fig_5">5</ref> shows a simple mixed-reality application in a variable focal plane mode. The real scene consists of two real cups, one located at 40cm from the viewer and the other at 100cm away. Focusing the digital camera at 40cm and 100cm, respectively, Figure <ref type="figure" target="#fig_5">5</ref>(a) shows a virtual COKE can clearly rendered at a 40cm depth, while in Figure <ref type="figure" target="#fig_5">5</ref>(c) the can was rendered at a 100cm depth. In comparison, the virtual COKE can appears blurred while the digital camera was focused at 100cm (Figure <ref type="figure" target="#fig_5">5(b)</ref>) and 40cm (Figure <ref type="figure" target="#fig_5">5</ref> (d)), respectively. By applying a voltage at 46 Vrms and 49 Vrms, respectively, the virtual COKE can appears realistically mixed with the real cups at two different depths with correct focusing cues. In this example, while a user interacts with a virtual object, its focusing cue may be dynamically modified to match with its physical distance to the user, yielding a realistic augmentation with a real scene. Such capability may offer accurate depth perceptions in an augmented reality application. The experiment in Section 4 will discuss in detail about the depth perception and accommodative responses in the display prototype.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head><p>Multi-focal plane approach Although the variable focal plane approach demonstrated potential applications in Section 3.1, there are endured research interests to the development of true-3D displays, in which depth perceptions are not limited by a single or a variable focal plane. As discussed in Section 1.1, compared to the volumetric displays, multi-focal plane displays leverage the accuracy on depth perception, the practicability for device implementation and the accessibility to computational resources as well as mainstream graphics rendering techniques. In this section, we explore the feasibility of implementing time-multiplexed multi-focal planes in an optical see-through HMD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Method</head><p>Similar to the RSD system with a variable focus DMM device <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b19">21]</ref>, adopting the liquid lens as an active optical element to control the accommodation cue offers the potential to develop a time-multiplexed multi-focal plane display. However, it is worth noting that there are a few major differences between our approach and the RSD technique. Firstly, we have used a transmissive liquid lens, rather than a reflective DMM device, which enables a compact and practical HMD layout without compromising the range of accommodation cues. Secondly, instead of addressing each pixel by a laser scanning mechanism in the RSD, our approach uses a 2D microdisplay device to present a high-resolution, full-color image time-sequentially to generate multiple focal planes, which remarkably relaxes the requirement for the addressing speed of the display device and the active optical components down to 100Hz level, whereas the pixelsequential rendering approach in a RSD system requires MHz operation speed for both the DMM device and the scanning mechanism of multiple laser beams.</p><p>Starting with the simplest case of a dual focal plane design, the driving signal of the liquid lens and the rendering method of virtual objects, are shown in Figure <ref type="figure" target="#fig_7">6</ref> (a) and (b), respectively. Different from the variable focal plane approach in Section 3.1, the liquid lens is fast-switched between two driving voltages, as shown in Figure <ref type="figure" target="#fig_7">6(a)</ref>. The accommodation cue of the HMD is consequently fast-switched between far and near distances. In synchronization with the driving signal of the liquid lens, far and near virtual objects are rendered on two separate image frames and displayed sequentially, as shown in Figure <ref type="figure" target="#fig_7">6</ref>(b). Apparently, to create a flickering-free appearance of the virtual objects rendered sequentially at two depths, from the hardware perspective, this dual-focal plane method requires not only the microdisplay and graphical card to have a frame rate two-times higher than their regular counterparts, but also the liquid lens with compatible response speed. In general, the maximally achievable frame rate, , of a multi-focal plane display is given by:</p><formula xml:id="formula_2">N f</formula><p>where N is the total number of focal planes and min is the lowest response speed (in Hz) among the microdisplay, the active optical elements, and the graphics card. The waveforms in Figure <ref type="figure" target="#fig_7">6</ref> were drawn under the assumption that all of these elements can operate at ideal speed. (2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Results</head><p>In our prototype implementation, the liquid lens was driven by a square wave switching between 49 Vrms and 38 Vrms, respectively, and the accommodation cue of the HMD was consequently fast-switched between 100cm and 16cm. The period, T , of the driving signal was adjustable in the rendering program. Ideally, T should be set to match the response speed of the slowest device in the system, which determines the frame rate of the dual-focal plane display. For example, if T is set to be 200ms matching the speed ( ) of the slowest device in the system, the speed of the dual focal plane display will be 5Hz and the virtual objects at the two depth ranges will appear alternately. If min f T is set to 20ms (50Hz) faster than the slowest device (e.g. the highest refresh rate of the graphics card is 75 Hz in the current setup), the virtual objects will be rendered at a speed of about . The control unit of the liquid lens device allows for a high-speed operation mode, in which the driving voltage is updated at every 600μs to drive the liquid lens. However, the response speed of the current liquid lens Arctic 320, shown as the red curve with diamond markers in Figure <ref type="figure" target="#fig_10">8</ref>, is in the level of 75ms. The maximum refresh rate of the microdisplay is 85Hz and of the graphics card is 75Hz. Obviously, the liquid lens is the limiting factor on speed in the current prototype.  Along with two video clips, Figures <ref type="figure" target="#fig_9">7(a</ref>) and (b) demonstrate the experimental results of the dual-focal plane display at two different periods, T , of 20ms and 4s, respectively. In both examples, the focus of the camcorder was manually adjusted slowly from 100cm to 16cm. As shown in the video clip 7(a) (Dual-focalPlane20ms.wmv), the two virtual toruses, one rendered at a depth of 100cm and the other at 16cm, appeared simultaneously with noticeable flickering effect, partially due to the relatively low frame rate (75Hz) of the graphics card and the sampling rate of the camcorder (30Hz). However, along with the focus change of the camera, both virtual objects appear to be either in focus or blurred at the same time. The focus cues of the two virtual objects were hardly visible due to the slow response of the liquid lens. The video clip (Dual-focalPlane4s.wmv) in Figure <ref type="figure" target="#fig_9">7</ref> (b) demonstrates the result with T=4s. The two virtual objects appear alternately but with a faithful focus cue in synchronization with the focus setting of the camcorder. This clearly demonstrates the need for much faster display and active optical element to develop practically usable multi-focal plane displays with less flickering effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.3</head><p>Discussions The observation in Figure <ref type="figure" target="#fig_9">7</ref> was confirmed by the measurement of the response speed of the liquid lens currently used in the prototype (Arctic 320). The time response is plotted in Figure <ref type="figure" target="#fig_10">8</ref>, shown as the red curve with diamond markers <ref type="bibr">[13]</ref>. The optical power of the liquid lens was measured on the time scale by a Shark-Hartman wavefront sensor with 5ms temporal resolution. Corresponding to a step function of the driving voltage from 0 to 60 Vrms, the response curve of the Arctic 320 suggests a 74ms rise time to reach 90% of the maximum optical power, which apparently is the slowest device in the current prototype and is insufficient to render the dual-focal plane display at 37.5Hz with faithful accommodation cues. For future developments, specifically on the dual-focal plane see-through HMD with satisfactory frame rates, we examined the hardware requirements for all of the active components being used in the proposed system. Shown on the left column of Table <ref type="table" target="#tab_0">1</ref>, potential limiting factors to the maximum speed of the dual focal planes display are listed, including the liquid lens, the microdisplay and the graphical card. For example, if the liquid lens Arctic 320 is used in the HMD, the maximum achievable frame rate of the dual-focal plane display is only 7Hz. However, the new generation liquid lens, Arctic 314, from Varioptic has promised 5~10 times faster response speed than the Arctic 320 <ref type="bibr">[13]</ref>. As shown by the blue curve with circles in Figure <ref type="figure" target="#fig_10">8</ref>, the new liquid lens module demonstrates a 9ms rise time to reach 90% of its maximum optical power. With this new liquid lens, the highest achievable frequency of the dual focal planes display would be 56Hz, if the lens is the limiting factor of speed in the whole system. This frame rate almost approaches the flickering-free frequency of 60Hz. In future developments, we plan to implement the new liquid lens into the bench prototype for a dual-focal planes optical see-through HMD. We also plan to explore many other technology candidates for the fast switching active optical components, such as a bi-focal liquid crystal lens device.</p><p>The SVGA resolution full color OLED microdisplay currently used in the prototype has a refresh rate up to 85Hz, which can produce dual-focal planes at 42.5Hz in maximum. Other display technologies, such as the digital micromirror device (DMD) and ferroelectric liquid crystal on silicon (FLCOS) displays, should be explored to achieve high refresh rate. Flicker-free frequency 8.4 60</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION EXPERIMENTS</head><p>Numerous usability studies have been conducted on traditional stereoscopic displays with a fixed focal distance <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b4">5]</ref>. One of the widely reported adverse effects by using stereoscopic displays is the depth perception error partially attributed to the conflicting accommodation-convergence cues <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b25">27]</ref>. To better understand how the depth perception is affected by and how the HVS responds to the addressable focal planes in the see-through HMD prototype, we performed two types of experiments: one is a subjective evaluation, in which we explored the perceived depth of the virtual display by a controlled depth judgment task; the other is an objective measurement, in which we quantitatively measured the accommodative response of a user to the virtual target presented at different depths. Both experiments were carried out in a variable focal plane mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Subjective evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Experimental setup and task description</head><p>The major purpose of the subjective evaluation is to understand the relationship of the perceived depth of virtual objects versus the accommodation cue rendered by the active optical method. We devised a depth judgment task to evaluate the perceived depth of a virtual object. In this task, a subject is asked to position a reference real object based on the perceived depth of a virtual object.</p><p>Figure <ref type="figure" target="#fig_11">9</ref> illustrates the schematic setup for the subjective evaluation. The monocular bench prototype described in Section 2 was employed as the testbed. The total FOV of the HMD prototype is divided into top and bottom regions, each of which subtends about 12-degree diagonal FOV. The top region displays a virtual target while a real target covers the bottom part. Because the focus cue is the major visual stimuli in the subjective evaluation, square-wave gratings were chosen as the virtual and real targets: circular gratings as the virtual target and bar gratings for the real one. The real target was mounted on a translational stage and can be moved along the visual axis of the HMD. The accommodation cue of the virtual target, indicated as the distance from the eye to the virtual image display, was controlled by applying three different voltages to the liquid lens: 49 Vrms, 44</p><p>Vrms and 40 Vrms which correspond to accommodation cues of 1 diopter, 3 diopters and 5 diopters, respectively.</p><p>For a virtual target displayed at one of the three depths, the experimenter helps the subject to move the real target back and forth along the visual axis until the subject determines that they appear to be at the same depth. For better accuracy, once the initial depth judgment was made, the subject made fine depth judgment by repeatedly moving the real target from the previous judgment position backward and forward at the decreasing amount of increment until the incremental step was small enough. The final position of the real target was recorded as the perceived depth of the virtual target. A good match between the perceived depth and the actual accommodation cue rendered by the liquid lens will suggest a realistic depth perception of the virtual object. During the experiment, the subject positions his or her head on a chin rest and only views the targets through one eye with the other eye covered to eliminate other depth cues rather than the accommodation cue we are interested in.</p><p>Five subjects with either normal vision or corrected vision were recruited, with 1 female and 4 males. The average age of the subjects is 28. Each subject performed three depth judgment trials. The virtual targets were presented in a random order from the three accommodation cues. Before starting the experiment, the experimenter explained each subject the experiment procedure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Results</head><p>Figure <ref type="figure" target="#fig_12">10</ref> plots the relationship between perceived depth of the virtual target and the accommodation cue rendered by the liquid lens. As the accommodation cue varies, shown as 1 diopter, 3 diopters and 5 diopters along the x-axis, the average perceived depth among the 5 subjects is 1.1 diopter, 2.9 diopters and 5.2 diopters, respectively, shown as blue diamonds in Figure <ref type="figure" target="#fig_12">10</ref>. The standard deviation of the perceived depths at the three accommodation cue conditions are 0.1 diopter, 0.4 diopter, and 1.3 diopters, respectively. The error bars in Figure <ref type="figure" target="#fig_12">10</ref> indicate the minimum and maximum readings of the perceived depths among all subjects. Overall, the average values of the perceived depths match well with the rendered accommodation cues. This preliminary result suggests a potentially improved depth perception by appropriately rendering accommodation cues in a HMD with addressable focal planes, by comparing to the usability studies on traditional stereoscopic displays which have suggested distorted and compressed perceived depths by solely rendering binocular disparity cue <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b24">26]</ref>, The errors in the user evaluation may be explained by many contributing factors, such as image aberrations, ambient noise, and subject's fatigue level. Similar results were also reported on a user experiment with an addressable focal plane HMD in which the addressable focal plane was achieved by the active DMM device <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b19">21]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Objective measurement</head><p>The major purpose of the objective evaluation is to quantify accommodative response of the HVS to the depth cues presented through our display prototype. In this experiment, the accommodative responses of the eye were measured by a nearinfrared (NIR) auto-refractor (RM-8000B, Topcon). The autorefractor has a measurement range of the refractive power from to 20 diopters and a measurement speed of about 2s. The eye relief of the auto-refractor is about 50mm. In the objective measurement, the auto-refractor was placed right in front of the BS, so that the exit pupil of the auto-refractor coincides with that of the see-through HMD prototype. Throughout the data acquisition procedure, the ambient lights were turned off to prevent their influences on accommodation responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="20">-</head><p>During the test, a subject with normal vision was asked to focus on the virtual display, which was presented at 1 diopter, 3 diopters and 5 diopters, respectively, in a three-trial test. At each trial, after the subject set his or her focus on the virtual display, the accommodative response of the subject's eye was recorded at every 2s for up to 9 measurement points. The results for one subject were plotted in Figure <ref type="figure" target="#fig_13">11</ref> for the three trials corresponding to three focal distance of the virtual display and the data points were shown as three sets of blue diamonds. The red solid lines in Figure <ref type="figure" target="#fig_13">11</ref> correspond to the accommodation cues rendered by the liquid lens. Although the measured accommodative response of the user fluctuates with time, the average value of the 9 measurements in each trial is 0.97 diopters, 2.95 diopters, and 5.38 diopters, with standard deviations of 0.33 diopters, 0.33 diopters and 0.42 diopters, respectively. The averages of the accommodative responses of the user match well with the accommodation cues stimuli presented by the see-through HMD prototype.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Although accommodation response may be caused by a variety of visual stimuli, such as convergence, brightness and spatial frequency, the major observations in the experiments described above are elicited mostly by the accommodation cue of the virtual display, by simply controlling the position of the focal plane in the monocular prototype without rendering other types of visual stimuli. The preliminary results from both the subjective and objective evaluations in this paper suggest that in a variable focal plane HMD, a user can yield appropriate accommodative responses to the variable accommodation cue and the perceived depths can match well with rendered accommodation cues. Referring to the variable focal plane method in Section 3.1, the proposed HMD prototype can potentially yield realistic rendering of virtual objects throughout an augmented space by presenting extra accommodation cue in traditional stereoscopic displays. Referring to the multi-focal plane method in Section 3.2, the development of the prototype based on a faster liquid lens would possibly allow for decreased discrepancy between accommodation and convergence.</p><p>There have been increasing research interests to study characteristics of accommodation response in stereoscopic displays <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b25">27]</ref>. The addressable focal plane HMDs can be applicable to such human factor studies, whenever dynamic manipulation of the focus cues is desired. As an example, convergence induced accommodation has been broadly explored in traditional stereoscopic displays. Due to the lack of providing accommodation cues in traditional stereoscopic displays, however, accommodation induced convergence has not been well studied and understood. An addressable focal plane HMD can offer opportunities for such psychophysical studies to better understand the underlying mechanism of stereoscopic vision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORK</head><p>In this paper, we presented the design of a bench prototype for an optical see-through HMD with addressable focal planes, enabled by a liquid lens device. The accommodation cues in a proof-of concept bench prototype can be rendered, from optical infinity to as close as the near point of the eye, either in a variable focal plane mode or in a multi-focal plane manner. The applicability of the variable focal plane approach was validated by two mixedreality examples. We also examined the hardware requirements for the development of a flickering-free dual-focal plane seethrough HMD. Finally, we reported two experiments to evaluate the perceived depth and the accommodative responses of the eye as the accommodation cue is varied in the display prototype. The preliminary results from both evaluations suggest that in a variable focal plane HMD, a user can yield appropriate accommodative responses to the variable accommodation cue and the perceived depths can match well with rendered accommodation cues. Addressable focal planes in an optical see-through HMD enable numerous possibilities for future research. From a technology development perspective, we will explore many candidate technologies, such as high refresh rate DMD or FLCOS displays as well as high speed liquid lens or liquid crystal lens to develop a multi-focal plane display at flickering-free rate. From the usability perspective, we will use the addressable focal plane HMD for various human factor studies, such as to explore accommodation induced convergence in stereoscopic displays. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Schematics of an optical see-through HMD with addressable focal planes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Monocular bench prototype of an optical see-through HMD with addressable focal planes. Inset: the liquid lens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 (</head><label>4</label><figDesc>Figure 4 (a) plots the optical power of the liquid lens device as a function of applied voltages. The curve is simulated by importing specifications of the liquid lens under different driving voltages in an optical design software-CODE V [28]. Two examples are shown in Figure 4 (a): at 38Vrms of applied voltage, the liquid lens produces 0 diopter of optical power indicated by the flat shape of the liquid interface; while at 49Vrms the liquid lens delivers 10.5 diopters of optical power indicated by the strongly curved liquid interface.Based on the parametric selections in the bench prototype and Eq. (1), Figure4(b) plots the accommodation cue of the HMD as a function of the applied voltage on the liquid lens. Labeled by two solid triangle markers in Figure4(b), driving the liquid lens at 38 Vrms and 49 Vrms corresponds to accommodation cues at 6 diopters and 1 diopter, respectively. Driving the liquid lens from 32 Vrms to 51 Vrms will enable the accommodation cue of the HMD prototype from 12.5cm (8 diopters) to infinity (0 diopter) correspondingly, covering almost the whole accommodative range of the HVS<ref type="bibr" target="#b23">[25]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. (a) Optical power of the liquid lens and (b) accommodation cue of the HMD prototype versus the applied voltage on the liquid lens.</figDesc><graphic coords="4,330.06,356.99,203.46,150.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Two real cups, one at 40cm and the other at 100cm away from the eye, are realistically augmented with a virtual COKE can rendered at two different depths: (a)-(b) 40cm; and (c)-(d) 100cm. The digital camera was focused at (a), (d) 40cm and (b), (c) 100cm, respectively.</figDesc><graphic coords="4,330.24,508.98,202.56,149.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>) through 1(c) show three frames with the camcorder focusing on the resolution targets located at 16cm, 33cm and 100cm, respectively. A movie clip (VariFocalPlane.wmv) consisted of three sub-clips are also presented. For example, comparing the sub-clips (a), (b) and (c) at the same time, the virtual torus in clip (a) only appears in focus when the applied voltage on the liquid lens is 38rms, since the camcorder in clip (a) was constantly focused at 16cm (6 diopters) distance. Similarly, the torus in clip (b) and (c) only appears in focus when the driving voltage is 45 Vrms and 49Vrms, respectively. The images and the video clearly demonstrate the change of accommodation cue of the virtual object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>fFigure 6 .</head><label>6</label><figDesc>Figure 6. Driving mechanism of the liquid lens and rendering of virtual objects to produce a dual-focal plane display.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Two toruses at different depths are rendered sequentially by the dual-focal plane HMD prototype at a frame rate of (a) 37.5Hz (Dual-focalPlane20ms.wmv) and (b) 0.25Hz (Dual-focalPlane4s.wmv).</figDesc><graphic coords="6,103.56,433.50,140.88,105.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Time response of the liquid lens: module Arctic 320 and module Arctic 314.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Schematic illustration of the subjective evaluation experiment.</figDesc><graphic coords="7,348.66,303.96,178.50,125.40" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Subjective evaluation results of the perceived depth of the virtual display versus the accommodation cue rendered by the liquid lens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Objective measurements of the accommodative responses to the accommodation cues presented by the seethrough HMD prototype.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Unfolded optical path of the HMD schematics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,82.74,162.78,446.52,118.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Hardware evaluations for the development of a dual focal plane stereoscopic display.</figDesc><table><row><cell>Limiting factor</cell><cell>Hardware speed</cell><cell>Maximum speed</cell></row><row><cell></cell><cell>(ms)</cell><cell>of the dual focal</cell></row><row><cell></cell><cell></cell><cell>planes display</cell></row><row><cell></cell><cell></cell><cell>(Hz)</cell></row><row><cell>Liquid Lens, Arctic 320</cell><cell>74</cell><cell>7</cell></row><row><cell>Graphics Card, 75Hz</cell><cell>13.3</cell><cell>37.5</cell></row><row><cell>OLED Microdisplay, 85Hz</cell><cell>11.8</cell><cell>42.5</cell></row><row><cell>Liquid Lens, Arctic 314</cell><cell>9</cell><cell>56</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>We would like to thank Professor Jim Schwiegerling for providing the auto-refractor used in our evaluation experiment. This work was partially funded by the National Science Foundation grant 0534777 and the TRIF Imaging Fellowship of the University of Arizona.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: DERIVATION OF EQUATION 1</head><p>Furthermore, the intermediate image I' becomes the object for the spherical mirror with the object distance v given by:</p><p>After the reflection by the spherical mirror, the virtual image I'' is formed at distance v' to the vertex of the spherical mirror given by:</p><p>Finally, the accommodation cue, d (assuming d&gt;0), is obtained as:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A stereo display prototype with multiple focal distances</title>
		<author>
			<persName><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Watt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;04</title>
		<editor>
			<persName><forename type="first">Joe</forename><surname>Marks</surname></persName>
		</editor>
		<meeting>SIGGRAPH &apos;04<address><addrLine>Los Angles, California</addrLine></address></meeting>
		<imprint>
			<publisher>ACM SIGGRAPH, ACM Press</publisher>
			<date type="published" when="2004-09-14">August 08-14, 2004. September 2004</date>
			<biblScope unit="page" from="804" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recent advances in augmented reality</title>
		<author>
			<persName><forename type="first">R</forename><surname>Azuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Baillot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Behringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Julier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macintyre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="34" to="47" />
			<date type="published" when="2001-12">Nov/Dec 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Surround-screen projection-based virtual reality: the design and implementation of the CAVE</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cruz-Neira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sandin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Defanti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 20th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<publisher>ACM SIGGRAPH, ACM Press</publisher>
			<date type="published" when="1993-09">September 1993</date>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A threecolor, solid-state, three-dimensional display</title>
		<author>
			<persName><forename type="first">E</forename><surname>Downing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ralston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Macfarlane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="1185" to="1189" />
			<date type="published" when="1996-08">August 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Accommodation to large disparity stereograms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E G</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A A</forename><surname>Brennand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Frisby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of AAPOS</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="377" to="384" />
			<date type="published" when="2002-12">Dec 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visual accomodation problems with head-up and helmet-mounted displays</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Edgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C D</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Craig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Displays</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="68" to="75" />
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">100 million-voxel volumetric display</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Favalora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Napoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Dorval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Giovinco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Richmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Chun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2002-08">August 2002</date>
			<biblScope unit="volume">4712</biblScope>
			<biblScope unit="page" from="300" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Liquid lenses make a splash</title>
		<author>
			<persName><forename type="first">D</forename><surname>Graham-Rowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature-Photonics</title>
		<imprint>
			<date type="published" when="2006-02-04">September: 2-4, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Greivenkamp</surname></persName>
		</author>
		<title level="m">Field guide to geometrical optics</title>
		<meeting><address><addrLine>Bellingham, WA</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Merging the Worlds of Atoms and Bits: Augmented Virtual Environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics and Photonics News</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="26" to="33" />
			<date type="published" when="2006-10">October 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Design of a bright polarized head-mounted projection display</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="2600" to="2610" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Volume Holographic Storage and Retrieval of Digital Data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Heanue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="749" to="752" />
			<date type="published" when="1994-08">August 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Accommodative responses to stereoscopic three-dimensional display</title>
		<author>
			<persName><forename type="first">T</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ohzu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="4509" to="4515" />
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A method for reproducing apparent continuous depth in a stereoscopic display using &quot;Depth-Fused 3D&quot; technology</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kuribayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Date</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hatada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Information Display</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="493" to="498" />
			<date type="published" when="2006-05">May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Variable-focus liquid lens for miniature cameras</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kuiper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H W</forename><surname>Hendriks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Physics Letters</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1128" to="1130" />
			<date type="published" when="2004-08">August 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Binocular vision in a virtual world : visual deficits following the wearing of a headmounted display</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mon-Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rushton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmic Physiol. Opt</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="387" to="391" />
			<date type="published" when="1993-10">October 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A retinal scanning display system that produces multiple focal planes with a deformable membrane mirror</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Mcquaide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Seibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Schowengerdt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A A</forename><surname>Furness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Displays</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="65" to="72" />
			<date type="published" when="2003-08">August 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multifocal planes headmounted displays</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Rolland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="3209" to="3215" />
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A solid-state multi-planar volumetric display</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SID Symposium Digest of Technical Papers</title>
		<imprint>
			<date type="published" when="2003-05">May 2003</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1531" to="1533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">True 3-D scanned voxel displays using single or multiple light sources</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Schowengerdt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Seibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Soc. Info. Display</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="135" to="143" />
			<date type="published" when="2006-02">February 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Performance and comfort on near-eye computer displays</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sheedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bergstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optometry and Vision Science</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="306" to="312" />
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Proposal for a 3-D display with accommodative compensation: 3DDAC</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shiwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Omura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kishino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Information Display</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="255" to="261" />
			<date type="published" when="1996-12">December 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Stereoscopic 3-D display with optical correction for the reduction of the discrepancy between accommodation and convergence</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kawai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Otsuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Miyake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yoshihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Iwasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Information Display</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="665" to="671" />
			<date type="published" when="2005-08">August 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Foundations of Vision</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Wandell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Sinauer Associates Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Natural problems for stereoscopic depth perception in virtual environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rushton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mon-Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2731" to="2736" />
			<date type="published" when="1995-10">October 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Focus cues affect perceived depth</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Watt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vision</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="834" to="862" />
			<date type="published" when="2005-12">December 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
