<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Intelligent fault diagnosis of rolling bearings based on normalized CNN considering data imbalance and variable working conditions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bo</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Xianmin</forename><surname>Zhang</surname></persName>
							<email>zhangxm@scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hai</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhuobo</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Mechanical and Automotive Engineering</orgName>
								<orgName type="laboratory">Guangdong Key Laboratory of Precision Equipment and Manufacturing Technology</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Intelligent fault diagnosis of rolling bearings based on normalized CNN considering data imbalance and variable working conditions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9ACBB56E290A5D1A353A2FDCE916D345</idno>
					<idno type="DOI">10.1016/j.knosys.2020.105971</idno>
					<note type="submission">Received date : 26 November 2019 Revised date : 22 April 2020 Accepted date : 23 April 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Knowledge-Based Systems rolling bearing</term>
					<term>fault diagnosis</term>
					<term>convolutional neural network</term>
					<term>deep learning</term>
					<term>data imbalance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the rapid development of intelligent manufacturing, the intelligence and integration of equipments in modern industries are enhancing. The condition monitoring and fault diagnosis have gradually become important strategies to ensure the safety and reliability of equipments. As one of the most widely deployed mechanical equipment in industrial applications <ref type="bibr" target="#b0">[1]</ref>, the efficient and stable operation of rotating machinery has received much attention. Rolling bearings, which performances directly affect the stability and reliability of equipments, are one of the most critical support components in rotating machinery, such as motors, wind turbines and gearboxes. However, in real industries, it is common to face that the number of fault data especially catastrophic fault data or accidental mechanical failure is very small and the equipments frequently change the working conditions according to the production, resulting in data imbalance and inconsistent distribution <ref type="bibr" target="#b1">[2]</ref>. Therefore, how to stably and accurately diagnose the conditions of the rolling bearings under data imbalance and variable working conditions has become a hotspot among many bearing kinds of researches.</p><p>In the past years, a large number of effective fault diagnosis methods have been proposed based on two strategies: signal processing <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> and intelligent diagnosis <ref type="bibr" target="#b4">[5]</ref>. Signal processing has been proved to be an effective method for feature extraction, such as empirical mode decomposition <ref type="bibr" target="#b5">[6]</ref> and wavelet decomposition <ref type="bibr" target="#b6">[7]</ref>. However, signal processing based methods rely heavily on expert experience and prior knowledge. This means that the quality of the fault diagnosis model is largely influenced by human factors and it is unavailable in the practical mechanical systems with complex working conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Journal Pre-proof</head><p>Recently, with the development of sensors and computers, many intelligent diagnostic models based on the data-driven have received increasing attention from researchers and engineers <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. Compared with the signal processing, the intelligent diagnosis method can adaptively mine the fault information hidden in the measured data, such as vibration signal, which is widely collected and used as one of the typical equipment signals <ref type="bibr" target="#b9">[10]</ref>. It can be further subdivided into two categories: traditional machine learning (ML) models and deep learning (DL) models. The methods, which belong to ML, such as support vector machine (SVM) <ref type="bibr" target="#b10">[11]</ref>, principal component analysis (PCA) <ref type="bibr" target="#b11">[12]</ref> and artificial neural network (ANN) <ref type="bibr" target="#b12">[13]</ref>, have been widely adopted for fault diagnosis and condition monitoring of rolling bearings and have achieved some meaningful results. However, some of the deficiencies inherent in the traditional ML model are that it is difficult to extract deep features from raw data and process massive amounts of data.</p><p>To address the above problems and improve the learning ability of the intelligent models, DL technology, which is first proposed by Hinton in 2006 <ref type="bibr" target="#b13">[14]</ref>, has gained more and more attention because it can automatically learn the deep representative features from the raw data.</p><p>Several structures of DL models, such as deep auto-encoder (DAE), deep belief network (DBN), convolutional neural network (CNN) and recurrent neural network (RNN), are constructed and widely employed in the mechanical fields <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref>. Wang et al. <ref type="bibr" target="#b18">[19]</ref> achieved the improvement of model performance by introducing the kernel function into the DAE and applied it to the rolling bearing fault diagnosis. Shao et al. <ref type="bibr" target="#b19">[20]</ref> proposed a novel method called ensemble DAEs, which was used for intelligent fault diagnosis of rolling bearing and this model was established based on different DAEs with the 15 activation functions, the results showed that it could significantly improve accuracy and robustness. Chen et al. <ref type="bibr" target="#b20">[21]</ref> used multiple DAE models to implement feature extraction of different sensors and further fusion based on the DBN model. DBN is a probability generation model, and it is stacked by J o u r n a l P r e -p r o o f Journal Pre-proof multiple restricted Boltzmann machines. Based on the DBN model, Oh et al. <ref type="bibr" target="#b22">[22]</ref> proposed a vibration imaging-and deep learning-based approach for rotor system diagnosis, in which the incorporates data from a small-scale testbed and real field system. An intelligent and integrated approach based on impulsive signals, DBN and feature uniformities are constructed by Wang et al. <ref type="bibr" target="#b23">[23]</ref>, and the results show that this method can achieve real-time fault diagnosis and reduce the interference of loads. Shao et al. <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25]</ref> proposed an improved convolutional deep belief network combining DBN and CNN to diagnose the faults and the results are better than that by the standard DBN, DAE and CNN. Above all, it can be seen that fully-connected networks such as DAE, DBN and RNN are widely used in rolling bearing fault diagnosis, and some meaningful results have been obtained. However, the training process of the DAE and DBN models is complicated and time consuming, which caused by the pre-training in models. As another branch of deep learning models. CNN, which is inspired by the concept of simple and complex cells in visual cortex in brain, is a special feedforward neural network. And three key techniques are applied to the CNN: 1) sparse connectivity, 2) shared weights, 3) pooling. These characteristics greatly reduce the number of parameters that needs to be trained <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b27">27]</ref>. Based on the special structure and advantages of CNN, Zhang et al. <ref type="bibr" target="#b28">[28]</ref> proposed a domain adaptive CNN model, which can solve the problem of fault diagnosis using different distributed datasets. Huang et al. <ref type="bibr" target="#b29">[29]</ref> proposed a novel decoupling CNN model for intelligent compound fault diagnosis, the results show that it can effectively identify the compound fault. And more and more improved CNN models are used for fault diagnosis, such as CNN with capsule network <ref type="bibr" target="#b30">[30]</ref> and dilated CNN <ref type="bibr" target="#b31">[31]</ref>.</p><p>In the above studies, although various special models for fault diagnosis of rolling bearings are established and performed well, there are still many challenges. It is worth noting that traditional deep learning based models require a large number of high-quality samples to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof participate in training to ensure the performance, and most of the existing research is established with the assumption of same distribution. However, it is not in accord with real task situations, the phenomenon of data imbalance, which widely exists in various fields <ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref>, is widespread because the number of fault samples is small and it is time-consuming and expensive to construct sufficient fault samples. Moreover, the collected data are influenced by many factors, such as variable working conditions, vibration, environment noise and so on. To achieve stable diagnostic performance, Zhou et al. <ref type="bibr" target="#b35">[35]</ref> proposed a novel approach called global optimization generative adversarial network (GOGAN), which was adopted to address the scenario of unbalanced samples. An auto-encoder based generator, which is used to expand the unbalanced sample set, and a two-hierarchical discriminator are established, respectively. And the global optimization strategy is adopted for model updating.</p><p>the results showed that the performances of the proposed GPGAN are significantly superior to other comparison methods. Bi et al. <ref type="bibr" target="#b36">[36]</ref> conducted a very comprehensive review of the latest classification algorithm of multi-class unbalanced data and proposed a novel multi-class unbalanced classification algorithm, called diversified error correcting output codes (DECOC).</p><p>The performances of DECOC was verified based on nineteen public datasets. In addition, based on the ensemble approach described in Ref. <ref type="bibr" target="#b19">[20]</ref>, the stability of the mentioned method with different unbalance rates is illustrated.</p><p>Based on the inspiration of the above researches, this paper proposed a normalized CNN for the rolling bearings diagnosis of different fault severities and orientations under the scenarios of data imbalance and variable working conditions. And the procedures of the proposed method can be summarized as follows. First, the batch normalization is adopted as a novel application to eliminate feature distribution difference, which is a prerequisite for ensuring generalization ability under different working conditions, and to obtain stable feature distribution. Then, the proposed method is trained based on exponential decay learning rate J o u r n a l P r e -p r o o f Journal Pre-proof and exponential moving average algorithm to improve overall performance. Finally, the proposed model is applied to the fault diagnosis under other working conditions and unbalanced data. The aim of this paper is to establish a low complexity but efficient intelligent fault diagnosis method, which can better suppress noise in raw data and has excellent performances under different working conditions and unbalanced datasets.</p><p>The rest of the paper is organized as follows: In the upcoming section, the theories of CNN and BN are introduced. In Section 3.1, the framework of normalized CNN model is described. Section 3.2 shows the general procedure of the proposed method. Three cases are presented to validate the method and analyze the effectiveness of the method in Section 4.</p><p>Finally, some conclusions are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Theoretical background</head><p>In this section, the basic theories and characteristics of CNN model and BN technology are introduced. First, the topology structure and key technologies of CNN model are described in detail. Then, the principle and training process of BN technology are also introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Convolutional neural network (CNN)</head><p>CNN, which is inspired by the principle of cell perception in the visual cortex of the brain, is first proposed by LeCun for image processing <ref type="bibr" target="#b26">[26]</ref>. As another branch of deep learning models, it has a specific structure compared with other fully connected deep neural networks (DNN). Three main attributes are contained in this model: 1) sparse connectivity; 2) shared weights; 3) pooling. The sparse connectivity is mainly through the perception of the local region in the data to discover some local features. The shared weights mean that the parameters in each group of receptive fields are shared. In other words, the convolutional filter on the same perceptual channel is the same, and this can significantly reduce the number J o u r n a l P r e -p r o o f Journal Pre-proof of parameters that need to be optimized.</p><p>Based on the translation-invariant characteristic, CNN has achieved remarkable success in many research and industry fields including computer vision, natural language processing, speech recognition and so forth. And more and more variants of the CNN model are constructed and employed, which together form a large model library that contains many well-known models, such as LeNet-5, AlexNet, VGGNet, GoogLeNet, 1-D CNN and so on.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Convolutional layer</head><p>The main function of the convolutional layer is to obtain the feature maps through a series of convolutional operations of the filters on the input. The convolutional layer is usually composed of a set of learnable kernels and bias. The kernel size corresponds to the length of J o u r n a l P r e -p r o o f Journal Pre-proof the filter window and kernel depth corresponds to the number of map channels. The input of neurons in the convolutional layer can be obtained by calculating the dot product between the weight and the perceived region, which can be expressed as follows:</p><formula xml:id="formula_0">conv pool , , 1, 1 k ll l j i j l i j i y w y b      <label>(1)</label></formula><p>where  represents the activation function in the fully connected layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Batch normalization (BN)</head><p>Generally, with the deepening of the neural network structure, the distribution of its features changes, and overall distribution gradually approaches the two ends of the nonlinear</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof function value interval. This phenomenon is called gradient diffusion, which causes model convergence difficulties. In order to overcome this problem, BN technology, which is different from the input standardization, is proposed by Google's DeepMind team in 2014 <ref type="bibr" target="#b37">[37]</ref>.</p><p>The essence of BN technology is to pull the distribution of any neuron back to the standard normal distribution by a certain normalization method. BN can elegantly reparametrize almost any DNN, and it can be employed in any hidden layer. As a technology to optimize a neural network, its application can improve the performance of the DNN, such as faster convergence, shorter learning time, ability to tolerate higher learning rate and easier initialization of weights. Moreover, the efficiency of applying BN in other DL-based models has attracted increasing attention. Wang et al. <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b37">37]</ref> proposed a fast intelligent fault diagnosis method by introducing BN into other DL-based models, the beneficial effects of BN technology on the improvement of model efficiency have been studied from different levels.</p><p>And the effectiveness under variable working conditions is illustrated by training the model from scratch. Therefore, BN technology is also effective to be introduced into other DL-based models. For the hidden layer with n-dimensional input x = (x 1 … x n ), to reduce the internal covariate shift, two main simplifications are adopted in BN.</p><p>Firstly, normalization is completed by making each individual scalar feature with zero mean and unit variance, which can be expressed as follows:</p><formula xml:id="formula_1">  ˆE Var i i i i x x x x         <label>(5)</label></formula><p>However, the learned features can be affected when the features of a certain layer are normalized directly using the above formula, which leads to a decline in the ability of the network expression. In order to deal with this problem, each normalized value x i is modified based on two adjustment parameters i  and i  , which aims to scale and shift the normalized value. This process can be expressed as follows:</p><p>J o u r n a l P r e -p r o o f Journal Pre-proof</p><formula xml:id="formula_2">î i i fx  <label>(6)</label></formula><p>The 1</p><formula xml:id="formula_3">1 E B p p xx B       (7)   2 1 1 Var E B p p x x x B             (8)   ˆE Var pp x x x x              (9) ˆpp yx   (<label>10</label></formula><formula xml:id="formula_4">)</formula><p>where ε is a constant, which is imposed to avoid meeting with the undefined gradient.</p><p>It can be seen from the above expressions, the transformation process can be divided into  where the model has excellent performance. Thus, BN is adopted in this paper to optimize model and eliminate distribution difference, so as to ensure the performance of the model under unbalanced data and variable working conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The proposed method</head><p>In this section, the construction of normalized CNN model is proposed to achieve an intelligent fault diagnosis of rolling bearings under different working conditions and unbalanced datasets. Firstly, the framework of the proposed method is described to complete offline training, in which exponential decay learning rate and exponential moving average are employed to improve the model performance. Secondly, the overall framework and innovations of the model are introduced. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, the proposed model consists of two convolutional layers and two pooling layers in stage 1, which labeled C1, P1, C2, P2, respectively. The input is a 1-D sample with a size of 400 sampling points. Subsequently, the first convolutional operation is applied to the input, and features in C1 with the size of 3@376×1 can be obtained, where 3 represents three convolutional channels and the feature size of each channel is 376×1 under the condition that the size of the convolutional kernel is 25×1. It is worth noting that environmental noise and random interference are always unavoidable introduced into the raw signal, which significantly deteriorate the model performance. To overcome the above difficulties, the wide kernel is first designed in the first convolutional layer to better suppress noise and capture useful information <ref type="bibr" target="#b38">[38]</ref>. Then, pooling operation is used to subsampling according to Eq. ( <ref type="formula">3</ref>), and the pooling features are acquired, in which the size is 3@317×1 with the pooling kernel size is 8×1. Since subsampling does not change the distribution of features, the BN layer is only employed after two convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Proposed framework</head><p>Through a series of convolutional and pooling layers, the deep features learned in P2 are rearranged and labeled F. Then, the features are further mapped in stage 2, which consists of two hidden layers, labeled H1 and H2, and a softmax classifier. And the weights of the two hidden layers are determined by the subsequent exponential moving average.</p><p>Suppose that there has a training dataset    </p><formula xml:id="formula_5">( ) ( ) 1 , B ss s X label  including B training samples.</formula><p>And the forward feature of each sample, which is denoted as</p><formula xml:id="formula_6">  () ,</formula><p>s wb hX, are extracted on the H2 layer through a series of forward propagations. In order to get the predicted output of the model, the softmax function is used to transform the logits of the neurons to conform the form of probability distribution for different rolling bearing fault severities. The transform process can be expressed as follows: where  is parameter of the softmax function, k represents the class. Subsequently, based on the difference between the predicted output and the true category, the loss function is determined by the cross entropy, which can be calculated as follows:</p><formula xml:id="formula_7">J o u r n a l P r e -p r o o f Journal Pre-proof                                         1,<label>2, , , , , , 1 , ( 1| ; ) ( 2 |</label></formula><formula xml:id="formula_8">            ( ) ( ) ,, 1 1 , log( ( )) 1 log(1 ( )) 2 B ss ss w b w b s J w b label h h X label h h X L B            (12)</formula><p>where L2 represents the regularization item, its function is to reduce overfitting and it can be expressed as follows:</p><formula xml:id="formula_9">  11 2 , 1 1 1 2= 2 l l l n s s l ij l j i Lw       (<label>13</label></formula><formula xml:id="formula_10">)</formula><p>where λ is a regularization factor, , l ij w represents the connection weight between the ith neuron of the l layer and the jth neuron of the l+1 layer.</p><p>In the architecture of normalized CNN, the weights and biases can be optimized by minimizing the Eq. ( <ref type="formula" target="#formula_16">12</ref>), the stochastic gradient decent optimization algorithm is applied <ref type="bibr" target="#b39">[39]</ref>.</p><p>And the weight , l ij w can be updated based on the BP algorithm as follows:</p><formula xml:id="formula_11">      ,, ,<label>( , )( )</label></formula><formula xml:id="formula_12">1 ll l i j i j ij J w b n w n w n wn      <label>(14)</label></formula><p>In the model training process, the learning rate is usually used to control the magnitude of the parameter update in the gradient descent. Although a smaller learning rate can ultimately result in a smaller loss value, the optimization speed of the model is greatly reduced.</p><p>Conversely, it may cause the parameter to exhibit a wobble phenomenon. Thus, in order to match the learning rate with the training process, an exponential decay learning rate is employed in the proposed method. Its remarkable characteristic is that it can achieve fast The exponential moving average model maintains the shadow variable of each parameter.</p><p>The initial value of this shadow variable is the initial value of the corresponding parameter. If the parameter changes, the value of the shadow variable is also updated, which can be expressed as follows:</p><p>  </p><formula xml:id="formula_13">     <label>(17)</label></formula><p>where decay_init represents the initial value of decay, num_updates is used to limit the size of decay.</p><p>Generally, based on the smaller num_updates, a faster update speed of shadow variable can be obtained. In contrast, decay_init is always employed during the model training. In order to achieve the adaptation of the decay coefficient in the exponential moving average</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof model, the parameter num_updates is set to the current number of iterations in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">General procedure of the proposed method</head><p>In this paper, an intelligent fault diagnosis method of rolling bearings under different working conditions and unbalanced datasets is proposed based on normalized CNN. The flowchart of the proposed method is shown in Fig. <ref type="figure" target="#fig_8">4</ref>. The general procedures are summarized as follows:</p><p>Step 1: Collect the vibration signals of rolling bearing with acquisition device.</p><p>Step 2: The raw vibration data is divided into the training samples and the testing samples separately by resampling.</p><p>Step 3: The proposed method mentioned in Section 3.1 is adopted to extract deep features from the training samples based on convolutional operations and pooling operations.</p><p>Step 4: The learned deep features are fed into the fully-connected forward network to achieve nonlinear transformation, in which exponential moving average is employed. And a softmax classifier is used to map the output, then the BP algorithm is adopted to train the model according to the Eq. ( <ref type="formula" target="#formula_16">12</ref>).</p><p>Step 5: The trained model is deployed online for the diagnosis of different fault severities and orientations of the rolling bearings, which are tested under the same or different working conditions and unbalanced datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof Fig. <ref type="figure" target="#fig_8">4</ref> The procedure of the proposed method</p><p>The proposed model is mainly aimed at the scenarios of data imbalance and variable working conditions. The main innovations of this paper can be summarized as follows:</p><p>1) A stable data-driven model with low structure complexity for data imbalance scenarios is designed to achieve excellent diagnostic performance in highly unbalanced cases without using techniques such as data enhancement.</p><p>2) For the interference of different working conditions, a novel application of BN for eliminating distribution differences caused by different working conditions is illustrated and applied in the model, which has superior adaptability without using transfer learning.</p><p>3) The proposed method focuses on the rolling bearing fault diagnosis without any signal </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model validation</head><p>In this section, the proposed method is used for the diagnosis of different fault severities and orientations of rolling bearings based on the vibration signals, which are collected through accelerometers and contains different bearing conditions. This model is written in TensorFlow software and run on Windows 64 with the Core 8250 CPU and 8G RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Case 1: Model validation on the same working condition</head><p>In this case, the proposed model, which is trained offline based on the training dataset, is used for fault diagnosis of rolling bearings under the same working condition. In addition, the stability of the proposed model on unbalanced datasets is also described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Rolling bearing experimental data</head><p>In order to validate the feasibility and effectiveness of the proposed method for the rolling bearing fault diagnosis, an experimental data is adopted, which is from Case Western Reserve University Lab <ref type="bibr" target="#b40">[40]</ref>. The experimental facility is shown in  The collected vibration signals under 0 HP are used for method validation in this case, which contains 12 bearing conditions that include different fault locations, fault severities and fault orientations. For each rolling bearing condition, 300 samples with 400 data points are constructed from the raw vibration signal <ref type="bibr" target="#b19">[20]</ref>. In order to avoid continuity between samples and enhance the model's robustness, the random 200 samples of each condition are selected for training and the remaining 100 samples for testing. Twelve rolling bearings information are listed in Table <ref type="table" target="#tab_3">1</ref>. As shown in Table <ref type="table" target="#tab_3">1</ref>, sample labels range from 1 to 12. The symbol '@3:00' means that the fault orientation is at 3 o'clock. The time-domain waveforms are shown in Fig. <ref type="figure" target="#fig_11">6</ref>. (i) outer race fault condition (0.007@6:00); (j) outer race fault condition (0.014@6:00); (k) outer race fault condition (0.021@3:00); (l) outer race fault condition (0.021@6:00)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Diagnosis results and analysis</head><p>Based on the constructed training set, the proposed normalized CNN model is established</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof</p><p>for deep feature extraction. The parameters on each layer of the proposed model are determined by grid search <ref type="bibr" target="#b41">[41]</ref>, which are described in Table <ref type="table">2</ref>.</p><p>Table <ref type="table">2</ref> The main parameters of proposed method Layer name Kernel size Layer size</p><formula xml:id="formula_14">Input -- 1@400×1 C1 Conv(25×1) 3@376×1 P1 Maxpool(8×1) 3@47×1 C2 Conv(23×1) 8@25×1 P2 Maxpool(5×1) 8@5×1 F --<label>40</label></formula><formula xml:id="formula_15">H1 --<label>20</label></formula><formula xml:id="formula_16">H2 --<label>12</label></formula><formula xml:id="formula_17">O softmax 12</formula><p>As shown in Table <ref type="table">2</ref>, the layer name are already mentioned in Section 3.1, and Conv(23×1) means that the size of convolutional kernel is 23×1. Maxpool(5×1) represents the size of max pooling window is 5×1. In addition, the regularization factor λ is set to 0.0003. The initial learning rate 0  is 0.05 with a decay rate  , which is set to 0.95.</p><p>Then, kernel principal analysis (KPCA) is employed to visualize features in different layers, which is shown in Fig. <ref type="figure">7</ref>. It can be seen from Fig. <ref type="figure">7</ref>(a) that the distribution of the points with the same color is relatively dispersed and difficult to distinguish. However, with the deepening of the feature extraction process, the distribution of points with the same color is relatively concentrated, which can be seen from Fig. Then, it is necessary to compare the performance of the proposed method with other models. First, based on the different deep learning (DL) methods, the performance is verified, and the results are listed in Table <ref type="table" target="#tab_4">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof in Ref. <ref type="bibr" target="#b19">[20]</ref> and Ref <ref type="bibr" target="#b43">[43]</ref> respectively, their accuracies are reduced by 1.32% and 2.06% compared with the proposed method. In addition, it also can be seen that the performance of image-based model described in Ref. <ref type="bibr" target="#b42">[42]</ref> is still not as good as the proposed method.</p><p>Therefore, the proposed method performs much better than those DL methods, and the multi-class confusion matrix of the output is shown in Fig. <ref type="figure" target="#fig_13">8</ref>. It can be seen that the lowest accuracy happens in condition 4.  <ref type="table" target="#tab_6">4</ref>. The main parameters of the other methods are described as follows:</p><p> Method 2 (SVM with raw data): RBF kernel is applied. The penalty coefficient and the gamma value are set to 30 and 0.015, respectively.</p><p> Method 3 (SVM with 24 features): RBF kernel is applied. The penalty coefficient and the gamma value are set to 30 and 0.005, respectively. More details about the 24 features can be seen in Ref. <ref type="bibr" target="#b44">[44]</ref>.</p><p> Method 4 (RF with raw data): The number of trees is 500 with maximum depth is 20.</p><p> Method 5 (RF with 24 features): The number of trees is 500 with depth 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof  Method 6 (Adaboost with raw data): The basic learners are decision tree with a depth of 10, and the number of weak learners is 200.</p><p> Method 7 (Adaboost with 24 features): The basic learners are decision tree with a depth of 2, and the number of weak learners is 200.</p><p> Method 8 (BPNN with raw data): The architecture is 400-801-12.</p><p> Method 9 (BPNN with 24 features): The architecture is 24-100-12. As listed in Table <ref type="table" target="#tab_6">4</ref>, it can be seen that the proposed method shows the highest classification performance compared with other methods. It is much higher than SVM, RF, Adaboost and BPNN using the raw vibration data, which are 88.500%, 86.500%, 78.833% and 89.667%, respectively. After manual feature extraction, although the testing accuracies of SVM, RF, Adaboost and BPNN increase to 96.833%, 98.417%, 96.000% and 94.083%, respectively, their performances still cannot be compared with the proposed method.</p><p>To quantitatively evaluate the classification performances of the above different methods, precision rate and recall rate are calculated, which can be expressed as follows:</p><formula xml:id="formula_18">P=precision 100 TP TP FP  <label>(18)</label></formula><p>J o u r n a l P r e -p r o o f</p><p>Journal Pre-proof</p><formula xml:id="formula_19">R=recall= 100 TP TP FN  <label>(19)</label></formula><p>where TP represents the number of true positive instances, FP represents the number of false positive instances, and FN represents the number of false negative instances.</p><p>The analysis results of the better models of the above methods are listed in Table <ref type="table" target="#tab_7">5</ref>. It can be seen from Table <ref type="table" target="#tab_7">5</ref> that the proposed method has better performance in the identification of different rolling bearing operating conditions, and its quantitative indexes are superior to other methods. In addition, the phenomenon that the classification accuracy of all models in condition 4 is reduced can be found, which may be determined by the quality of the dataset itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">Influence of the unbalanced datasets</head><p>In the previous section, the diagnostic performance of the proposed method is discussed based on the balanced datasets. However, the phenomenon of data imbalance is common to face in real industry since the number of fault data especially catastrophic fault data or  As shown in Table <ref type="table" target="#tab_8">6</ref>, a total of ten kinds of unbalanced cases are established for analysis and compared with the other five methods using raw data as input. The parameters of comparison methods, which belong to ML, are described in Section 4.1. It can be seen from the fault diagnosis results in Fig. <ref type="figure">9</ref>  Based on the above analysis, the intelligent diagnosis performance of different fault severities and orientations of the proposed method is verified under the same working J o u r n a l P r e -p r o o f condition, and the excellent stability on the unbalanced dataset is also proved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Case 2: Model validation on other working conditions</head><p>In the previous section, the diagnostic performances of the method described in this paper are verified under the same working condition (0 HP). However, in order to meet the needs of mechanical equipment, rolling bearings often operate under different working conditions.</p><p>Thus, in this case, the online deployment model, which is trained under 0 HP and described in Section 4.1.2, is directly used to diagnose rolling bearing conditions under other working conditions, such as 1 HP and 2 HP. And two DL-based methods described in Ref.</p><p>[45] and Ref.</p><p>[46] are also used for further comparison. The diagnostic accuracies are listed in Table <ref type="table" target="#tab_10">7</ref>. From Table <ref type="table" target="#tab_10">7</ref>, it can be seen that the proposed method has the highest testing accuracies on different working conditions, which are 97.1667% and 95.8333% on load 2 and load 3 respectively. For the load 2 (1 HP), the testing accuracy of the proposed method is much higher than SVM, RF, Adaboost and BPNN using the raw vibration data, which are 43.4167%, 64.250%, 51.9167% and 39.1667%, respectively. After manual feature extraction J o u r n a l P r e -p r o o f</p><p>Journal Pre-proof <ref type="bibr">(24-dimension)</ref>, although the testing accuracies of SVM, RF, Adaboost and BPNN increase to 78.583%, 94.167%, 79.3333% and 76.000%, respectively, their performances still cannot be compared with the proposed method. This tendency also exists in the diagnosis results of load 3. In addition, although the two DL-based comparison methods have better diagnostic accuracy at 0 HP, their performance degrades significantly when applied to other operating conditions. Therefore, the classification performance of the online deployed model described in this paper shows good stability when it is used directly for other loads. It reveals that the proposed method has high accuracy and universality. The confusion matrixes of the proposed method under different working conditions are shown in Fig. <ref type="figure" target="#fig_1">10</ref>.  <ref type="table" target="#tab_11">8</ref>.    <ref type="table" target="#tab_12">9</ref>. As shown in Table <ref type="table" target="#tab_12">9</ref>, the classification accuracy of the proposed method on the IMS dataset is 99.200% (496/500), which is much high than the performances of SVM, RF, Adaboost and BPNN, respectively. And although the testing accuracies of these ML methods are improved a lot based on the manual feature extraction, which increase to 98.200%</p><p>(491/500), 99.200% (496/500), 99.000% (495/500) and 97.400% (487/500), respectively, it is still lower than the method described in this paper. Therefore, the universality of the normalized CNN model is further proved and the multi-class confusion matrix on IMS dataset is shown in Fig. <ref type="figure" target="#fig_20">14</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, a normalized CNN model is proposed for the intelligent fault diagnosis of rolling bearings considering data imbalance and variable working conditions. The proposed method can be divided into two main phases: Firstly, the offline model is constructed for deep feature learning based on multiple convolutional layers, pooling layer and hidden layers, which combines BN technology and exponential moving average. Secondly, the trained model is deployed online and used directly for fault diagnosis of other rolling bearings, which are acquired under different working conditions and unbalanced datasets.</p><p>The method described in this paper focuses on the scenarios of data imbalance and different DL and ML methods, the proposed model shows higher classification accuracy. In addition, this method is able to exhibit excellent stability on highly unbalanced datasets.</p><p>Moreover, the proposed method can be directly applied to the fault diagnosis of rolling bearings under different working loads, which does not require transfer learning. Therefore, the proposed method not only has the advantage of low structural complexity, but also has very strong robustness and stability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Among them, 1-D CNN is more suitable for processing 1-D signals, which are widely existed in the industrial field, and the structure of 1-D CNN model is shown in Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1</head><label>1</label><figDesc>Fig.1 The topology structure of 1-D CNN model As shown in Fig.1, three critical components are included in the 1-D CNN model, which</figDesc><graphic coords="8,111.32,299.46,372.62,277.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 )</head><label>3</label><figDesc>Fully-connected layer Generally, multiple convolutional and pooling layers are included in the CNN model, which perform layer-by-layer extraction of features with an alternating manner. Then, the extracted features are flattened into a vector and used as the input of fully-connected layer, its main function is to further extract the features and to connect the output stage with the softmax classifier. A fully-connected layer is usually composed of 2~3 hidden layers, and all neurons in hidden layers are interconnected based on the following definition: weight matrix used to connect the two fully connected layers, b f represents the bias, and s m represents the input data of the fully connected layer,    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>are learnable reconstruction parameters that can learn to recover the feature distribution of the original network. Note that the original activations can be restored  . In this case, the stable distribution of activation values can be guaranteed during each learning.Secondly, since mini-batch technique is used during the training process, a particular activation x i which owns B values in a mini-batch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>two phases: normalization and scaling. In addition, it is worth noting that the special training method is introduced into the BN layer: first, the hyper-parameters in BN layers are continuously updated based on the training dataset to adjust the feature distribution, and the chain-based update process is introduced in Ref.<ref type="bibr" target="#b37">[37]</ref>. Then, during the testing phase, hyper-parameters learned from the training dataset are fixed and reused to adjust feature distribution of the testing dataset. Based on this specific training mode, BN can not only obtain stable feature distribution, but also be used in a novel application to eliminate J o u r n a l P r e -p r o o f Journal Pre-proof distribution differences caused by different working conditions, it can also be illustrated as shown in Fig.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Illustration of eliminating distribution differenceIt can be seen form Fig.2that BN as a feasible method can form a bridge between two</figDesc><graphic coords="13,179.87,128.01,235.21,142.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3</head><label>3</label><figDesc>Fig.3The topology structure of the proposed method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>J o u r</head><label></label><figDesc>n a l P r e -p r o o f Journal Pre-proof convergence through a large learning rate at the beginning of training process, and then achieve model optimization with a small learning rate, which can be expressed as follows: represents the initial learning rate,  represents the decay rate, decay_step represents the speed of decay, global_step represents the current number of iterations.In addition, in order to improve the performance of the model trained by the stochastic gradient descent algorithm on the testing dataset, the exponential moving average model is employed in the training stage. The essence of the exponential moving average model is based on smooth updates so that the overall performance of the proposed method does not deviate far from the best, thus improving the robustness of the model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>J o u r 4 )</head><label>4</label><figDesc>n a l P r e -p r o o f Journal Pre-proof preprocessing or feature pre-extraction, which means that the input of this model is the raw vibration signal, it not only does not destroy the original structure of mechanical signal, but also reduces the dependence of manual signal processing. The proposed normalized CNN model can be employed in the diagnosis of different fault severities and orientations of rolling bearings under variable working conditions and unbalanced datasets. Its performance is fully demonstrated in Section 4 by comparison with other methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 .</head><label>5</label><figDesc>The main components of this experimental facility consist of a 2 hp motor (left), a torque transducer (center) and a dynamometer (right). The test bearing (6205-2RS JEM SKF) support the motor shaft. The rolling bearing is tested under different loads (0, 1, and 2 HP). The location of the fault mainly includes ball defect (BD), outer race defect (OR) and inner race defect (IR). And the single J o u r n a l P r e -p r o o f Journal Pre-proof point faults are introduced to the test bearing using electro-discharge machining with fault diameters of 0.007, 0.014, 0.021 and 0.028 inches (1 inches = 25.4 mm). The vibration signals are collected by the accelerometer sensor with 12kHz.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 The rolling bearing experimental platform</figDesc><graphic coords="21,180.60,156.51,233.45,140.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Waveforms of twelve rolling bearings: (a) normal condition; (b) ball fault condition (0.007); (c) ball fault condition (0.014); (d) ball fault condition (0.021); (e) inner race fault condition (0.007); (f) inner race fault condition (0.021); (g) inner race fault condition (0.028); (h) outer race fault condition (0.007@3:00);</figDesc><graphic coords="22,82.82,153.16,429.62,418.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Fig. 7 Features visualization using KPCA: (a) input layer; (b) C1 layer; (c) C2 layer; (d) F layer; (e) H1 layer; (f) H2 layer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Multi-class confusion matrix of the proposed method In addition, to further demonstrate the superiority of the proposed method, other</figDesc><graphic coords="25,193.82,237.38,207.61,209.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>J o u r</head><label></label><figDesc>n a l P r e -p r o o f Journal Pre-proof accidental mechanical failure is very small, which significantly deteriorates the model performances. But the traditional deep learning-based models require a large number of high-quality samples to participate in training to ensure the performances. Thus, how to effectively solve the fault diagnosis problem with the unbalanced dataset has been a great challenge in the mechanical fault diagnosis field. In this section, the diagnostic stability of the proposed method is further investigated based on the unbalanced datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>2 .</head><label>2</label><figDesc>And the main parameters of two DL models are described as follows: (1) standard DBN: the structure of DBN is 400-200-100-80-12. The learning rate and iteration number are 3 and 150, respectively. (2) standard DAE: The structure of DBN is 400-200-100-80-12. The learning rate and iteration number are 0.15 and 150, respectively. Besides, the other two existing methods are also used to further illustrate the effectiveness of the proposed method: (1) according to the literature [20], a network structure called ensemble deep auto-encoders (EDAEs) is employed for the fault diagnosis considering data imbalance. (2) according to the J o u r n a l P r e -p r o o f Journal Pre-proof literature [45], a supervised network based on VGG-CNN is also added for comparison. Under the ten unbalanced cases, the number of the testing dataset in each bearing condition is always set to 100, while the ratios of the normal sample and each kind of fault sample in the training dataset are set to 200:180, 200:170, 200:160, 200:140, 200:120, 200:100, 200:80, 200:60 and 200:50, respectively. It should be noted the unbalanced Case 1 is the same as Section 4.1.2, each bearing condition contains 200 training dataset and 100 testing dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>J o u r</head><label></label><figDesc>Fig. 9 Diagnosis results of different methods on ten unbalanced cases In addition, the reasons for the poor performances of DBN and DAE models can be</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 10 4 . 3 Case 3 :</head><label>10433</label><figDesc>Fig. 10 Multi-class confusion matrix under different working conditions</figDesc><graphic coords="32,90.62,323.86,414.02,219.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 12 .Fig. 13 .</head><label>1213</label><figDesc>Fig.12. J o u r n a l P r e -p r o o f</figDesc><graphic coords="33,180.62,75.96,234.01,136.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>J o u r</head><label></label><figDesc>Fig. 13 Features visualization based on t-SNE: (a) input layer; (b) C1 layer; (c) C2 layer; (d) F layer; (e) H1 layer; (f) H2 layer After several iterations and parameter updates, the classification performance of the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 14</head><label>14</label><figDesc>Fig.14Multi-class confusion matrix on IMS dataset Also, according to the strategy described in Table6, ten unbalanced cases on the IMS</figDesc><graphic coords="36,208.36,299.46,178.25,180.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>J o u r</head><label></label><figDesc>n a l P r e -p r o o f Journal Pre-proof variable working conditions, a novel application of BN for eliminating distribution differences caused by different working conditions is illustrated and applied in the model. The diagnostic results show that this method can automatically and accurately identify the different fault types, such the fault orientations and fault severities. Compared with many</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,151.37,298.50,292.21,458.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="24,83.87,76.01,427.17,250.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="30,135.60,76.84,323.36,216.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="35,70.87,76.66,453.52,265.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="44,-0.04,1.88,608.03,840.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>Different conditions of the rolling bearing in this case</figDesc><table><row><cell></cell><cell></cell><cell>Journal Pre-proof</cell><cell></cell><cell></cell></row><row><cell cols="5">Location Fault diameter Fault orientation The number of training/testing samples Label Normal 0 -200 / 100 Ball 0.007 -200 / 100 Ball 0.014 -200 / 100 Ball 0.021 -200 / 100 Inner race 0.007 -200 / 100 Inner race 0.021 -200 / 100 Inner race 0.028 -200 / 100 Outer race 0.007 Vertical @3:00 200 / 100 J o u r n a l P r e -p r o o f</cell></row><row><cell>Outer race</cell><cell>0.007</cell><cell>Center @6:00</cell><cell>200 / 100</cell><cell></cell></row><row><cell>Outer race</cell><cell>0.014</cell><cell>Center @6:00</cell><cell>200 / 100</cell><cell>10</cell></row><row><cell>Outer race</cell><cell>0.021</cell><cell>Vertical @3:00</cell><cell>200 / 100</cell><cell>11</cell></row><row><cell>Outer race</cell><cell>0.021</cell><cell>Center @6:00</cell><cell>200 / 100</cell><cell>12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Diagnosis results of different DL methods</figDesc><table><row><cell></cell><cell cols="2">Accuracy (%)</cell></row><row><cell>Method</cell><cell>Input dimension</cell></row><row><cell></cell><cell>Training dataset</cell><cell>Testing dataset</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>The proposed method 400 100.00% (2400/2400) 98.50% (1182/1200)</head><label></label><figDesc></figDesc><table><row><cell>Standard DBN</cell><cell>400</cell><cell>--</cell><cell>88.50% (1062/1200)</cell></row><row><cell>Standard SAE</cell><cell>400</cell><cell>--</cell><cell>86.33% (1036/1200)</cell></row><row><cell>Ref. [20]</cell><cell>400</cell><cell>99.15% (2380/2400)</cell><cell>97.18% (1166/1200)</cell></row><row><cell>Ref. [42]</cell><cell>20×20</cell><cell>98.36% (2164/2200)</cell><cell>88.00% (968/1100)</cell></row><row><cell>Ref. [43]</cell><cell>400</cell><cell>100.00% (2400/2400)</cell><cell>96.44% (1157/1200)</cell></row><row><cell cols="4">As shown in Table 3, the classification accuracy on the testing dataset based on the trained</cell></row><row><cell cols="4">method is 98.50% (1182/1200). That is much higher than those based on standard DBN and</cell></row></table><note><p>standard SAE, which are 88.50% (1062/1200) and 86.33% (1036/1200). Although two different ensemble strategies, which have excellent diagnostic performances, are constructed</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Diagnosis results of different ML methods</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Accuracy (%)</cell></row><row><cell>Method</cell><cell>Input dimension</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Training dataset</cell><cell>Testing dataset</cell></row><row><cell>The proposed method</cell><cell>400</cell><cell>100.00% (2400/2400)</cell><cell>98.500% (1182/1200)</cell></row><row><cell>Method 2</cell><cell>400</cell><cell>99.625% (2391/2400)</cell><cell>88.500% (1062/1200)</cell></row><row><cell>Method 3</cell><cell>24</cell><cell>99.792% (2395/2400)</cell><cell>96.833% (1162/1200)</cell></row><row><cell>Method 4</cell><cell>400</cell><cell>100.00% (2400/2400)</cell><cell>86.500% (1038/1200)</cell></row><row><cell>Method 5</cell><cell>24</cell><cell>99.250% (2382/2400)</cell><cell>98.417% (1181/1200)</cell></row><row><cell>Method 6</cell><cell>400</cell><cell>100.00% (2400/2400)</cell><cell>78.833% (946/1200)</cell></row><row><cell>Method 7</cell><cell>24</cell><cell>97.208% (2333/2400)</cell><cell>96.000% (1152/1200)</cell></row><row><cell>Method 8</cell><cell>400</cell><cell>100.00% (2400/2400)</cell><cell>89.667% (1076/1200)</cell></row><row><cell>Method 9</cell><cell>24</cell><cell>94.583% (2267/2400)</cell><cell>94.083% (1129/1200)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Precision rate and recall rate using different methods</figDesc><table><row><cell>Bearing</cell><cell cols="2">Proposed method</cell><cell>SVM</cell><cell></cell><cell>RF</cell><cell></cell><cell cols="2">AdaBoost</cell><cell cols="2">BPNN</cell></row><row><cell>label</cell><cell>P (%)</cell><cell>R (%)</cell><cell cols="8">P (%) R (%) P (%) R (%) P (%) R (%) P (%) R (%)</cell></row><row><cell>Label 1</cell><cell>100</cell><cell>100</cell><cell>95</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Label 2</cell><cell>93</cell><cell>97</cell><cell>91</cell><cell>94</cell><cell>98</cell><cell>92</cell><cell>98</cell><cell>83</cell><cell>90</cell><cell>90</cell></row><row><cell>Label 3</cell><cell>97</cell><cell>97</cell><cell>95</cell><cell>83</cell><cell>100</cell><cell>95</cell><cell>88</cell><cell>95</cell><cell>92</cell><cell>84</cell></row><row><cell>Label 4</cell><cell>95</cell><cell>90</cell><cell>87</cell><cell>90</cell><cell>91</cell><cell>97</cell><cell>83</cell><cell>85</cell><cell>77</cell><cell>76</cell></row><row><cell>Label 5</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>98</cell><cell>100</cell><cell>92</cell><cell>100</cell><cell>98</cell><cell>100</cell></row><row><cell>Label 6</cell><cell>99</cell><cell>100</cell><cell>95</cell><cell>100</cell><cell>98</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>92</cell><cell>99</cell></row><row><cell>Label 7</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>98</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Label 8</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>96</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>97</cell></row><row><cell>Label 9</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99</cell><cell>100</cell><cell>96</cell><cell>100</cell></row><row><cell>Label 10</cell><cell>100</cell><cell>100</cell><cell>98</cell><cell>99</cell><cell>99</cell><cell>99</cell><cell>100</cell><cell>98</cell><cell>89</cell><cell>96</cell></row><row><cell>Label 11</cell><cell>98</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99</cell><cell>100</cell><cell>99</cell><cell>98</cell><cell>99</cell></row><row><cell>Label 12</cell><cell>100</cell><cell>98</cell><cell>100</cell><cell>100</cell><cell>98</cell><cell>99</cell><cell>97</cell><cell>92</cell><cell>98</cell><cell>88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Description of the unbalanced training dataset</figDesc><table><row><cell></cell><cell cols="2">Size of normal condition</cell><cell cols="2">Size of each kind of fault conditions</cell></row><row><cell>Unbalanced cases</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Training dataset</cell><cell>Testing dataset</cell><cell>Training dataset</cell><cell>Testing dataset</cell></row><row><cell>Case 1</cell><cell>200</cell><cell>100</cell><cell>200</cell><cell>100</cell></row><row><cell>Case 2</cell><cell>200</cell><cell>100</cell><cell>180</cell><cell>100</cell></row><row><cell>Case 3</cell><cell>200</cell><cell>100</cell><cell>170</cell><cell>100</cell></row><row><cell>Case 4</cell><cell>200</cell><cell>100</cell><cell>160</cell><cell>100</cell></row><row><cell>Case 5</cell><cell>200</cell><cell>100</cell><cell>140</cell><cell>100</cell></row><row><cell>Case 6</cell><cell>200</cell><cell>100</cell><cell>120</cell><cell>100</cell></row><row><cell>Case 7</cell><cell>200</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>Case 8</cell><cell>200</cell><cell>100</cell><cell>80</cell><cell>100</cell></row><row><cell>Case 9</cell><cell>200</cell><cell>100</cell><cell>60</cell><cell>100</cell></row><row><cell>Case 10</cell><cell>200</cell><cell>100</cell><cell>50</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>, the classification accuracy of the proposed method in Case 1 is 98.50%, compared with other seven methods, which are 97.41%, 93.75%, 88.50%, 86.50%, 89.667%, 88.500% and 86.333%, respectively. Then, in unbalanced Case 7, in which the number of fault samples under each fault condition in the training phase is reduced to half of Case 1, the diagnosis accuracy of the proposed method is 96.80%, and it is much higher than others, which are 86.37%, 90.92%, 80.108%, 78.29%, 75.346%, 80.17% and 72.08%, respectively. When the data imbalance ratio reaches 4:1, the proposed model mentioned still has excellent fault pattern recognition performance, and its classification accuracy rate is only 2.46% lower than Case 1. In contrast, the performances of other comparison methods are severely degraded in the highly unbalanced scenario. In addition, it is worth noting that with the aggravation of the imbalance rate, the degradation of fault diagnosis performance of the EDAEs-based method is more serious than that of the VGG-CNN based method, which indicates that the former is more vulnerable to data imbalance. Moreover, as the number of training samples decreases, the standard deep learning models DAE and DBN are difficult to train and cannot effectively represent the fault information, thus greatly reducing its performances. Therefore, it can be clearly seen that although the severely unbalanced dataset can cause a decline in the performance of all models, the proposed method exhibits superior stability performance compared with other methods.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7</head><label>7</label><figDesc>Diagnostic results for different working conditions</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Testing accuracy (%)</cell><cell></cell></row><row><cell>Method</cell><cell>Input dimension</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Load 1 (0 HP)</cell><cell>Load 2 (1 HP)</cell><cell>Load 3 (2 HP)</cell></row><row><cell>The proposed method</cell><cell>400</cell><cell>98.500%</cell><cell>97.1667%</cell><cell>95.8333%</cell></row><row><cell>Method 2</cell><cell>400</cell><cell>88.500%</cell><cell>43.4167%</cell><cell>44.250%</cell></row><row><cell>Method 3</cell><cell>24</cell><cell>96.833%</cell><cell>78.583%</cell><cell>83.500%</cell></row><row><cell>Method 4</cell><cell>400</cell><cell>86.500%</cell><cell>64.250%</cell><cell>66.8333%</cell></row><row><cell>Method 5</cell><cell>24</cell><cell>98.417%</cell><cell>94.167%</cell><cell>89.833%</cell></row><row><cell>Method 6</cell><cell>400</cell><cell>78.833%</cell><cell>51.9167%</cell><cell>55.3333%</cell></row><row><cell>Method 7</cell><cell>24</cell><cell>96.000%</cell><cell>79.3333%</cell><cell>78.3333%</cell></row><row><cell>Method 8</cell><cell>400</cell><cell>89.667%</cell><cell>39.1667%</cell><cell>45.250%</cell></row><row><cell>Method 9</cell><cell>24</cell><cell>94.083%</cell><cell>76.000%</cell><cell>77.500%</cell></row><row><cell>Ref. [45]</cell><cell>400</cell><cell>94.250%</cell><cell>82.750%</cell><cell>83.083%</cell></row><row><cell>Ref. [46]</cell><cell>400</cell><cell>98.000%</cell><cell>93.917%</cell><cell>94.833%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8</head><label>8</label><figDesc>Different conditions of the IMS datasetAs shown in Table8, five different conditions of rolling bearings are labeled, ORF1 and ORF2 respectively represent the outer race faults generated in the two experiments, which can be regarded as different working conditions. The time-domain waveforms are shown in</figDesc><table><row><cell cols="3">Location The number of training/testing samples Label</cell></row><row><cell>Normal</cell><cell>200 / 100</cell><cell>1</cell></row><row><cell>IF</cell><cell>200 / 100</cell><cell>2</cell></row><row><cell>ORF1</cell><cell>200 / 100</cell><cell>3</cell></row><row><cell>ORF2</cell><cell>200 / 100</cell><cell>4</cell></row><row><cell>BF</cell><cell>200 / 100</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9</head><label>9</label><figDesc>Diagnosis results of different methods based on IMS dataset</figDesc><table><row><cell cols="4">Method The proposed method Method 2 Method 3 Method 4 Method 5 Method 6 Method 7 J o u r n a l P r e -p r o o f Input dimension Accuracy (%) Training dataset Testing dataset 400 100.00% (1000/1000) 99.200% (496/500) 400 99.000% (990/1000) 86.200% (431/500) 24 100.00% (1000/1000) 98.200% (491/500) 400 100.00% (1000/1000) 82.400% (412/500) 24 99.400% (994/1000) 99.200% (496/500) 400 100.00% (1000/1000) 82.000% (410/500) 24 100.00% (1000/1000) 99.000% (495/500)</cell></row><row><cell>Method 8</cell><cell>400</cell><cell>100.00% (1000/1000)</cell><cell>75.000% (375/500)</cell></row><row><cell>Method 9</cell><cell>24</cell><cell>98.200% (982/1000)</cell><cell>97.400% (487/500)</cell></row></table><note><p>Journal Pre-proof</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by the National Natural Science Foundation of China [grant number U1501247].</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest</head><p>The authors declare that they have no conflict of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Highlights</head><p>(1) A stable data-driven model with low structure complexity for data imbalance scenarios is designed to achieve excellent diagnostic performance in highly unbalanced cases without using techniques such as data enhancement.</p><p>(2) For the interference of different working conditions, a novel application of BN for eliminating distribution differences caused by different working conditions is illustrated and applied in the model, which has superior adaptability without using transfer learning.</p><p>(3) The proposed method focuses on the rolling bearing fault diagnosis without any signal preprocessing or feature pre-extraction, which means that the input of this model is the raw vibration signal, it not only does not destroy the original structure of mechanical signal, but also reduces the dependence of manual signal processing.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A recurrent neural network based health indicator for remaining useful life prediction of bearings</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2017.02.045</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2017.02.045" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="page" from="98" to="109" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bearing fault diagnosis using fully-connected winner-take-all autoencoder</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2017.2717492</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2017.2717492" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="6103" to="6115" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A multiscale noise tuning stochastic resonance for fault diagnosis in rolling element bearings</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cjph.2017.11.013</idno>
		<ptr target="https://doi.org/10.1016/j.cjph.2017.11.013" />
	</analytic>
	<monogr>
		<title level="j">Chin. J. Phys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="145" to="157" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical spectral analysis for fault diagnosis of rotating machines</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ciabattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferracuti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Freddi</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIE.2017.2762623</idno>
		<ptr target="https://doi.org/10.1109/TIE.2017.2762623" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="4301" to="4310" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Artificial intelligence for fault diagnosis of rotating machinery: A review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zio</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymssp.2018.02.016</idno>
		<ptr target="https://doi.org/10.1016/j.ymssp.2018.02.016" />
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Proc</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="33" to="47" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Journal Pre-proof</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rolling bearing fault diagnosis using modified LFDA and EMD with sensitive feature selection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2017.2773460</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2017.2773460" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3715" to="3730" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enabling health monitoring approach based on vibration data for accurate prognostics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gouriveau</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIE.2014.2327917</idno>
		<ptr target="https://doi.org/10.1109/TIE.2014.2327917" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A review on data-driven fault severity assessment in rolling bearings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cerrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymssp.2017.06.012</idno>
		<ptr target="https://doi.org/10.1016/j.ymssp.2017.06.012" />
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Proc</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="169" to="196" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Artificial intelligence technology and engineering applications</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Electromagn. Soc. J</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="381" to="388" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning enabled intelligent fault diagnosis: Overview and applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.3233/JIFS-17938</idno>
		<ptr target="https://doi.org/10.3233/JIFS-17938" />
	</analytic>
	<monogr>
		<title level="j">J. Intell. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="5771" to="5784" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A monotonic degradation assessment index of rolling bearings using fuzzy support vector data description and running time</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.3390/s120810109</idno>
		<ptr target="https://doi.org/10.3390/s120810109" />
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="10109" to="10135" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rolling bearing fault diagnosis based on supervised laplaian score and principal component analysis</title>
		<author>
			<persName><forename type="first">O U</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dejie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chin. J. Mech. Eng</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="88" to="94" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Regrouping particle swarm optimization based variable neural network for gearbox fault diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.3233/JIFS-169542</idno>
		<ptr target="https://doi.org/10.3233/JIFS-169542" />
	</analytic>
	<monogr>
		<title level="j">J. Intell. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><surname>Salakhutdinov R R</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1127647</idno>
		<ptr target="https://doi.org/10.1126/science.1127647" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep learning and its applications to machine health monitoring</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymssp.2018.05.050</idno>
		<ptr target="https://doi.org/10.1016/j.ymssp.2018.05.050" />
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Proc</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="213" to="237" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep neural networks: A promising tool for fault characteristic mining and intelligent diagnosis of rotating machinery with massive data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymssp.2015.10.025</idno>
		<ptr target="https://doi.org/10.1016/j.ymssp.2015.10.025" />
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Proc</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="303" to="315" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Intelligent bearing fault diagnosis method combining compressed data acquisition and deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIM.2017.2759418</idno>
		<ptr target="https://doi.org/10.1109/TIM.2017.2759418" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="185" to="195" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Batch-normalized deep neural networks for achieving fast intelligent fault diagnosis of machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>An</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2018.10.049</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2018.10.049" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">An enhancement deep feature extraction method for bearing fault diagnosis based on kernel function and autoencoder, Shock Vib</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1155/2018/6024874</idno>
		<ptr target="https://doi.org/10.1155/2018/6024874" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A novel method for intelligent fault diagnosis of rolling bearings using ensemble deep auto-encoders</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymssp.2017.09.026</idno>
		<ptr target="https://doi.org/10.1016/j.ymssp.2017.09.026" />
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Proc</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="278" to="297" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multisensor feature fusion for bearing fault diagnosis using sparse autoencoder and deep belief network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="1693" to="1702" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<idno type="DOI">10.1109/TIM.2017.2669947</idno>
		<ptr target="https://doi.org/10.1109/TIM.2017.2669947" />
	</analytic>
	<monogr>
		<title level="j">J o u r n a l P r e -p r o o f Journal Pre-proof</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scalable and unsupervised feature engineering using vibration-imaging and deep learning for rotor system diagnosis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Jeon</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIE.2017.2752151</idno>
		<ptr target="https://doi.org/10.1109/TIE.2017.2752151" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="3539" to="3549" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An intelligent fault diagnosis approach for planetary gearboxes based on deep belief networks and uniformed features</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.3233/JIFS-169538</idno>
		<ptr target="https://doi.org/10.3233/JIFS-169538" />
	</analytic>
	<monogr>
		<title level="j">J. Intell. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3619" to="3634" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rolling bearing fault feature learning using improved convolutional deep belief network with compressed sensing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ymssp.2017.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.ymssp.2017.08.002" />
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Proc</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="743" to="765" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Electric locomotive bearing fault diagnosis using a novel convolutional deep belief network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIE.2017.2745473</idno>
		<ptr target="https://doi.org/10.1109/TIE.2017.2745473" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="2727" to="2736" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep learning-based remaining useful life estimation of bearings using multi-scale feature extraction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ress.2018.11.011</idno>
		<ptr target="https://doi.org/10.1016/j.ress.2018.11.011" />
	</analytic>
	<monogr>
		<title level="j">Reliab. Eng. Syst. Saf</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="208" to="218" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An intelligent fault diagnosis framework for raw vibration signals: adaptive overlapping convolutional neural network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-6501/aad101</idno>
		<ptr target="https://doi.org/10.1088/1361-6501/aad101" />
	</analytic>
	<monogr>
		<title level="j">Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Intelligent fault diagnosis under varying working conditions based on domain adaptive convolutional neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X-L</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2018.2878491</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2018.2878491" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="367" to="384" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep decoupling convolutional neural network for intelligent compound fault diagnosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2018.2886343</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2018.2886343" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="48" to="58" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A convolutional neural network based on a capsule network with strong generalization for bearing fault diagnosis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2018.09.050</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2018.09.050" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="62" to="75" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intelligent fault detection via dilated convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<idno type="DOI">10.1109/BigComp.2018.00137</idno>
		<ptr target="https://doi.org/10.1109/BigComp.2018.00137" />
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Big Data And Smart Computing</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="729" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Imbalanced enterprise credit evaluation with DTE-SBD: Decision tree ensemble based on SMOTE and bagging with differentiated sampling rates</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2017.10.017</idno>
		<ptr target="https://doi.org/10.1016/j.ins.2017.10.017" />
	</analytic>
	<monogr>
		<title level="j">Inform. Sciences</title>
		<imprint>
			<biblScope unit="volume">425</biblScope>
			<biblScope unit="page" from="76" to="91" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Class-imbalanced dynamic financial distress prediction based on Adaboost-SVM ensemble combined with SMOTE and time weighting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2019.07.006</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2019.07.006" />
	</analytic>
	<monogr>
		<title level="j">Inform. Fusion</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="128" to="144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-imbalance: An open-source software for multi-class imbalance learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2019.03.001</idno>
		<ptr target="https://doi.org/10.1016/j.knosys.2019.03.001" />
	</analytic>
	<monogr>
		<title level="j">Knowl-Based. Syst</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="137" to="143" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep learning fault diagnosis method based on global optimization J</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys</idno>
		<idno>07.008</idno>
		<ptr target="https://doi.org/10.1016/j.knosys" />
	</analytic>
	<monogr>
		<title level="j">Journal Pre-proof GAN for unbalanced data</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page">104837</biblScope>
			<date type="published" when="2019">2020. 2019</date>
		</imprint>
	</monogr>
	<note>Knowl-Based. Syst.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An empirical comparison on state-of-the-art multi-class imbalance learning algorithms and a new diversified ensemble learning scheme</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2018.05.037</idno>
		<ptr target="https://doi.org/10.1016/j.knosys.2018.05.037" />
	</analytic>
	<monogr>
		<title level="j">Knowl-Based. Syst</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Construction of a batch-normalized autoencoder network and its application in mechanical intelligent fault diagnosis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-6501/aaf319</idno>
		<ptr target="https://doi.org/10.1088/1361-6501/aaf319" />
	</analytic>
	<monogr>
		<title level="j">Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised adversarial adaptation network for intelligent fault diagnosis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIE.2019.2956366</idno>
		<ptr target="https://doi.org/10.1109/TIE.2019.2956366" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A novel bearing fault diagnosis method based on 2D image representation and transfer learning-convolutional neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><forename type="middle">W</forename></persName>
		</author>
		<idno type="DOI">10.1088/1361-6501/ab0793</idno>
		<ptr target="https://doi.org/10.1088/1361-6501/ab0793" />
	</analytic>
	<monogr>
		<title level="j">Meas. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A novel transfer learning method for robust fault diagnosis of rotating machines under variable working conditions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.measurement</idno>
		<idno>02.073</idno>
		<ptr target="https://doi.org/10.1016/j.measurement" />
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="514" to="525" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rub-impact fault diagnosis of rotating machinery based on 1-D convolutional neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng Z K, Ren</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSEN.2019.2944157</idno>
		<ptr target="https://doi.org/10.1109/JSEN.2019.2944157" />
	</analytic>
	<monogr>
		<title level="j">IEEE Sens. J</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rolling bearing fault identification using multilayer deep learning convolutional neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">10.21595/jve.2016.16939</idno>
		<ptr target="https://doi.org/10.21595/jve.2016.16939" />
	</analytic>
	<monogr>
		<title level="j">J. Vibroeng</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="138" to="149" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A multi-ensemble method based on deep auto-encoders for fault diagnosis of rolling bearings</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mao</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.measurement.2019.107132</idno>
		<ptr target="https://doi.org/10.1016/j.measurement.2019.107132" />
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Teng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2015.07.020</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2015.07.020" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="837" to="853" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Highly accurate machine fault diagnosis using deep transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcaleer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TII.2018.2864759</idno>
		<ptr target="https://doi.org/10.1109/TII.2018.2864759" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Inform</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2446" to="2455" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Intelligent fault diagnosis for rotary machinery using transferable convolutional neural network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gryllias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/TII.2019.2917233</idno>
		<ptr target="https://doi.org/10.1109/TII.2019.2917233" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Inform</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="339" to="349" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep convolutional transfer learning network: A new method for intelligent fault diagnosis of machines with unlabeled data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xing</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIE.2018.2877090</idno>
		<ptr target="https://doi.org/10.1109/TIE.2018.2877090" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="7316" to="7325" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Journal Pre-proof</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
