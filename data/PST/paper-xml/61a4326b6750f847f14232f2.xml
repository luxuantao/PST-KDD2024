<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Continuous-Time Sequential Recommendation with Temporal Graph Collaborative Transformer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-08-22">22 Aug 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
							<email>jiawei@ifmlab.org</email>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><surname>Xiong</surname></persName>
							<email>yunx@fudan.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
							<email>lzheng@pinterest.com</email>
						</author>
						<author>
							<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
							<email>psyu@uic.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">IFM Lab</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Davis</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Shanghai Key Laboratory of Data Science</orgName>
								<orgName type="department" key="dep2">School of Computer Science</orgName>
								<address>
									<country>Fudan University China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Pinterest Inc</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Continuous-Time Sequential Recommendation with Temporal Graph Collaborative Transformer</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-22">22 Aug 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3459637.3482242</idno>
					<idno type="arXiv">arXiv:2108.06625v2[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>â€¢ Information systems â†’ Collaborative filtering</term>
					<term>Recommender systems</term>
					<term>Personalization Sequential Recommendation, Temporal Effects, Graph Neural Network, Transformer</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In order to model the evolution of user preference, we should learn user/item embeddings based on time-ordered item purchasing sequences, which is defined as Sequential Recommendation (SR) problem. Existing methods leverage sequential patterns to model item transitions. However, most of them ignore crucial temporal collaborative signals, which are latent in evolving user-item interactions and coexist with sequential patterns. Therefore, we propose to unify sequential patterns and temporal collaborative signals to improve the quality of recommendation, which is rather challenging. Firstly, it is hard to simultaneously encode sequential patterns and collaborative signals. Secondly, it is non-trivial to express the temporal effects of collaborative signals.</p><p>Hence, we design a new framework Temporal Graph Sequential Recommender (TGSRec) upon our defined continuous-time bipartite graph. We propose a novel Temporal Collaborative Transformer (TCT) layer in TGSRec, which advances the self-attention mechanism by adopting a novel collaborative attention. TCT layer can simultaneously capture collaborative signals from both users and items, as well as considering temporal dynamics inside sequential patterns. We propagate the information learned from TCT layer over the temporal graph to unify sequential patterns and temporal collaborative signals. Empirical results on five datasets show that TGSRec significantly outperforms other baselines, in average up to 22.5% and 22.1% absolute improvements in Recall@10 and MRR, respectively. Our code is available online in https://github.com/ DyGRec/TGSRec.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommender system has become essential in providing personalized information filtering services in a variety of applications <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>. It learns the user and item embeddings from historical records on the user-item interactions <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b33">34]</ref>. In order to model the dynamics of the user-item interaction, current research works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b41">42]</ref> leverage historical time-ordered item purchasing sequences to predict future items for users, referred to as the sequential recommendation (SR) problem <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref>. One of the fundamental assumptions of SR is that the users' interests change smoothly <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b41">42]</ref>. Thus, we can train a model to infer the items more likely to appear in the future sequence. For example, with the recent developments of Transformer <ref type="bibr" target="#b37">[38]</ref>, current endeavors design a series of self-attention SR models to predict future item sequences <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">44]</ref>. A self-attention model infers sequence embeddings at position ğ‘¡ by assigning an attention weight to each historical item and aggregating these items. The attention weights reveal impacts of previous items to the current state at time point ğ‘¡.</p><p>Despite their effectiveness, existing works only leverage the sequential patterns to model the item transitions within sequences, which is still insufficient to yield satisfactory results. The reason is that they ignore the crucial temporal collaborative signals, which are latent in evolving user-item interactions and coexist with Given the items that users ğ‘¢ 1 , ğ‘¢ 2 , ğ‘¢ 3 and ğ‘¢ 4 like in the past timestamps ğ‘¡ 1 , ğ‘¡ 2 , ğ‘¡ 3 and ğ‘¡ 4 , the target is to recommend an item to ğ‘¢ 4 at ğ‘¡ 5 as the next item after ğ‘– 2 . sequential patterns. To be specific, we present the effects of temporal collaborative signals in Figure <ref type="figure" target="#fig_0">1</ref>. The target is to recommend an item to ğ‘¢ 4 at ğ‘¡ 5 as the next item after ğ‘– 2 . By only considering the sequential patterns, ğ‘– 3 is recommended since it appears 2 times after ğ‘– 2 as in ğ‘¢ 1 and ğ‘¢ 3 , compared with ğ‘– 4 of only 1 time in ğ‘¢ 2 . However, if also taking account of collaborative signals, we would recommend ğ‘– 4 , because both ğ‘¢ 2 and ğ‘¢ 4 have interactions with ğ‘– 1 at ğ‘¡ 2 and ğ‘– 2 at ğ‘¡ 3 and ğ‘¡ 4 , respectively, which indicates their high similarity. Hence, ğ‘¢ 2 's sequential patterns are of more impacts to ğ‘¢ 4 . This motivates us to unify sequential patterns and temporal collaborative signals.</p><p>However, incorporating temporal collaborative signals in SR is rather challenging. The first challenge is that it is hard to simultaneously encode collaborative signals and sequential patterns. Current models capture the sequential pattern based on the transition of items within sequences <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b27">28]</ref>, thus lacking the mechanism to model the collaborative signals across sequences. Jodie <ref type="bibr" target="#b16">[17]</ref> and DGCF <ref type="bibr" target="#b19">[20]</ref> employs LSTM to model the dynamics and interactions of user and item embeddings but they cannot learn the impacts of all historical items, thus unable to encode sequences. SASRec <ref type="bibr" target="#b11">[12]</ref> proposed to use a self-attention mechanism to encode item sequence, while the effects of users, i.e., collaborative signals, are omitted. SSE-PT <ref type="bibr" target="#b43">[44]</ref> implicitly models collaborative signals by directly adding the same user embedding into the sequence encoding. However, it fails to model the interactions between user and item, thus unable to explicitly express collaborative signals.</p><p>The second challenge is that it is hard to express the temporal effects of collaborative signals. In other words, it remains unclear how to measure the impacts of those signals from a temporal perspective. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, ğ‘– 1 is interacted with ğ‘¢ 2 and ğ‘¢ 4 at ğ‘¡ 1 , while ğ‘– 2 is interacted with them respectively at ğ‘¡ 3 and ğ‘¡ 4 . Since there is a lag, it is problematic to ignore the time gap and assume they are of equal contributions. We should use temporal information to infer the importance of those collaborative signals to the recommendation on ğ‘¡ 5 . Existing works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b35">36]</ref> assume that items appear discretely with equal time intervals. Thus, they only focus on the orders/positions of items in the sequence, which limits their capacity in expressing the temporal information. Some recent works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b49">50]</ref> also notice the importance of time span. But their models either fail to capture time differences between historical interactions or are unable to generalize to any unseen future timestamps or time difference, thus are still far from revealing the actual temporal effects of collaborative signals.  Current transformer-based models <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">36]</ref> adopt self-attention mechanism, which has query, key, and value inputs from item embeddings and employs dot-product to learn their correlation scores. The limitation is that self-attention is only able to capture item-item relationships in sequences. Additionally, they have no module to capture temporal correlations of items. To this end, we propose a new model Temporal Graph Sequential Recommender (TGSRec). It consists of two novel components: (1) the Temporal Collaborative Transformer (TCT) layer and (2) graph information propagation.</p><p>The first component advances current transformer-based models as it can explicitly model collaborative signals in sequences and express temporal correlations of items in sequences. To be more specific, TCT layer adopts collaborative attention among user-item interactions, where the query input to the collaborative attention is from the target node (user/item), while the key and value inputs are from connected neighbors. As such, TCT layer learns the importance of those interactions, thus well characterizing the collaborative signals. Moreover, TCT layer fuses the temporal information into the collaborative attention mechanism, which explicitly expresses the temporal effects of those interactions. Altogether, the TCT layer captures temporal collaborative signals.</p><p>The second module is devised upon our proposed Continuous-Time Bipartite Graph (CTBG). The CTBG consists of user/item nodes, and interaction edges with timestamps, as shown in Figure <ref type="figure" target="#fig_2">2a</ref>. Given timestamps, neighbor items of users preserve sequential patterns. We propagate temporal collaborative information learned around each node to surrounding neighbors over CTBG. Therefore, it unifies sequential patterns with temporal collaborative signals.</p><p>In this work, we propose to use temporal embeddings of nodes for recommendation, which are dynamic and inferred at specified timestamps. For example, at time ğ‘¡, we infer the temporal user embedding by aggregating the context. We illustrate the temporal inference of ğ‘¢ Extensive Experiments: We conduct a comparison experiment on five real-world datasets. Comprehensive experiments demonstrate the state-of-the-art performance of TGSRec and its effectiveness of modeling temporal collaborative signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we first review some related work, which includes sequential recommendation (SR), temporal information, and some graph-based recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sequential Recommendation</head><p>SR predicts the future items in the user shopping sequence by mining the sequential patterns. An initial solution to the SR problem is to build a Recurrent Neural Network (RNN) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55]</ref>. GRU4Rec <ref type="bibr" target="#b8">[9]</ref> is proposed to predict the next item in a session by employing the GRU modules. Later, a Hierarchical RNN <ref type="bibr" target="#b32">[33]</ref> is proposed to enhance the RNN model regarding the personalizing information. Additionally, LSTM <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b41">42]</ref> can be applied to explore both the long-term and short-term sequential patterns. Moreover, in order to capture the intent of users at local sub-sequence, NARM <ref type="bibr" target="#b17">[18]</ref> is proposed by combining the RNN model with attention weights. The major drawback of the RNN model is that it can only generate a single hidden vector, which limits its power to encode sequences <ref type="bibr" target="#b1">[2]</ref>.</p><p>Recently, owing to the success of self-attention model <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b51">52]</ref> in NLP tasks, a series of attention-based SR models are proposed <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43]</ref>. SASRec <ref type="bibr" target="#b11">[12]</ref> applies the transformer layer to assign weights to items in the sequence. Later, inspired by the BERT <ref type="bibr" target="#b2">[3]</ref> model, BERT4Rec <ref type="bibr" target="#b35">[36]</ref> is proposed with a bidirectional transformer layer. <ref type="bibr" target="#b27">[28]</ref> introduce the sequence to sequence training procedure in SR. SSE-PT <ref type="bibr" target="#b43">[44]</ref> designs a personalized transformer to improve the SR performance. ASReP <ref type="bibr" target="#b22">[23]</ref> proposes augmenting short sequences to alleviate the cold-start issue in Transformer. Ti-SASRec <ref type="bibr" target="#b18">[19]</ref> enhances SASRec with the time-interval information found in the training data. However, these models only focus on the item transitions within sequences, while unable to unify the important temporal collaborative signals with sequential patterns and are not generalized to unseen timestamps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Temporal Information</head><p>Previously mentioned SR works are specifically designed to capture sequential patterns, while ignoring the important temporal information <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>. In practice, the context of users and items changes over time, which is crucial for modeling the temporal dynamics in SR. TimeSVD++ <ref type="bibr" target="#b14">[15]</ref> is a representative work which models the temporal information into collaborative filtering (CF) method. It simply treats the bias as a function over time. BPTF <ref type="bibr" target="#b46">[47]</ref> extends matrix factorization to tensor factorization and uses time as the third dimension. MS-IPF <ref type="bibr" target="#b45">[46]</ref> defines a temporal graph, where it operates PageRank algorithm for recommendation. Recently, CDTNE <ref type="bibr" target="#b29">[30]</ref> is proposed by applying temporal random walk over its defined continuous-time dynamic network. TGAT <ref type="bibr" target="#b48">[49]</ref> also introduces temporal attention for learning dynamic graph embeddings. JODIE <ref type="bibr" target="#b16">[17]</ref> develops user and item RNNs to update user and item embeddings. Regarding the SR problem, a few recent works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b49">50]</ref> also notice the importance of temporal information. CTA <ref type="bibr" target="#b42">[43]</ref>, MTAM <ref type="bibr" target="#b10">[11]</ref>, and TiSASRec <ref type="bibr" target="#b18">[19]</ref> all consider to use time intervals between successive items in sequences. TASER <ref type="bibr" target="#b49">[50]</ref> encodes both the absolute time and relative time as vectors, which are processed to attention models to complete the SR task. However, these models are not able to unify temporal collaborative signals with sequential patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph-based Recommendation</head><p>Because we solve the SR problem based on the graph structure <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b53">54]</ref>, we also review some graph-based recommender system models <ref type="bibr">[7, 24-26, 30, 40]</ref>, especially those based on Graph Neural Network (GNN) methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b39">40]</ref>. Compared with directly learning from sequences, graph-based models can also capture the structural information <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref>. Both NGCF <ref type="bibr" target="#b39">[40]</ref> and LightGCN <ref type="bibr" target="#b6">[7]</ref> argue that graph-based models are able to effectively model collaborative signals, which is crucial in learning user/item embeddings. The successes of GNN in recommender systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref> provide simple yet effective methods in learning user/item embeddings from graphs. GNN models learn the embeddings by aggregating neighbors <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40]</ref>. Therefore, it is easy to stack multiple layers to learn both the first-order and high-order collaborative signals <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40]</ref>. CTDNE <ref type="bibr" target="#b29">[30]</ref> defines a temporal graph to learn dynamic embeddings of nodes. TGAT <ref type="bibr" target="#b48">[49]</ref> learns the dynamic graph embeddings based on the graph attention model. Basconv <ref type="bibr" target="#b24">[25]</ref> characterizes heterogeneous graphs to learn user/item embeddings. Those models argue that graph is powerful in modeling both the structural and temporal information. However, few works investigate the possibility of solving SR problems based on graphs. SR-GNN <ref type="bibr" target="#b44">[45]</ref> learns embeddings of session graphs by using a GNN to aggregate item embeddings but fails to model temporal collaborative signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DEFINITIONS AND PRELIMINARIES</head><p>In this section, we introduce some definitions and preliminaries. Different from using users' interactions sequences as inputs in SR, we introduce the Continuous-Time Bipartite Graph (CTBG) to represent all temporal interactions. Each edge in this graph has the timestamp as the attribute. The directly connected neighbors of every user/item node in this graph preserve the sequential order via the timestamps at edges. The formal definition of CTBG are given in the following: Definition 3.1 (Continuous-Time Bipartite Graph). A continuous time bipartite graph with ğ‘ nodes and ğ¸ edges for recommendations is defined as B = {U, I, E T }, where U and I are two disjoint node sets of users and items, respectively. Every edge ğ‘’ âˆˆ E T is denoted as a tuple ğ‘’ = (ğ‘¢, ğ‘–, ğ‘¡), where ğ‘¢ âˆˆ U, ğ‘– âˆˆ I, and ğ‘¡ âˆˆ R + as the edge attribute. Each triplet (ğ‘¢, ğ‘–, ğ‘¡) denotes the interaction of a user ğ‘¢ with item ğ‘– at timestamp ğ‘¡.</p><p>This paper focuses on the SR problem with continuous timestamps. An example of the CTBG is presented in Figure <ref type="figure" target="#fig_2">2a</ref>. Let I ğ‘¢ (ğ‘¡) denote the set of items interacted with the user ğ‘¢ before timestamp ğ‘¡, and I \ I ğ‘¢ (ğ‘¡) denote the remaining items. We defined the continuous-time sequential recommendation problem which we study in this paper as following: Definition 3.2 (Continuous-Time Recommendation). At a specific timestamp ğ‘¡, given user set U, item set I, and the associated CTBG, the continuous-time recommendation of ğ‘¢ is to generate a ranking list of items from I\I ğ‘¢ (ğ‘¡), where the items that ğ‘¢ is interested will be ranked top in the list.</p><p>Then, the SR problem is equivalent to make continuous-time recommendations on a set of future timestamps T ğ‘¢ for each user ğ‘¢: Definition 3.3 (Continuous-Time Seqential Recommendation). For a specific user ğ‘¢, given a set of future timestamps T ğ‘¢ &gt; ğ‘‡ , the continuous-time sequential recommendation for this user is to make a continuous-time recommendation for every timestamp ğ‘¡ âˆˆ T ğ‘¢ . This is a generalized definition compared with other works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28]</ref>. We explicitly consider timestamps, while others only care about the orders/positions. Therefore, differing from existing works using next-item prediction to evaluate sequential recommendation, future timestamps should be present to make a prediction. If timestamps are position numbers in sequences, the studied problem is reduced to the same definition as using only orders/positions information. Note that timestamp can be any real value, thus being continuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED MODEL</head><p>In this section, we present the TGSRec model, which unifies sequential patterns and temporal collaborative signals. The framework of the TGSRec model is presented in Figure <ref type="figure">3</ref>. There are three major components: 1) Embedding layer, which encodes nodes and timestamps in a consistent way to connect the SR problem with graph embedding method; 2) Temporal Collaborative Transformer (TCT) layer, which employs a novel temporal collaborative attention mechanism to discriminate temporal impacts of neighbors, and aggregates both node and time embeddings to infer the temporal node embedding; 3) Prediction layer, which utilizes output embeddings from the final TCT layer to calculate the score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Embedding Layer</head><p>We encode two types of embeddings in this paper, one being the long-term embeddings of nodes, and the other being the continuoustime embeddings of timestamps on edges.</p><p>4.1.1 Long-Term User/Item Embeddings. Long-term embeddings for users and items are necessary <ref type="bibr" target="#b3">[4]</ref> for long-term collaborative signals representation. In CTBG, it functions as node features and is optimized to model the holistic structural information. A user (item) node is parameterized by a vector ğ’† ğ‘¢ (ğ’† ğ‘– ) âˆˆ R ğ‘‘ . Since we learn embeddings for nodes in the CTBG, we retrieve the embedding of a node by indexing an embedding table ğ‘¬ = [ğ‘¬ U ; ğ‘¬ I ] âˆˆ R ğ‘‘Ã—|V | , where V = U âˆª I. Note that the embedding table ğ‘¬ serves as a starting state for the inference of temporal user/item embeddings. During the training process, ğ‘¬ will be optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Continuous-Time Embedding.</head><p>The continuous time encoding <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b49">50]</ref> behaves as a function that maps those scalar timestamps into vectors, i.e., Î¦ : ğ‘‡ â†¦ â†’ R ğ‘‘ ğ‘‡ , where ğ‘‡ âˆˆ R + . Based on previous SR models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50]</ref>, time span plays a vital component in expressing the temporal effects and uncovering sequential patterns. The time encoding function embeds timestamps into vectors so as to represent the time span as the dot product of corresponding encoded time embeddings. Therefore, we define the temporal effects as a function of time span in continuous time space: given a pair of interactions (ğ‘¢, ğ‘–, ğ‘¡ 1 ) and (ğ‘¢, ğ‘—, ğ‘¡ 2 ) of the same user, the temporal effect is defined as a function ğœ“ (ğ‘¡ 1 âˆ’ ğ‘¡ 2 ) â†¦ â†’ R, which is expressed as a kernel value of the time embeddings of ğ‘¡ 1 and ğ‘¡ 2 :</p><formula xml:id="formula_0">ğœ“ (ğ‘¡ 1 âˆ’ ğ‘¡ 2 ) = K (ğ‘¡ 1 , ğ‘¡ 2 ) = Î¦(ğ‘¡ 1 ) â€¢ Î¦(ğ‘¡ 2 ),<label>(1)</label></formula><p>where K is the temporal kernel and â€¢ denotes the dot product operation. The temporal effect ğœ“ (ğ‘¡ 1 âˆ’ ğ‘¡ 2 ) measures the temporal correlation between two timestamps. Moreover, the time encoding function should be generalized to any unseen timestamp such that any time span not found in training data can still be inferred by the encoded time embeddings. Unlike modeling the absolute time difference like <ref type="bibr" target="#b18">[19]</ref>, representing temporal effects as a kernel is generalized to any timestamp as it models the time representations directly. Therefore, the temporal effect of any pair of timestamps can be inductively inferred by the dot product of time representations.</p><p>Eq. ( <ref type="formula" target="#formula_0">1</ref>) can be achieved by a continuous and translation-invariant kernel K (ğ‘¡ 1 , ğ‘¡ 2 ) based on Bochner's Theorem <ref type="bibr" target="#b26">[27]</ref>. By explicitly representing the temporal features, the temporal embedding is:</p><formula xml:id="formula_1">Î¦(ğ‘¡) â†¦ â†’ âˆšï¸‚ 1 ğ‘‘ ğ‘‡ cos(ğœ” 1 ğ‘¡), sin(ğœ” 1 ğ‘¡), . . . , cos(ğœ” ğ‘‘ ğ‘‡ ğ‘¡), sin(ğœ” ğ‘‘ ğ‘‡ ğ‘¡) âŠ¤ ,<label>(2)</label></formula><p>where ğ = ğœ” 1 , . . . , ğœ” ğ‘‘ ğ‘‡ âŠ¤ are learnable and ğ‘‘ ğ‘‡ is the dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Temporal Collaborative Transformer</head><p>Next, we present the novel TCT layer of TGSRec. We intend to address two strengths of a TCT layer: (1) constructing information from both user/item embeddings and temporal embedding, which explicitly characterizes temporal effects of the correlations;</p><p>(2) a collaborative attention module, which advances existing selfattention mechanism by modeling the importance of user-item interactions, which is thus able to explicitly recognize collaborative signals. To achieve this, we first present the information construction and aggregation from a user perspective. Then, we introduce a novel collaborative attention mechanism to infer importance of interactions. Finally, we demonstrate how to generalize to items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Information</head><p>Construction. We construct input information of each TCT layer as the combination of long term node embeddings and time embeddings. As such, we can unify temporal information and collaborative signals. In particular, the query input information at the ğ‘™-th layer for user ğ‘¢ at time ğ‘¡ is:</p><formula xml:id="formula_2">ğ’‰ (ğ‘™âˆ’1) ğ‘¢ (ğ‘¡) = ğ’† (ğ‘™âˆ’1) ğ‘¢ (ğ‘¡)âˆ¥Î¦(ğ‘¡),<label>(3)</label></formula><p>where ğ‘™ = 1, 2, . . . , ğ¿. ğ’‰</p><formula xml:id="formula_3">(ğ‘™âˆ’1) ğ‘¢ (ğ‘¡) âˆˆ R ğ‘‘+ğ‘‘ ğ‘‡ is the information for ğ‘¢ at ğ‘¡, ğ’† (ğ‘™âˆ’1) ğ‘¢ (ğ‘¡) âˆˆ R ğ‘‘</formula><p>is the temporal embedding of ğ‘¢, and Î¦(ğ‘¡) âˆˆ R ğ‘‘ ğ‘‡ denotes the time vector of ğ‘¡. âˆ¥ denotes the concatenation operation. Other operations including summation are possible. However, we use concatenation for simplicity. It also provides intuitive interpretation in the attention, as shown in Eq. <ref type="bibr" target="#b6">(7)</ref>. Note that when ğ‘™ = 1, it is the first TCT layer. The temporal embedding ğ’† (0) ğ‘¢ (ğ‘¡) = ğ‘¬ ğ‘¢ , i.e., the long-term user embedding. When ğ‘™ &gt; 1, the temporal embedding is generated from the previous TCT layer.</p><p>In addition to the query node itself, to we also propagate temporal collaborative information from its neighbors. We randomly sample ğ‘† different interactions of ğ‘¢ before time ğ‘¡ as N ğ‘¢ (ğ‘¡) = {(ğ‘–, ğ‘¡ ğ‘  )|(ğ‘¢, ğ‘–, ğ‘¡ ğ‘  ) âˆˆ E ğ‘¡ and ğ‘¡ ğ‘  &lt; ğ‘¡ }. The input information at the ğ‘™-th layer for each </p><p>ğ‘¢ 4 (ğ‘¡ 5 ). The TCT layer samples its neighbor nodes and edges. Timestamps on edges are encoded as vectors by using mapping function Î¦. Node embeddings for the first TCT layer are long-term embeddings. Node embeddings for other TCT layers (e.g. layer 2) are propagated from the previous TCT layer, thus being temporal node embeddings.</p><p>(ğ‘–, ğ‘¡ ğ‘  ) pair is:</p><formula xml:id="formula_5">ğ’‰ (ğ‘™âˆ’1) ğ‘– (ğ‘¡ ğ‘  ) = ğ’† (ğ‘™âˆ’1) ğ‘– (ğ‘¡ ğ‘  )âˆ¥Î¦(ğ‘¡ ğ‘  ),<label>(4)</label></formula><p>where ğ’‰ ğ‘– (ğ‘¡ ğ‘  ) is the information for item ğ‘– at ğ‘¡ ğ‘  , ğ’† ğ‘– (ğ‘¡ ğ‘  ) denotes the temporal embedding of ğ‘– at ğ‘¡ ğ‘  . Again, note that when ğ‘™ = 1, ğ’†</p><p>ğ‘– (ğ‘¡ ğ‘  ) = ğ‘¬ ğ‘– , i.e., the long-term item embedding. When ğ‘™ &gt; 1, the temporal embedding is output from the previous TCT layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Information</head><p>Propagation. After constructing the information, we propagate the information of sampled neighbors N ğ‘¢ (ğ‘¡) to infer the temporal embeddings. Since the neighbors are involving with time ğ‘¡, in this way, we can unify the sequential patterns with temporal collaborative signals. We compute the linear combination of the information from all sampled interactions as:</p><formula xml:id="formula_7">ğ’† (ğ‘™) N ğ‘¢ (ğ‘¡) = âˆ‘ï¸ (ğ‘–,ğ‘¡ ğ‘  ) âˆˆğ‘ ğ‘¢ (ğ‘¡ ) ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  )ğ‘¾ (ğ‘™) ğ‘£ ğ’‰ (ğ‘™âˆ’1) ğ‘– (ğ‘¡ ğ‘  ),<label>(5)</label></formula><p>where ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) 1 denotes the importance of an interaction (ğ‘¢, ğ‘–, ğ‘¡ ğ‘  ) and ğ‘¾ ğ‘£ âˆˆ R ğ‘‘Ã—(ğ‘‘+ğ‘‘ ğ‘‡ ) is the linear transformation matrix. ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) represents the impact of a historical interaction (ğ‘¢, ğ‘–, ğ‘¡ ğ‘  ) to the temporal inference of ğ‘¢ at time ğ‘¡, which is calculated by the temporal collaborative attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Temporal Collaborative Attention.</head><p>We adopt the novel temporal collaborative attention mechanism to measure the weights ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ), which considers both neighboring interactions and the temporal information on edges. Both factors contribute to the importance of historical interactions. Thus, it is a better mechanism to capture temporal collaborative signals than self-attention mechanism that only models item-item correlations. The attention weight ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) is formulated as follows:</p><formula xml:id="formula_8">ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) = 1 âˆšï¸ ğ‘‘ + ğ‘‘ ğ‘‡ ğ‘¾ (ğ‘™) ğ‘˜ ğ’‰ (ğ‘™âˆ’1) ğ‘– (ğ‘¡ ğ‘  ) âŠ¤ ğ‘¾ (ğ‘™) ğ‘ ğ’‰ (ğ‘™âˆ’1) ğ‘¢ (ğ‘¡),<label>(6)</label></formula><p>where ğ‘¾ (ğ‘™)</p><p>ğ‘˜ and ğ‘¾ (ğ‘™)</p><p>ğ‘ are both linear transformation matrices, and the factor 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>âˆš</head><p>ğ‘‘+ğ‘‘ ğ‘‡ protects the dot-product from growing large with high dimensions. We adopt dot-product attention because if we ignore transformation matrices and the scalar factor, based on Eq. ( <ref type="formula" target="#formula_2">3</ref>) 1 ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) also has a superscript of the layer number ğ‘™, which is ignored for simplicity.</p><p>and Eq. ( <ref type="formula" target="#formula_5">4</ref>), the right-hand side of Eq. ( <ref type="formula" target="#formula_8">6</ref>) can be rewritten as:</p><formula xml:id="formula_9">ğ’† (ğ‘™âˆ’1) ğ‘¢ (ğ‘¡) â€¢ ğ’† (ğ‘™âˆ’1) ğ‘– (ğ‘¡ ğ‘  ) + Î¦(ğ‘¡) â€¢ Î¦(ğ‘¡ ğ‘  ),<label>(7)</label></formula><p>where the first term denotes the user-item collaborative signal, and the second term models the temporal effect according to Eq. ( <ref type="formula" target="#formula_0">1</ref>). With more stacked layers, collaborative signals and temporal effects are entangled and tightly connected. Hence, the dot-product attention can characterize impacts of temporal collaborative signals.</p><p>Hereafter, we normalize the attention weights across all sampled interactions by employing a softmax function:</p><formula xml:id="formula_10">ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) = exp ğœ‹ ğ‘¢ ğ‘¡ (ğ‘–, ğ‘¡ ğ‘  ) (ğ‘– â€² ,ğ‘¡ â€² ğ‘  ) âˆˆğ‘ ğ‘¢ (ğ‘¡ ) exp ğœ‹ ğ‘¢ ğ‘¡ (ğ‘– â€² , ğ‘¡ â€² ğ‘  ) .<label>(8)</label></formula><p>Moreover, the computation is implemented by packing the information of all sampled interactions. To be more specific, we stack the information (Eq. ( <ref type="formula" target="#formula_5">4</ref>)) of all sampled interactions as a matrix ğ‘¯ (ğ‘¡), which are respectively the key, value and query input for the temporal collaborative attention module. We illustrate this in Figure <ref type="figure">3</ref> as green blocks. For simplicity and without ambiguity, we ignore the superscripts and time ğ‘¡ and combine Eq. ( <ref type="formula" target="#formula_8">6</ref>) and Eq. ( <ref type="formula" target="#formula_10">8</ref>). Then, we can rewrite the Eq. ( <ref type="formula" target="#formula_7">5</ref>) as:</p><formula xml:id="formula_11">ğ’† N ğ‘¢ = ğ‘½ ğ‘¢ â€¢ Softmax ğ‘² âŠ¤ ğ‘¢ ğ’’ ğ‘¢ âˆšï¸ ğ‘‘ + ğ‘‘ ğ‘‡ ,<label>(9)</label></formula><p>which is in the form of dot-product attention in Transformer <ref type="bibr" target="#b37">[38]</ref>. Therefore, we can safely apply the multi-head attention operation and concatenate the output from each head as the information for aggregation, which is presented in Figure <ref type="figure">3</ref>. Note that our attention is not a self-attention but a temporal collaborative attention, which jointly models user-item interactions and temporal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Information Aggregation.</head><p>To output the temporal node embedding, the final step of a TCT layer is to aggregate the query information in Eq. ( <ref type="formula" target="#formula_2">3</ref>) and the neighbor information in Eq. ( <ref type="formula" target="#formula_7">5</ref>). We concatenate and send them to a feed-forward neural network (FFN):</p><formula xml:id="formula_12">ğ’† (ğ‘™) ğ‘¢ (ğ‘¡) = FFN ğ’† (ğ‘™) N ğ‘¢ (ğ‘¡)âˆ¥ğ’‰ (ğ‘™âˆ’1) ğ‘¢ (ğ‘¡) ,<label>(10)</label></formula><p>where ğ’†</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(ğ‘™)</head><p>ğ‘¢ (ğ‘¡) is the temporal embedding of ğ‘¢ at ğ‘¡ on ğ‘™-th layer, and FFN consists of two linear transformation layers with a ReLU activation function in between <ref type="bibr" target="#b37">[38]</ref>. The output temporal embedding ğ’† (ğ‘™) ğ‘¢ (ğ‘¡) can either be sent to the next layer or output as the final temporal node embedding for prediction. 4.2.5 Generalization to items. Though we only present the TCT layer from the user query perspective, it is analogous if the query is an item at a specific time. We only need to alternate the user query information to the item query information, and change the neighbor information in Eq. ( <ref type="formula" target="#formula_5">4</ref>) and Eq. ( <ref type="formula" target="#formula_7">5</ref>) accordingly as user-time pairs. Then, we can make an inference of the temporal embedding of item ğ‘– at time ğ‘¡ as ğ’† (ğ‘™) ğ‘– (ğ‘¡), which is sent to the next layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Prediction</head><p>The TGSRec model consists of ğ¿ TCT layers. For each test triplet (ğ‘¢, ğ‘–, ğ‘¡), it yields temporal embeddings for both ğ‘¢ and ğ‘– at ğ‘¡ on the last TCT layer, denoting as ğ’† (ğ¿) ğ‘¢ (ğ‘¡) and ğ’† (ğ¿) ğ‘– (ğ‘¡), respectively. Then, the prediction score is:</p><formula xml:id="formula_13">ğ‘Ÿ (ğ‘¢, ğ‘–, ğ‘¡) = ğ’† (ğ¿) ğ‘¢ (ğ‘¡) â€¢ ğ’† (ğ¿) ğ‘– (ğ‘¡),<label>(11)</label></formula><p>where ğ‘Ÿ (ğ‘¢, ğ‘–, ğ‘¡) denotes the score to recommend ğ‘– for ğ‘¢ at time ğ‘¡. With the generalized continuous-time embeddings and the proposed TCT layers, we can generalize and infer user/item embeddings at any timestamp, thus making multiple steps recommendation feasible while existing work only predicts next item. Recall that based on the Definition 3.3, we recommend each user a ranking list of items at the given timestamp. Therefore, we use Eq. ( <ref type="formula" target="#formula_13">11</ref>) to calculate scores of all candidate items and sort them by scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Model Optimization</head><p>To learn the model parameters, we use the pairwise BPR loss <ref type="bibr" target="#b33">[34]</ref>, which is widely used for top-N recommendation. The pairwise BPR loss assumes that the observed implicit feedback items have greater prediction scores than those unobserved and is also designed for ranking based top-N recommendation. The objective function is:</p><formula xml:id="formula_14">L ğ‘ğ‘ğ‘Ÿ = âˆ‘ï¸ (ğ‘¢,ğ‘–,ğ‘—,ğ‘¡ ) âˆˆ O ğ‘‡ âˆ’logğœ (ğ‘Ÿ (ğ‘¢, ğ‘–, ğ‘¡) âˆ’ ğ‘Ÿ (ğ‘¢, ğ‘—, ğ‘¡)) + ğœ†||Î˜|| 2 2 , (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where O ğ‘‡ denotes the training samples, Î˜ includes all learnable parameter, and ğœ (â€¢) is a sigmoid function. The training samples O ğ‘‡ = {(ğ‘¢, ğ‘–, ğ‘—, ğ‘¡)|(ğ‘¢, ğ‘–, ğ‘¡) âˆˆ E ğ‘‡ , ğ‘— âˆˆ I \ I ğ‘¢ (ğ‘¡)}, where the positive interaction (ğ‘¢, ğ‘–, ğ‘¡) comes from the edge set E ğ‘‡ of CTBG, the negative item ğ‘— is sampled from unobserved items I \ I ğ‘¢ (ğ‘¡) of user ğ‘¢ at timestamp ğ‘¡; Î˜ includes long-term embedding ğ¸, time embedding parameter ğœ”, and all linear transformation matrices. The loss is optimized via mini-batch Adam <ref type="bibr" target="#b12">[13]</ref> with adaptive learning rate. Alternatively, we can optimize the model with a Binary Cross Entropy (BCE) loss as:</p><formula xml:id="formula_16">L ğ‘ğ‘ğ‘’ = âˆ‘ï¸ (ğ‘¢,ğ‘–,ğ‘—,ğ‘¡ ) âˆˆ O ğ‘‡ log ğœ (ğ‘Ÿ (ğ‘¢, ğ‘–, ğ‘¡)) + log ğœ (1 âˆ’ ğ‘Ÿ (ğ‘¢, ğ‘—, ğ‘¡)) + ğœ†||Î˜|| 2 2 ,<label>(13)</label></formula><p>which is compared with BPR loss in experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we present the experimental setups and results to demonstrate the effectiveness of TGSRec. The experiments answer the following Research Questions (RQs): â€¢ RQ1: Does TGSRec yield better recommendation? â€¢ RQ2: How do different hyper-parameters (e.g., number of neighbors ğ‘†, etc.) affect the performance of TGSRec? â€¢ RQ3: How do different modules (e.g., temporal collaborative attention, etc.) affect the performance of TGSRec? â€¢ RQ4: Can TGSRec effectively unify sequential patterns and temporal collaborative signals? (Reveal temporal correlations)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We conduct our experiments on four Amazon review datasets <ref type="bibr" target="#b28">[29]</ref> and MovieLens ML-100K dataset <ref type="bibr" target="#b5">[6]</ref>. The Amazon datasets are collected from different domains <ref type="foot" target="#foot_2">3</ref> , from the Amazon website during May 1996 to July 2014. The Movie Lens dataset is collected from September 19th, 1997 through April 22nd, 1998. We use Unix timestamps on all datasets. For each dataset, we chronologically split for train/validation/test in 80%/10%/10% ratio based on the interaction timestamps. More details, such as data descriptions and statistics, are presented in the Table <ref type="table" target="#tab_1">1</ref>. We can find amazon datasets are much sparser and their time spans are much longer compared with ML-100K dataset. For Amazon related datasets, the time intervals of successive interactions are typically in days, while ML-100k has shorter time intervals, ranging from seconds to days. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Settings</head><p>5.2.1 Baselines. We compared TGSRec with the state-of-the-art methods in three different groups. Static models: Static models ignore the temporal information and generate static user/item embeddings for a recommendation. We compare with the most standard baseline BPRMF <ref type="bibr" target="#b33">[34]</ref>, and also compare with a recent GNN-based model LightGCN <ref type="bibr" target="#b6">[7]</ref>. Temporal models: We compare some relevant temporal methods, such as CTDNE <ref type="bibr" target="#b29">[30]</ref> and one recent model TiSASRec <ref type="bibr" target="#b18">[19]</ref>, which utilize time information. We also try to compare with JODIE <ref type="bibr" target="#b16">[17]</ref>. However, we do not report it because has out-of-memory errors on most datasets. Transformer-based SR models: Since our model is built upon the transformer, we mainly focus on comparing with the recent transformer-based SR methods,   which are SASRec <ref type="bibr" target="#b11">[12]</ref>, BERT4Rec <ref type="bibr" target="#b35">[36]</ref>, SSE-PT <ref type="bibr" target="#b43">[44]</ref>, and TiSAS-Rec <ref type="bibr" target="#b18">[19]</ref>. Other SR models: In addition, we also compare with other type of SR models, i.e., FPMC <ref type="bibr" target="#b34">[35]</ref>, GRU4Rec <ref type="bibr" target="#b8">[9]</ref>, Caser <ref type="bibr" target="#b36">[37]</ref>, and SR-GNN <ref type="bibr" target="#b44">[45]</ref>, for comprehensive study.</p><p>For each testing interaction (ğ‘¢, ğ‘–, ğ‘¡ ğ‘¡ğ‘’ğ‘ ğ‘¡ ), our continuous-time sequential recommendation setting allows models to use any history interactions {(ğ‘¢, ğ‘–, ğ‘¡)|ğ‘¡ &lt; ğ‘¡ ğ‘¡ğ‘’ğ‘ ğ‘¡ } during the prediction stage, regardless of whether the historical interactions are in training portion, validation part or even in testing set. However, all parameters of models are only learned from the training data.</p><p>We implement TGSRec with Pytorch in a Nvidia 1080Ti GPU. We grid search all parameters and report the test performance based on the best validation results. For all models, we search for the dimensions of embeddings ğ‘‘ in range of <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr">64]</ref> and we tune the learning rate in [10 âˆ’2 , 10 âˆ’3 , 10 âˆ’4 ], search the L2 regularization weight from [5 Ã— 10 âˆ’1 , 10 âˆ’1 , 10 âˆ’2 , 10 âˆ’3 ]. For sequential methods, we search the maximum length of sequence in <ref type="bibr" target="#b49">[50,</ref><ref type="bibr">100]</ref>, number of layers from <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>, and number of heads in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Evaluation</head><p>Protocol. All models will generate a ranking list of items for each testing interaction. Each evaluation metric is averaged over the total number of interactions as the final reported result. In order to accelerate the evaluation, we sample 1,000 negative items for evaluation instead of full set of negative items. For each interaction (ğ‘¢, ğ‘–, ğ‘¡) in validation/test sets, we treat items that ğ‘¢ has no interactions with before ğ‘¡ as negative items. Regarding the sampling bias for evaluation <ref type="bibr" target="#b15">[16]</ref>, we apply the unbiased estimator in <ref type="bibr" target="#b15">[16]</ref> to correct the sampled ranks. We evaluate the top-N recommendation performance by standard ranking-based evaluation metrics Recall@N, NDCG@N, and Mean Reciprocal Rank (MRR). We set N to be either 10 or 20 for a comprehensive comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Performance Comparison (RQ1)</head><p>We compare the performance of all models and demonstrate the superiority of TGSRec. We report the Recall and MRR of all models in Table <ref type="table" target="#tab_2">2</ref>. Additionally, we visualize the comparisons of NDCG in Figure <ref type="figure" target="#fig_6">4</ref>. We have the following observations:</p><p>â€¢ TGSRec consistently and significantly outperforms all baselines in all datasets. In particular, for absolute performance improvement gains relative to the 2nd best, TGSRec achieves 22.51%, 16.90% and 22.15% absolute gains at recall@10, recall@20, and MRR, respectively. TGSRec also significantly outperforms others in NDCG, as shown in Figure <ref type="figure" target="#fig_6">4</ref>. Several factors together determine the superiority of TGSRec: (1) TGSRec captures temporal collaborative signals;</p><p>(2) TGSRec explicitly expresses temporal effects; and (3) TGSRec stacks multiple TCT layers to propagate the information. â€¢ Those static methods achieve the worst performance among all models. A simple GRU4Rec even performs 10 times better than them. This indicates that static embeddings fail to utilize the temporal information, limiting its recommendation ability in SR. Thus, it is important to model dynamics. â€¢ The CDTNE performs better than Caser and GRU4Rec in Tools and Baby datasets. This suggests the benefit of modeling temporal information with a graph. But it is still much worse than those transformer-based methods, which again proves the strength of transformer in encoding sequences. We also notice the poor performance of SR-GNN. We analyze the data and find time intervals between successive interactions vary a lot. Since SR-GNN is originally designed for session-based sequences, it is not suitable for SR with a long time span. â€¢ The transformer-based SR methods consistently outperform all other types of baselines, which demonstrates the effectiveness of using transformer structure to encode sequence. Among them, TiSASRec is better than SASRec on two datasets, which proves the effectiveness of using time information. But it is still far worse than TGSRec. The reason is twofold. One is that only the interval information is not enough to unify the temporal information with sequential patterns. The other is that the proposed temporal collaborative attention in TCT layer captures more precise and generalized temporal effects. We find that BERT4Rec is better than the other baselines on the Tools dataset but not better on other datasets. Since the main difference between BERT4Rec and SASRec is the bi-directional sequence encoding, it may break causal relations among items within a sequence. The TGSRec performs much better than SR models, showing the necessity of unifying sequential patterns and temporal collaborative signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Parameter Sensitivity (RQ2)</head><p>In this section, we conduct sensitivity analyses of the hyperparameters of TGSRec, including the number of layers ğ¿, embedding size ğ‘‘, and the number of neighbors ğ‘†. The results are reported in Figure <ref type="figure" target="#fig_7">5</ref>.</p><p>The number of layers. The number of TCT layers ğ¿ is searched from {0, 1, 2}. The results are shown in the top row of Figure <ref type="figure" target="#fig_7">5</ref>.</p><p>When ğ¿ = 0, TGSRec has no TCT layer, thus unable to infer temporal embeddings. We can observe it performs the worst on all dataset, which justify the benefit of temporal inference. When ğ¿ = 1, it makes temporal inference, but without propagation to the next layer. Therefore, it still performs worse than ğ¿ = 2 on most datasets. When ğ¿ = 2, it can not only make temporal inference, but also propagate the information to capture high-order signals, which alleviates the data sparsity problem.</p><p>Embedding size. The embedding size ğ‘‘ of TCT layers is searched from {8, 16, 32, 64}, which is presented at the mid-row in Figure <ref type="figure" target="#fig_7">5</ref>.</p><p>We can find that the performance increases as the embedding size enlarges. However, when the embedding size is too large, e.g., ğ‘‘ = 64, the performance drops, which results from the over-fitting problem because of too many parameters. Number of neighbors. The number of neighbors ğ‘† is searched in {5, 10, 20}, which is illustrated in the bottom row of Figure <ref type="figure" target="#fig_7">5</ref>. We can observe that TGSRec has performance gains on most datasets as the number of neighbors grows. It is because more neighbors can provide more information for encoding both sequences and temporal collaborative signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study (RQ3 &amp; RQ4)</head><p>In this section, we conduct experiments to analyze different components in TGSRec. We develop several variants to better understand their effectiveness. Table <ref type="table" target="#tab_3">3</ref> shows the performance w.r.t. Recall@10 of the default TGSRec and other variants. We label each row with an index number for quick reference. The default is TGSRec with all components and labeled as 0. We develop the variants by substituting some components, which are temporal collaborative attention (1-2), continuous-time embeddings <ref type="bibr" target="#b2">(3)</ref><ref type="bibr" target="#b3">(4)</ref><ref type="bibr" target="#b4">(5)</ref>, and loss function (6): Temporal collaborative attention. We replace the proposed temporal collaborative attention of sampled neighbors with a mean pooling or LSTM module, both of which are widely used to encode sequences. Results are labeled as (1) and (2) in Table <ref type="table" target="#tab_3">3</ref>. We can observe that substituting collaborative attention with a mean pooling layer severely spoils the performance. Compared with that, the adoption of LSTM is much better, indicating the necessity of encoding sequential patterns by considering item transitions. However, both of them are worse than the default one, which implies the advantage of temporal collaborative attention in encoding sequences. Continuous-time embedding. We use three variants to verify the efficacy of the time mapping function Î¦. The first variant is that we sample ğœ” in Eq. ( <ref type="formula" target="#formula_1">2</ref>) directly from a normal distribution. The second and third variants replace the Î¦ with a learnable positional embedding as in <ref type="bibr" target="#b11">[12]</ref> and emptying all zeros, respectively. The results are labeled as (3) âˆ’ (5) in Table <ref type="table" target="#tab_3">3</ref>. Because of the better performance of position embedding compared with empty embedding, we can conclude that TGSRec has the ability to encode sequential patterns. In addition, we also find that even a fixed ğœ” to learn</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A toy example of temporal collaborative signals. Given the items that users ğ‘¢ 1 , ğ‘¢ 2 , ğ‘¢ 3 and ğ‘¢ 4 like in the past timestamps ğ‘¡ 1 , ğ‘¡ 2 , ğ‘¡ 3 and ğ‘¡ 4 , the target is to recommend an item to ğ‘¢ 4 at ğ‘¡ 5 as the next item after ğ‘– 2 .</figDesc><graphic url="image-1.png" coords="2,85.65,83.69,176.54,90.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The associated CTBG of Figure 1 and the inference of temporal embeddings of ğ‘¢ 4 and ğ‘– 4 at ğ‘¡ 5 .</figDesc><graphic url="image-2.png" coords="2,327.11,90.10,99.87,53.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>4 and ğ‘– 4 at time ğ‘¡ 5 in Figure 2b. The temporal embeddings are inferred by our proposed TCT layer. It uses temporal information to discriminate impacts of those historical interactions and makes inferences of temporal node embeddings. The contributions of this paper are as follows: Graph Sequential Recommendation: We connect the SR problem with graph embedding methods, which focuses on unifying the sequential patterns and temporal collaborative signals. Temporal Collaborative Transformer: We propose a novel temporal collaborative attention mechanism to infer temporal node embeddings, which jointly models collaborative signals and temporal effects. This overcomes the inadequacy of the traditional self-attention mechanism on capturing the temporal effects and user-item collaborative signals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>âˆˆ R (ğ‘‘+ğ‘‘ ğ‘‡ )Ã—ğ‘† , as illustrated 2 in Figure3. We de-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: NDCG@10 Performance in all Datasets. We ignore other methods because of their low values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Recall@10 w.r.t. ğ¿, ğ‘‘ and ğ‘† on 5 datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 3: The framework of TGSRec. The query node is ğ‘¢ 4 , whose final temporal embedding at time ğ‘¡ 5 is ğ’‰</figDesc><table><row><cell>ğ‘– 1 ğ‘– 2 ğ‘– 4 ğ‘– 3</cell><cell>ğ‘¡ 4 ğ‘¡ 3</cell><cell>ğ‘¡ 5</cell><cell>ğ‘¢ 1 ğ‘¢ 2 ğ‘¢ 3 ğ‘¢ 4</cell><cell>Neighbor Sampling ğ‘¢ 4 ğ‘– 1 ğ‘¡ 3 ğ‘– 2 ğ‘¡ 4 ğ‘¡ 5</cell><cell>ğ’† ğ‘¢ 4 (ğŸ) ğ’† ğ‘– 2 ğŸ ğ’† ğ‘– 1 ğŸ</cell><cell>Temporal Collaborative Transformer (TCT) -layer 1 Temporal Collaborative Attention ğ›Ÿ(ğ‘¡ 5 ) ğ›Ÿ(ğ‘¡ 3 ) ğ›Ÿ(ğ‘¡ 4 ) key value query Concat ğ‘¯ ğ’©ğ‘¢ 4 ğŸ (ğ’•ğŸ“) Linear Linear Linear</cell><cell>FFN ğ‘¢ 1 ğ‘¢ 2 ğ‘¢ 3 ğ‘¢ 4</cell><cell>propagation</cell><cell>ğ’† ğ‘¢4 ğŸ (ğ’• ğŸ“ ) ğ’† ğ‘–2 ğŸ (ğ’• ğŸ’ ) ğ’† ğ‘–1 ğŸ (ğ’• ğŸ‘ )</cell><cell>TCT -layer 2 ğ›Ÿ(ğ‘¡ 5 ) ğ›Ÿ(ğ‘¡ 3 ) ğ›Ÿ(ğ‘¡ 4 ) Linear Linear Linear</cell><cell>Temporal Collaborative Attention</cell><cell>Concat FFN</cell><cell>â€¦</cell><cell>L TCT -Layer</cell><cell>â€¦</cell><cell>ğ’† ğ‘¢4 ğ‘³ (ğ’• ğŸ“ ) ğ’† ğ‘– 4 ğ‘³ (ğ’• ğŸ“ ) Prediction</cell><cell>BPR Loss</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets.</figDesc><table><row><cell>Dataset</cell><cell>Toys</cell><cell>Baby</cell><cell>Tools</cell><cell>Music</cell><cell>ML100K</cell></row><row><cell>#Users</cell><cell>17,946</cell><cell>17,739</cell><cell>15,920</cell><cell>4,652</cell><cell>943</cell></row><row><cell>#Items</cell><cell>11,639</cell><cell>6,876</cell><cell>10,043</cell><cell>3,051</cell><cell>1,682</cell></row><row><cell>#Edges</cell><cell cols="3">154,793 146,775 127,784</cell><cell>54,932</cell><cell>48,569</cell></row><row><cell>#Train</cell><cell cols="3">134,632 128,833 107,684</cell><cell>51,765</cell><cell>80,003</cell></row><row><cell>#Valid</cell><cell>11,283</cell><cell>10,191</cell><cell>10,847</cell><cell>2,183</cell><cell>1,516</cell></row><row><cell>#Test</cell><cell>8,878</cell><cell>7,751</cell><cell>9,253</cell><cell>984</cell><cell>1,344</cell></row><row><cell>Density</cell><cell>0.07%</cell><cell>0.12%</cell><cell>0.08%</cell><cell>0.38%</cell><cell>6.30%</cell></row><row><cell cols="6">Avg. Int. 85 days 61 days 123 days 104 days 4.8 hours</cell></row></table><note>"Av. Int. " denotes average time interval.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overall Performance w.r.t. Recall@{10,20} and MRR.</figDesc><table><row><cell cols="2">Datasets</cell><cell>Metric</cell><cell>BPR</cell><cell cols="9">LightGCN SR-GNN GRU4Rec Caser SSE-PT BERT4Rec SASRec TiSASRec CDTNE TGSRec Improv.</cell></row><row><cell></cell><cell></cell><cell cols="2">Recall@10 0.0021</cell><cell>0.0016</cell><cell>0.0020</cell><cell>0.0274</cell><cell>0.0138 0.1213</cell><cell>0.1273</cell><cell>0.1452</cell><cell>0.1361</cell><cell>0.0016</cell><cell>0.3650</cell><cell>0.2198</cell></row><row><cell cols="2">Toys</cell><cell cols="2">Recall@20 0.0036</cell><cell>0.0026</cell><cell>0.0033</cell><cell>0.0288</cell><cell>0.0238 0.1719</cell><cell>0.1865</cell><cell>0.2044</cell><cell>0.1931</cell><cell>0.0045</cell><cell>0.3714</cell><cell>0.1670</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell>0.0024</cell><cell>0.0018</cell><cell>0.0018</cell><cell>0.0277</cell><cell>0.0082 0.0595</cell><cell>0.0643</cell><cell>0.0732</cell><cell>0.0671</cell><cell>0.0025</cell><cell>0.3661</cell><cell>0.2929</cell></row><row><cell></cell><cell></cell><cell cols="2">Recall@10 0.0028</cell><cell>0.0036</cell><cell>0.0030</cell><cell>0.0036</cell><cell>0.0077 0.0911</cell><cell>0.0884</cell><cell>0.0975</cell><cell>0.1040</cell><cell>0.0218</cell><cell>0.2235</cell><cell>0.1195</cell></row><row><cell cols="2">Baby</cell><cell cols="2">Recall@20 0.0039</cell><cell>0.0045</cell><cell>0.0062</cell><cell>0.0048</cell><cell>0.0193 0.1418</cell><cell>0.1634</cell><cell>0.1610</cell><cell>0.1662</cell><cell>0.0292</cell><cell>0.2295</cell><cell>0.0663</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell>0.0019</cell><cell>0.0024</cell><cell>0.0024</cell><cell>0.0028</cell><cell>0.0071 0.0434</cell><cell>0.0511</cell><cell>0.0455</cell><cell>0.0521</cell><cell>0.0157</cell><cell>0.2147</cell><cell>0.1626</cell></row><row><cell></cell><cell></cell><cell cols="2">Recall@10 0.0023</cell><cell>0.0021</cell><cell>0.0051</cell><cell>0.0048</cell><cell>0.0077 0.0775</cell><cell>0.1296</cell><cell>0.0913</cell><cell>0.0946</cell><cell>0.0186</cell><cell>0.2457</cell><cell>0.1161</cell></row><row><cell cols="2">Tools</cell><cell cols="2">Recall@20 0.0036</cell><cell>0.0035</cell><cell>0.0092</cell><cell>0.0059</cell><cell>0.0161 0.1155</cell><cell>0.1784</cell><cell>0.1337</cell><cell>0.1356</cell><cell>0.0271</cell><cell>0.2559</cell><cell>0.0775</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell>0.0026</cell><cell>0.0023</cell><cell>0.0028</cell><cell>0.0051</cell><cell>0.0068 0.0419</cell><cell>0.0628</cell><cell>0.0460</cell><cell>0.0480</cell><cell>0.0203</cell><cell>0.2468</cell><cell>0.1840</cell></row><row><cell></cell><cell></cell><cell cols="2">Recall@10 0.0122</cell><cell>0.0142</cell><cell>0.0051</cell><cell>0.0549</cell><cell>0.0183 0.0915</cell><cell>0.1352</cell><cell>0.1372</cell><cell>0.1372</cell><cell>0.0071</cell><cell>0.5935</cell><cell>0.4563</cell></row><row><cell cols="2">Music</cell><cell cols="2">Recall@20 0.0152</cell><cell>0.0183</cell><cell>0.0092</cell><cell>0.0589</cell><cell>0.0346 0.1494</cell><cell>0.2093</cell><cell>0.2094</cell><cell>0.1951</cell><cell>0.0163</cell><cell>0.5986</cell><cell>0.3892</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell>0.0057</cell><cell>0.0064</cell><cell>0.0028</cell><cell>0.0540</cell><cell>0.0106 0.0423</cell><cell>0.0824</cell><cell>0.0768</cell><cell>0.0681</cell><cell>0.0037</cell><cell>0.3820</cell><cell>0.2996</cell></row><row><cell></cell><cell></cell><cell cols="2">Recall@10 0.0461</cell><cell>0.0565</cell><cell>0.0045</cell><cell>0.0996</cell><cell>0.0246 0.1079</cell><cell>0.1116</cell><cell>0.09450</cell><cell>0.1332</cell><cell>0.0350</cell><cell>0.3118</cell><cell>0.1786</cell></row><row><cell cols="2">ML100k</cell><cell cols="2">Recall@20 0.0766</cell><cell>0.0960</cell><cell>0.0060</cell><cell>0.1168</cell><cell>0.0417 0.1801</cell><cell>0.1786</cell><cell>0.1808</cell><cell>0.2232</cell><cell>0.0536</cell><cell>0.3252</cell><cell>0.1020</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell>0.0213</cell><cell>0.0252</cell><cell>0.0012</cell><cell>0.0938</cell><cell>0.0147 0.0519</cell><cell>0.0600</cell><cell>0.0448</cell><cell>0.0605</cell><cell>0.0162</cell><cell>0.2416</cell><cell>0.1478</cell></row><row><cell>0.2 0.3</cell><cell cols="2">Toys BERT4Rec SSE-PT SASRec TiSASRec TGSRec</cell><cell>.3649</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.1</cell><cell cols="2">.0743 .0666 .0816 .0754</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablation analysis (Recall@10) on five datasets. Bold score indicates performance better than the default version, while â†“ indicates a performance drop more than 50%.</figDesc><table><row><cell>Architecture</cell><cell>Toys</cell><cell>Baby</cell><cell>Tools</cell><cell cols="2">Music ML100K</cell></row><row><cell>(0) Default</cell><cell cols="4">0.3649 0.2235 0.3623 0.5935</cell><cell>0.3118</cell></row><row><cell>(1) Mean</cell><cell cols="5">0.0027â†“ 0.0210â†“ 0.0055â†“ 0.0051â†“ 0.0647â†“</cell></row><row><cell>(2) LSTM</cell><cell>0.0991â†“</cell><cell cols="2">0.1237 0.1266â†“</cell><cell>0.3740</cell><cell>0.3088</cell></row><row><cell>(3) Fixed ğœ”</cell><cell cols="3">0.0854â†“ 0.0944â†“ 0.0910â†“</cell><cell>0.3679</cell><cell>0.2789</cell></row><row><cell>(4) Position</cell><cell cols="5">0.0380â†“ 0.0243â†“ 0.0209â†“ 0.0742â†“ 0.0878â†“</cell></row><row><cell>(5) Empty</cell><cell cols="5">0.0139â†“ 0.0240â†“ 0.0018â†“ 0.0346â†“ 0.0603â†“</cell></row><row><cell>(6) BCELoss</cell><cell>0.2200</cell><cell cols="2">0.1916 0.1763â†“</cell><cell>0.4624</cell><cell>0.3542</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">In figure</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">, an embedding is a row vector, while in notations, it is a column vector.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://jmcauley.ucsd.edu/data/amazon/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGMENTS</head><p>This work is supported in part by NSF under grants III-1763325, III-1909323, III-2106758, and SaTC-1930941. This work is also partially supported by NSF through grant IIS-1763365 and by UC Davis. This work is also funded in part by the National Natural Science Foundation of China Projects No. U1936213</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>the time embedding can significantly outperform the position embedding, indicating the necessity of using the temporal kernel to capture temporal effects in sequences. Moreover, the default version, using a trainable ğœ”, achieves the best performance, which indicates its capacity to learn temporal effects from data. Loss function. We also compare BPR loss and BCE Loss, which is labeled as (6) in Table <ref type="table">3</ref>. The results indicate that the BCE loss performs inferior to BPR loss, except for the ML100K dataset. This is because BPR loss is optimized for ranking while BCE loss is designed for binary classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Temporal Correlations (RQ4)</head><p>Though we have already indicated the answer of RQ4 in Sec. 5.5, this section also conducts detailed analyses of the temporal correlation within sequences to directly answer RQ4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.1">Temporal Information Construction.</head><p>We develop two variants by dismissing the time vector in either Eq. (3) or Eq. ( <ref type="formula">4</ref>), i.e., users without time vectors or items without time vectors. The results are presented in Table <ref type="table">4</ref>. The observations are two-fold. Firstly, the performance of items without time is better than users without time. It implies that the temporal inference of user embeddings are rather important, which matches the intuition that the preference of users are dynamic while items are relatively more static. Secondly, the performance deteriorates significantly in both variants, indicating again TGSRec is able to model temporal effects of collaborative signals while also encoding sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.2">Temporal Attention Weights</head><p>Visualization. We visualize the attention weights of TGSRec on the Music dataset for a user, which is shown in Figure <ref type="figure">6</ref>. Each row is associated with an increment ('h' for hour and 'd' for day) from the last interactive timestamp ğ‘‡ = 1159142400, where 'next' denotes the timestamp (ğ‘‡ +34d) for the test interaction. Each column is associated with an item. We can observe that the attention weights for items are dynamic at different timestamps, which indicates the temporal inference characteristics of TGSRec. Moreover, the time increments can be arbitrary values, which verifies its continuity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.3">Recommendation Results.</head><p>Besides the attention visualization, we also present a part of the recommendation results of the same user in Table <ref type="table">5</ref>. Additionally, we also show the results of SASRec and TiSASRec, which only leverage sequential patterns. We find that only TGSRec can predict the ground truth item (Killing Joke) in top-4 predictions at the time of interests. When time (e.g., ğ‘‡ +30d) becomes close to the predicting timestampe 'next' (i.e., ğ‘‡ +34d), the ground truth item appears in the top-4 predictions. We can observe that the top predicted items from SASRec are also recommended by TGSRec, though in lower ranks. It again proves that TGSRec can unify sequential patterns and temporal collaborative signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we design a new SR model, TGSRec, to unify sequential patterns and temporal collaborative signals. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Graph convolutional matrix completion</title>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sequential recommendation with user memory networks</title>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Long and short-term recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Devooght</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugues</forename><surname>Bersini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization</title>
				<meeting>the 25th Conference on User Modeling, Adaptation and Personalization</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 30th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<title level="m">The movielens datasets: History and context. TIIS</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR (SIGIR &apos;20)</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno>WWW. 173-182</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">BalÃ¡zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06939</idno>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Linas Baltrunas, and Domonkos Tikk</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">JÃ¼rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Cristea</surname></persName>
		</author>
		<title level="m">Hybrid Sequential Recommender via Time-aware Attentive Memory Network. CIKM</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM. IEEE</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<editor>ICLR, Yoshua Bengio and Yann LeCun</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collaborative filtering with temporal dynamics</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On Sampled Metrics for Item Recommendation</title>
		<author>
			<persName><forename type="first">Walid</forename><surname>Krichene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1748" to="1757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks</title>
		<author>
			<persName><forename type="first">Srijan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural attentive session-based recommendation</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Time Interval Aware Self-Attention for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<idno>WSDM. 322-330</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Dynamic Graph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ICDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modeling user exposure in recommendation</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="951" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Enriching Non-Autoregressive Transformer with Syntactic and Semantic Structures for Neural Machine Translation</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenting</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
				<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Augmenting Sequential Recommendation with Pseudo-Prior Items via Reversely Pre-training Transformer</title>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Basket Recommendation with Multi-Intent Translation Graph Neural Network</title>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Achan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/BigData50022.2020.9377917</idno>
		<ptr target="https://doi.org/10.1109/BigData50022.2020.9377917" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Big Data (Big Data)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="728" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">BasConv: Aggregating Heterogeneous Interactions for Basket Recommendation with Graph Convolutional Neural Network</title>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengting</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Achan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 SIAM International Conference on Data Mining. SIAM</title>
				<meeting>the 2020 SIAM International Conference on Data Mining. SIAM</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">JSCN: Joint Spectral Convolutional Network for Cross Domain Recommendation. Bigdata abs/1910</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page">8219</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Introduction to abstract harmonic analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lynn</surname></persName>
		</author>
		<author>
			<persName><surname>Loomis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Courier Corporation</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Disentangled Self-Supervision in Sequential Recommenders</title>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="483" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Targett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
	<note>Qinfeng Shi, and Anton Van Den Hengel</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Continuous-time dynamic network embeddings</title>
		<author>
			<persName><forename type="first">Giang</forename><surname>Hoang Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">Boaz</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nesreen</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunyee</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungchul</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="969" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Bo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01646</idno>
		<title level="m">M2: Mixed Models with Preferences, Popularities and Transitions for Next-Basket Recommendation</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">HAM: hybrid associations models for sequential recommendation</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Personalizing session-based recommendations with hierarchical recurrent neural networks</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">BalÃ¡zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Factorizing personalized markov chains for next-basket recommendation</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno>WWW. 811-820</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1441" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Personalized top-n sequential recommendation via convolutional sequence embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Åukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Kgat: Knowledge graph attention network for recommendation</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="950" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neural Graph Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">DSKReG: Differentiable Sampling on Knowledge Graph forRecommendation with Relational GNN</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 30th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recurrent recommender networks</title>
		<author>
			<persName><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">How</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">DÃ©jÃ  vu: A Contextualized Temporal Attention Mechanism for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Jibang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renqin</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2199" to="2209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SSE-PT: Sequential Recommendation Via Personalized Transformer</title>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Sharpnack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="328" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Session-based recommendation with graph neural networks</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="346" to="353" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Temporal recommendation on graphs via long-and short-term preference fusion</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiwan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiatian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<idno>KDD. 723-732</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Temporal collaborative filtering with bayesian probabilistic tensor factorization</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tzu-Kuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM. SIAM</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="211" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Self-attention with functional time representation learning</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanwei</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evren</forename><surname>Korpeoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushant</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Achan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15915" to="15925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Da</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanwei</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evren</forename><surname>Korpeoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushant</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kannan</forename><surname>Achan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07962</idno>
		<title level="m">Inductive Representation Learning on Temporal Graphs</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Time Matters: Sequential Recommendation with Complex Temporal Information</title>
		<author>
			<persName><forename type="first">Wenwen</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuaiqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuepeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">A dynamic recurrent model for next basket recommendation</title>
		<author>
			<persName><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<idno>SIGIR. 729-732</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Are Pretrained Transformers Robust in Intent Classification? A Missing Ingredient in Evaluation of Out-of-Scope Intent Detection</title>
		<author>
			<persName><forename type="first">Jian-Guo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04564</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">IGE+: A Framework for Learning Node Embeddings in Interaction Graphs</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning node embeddings in interaction graphs</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
				<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="397" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Gated Spectral Units: Modeling Co-Evolving Patterns for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun-Ta</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1077" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
