<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Inverse Problems Light: Numerical Differentiation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Martin</forename><surname>Hanke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Otmar</forename><surname>Scherzer</surname></persName>
						</author>
						<author>
							<affiliation>
								<orgName>1. INTRODUCTION.</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Inverse Problems Light: Numerical Differentiation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5DB36578ABB75D683D35E9C6542F67D1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reliable numerical simulations of technical processes require detailed knowledge of the underlying physical models. Consider the simulation of heat transport in a one-dimensional homogeneous medium, where the heat conductivity depends on the temperature. In this case the temperature distribution u is the solution of a one-dimensional parabolic differential equation Ut = (a(u)u,),o O &lt; x &lt; l, O &lt; t &lt; T,(1) involving a nonlinear diffusion coefficient a: IR i- R+. Problem (1.1) also serves as a model for the saturation of porous media by liquid flow, in which case a (u) is related to the capillary pressure of the pores.</p><p>In certain industrial applications a numerical simulation may require solving (1.1) for u. We call this the direct problem. In these simulations it is crucial that a coefficient a(u) be used that is not only qualitatively correct but also reasonably accurate. Unfortunately, tabulated values for a (u) from the literature often provide only a rough guess of the true coefficient; in this case simulations are not likely to be reliable.</p><p>Consequently, identification of the diffusion coefficient a (u) from experimental data (typically, u(x, t) for some abscissa x E (0, 1) and 0 &lt; t &lt; T) is often the first hurdle to clear. This is the associated inverse problem.</p><p>A standard method to solve the inverse problem is the output least squares method, which tries to match the given data with simulated quantities using a gradient or Newton type method for updating the diffusion coefficient. Alternatively, one can consider (1.1) as a linear equation for a (u). To set up this equation requires numerical differentiation of the data [6]. This approach is called the equation error method.</p><p>It must be emphasized that inverse problems are often very ill-conditioned: for example, small changes in a (.) have little effect on the solution u in (1.1), and consequently one cannot expect high resolution reconstructions of a in the presence of measurement errors in u. Indeed, small errors in u may cause large errors in the computed a if they are not taken into account appropriately.</p><p>Numerical differentiation of the data encompasses many subtleties and pitfalls that a complex (linear) inverse problem can exhibit; yet it is very easy to understand and analyze. For this reason one could say that numerical differentiation itself is an ideal model for inverse problems in a basic numerical analysis course.</p><p>To support this statement we revisit a well-known algorithm for numerical differentiation of noisy data and present a new error bound for it. The method and the error bound can be interpreted as an instance of one of the most important results in regularization theory for ill-posed problems. Still, our presentation is on a very basic level and requires no prior knowledge besides standard n-dimensional calculus and the notion of cubic splines. Groetsch's book [4] presents other realistic inverse problems on an elementary technical level. Further examples and a rigorous introduction to regularization theory for the computation of stable solutions to these examples can be found in [1].</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>where 8 is a known level of noise in the data. For the moment we assume that the boundary data are known exactly: yo = y(0) and Y = y(l).</p><p>We are interested in finding a smooth approximation f'(x) of y'(x), defined for all x E [0, 1], from the given data 5i, with some guaranteed (best possible) accuracy.</p><p>If this material is to be presented in class, the precise notion of smoothness depends on the level of the course. In principle, the Sobolev space H2[0, 1] of all functions f E C1 [0, 1] with square integrable second derivative is the appropriate choice. However, C2[0, 1] would also be all right (see Section 3), but then the following error bounds are no longer optimal.</p><p>Many textbooks on numerical analysis lack a satisfactory treatment of numerical differentiation. Usually, the treatment is restricted to the consistency error of sophisticated finite difference quotients while the stability problem due to error propagation is often ignored. Combining consistency error and propagation error for one-sided finite differences, one arrives at the bound</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yi+i</head><formula xml:id="formula_0">-Yi _ y/ (x) |&lt; O (h + 6/ h), xi &lt;_ x &lt;_ xi+i,<label>(2.2)</label></formula><p>h for the total error provided that y E C2[0, 1]; for a very nice pedagogical treatment of this subject, see <ref type="bibr" target="#b2">[3]</ref>. The right-hand side of (2.2)-as a function of h-is plotted in Figure <ref type="figure">1</ref> (solid line): it attains a minimal value of 0 (Vs) for h -. There is a trivial solution to the stability problem: discard data until the spacing between the grid points is about A/6 (this is sometimes called regularization by coarse discretization). This is not very satisfactory. Each datum carries information that should somehow be put to work. Another shortcoming of finite difference schemes is the lack of smoothness of the resulting approximations of y': the finite difference approximations are only piecewise constant functions.</p><p>We therefore take a different approach-one that uses all the data and leads to a smooth approximation. Let </p><p>i.e., the straight line interpolating the two boundary values. To see this consider ft = (1 -t) f for sufficiently small nonnegative t: by assumption, f, satisfies the con- straint (2.3), and lf'" II = (1 -t) lf "l so that 1If,"l must vanish in order to be mini- mal. This shows that f* is the linear interpolant of the given boundary data. This case occurs if and only if f satisfies the constraint (2.3).</p><p>Excluding this trivial case, the minimizer f. satisfies (2. Problem II is a special instance of a general method known as Tikhonov regularization; in this context a is called the regularization parameter, and the way a is chosen in Problem II is called the discrepancy principle <ref type="bibr" target="#b1">[2]</ref>.</p><p>Except for the interpolatory constraints at the boundary of the interval, (2.5) has been investigated and solved by Schoenberg <ref type="bibr" target="#b9">[10]</ref> and Reinsch <ref type="bibr" target="#b7">[8]</ref>, who showed that the solution of Problem 11 is a natural cubic spline over the grid A. Reinsch also gives a constructive algorithm for calculating this spline. The whole algorithm including the determination of the Lagrange multiplier 1 /a takes only 0(n) operations, but this is a different story that could fill another note.</p><p>Our main interest is the error f' -y', i.e., the error of this particular way of numer- ical differentiation. We have the following result, which appears to be new; a proof is given in Section 5. The theorem says that, as long as h &gt; (8/11 y"/II )1/2, the error bound is of the same order as that for finite differences; see (2.2). However, the bound (2.7) remains of order 0(V) when h -+ 0, without the need to discard any information. The error estimate (2.7) is sharp in the sense that for 8 = 0, i.e., noise-free data, the right-hand side coincides up to a multiplicative constant with the best-possible worst case bound for the interpolating spline; see Lemma 4.2. We can also give a hand-waving argument to illustrate the sharpness of the second term on the right-hand side of (2.7) as h -* 0. The remainder of this article is organized as follows. In Section 3 we prove that the minimizing element f* is a natural cubic spline over the grid A. Section 4 summarizes basic error estimates in spline approximation. A proof of Theorem 2.1 is contained in Section 5. Finally, numerical results and comments are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>To this end we integrate by parts and use the boundary values</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE MINIMIZING SPLINE. There are two ways to prove existence and uniqueness of the minimizing element f* of (2.5). One possibility is to consider this problem as a differentiable optimization problem over a convex domain in H2[0, 1]. This approach is technical and requires involved mathematical prerequisites if the derivation</head><p>is to be rigorous. The technique that we use verifies directly the optimality of the corresponding spline function. The shortcoming of our approach is that the characterization (3.1) of the minimizing element f* seems to appear from nowhere, but we feel that the simplicity of our treatment is fair compensation for this.</p><p>Let f* be a natural cubic spline over A, i.e., a function that is twice continuously differentiable over [0, 1] with f4"(0) = f*"(1) = 0, and coincides on each subinterval [xi 1, xi] of A with some cubic polynomial. We show that the minimizer f* is uniquely determined by connecting the jumps of f*" at the interior nodes x = xi with the values</p><formula xml:id="formula_2">f*(xi) through f"(xi+) -f"(xi-) (- -f(xi)), i-1 ...nn<label>(3.1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>* I * I oeu(n -1)</head><p>The boundary values of f, have been fixed to be f* (0) = 5o and f* (1) = Yn. For a constructive algorithm for computing f* see <ref type="bibr" target="#b7">[8]</ref>.</p><p>For any function g with square integrable second derivative and boundary values g (0) = g (1) = 0, integration by parts yields For the purpose of reconstructing a, the piecewise constant approximation is useless for its lack of smoothness; the exact solution u of the parabolic equation (1.1) is known to be smooth so that a cubic spline approximation is much more appropriate. The entire algorithm for reconstructing the diffusion coefficient is described in <ref type="bibr" target="#b5">[6]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 .</head><label>2</label><figDesc>SETTING OF THE PROBLEM. Suppose y = y(x) is a smooth function on 0 &lt; x &lt; 1 and noisy samples 5i of the values y (xi) are known at the points of a uniform grid A = {0 = xo &lt; x &lt; ...&lt; x = }. Let h = xi+I-xi be the mesh size of the grid</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 -</head><label>2</label><figDesc>norm of a square integrable function over (0, 1). With the aim of taming the wild oscillations in the approximate derivative that typically appear when differentiating noisy data, it appears natural to pose the numerical differentiation problem as a constrained optimization problem: Problem I. Minimize I f" Ill among all smooth functions f satisfying f (0) = y(0the derivative f4 of the minimizing element f* as an approximation of y'. It is important that the exact solution y belongs to the class of smooth fttnctions over which the minimum is taken. In fact, given the uncertainty in the data, all functions f satisfying (2.3) can be considered as solution candidates. The minimizer of Problem I is the particular candidate that is 'smoothest'. If the minimizing element f* of Problem I satisfies the constraint (2.3) with strict inequality (i.e., the constraint (2.3) is inactive) then f* must be the 'trivial solution' f(x) = y(0) + x(y(l)y(0)),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 ) 6 )</head><label>36</label><figDesc>with equality, and hence, can be calculated using the method of Lagrange. If 1 /a denotes the corresponding Lagrange multiplier for constraint (2.3), the equivalent formulation of Problem functions f satisfying f (O) = y(O), f (1) = y(l), where a is such that the minimizing element f; of (2The derivative f*' of the minimizing function f* is then an approximation of y'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Theorem 2 . 1 .</head><label>21</label><figDesc>Let y" be square integrable over (0, 1) and let f* be the minimizer of Problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>inequality ensures that the right-hand side of (2.8) is bounded by II f* -y II1I f4' -Y" II; the first factor is approximately 8 as h becomes small, while the second factor is bounded by 2 11 y" 11 because of the triangle inequality and the setting of Problem I.Although Theorem 2.1 may not surprise those who are acquainted with the literature on Tikhonov regularization, we emphasize that the standard theory in<ref type="bibr" target="#b0">[1]</ref> and<ref type="bibr" target="#b1">[2]</ref> does not cover a result like this. The reason is the somewhat nonstandard combination of the penalty term 11 f " 11 in (2.5) and the smoothness assumption on the exact solution y.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>+ 2a f(f -f*"))f" dx. RESULTS AND CONCLUDING REMARKS. Theorem 2.1 extends in a straightforward way to the situation when the boundary data of y are also perturbed. In this case one can consider the function Y(x) = y(x) + yO-y(O) + 8x, where 8 = n-y(l) + y(O) -j0. Then Y(0) = 50 and Y(1) = Yn, and hence Theorem 2.1 applies to Y. Note that Y" = y". Consequently, if 8 is replaced by 28 in Problems I and II then Theorem 2.1 yields the same bound as before for f' -Y'll, and since IIY' -y'll = I j &lt; 28 the same type of bound results for IIf' -y'll as well.For the inverse problem of determining the diffusion coefficient a( ) in (1.1), considered in [6], an industrial client provided temperature measurements of u (xi, tj) at a few thermocouples at locations xi and equidistant times tj E [0, T]. A crucial step of the equation error method used in<ref type="bibr" target="#b5">[6]</ref> requires knowledge of u, (xi, t), i.e., numerical differentiation of the given data. The left-hand plot in Figure2shows the measurements u(0, tj) (the circles) and the corresponding smoothing cubic spline. The righthand plot shows both the numerical derivatives computed with finite differences (the dashed, piecewise constant function) and the smoothing spline (solid line).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>When h is smaller, the bound (2.2) deteriorates. 0.2 0.18 0.16 h + 8/h 0.14 ---- h+ 0.12</head><label></label><figDesc></figDesc><table><row><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.08</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.06 -</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.04-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.02-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>0.01</cell><cell>0.02</cell><cell>0.03</cell><cell>0.04</cell><cell>0.05</cell></row></table><note><p>Figure 1. Qualitative behavior of the error bounds (2.2) and (2.7) versus h for fixed 1 = o-4.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This content downloaded from 152.3.102.242 on Wed, 31 Jul 2013 22:29:20 PM All use subject to JSTOR Terms and Conditions</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>ACKNOWLEDGMENT. This work was inspired by a note of Chuck Groetsch<ref type="bibr" target="#b2">[3]</ref>. We are very grateful for his careful reading of our manuscript and his editorial suggestions, which improved the paper a lot.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The technique that we have employed to show that f* is the minimizer of I is standard and applies to any quadratic functional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PRELIMINARIES ON SPLINE APPROXIMATION.</head><p>Before proving Theorem 2.1, we collect some preliminary results that provide background information on splines. Each of these facts is easy to prove, but for the reader's convenience we provide appropriate references. The idea of smoothing data by cubic splines has a long tradition, especially among statisticians; see <ref type="bibr" target="#b12">[13]</ref>, which summarizes early work in this area, and also <ref type="bibr" target="#b8">[9]</ref>.</p><p>Beyond the cubic spline setting there are many other approaches to the topic of this paper. A good place to search for additional literature is <ref type="bibr" target="#b6">[7]</ref>, which focuses on the mollification method. We caution, however, that many numerical schemes impose artificial boundary conditions on y, which may lead to annoying boundary artifacts for practical data sets.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Engi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neubauer</surname></persName>
		</author>
		<title level="m">Regularization of Inverse Problems</title>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Theory of Tikhonov Regularization for Fredholm Equations of the First Kind</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Groetsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<pubPlace>Pitman, London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Differentiation of approximately specified functions</title>
	</analytic>
	<monogr>
		<title level="j">Amer Math. Monthly</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="847" to="850" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">Inverse Problems in the Mathematical Sciences</title>
		<meeting><address><addrLine>Braunschweig</addrLine></address></meeting>
		<imprint>
			<publisher>Vieweg</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Hammerlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Hoffmann</surname></persName>
		</author>
		<title level="m">Numerical Mathematics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Error analysis of an equation error method for the identification of the diffusion coefficient in a quasilinear parabolic differential equation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName><surname>Scherzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1012" to="1027" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Mollification Method and the Numerical Solution of III-Posed Problems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Murio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Smoothing by spline functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Reinsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="177" to="183" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Smoothing splines: regression, derivatives and deconvolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="141" to="156" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spline functions and the problem of graduation</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Schoenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="947" to="950" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Schumaker</surname></persName>
		</author>
		<title level="m">Spline Functions: Basic Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An Analysis of the Finite Element Method</title>
		<author>
			<persName><forename type="first">G</forename><surname>Strang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Fix</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, N.J.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Spline Models for Observational Data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wahba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">He received his Ph.D. in 1989 from the University at Karlsruhe, and has taught at the universities in Karlsruhe, Kaiserslautern, and Mainz (all in Germany). He has (co)authored two monographs about inverse and ill-posed problems. This is also his major research interest</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hanke-Bourgeois</surname></persName>
		</author>
		<ptr target="D-95440Bayreuth,Germany.otmarscherzer@uni-bayreuth.de" />
	</analytic>
	<monogr>
		<title level="m">hanke @math. uni-mainz.de OTMAR SCHERZER holds a Ph.D. from the Johannes Kepler-Universitat Linz (Austria)</title>
		<meeting><address><addrLine>Mainz, Germany; Fachbereich Mathematik, Johannes Gutenberg-Universitdt, D-55099 Mainz, Germany</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Johannes Gutenberg-Universitat in ; Johannes Kepler-Universitat, the Ludwig-Maximilian Universitat Muinchen (Germany) and the University of Bayreuth (Germany) ; Universitat Bayreuth</orgName>
		</respStmt>
	</monogr>
	<note>His research interests include inverse problems and image processing</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
