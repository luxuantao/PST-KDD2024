<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robotics and Autonomous Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-10-30">30 October 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">V</forename><forename type="middle">Javier</forename><surname>Traver</surname></persName>
							<email>vtraver@uji.es</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Languages and Systems Dept</orgName>
								<orgName type="institution">Universitat Jaume I</orgName>
								<address>
									<settlement>Castellón</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of New Imaging Technologies (INIT)</orgName>
								<orgName type="institution">Universitat Jaume I</orgName>
								<address>
									<settlement>Castellón</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Bernardino</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Instituto de Sistemas e Robótica</orgName>
								<orgName type="institution">Instituto Superior Técnico</orgName>
								<address>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Computer Languages and Systems Dept</orgName>
								<orgName type="institution">Universitat Jaume I</orgName>
								<address>
									<settlement>Castellón</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robotics and Autonomous Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-10-30">30 October 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">3D8986FA76ACF5BA0BB7F6C187E27F69</idno>
					<idno type="DOI">10.1016/j.robot.2009.10.002</idno>
					<note type="submission">Received 31 July 2008 Received in revised form 6 October 2009 Accepted 13 October 2009</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Foveal imaging Log-polar mapping Real-time robotics Active vision</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Log-polar imaging consists of a type of methods that represent visual information with a space-variant resolution inspired by the visual system of mammals. It has been studied for about three decades and has surpassed conventional approaches in robotics applications, mainly the ones where real-time constraints make it necessary to utilize resource-economic image representations and processing methodologies. This paper surveys the application of log-polar imaging in robotic vision, particularly in visual attention, target tracking, egomotion estimation, and 3D perception. The concise yet comprehensive review offered in this paper is intended to provide novel and experienced roboticists with a quick and gentle overview of log-polar vision and to motivate vision researchers to investigate the many open problems that still need solving. To help readers identify promising research directions, a possible research agenda is outlined. Finally, since log-polar vision is not restricted to robotics, a couple of other areas of application are discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Both natural and artificial visual systems have to deal with large amounts of information coming from the surrounding environment. When real-time operation is required, as happens with animals or robots in dynamic and unstructured environments, image acquisition and processing must be performed in a very short time (a few milliseconds) in order to provide a sufficiently fast response to external stimuli. Appropriate sensor geometries and image representations are essential for the efficiency of the full visual processing stream. To address this problem it is wise to look for the solutions present in biological systems, which have been optimized by millions of years of evolution. For instance, the visual system of many animals exhibits a non-uniform structure, where the receptive fields 1 represent certain parts of the visual field more densely and acutely. In the case of mammals, whose eyes are able to move, retinas present a unique high resolution area in the center of the visual field, called the fovea. The distribution of receptive fields within the retina is fixed and the fovea can be redirected to other targets by ocular movements. The same structure is also commonly used in robot systems with moving cameras <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>.</p><p>In the late 70s computer vision researchers broke new ground by considering the foveal nature of the visual systems of primates as an alternative to conventional uniform resolution sensors for artificial perception in computers and robots. Earlier on, biological findings in the visual cortex of monkeys <ref type="bibr" target="#b6">[7]</ref> had shown that the displacement of a light stimulus in the retina produces displacements in the cortex that are inversely proportional to the distance to the fovea. This effect, also known as cortical magnification, indicates a general scaling behavior by which both receptive field spacing and size increase linearly with eccentricity, i.e. the distance from the fovea <ref type="bibr" target="#b7">[8]</ref>. It was found that responses to linear stimuli originating in the fovea lie roughly along lines in the cortex, and circular stimuli centered on the fovea produce linear responses in the cortex at approximately orthogonal orientations <ref type="bibr" target="#b8">[9]</ref>. Thus, the information transmitted between the retina and the visual cortex is organized in an approximate logarithmic-polar law <ref type="bibr" target="#b9">[10]</ref>.</p><p>The foveal structure of the retina of some animals is, together with their ability to move the eyes, a fundamental mechanism in the control of visual perception. In the late 80s and early 90s, researchers started exploiting eye movements to achieve complex visual tasks. The paradigm of active vision emerged as a powerful concept to endow an active observer with the ability to find more efficient solutions to problems that, from a passive vision perspective, were ill-posed and non-linear <ref type="bibr" target="#b10">[11]</ref>. The idea can be generalized beyond pure perception by including manipulation. The smart usage of robot arms and hands, for instance, opens up many more possibilities for better visual perception <ref type="bibr" target="#b11">[12]</ref>. A great deal of excitement was aroused at that time with regard to the present and future possibilities of active vision <ref type="bibr" target="#b12">[13]</ref>. For instance, by purposefully moving the eyes, an observer with a foveal low resolution sensor can acquire a ''virtual'' high resolution image of its entire field of view <ref type="bibr" target="#b13">[14]</ref>. Therefore, following on as the next natural step forward, a new concept appeared -space-variant active vision <ref type="bibr" target="#b14">[15]</ref>.</p><p>Since then, efforts have been made to explore the advantages that foveal-like log-polar imaging can bring to robotic applications. However, after almost three decades since those initial studies, no systematic and comprehensive work has been published that attempts to review past research on the topic. While a careful review of log-polar models was conducted ten years ago in <ref type="bibr" target="#b15">[16]</ref>, its focus was a detailed study and comparison of log-polar mapping templates and models with overlapping receptive fields. More recently, the motivations for retina-like sensors and the properties of the log-polar mapping were nicely considered in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. Another paper <ref type="bibr" target="#b18">[19]</ref> surveyed foveated sensors with a particular emphasis on image processing issues.</p><p>Thus, while these few review-like papers did not consider the applications and usages of log-polar images in depth, we feel that such an analysis is needed, to reflect on past achievements, discuss current challenges, and predict future developments. Additionally, this literature overview would be a valuable aid to any researcher interested in approaching the field, particularly to beginners. Finally, another important benefit of such a survey is that of helping to promote further work, both on the theoretical and practical sides of log-polar vision.</p><p>Therefore, the present survey aims to complement these previous reviews, by looking further into the variety of applications of log-polar sensing that have been proposed. Furthermore, our analysis pays particular attention to robotic applications. Hence, the usage of the log-polar transform for pattern recognition issues, though important, is not considered here. Studies and reviews on this other perspective can be found elsewhere <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>.</p><p>An overview of the log-polar mapping (Section 2) allows the readers to become familiar with the basics of this transform. There are different ways to obtain log-polar images either from conventional images or directly from a scene, using softwareand/or hardware-based solutions (Section 3). In Section 3 we also address issues regarding how the mapping parameters may influence the visual task and whether the selection of optimal parameters can be automated. The area of visual attention and salience computation under foveal vision (Section 4) has not been explored very much, even though it plays a key role in active object search and recognition, in exploratory gaze strategies, and in the proper integration of different visual tasks in practical scenarios. One of the visual processes where log-polar imaging is most suitable is probably active target tracking (Section 5), and substantial research has been devoted to this topic. Some advantages have also been found in estimating the observer's motion using log-polar images (Section 6), basically due to its polar geometric nature which fits particularly well with timeto-collision computation and other navigation tasks in mobile robots. Binocular depth estimation has been considered with a joint usage of log-polar imaging and active vergence movements (Section 7). There are also a number of less conventional sensor arrangements and less known properties of log-polar imaging that deserve some consideration. It is our prediction that many of these issues will open up the door to fascinating new research challenges in automatic foveal vision not only within robotics but also in other fields of application (Section 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Log-polar mapping</head><p>Log-polar mapping is a geometrical image transformation that attempts to emulate the topological reorganization of visual information from the retina to the visual cortex of primates. It can also be found in the literature under different names, such as log-polar transformation or the log(z) model. The reason for this last denomination comes from the fact that the mapping can be mathematically modeled by the complex logarithmic function log(z), where z is the complex variable representing points on the image plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Definition</head><p>Let us consider the complex retinal and cortical (log-polar) planes, represented by the variables z = x + jy and w = ξ + jη, respectively (j is the complex imaginary unit). The complex logpolar mapping is:</p><formula xml:id="formula_0">w = log(z) (1)</formula><p>and the log-polar coordinates ξ (eccentricity) and η (angle) are given by:</p><formula xml:id="formula_1">ξ = log(|z|) = log x 2 + y 2 η = arg(z) = atan2(y, x)</formula><p>where atan2(y, x) denotes the two-argument arctangent function that considers the sign of x and y in order to determine the quadrant of the resulting angle.</p><p>This mapping transforms concentric circumferences and radial lines in the retinal plane into straight lines along the ξ and η directions in the cortical plane, respectively (Fig. <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Properties</head><p>The main properties of the mapping and some of their practical implications are as follows:</p><p>Conformal mapping: The cortical image (also called log-polar image) preserves oriented angles between curves and neighborhood relationships, almost everywhere, with respect to the retinal image. In theory, this property predicts that image processing operations developed for Cartesian images can be applied directly to log-polar images. In practical terms, however, specific algorithms are required in many applications. Elegant trade-off solution between these three mutually opposing criteria: wide field of view, high visual resolution and little data to process. For robotics applications, there are two significant benefits of this particular sampling.</p><p>On the one hand, the reduced size of log-polar images (as much as 30 times smaller than uniformly-sampled Cartesian images have been reported) hugely facilitates real-time visual data processing. On the other hand, the radially logarithmic sampling entails that a higher resolution is devoted to the center of the scene (fovea area) which, in turn, means that foveal information is represented by a big number of pixels in the log-polar image. One of the most interesting practical implications of this foveal predominance, is that foveated targets can be tracked without being explicitly segmented from the background. Additionally, the segmentation of a verged target in a binocular system becomes easier. Biological plausibility: It approximates the receptive field distribution and retino-cortical mapping in the visual system of mammals. Depending on the application, this mimicry of biological solutions can be seen as an experimental support tool to neurophysiology, either to validate its findings or to propose new hypotheses. On the other hand, from an engineering point of view, it is a rich source of inspiration for sound strategies developed in the natural animal world. Rotation and scaling ''invariance'': When the original image is rotated or scaled with respect to its center, patterns in the log-polar image only undergo translations, thus preserving their shape. This geometric property, also known as edge or shape invariance, is particularly helpful for rotation-and scale-invariant pattern recognition, but it has also been exploited for motion estimation in active tracking scenarios, as described in Section 5.</p><p>The first two properties (conformality and data selection) are common to other space-variant imaging models, while the last two (biological inspiration and edge invariance) are specific advantages of the log-polar mapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Singularity at the origin</head><p>One weakness of the log(z) model is the existence of a singularity in the center of the image, since it is not possible to evaluate log(0). This means that receptive fields would become infinitely small toward the origin. Therefore, points in the fovea cannot be represented with this mapping. Two solutions are commonly used to overcome this problem: either using a different mapping for the fovea (e.g. the identity mapping or a pure polar structure) or applying the log(z + a) model. This other model was proposed in <ref type="bibr" target="#b23">[24]</ref> as a better approximation to the retino-topic mapping of monkeys and cats. The log(z + a) model transforms points in the first and fourth quadrants (x ≥ 0) of the retinal plane via</p><formula xml:id="formula_2">w = log(z + a), (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where a is a positive real number. In coordinates, we have:</p><formula xml:id="formula_4">ξ = log (x + a) 2 + y 2 η = arctan y x + a .</formula><p>Because x is positive in the first quadrant and a is a positive constant, the minimum value of ξ is finite (min ξ = log(a)), therefore avoiding the singularity present in the log(z) model (Fig. <ref type="figure" target="#fig_1">2</ref>(a,b)). The mapping for the other quadrants is obtained by symmetry, which saves some computation time. Additionally, pixels in the log-polar plane are rearranged to match the quadrants of the Cartesian plane and to be connected at the origin (Fig. <ref type="figure" target="#fig_1">2(c,</ref><ref type="figure">d</ref>)). The resulting mapping is: The log(z+a) model lacks the property of exact scale invariance. However, this is often tolerated in practical applications. Other solutions to the singularity problem have also been proposed <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Discretization</head><p>The log(z) and log(z + a) are conceptual models defined in continuous coordinates. They tell us how retinal and cortical coordinates are related, but, in practice, the mapping must be discretized. The conventional approach considers the cortical plane to be uniformly discretized as if it was an ordinary Cartesian image, i.e. covered with a dense grid of rectangular regions. Thus, let us consider a grid of E × A rectangular pixels (also known as cortical cells) whose corners are at coordinates w p,q = ξ p + jη q , p ∈ {1, . . . , E}, q ∈ {1, . . . , A}, with E as the number of eccentricities (radial rings) and A the number of angular sectors. In the retinal plane, the corresponding regions, γ p,q , are shaped like angular sections of concentric annuli. Such regions are called retinal cells or receptive fields (RFs). Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the partition of the cortical plane with a uniform grid and the corresponding retinal cells. Each retinal cell has a weighing function φ p,q (z) associated to it that represents the way the value of each cortical pixel is obtained from the information in the retinal array. This can be modeled by</p><formula xml:id="formula_5">c p,q = f , φ p,q ,<label>(3)</label></formula><p>where f is the function representing the Cartesian image. With uniform weighting functions, this operation represents the simple averaging of the retinal information within the spatial support of each retinal cell. Neighbor cells in the retinal domain are also neighbors in the cortical domain, except along the angular discontinuity and the radial singularity. Shape invariance to centered rotations and scalings no longer holds perfectly for the discretized log(z) model. However the approximation is good enough for practical applications, if discretization is not too coarse (Fig. <ref type="figure" target="#fig_2">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Other implementation details</head><p>Models following biological data more closely have overlapping cells. They are computationally more expensive than nonoverlapping ones but gain in smoothness of the log-polar image pixels. The models presented in <ref type="bibr" target="#b28">[29]</ref> and <ref type="bibr" target="#b29">[30]</ref> have cells with a log-polar distribution but with circular shapes and a moderate amount of overlap with the neighbors. In <ref type="bibr" target="#b28">[29]</ref> a tessellation is proposed with a linear relation between receptive field size and eccentricity, and a cell overlap of 50%, as shown in Fig. <ref type="figure">4(a)</ref>. The proposal in <ref type="bibr" target="#b29">[30]</ref> also uses circular receptive fields but attempts to minimize the amount of overlap between them by using a slightly different organization of receptive fields where direct neighbors are not in the same ring (Fig. <ref type="figure">4(b)</ref>). Besides those seen above, there are other implications of log-polar sampling, as well as less obvious properties. For instance, discrete log-polar images and their internal representation introduce some practical difficulties, as the shapes and motions of the objects are distorted in a complex non-linear and inhomogeneous way. Appropriate algorithms and strategies have to be devised carefully to deal with these issues. Another example is the difference in resolution between the fovea and the periphery which calls for active strategies from the observers so that the gaze can be redirected according to the scene, the goals of the task and the ongoing visual events.</p><p>In terms of data structures in computer implementations, a logpolar image may not differ from a conventional image, except for Overlapping models: (a) the model of <ref type="bibr" target="#b28">[29]</ref> implemented in <ref type="bibr" target="#b30">[31]</ref>, and (b) the model in <ref type="bibr" target="#b29">[30]</ref> (figure taken from <ref type="bibr" target="#b15">[16]</ref>). the different meaning of the axes (row and column indices). In this case, one common difficulty to be tackled refers to the circularity of the angular axis, since the two ends of the rectangular logpolar image have to be processed as if they were really connected.</p><p>To solve these kinds of technical complexities, an alternative representation, the connectivity graph, was proposed <ref type="bibr" target="#b31">[32]</ref>. It has the advantage of being very general and able to accommodate arbitrary sensor lattices, as illustrated in Fig. <ref type="figure" target="#fig_4">5</ref>. Local image operations, such as edge detection, can therefore be applied without special cases (e.g. image boundaries) in mind. As a disadvantage, graphs have to be defined, built, and processed, which may result in a loss of efficiency in particular circumstances.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Noise issues</head><p>Three aspects that relate log-polar images and noise issues can be identified. One of them is the occurrence of noise problems that need to be dealt with during the design or implementation of a log-polar sensor. A second situation may arise in image processing operations or computer vision applications that are performed favorably in terms of noise tolerance thanks to the nature of the log-polar image. Finally, procedures can be designed to reduce the noise present in an existing log-polar image. The scarce literature existing on these three aspects is commented briefly below.</p><p>With respect to sensor design, the implementation of hardwarebased log-polar sensors (more on this in Section 3) brings noiserelated problems, such as those related with the different size of the sensing elements used at different eccentricities, and that have to be addressed <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref>.</p><p>Regarding image noise, the advantage of log-polar images has been considered for scale-invariant feature recognition <ref type="bibr" target="#b38">[39]</ref>. Since the noise in different Cartesian pixels is uncorrelated, the signal-tonoise ratio (SNR) improves in log-polar pixels when the log-polar transform is computed from Cartesian images <ref type="bibr" target="#b39">[40]</ref>. The averaging procedure associated to the each receptive field to compute the gray-level value of a log-polar pixel is essentially a low-pass filter, and that is why an enhanced noise tolerance is also observed when performing image diffusion in the log-polar domain <ref type="bibr" target="#b40">[41]</ref>. Among linear filters, a simple moving average is shown to be optimal in reducing random white noise and preserving sharpness in the step response, with noise being reduced by a factor of √ n for n pixels being averaged <ref type="bibr" target="#b41">[42,</ref><ref type="bibr">Ch. 5]</ref>. Since the size of the RFs increases with eccentricity, resolution decays, but the SNR increases with distance to the center. Furthermore, for a given layout of RFs, their overlapping allows each of the RFs to be larger, which improves its SNR if the averaged signals are locally correlated, as it usually happens in natural images <ref type="bibr" target="#b42">[43]</ref>. An optimal amount of overlap can be found as a trade-off between a greater SNR and a smaller data redundancy <ref type="bibr" target="#b42">[43]</ref>. Recently, projection-based motion estimation has been shown to exhibit higher noise robustness in log-polar images than in Cartesian images <ref type="bibr" target="#b43">[44]</ref>. But log-polar imaging is not only good at tackling sensor noise in the periphery, it is also highly insensitive to perceptual noise (such as unmodeled issues, image clutter and distractors), since these undesirable artifacts are blurred or de-emphasized with respect to the dominant foveal visual data. This advantage has been demonstrated in a number of visual tasks, including tracking, depth computation and vergence control, as commented in Sections 5 and 7 below. Certainly, this very fact becomes a disadvantage if some occlusion happens at the foveal area.</p><p>Concerning noise reduction, in <ref type="bibr" target="#b44">[45]</ref> a discrete wavelet transform is applied to reduce white Gaussian noise in log-polar images. Interestingly, as a consequence of the implicit low-pass filtering discussed above, if low-pass filtering is required in log-polar images, this process can be limited to the central foveal area since the peripheral pixels, if large enough, already implement this. As a result, this can save further computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7.">Other foveal methods</head><p>While log-polar imaging is the most common foveal method, many alternative foveating approaches have been proposed. These are generally aimed at (a) preserving linearities; (b) having a shiftable fovea, adaptive-size fovea, or multiple foveae, or (c) the flexibility of a family of parameterized transformations. All the techniques share as their common goal that of reducing the amount of visual information and they differ in the different geometries and data structures chosen to suit certain purposes.</p><p>The Reciprocal Wedge Transform (RWT) <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref> (Fig. <ref type="figure" target="#fig_5">6</ref>(a)) preserves linear features, which is not possible in the log-polar domain. The RWT has been shown to be suitable in road following and depth recovery tasks. Multiresolution, pyramid-based foveallike mechanisms, such as the Cartesian exponential topology (CET), have been used in active vision <ref type="bibr" target="#b47">[48]</ref>, video transmission <ref type="bibr" target="#b48">[49]</ref>, and motion and image segmentation <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>. The Cartesian Foveal Geometry (CFG) <ref type="bibr" target="#b51">[52]</ref> (Fig. <ref type="figure" target="#fig_5">6(b)</ref>) is similar to the CET, but the receptive fields are of constant size regardless of their eccentricity and no actual multiresolution is used. While CET and CFG have been shown to work in some tasks, no particular benefit over log-polar imaging has been demonstrated besides the claimed advantage that conventional image processing procedures require less modification than in the log-polar case. In general, foveated systems have been proposed to reduce the required communication bandwidth by exploiting the limitations (spacevariant nature) of the human visual system <ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref>.</p><p>Multiple foveae systems are described in <ref type="bibr" target="#b55">[56]</ref> and <ref type="bibr" target="#b56">[57]</ref> for stereo and video-conference applications, respectively. The potential benefit of having a relocatable fovea or several foveae in active vision contexts is that no hardware is required for camera movements, and their costly and/or inaccurate movements due to their mechanical nature are avoided <ref type="bibr" target="#b57">[58]</ref>. In practical terms, multifoveae systems have virtually not been applied in robotic systems.</p><p>The dimensionally-independent exponential mapping (DIEM) <ref type="bibr" target="#b58">[59]</ref> (Fig. <ref type="figure" target="#fig_5">6(c</ref>)) can sample along the vertical and horizontal dimensions differently. Possibly, the main advantage of DIEM is its flexibility, so that its parameters can easily be chosen to fit the problem at hand by granting more importance to one dimension or the other, and by sampling more densely at the center or at the periphery.</p><p>In short, no foveation mechanism is suitable for all tasks, and all of them exhibit advantages and disadvantages. With respect to other techniques, the log-polar method is biologically motivated, (a) first CCD sensor built <ref type="bibr" target="#b60">[61]</ref>.</p><formula xml:id="formula_6">© 2002 IEEE.</formula><p>(b) CMOS sensors reported in <ref type="bibr" target="#b64">[65]</ref>.</p><p>© 1995 IEEE.</p><p>(c) CMOS sensors reported in <ref type="bibr" target="#b35">[36]</ref>. Source: Courtesy by Cypress Semiconductor Image Sensor. it is one of the best known transforms, and it has been largely studied and shown to be useful in a wide range of applications. While linearities and translation invariance are certainly lost in log-polar images, the limitations associated with this lack can be compensated by proper algorithm design and/or appropriate active vision mechanisms, as reported in a significant part of the literature surveyed in this article. Real-time active target tracking and time-to-impact estimation are possibly the tasks that log-polar imaging is clearly best suited to, due to its favorable geometric arrangement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Sensor design</head><p>While the market of commercial visual cameras is dominated by sensors with conventional Cartesian lattices, research and development on foveal imaging during the 90s led to the design and construction of several prototypes of the so-called retina-like cameras with sensitive elements arranged following a log-polar pattern. The first versions of these sensors and cameras were based on the Charged Coupled Device (CCD) technology <ref type="bibr" target="#b59">[60]</ref><ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref>, while later models used the Complementary Metal Oxide Semiconductor (CMOS) technology <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b35">36]</ref>. Technical difficulties were gradually overcome and the sensor was improved by increasing the number of pixels and introducing color sensing <ref type="bibr" target="#b66">[67]</ref>. Three of these sensors are depicted in Fig. <ref type="figure" target="#fig_6">7</ref>. A detailed report on vision chips, including foveal ones, is provided in <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b68">69]</ref>.</p><p>The main advantage of these hardware-based log-polar imaging devices is that the captured image is already in the log-polar format, which allows or promises fast real-time processing in timecritical applications like active vision tasks. One main drawback, however, is represented by the technical obstacles faced either during their design and construction or even during their usage, which limits the range of applications. Furthermore, the hardcoded geometry layout makes it very difficult, if not impossible, to experimenting with different sensor parameters. An alternative (not log-polar) biologically inspired kind of visual sensor is offered by curved sensors <ref type="bibr" target="#b69">[70]</ref>, which mimic the hemispherical geometry of the human eye and bring forward additional challenges and possibilities.</p><p>Because flexibility in setting the log-polar parameters is such an important issue for experimental work, software that obtains log-polar images from Cartesian ones has been the most frequently used method. In this case, however, care should be taken to perform the log-polar transformation properly. The literature contains several works that provide hints for log-polar mapping computation <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref><ref type="bibr" target="#b73">[74]</ref>, design or resolution considerations <ref type="bibr" target="#b74">[75]</ref><ref type="bibr" target="#b75">[76]</ref><ref type="bibr" target="#b76">[77]</ref>, and alternative fovea designs <ref type="bibr" target="#b77">[78]</ref>.</p><p>Unlike hardware-based sensors, software-based ones have the unavoidable cost of obtaining the log-polar image from the Cartesian image. While this represents no (significant) disadvantage for proof-of-concept studies, it may be a drawback in real applications. To overcome this problem and still count on the flexibility of software, an intermediate solution is represented by virtual log-polar sensors <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b79">80]</ref>. This alternative still needs Cartesian images as input, but the implementation of the log-polar mapping is performed in special-purpose hardware cards, thus making the conversion faster while providing the possibility of setting the sensor parameters. Other possibilities, not considered to date, include parallel implementations of the logpolar transform, or exploring the speed-up provided by the now popular Graphics Processing Units (GPUs) <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b81">82]</ref>.</p><p>In the case of hardware-based retina-like sensors, the maximum resolution achievable is dictated by the limits of the smallest sensing element that current imaging technology has to offer. In contrast, the maximum resolution of log-polar images formed by remapping the contents of Cartesian images depends on the size of the sensing element used in conventional Cartesian images. Therefore, while it is possible to oversample a Cartesian pixel to set the brightness of a set of corresponding log-polar pixels, this strategy can only lead to redundant visual information in the foveal area. For this reason, and because of the singularity of the logarithmic function, a central region is usually kept out of the mapping, thus becoming a blind area, as can be appreciated in Fig. <ref type="figure" target="#fig_2">3</ref>(top). The reverse phenomenon, under-sampling, occurs when many Cartesian pixels contribute to the same log-polar pixel. At the borders between receptive fields, a Cartesian pixel can be recursively subdivided, up to a desired precision, so that its contribution to a given log-polar pixel is weighted according to the percentage of its area lying in the associated receptive field <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b82">83]</ref>.</p><p>Receptive fields can be defined to have different shapes, locations, amounts of overlapping and averaging functions <ref type="bibr" target="#b15">[16]</ref>. Depending on the requirements, different solutions can be adopted. While for higher precision, sub-pixel methods <ref type="bibr" target="#b25">[26]</ref> are possible, sampling without receptive fields averaging is sometimes used to speed-up computations <ref type="bibr" target="#b72">[73]</ref>. Unfortunately, as far as we know, no systematic study has been performed to date on the actual practical impact that these different sampling strategies have.</p><p>There has been some interest in analyzing the influence of sensor parameters on performance in some visual tasks, such as vergence control <ref type="bibr" target="#b83">[84]</ref> or depth recovery<ref type="foot" target="#foot_0">3</ref>  <ref type="bibr" target="#b84">[85]</ref>. Formulating this problem in a more general way, one can be interested in finding the sensor parameters that are best suited to a particular task automatically. As a step further towards this automation, a generic framework is proposed in <ref type="bibr" target="#b85">[86]</ref>, where a genetic algorithm <ref type="foot" target="#foot_1">4</ref>finds the geometric parameters of a log-polar sensor that fulfill a set of given design criteria. A further challenging step would be to automatically find the best sensor configuration adaptively, depending on the particular visual task currently being carried out. While log-polar imaging is adequate for many tasks, it turns out to be limited in certain scenarios. For instance, the log-polar mapping is used in <ref type="bibr" target="#b87">[88]</ref> in a context of human-robot interaction to extract depth information through vergence movements of the cameras of a binocular head mounted on a robotic arm, and to center and track a target (in this case, a user's mouth) <ref type="bibr" target="#b88">[89]</ref>. This work illustrates that having a central region with too much information becomes a disadvantage when a target is too close to the camera, because of the amount of redundancy. Therefore, in such a situation they use a modified log-polar transform <ref type="bibr" target="#b89">[90]</ref>, moving the location of maximum resolution towards the periphery. It can be shown <ref type="bibr" target="#b90">[91]</ref> that Jurie's log-polar mapping <ref type="bibr" target="#b25">[26]</ref> can accomplish this resolution-reversing effect just by properly setting one parameter, even though this was not a planned prerequisite of its design, and neither did the author explicitly mention this property. The logarithmic profiles for different values of this parameter of Jurie's model are shown in Fig. <ref type="figure" target="#fig_7">8</ref>. However, as can be easily verified <ref type="bibr" target="#b91">[92]</ref>, this log-polar model lacks the scaling invariance property. This is a nice example giving rise to the need for flexible general visual transforms so that switching between them can be performed quickly and easily as a function of the requirements of the task at hand. In particular, a generalized (log-)polar transform, with a reduced and meaningful set of changeable parameters, could be a useful tool in a number of computer vision problems. Viewing the mapping-related computations as matrix operations can be a conceptually elegant way to get insight into this desired generalization <ref type="bibr" target="#b92">[93]</ref>.</p><p>To perform experiments under the philosophy of active vision, some researchers propose the use of foveal sensors in conjunction with hardware-based mobile platforms. One of the first of such, conceived for the specifications required by an active vision context, is the spherical pointing motor, a miniature pan-tilt system <ref type="bibr" target="#b93">[94]</ref> that had a CCD sensor mounted on it, and the log-polar transform was applied to obtain a complete space-variant active vision system, Cortex-I <ref type="bibr" target="#b94">[95]</ref>. Binocular systems with log-polar imaging have also been studied, either as single heads <ref type="bibr" target="#b95">[96,</ref><ref type="bibr" target="#b96">97,</ref><ref type="bibr" target="#b77">78]</ref> or as part of bigger humanoid-like robots <ref type="bibr" target="#b97">[98]</ref>. Very often, off-theshelf, commercial (pan-tilt) cameras are used, rather than more sophisticated, high performance, expensive platforms. For some proof-of-concept research these simpler solutions are enough, however. It is important to notice that although all these works use log-polar images in their robotic mechanisms, all of them simulate log-polar images by software conversion. Indeed, little published material exists reporting the direct usage of hardware-based, retina-like sensors, one example being the work by Yeung and Barnes <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b99">100]</ref>. Finally, a few authors also simulate the camera and the environment by using simple graphics-based setups <ref type="bibr" target="#b100">[101,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b101">[102]</ref><ref type="bibr" target="#b102">[103]</ref><ref type="bibr" target="#b103">[104]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Visual attention</head><p>In animals, attention is a cognitive process through which only a reduced subset of all sensory stimuli in the environment is selected. Paying attention to all the information at all times would clearly overwhelm the animal's cognitive capabilities. In robots, this selection is also required since the computational resources are limited, and it is also beneficial to automatically select and process only the most interesting parts. Regarding visual perception, models of primate visual attention <ref type="bibr" target="#b104">[105]</ref>, as well as computational models <ref type="bibr" target="#b105">[106]</ref><ref type="bibr" target="#b106">[107]</ref><ref type="bibr" target="#b107">[108]</ref> have been proposed. Important distinctions in all these models are bottom-up vs. top-down approaches, covert vs. overt attention, and object-based vs. space-based attention <ref type="bibr" target="#b108">[109]</ref>.</p><p>Bottom-up attention is driven by low-level visual cues (contrast, orientation, color, motion, etc.) which are different within a neighborhood and thus become visually salient. On the other hand, top-down attention is guided by the requirements of the current task. Computationally, bottom-up attention is typically modeled through salience maps encoding the degree of local conspicuity within an image, while top-down attention is usually represented by providing these maps with task-related biases.</p><p>In relation with other visual tasks, visual attention can be understood as a core task orchestrating the functioning of the whole system. For instance, before a target is tracked, it should be detected by drawing the attention of the system over other parts of the scene or even over other competing targets. Most tracking works, however, obviate this attentional part, and assume the target position to be known initially, typically by having the target centered in the visual field.</p><p>While a considerable amount of work has been carried out on visual attention in the computer vision and robotics communities, little published material exists that explores the topic within the context of log-polar vision. However, addressing the problem of visual attention combined with foveal vision is relevant and important for several reasons <ref type="bibr" target="#b109">[110]</ref>. First, both log-polar vision and visual attention have sound underlying biological principles and motivations; second, a deep interplay between both issues can be expected and this deserves an in-depth study; and third, these related problems are of great interest for robot vision systems.</p><p>In his thesis, 15 years ago, Milanese considered a model of visual attention with several elements of biological plausibility <ref type="bibr" target="#b110">[111]</ref>. He was possibly a pioneer in considering log-polar images within an attention model. However, this was only lightly dealt with on the surface, as a possible extension of his work. Rao et al. have also explored attention-like problems <ref type="bibr" target="#b111">[112,</ref><ref type="bibr" target="#b112">113]</ref> and provided ideas to extend their approaches to space-variant sensing. A simplified model of salience computation with log-polar images was proposed in <ref type="bibr" target="#b113">[114]</ref>. Some authors <ref type="bibr" target="#b114">[115,</ref><ref type="bibr" target="#b115">116]</ref> have implemented a version of the Itti and Koch's well-known model <ref type="bibr" target="#b116">[117]</ref> for log-polar images (Fig. <ref type="figure" target="#fig_8">9</ref>). The FeatureGate bottom-up attention model <ref type="bibr" target="#b107">[108]</ref> is adopted in <ref type="bibr" target="#b117">[118]</ref> through banks of oriented filters on log-polar images. Unlike many other approaches, they include the optic flow as one of the feature maps.</p><p>The work by Colombo et al. <ref type="bibr" target="#b118">[119,</ref><ref type="bibr" target="#b119">120]</ref> consists in computing ''cortical pyramids'' (image pyramids in the cortical domain) of some given features, an interesting innovative approach in the log-polar literature. As an example, a 3-level cortical pyramid is depicted in Fig. <ref type="figure" target="#fig_0">10</ref>. They describe a system that computes a salience map and models task priorities through scalar weights. From this, they derive a mechanism of gaze selection for attention control. Their simulations with motion features (optical flow magnitude and upper bound on immediacy of collision) allows objects to be recognized after a reduced number of foveations. This setup, while simple, demonstrates the effectiveness of modeling biological theories in computer vision applications. Fig. <ref type="figure" target="#fig_0">11</ref> illustrates how this system works in a toy scenario.</p><p>An interest operator, which can be regarded as a very simple version of a salience-computation model, was defined in <ref type="bibr" target="#b120">[121]</ref> on foveated sensors. By using this operator, a sequence of fixation points are selected, and a panoramic-like representation is built from successive snapshots by combining high and low resolution image areas. A measure of convergence of the ''scan path'' (the sequence of gaze fixations following attentional cues) can be used to evaluate different attention-based strategies <ref type="bibr" target="#b121">[122]</ref>. An example of such a scan path is given in Fig. <ref type="figure" target="#fig_1">12</ref>. Another possible way to assess the performance of a computational model of visual attention is by (subjectively) comparing its results with those of actual persons obtained through psychophysical experiments, as illustrated in Fig. <ref type="figure" target="#fig_2">13</ref>. Sela and Levine <ref type="bibr" target="#b122">[123]</ref> propose an interestpoint selection method, also based on a symmetry measure, a b c d Fig. <ref type="figure" target="#fig_0">11</ref>. Illustration of an attentional system <ref type="bibr" target="#b119">[120]</ref>. From a first ''neutral'' foveation in (a), the dog draws the system's attention in (b) because its immediacy of collision is higher than the speed of the cat, which is moving away. After this, the recognition task is triggered, and a sequence of four foveations are executed to complete the identification of the dog at (c). While the system is recognizing the dog, the train starts moving parallel to the camera, but the system does not interrupt the recognition process because speed detection has a lower priority than the recognition task. Therefore, only after recognition is the system's attention drawn by the moving train at (d).</p><p>Source: With kind permission of Springer Science + Business Media.</p><p>which is then adapted to log-polar images. It can be seen that symmetry-based measures have been repeatedly proposed for visual attention since it is believed that humans are particularly good at detecting symmetric stimuli <ref type="bibr" target="#b123">[124]</ref>. An interest map, combining features such as blobs, bars, corners and opponent color bands, is also used in <ref type="bibr" target="#b124">[125]</ref>, where images resulting from narrow-span saccades are reconstructed (fused) into a single representation.</p><p>While interest or key points detection is usually adopted in matching and recognition problems, they can also be used to compute measures of salience, even though this particular meaning of salience might be somehow different to that implied by researchers who use the term either to denote perceptual salience or to seek more biologically faithful attentional models. For (a) A human subject. 6  (b) The system proposed in <ref type="bibr" target="#b120">[121]</ref> using a symmetry operator.</p><p>Fig. <ref type="figure" target="#fig_2">13</ref>. Similar scan paths. 5   instance, the popular Kadir-Brady Scale Saliency algorithm <ref type="bibr" target="#b125">[126]</ref> (which, despite its name, is also a key-point detector), has recently been tested and compared using log-polar images <ref type="bibr" target="#b109">[110]</ref>.</p><p>Although they do not explicitly demonstrated how it could be achieved, these authors suggest that the same principles could potentially be applied both for interest-point detection and salience computation, since both problems aim at a different, but very similar goal, namely, finding local distinctiveness. In any case, key-point detection and local image descriptors, which have a richer literature in the context of conventional images <ref type="bibr" target="#b126">[127,</ref><ref type="bibr" target="#b127">128]</ref>, remain open problems for log-polar images, and in space-variant imaging in general. Achieving general geometric invariance in local descriptors for these unconventional image formats represents an interesting but challenging issue. Fovea and periphery areas in the image sensor may serve different purposes. Features can be extracted from the periphery to address the ''where-to-look-next'' problem, while central vision is better suited for a detailed analysis of the visual data <ref type="bibr" target="#b128">[129]</ref>. Scene exploration can therefore be performed by the suitable integration of both behaviors. Object recognition can also benefit from active and purposive movements <ref type="bibr" target="#b129">[130,</ref><ref type="bibr" target="#b130">131]</ref>. Baba et al. <ref type="bibr" target="#b131">[132]</ref> propose a fish-eye system where the log-polar images obtained at each eye fixation are integrated into a global map. A similar idea is provided in <ref type="bibr" target="#b132">[133]</ref>, where the merging of old and new visual data into the panoramic image considers the resolution at which the data is acquired. Baron et al. <ref type="bibr" target="#b133">[134]</ref> compute a salience map based on a radial symmetry operator and use this map, along with a set of simple heuristics, to perform a sequence of exploratory fixations, while a long-term memory keeps track of the scene areas that have already been visited. In <ref type="bibr" target="#b134">[135]</ref>, depth maps computed in log-polar images are input to dynamic neural fields to get distinctive blobs of activation which are used to trigger saccades.</p><p>There is not yet full evidence on how salience influences eye movements and these, in turn, influence further visual salience and attention shifts. However, Sun et al. <ref type="bibr" target="#b135">[136]</ref> propose a computational model to integrate (covert) attentional shifts and (overt) gaze movements, based on object-based visual attention and tested on natural scenes, where eye movements were simulated by selecting image windows (no robotic platform is actually used). Log-polar images of these windows are taken and processed.</p><p>Because detailed high-frequency information is lost in peripheral areas of log-polar images, a filtering before sampling (FbS) mechanism is suggested in <ref type="bibr" target="#b136">[137,</ref><ref type="bibr">Ch. 6</ref>]. The idea is to perform local image operations on Cartesian images (filtering) to get feature maps, and only after that is the log-polar transformation (sampling) of these feature maps performed. While there is some biological motivation underlying this strategy, the alternative approach, filtering after sampling (FaS), is not only possible, but also makes sense for several reasons <ref type="bibr" target="#b137">[138]</ref>, including the probable computational advantage and its agreement with the principles of active vision. Both perspectives, FbS and FaS, have advantages and disadvantages, and further studies can be carried out to explore and compare them more deeply.</p><p>Exploring visual salience and attention under a space-variant sampling is of interest not only in computer and robot vision, but also in animal vision studies, as shown in recent research <ref type="bibr" target="#b138">[139]</ref>. The relationship between spatial resolution and visual attention <ref type="bibr" target="#b139">[140]</ref> is also of relevance in the context of foveal-based robot vision.</p><p>We feel that many important topics on visual attention in logpolar images can still be studied, and a few of them are mentioned briefly here. The role of the periphery for attention is of great importance and clearly still under-explored. The integration of overt attention in robotic heads, possibly inspired by existing models of eye movements <ref type="bibr" target="#b140">[141,</ref><ref type="bibr" target="#b141">142]</ref> is a suggestive research avenue for using foveal vision in its natural context of active vision. 7 While computational models for emotion exist for artificial agents, no attempt has yet been performed, as far as we know, to combine attention and emotion. However, biologically, emotions and attention emerge from the same area in the brain <ref type="bibr" target="#b142">[143]</ref>, which suggests their connection, in particular, for top-down attention modeling. Research showing the usefulness of attention for faster, non-brute-force, recognition <ref type="bibr" target="#b143">[144]</ref> has still room of further development, particularly for foveal imaging. Since attention provides a link between perception and action <ref type="bibr" target="#b144">[145]</ref>, it might play a significant role in modeling and implementing affordances <ref type="bibr" target="#b145">[146]</ref>. Demonstrating the usefulness of attention in practical real-world, useful applications, and its seamless integration with the rest of the components of a robotic system, is also an appropriate and exciting direction to pursue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Visual tracking</head><p>Visual tracking consists in keeping track over time of the movements of one or more moving objects within the visual field of a given observer. When the camera dynamically changes its parameters to track a moving object <ref type="bibr" target="#b146">[147]</ref>, this can be referred to as active tracking. On the contrary, passive tracking just keeps record of the target position without moving the camera, and therefore entails a smaller field of view. A simple taxonomy of visual tracking may consider two dimensions: passive/active tracking and uniform/space-variant sampling <ref type="bibr" target="#b147">[148]</ref>. Foveal vision makes most sense when used in active vision scenarios and this is thus our focus in this section. In this context, several issues can be raised regarding the impact on performance of a number of factors such as the dynamics of the mechanical visual system, the delays due to computations, the hardware constraints, and the mobility of the target. These relationships were analyzed in <ref type="bibr" target="#b148">[149]</ref>, using linear optimal control theory.</p><p>There are two main issues to consider in active tracking approaches. One has to do with the estimation of the relative motion between the target to be tracked and the camera. This ''retinal slip'' is one of the main visual features used by humans in controlling the oculomotor behavior known as smooth pursuit <ref type="bibr" target="#b149">[150]</ref>. Most of the work conducted within the context of visual tracking with log-polar sensors addresses this problem and this will be the main interest in this section.</p><p>The second relevant issue to consider is how to control the active tracking device in order to keep the target stabilized in the fovea most of the time. Tracking can only be perfect when the target trajectories are regular. If the system is able to predict these regularities, it can issue the motor commands anticipatively and cancel the delays existing in the control system. Such predictive control schemes are found in infants at early ages and have been implemented recently in humanoid robot heads <ref type="bibr" target="#b150">[151]</ref><ref type="bibr" target="#b151">[152]</ref><ref type="bibr" target="#b152">[153]</ref>. Constant velocity, constant acceleration and sinusoidal motions are typical motions taken into account in these problems. When the trajectories of the target are not regular, tracking errors will arise and the target may move out of the fovea. In these cases the perception system must be able to identify the target in the periphery of the visual system.</p><p>An interesting study by Vincze and Weiman <ref type="bibr" target="#b153">[154]</ref> considers the trade-off existing between sampling time and tracking errors. For a certain velocity error, the longer the sampling time is, the farther away the target will be from the predicted position. This would suggest that short sampling times are better, but with short sampling times one can only process small image windows that may not reach the target. Vincze and Weiman <ref type="bibr" target="#b153">[154]</ref> show that some space-variant sampling approaches, such as log-polar and pyramids, always improve their performance when their visual search range increases: the rate of growth of computation time is smaller than the rate of growth in the window size. The same does not happen for Cartesian geometries, where the window sizes that maximize performance are limited to prevent long sampling times that would allow the target to escape from the field of view. This is a significant argument for the use of space-variant sampling strategies in active tracking scenarios.</p><p>The remainder of this section will review motion estimation methods in log-polar images, either for passive tracking (to update the tracking window) or in active tracking (to update the camera's gaze directions). Although the focus is on tracking, the techniques described here can also be helpful in other problems. We will distinguish between approaches which estimate the target motion more explicitly from those which estimate the change of target position and, therefore, motion is estimated indirectly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Explicit motion estimation</head><p>Motion estimation is a fundamental and challenging problem in computer vision <ref type="bibr" target="#b154">[155]</ref>, and has many applications in robotics, including visual tracking. In terms of the locality of the visual information being used and the usage of parametric motion models, two broad groups of motion estimation methods can be distinguished: optical flow-based ones (which tend to be local and non-parametric) and region-based ones (which are generally more global and assume parametric motion models). Both approaches are discussed in the following paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Optical flow-based methods</head><p>One fundamental technique to estimate motion is that of optical flow <ref type="bibr" target="#b155">[156]</ref><ref type="bibr" target="#b156">[157]</ref><ref type="bibr" target="#b157">[158]</ref><ref type="bibr" target="#b158">[159]</ref>, where the motion is estimated locally either at each image pixel or only at selected image positions. The main advantage of optical flow lies in its flexibility to represent local motion, which is required when the moving object is non-rigid, or articulated, or when different objects move independently in the same scene. However, optical flow estimation also has some disadvantages, such as the influence of the aperture problem <ref type="foot" target="#foot_2">8</ref> , a high computational cost, and noise sensitiveness.</p><p>Theoretically, optical flow can also be computed in log-polar images. Araujo and Dias <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b72">73]</ref> compute the normal optic flow, which is the projection of the flow vector perpendicular to the local image gradient, since the aperture problem prevents the true motion vector from being computed unless more sophisticated means and assumptions are employed. Daniilidis and Krüger have also made contributions to optical flow computation and 3D motion estimates using log-polar images <ref type="bibr" target="#b160">[161,</ref><ref type="bibr" target="#b161">162]</ref>.</p><p>In practice, care must be taken when computing optical flow in log-polar images <ref type="bibr" target="#b70">[71]</ref>. On the one hand, some techniques developed bearing the Cartesian geometry in mind may lead to wrong results if they are directly applied to the log-polar geometry; on the other hand, the particular polar nature and logarithmic sampling of discrete log-polar images motivate the need of devising appropriate filters for computing spatio-temporal derivatives. Similarly, the well-known brightness constancy assumption <ref type="bibr" target="#b159">[160]</ref> underlying many optical flow methods, <ref type="foot" target="#foot_3">9</ref> is easily violated when illumination changes, and under these conditions motion could be wrongly detected even with a static scene. To deal with this problem, a generalized dynamic image model, which also takes into account the changes in brightness, is used in <ref type="bibr" target="#b162">[163]</ref> for log-polar images. In that work, the practical issues related to space-variant sampling are addressed through space-variant local windows and specialized versions of the gradient operator, a topic also considered in other works <ref type="bibr" target="#b163">[164,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Despite these caveats, other authors have used conventional optical flow in log-polar images, not only without drawing attention to any disadvantages, but in fact with reported benefits with respect to Cartesian images <ref type="bibr" target="#b164">[165]</ref>: under fixation conditions, translational motion is nearly zero, and the other affine motion components (rotation, scaling and shear) can be estimated better in polar-logarithmic images. This is based on the fact that the highacuity fovea can appreciate small motion, while the coarser sampling at periphery is more suitable for larger motion estimation, which is something other authors have noticed too <ref type="bibr" target="#b165">[166]</ref>. Tunley and Young's approach has been employed by some authors using log-polar images in active vision tasks <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b166">167,</ref><ref type="bibr" target="#b167">168]</ref>. This idea of detecting large-range motions while still being able to accurately estimate them seems to be under-explored, despite its theoretical and practical attractiveness. Recently, experiments with 1D space-variant arrays of elementary motion detectors (EMD) have been performed to actively track a single target <ref type="bibr" target="#b168">[169]</ref>. The tuning and arrangement of the EMDs within the array are customized according to the expected target velocities and desired precision. Even though this work does not really use log-polar imaging, the concept is however applicable and provides inspiration for further developments.</p><p>For actual practical purposes, the optical flow field itself is not very useful, and some kind of post-processing is required. In <ref type="bibr" target="#b72">[73]</ref>, for instance, the magnitude of the flow vectors are computed and summed along the radial and angular directions. The center of mass of the two resulting magnitude profiles is then used to locate the moving target, and to control the cameras in order to fixate it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Region-based methods</head><p>In contrast to optical flow, which is basically a local approach, global and region-based techniques are attractive for their higher robustness. One known and efficient region-based tracking approach is that proposed by Hager and Belhumeur <ref type="bibr" target="#b169">[170]</ref> for Cartesian images, and which inspired two alternative solutions in the log-polar domain. On the one hand, the work in <ref type="bibr" target="#b170">[171]</ref> brings further efficiency by reformulating the framework and then applying it to log-polar images. On the other hand, the emphasis in <ref type="bibr" target="#b171">[172]</ref> is to exploit the log-polar domain by minimizing the explicit usage of Cartesian coordinates.</p><p>While translation is the simplest motion component in Cartesian domain, because it can be represented simply by two constants (the shifts along the x and y axes), it becomes a complicated space-variant warping in log-polar imagery. An early attempt to solve this used a 1D correlation-based approach along individual rows and columns in an alternative log-polar representation that was particularly suitable for the estimation of translational motion, but lacked the scale and rotation invariance <ref type="bibr" target="#b172">[173]</ref>. More recently, the problem was better addressed in <ref type="bibr" target="#b173">[174]</ref> by proposing and comparing two techniques: a gradient descent optimization approach and a projection-based technique, the latter being much more effective and robust. These two techniques deal with the added complication of how translation maps onto log-polar domain while, unlike <ref type="bibr" target="#b172">[173]</ref>, still preserving the edge invariance property. Bonmassar and Schwartz proposed the exponential chirp transform (ECT) <ref type="bibr" target="#b174">[175]</ref>, by means of which the shift invariance of a Fourier transform still holds in a space-variant domain such as the logpolar, and that was used for motion deblurring <ref type="bibr" target="#b175">[176]</ref>. Although this is an outstanding contribution, the conceptual and implementation complexities behind the ECT probably reduce its appeal in practical applications.</p><p>A progressive registration technique <ref type="bibr" target="#b176">[177]</ref> has been successfully applied to log-polar images in <ref type="bibr" target="#b177">[178]</ref> to track planar structures. The idea is to pre-compute a set of sample templates by assuming a known initial reference template as well as the kind and range of expected image deformations. Planar tracking in logpolar images has also been approached with other methods, such as complex wavelets <ref type="bibr" target="#b178">[179]</ref> and spatio-temporal gradient-based least squares <ref type="bibr" target="#b179">[180]</ref>. A redundant 2D motion parameterization <ref type="bibr" target="#b170">[171]</ref> has proven effective in estimating different parametric motion up to projective models. Basically, a linear combination of partial derivatives is improved by a linear combination of discrete derivatives in several directions and scales.</p><p>The effectiveness and robustness of log-polar images in estimating large rotations and scale changes has been exploited in image registration problems, allowing the recovery of large affine motions <ref type="bibr" target="#b180">[181]</ref>. Motion estimation based on a generalized least-squares (GLS) technique is studied and compared in <ref type="bibr" target="#b181">[182]</ref> both on Cartesian and log-polar images as well as on their combination. These two last works are examples of combining Cartesian images with the log-polar transform. While this idea is a powerful means of exploiting the best of both domains, one of its chief disadvantages is that it would not be applicable if a hardwarebased log-polar sensor were to be used, since only log-polar images are available in this case.</p><p>By using four different kinds of projections (vertical, horizontal, angular and radial), the four parameters of a similarity motion model (horizontal and vertical translation, rotation angle and scaling factor, respectively) can be recovered simultaneously as long as the target is actively tracked, which reduces the amount of relative translation and thus decouples the translational effects from scaling-rotation effects <ref type="bibr" target="#b147">[148]</ref>. This is a nice example of exploiting the synergy of active vision, foveal sensing and appropriately devised algorithms: (i) active tracking simplifies motion estimation; (ii) log-polar images allow fast image processing and facilitates rotation and scaling estimation; and (iii) the efficient and effective projection-based motion estimator makes active foveal tracking possible and simpler. A block diagram of this projection-based approach is given in Fig. <ref type="figure" target="#fig_11">14</ref>.</p><p>A number of approaches have been proposed to take advantage of the fact that changes in scale and rotational motion both map to simple shifts along the log-polar coordinates <ref type="bibr" target="#b171">[172,</ref><ref type="bibr" target="#b147">148]</ref>. However, moving beyond similarity motion models or disabling the active tracking scenario, and still exploiting the log-polar domain, seems considerably harder. A generalization of the spatial projections by using the Radon transform for affine motion estimation has been suggested <ref type="bibr" target="#b182">[183,</ref><ref type="bibr" target="#b43">44]</ref> with interesting, but still limited, results as regards the number of affine parameters and the range or accuracy with which these parameters can be estimated. Nevertheless, logpolar images have been shown to exhibit higher noise robustness and better results than Cartesian images with the same number of pixels and field of view <ref type="bibr" target="#b43">[44]</ref>.</p><p>Unfortunately, some of the more general approaches <ref type="bibr" target="#b170">[171,</ref><ref type="bibr" target="#b183">184]</ref> not only fail to exploit the characteristics of log-polar imaging so smoothly, but also require that the target to be tracked is known in advance, thus posing a significant limit on their practical application. While both ideas are similar, the more recent work <ref type="bibr" target="#b183">[184]</ref>, based on the idea of the interaction matrix proposed for Cartesian images in <ref type="bibr" target="#b184">[185]</ref>, has some advantages over <ref type="bibr" target="#b170">[171]</ref>. This is essentially due to the fact that it does not depend on the motion model (theoretically, any arbitrarily complex motion model can be implicitly adopted) nor on the image sampling scheme (any sampling other than log-polar can be used). A deeper analysis and experimental comparison of both approaches in both theoretical and practical terms would be interesting. Regarding their common limitations of an assumed initial template, two kinds of interesting, non-trivial solutions can be considered. On the one hand, the computationally heavy off-line procedures now involved in these approaches should be turned into very fast real-time processes, so that they could be applied on-line once the target to be tracked is decided. The other alternative would seek the quite different route of devising some template-independent technique, and still sharing with existing approaches nice properties such as searchfree motion estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Feature-based approaches</head><p>The advantage of feature-based tracking is that, once features have been extracted, fewer data have to be processed and matching may be less ambiguous. However, good features need be found and matched, which is not always easy, and the object of interest must have enough texture. Additionally, detecting certain features in log-polar images can become a particularly challenging problem. Corner detection, for instance, was tackled in <ref type="bibr" target="#b98">[99]</ref> through a Hough-based straight-line detection. Detecting lines through the Hough transform becomes more natural in log-polar space since the Hough and (log-polar) image spaces are the same, as found almost 20 years ago <ref type="bibr" target="#b185">[186]</ref>. Since then, other researchers have been attracted by the problems of line and circle detection in the log-polar domain <ref type="bibr" target="#b186">[187,</ref><ref type="bibr" target="#b187">188]</ref>. In general, learning is found to be a better strategy for extracting some features (edges, bars, blobs) than mathematically modeling these features <ref type="bibr" target="#b188">[189,</ref><ref type="bibr" target="#b189">190]</ref>. Specialized table-based data structures are proposed <ref type="bibr" target="#b190">[191]</ref> to compute image processing operations directly and efficiently onto foveated images. While initializing these tables can be time consuming, this off-line effort is paid off by the real-time on-line application.</p><p>As mentioned above, because of their sampling, log-polar images are suitable for detecting large motion in the periphery and smaller motions at the fovea <ref type="bibr" target="#b179">[180,</ref><ref type="bibr" target="#b165">166,</ref><ref type="bibr" target="#b72">73]</ref>, since these areas have different motion sensitivity. Weiman and Juday proposed three tracking algorithms acting differently, depending on the position of the target blob <ref type="bibr" target="#b191">[192]</ref>. An interesting aspect of their approach is that they exploit the nature of log-polar images. For instance, instead of explicitly computing the centroid of a blob, centering it can be achieved actively by camera movements that maximize the number of target pixels. This is a nice example of how properties of log-polar mapping can be considered and exploited. This algorithm is also used in <ref type="bibr" target="#b192">[193]</ref>, as part of a gaze control mechanism. Similarly, <ref type="bibr" target="#b100">[101]</ref> uses the fact that objects increase in size as they approach the fovea.</p><p>Tracking simple bright shapes moving on a uniform black background is considered in <ref type="bibr" target="#b193">[194]</ref> as a proof-of-concept of the adaptation to the log-polar domain of a number of well-known image processing techniques (erosion, dilation, region labeling, boundary tracking, corner detection and Hough transform of circles, ellipses and polygons).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Other tracking approaches</head><p>Due to their particular geometric nature, log-polar images are particularly well suited for actively tracking one single object at a time. However, the unconventional work by Kang and Lee <ref type="bibr" target="#b194">[195]</ref> considers the tracking of several objects passively (i.e. without camera movements) by keeping image templates and updating them over time. In a simulated active vision system, Lim et al. <ref type="bibr" target="#b100">[101]</ref> also addressed a simplified version of the problem of tracking multiple targets. They decide which object to foveate and track next as a function of the size of the objects, how much they have moved between consecutive images, and their distance to the fovea.</p><p>Principal Component Analysis is employed in <ref type="bibr" target="#b25">[26]</ref> for face detection and tracking in log-polar images. This approach uses a single face model for all possible positions. Under a space-variant imaging representation, however, considering multiple models seems more advantageous, as it takes advantage of the varying resolution, as suggested in <ref type="bibr" target="#b195">[196]</ref>.</p><p>Since color is invariant to a number of geometric and resolution changes, it is an appropriate cue in some visual tasks, allowing distinctively colored objects to be robustly tracked even in logpolar images <ref type="bibr" target="#b196">[197]</ref>.</p><p>Background subtraction is a well-known technique to detect objects moving on a static background <ref type="bibr" target="#b197">[198]</ref>. However, these algorithms generally do not account for a moving background, and are therefore not useful with a moving observer. In those situations, a panoramic image can be built, so that a part of the scene can be indexed according to the direction of the observer's gaze. In the case of a pan-tilt unit, spherical panoramas seem to be particularly well suited to a polar-like image representation, as suggested in <ref type="bibr" target="#b132">[133]</ref>. An alternative way of segmenting an unknown object from the background can be performed if the object is actively tracked and the background changes over time <ref type="bibr" target="#b171">[172]</ref>.</p><p>Binocular tracking is still another possibility, but it is left to Section 7, where 3D issues (depth recovery and vergence control) will be examined.</p><p>To recap on the usage of log-polar vision in tracking, it is worth stressing how the implicit focus-of-attention brought by the foveal predominance (Section 2) has been considered for tracking without explicitly segmenting the target. However, this is only possible if tracking is very accurate and/or the object has a minimum size and certain round-like shapes. For instance, it has been found <ref type="bibr" target="#b147">[148]</ref> that centered targets should represent roughly 25% of the field of view to successfully estimate their motion and track them. While this result actually depends on the particular mapping parameters being used and the capabilities of the tracking algorithm, it is nevertheless clear that further research is still required to address the tracking of non-centered, smaller, arbitrarily-shaped targets, and also multiple targets. The actual challenge lies in solving these problems as elegantly as possible so that log-polar imaging, combined with powerful active vision strategies, can still have advantages to offer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Egomotion estimation</head><p>Egomotion is the motion of the observer (a pan-tilt camera, a robot arm, or any other dynamic visual agent). Its estimation is important in those situations where the knowledge of actual robot movement is required either for self-localization, or to distinguish it from the motion of objects in the scene. Although egomotion estimation can be tackled with the general tools for motion estimation, some specific approaches have been proposed that exploit the task at hand. Two common characteristics of these systems are their reliance on the computation and analysis of patterns of optic flow, and their hardware implementation (usually, on FPGA-based architectures). Not surprisingly, the polarlike geometric nature of log-polar images makes them very suitable for the estimation of self-motion in the direction of the optical axis. When the focus of expansion is aligned with the center of the log-polar transform, motion flow vectors are only radial and of uniform magnitude in the log-polar plane. As a result, time-toimpact (also called time-to-collision, or its reciprocal, immediacy of collision) computation can be addressed more easily <ref type="bibr" target="#b198">[199]</ref><ref type="bibr" target="#b199">[200]</ref><ref type="bibr" target="#b200">[201]</ref><ref type="bibr" target="#b201">[202]</ref><ref type="bibr" target="#b202">[203]</ref>. However, some authors find that the main benefit comes from the polar structure and no advantage, besides the computational speed-up, are gained from the logarithmic radial sampling <ref type="bibr" target="#b203">[204]</ref>. Others consider that these radial-like sensors (polar and logpolar) bring no particular advantage for the time-to-collision computation, which is in fact simplified by the assumption of fronto-parallel surfaces <ref type="bibr" target="#b204">[205]</ref>.</p><p>When it is the observer that moves, rather than a visual target, the task of keeping a static target in view is called fixation. The problem of fixation is similar to that of tracking, and has also been tackled with log-polar images <ref type="bibr" target="#b179">[180,</ref><ref type="bibr" target="#b205">206,</ref><ref type="bibr" target="#b206">207,</ref><ref type="bibr" target="#b98">99,</ref><ref type="bibr" target="#b207">208]</ref>. Ahrns and Neumann <ref type="bibr" target="#b205">[206,</ref><ref type="bibr" target="#b206">207]</ref> compare log-polar and Cartesian windows and find that error measures tend to be more robust, with fewer local minima, under a log-polar sampling. This result for the pan angle of a camera, has been repeatedly verified in other contexts, such as in vergence control <ref type="bibr" target="#b208">[209,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b83">84]</ref>, or translation estimation <ref type="bibr" target="#b209">[210]</ref>. An interesting point in the appearance-based fixation strategy by Ahrns and Neumann is that a confidencebased measure, by comparing the reference and current views, is incorporated to make the procedure more robust against occlusions or other changes of view <ref type="bibr" target="#b206">[207]</ref>.</p><p>Daniilidis proposed two algorithms for the estimation of the focus of expansion, which are based on a 1D global minima search for flow patterns <ref type="bibr" target="#b203">[204]</ref>. Similarly, the rotational component of optical flow is used in <ref type="bibr" target="#b210">[211,</ref><ref type="bibr" target="#b211">212]</ref> to implement an active docking behavior, which aims to align the camera's optical axis with the robot's direction of motion. Silva and Santos-Victor found that the subset of points whose radial and circular normal flow vectors do not depend on the camera translation are described, respectively, by a special circle and line <ref type="bibr" target="#b212">[213]</ref>. These image locations provide relevant geometric information about the observer's motion, and their estimation is reduced to searches along horizontal and vertical lines in the log-polar image, so that the focus of expansion and the rest of the parameters are estimated in a two-step algorithm <ref type="bibr" target="#b212">[213]</ref>. In <ref type="bibr" target="#b213">[214]</ref>, four sets of spatio-temporal Gabor filters are applied: two spatial filters are aligned in the radial and angular directions, while two temporal Gabor filters are tuned to opposite directions of motion, so that expanding and contracting patterns of motion can be discriminated.</p><p>Bishay et al. <ref type="bibr" target="#b214">[215]</ref> take advantage of the fact that a mobile robot moving along an indoor corridor will perceive the edges arising from the intersections between the walls and the floor and between the walls and the ceiling as horizontal lines in the log-polar plane. Additionally, the varying resolution of log-polar images simplifies a matching procedure, since doors or lamps along the corridor map to very similar patterns even when they are at different depths. This makes the detection of these landmarks simpler and faster for robot navigation. Similar ideas are explored in <ref type="bibr" target="#b215">[216]</ref>. Advantages of log-polar and other task-specific image representations are also exploited in <ref type="bibr" target="#b216">[217]</ref> for robot navigation in a corridor. In outdoors environments with some structure, such as roads, these kinds of benefits also apply: lane marks in straight road sections become parallel lines in the log-polar space and vehicles are perceived with the same size and shapes. However, this is only true if the vanishing point coincides with the center of the log-polar transform. To fulfill this assumption, the camera has to be fixated on the vanishing point, so that the movements of the vehicle on which the camera is attached can be compensated for <ref type="bibr" target="#b103">[104]</ref>.</p><p>To distinguish ecomotion (the object's motion) from egomotion, a differential algorithm is proposed for log-polar images, and implemented using FPGAs <ref type="bibr" target="#b217">[218]</ref><ref type="bibr" target="#b218">[219]</ref><ref type="bibr" target="#b219">[220]</ref><ref type="bibr" target="#b220">[221]</ref> based on the fact that the second temporal derivative in the image sequence is non-zero only at the borders of self-moving objects.</p><p>Omnidirectional vision, usually consisting of the combination of a curved mirror and a camera pointing towards this mirror, provides a 360-degree view, which can be very effective for robot navigation. Under this arrangement, if conventional cameras are used, the resulting images have to be unwarped for their human or machine processing. However, the mirror's shape can be designed to match certain design properties and, when combined with a logpolar camera, rectangular panoramic images are obtained directly, with no additional computational effort <ref type="bibr" target="#b221">[222,</ref><ref type="bibr" target="#b222">223]</ref>. These ideas are illustrated in Fig. <ref type="figure" target="#fig_13">15</ref>.</p><p>One problem related to egomotion estimation is image stabilization, where the goal is to compensate for unwanted camera movements so that better images are obtained. Some benefits of using log-polar images in the context of this problem were explored in <ref type="bibr" target="#b223">[224]</ref>, where optical flow is computed in four selected peripheral regions of the log-polar image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">3D cues and vergence control</head><p>One of the most important capabilities of autonomous robots is their ability to perceive the three-dimensional structure of the environment, in order to avoid obstacles, recognize shapes, and manipulate objects. Several cues for depth perception can be used from an image stream. In monocular systems, motion, focus and shading cues (amongst others) have been systematically used to address the problem of depth perception. In binocular systems, depth can be computed via stereo, a conceptually simple and easy methodology. In active vision systems <ref type="bibr" target="#b10">[11]</ref>, improved perception can be achieved by controlling the camera motion. In this section we will review the main works using log-polar sensors for depth perception, considering both static and active vision systems. In the active case we will also refer to the control of the vision system parameters for improved perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Depth maps</head><p>Though a full 3D reconstruction of the environment is not possible in the general case and, indeed, may not even be a desirable goal under a purposive vision philosophy <ref type="bibr" target="#b224">[225]</ref>, depth maps (i.e. images where each pixel location represents the measured depth of an observed 3D point) are important perceptual structures for robot motion and behavior control.</p><p>Beyond the obvious reduction in computational cost, log-polar images have other benefits in computing depth maps. Although the greatest advantages arise in active vision scenarios (see next section), the use of log-polar sensors is advantageous in the following cases:</p><p>• Depth from forward motion: When the observer is moving forward in natural scenarios, the optical flow amplitude grows, on average, from the center to the periphery of the visual field. Due to the log-polar transformation properties, the magnitude of the optic flow in the periphery is reduced, thus facilitating its computation by local search or gradient methods <ref type="bibr" target="#b225">[226]</ref>.</p><p>• Depth from convergent stereo: In converging camera configurations the image planes are rotated with respect to each other. This poses registration difficulties because corresponding points in the two images diverge towards the periphery of the visual field. Again, since log-polar tessellations compress coordinates in the periphery, registration mismatches are reduced, thus facilitating the search for corresponding points <ref type="bibr" target="#b226">[227]</ref>.</p><p>In this section we review some works that compute depth maps in log-polar images. The techniques are similar to their Cartesian counterparts, but must be adapted to cope with the different image topology. Two basic approaches have been used: depthfrom-motion and depth-from-stereo.</p><p>In depth-from-(ego)motion, a (monocular) moving observer in a static scenario can stabilize the center of the image by a proper gaze control. In these fixation conditions, the depth-from-motion problem becomes well-posed and its dimensionality is reduced. Optical flow corresponding to camera motion can then be used to  compute the depth only at sufficiently textured pixels (sparse depth maps) <ref type="bibr" target="#b225">[226]</ref>. Alternatively, a phase-based technique using Gabor filters can be used to compute optical flow vectors and integrate them over time via a Kalman filter <ref type="bibr" target="#b227">[228]</ref>. This results in a depth estimation for every pixel (dense depth map).</p><p>The second approach, depth-from-stereo, uses two cameras and the projection of 3D scene points onto different locations in the retinas. The difference between these corresponding locations, known as disparity, depends on the depth of the observed point as well as on the camera setup calibration. Sparse disparity maps can be computed <ref type="bibr" target="#b228">[229]</ref> by estimating disparity in log-polar images at pixels with enough texture. Dense disparity maps are computed in real time in <ref type="bibr" target="#b229">[230]</ref> by testing several hypotheses between pixels from the left and right cameras and using local pixel interactions to avoid ambiguities in the disparity estimates in non-textured areas.</p><p>More recently, epipolar geometry has been proposed to compute dense disparity maps in log-polar images <ref type="bibr" target="#b230">[231]</ref>, which reduces the general 2D matching problem to a 1D search along the epipolar lines. However, since straight lines in the Cartesian domain become curves in the log-polar space, good line re-sampling algorithms are required for an accurate matching procedure <ref type="bibr" target="#b187">[188]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Active perception</head><p>Log-polar images have their maximum acuity in the central part (the fovea). Furthermore, the rotation and scaling invariance properties only hold when objects are centered in the visual field. Therefore, when analyzing some particular targets of interest, it is natural to consider controlling the cameras motion so as to keep the targets centered in the fovea. This is also the solution adopted by foveated biological vision systems, which are constantly changing the direction of their gaze toward the objects of interest. Fig. <ref type="figure" target="#fig_14">16</ref> shows a couple of active robotic stereo heads that have been used within this paradigm.</p><p>The advantages of using this elegant combination of foveated sensors and active vision systems have been demonstrated in a series of works. As far as depth estimation is concerned, Weiman <ref type="bibr" target="#b233">[234]</ref> was one of the first to formally analyze the gains obtained from the use of log-polar images (apart from the obvious computation reduction aspect). It was shown that the maximum stereo resolution with a Cartesian binocular setup is obtained inconveniently at the periphery of the visual field, whereas logpolar stereo resolution is maximal in the center of the visual field of both cameras. Therefore, actively controlling the point of (a) Baltazar's head <ref type="bibr" target="#b231">[232]</ref>.</p><p>(b) Eurohead <ref type="bibr" target="#b232">[233]</ref>. fixation toward the objects of interest allows the visual acuity to be maximized also in the depth dimension.</p><p>To be able to fully exploit the stereo resolution properties of log-polar stereo, the fixation point must be controlled to track the object of interest. In active vision systems, oculomotor control is usually inspired in its biological counterparts and is decomposed into vergence and version movements <ref type="bibr" target="#b234">[235]</ref>. To track motions in depth, the vergence angle should be adjusted so that the fixation point matches the distance from the object of interest. To track motions in fronto-parallel directions to the observer, the camera's direction is controlled to center the target in the eyes. Interestingly, it has been demonstrated that log-polar images facilitate the tracking problem per se, both in depth and in fronto-parallel directions to the cameras <ref type="bibr" target="#b235">[236]</ref>.</p><p>When a target is being tracked, its disparity in the images is near to zero, i.e. there is a close match between the information contained in the same retinal coordinates in both images. Some authors have proposed the maximization of a binocular fusion index measured by the correlation between the left and right images <ref type="bibr" target="#b236">[237,</ref><ref type="bibr" target="#b237">238]</ref>. The process involves the execution of some exploratory motion on the vergence angle in order to obtain the gradient of the fusion index, and then controlling the vergence angle so as to maximize it. A correct vergence on the object would be attained when the fusion index is at its maximum value. In <ref type="bibr" target="#b26">[27]</ref>, this method is complemented by estimating the expansion and contraction patterns from the optical flow of the image, velocity feedback measurements being provided for vergence control.</p><p>Searching for the maximum fusion index requires active vergence movements, which may lead to some problems in the control loop. Other alternatives have been proposed that attempt to overcome this problem. In <ref type="bibr" target="#b236">[237]</ref>, it is proposed to Fig. <ref type="figure" target="#fig_6">17</ref>. Zero disparity filtering in log-polar images <ref type="bibr" target="#b235">[236]</ref>. When objects are under fixation in both cameras, their disparity is close to zero. A zero disparity filter can thus segment the points belonging to the object (right column). This process is illustrated for a hand (top row) and a face (bottom row). The input stereo images are in the left and middle columns.</p><p>compute the dominant disparity in the images explicitly, by evaluating the correlation between the images, where one of the images is transformed according to certain disparity hypotheses. The hypothesis with maximum correlation is taken as the true disparity. This value is then input to a feedback PID filter in order to control the vergence angle.</p><p>In <ref type="bibr" target="#b238">[239]</ref>, a similar approach is taken but using the concept of virtual horopter <ref type="bibr" target="#b239">[240]</ref> and the output of zero disparity filters <ref type="bibr" target="#b240">[241]</ref>. The horopter is the locus of all points with zero disparity. Points in the horopter can be segmented in the images by matching left and right image patches at the same image coordinates, in a process known as zero disparity filtering (ZDF). Such points are then assigned to the target under vergence. Fig. <ref type="figure" target="#fig_6">17</ref> illustrates the ZDF process by which points belonging to the target under vergence are segregated from the background. A virtual horopter, tuned for disparities other than zero, can be obtained by transforming one of the images according to the required disparity. Oshiro et al. <ref type="bibr" target="#b238">[239]</ref> create several virtual horopters for a discrete set of disparity hypotheses, and compute the output of zero disparity filtering for each one. The disparity hypothesis leading to the greatest number of segmented points is then fed back to control the vergence angle.</p><p>The segmentations provided by zero disparity filtering have proven useful for rejecting points belonging to background elements. Although the log-polar mapping attenuates background elements in the periphery of the visual field in a hard-wired manner, the output of zero disparity filtering has been exploited to provide added robustness to tasks. In <ref type="bibr" target="#b26">[27]</ref>, affine optical flow parameters are computed on the target region and used for vergence control. In <ref type="bibr" target="#b235">[236]</ref> the centroid of the segmented region and the translational parameters of the optical flow are used for tracking in the fronto-parallel directions, controlling the robot head pan and tilt degrees of freedom.</p><p>In the above-mentioned works, the set of disparity hypotheses is often distributed in a non-uniform fashion; it samples the small disparity range densely and has a coarse representation of large disparities. The purpose is to have simultaneously, and with limited computational resources, good precision in keeping the target disparity close to zero and the ability to detect and compensate for large disparities. In <ref type="bibr" target="#b241">[242]</ref>, an explicit rule to determine the set of disparity hypotheses is proposed, and sub-pixel disparity estimation is achieved by employing quadratic interpolation methods.</p><p>Methods based on testing disparity hypotheses have proven to be fast and robust to environmental changes. In <ref type="bibr" target="#b1">[2]</ref>, it was shown that vergence control with correlation measures in logpolar images allows smaller objects to be tracked than its Cartesian counterpart. The reason provided empirically is that global disparity computation is dominated by the disparity with the largest support, in terms of numbers of pixels. In Cartesian images this is only the case when the object occupies a very large part of the image (&gt;50%). However, in log-polar images, objects can be much smaller if they are centered in the retina, due to the larger number of pixels assigned to the fovea. Fig. <ref type="figure" target="#fig_15">18</ref> shows a sequence where a small object approaches the center of the image. While in the periphery its influence on the global disparity is small and the system does not change its vergence, as it approaches the fovea its weight increasingly grows and the robot locks onto the target.</p><p>The global disparity computation in log-polar images using correlation measures is theoretically equivalent to performing the same computation in Cartesian images that are pre-weighted by a function (the Jacobian of the log-polar transformation) that attenuates the value of background pixels <ref type="bibr" target="#b1">[2]</ref>. Although this analysis in the Cartesian domain clarifies the advantage of using log-polar images for centered objects, for computational reasons it is preferable to perform the operations in log-polar images due to the smaller number of image pixels to be processed. However, as in the case of tracking, whether (and how) the scenario of noncentered objects can be appropriately coped with remains an open issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">A look to the future</head><p>The research on log-polar imaging, with emphasis on the robot vision community, has been reviewed in this article. In the past few years, fundamental properties of this image representation have been studied and exploited in appropriate algorithms.</p><p>One criticism that can naturally be posed is whether, taking all into account, it is really worth adopting log-polar images. Regarding the computational advantages, it could be argued The first image (left) corresponds to the binocular system verging on the background. No other objects are present. In the second image, an object appears in the periphery, but it is still far from the center and the system keeps fixating the background. In the third image, the object approaches the fovea and the system starts moving the cameras in order to gaze at the target. Finally, in the fourth image (right) the object is in the fovea and the system verges perfectly on the target. (Figure to be seen in color).</p><p>that, after all, almost any task solved with log-polar images can be (and in many cases has been) approached successfully using conventional images. This is possible due either to the use of special-purpose, high performance equipment or to the advances in hardware technology, which make a reduction in image processing times affordable. While this is certainly true, it should be noted that, in any case, equal conditions (same computer resources), performance can always be better with logpolar images. We like to compare the computational benefits of log-polar image sensors with those offered by algorithmics. It may be the case that a quadratic cost O(n 2 ) algorithm exists to solve some known and useful problem. If a novel algorithm is devised that allows this same problem to be solved in logarithmic cost O(log n), this is seen as an outstanding achievement because the order of magnitude of the speed-up has a more profound and significant impact than those allowed by advances in hardware technology. This is also the scenario with logarithmic polar images, where, as a function of the field width ρ, the spatial complexity would be logarithmic, O(log ρ), in contrast to the quadratic cost, O(ρ 2 ), exhibited by the uniform resolution images <ref type="bibr" target="#b75">[76]</ref>.</p><p>Like the design of a new algorithm that outperforms existing ones, which may be a rather contrived, intellectually demanding task, the design of retinal sensors faces its own challenges too. Furthermore, having a good sensor does not, by itself, guarantee that any visual task will be performed efficiently and successfully. On the contrary, appropriate algorithms and mechanisms should be conceived to exploit the advantages of such a sensor and to deal with its difficulties.</p><p>As described in Section 2, some properties of log-polar imaging such as scale and rotation invariance, the selective data reduction or the implicit focus-of-attention have been widely explored, while others have only been slightly considered (or still remain undiscovered!). One example is the better numerical behavior that log-polar images offer for eye-in-hand visual servoing, as revealed by an analysis of the Jacobian matrix condition number <ref type="bibr" target="#b242">[243,</ref><ref type="bibr" target="#b243">244]</ref>, and its comparison with polar images.</p><p>Finally, as in many algorithmic achievements, the log-polar geometry offers a trade-off solution. Compromises of some kind are at the core of many new discoveries in any field, and particularly in computer science. Benefits are often possible only at the cost of something else. Indeed, progress in scientific research is in many respects determined by well-engineered trade-off solutions. Log-polar sensors are, to our mind, one of such solutions.</p><p>The geometric and sampling properties of log-polar images have been emphasized throughout the paper. It has become clear that polar-logarithmic sampling provides interesting benefits in a number of scenarios. But it has also been shown that more general or customizable mappings could be more generally useful.</p><p>While log-polar vision is one of the most popular foveal sensing models being used, some works consider the simultaneous use of wide-and narrow-field cameras so that their coordination makes it possible to have both rough visual data from large field of view and detailed information from a narrow part of the scene. Most of these arrangements use conventional Cartesian images <ref type="bibr" target="#b244">[245]</ref>, but recently log-polar images have been considered in a system inspired by the eyes of birds of prey <ref type="bibr" target="#b102">[103]</ref> for easier detection and tracking of objects in a wider visual scene. In their approach, Melnyk and Messner use a driving simulator to illustrate how two images from two cameras of different fields of view can be seamlessly integrated into a single log-polar image where the oversampling problem (Section 3) is somehow solved.</p><p>We would like to point out two potential areas of application where foveal vision is now absent, but could fit in well. In sensor networks, there are four resources that can be limited: power, sensing, communication and computation <ref type="bibr" target="#b245">[246]</ref>. In the case of vision networks, all of these resource requirements can benefit from using log-polar sensors. Indeed, we found that our idea about the challenges imposed by the resolution-variant images and the need for proper algorithms addressing these visual limitations finds support in the following quote: ''Finally, tiny inexpensive sensor nodes are often limited in computational capability, so developers may need to implement computationally lightweight algorithms that sacrifice sensing quality but take advantage of the distributed computation resources of the sensor network.'' <ref type="bibr">[246, p. 38]</ref> While its authors did not seem to have had foveal vision in mind when they wrote it, we find an appropriate link between this statement and the issues raised by foveal sensing.</p><p>A second class of domains where foveal sensing might prove beneficial is in applications involving control loops that require very low latencies. This is the case not only in robot control, but also in perceptual user interfaces (PUIs) <ref type="bibr" target="#b246">[247]</ref>, and visualbased interfaces in particular <ref type="bibr" target="#b247">[248]</ref>. One key problem in PUIs is to guarantee low reaction times to user commands captured through cameras as the input signal. Latencies that are too high may lead to unstable behavior and low usability of the interface and, in the end, low user acceptability of the system. Log-polar images might be an advantageous sensing device for these perceptual interfaces, which may include human-robot interaction <ref type="bibr" target="#b248">[249]</ref>.</p><p>Algorithmic, computational and geometric issues aside, still another insight on why log-polar vision can deserve study and investigation lies in its biological inspiration, for two reasons. One, because nature is wise and we, scientists and engineers, can try to introduce some of this wisdom into the artificial systems we build. And two, because these very artificial agents can provide us with</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The log(z) model for retino-cortical mapping, where a central circle of small radius has been left out of the mapping in order to deal with the singularity problem. The retinal plane (left) is mapped onto the cortical plane (right) via w = log(z). Concentric circumferences and radial lines in the retinal plane become straight lines in the cortical plane. Rectangular cells in the transform domain correspond to sections of concentric annuli in the original domain.</figDesc><graphic coords="2,453.70,63.89,105.18,128.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 ..</head><label>2</label><figDesc>Fig. 2. The log(z + a) model [25] can be seen as removing the shaded region in (a) from the log(z) model. The new log-polar coordinates are designed to have connectivity at the origin and regions organized in the usual quadrants (Q 1, Q 2, Q 3, Q 4). Figure adapted from [25]. Source: With kind permission from Springer Science + Business Media: International Journal of Computer Vision, Volume 13, 1995, pages 75, R. Wallace, P. Ong, B. Bederson, and E. Schwartz, Fig. 3. • first and fourth quadrants (x ≥ 0): ξ = log (x + a) 2 + y 2 -log(a) η = arctan</figDesc><graphic coords="3,326.36,63.92,201.96,195.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Top: Retinal images on the log-polar mapping template. Bottom: The corresponding log-polar images. To illustrate the edge invariance property, the image on the left is rotated (middle) and scaled (right), which correspond to approximate translations in the log-polar domain, in the angular (η) and radial (ξ ) directions, respectively, as shown with the arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 4. Overlapping models: (a) the model of<ref type="bibr" target="#b28">[29]</ref> implemented in<ref type="bibr" target="#b30">[31]</ref>, and (b) the model in<ref type="bibr" target="#b29">[30]</ref> (figure taken from<ref type="bibr" target="#b15">[16]</ref>).2   </figDesc><graphic coords="4,317.46,247.50,239.46,230.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 4. Overlapping models: (a) the model of<ref type="bibr" target="#b28">[29]</ref> implemented in<ref type="bibr" target="#b30">[31]</ref>, and (b) the model in<ref type="bibr" target="#b29">[30]</ref> (figure taken from<ref type="bibr" target="#b15">[16]</ref>).2   </figDesc><graphic coords="4,49.45,63.93,237.24,186.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Some alternative foveal imaging methods. Left column: original Cartesian image; Middle column: image in the transform space; Right column: Cartesian image after reconstruction from transformed image.</figDesc><graphic coords="5,32.68,272.10,243.06,71.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Retina-like sensors.</figDesc><graphic coords="6,244.72,66.29,115.98,113.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. Customizable mappings. Under Jurie's model<ref type="bibr" target="#b25">[26]</ref>, different profiles for the radial log-polar coordinate (ξ ) can be obtained with different values of a parameter (ρ 0 ), as a function of the eccentricity (ρ): ξ = log a ρ+ρ 0 ρ 0 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Salience maps. Results of a model of object-based visual attention being tested on Babybot, a humanoid robot endowed with log-polar vision [116]: picture 4 is the bottom-up salience of picture 1; picture 5 is the top-down salience map of picture 2; and picture 6 shows a segmented object after its recognition. © 2005 IEEE.</figDesc><graphic coords="8,52.62,63.93,231.12,154.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .Fig. 12 .</head><label>1012</label><figDesc>Fig.10. A 3-level cortical pyramid<ref type="bibr" target="#b119">[120]</ref>. Cortical (log-polar) images are on the bottom row and their reconstructions to Cartesian (retinal) space are in the top row. Resolution (and the size of the log-polar images) decreases from left to right.Source: With kind permission of Springer Science + Business Media.</figDesc><graphic coords="8,150.97,586.38,303.18,131.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>5</head><label></label><figDesc>Source: Reprinted from Computer Vision and Image Understanding, Vol. 63, No. 1, H. Yamamoto, Y. Yeshurun, and M. D. Levine, An active foveated vision system: Attentional mechanisms and scan path convergence measures, Pages 50-65, Copyright (1996), with permission from Elsevier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. From projections to motion estimates [148]. Radial and angular projections, R k , A k , of the input images, I k , k ∈ {1, 2}, allow the estimation of shifts s and r along the two axes in the log-polar plane which, through the scale and rotation invariance of this mapping, can be readily converted into the estimated change of scale and rotation angle, respectively. Shifts s and r are then used to rectify one of the input images, so that finally the remaining translational shifts, b and c, are estimated from the vertical and horizontal projections, V k and H k . In turn, b and c are used to control the camera's pan and tilt degrees of freedom.</figDesc><graphic coords="11,319.53,63.89,215.70,112.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(a) Catadioptric system. (b) Image with a conventional setup. (c) Image with a space-variant camera.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. (a) Catadioptric sensor designed within the OMNIVIEWS EU project [223]; panoramic images obtained with (b) a conventional mirror-camera setup, and (c) a mirror designed to match the geometric features of an existing log-polar camera. © 2002 IEEE.</figDesc><graphic coords="14,436.62,291.68,124.92,91.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Example of robotic active stereo heads: (a) the head of Baltazar [232], a humanoid robot, and (b) Eurohead [233], a high precision head for quality measurements.</figDesc><graphic coords="14,312.81,292.81,114.12,90.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 18 .</head><label>18</label><figDesc>Fig.18. Active vergence control using log-polar images<ref type="bibr" target="#b236">[237]</ref>. Global disparity computation in log-polar images weighs objects in the center more favorably. Four images of an active tracking sequence are shown. Each color image codes both images of the stereo pair: the right image in the red channel and the left image in the green channel. The first image (left) corresponds to the binocular system verging on the background. No other objects are present. In the second image, an object appears in the periphery, but it is still far from the center and the system keeps fixating the background. In the third image, the object approaches the fovea and the system starts moving the cameras in order to gaze at the target. Finally, in the fourth image (right) the object is in the fovea and the system verges perfectly on the target. (Figure to be seen in color).</figDesc><graphic coords="16,115.18,63.92,374.76,122.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="15,143.81,63.90,297.88,241.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>2</head><label></label><figDesc>Source: Reprinted from Computer Vision and Image Understanding, Vol. 69, No.</figDesc><table /><note><p>2, M. Bolduc and M. D. Levine, A review of biologically motivated space-variant data reduction models for robotic vision, Pages 170-184, Copyright (1998), with permission from Elsevier.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>The concepts of vergence control and depth recovery are covered later, in Section 7.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Genetic algorithms are a kind of stochastic optimization methods that are particularly useful in searching in large and non-convex search spaces<ref type="bibr" target="#b86">[87]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_2"><p>The aperture problem arises because the limited visual data of a local analysis prevents the true direction of motion from being inferred<ref type="bibr" target="#b159">[160]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_3"><p>Basically, this assumption states that a change in brightness at an image location can only be due to an underlying motion.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors acknowledge the Integrated Actions programs funded by the Portuguese Government and Spanish Ministry of Science and Education, through projects E 47-06 and HP2005-0095, respectively, under the topic ''FOVEAR: Foveal vision for robotic applications'', and the Spanish research programme Consolider Ingenio-2010 CSD2007-00018. The authors are also grateful to the anonymous reviewers for their comments, the ''Servei de Llengües i Terminologia'' at Universitat Jaume I for their professional English revision service, Thies Pfeiffer for telling us about Ref. <ref type="bibr" target="#b69">[70]</ref>, and publishers and authors for their kind permission to reproduce figures used in this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>• Object segmentation in disparity maps • Integration of multiple cues (motion, color, edges, etc.)</p><p>• High resolution depth maps by active scanning • Detection of occlusions and object boundaries cues for widening our still limited understanding of human vision and related brain processes.</p><p>In conclusion, while some work has been done on log-polar artificial vision in the past, this can be seen only as the germ of future work addressing new challenges. Table <ref type="table">1</ref> is intended to be a brief guide to identify both problems that have already been solved and some open research issues. We would like the review offered in this article to be of some help for those looking back to the past in order to head into the future. Note: Matlab code for the (direct and inverse) log-polar mapping can be found at http://www.isr.ist.utl.pt/~alex/resources.html. He participates in several national and international research projects in the fields of robotics, cognitive systems, computer vision and surveillance. He has published several articles in international journals and conferences, and his main research interests focus on the application of computer vision, cognitive science and control theory to advanced robotic and surveillance systems.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Receptive fields for vision: From hyperaccuity to object recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Edelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Watt</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Binocular tracking: Integrating perception and control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1080" to="1094" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Video compression via log-polar mapping</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Symposium on OE/Aerospace Sensing</title>
		<meeting><address><addrLine>Orlando, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-04">Apr. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Space variant vision for an active camera mount</title>
		<author>
			<persName><forename type="first">F</forename><surname>Panerai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<idno>TR 1/95</idno>
	</analytic>
	<monogr>
		<title level="j">LIRA</title>
		<imprint>
			<date type="published" when="1995-02">Feb. 1995</date>
			<pubPlace>Genova, Italy</pubPlace>
		</imprint>
		<respStmt>
			<orgName>DIST, Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Active vision for sociable robots</title>
		<author>
			<persName><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Edsinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scassellati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Transactions on Systems</title>
		<meeting>IEEE Transactions on Systems</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="443" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A miniature space-variant active vision system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bederson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>New York University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The representation of the visual field on the cerebral cortex in monkeys</title>
		<author>
			<persName><forename type="first">P</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitteridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="203" to="221" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Foveal scale-space and the linear increase of receptive field size as a function of eccentricity</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lindeberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Florack</surname></persName>
		</author>
		<idno>ISRN KTH/NA/P-94/27-SE</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deosyxlucose analysis of retinotopic organization in primate striate cortex</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tootell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Swikes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Devalois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="902" to="904" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spatial mapping in the primate sensory projection: Analytic structure and relevance to perception</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="181" to="194" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active vision</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Aloimonos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="page" from="333" to="356" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Active perception and exploratory robotics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robots and Biological Systems: Towards a New Bionics?</title>
		<editor>
			<persName><surname>Dario</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aebischer</forename><surname>Sandini</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="3" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Promising directions in active vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="126" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Animate vision</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="57" to="86" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Space-variant active vision: Definition, overview and examples</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Greve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bonmassar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">7-8</biblScope>
			<biblScope unit="page" from="1297" to="1308" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A review of biologically motivated space-variant data reduction models for robotic vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bolduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="170" to="184" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Retina-like sensors: Motivations, technology and applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sensors and Sensing in Biology and Engineering</title>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Barth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Humphrey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Secomb</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Anthropomorphic visual sensors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Berton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Sensors</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Grimes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Dickey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Pishko</surname></persName>
		</editor>
		<imprint>
			<publisher>American Scientific Publishers</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">X</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Foveated vision sensor and image processing-A review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yeasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Robot Perception</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Apolloni</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Alpaslan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Patnaik</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="57" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Form-Invariant&apos; topological mapping strategy for 2D shape recognition, Computer Vision, Graphics, and Image Processing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Massone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tagliasco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="169" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An image processing architecture for real time generation of scale and rotation invariant patterns</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Messner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Szu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision, Graphics, and Image Processing Journal</title>
		<imprint>
			<biblScope unit="page" from="50" to="66" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hodgson</surname></persName>
		</author>
		<title level="m">A pattern recognition system based on models of aspects of the human visual system, in: 4th Intl. Conf. on Image Processing and Applications</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="258" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The log-polar image representation in pattern recognition tasks</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Iberian Conf. on Pattern Recognition and Image Analysis</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Mallorca, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003-06">June 2003. 2003</date>
			<biblScope unit="volume">2652</biblScope>
			<biblScope unit="page" from="1032" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Computational anatomy and functional architecture of the striate cortex</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="645" to="669" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Space variant image processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="90" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new log-polar mapping for space variant imaging. Application to face detection and tracking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="865" to="875" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic vergence using log-polar images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Panerai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="94" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modeling foveal vision</title>
		<author>
			<persName><forename type="first">L</forename><surname>Florack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scale Space and Variational Methods in Computer Vision (SSVM)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4485</biblScope>
			<biblScope unit="page" from="919" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the retino-cortical mapping</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Man-Machine studies</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="361" to="389" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An anthropomorphic retina-like structure for scene analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tagliasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="365" to="372" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A real-time foveated sensor with overlapping receptive fields</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bolduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Imaging: Special Issue on Natural and Artifical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="212" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Space variant image processing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-W</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="90" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Space-variant image processing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-W</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<idno>589-R256</idno>
		<imprint>
			<date type="published" when="1991-11">Nov. 1991</date>
			<publisher>Vision Applications, Inc</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Space variant image processing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-W</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<idno>633</idno>
		<imprint>
			<date type="published" when="1993-04">Apr. 1993</date>
			<publisher>Courant Institute of Mathematical Sciences</publisher>
			<pubPlace>New York University, NY</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A new foveated space-variant camera for robotic applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kayser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pelechano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conference on Electronics Circuits and Systems, ICECS&apos;96</title>
		<meeting><address><addrLine>Rhodes, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996</date>
			<biblScope unit="page" from="680" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Design issues on CMOS space-variant image sensors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dierickx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scheffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conf. on Advanced Focal Plane Arrays and Electronic Cameras</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996</date>
			<biblScope unit="volume">2950</biblScope>
			<biblScope unit="page" from="98" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A log-polar image sensor fabricated in a standard 1.2-µm ASIC CMOS process</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wodnicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1274" to="1277" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Space-variant nonorthogonal structure CMOS image sensor design</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dierickx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scheffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="842" to="849" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Building smarter sensors-Lessons learned from computer vision</title>
		<author>
			<persName><forename type="first">S</forename><surname>Meikle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium, 2000. IV 2000</title>
		<meeting><address><addrLine>Dearborn, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-10">Oct. 2000</date>
			<biblScope unit="page" from="210" to="214" />
		</imprint>
	</monogr>
	<note>Proceedings of the IEEE</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Gradient detection in discrete log-polar images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Mclaren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2185" to="2208" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rapid anisotropic diffusion using spacevariant vision</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="212" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="http://www.dspguide.com" />
		<title level="m">The Scientist and Engineer&apos;s Guide to Digital Signal Processing</title>
		<imprint>
			<publisher>California Technical Pub</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Design of a neuronal array</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Borghuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Ratliff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3178" to="3189" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Motion analysis with the Radon transform on log-polar images</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="165" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Eccentricity compensator for log-polar sensor</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burdick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2007-04">Apr. 2007</date>
			<biblScope unit="page" from="4214" to="4219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Reciprocal-Wedge transform for space-variant sensing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="500" to="511" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Reciprocal-Wedge Transform: A Space-Variant Image Representation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
		<respStmt>
			<orgName>School of Computing Science, Simon Fraser University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Vision system based on shifted fovea multiresolution retinotopologies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Arrebola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Urdiales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Camacho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sandoval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IECON&apos;98</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1357" to="1361" />
			<date type="published" when="1998-08">Aug.-Sept. 1998</date>
			<publisher>IEEE Industrial Electronics Society</publisher>
			<pubPlace>Aachen, Germany</pubPlace>
		</imprint>
	</monogr>
	<note>in: 24th annual conference of the</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Video flow active control by means of adaptive shifted foveal geometries</title>
		<author>
			<persName><forename type="first">C</forename><surname>Urdiales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bandera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sandoval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE International Symposium on Intelligent Systems for Advanced Manufacturing, ISAM&apos;2000: Intelligent Robots and Computer Vision XIX</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-11">Nov. 2000</date>
			<biblScope unit="volume">4197</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A multiresolution spatiotemporal motion segmentation technique for video sequences based on pyramidal structures</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Urdiales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bandera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1761" to="1769" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pyramid segmentation algorithms revisited</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marfil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Molina-Tanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bandera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1430" to="1451" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">FPGA-based pipeline architecture to transform cartesian images into foveal images by using a new foveation approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Altamirano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE International Conference on Reconfigurable Computing and FPGAs</title>
		<meeting>of the IEEE International Conference on Reconfigurable Computing and FPGAs</meeting>
		<imprint>
			<date type="published" when="2006-09">Sept. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A wavelet approach to foveating images</title>
		<author>
			<persName><forename type="first">E.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Yap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Symp. on Computational Geometry</title>
		<imprint>
			<biblScope unit="page" from="397" to="399" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Real-time visualization of large images over a thinwire</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-J</forename><surname>Yen</surname></persName>
		</author>
		<editor>IEEE Visualization</editor>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Late Breaking Hot Topics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Implementation of a foveated image-coding system for bandwith reduction of video images</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Kortum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Vision and Electronic Imaging</title>
		<title level="s">SPIE Proceedings</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Rogowiz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Allebach</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">2657</biblScope>
			<biblScope unit="page" from="350" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multifoveal imager for stereo applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Camacho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Coslado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sandoval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Imaging Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="149" to="165" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Enhancing videoconferencing using spatially varying sensing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="148" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Nonuniform video coding by means of multifoveal geometries</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Urdiales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bandera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sandoval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Imaging Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="34" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arcot</surname></persName>
		</author>
		<title level="m">A real-time variable sampling technique: DIEM, in: Intl. Conf. on Pattern Recognition, ICPR</title>
		<meeting><address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Retina-like CCD sensor for active vision</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demicheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer and Systems Sciences (NATO ARW on Robots and Biological Systems)</title>
		<meeting><address><addrLine>Il Ciocco, Tuscany, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1989">1989. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Biologically inspired vision sensors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Der Spiegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Etienne-Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nishimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd International Conference on Microelectronics (MIEL 2002)</title>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="125" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Kreider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Der Spiegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Claeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Debusschere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Computer Vision IX: Algorithms and Techniques</title>
		<title level="s">Proc. of SPIE</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">1381</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Hardware environment for a retinal CCD visual sensor</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Martinuzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EU-HCM Smart Workshop: Semi-Autonomous Monitoring and Robotics Technologies</title>
		<meeting><address><addrLine>Ispra, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-04">Apr. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Retina-like visual sensor for fast tracking and navigation robots</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Inokuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Vision and Applications (MVA)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A foveated image sensor in standard CMOS technology</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wodnicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Custom Integrated Circuits Conf</title>
		<meeting><address><addrLine>Santa Clara</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Design of a foveated log-polar image sensor using standard CMOS technology, in: XI Design of Integrated Circuits and Systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Felici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dierickx</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-11">Nov. 1996</date>
			<biblScope unit="page" from="49" to="54" />
			<pubPlace>Sitges, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A retina-like CMOS sensor and its applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Questa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scheffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dierickx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mannucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st IEEE SAM Workshop</title>
		<meeting>1st IEEE SAM Workshop<address><addrLine>Cambridge, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-03">Mar. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">The Centre for High Performance Integrated Technologies and Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
		<respStmt>
			<orgName>The University of Adelaide, Australia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Vision chips or seeing silicon</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Vision Chips</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A hemispherical electronic eye camera based on compressible silicon optoelectronics</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Stoykovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Malyarchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">454</biblScope>
			<biblScope unit="issue">7205</biblScope>
			<biblScope unit="page" from="748" to="753" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Optical flow estimation in the complex logarithmic plane</title>
		<author>
			<persName><forename type="first">V</forename><surname>Krüger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Kiel</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">On the computation of the log-polar transform</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bishay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rogers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-03">Mar. 1996</date>
		</imprint>
		<respStmt>
			<orgName>School of Engineering, Vanderbilt University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Optical normal flow estimation on logpolar images. A solution for real-time binocular vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real Time Imaging</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="213" to="228" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">An introduction to the log-polar mapping</title>
		<author>
			<persName><forename type="first">H</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Dias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Second Workshop on Cybernetic Vision</title>
		<meeting>of Second Workshop on Cybernetic Vision</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="139" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Exponential sensor array geometry and simulation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital and Optical Shape Representation and Pattern Recognition</title>
		<meeting><address><addrLine>Orlando, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-04">Apr. 1988</date>
			<biblScope unit="volume">938</biblScope>
		</imprint>
	</monogr>
	<note>Preprint from the Proc. of SPIE</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Design considerations for a space-variant visual sensor with complex-logarithmic geometry</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rojer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="278" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Resolution consideration in spatially variant sensors</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A W</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing (IVC)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="901" to="912" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Log-polar binocular vision system</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NASA Phase II SBIR Final Report</title>
		<imprint>
			<date type="published" when="1994-12">Dec. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A programmable video image remapper</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Juday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital and Optical Shape Representation and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">938</biblScope>
			<biblScope unit="page" from="122" to="128" />
		</imprint>
	</monogr>
	<note>SPIE Conf. on Pattern Recognition and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">VIPOL: A virtual polar-logarithmic sensor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Del Solar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nowack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scandinavian Conf. on Image Analysis, SCIA, Finland</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="739" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m">GPU Gems 3</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</editor>
		<imprint>
			<publisher>Addison-Wesley Professional</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">On the computation of the circle Hough transform by a GPU rasterizer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ujaldón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Guil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="318" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Sensor geometry and sampling methods for space-variant image processing</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C D</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Chatwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Analysis and Application (PAA)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="369" to="384" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Sensor geometry for dynamic vergence: Characterization and performance analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Performance Characteristics of Vision Algorithms, ECCV</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-04">Apr. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Vision for mobile robots</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hampapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kortenkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moezzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Technology: Advances in Image Processing, Multimedia and Machine Vision</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L C</forename><surname>Sanz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="1" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Log-polar mapping template design: From task-level requirements to geometry parameters</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing (IVC)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1354" to="1370" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Genetic Algorithms in Search, Optimization, and Machine Learning</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Visionbased control with emergency stop through EMG of the wheelchair-based rehabilitation robotic arm</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Bien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Rehabilitation Robotics</title>
		<meeting><address><addrLine>Evry, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-04">Apr. 2001</date>
			<biblScope unit="volume">II</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Visual servoing for a user&apos;s mouth with effective intention reading in a wheelchair-based robotic arm</title>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">on Robotics and Automation</title>
		<meeting><address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Intl</publisher>
			<date type="published" when="2001-05">May 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Visual servoing for human-robot interaction in the weelchair-based rehabilitation robot</title>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Systems, Man and Cybernetics</title>
		<meeting><address><addrLine>Nashville, Tenesse, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-10">Oct. 2000</date>
			<biblScope unit="page" from="1811" to="1816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Estudio comparativo de modelos de conversión de imágenes log-polar</title>
		<author>
			<persName><forename type="first">J</forename><surname>López-Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf. de la Asoc. Española para la Inteligencia Artificial</title>
		<meeting><address><addrLine>Gijón, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-11">Nov. 2001</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
	<note>in Spanish</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Motion Estimation Algorithms in Log-polar Images and Application to Monocular Active Tracking</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dep. Llenguatges i Sistemes Informàtics</title>
		<imprint>
			<date type="published" when="2002-09">Sept. 2002</date>
			<pubPlace>Castellón, Spain</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universitat Jaume I</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Pamplona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<title level="m">Smooth foveal vision with Gaussian receptive fields, in: 9th IEEE-RAS Intl. Conf. on Humanoid Robots</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">A miniature pan-tilt actuator: The spherical pointing motor</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A miniaturized space-variant active vision system: Cortex-I, Machine Vision and Applications</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="101" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">A binocular active vision system using space variant sensors: Exploiting autonomous behaviors for space applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Panerai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">rd. Intl. Conf. on Digital Signal Processing</title>
		<meeting><address><addrLine>Nicosia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-07">July 1993</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Trigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sentieiro</surname></persName>
		</author>
		<title level="m">Medusa-A stereo head for active vision, in: Intl. Workshop on Intelligent Robotic Systems (IRS)</title>
		<meeting><address><addrLine>Grenoble, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-07">July 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Babybot: An artificial developing robotic agent</title>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Panerai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manzotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on the simulation of adaptive behavior</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>SAB</publisher>
			<date type="published" when="2000-09">Sept. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Towards log-polar fixation for mobile robots-Analysis of corner tracking on the log-polar camera</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR</title>
		<meeting><address><addrLine>Québec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="300" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Efficient active monocular fixation using the logpolar sensor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Intelligent Systems Technologies and Applications</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Tracking in a space variant active vision system</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A W</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR, Viena, Austria</title>
		<imprint>
			<date type="published" when="1996-08">Aug. 1996</date>
			<biblScope unit="page" from="745" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Use of log polar space for foveation and feature recognition</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A W</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE Proc. Vis. Image Signal Process</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="323" to="331" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Biologically motivated composite image sensor for deep-field target tracking</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Melnyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Messner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision Geometry XV</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Mount</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</editor>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">6499</biblScope>
			<biblScope unit="page" from="649905" to="649905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Log-polar based framework for mobile vehicle tracking with road follower</title>
		<author>
			<persName><forename type="first">P</forename><surname>Melnyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Messner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Defense and Security Symposium</title>
		<meeting><address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-04">Apr. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Modelling primate visual attention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Neuroscience: A Comprehensive Approach</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</editor>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="635" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">A saliency-based search mechanism for overt and covert shifts of visual attention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1489" to="1506" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Guided search 2.0: A revised model of visual search</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="238" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">The FeatureGate model of visual selection</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Cave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="182" to="194" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Object-based visual attention for computer vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="77" to="123" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Entropy-based saliency computation in log-polar images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tamayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Computer Vision Theory and Applications</title>
		<meeting><address><addrLine>Funchal, Madeira, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-01">Jan. 2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="501" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Detecting Salient regions in images: From biological evidence to computer implementation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Milanese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Gevena, Switzerland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dep. of Computer Science, University of Geneva</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Top-down gaze targeting for space-variant active vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ARPA Image Understanding Workshop</title>
		<meeting>ARPA Image Understanding Workshop<address><addrLine>Monterey, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
			<biblScope unit="page" from="1049" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">An active vision architecture based on iconic representations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="461" to="505" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">An attentional system for a humanoid robot exploiting space variant vision</title>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Humanoid Robots</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-11">Nov. 2001</date>
			<biblScope unit="page" from="22" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Modello per l&apos;estrazione di caractteristiche salientei ispirato al sistema visivo periferico</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dipartamento di Informatica Sistemistica e Telematica, Facoltà di Ingegneria</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Laboratorio Integrato di Robotica Avanzata ; Università di Genova</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Object-based visual attention: A model for a behaving robot</title>
		<author>
			<persName><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<meeting>IEEE Computer Vision and Pattern Recognition, CVPR<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Development of a biologically inspired realtime visual attention system</title>
		<author>
			<persName><forename type="first">O</forename><surname>Stasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kuniyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<editor>
			<persName><surname>Bmcv 2000</surname></persName>
		</editor>
		<editor>
			<persName><surname>Seoul</surname></persName>
		</editor>
		<editor>
			<persName><surname>Korea</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">1811</biblScope>
			<biblScope unit="page" from="150" to="159" />
			<date type="published" when="2000-05">May 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Attentive behavior in an anthropomorphic robot vision system</title>
		<author>
			<persName><forename type="first">C</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="121" to="131" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Integrating selective attention and spacevariant sensing in machine vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Technology: Advances in Image Processing, Multimedia and Machine Vision</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L C</forename><surname>Sanz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="109" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">An active foveated vision system: Attentional mechanisms and scan path convergence measures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="65" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Shape description with a space-variant sensor: Algorithms for scan-path, fusion, and convergence over multiple scans</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1217" to="1222" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Real-time attention for robotic vision</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real Time Imaging</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="173" to="194" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Paying attention to symmetry</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kootstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Boer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<meeting><address><addrLine>Leeds, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09">Sept. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Attention in iconic object matching</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Groove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conf., BMVC96</title>
		<meeting>British Machine Vision Conf., BMVC96<address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-09">Sept. 1996</date>
			<biblScope unit="page" from="293" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">scale and image description</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saliency</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="105" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Scale &amp; affine invariant interest point detectors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Foveated vision for scene exploration</title>
		<author>
			<persName><forename type="first">N</forename><surname>Oshiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nishikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miyazaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd Asian Conference on Computer Vision, ACCV98</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
			<biblScope unit="page" from="256" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Active/space-variant object recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing (IVC)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="226" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Active vision-based face authentication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing (IVC)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">An experimental foveated vision system using fish-eye lens and integration of retinal images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kurita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Akaho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Umeyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mishima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Technical Conf. on Circuits/Systems, Computers, and Communications, ITC-CSCC</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Spherical panoramas for pan-tilt camera motion compensation in space-variant images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topics in Artificial Intelligence</title>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Escrig</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Toledo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Golobardes</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2504</biblScope>
			<biblScope unit="page" from="375" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Exploring with foveated robot eye system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition (ICPR)</title>
		<meeting><address><addrLine>Jerusalem, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-10">Oct. 1994</date>
			<biblScope unit="page" from="377" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Space-variant dynamic neural fields for visual attention</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ahrns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<meeting>IEEE Computer Vision and Pattern Recognition, CVPR<address><addrLine>Fort Collins, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">A computer vision model for visualobject-based attention and eye movements</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Gomes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="142" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<title level="m">Binocular Head Control with Foveal Vision: Methods and Applications</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
	<note>Vislab, ISR-IST</note>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Visual attention under foveated vision in robotic heads</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Vislab, ISR-IST, Lisbon, Portugal and DLSI-UJI, Castellón, Spain</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Investigating a space-variant weighted salience account of visual selection</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Trosciankoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Gilchrista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1809" to="1820" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">The spatial resolution of visual attention</title>
		<author>
			<persName><forename type="first">J</forename><surname>Intriligator</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cavanagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Pshychology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="171" to="216" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Movements of the eyes</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H S</forename><surname>Carpenter</surname></persName>
		</author>
		<editor>London Pion</editor>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Active Vision: The Psychology of Looking and Seeing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Findlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D D</forename><surname>Gilchrist</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<title level="m">Affective Computing</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Sharing resources: Buy attention, get object recognition, in: Intl. Workshop on Attention and Performance in Computer Vision, WAPCV</title>
		<author>
			<persName><forename type="first">V</forename><surname>Navalpakkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
			<pubPlace>Graz, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Attentional processes link perception and action</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yamagishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karavia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society of London B</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="page" from="1225" to="1226" />
			<date type="published" when="2002-05">May. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Learning object affordances: From sensory motor maps to imitation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Montesano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Motion tracking with an active camera</title>
		<author>
			<persName><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="449" to="459" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Similarity motion estimation and active tracking through spatial-domain projections on log-polar images</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="241" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Control of a camera for active vision: Foveal vision, smooth tracking and saccade</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rotstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="96" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Neurophysiology and neuroanatomy of smooth pursuit in humans</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lencer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Trillenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and Cognition</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="219" to="228" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Biomimetic eye-neck coordination</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hofsten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rosander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 8th International Conference on Development and Learning, ICDL&apos;09</title>
		<meeting><address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Falotico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taiana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zambrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dario</surname></persName>
		</author>
		<title level="m">Predictive tracking across occlusions on the iCub robot, in: 9th IEEE-RAS International Conference on Humanoid Robots</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Conradt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomimetic oculomotor control</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="187" to="207" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>Adaptive Behavior</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">A general relationship for optimal tracking performance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SPIE&apos;96: Intelligent Robots and Computer Vision XV</title>
		<meeting>of the SPIE&apos;96: Intelligent Robots and Computer Vision XV<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="402" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Estimating motion in image sequences: A tutorial on modeling and computation of 2D motion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="page" from="70" to="91" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Joint Conference on Artificial Intelligence</title>
		<meeting>of the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Optic flow</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="161" to="180" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">The computation of optical flow</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Beauchemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Barron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="433" to="467" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Kanade 20 years on: A unifying framework</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><forename type="middle">-</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="255" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Horn</surname></persName>
		</author>
		<title level="m">Robot Vision, McGraw-Hill Higher Education</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Optical flow computation in the log-polar plane</title>
		<author>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Krüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Computer Analysis of Images and Patterns</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Hlaváč</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Šára</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Computation of 3D-motion parameters using the log-polar transform</title>
		<author>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Computer Analysis of Images and Patterns</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Hlaváč</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Šára</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">970</biblScope>
			<biblScope unit="page" from="82" to="89" />
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Optical flow in log-mapped image plane: A new approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yeasin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="131" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">The local structure of space-variant images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="815" to="831" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">First order optic flow from log-polar sampled images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tunley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<editor>
			<persName><forename type="first">J.-O</forename><surname>Eklundh</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">800</biblScope>
			<biblScope unit="page" from="132" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Autonomous visual control of a mobile robot</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ARPA Image Understanding Workshop</title>
		<meeting><address><addrLine>Monterey, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">Baby(ro)bot: A Study on Sensori-Motor Development</title>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Italy</pubPlace>
		</imprint>
		<respStmt>
			<orgName>LIRA-Lab ; DIST, University of Genoa</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Panerai</surname></persName>
		</author>
		<title level="m">Integration of Inertial and Visual Information in Binocular Vision Systems</title>
		<imprint>
			<date type="published" when="1998-02">Feb. 1998</date>
		</imprint>
		<respStmt>
			<orgName>LIRA-Lab (Laboratory for Integrated Advanced Robotics), Department of Communication Computer and Systems Science, Faculty of Engineering, University of Genova</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Space-variant motion detection for active visual target tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Claveau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Efficient region tracking with parametric models of geometry and illumination</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1025" to="1039" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Foveated active tracking with redundant 2D motion parameters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="205" to="221" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Motion estimation and figure-ground segmentation in logpolar images</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR</title>
		<meeting><address><addrLine>Québec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08">Aug. 2002</date>
			<biblScope unit="page" from="166" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">An algorithm for motion prediction using a biological visual sensor</title>
		<author>
			<persName><forename type="first">C</forename><surname>Narathong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iñigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Doner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mcvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Robotics and Automation</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1261" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Dealing with 2D translation estimation in log-polar imagery</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing (IVC)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="160" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Space-variant Fourier analysis: The exponential chirp transform</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bonmassar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1080" to="1089" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Real-time restoration of images degraded by uniform motion blur in foveal active vision systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bonmassar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1838" to="1842" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Projective registration with difference decomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<meeting>IEEE Computer Vision and Pattern Recognition, CVPR</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="331" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<title level="m">Tracking planar structures with log-polar images, in: Symp. on Intelligent Robotic Systems</title>
		<meeting><address><addrLine>Reading, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Motion estimation and target tracking in the log-polar geometry</title>
		<author>
			<persName><forename type="first">N</forename><surname>Okajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nitta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mitsuhashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Sensor Symposium</title>
		<meeting><address><addrLine>Kawasaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Dynamic fixation of a moving surface using log polar sampling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tunley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<meeting><address><addrLine>York</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="1994">Sept. 1994. 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="579" to="588" />
		</imprint>
		<respStmt>
			<orgName>Univ. York</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Image registration using log-polar mappings for recovery of large-scale similarity and projective transformations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zokai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wolberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1422" to="1434" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Log-polar mapping in generalized least-squares motion estimation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Montoliu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization, Imaging and Image Processing Conf</title>
		<meeting><address><addrLine>Benalmádena, Málaga, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09">Sept. 2002</date>
			<biblScope unit="page" from="656" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Radon-like transforms in log-polar images for affine motion estimation</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Portuguese Conf. on Pattern Recognition</title>
		<meeting><address><addrLine>Aveiro, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Efficient tracking of objects with arbitrary 2D motions in space-variant imagery</title>
		<author>
			<persName><forename type="first">L</forename><surname>Puig-M</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Desé Congrés Català d&apos;Intel.ligència Artificial (CCIA 2007)</title>
		<title level="s">Frontiers in Artificial Intelligence and Applications</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Angulo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Godo</surname></persName>
		</editor>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
	<note>Sant Julià de Lòria, Principat d&apos;Andorra</note>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Real time tracking of 3D objects: An efficient and robust approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dhome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Polar exponential sensor arrays unify iconic and Hough space representation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Conf. on Intelligent Robots and Computer Vision VIII: Algorithms and Techniques</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-11">Nov. 1989</date>
			<biblScope unit="volume">1192</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Straight lines and circles in the log-polar image</title>
		<author>
			<persName><forename type="first">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<meeting><address><addrLine>Bristol, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09">Sept. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Geometry and construction of straight lines in log-polar images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="196" to="207" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Learning-based versus model-based log-polar feature extraction operators: A comparative study</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">XVI Brazilian Symp. on Computer Graphics &amp; Image Processing</title>
		<meeting><address><addrLine>San Carlos, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2003-10">Oct. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Primal sketch feature extraction from a log-polar image</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="983" to="992" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Direct feature extraction in a foveated environment</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nattel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1537" to="1548" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Tracking algorithms using log-polar mapped image coordinates</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Weiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Juday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Computer Vision VIII: Algorithms and Techniques</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="843" to="853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">A fixation and viewpoint measure for object-based gaze control</title>
		<author>
			<persName><forename type="first">R</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Illingworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<title level="m" type="main">Topography of primary visual cortex: Theory and implementation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Wood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Graduate School of Arts and Sciences, Boston University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Real-time tracking of multiple objects in space-variant vision based on magnocellular visual pathway</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2031" to="2040" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Appearance-based object detection in space-variant images: A multi-model approach</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Image Analysis and Recognition, ICIAR</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Porto, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-11">Nov. 2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="538" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Learning to track colored objects with logpolar vision</title>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mechatronics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="989" to="1006" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Background and foreground modeling using nonparametric kernel density for visual surveillance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elgammal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Duraiswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1151" to="1163" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Log-polar vision for mobile robot navigation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Electronic Imaging Conference</title>
		<meeting>of Electronic Imaging Conference<address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-11">Nov. 1990</date>
			<biblScope unit="page" from="382" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">On the advantages of polar and log-polar mapping for direct estimation of time-to-impact from optical flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="401" to="410" />
			<date type="published" when="1993">1993</date>
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Looming detection in log-polar coordinates</title>
		<author>
			<persName><forename type="first">G</forename><surname>Salgian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DARPA Image Understanding Workshop</title>
		<meeting><address><addrLine>Monterey, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="165" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">High speed log-polar time to crash calculation for mobile vehicles</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Coma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Micó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing &amp; Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Feature extraction and correlation for time-toimpact segmentation using log-polar images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCSA</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Laganà</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Gavrilova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Mun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J K</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Gervasi</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3046</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="887" to="895" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Attentive visual motion processing: Computations in the logpolar plane</title>
		<author>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Time to collision from first-order spherical motion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Colombo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5" to="15" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">A view-based approach for real-time fixation using logpolar mapping</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ahrns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Freksa</surname></persName>
		</editor>
		<meeting>in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">Real-time monocular fixation control using the logpolar transformation and a confidence-based similarity measure</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ahrns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</editor>
		<meeting><address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-08">Aug. 1998</date>
			<biblScope unit="page" from="310" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Model-based attention fixation using log-polar images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Attention Mechanisms</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Cantoni</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Petrosino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Marinaro</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Plenum Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Vergence and tracking fusing log-polar images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Panerai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="740" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">An optimization approach for translational motion estimation in log-polar domain</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Traver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Computer Analysis of Images and Patterns</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Skarbek</surname></persName>
		</editor>
		<meeting><address><addrLine>Warsaw, Poland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001-09">Sept. 2001</date>
			<biblScope unit="volume">2124</biblScope>
			<biblScope unit="page" from="365" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Active docking based on the rotational component of log-polar optic flow</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conf. on Computer Vision</title>
		<editor>
			<persName><forename type="first">W.-H</forename><surname>Tsai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-J</forename><surname>Lee</surname></persName>
		</editor>
		<meeting><address><addrLine>Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-01">Jan. 2000</date>
			<biblScope unit="page" from="955" to="960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Direction control for an active docking behavior based on the rotational component of log-polar optic flow</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<editor>
			<persName><forename type="first">W.-H</forename><surname>Tsai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-J</forename><surname>Lee</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="167" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Egomotion estimation using log-polar images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Computer Vision</title>
		<meeting><address><addrLine>Bombay, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Neuromorphic translational ego-motion estimation using log-polar motion energy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks, 2006. IJCNN &apos;06. International Joint Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="5204" to="5211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Object detection in indoor scenes using logpolar mapping</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bishay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A P</forename><surname>Ii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kawamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intl. Conf. on Robotics and Automation, ICRA</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="775" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Autonomous robot navigation-A study using optical flow and log-polar image representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Colloquium of Automation</title>
		<meeting>of the Colloquium of Automation<address><addrLine>Salzhausen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003/2004, 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Combined space-variant maps for optical-flow-based navigation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Baratoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Toepfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="199" to="209" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Detecting Motion Independent of the Camera Movement Through a Log-Polar Differential Approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pelechano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">1296</biblScope>
			<biblScope unit="page" from="702" to="710" />
			<date type="published" when="1997">1997</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda-Grau</surname></persName>
		</author>
		<title level="m">Arquitectura de Procesamiento de Imágenes Basada En Lógica Reconfigurable Para Navegación de Vehículos Autónomos con Visión Foveal</title>
		<meeting><address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Departamento de Informática, Facultad de Física, Universitat de València</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">FPGA implementation of a logpolar motion detection algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pelechano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Autonomous Systems</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Pagello</surname></persName>
		</editor>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="851" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">On the advantages of combining differential algorithms and log-polar vision for detection of self-motion from a mobile robot</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boluda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="283" to="296" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Mirror design for an omnidirectional camera with a space variant imager</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gächter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mičušík</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Omnidirectional Vision Applied to Robotic Orientation and Nondestructive Testing</title>
		<imprint>
			<date type="published" when="2001-08">2001. Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">OMNIVIEWS: Direct omnidirectional imaging based on a retina-like sensor</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First IEEE International Conference on Sensors, IEEE Sensors -2002</title>
		<imprint>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Image sequence stabilization using fuzzy kalman filtering and log-polar transformation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kyriakoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amanatiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Computer Vision Theory and Applications</title>
		<meeting><address><addrLine>Funchal, Madeira, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-01">Jan. 2008</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Mertsching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmaiz</surname></persName>
		</author>
		<title level="m">Systems and Applications, in: Active Vision Systems</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="197" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">Estimation of depth from motion using an anthropomorphic visual sensor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing (IVC)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="271" to="278" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Binocular fusion revisited utilizing a log-polar tessellation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Griswold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F R</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Image Processing</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="421" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Combining log-polar mapping and Gabor filtering for real-time depth estimation</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ahrns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. in Artificial Intelligence, Proc. Workshop Dynamische Perzeption</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Freksa</surname></persName>
		</editor>
		<meeting>in Artificial Intelligence, . Workshop Dynamische Perzeption</meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">Log-polar stereo for anthropomorphic robots</title>
		<author>
			<persName><forename type="first">E</forename><surname>Grosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conf. on Computer Vision</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-07">July 2000</date>
			<biblScope unit="page" from="299" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">A binocular stereo algorithm for log-polar foveated systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2nd Workshop on Biologically Motivated Computer Vision</title>
		<meeting>of the 2nd Workshop on Biologically Motivated Computer Vision</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">The epipolar geometry of the log-polar image plane</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Pattern Recognition, ICPR</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">Aug. 2004</date>
			<biblScope unit="page" from="40" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">A developmental roadmap for task learning by imitation in humanoid robots: Baltazar&apos;s story</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISB 2005 Symposium on Imitation in Animals and Artifacts</title>
		<imprint>
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">Precise 3D measurements with a high resolution stereo head</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martinotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Intl. Workshop on Image and Signal Processing and Analysis, IWISPA&apos;00</title>
		<meeting><address><addrLine>Pula, Croatia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Binocular stereo via log-polar retinas</title>
		<author>
			<persName><forename type="first">C</forename><surname>Weiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SPIE</title>
		<imprint>
			<biblScope unit="volume">2488</biblScope>
			<biblScope unit="page" from="309" to="320" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Carpenter</surname></persName>
		</author>
		<title level="m">Eye Movements</title>
		<imprint>
			<publisher>The Macmillan Press</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">Visual behaviors for binocular tracking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="137" to="146" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Vergence control for robotic heads using logpolar images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems</title>
		<meeting><address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-11">Nov. 1996</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1264" to="1271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">A space-variant approach to oculomotor control</title>
		<author>
			<persName><forename type="first">E</forename><surname>Grosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manzotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tiso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Symposium on Computer Vision</title>
		<meeting><address><addrLine>Coral Gables, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-11">Nov. 1995</date>
			<biblScope unit="page" from="509" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Binocular tracking using log polar mapping</title>
		<author>
			<persName><forename type="first">N</forename><surname>Oshiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nishikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miyazaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems</title>
		<meeting><address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-11">Nov. 1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">Binocular tracking based on virtual horopters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rougeaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kuniyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C S</forename><surname>Sakano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2052" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">Real-time binocular smooth pursuit</title>
		<author>
			<persName><forename type="first">D</forename><surname>Coombs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="164" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">Disparity estimation on log-polar images and vergence control</title>
		<author>
			<persName><forename type="first">R</forename><surname>Manzotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="97" to="117" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">Novel wheelchair-based robotic arm with visual servoing capability for human-robot interaction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Bien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Service Automation and Robotics</title>
		<meeting><address><addrLine>Kowloon Tong, Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="5" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
		<title level="m" type="main">Intelligent Visual Servoing using Space Variant Vision with Application for Rehabilitation Robots</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>KAIST, Korea</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">A binocular, foveated active vision system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Scassellati</surname></persName>
		</author>
		<idno>MIT AI Memo 1628</idno>
	</analytic>
	<monogr>
		<title level="j">MIT Artificial Intelligence Lab</title>
		<imprint>
			<date type="published" when="1998-03">Mar. 1998</date>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b245">
	<analytic>
		<title level="a" type="main">Multitarget tracking in distributed sensor networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Reich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="36" to="46" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Perceptual user interfaces (introduction)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="32" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Porta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision-based user interfaces: Methods and applications</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="27" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">Human-oriented interaction with an anthropomorphic robot</title>
		<author>
			<persName><forename type="first">T</forename><surname>Spexard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hanheide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sagerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="852" to="862" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
