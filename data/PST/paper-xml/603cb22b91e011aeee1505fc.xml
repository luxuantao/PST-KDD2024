<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TOWARDS A UNIFIED FRAMEWORK FOR FAIR AND STABLE GRAPH REPRESENTATION LEARNING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chirag</forename><surname>Agarwal</surname></persName>
							<email>agarwal@hms.harvard.edu</email>
						</author>
						<author>
							<persName><forename type="first">Himabindu</forename><surname>Lakkaraju</surname></persName>
							<email>hlakkaraju@hbs.edu</email>
						</author>
						<author>
							<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
							<email>marinka@hms.harvard.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TOWARDS A UNIFIED FRAMEWORK FOR FAIR AND STABLE GRAPH REPRESENTATION LEARNING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As the representations output by Graph Neural Networks (GNNs) are increasingly employed in real-world applications, it becomes important to ensure that these representations are fair and stable. In this work, we establish a key connection between counterfactual fairness and stability and leverage it to propose a novel framework, NIFTY (uNIfying Fairness and stabiliTY), which can be used with any GNN to learn fair and stable representations. We introduce a novel objective function that simultaneously accounts for fairness and stability and develop a layer-wise weight normalization using the Lipschitz constant to enhance neural message passing in GNNs. In doing so, we enforce fairness and stability both in the objective function as well as in the GNN architecture. Further, we show theoretically that our layer-wise weight normalization promotes counterfactual fairness and stability in the resulting representations. We introduce three new graph datasets comprising of high-stakes decisions in criminal justice and financial lending domains. Extensive experimentation with the above datasets demonstrates the efficacy of our framework.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the past decade, there has been a surge of interest in leveraging GNNs for graph representation learning. GNNs have been used to learn powerful representations that enabled critical predictions in downstream applications-e.g., predicting protein-protein interactions <ref type="bibr" target="#b12">[Gainza et al., 2020</ref><ref type="bibr">, Huang et al., 2020]</ref>, drug repurposing <ref type="bibr" target="#b17">[Gysi et al., 2020</ref><ref type="bibr">, Zitnik et al., 2018]</ref>, crime forecasting <ref type="bibr" target="#b22">[Jin et al., 2020]</ref>, news and product recommendations <ref type="bibr" target="#b34">[Ying et al., 2018]</ref>. As GNNs are increasingly implemented in real-world applications, it becomes important to ensure that these models and the resulting representations are safe and reliable. More specifically, it is important to ensure that these models and the representations they produce are not perpetrating undesirable discriminatory biases (i.e., they are fair), and are also robust to attacks resulting from small perturbations to the graph structure and node attributes (i.e., they are stable).</p><p>A myriad of GNN methods with various neighborhood aggregation schemes have recently been developed (e.g., <ref type="bibr" target="#b24">Kipf and Welling [2017]</ref>, <ref type="bibr" target="#b18">Hamilton et al. [2017]</ref>, <ref type="bibr" target="#b32">Xu et al. [2018</ref><ref type="bibr" target="#b33">Xu et al. [ , 2019]]</ref>, <ref type="bibr" target="#b30">Veličković et al. [2019]</ref>). While these methods achieve state-of-the-art performance in tasks such as node classification and link prediction, these methods can be prone to discrimination and instability <ref type="bibr" target="#b7">[Dai and Wang, 2021</ref><ref type="bibr" target="#b28">, Rahman et al., 2019</ref><ref type="bibr" target="#b2">, Bose and Hamilton, 2019]</ref>. Furthermore, prior work has argued that GNNs not only capture the undesirable biases prevalent in the data, but may also exacerbate them thanks to their message passing schemes <ref type="bibr" target="#b7">[Dai and Wang, 2021]</ref>. Generally, in graphs such as social networks, nodes with similar sensitive attribute (e.g., race, age) values are likely to connect to each other <ref type="bibr" target="#b7">[Dai and Wang, 2021]</ref>. Since GNNs compute node representations by propagating and aggregating neural messages along edges in graph neighborhoods, nodes with similar sensitive attribute values are likely to share similar representations leading to severe discriminatory biases, i.e., downstream predictions may be highly correlated with sensitive attributes.</p><p>Recent research has treated fairness and stability in GNNs as independent problems and proposed standalone solutions for the same. For example, <ref type="bibr" target="#b7">Dai and Wang [2021]</ref> proposed FairGNN to promote fairness in GNNs through an objective function that incorporates group fairness measures such as statistical parity and equality of opportunity. On the other hand, <ref type="bibr" target="#b38">Zhu et al. [2019]</ref> aimed to make GNNs stable and robust to adversarial attacks. While these techniques provide a promising approach to study fairness and stability independently, it remains an open question whether there are any deeper connections between fairness and stability in GNNs, and if these properties can be achieved simultaneously.</p><p>Present work. Here, we address the problem of learning node representations that are both fair and stable. To tackle this problem, we first identify a key connection between counterfactual fairness and stability. While stability accounts for robustness w.r.t. small random perturbations to node attributes and/or edges, counterfactual fairness accounts for robustness w.r.t. modifications of the sensitive attribute. We leverage this connection to propose a novel framework, NIFTY<ref type="foot" target="#foot_0">2</ref> (uNIfying Fairness and stabiliTY), that can be used with any existing GNN model to learn fair and stable representations. Our framework exploits the aforementioned connection to enforce fairness and stability both in the objective function as well as in the GNN architecture. More specifically, we introduce a novel objective function which simultaneously optimizes for counterfactual fairness and stability by maximizing the similarity between representations of the original nodes in the graph, and their counterparts in the augmented graph (Fig. <ref type="figure" target="#fig_0">1</ref>). Nodes in the augmented graph are generated by slightly perturbing the original node attributes and edges or by considering counterfactuals of the original nodes where the value of the sensitive attribute is modified. We also develop a novel method for improving neural message passing by carrying out layer-wise weight normalization using the Lipschitz constant. We theoretically show that this normalization promotes counterfactual fairness and stability of learned representations. To the best of our knowledge, this work is the first to tackle the problem of learning node representations that are both fair and stable.</p><p>We introduce and experiment with three new graph datasets comprising of critical decisions in criminal justice (if a defendant should be released on bail) and financial lending (if an individual should be given loan) domains. Our results show that NIFTY improves the fairness and stability of five GNNs by 92.01% and 60.87% respectively (on an average) without sacrificing predictive performance. We also observe that the resulting representations become fairer not only w.r.t. the notion of counterfactual fairness but also w.r.t. other notions of group fairness such as statistical parity and equality of opportunity. Further, our results establish that enforcing fairness and stability both in the objective function as well as in the GNN architecture can be incredibly beneficial for learning fair and stable representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This work lies at the intersection of fairness and stability in machine learning, and Graph Neural Networks (GNNs). Below we discuss related work for each of these topics.</p><p>Fairness. Several competing and contrasting notions of fairness have been proposed in recent literature. They can be broadly categorized into: 1) group fairness, which emphasizes that minority groups should receive similar treatment as that of advantaged groups <ref type="bibr" target="#b1">[Berk et al., 2018</ref><ref type="bibr">, Hardt et al., 2016]</ref>, 2) individual fairness, which requires that similar individuals should be treated similarly <ref type="bibr" target="#b10">[Dwork et al., 2012]</ref>, and 3) counterfactual fairness, which captures the intuition that a decision pertaining to an individual is fair if changing the individual's sensitive attribute value does not affect the decision <ref type="bibr">[Kusner et al., 2017]</ref>. Furthermore, various metrics have been proposed to realize each of the aforementioned notions of fairness. For example, statistical (demographic) parity, equalized odds, equality of opportunity, and predictive parity are metrics proposed to enforce group fairness. These metrics have also been leveraged to develop new objective functions for constructing machine learning models that are both fair and accurate <ref type="bibr">[Zafar et al., 2017b,a]</ref>. Prior research has also established that certain notions of fairness (calibration and balance conditions) are fundamentally incompatible and cannot be simultaneously optimized <ref type="bibr" target="#b25">[Kleinberg et al., 2017</ref><ref type="bibr" target="#b6">, Chouldechova, 2017]</ref>.</p><p>Graph Neural Networks. Deep learning on graphs and GNNs, in particular, learn how to represent nodes in a graph as points, i.e., embeddings, in a vector embedding space, where the geometry of the embedding space is optimized to reflect topology of the graph as well as node attribute information <ref type="bibr" target="#b31">[Wu et al., 2020]</ref>. Motivated by spectral graph convolutions <ref type="bibr" target="#b19">[Hammond et al., 2011</ref><ref type="bibr" target="#b8">, Defferrard et al., 2016]</ref>  <ref type="bibr" target="#b33">[Xu et al., 2019]</ref> adaptively adjust the importance weights of nodes and Deep Graph Infomax (DGI) <ref type="bibr" target="#b30">[Veličković et al., 2019]</ref> relies on maximizing mutual information between patch representations and high-level graph summaries to produce node representations.</p><p>Fairness and Stability in GNNs. Recent studies addressed the issues of fairness and stability in GNNs <ref type="bibr" target="#b7">[Dai and Wang, 2021</ref><ref type="bibr" target="#b11">, Fisher et al., 2020</ref><ref type="bibr" target="#b13">, Geisler et al., 2020</ref><ref type="bibr" target="#b2">, Bose and Hamilton, 2019</ref><ref type="bibr" target="#b28">, Rahman et al., 2019</ref><ref type="bibr" target="#b38">, Zhu et al., 2019</ref><ref type="bibr" target="#b37">, Zhang and Zitnik, 2020]</ref>. To achieve fairness, existing work de-biases embeddings with respect to sensitive attributes via adversarial learning frameworks <ref type="bibr" target="#b7">[Dai and</ref><ref type="bibr">Wang, 2021, Bose and</ref><ref type="bibr">Hamilton, 2019]</ref>. These methods use regularization to implement the notion of group fairness; however, they are incapable of achieving counterfactual fairness. To achieve stability, recent methods use adversarial training <ref type="bibr">[Zügner and Günnemann, 2019]</ref>, robust message-aggregation <ref type="bibr" target="#b13">[Geisler et al., 2020]</ref>, and attention mechanisms <ref type="bibr" target="#b38">[Zhu et al., 2019]</ref> to defend GNNs against a variety of attacks that perturb discrete graph structure or node attributes. In contrast, our unifying framework can learn graph embeddings that are simultaneously fair and stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>Notation. Let G = (V, E, X) denote an undirected graph comprising of a set of nodes V and a set of edges E. Let X = {x 1 , x 2 , . . . , x N } denote the set of node attribute vectors corresponding to all the nodes in V. More specifically, x v ∈ X is an M -dimensional vector which captures the attribute values of node v ∈ V. Let N = |V| denote the number of nodes in the graph and let A ∈ R N ×N be the graph adjacency matrix where element A uv = 1 if there exists some edge e ∈ E between nodes u and v, and A uv = 0 otherwise. We also use N u to denote the set of immediate neighbors of node u, i.e., N u = {v ∈ V|A uv = 1}. Furthermore, let I u ∈ {0, 1} N denote the binary incidence vector which captures all the edges incident on node u, i.e., I uv = 1 if an edge exists between nodes u and v otherwise it is set to 0. Finally, we introduce b u to capture all the information associated with node u, i.e., b u = [x u ; I u ] denotes the concatenation of node attribute vector and binary incidence vector corresponding to node u. We also generate an augmented graph G = (V, E , X) as follows: for each node u ∈ V in the original graph, we generate a corresponding node in the augmented graph by slightly perturbing the attribute values, incident edges, and/or modifying the value of the sensitive attribute of node u. The adjacency matrix and node attribute vectors corresponding to this augmented graph G are denoted by Ã and X.</p><p>We consider a GNN with K layers and denote the representations output by each of these layers as</p><formula xml:id="formula_0">h 1 u , h 2 u , • • • h K−1 u , h K u</formula><p>for a given node u. We use z u to denote the representation output by the last layer of the GNN for node u i.e., z u = h K u . Analogously, zu denotes the representation output by the last layer of the GNN for node u in the augmented graph G . We assume that the (dis)similarity between any two node representations is given by a distance metric D : R d ×R d → R. Our goal is to learn an encoder function ENC which maps a given node u to a representation z u i.e., ENC(u) = z u . Lastly, let f denote a downstream classifier that maps the node representation z u of a given node u to a class label ŷu .</p><p>Graph Neural Networks. Many GNNs can be formulated as message passing networks <ref type="bibr" target="#b31">[Wu et al., 2020]</ref> specified by trainable operators MSG, AGG, and UPD. In a K-layer GNN, the operators are recursively applied on G, specifying how neural messages (i.e., embeddings) are exchanged between nodes, aggregated, and transformed to arrive at final node representations in the last layer of transformations. Typically, a message between a pair of nodes (u, v) in layer k is defined as a function of hidden representations of nodes h k−1 u and h k−1 v from the previous layer:</p><formula xml:id="formula_1">m k uv = MSG(h k−1 u , h k−1 v ).</formula><p>In AGG, messages from N u are aggregated as</p><formula xml:id="formula_2">m k u = AGG(m k uv |u ∈ N u ). In UPD, the aggregated message m k u is combined with h k−1 u to produce u's representation for layer k as h k u = UPD(m k u , h k−1 u ). Final node representation z u = h K</formula><p>u is the output of the last layer. Fairness and Stability. Our goal is to learn node representations that are fair and stable. More specifically, the notions of fairness and stability that we consider in this work are counterfactual fairness and Lipschitz continuity respectively. Below, we provide definitions of these notions and formalize them in the context of graph representation learning.</p><p>Counterfactual Fairness: A function is considered to be counterfactually fair if its output is independent of the sensitive attribute, i.e., changing the sensitive attribute value of any given instance should not affect the output of the function for that instance. In the context of graph representation learning, this notion can be interpreted as follows: node representations output by encoders should be independent of the sensitive attribute.</p><p>Definition 1. An encoder function ENC satisfies counterfactual fairness if the following holds for any given node u:</p><formula xml:id="formula_3">ENC(u) = ENC(ũ s ),<label>(1)</label></formula><p>where ũs is a node in the augmented graph which is generated by modifying/flipping the value of the sensitive attribute (s) of node u while keeping everything else constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stability via Lipschitz Continuity:</head><p>A function is considered to be stable according to the notion of Lipschitz continuity if slightly perturbing any given instance does not drastically change the output of the function. In the context of graph representation learning, this notion can be interpreted as follows: small perturbations to node attributes and/or incident edges should not drastically change the resulting representations.</p><p>Definition 2. An encoder function ENC is stable according to the notion of Lipschitz continuity if:</p><formula xml:id="formula_4">||ENC(ũ) − ENC(u)|| p ≤ L|| bu − b u || p ,<label>(2)</label></formula><p>where ũ is a node in the augmented graph generated by perturbing u's attribute values and/or incident edges, b u and bu capture the attribute and incident edge information for nodes u and ũ respectively, and L is the Lipschitz constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Framework NIFTY</head><p>Next, we describe our framework NIFTY which aims to generate fair and stable graph embeddings. To achieve this goal, NIFTY infuses fairness and stability in the objective function (Section 4.1) as well as in the architecture (Section 4.2) of underlying GNN.</p><p>Problem formulation (Fair and Stable embeddings). Given a graph G = (V, E, X), NIFTY aims to generate d-dim. embeddings z u ∈ R d that are counterfactually fair (Eq. 1) and stable to attribute and structural perturbations of G (Eq. 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Enforcing Fairness and Stability in the Objective function</head><p>To infuse fairness and stability in the objective function, we introduce a triplet-based objective that maximizes the agreement between the original graph and its counterfactual and noisy views. To this end, we build off the Siamese networks to maximize this agreement, i.e., the two augmented network neighborhoods and the augmented attribute vectors of the same node should result in the same embedding <ref type="bibr">[Chen et al., 2020, Chen and</ref><ref type="bibr" target="#b5">He, 2020]</ref>. Next, we describe the graph augmentation procedure.</p><p>Generating augmented views of graph structure and attribute information is key for the Siamese learning approach. We generate them using node-, sensitive attribute-, and edge-level perturbations.</p><p>a) Perturbing node attributes. We draw a random attribute masking vector r ∈ {0, 1} M from a Bernoulli distribution, i.e., r ∼ B(p n ), where p n is the probability of independently perturbing each attribute (except for the sensitive attribute s) in x u . The augmented attribute vector is then defined as</p><formula xml:id="formula_5">xu = x u + r • δ, where δ ∈ R M is sampled from a normal distribution.</formula><p>b) Counterfactual perturbation of sensitive attribute. We modify the value of sensitive attribute s in x u to generate a counterfactual. More specifically, we consider the case where the sensitive attribute is a binary variable (i.e., s ∈ {0, 1}) and we create a counterfactual node ũs by flipping the value of s from 0 to 1 or vice-versa.</p><p>c) Perturbing graph structure. We draw a random binary mask from a Bernoulli distribution, i.e., R e ∼ B(1 − p e ),</p><p>where R e ∈ {0, 1} N ×N and p e denotes the probability with which an edge is dropped from G. We construct the augmented adjacency matrix as</p><formula xml:id="formula_6">Ã = A • R e .</formula><p>To learn embeddings that are invariant to the sensitive attribute and stable against perturbations of the graph structure and non-sensitive attributes, we train the GNN encoder ENC using the Siamese framework <ref type="bibr" target="#b3">[Bromley et al., 1994]</ref>.</p><p>The encoder generates representations zu of the augmented graph at every iteration. By generating augmented graphs, NIFTY can induce appropriate bias into the underlying GNN to learn embeddings that are invariant to the combination of counterfactual nodes as well as to random perturbations in the graph structure. A predictor t : R d → R d consisting of a fully-connected neural layer is then used to transform and match the representations with each other. Inspired by <ref type="bibr" target="#b16">Grill et al. [2020]</ref>, we define a triplet-based objective function that optimizes the similarity between the original graph and its augmented (i.e., counterfactual and noisy) representations:</p><formula xml:id="formula_7">L s = E u 1 2 D(t(z u ), sg(z u )) + D(t(z u ), sg(z u )) ,<label>(3)</label></formula><p>where t(z u ) and t(z u ) are the transformed representations of node u and perturbed node ũ respectively, D is the cosine distance, and stopgrad (sg) prevents gradients from being backpropagated. The stopgrad signifies that the node representations zu are considered as constant when operating on t(z u ) and vice-versa.</p><p>Finally, the overall objective function for NIFTY is:</p><formula xml:id="formula_8">min θENC,θt,θ f E u (1 − λ)L c ] + λL s ,<label>(4)</label></formula><p>where {θ ENC , θ t , θ f } denotes trainable parameters of ENC, predictor t, and classifier f , L c is the binary cross entropy (BCE) loss, and the expectation is taken over training nodes in G. The regularization coefficient λ controls the trade-off between downstream node classification loss L c and the tripled-based objective L s . Algorithm 1 summarizes the overall training procedure of NIFTY.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Enforcing Fairness and Stability in GNN architecture</head><p>Next, we describe how NIFTY infuses fairness and stability in the architecture of the underlying GNN. In particular, NIFTY modifies the GNN's routing of neural messages. Recall (Sec. 3) that a typical GNN layer is given by:</p><formula xml:id="formula_9">h k u = UPD(AGG(MSG(h k−1 u , h k−1 v )|v ∈ N u ), h k−1 u ).</formula><p>As we will see in this section, NIFTY modifies the UPD step of each GNN layer.</p><p>Without loss of generality, we can consider AGG operator to be a fully-connected layer and UPD to be a non-linear activation function σ. Using these specific parametrizations, the message-passing step can be rewritten as:</p><formula xml:id="formula_10">h k u = σ W k a h k−1 u +W k n v∈N (u) h k−1 v</formula><p>, where W k n is the weight matrix associated with the neighbors of node u at layer k and W k a is the self-attention weight matrix at layer k. Definition 2 tells us that as the local network neighborhood and the node attribute vector of node u change from b u to bu , the Lipschitz constant L provides an upper bound on how much u's node embedding can change. In fact, the Lipschitz constant L represents the smallest value for which Eqn. 2 in Definition 2 holds true. Leveraging this understanding, NIFTY bounds the change in u's embedding by appropriately normalizing the encoder's weight matrices. This is possible because of the slope-restricted structure of the nonlinear activation function in the UPD step (see proof in Sec. 5).</p><p>Using our derivations in Sec. 5, at each layer k, we calculate the Lipschitz constant L of term W k a h k−1 u as the spectral norm of the weight matrix. We use L to normalize W k a as:</p><formula xml:id="formula_11">Wk a = W k a /σ(W k a ).<label>(5)</label></formula><p>We use this Lipschitz-normalized weight matrix Wk a to modify the UPD step as:</p><formula xml:id="formula_12">h k u = σ( Wk a h k−1 u + W k n v∈N (u) h k−1 v ).</formula><p>Lipschitz normalization of weight matrices is appealing for two reasons. It bounds the difference between embeddings of original and perturbed nodes (attributes). It also establishes a connection between the stability and counterfactual fairness in a sense that similar inputs should yield similar predictions. Next, we investigate this connection in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Theoretical analysis of NIFTY</head><p>Here, we provide detailed theoretical analysis of our framework NIFTY. More specifically, we prove that representations generated by NIFTY are stable. We also provide a theoretical upper bound on the unfairness of the resulting representations. Lastly, we show that the downstream classifiers that leverage the representations output by NIFTY satisfy counterfactual fairness as well. </p><formula xml:id="formula_13">||ENC(ũ) − ENC(u)|| p ≤ K k=1 ||W k a || p ||( bu − b u )|| p ,<label>(6)</label></formula><p>where ũ is a node in the augmented graph which is generated by perturbing the attribute values and/or incident edges of node u, b u and bu capture all attribute values and incident edge information for nodes u and ũ respectively, and W k a is weight matrix associated with attributes of node u at layer k.</p><p>Proof. Following Sec. 4.2, the node representation output by layer k of the GNN for a perturbed node ũ is given by:</p><formula xml:id="formula_14">hk u = σ W k a hk−1 u +W k n v∈N (ũ) h k−1 v ,<label>(7)</label></formula><p>where N (ũ) is the neighborhood of node ũ which is obtained after perturbing edges incident on node u. Now, the difference between the node embeddings obtained after the message-passing in layer k is:</p><formula xml:id="formula_15">hk u − h k u = σ W k a hk−1 u +W k n v∈N (ũ) h k−1 v − σ W k a h k−1 u + W k n v∈N (u) h k−1 v</formula><p>Taking the norm and assuming that σ is normalized Lipschitz, i.e., ||σ(b) − σ(a)|| p ≤ ||b − a|| p , we get:</p><formula xml:id="formula_16">|| hk u − h k u || p ≤ ||W k a hk−1 u +W k n v∈N (ũ) h k−1 v −W k a h k−1 u −W k n v∈N (u) h k−1 v || p ≤ ||W k a ( hk−1 u −h k−1 u )+W k n ( v∈N (ũ) h k−1 v − v∈N (u) h k−1 v )|| p<label>(8)</label></formula><p>The second term in the above inequality will be close to 0 since the probability of dropping an edge p e is very small. So, we can drop the second term and then leverage Cauchy-Schwartz inequality to get:</p><formula xml:id="formula_17">|| hk u − h k u || p ≤ ||W k a ( hk−1 u −h k−1 u ) ≤ ||W k a || p ||( bu − b u )|| p (9)</formula><p>Note that the encoder ENC is essentially a sequential composition of message-passing functions applied at layers 1 • • • K. Furthermore, the composition of two Lipschitz continuous functions with Lipschitz constants L 1 and L 2 is a new Lipschitz continuous function with L 1 × L 2 as the Lipschitz constant <ref type="bibr" target="#b15">[Gouk et al., 2021]</ref>. Putting it all together, we have:</p><formula xml:id="formula_18">||ENC(ũ) − ENC(u)|| p = ||z u − z u || p = || hK u − h K u || p ≤ K k=1 ||W k a || p ||( bu − b u )|| p , (<label>10</label></formula><formula xml:id="formula_19">)</formula><p>where K is the last GNN layer. In the case of p = 2, the Lipschitz constant in the above equation is equal to the product of the largest singular values (i.e., spectral norm) of weight matrices W k a and can be approximated with a small number of iterations of the power method. We thus perform spectral normalization on the weights of each layer and use the normalized weights Wk a in the UPD step of each layer. Theorem 2 (NIFTY Counterfactual Fairness). Given a non-linear activation function σ that is Lipschitz continuous and a binary valued sensitive attribute s, the (counterfactual) unfairness of the representations learned by our framework NIFTY can be bounded as follows:</p><formula xml:id="formula_20">||ENC(ũ s ) − ENC(u)|| p ≤ K k=1 ||W k a || p , (<label>11</label></formula><formula xml:id="formula_21">)</formula><p>where ũs is a node in the augmented graph which is generated by modifying (flipping) the value of the sensitive attribute (s) of node u while keeping everything else constant.</p><p>Proof Sketch. In order to prove this theorem, we will first prove the following:</p><formula xml:id="formula_22">||ENC(ũ s ) − ENC(u)|| p ≤ K k=1 ||W k a || p ||( bs u − b u )|| p<label>(12)</label></formula><p>It can be seen that the above equation has a similar form as that of Eqn. 6 in Theorem 1. Therefore, the above equation can be proved analogously. Note that the node ũs in Eqn. 12 is exactly the same as the node u except that the value of the sensitive attribute is flipped (either from 0 to 1, or from 1 to 0). Therefore, ||( bs u − b u )|| p = 1 and we obtain Eqn. 11.</p><p>Proposition 1 (Counterfactual Fairness of Downstream Classifier). If the representations learned by our framework NIFTY satisfy counterfactual fairness, then a downstream classifier f : z u → ŷu which leverages these representations also satisfies counterfactual fairness.</p><p>Proof is provided in the Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>Next, we present experimental results for our NIFTY framework. We address the following key questions: Q1) Does NIFTY enable GNNs to learn fair and stable embeddings? Q2) Can NIFTY achieve group fairness? Q3) How does the interplay between fairness and stability affect downstream performance? Q4) Are changes to GNN's architecture and objective function necessary for fair and stable predictions?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets and Experimental Setup</head><p>We first describe datasets designed to study fair and stable network embeddings and then outline experimental setup.</p><p>Datasets. We construct three new datasets. 1) The German credit graph has 1,000 nodes representing clients in a German bank that are connected based on the similarity of their credit accounts. The task is to classify clients into good vs. bad credit risks considering clients' gender as the sensitive attribute <ref type="bibr" target="#b9">[Dua and Graff, 2017]</ref>. 2) The Recidivism graph has 18,876 nodes representing defendants who got released on bail at the U.S state courts during <ref type="bibr">1990</ref><ref type="bibr" target="#b33">-2009</ref><ref type="bibr" target="#b23">[Jordan and Freiburger, 2015]</ref>. Defendants are connected based on the similarity of past criminal records and demographics. The goal is to classify defendants into bail (i.e., unlikely to commit a violent crime if released) vs. no bail (i.e., likely to commit a violent crime) considering race information as the protected attribute. 3) The Credit defaulter graph has 30,000 nodes representing individuals that we connected based on the similarity of their spending and payment patterns <ref type="bibr" target="#b33">[Yeh and Lien, 2009]</ref>. The task is to predict whether an individual will default on the credit card payment or not while considering age as the sensitive attribute. See Appendix for details on dataset construction.</p><p>Performance evaluation. To measure predictive performance of downstream binary node classification, we use AUROC and F1-score. To quantify group fairness, we use statistical parity (SP) <ref type="bibr" target="#b10">[Dwork et al., 2012]</ref>, defined as: ∆ SP =|P (ŷ u =1|s=0)−P (ŷ u =1|s=1)|, and equal opportunity (EO) <ref type="bibr">[Hardt et al., 2016]</ref>, defined as: ∆ EO =|P (ŷ u =1|y u =1, s=0)−P (ŷ u =1|y u =1, s=1)|, where probabilities are estimated on the test set <ref type="bibr" target="#b7">[Dai and Wang, 2021]</ref>. To measure counterfactual fairness, we define the unfairness score as the percentage of test nodes for which predicted label changes when the node's sensitive attribute is flipped. Finally, the instability score represents the percentage of test nodes for which predicted label changes when random noise is added to node attributes.</p><p>GNN methods. To investigate the flexibility of NIFTY, we incorporate it into five estabished and state-of-the-art GNN methods: <ref type="bibr">GCN [Kipf and Welling, 2017]</ref>, GraphSAGE <ref type="bibr" target="#b18">[Hamilton et al., 2017]</ref>, Jumping Knowledge (JK) <ref type="bibr" target="#b32">[Xu et al., 2018]</ref>, GIN <ref type="bibr" target="#b33">[Xu et al., 2019]</ref>, and InfoMax <ref type="bibr" target="#b30">[Veličković et al., 2019]</ref>.  Baseline methods and implementation. We consider two baseline methods: FairGCN <ref type="bibr" target="#b7">[Dai and Wang, 2021]</ref> and RobustGCN <ref type="bibr" target="#b38">[Zhu et al., 2019]</ref>; all hyperparameters are set following the authors' guidelines. We use stop-gradient operation for training the Siamese networks <ref type="bibr" target="#b5">[Chen and He, 2020]</ref>. We set regularization coefficient to λ = 0.6 in all our experiments and conduct a sensitivity analysis into the effect of λ on NIFTY's performance. See Appendix for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>Next, we discuss experimental results that answer key questions highlighted at the beginning of this section (Q1-Q4).</p><p>Q1) NIFTY improves fairness and stability of GNNs. Across three datasets and five GNNs, Fig. <ref type="figure" target="#fig_2">2</ref> shows that NIFTYaugmented GNNs learn fairer and more stable embeddings than unmodified GNNs. On average, NIFTY improves stability and fairness of GNNs by 60.87% and 92.01%, respectively. Further, NIFTY can promote fairness and stability of GNNs without sacrificing their predictive performance, as evidenced by AUROC and F1-scores in Table <ref type="table">2</ref>. Finally, NIFTY outperforms baseline FairGCN and RobustGCN methods by 57.26% and 62.07% on stability and fairness metrics (Table <ref type="table" target="#tab_1">1</ref>). Q2) NIFTY achieves group fairness. Remarkably, while NIFTY's explicit aim is to capture counterfactual fairness, our approach indirectly improves group fairness of GNNs because it reduces information on protected attributes, and, we argue, makes the multi-objective problem of satisfying fairness and stability more tractable. Across three datasets, five GNNs, and two group fairness metrics, NIFTY achieves 43.56% lower ∆ SP and 34.70% lower ∆ EO . Further, we find that NIFTY achieves 36.05% lower ∆ SP and 29.71% lower ∆ EO error rates than baseline methods (Table <ref type="table" target="#tab_1">1</ref>), suggesting that in NIFTY, a node's chance of being represented as a particular point in the embedding space does not depend on the node's membership in a protected group.</p><p>Table <ref type="table">2</ref>: Results of NIFTY for five GNNs and three graph datasets. Shown is average performance across five independent runs. Arrows (↑, ↓) indicate the direction of better performance. NIFTY keeps the predictive power (AUROC and F1-score) of original GNNs while improving their fairness and stability (shaded area).  Q3) Trade-offs between fairness, stability, and predictive performance. As we increase regularization coefficient λ in NIFTY (Fig. <ref type="figure" target="#fig_3">3</ref>), we find that the error rates for counterfactual fairness and stability steadily decrease. Interestingly, even with a modest amount of regularization (λ = 0.1), NIFTY achieves a 94.29% improvement in unfairness error rate.</p><p>As expected, a more strongly regularized NIFTY model takes a hit on its predictive performance (higher error rate for AUROC and F1-score). See Fig. <ref type="figure" target="#fig_4">4</ref> for similar trends on the recidivism and credit defaulter graphs.</p><p>Q4) Ablation study. We conduct ablations on two key NIFTY's components, namely the objective function and the layer-wise normalization of GNN's architecture using the Lipschitz constant. Results show that both components are necessary to generate embeddings that are simultaneously fair and stable (Table <ref type="table" target="#tab_3">3</ref>). In particular, we observe a 90.7% improvement in fairness of NIFTY-GCN as compared to vanilla GCN, providing empirical evidence for our theoretical analysis that the Lipschitz normalization can improve both fairness and stability of graph embeddings (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions &amp; Future Work</head><p>We propose and address the problem of learning representations that are both fair and stable. To this end, we introduce NIFTY, a unified framework which exploits a key connection between counterfactual fairness and stability to learn representations that satisfy both these properties. At its core, NIFTY, outlines a two-level strategy to modify an existing GNN both at the architectural as well as the objective function level. We carry out detailed theoretical analysis to show that the representations learned by NIFTY are both counterfactually fair and stable. Further, results on new graph datasets from domains such as criminal justice and financial lending show that NIFTY can considerably improve fairness (both in terms of counterfactual and group fairness) and stability without sacrificing predictive performance. This work paves way for several exciting future directions. For instance, it would be interesting to extend NIFTY to generate fair and stable representations of other graph components (e.g., edges, subgraphs) and to cater to other downstream tasks (e.g., link prediction, graph classification).</p><p>Marinka Zitnik, Monica Agrawal, and Jure Leskovec. Modeling polypharmacy side effects with graph convolutional networks. In Bioinformatics, 2018. Daniel Zügner and Stephan Günnemann. Adversarial attacks on graph neural networks via meta learning. In ICLR, 2019.</p><p>A Proposition 1 and its Proof Proposition 1 (Counterfactual Fairness of Downstream Classifier). If the representations learned by our framework NIFTY satisfy counterfactual fairness, then a downstream classifier f : z u → ŷu which leverages these representations also satisfies counterfactual fairness.</p><p>Proof. The downstream classifier uses the representation z u output by our framework for predicting the label ŷu of node u, thus forming a Markov chain x u → z u → ŷu <ref type="bibr" target="#b27">[Liao et al., 2019</ref>]. As we discuss in Section 3, node representations are said to be counterfactually fair if they are independent of the sensitive attribute, i.e., the mutual information between the sensitive attribute s and the representation z u for any given node u is zero: I(s; z u ) = 0.</p><p>Using the properties of inequality and non-negativity of mutual information:</p><formula xml:id="formula_23">0 ≤ I(s; ŷu ) ≤ I(s; z u ) and I(s; z u ) = 0 =⇒ I(s; ŷu ) = 0<label>(13)</label></formula><p>Therefore, the node label ŷu for any given node u is independent of the sensitive attribute s, and consequently the downstream node classifier satisfies counterfactual fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset details</head><p>German Credit Graph. The German Graph credit dataset classifies people described by a set of attributes as good or bad credit risks <ref type="bibr" target="#b9">[Dua and Graff, 2017]</ref>. It consists of attributes like Gender, LoanAmount, and other account-related features of 1,000 clients. We use Minkowski distance as the similarity measure for calculating the similarity between two node attributes using: 1/(1 + minkowski(x u , x v )). To obtain the credit graph network that connects clients, we connect two nodes if the similarity between them is 80% of the maximum similarity between all respective nodes (Refer Table <ref type="table">.</ref> 4 for details). We argue that a graph neural network is fair if it predicts the client credit risk irrespective of their gender. Hence, we used gender as the sensitive attribute for the loan dataset.</p><p>Recidivism Graph. The dataset consists of samples of bail outcomes collected from several state courts in the US between <ref type="bibr">1990</ref><ref type="bibr" target="#b33">-2009</ref><ref type="bibr" target="#b23">[Jordan and Freiburger, 2015]</ref>. It consists of past criminal records, demographic attributes, and other details of 18,876 defendants who got released on bail. We use Minkowski distance as the similarity measure for calculating the similarity between two node attributes using: 1/(1 + minkowski(x u , x v )). To obtain the bail graph network that connects defendants, we connect two nodes if the similarity between them is 60% of the maximum similarity between all respective nodes (Refer Table <ref type="table">.</ref> 4 for details). A machine learning model is trained to predict a defendant who is more likely to commit a violent or nonviolent crime once released on bail. A fair model should make predictions independent of the defendant's race, and, thus, we use it as the protected attribute for the dataset.</p><p>Credit Defaulter Graph. We use a processed version <ref type="bibr" target="#b29">[Ustun et al., 2019]</ref> of the credit dataset in Yeh and Lien <ref type="bibr">[2009]</ref>.</p><p>The task is to predict whether an applicant will default on an upcoming credit card payment. The dataset contains 30,000 individuals with features like education, credit history, age, and features derived from their spending and payment patterns. We use Minkowski distance as the similarity measure for calculating the similarity between two node attributes using: 1/(1 + minkowski(x u , x v )). To obtain the credit defaulter graph network that connects applicants, we connect two nodes if the similarity between them is 70% of the maximum similarity between all respective nodes (Refer Table <ref type="table">.</ref> 4 for details). For the credit dataset, we used age as the sensitive attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Architecture and Hyperparameter selection</head><p>We provide an overview of the important components of our proposed architecture and their respective training settings.</p><p>Encoder. The encoder block of our proposed framework can comprise of either simple Multilayer Perceptron (MLP) networks or any other GNN variant. For all our experiments, we use the vanilla GNN as the encoder block of our contrastive learning framework. For all datasets, we use a single-layer GNN encoder and set the hidden dimensionality to 16. The encoder is followed by a two-layer MLP projection head <ref type="bibr">[Chen et al., 2020]</ref>. We only use ReLU and BatchNormalization (BN) layers after the first hidden layer in the MLP. For both the MLP layers, we set the hidden dimensionality to 16.</p><p>Predictor. We use a single layer MLP with no ReLU and BN as our predictor <ref type="bibr">[Chen et al., 2020]</ref> to transform the graph embeddings of one augmented graph to another and vice-versa. We set the hidden dimensionality to 16 for the predictor layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Downstream classifier.</head><p>We use a single fully-connected layer with a Sigmoid activation function in all our nodeclassification experiments. We set the hidden dimensionality of the fully-connected layer to 16.</p><p>Hyperparameters. For all experiments, we set the probability of perturbing a feature dimension to p n = 0.1 and the probability with which an edge is dropped to p e = 0.001. For training GNNs and their NIFTY-augmented counterparts (Sec. 6.1), we use an Adam optimizer with a learning rate of 1 × 10 −3 , weight decay of 1 × 10 −5 , and the number of epochs to 1000. For RobustGCN and FairGCN, all hyperparameters are set following the authors' guidelines.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our framework NIFTY can learn node representations that are both fair and stable (i.e., invariant to the sensitive attribute value and perturbations to the graph structure and non-sensitive attributes) by maximizing the similarity between representations from diverse augmented graphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 :</head><label>1</label><figDesc>Overview of NIFTY algorithm Input: Graph G = (V, E, X); regularization λ; sensitive attribute s; number of training epochs num epoch Output: Optimized model parameters {θENC, θt, θ f }; fair and stable representations zu for u ∈ G for ep ← 1 to num epoch do for layer k ← 1 to K do Lipschitz-normalize ENC's weights W k a (Eqn. 5) end for node u ← 1 to -V-do Perturb attributes and graph structure to get ũ (Sec. 4.1) Modify sensitive attribute value to get ũs (Sec. 4.1) Encode zu = ENC(u), zu = ENC(ũ), zs u = ENC(ũ s ) Transform embeddings: t(zu), t(zu), t(z s ũ) (Sec. 4.1) end Calculate triplet-based similarity (Eqn. 3) Apply downstream classifier f as ŷu = f (ENC(u)) Update {θENC, θt, θ f } according to the objective in Eqn. 4 end Theorem 1 (NIFTY Stability). Given a non-linear activation function σ that is Lipschitz continuous, the representations learned by our framework NIFTY are stable, i.e., ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Unfairness (top) and instability (bottom) error rates for five GNNs and their NIFTY counterparts. NIFTYenhanced GNNs give fairer and more stable predictions than their unmodified counterparts across all three datasets and five GNNs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: The effects of regularization on the performance of NIFTY. Shown are results for NIFTY-GIN and the German credit graph (see Fig.4for other datasets). Over a wide range of regularization strength (0.1 &lt; λ &lt; 0.5), NIFTY achieves a near-perfect stability and fairness on the downstream task without sacrificing the predictive ability of GIN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Effect of regularization coefficient on AUROC, F1-score, stability, and fairness in NIFTY-GIN on (a) the German credit graph, (b) the recidivism graph, and (c) the credit defaulter graph. With increasing the regularization coefficient on the self-supervised task the robustness and fairness score can reach 0% error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of NIFTY to existing methods for improving fairness (i.e.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell cols="5">AUROC (↑) F1-score (↑) Unfairness (↓) Instability (↓) ∆SP (↓)</cell><cell>∆EO (↓)</cell></row><row><cell></cell><cell>FairGCN</cell><cell>75.21±0.36</cell><cell>81.52±0.68</cell><cell>N/A</cell><cell>7.84±2.20</cell><cell>38.12±4.87</cell><cell>26.70±4.27</cell></row><row><cell>German credit graph</cell><cell>RobustGCN NIFTY-GCN</cell><cell>71.06±1.48 70.32±4.42</cell><cell>78.85±6.39 81.98±0.82</cell><cell>7.68±4.69 1.12±0.77</cell><cell>4.48±1.07 4.48±3.23</cell><cell>25.78±10.92 15.08±8.22</cell><cell>18.47±9.87 12.56±8.60</cell></row><row><cell>Recidivism graph</cell><cell>FairGCN RobustGCN NIFTY-GCN</cell><cell>87.55±0.60 87.25±1.67 81.40±0.89</cell><cell>78.14±0.94 79.02±2.84 69.24±0.70</cell><cell>N/A 2.61±1.58 0.84±0.68</cell><cell>24.37±2.33 13.02±6.06 13.28±1.62</cell><cell>6.51±0.77 5.36±1.28 3.16±0.60</cell><cell>4.51±1.10 4.20±1.88 2.99±0.40</cell></row><row><cell></cell><cell>FairGCN</cell><cell>72.69±1.23</cell><cell>80.16±2.03</cell><cell>N/A</cell><cell>5.73±0.60</cell><cell>15.86±5.16</cell><cell>14.43±6.06</cell></row><row><cell>Credit defaulter graph</cell><cell>RobustGCN NIFTY-GCN</cell><cell>72.98±0.26 71.92±0.19</cell><cell>81.79±0.60 81.99±0.63</cell><cell>0.94±0.60 0.63±1.28</cell><cell>1.68±0.83 0.95±1.16</cell><cell>12.41±0.54 12.40±1.62</cell><cell>10.16±0.49 10.09±1.55</cell></row></table><note>, FairGCN<ref type="bibr" target="#b7">[Dai and Wang, 2021]</ref>) and stability (i.e., RobustGCN<ref type="bibr" target="#b38">[Zhu et al., 2019]</ref>) of GNNs. Shown is average performance across five independent runs. The counterfactual fairness does not apply to FairGCN (i.e., N/A) as FairGCN cannot consider sensitive attributes. Arrows (↑, ↓) indicate the direction of better performance. NIFTY outperforms baselines methods by a large margin.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablation study on the recidivism graph. Shown is average performance across five independent runs, evidencing that NIFTY's changes in the GNN architecture and the objective function are complementary and improve fairness and stability.</figDesc><table><row><cell>Method</cell><cell cols="6">AUROC (↑) F1-score (↑) Unfairness (↓) Instability (↓) ∆SP (↓) ∆EO(↓)</cell></row><row><cell>GCN [Kipf and Welling, 2017]</cell><cell>86.52±0.42</cell><cell>77.50±0.87</cell><cell>9.02±3.04</cell><cell>21.97±1.63</cell><cell>8.49±0.73</cell><cell>5.93±0.56</cell></row><row><cell>NIFTY-GCN w/o obj. changes (Sec. 4.1)</cell><cell>80.02 ±0.20</cell><cell>67.51 ±0.23</cell><cell>2.61±0.64</cell><cell>13.69±0.60</cell><cell>5.86±0.85</cell><cell>4.65±0.49</cell></row><row><cell>NIFTY-GCN w/o arch. changes (Sec. 4.2) NIFTY-GCN</cell><cell>84.83 ±2.85 81.40 ±0.89</cell><cell>76.15±5.74 69.24±0.70</cell><cell>1.64 ±1.58 0.84±0.68</cell><cell>13.98 ±1.38 13.28±1.62</cell><cell>4.29 ±1.32 3.16±0.60</cell><cell>3.48 ±1.37 2.99±0.40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Statistics of novel graph datasets designed for node classification and accompanied by sensitive attributes. The datasets are appropriate to study fairness-and stability-aware algorithms.</figDesc><table><row><cell>Dataset</cell><cell>German credit graph</cell><cell>Recidivism graph</cell><cell>Credit defaulter graph</cell></row><row><cell>Nodes</cell><cell>1,000</cell><cell>18,876</cell><cell>30,000</cell></row><row><cell>Edges</cell><cell>22,242</cell><cell>321,308</cell><cell>1,436,858</cell></row><row><cell>Node features</cell><cell>27</cell><cell>18</cell><cell>13</cell></row><row><cell>Average node degree</cell><cell>44.48±26.51</cell><cell>34.04±46.65</cell><cell>95.79±85.88</cell></row><row><cell>Sensitive attribute</cell><cell>Gender (Male/Female)</cell><cell>Race (Black/White)</cell><cell>Age (≤ 25/ &gt; 25)</cell></row><row><cell>Node labels</cell><cell>good credit vs. bad credit</cell><cell>bail vs. no bail</cell><cell>payment default vs. no default</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">Code and datasets are available at https://github.com/chirag126/nifty</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Subgraph neural networks</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><forename type="middle">M</forename><surname>Samuel G Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Zitnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fairness in criminal justice risk assessments: The state of the art</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Berk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoda</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahin</forename><surname>Jabbari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sociological Methods &amp; Research</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Compositional fairness constraints for graph embeddings</title>
		<author>
			<persName><forename type="first">Joey</forename><surname>Avishek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Signature verification using a&quot; siamese&quot; time delay neural network</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Säckinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Exploring simple siamese representation learning. arXiv</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fair prediction with disparate impact: A study of bias in recidivism prediction instruments</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Chouldechova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fairgnn: Eliminating the discrimination in graph neural networks with limited sensitive attribute information</title>
		<author>
			<persName><forename type="first">Enyan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Casey</forename><surname>Graff</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITCS</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Debiasing knowledge graph embeddings</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Palfrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Gainza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freyr</forename><surname>Sverrisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><surname>Correia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nature Methods</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reliable graph neural networks via robust aggregation</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Samuel S Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Regularisation of neural networks by enforcing lipschitz continuity</title>
		<author>
			<persName><forename type="first">Henry</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Cree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Pierre H Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Daniel Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Gheshlaghi Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Network medicine framework for identifying drug repurposing opportunities for</title>
		<author>
			<persName><forename type="first">Deisy</forename><surname>Morselli Gysi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ítalo</forename><forename type="middle">Do</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asher</forename><surname>Ameli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helia</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">Marlene</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Ghiassian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Loscalzo</surname></persName>
		</author>
		<idno>COVID-19. arXiv</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wavelets on graphs via spectral graph theory</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>David K Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applied and Computational Harmonic Analysis</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
		</author>
		<editor>NeurIPS, 2016. Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
	<note>Heterogeneous graph transformer</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Skipgnn: predicting molecular interactions with skip-graph networks</title>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><forename type="middle">M</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific Reports</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Addressing crime situation forecasting task with temporal graph convolutional neural network approach</title>
		<author>
			<persName><forename type="first">Guangyin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghe</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jincai</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangping</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMTMA</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The effect of race/ethnicity on sentencing: Examining sentence type, jail length, and prison length</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kareem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tina</forename><forename type="middle">L</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><surname>Freiburger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Ethnicity in Criminal Justice</title>
				<imprint>
			<publisher>Taylor &amp; Francis</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Inherent trade-offs in the fair determination of risk scores</title>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sendhil</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITCS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-attention graph pooling</title>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Loftus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<editor>
			<persName><forename type="first">2017</forename><forename type="middle">Junhyun</forename><surname>Neurips</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Inyeop</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaewoo</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><surname>Kang</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Counterfactual fairness</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning generative adversarial representations (gap) under fairness and censoring constraints</title>
		<author>
			<persName><forename type="first">Jiachun</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lalitha</forename><surname>Sankar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fairwalk: Towards fair graph embedding</title>
		<author>
			<persName><forename type="first">Bartlomiej</forename><surname>Tahleen A Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Surma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Actionable recourse in linear classification</title>
		<author>
			<persName><forename type="first">Berk</forename><surname>Ustun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Spangher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FAT</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Deep graph infomax</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Hjelm</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomohiro</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; I-Cheng</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Che-Hui</forename><surname>Lien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<title level="s">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2009">2019. 2009</date>
		</imprint>
	</monogr>
	<note>How powerful are graph neural networks?</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PKDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fairness beyond disparate treatment &amp; disparate impact: Learning classification without disparate mistreatment</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Bilal Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">Gomez</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017a</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">From parity to preference-based notions of fairness in classification</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Bilal Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Gomez Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Weller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">GNNguard: Defending graph neural networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Robust graph convolutional networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Dingyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
