<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tapping on the Potential of Q&amp;A Community by Recommending Answer Providers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinwen</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering Shanghai Jiao Tong University No</orgName>
								<address>
									<addrLine>800 DongChuan Road Shanghai</addrLine>
									<postCode>200240</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shengliang</forename><surname>Xu</surname></persName>
							<email>slxu@apex.sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering Shanghai Jiao Tong University No</orgName>
								<address>
									<addrLine>800 DongChuan Road Shanghai</addrLine>
									<postCode>200240</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shenghua</forename><surname>Bao</surname></persName>
							<email>shhbao@apex.sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering Shanghai Jiao Tong University No</orgName>
								<address>
									<addrLine>800 DongChuan Road Shanghai</addrLine>
									<postCode>200240</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science &amp; Engineering Shanghai Jiao Tong University No</orgName>
								<address>
									<addrLine>800 DongChuan Road Shanghai</addrLine>
									<postCode>200240</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Tapping on the Potential of Q&amp;A Community by Recommending Answer Providers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4ACDD6361E721732096E5089C4B06ED4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval -search process</term>
					<term>H.3.5 [Information Systems and Applications]: On-line information Services -web-based services</term>
					<term>G.3 [Probability and Statistics] Algorithms, Experimentation, Human Factors Community-based Question Answering, Question Answerer Recommendation, Latent Topic Modeling, Gibbs Sampling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The rapidly increasing popularity of community-based Question Answering (cQA) services, e.g. Yahoo! Answers, Baidu Zhidao, etc. have attracted great attention from both academia and industry. Besides the basic problems, like question searching and answer finding, it should be noted that the low participation rate of users in cQA service is the crucial problem which limits its development potential. In this paper, we focus on addressing this problem by recommending answer providers, in which a question is given as a query and a ranked list of users is returned according to the likelihood of answering the question. Based on the intuitive idea for recommendation, we try to introduce topic-level model to improve heuristic term-level methods, which are treated as the baselines. The proposed approach consists of two steps: (1) discovering latent topics in the content of questions and answers as well as latent interests of users to build user profiles; (2) recommending question answerers for new arrival questions based on latent topics and term-level model. Specifically, we develop a general generative model for questions and answers in cQA, which is then altered to obtain a novel computationally tractable Bayesian network model. Experiments are carried out on a real-world data crawled from Yahoo! Answers during Jun 12 2007 to Aug 04 2007, which consists of 118510 questions, 772962 answers and 150324 users. The experimental results reveal significant improvements over the baseline methods and validate the positive influence of topic-level information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>As Web 2.0 applications become more and more popular, an enormous human knowledge sharing and exchanging activities are occurring explicitly or implicitly everyday online. Inspired by the idea that the wisdom of crowds is larger than few intelligent individuals <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, much work has been proposed to leverage crowds' knowledge contained in many different types of social media, such as Wikipedia <ref type="bibr" target="#b33">[34]</ref>, query log <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, social annotation <ref type="bibr" target="#b31">[32]</ref>, blogosphere <ref type="bibr" target="#b30">[31]</ref> and community-based QA <ref type="bibr" target="#b32">[33]</ref>. Research on these social media has been mainly focused on discovering hidden semantic information from structured content <ref type="bibr" target="#b33">[34]</ref> or unstructured content <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, and identifying influential authorities in community <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33]</ref>. In this paper, we focus on the community-based QA service in large part motivated by its popularity and the diversity of knowledge covered by it.</p><p>Community-based Question Answering (cQA) service is a particular form of online service for leveraging user-generated content, which is gaining increasing audiences in recent years, such as Yahoo! Answers<ref type="foot" target="#foot_0">1</ref> , Baidu Zhidao<ref type="foot" target="#foot_1">2</ref> and Live QnA <ref type="foot" target="#foot_2">3</ref> . In cQA, users exchange and share their knowledge explicitly by asking questions or answering others' questions in all service-predefined categories. Additionally, users can give positive or negative judgment to answers provided by other users. Intuitively, the questions and answers in QA communities can be viewed as a large base which stores all users' knowledge. Benefitting from the knowledge diversity of cQA portals <ref type="bibr" target="#b20">[21]</ref>, people are supposed to find the answer of any question once all people fully participate into community and share their knowledge. However, the main problem faced by cQA is the low participation rate of most users. It means that most answers or knowledge in the community comes from minority users. Therefore, the primary question is: can we tap on the potential of majority users in cQA?</p><p>Actually, the low participation rate in cQA is caused by two main reasons. <ref type="bibr" target="#b0">(1)</ref> Solving a new question is not an attractive job to most users, so they typically are not willing to spend their time on it. <ref type="bibr" target="#b1">(2)</ref> Many new users, even experienced users, do not know about the arrival of new questions which may interest them and can be solved by them. In nowadays' cQA services, many incentive mechanisms have been adopted to stimulate the participation enthusiasm of the users, such as awarding score to the question answerers. However, there is no significant improvement after taking such steps. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, we can see that the number of users who answered more than 5 questions is only 20% of the total number of users. The discussion in <ref type="bibr" target="#b20">[21]</ref> also concluded heavy tail phenomena in all the three subcategories (Programming, Cancer and Wrestling).</p><p>It is worthy to note that all incentive mechanisms taken by cQA service providers are focused on tackle with the first cause of low participation rate, low-enthusiasm. Additionally, in today's QA community, users have to browse the question category hierarchy to find interesting and solvable questions among millions of open questions to answer. It is really time-consuming and enthusiasm-dispelling even with the help of organized question categories. This kind of open question finding also keeps users from fully participating in QA community.</p><p>In this paper, we focus on recommending possible and reasonable question answerers for new arrival questions in order to tackle with the second cause of low participation rate in cQA. To the best of our knowledge, it is the first work on solving this problem in the context of cQA. Two intuitive ideas for handling this problem is either to find similar solved questions for new arrival questions first, and then recommend the answerers of these similar questions as the answerers for the new question, or construct user profiles first according to their history activities, and then suggest question answerers based on user-profiles. In the above two intuitive ideas, the similarities between question-question and between question-user are calculated on the term-level. However, the content quality variance in cQA caused by the informality of natural language and the data sparseness problem caused by low participation brings trouble to term-level question answerer recommendation. Therefore, we try to combine topic-level information about questions and users with term-level question answerer recommendation in our approach. First, we seek to discover latent topics in the content of questions as well as the associated answers, and latent topic interests of users. We propose a generative model to simulate user behaviors in cQA, for both question asking and answering, and then simultaneously obtain topic analysis of questions/answers and users. Second, we recommend answer providers for new questions according to discovered topics as well as term-level information of questions and users. In the experiment part, we first discuss the topic number selection followed by an analysis about the topics discovered by the proposed model. And then we compare the performance of several methods for question answerer recommendation on real-world cQA data which is crawled from Yahoo! Answers. The experimental results demon-strate that the combination of topic-level and term-level model improves the performance of question answerer recommendation.</p><p>The remainder of this paper is organized as follows: Section 2 introduces some prior work related to our approach. Section 3 discusses a general generative model for questions and answers in cQA followed by a simplified tractable model for user behavior. Experimental results are presented in Section 4. At last, we conclude the paper and discuss about future work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>In this section, we review three lines of work which are closely related to our approach: research on Question Answering, topic analysis using generative models, and expert search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Research on Question Answering</head><p>There is a large body of work conducted on QA domain. The main purpose of these work is to avoid the lag time involved by waiting for a response from other users. Typically, question searching and answer finding for new questions are the two primary applications.</p><p>In question search, given a question as query, the task is to find similar solved questions in QA community. Jeon et al. in <ref type="bibr" target="#b7">[8]</ref> proposed an approach to estimate the question semantic similarity based on their answers. Additionally, Jeon et al. proposed a translate model to find similar questions in large question-answer archives in <ref type="bibr" target="#b6">[7]</ref>. Besides searching for similar questions, recommending related questions in cQA, proposed by Y. Cao in <ref type="bibr" target="#b9">[10]</ref> recently, is an alternative of similar question search.</p><p>In answer finding, given a question as query, the task is to find the right answer to it in QA community. Initially, many research on answer retrieval have been done on FAQ data. In <ref type="bibr" target="#b10">[11]</ref>, Berger et al. used only statistic techniques to tackle with question answering. FAQ Finder <ref type="bibr" target="#b11">[12]</ref> combines statistics and semantic techniques in question answers finding. WordNet <ref type="bibr" target="#b0">[1]</ref> is used as a semantic knowledge base to calculate the semantic similarity. Methods using question templates and artificial rules to answer questions automatically are proposed in <ref type="bibr" target="#b13">[14]</ref> by Sneiders. Other extensive research on question answering has been done on TREC data <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>. Additionally, <ref type="bibr" target="#b5">[6]</ref> proposed a framework using non-textual features in QA community to predict the quality of answers.</p><p>Recently, E. Agichtein et al. proposed method in <ref type="bibr" target="#b32">[33]</ref> to distinguish high-quality content, both questions and answers, from the rest. Different from questions and answers finding problems above, the focus of this paper is to recommend possible and reasonable answer providers to new questions. Although P. Jurczyk and E. Agichtein <ref type="bibr" target="#b36">[37]</ref> exploited link analysis to identify authority users in QA community, it is quite different from the problem addressed in this paper too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Latent Topic Analysis</head><p>Vector Space Model <ref type="bibr" target="#b1">[2]</ref> is the most famous and successful model for text retrieval because of its simplicity. However, the "bag-of-words" assumption brings the problems of high dimension document representation and non-semantic relationship between words. Eliminating stop words in documents can be viewed as a simple attempt to reduce the dimension of document space. The first model dealing with space reduction is Latent Semantic Indexing (LSI) <ref type="bibr" target="#b21">[22]</ref>, which uses Singular Value Decomposition to represent document in a low-dimension space. Although LSI includes "semantic" in its name, it still encounters the problem of User Participation lacking for semantic explanation. In order to leverage semantic between words in documents, pLSI <ref type="bibr" target="#b22">[23]</ref> introduces latent topics to represent documents, which also reduces document representation space dimension, and model the data generation process as a Bayesian network. Further, David M. Blei et al. in <ref type="bibr" target="#b23">[24]</ref> proposed Latent Dirichlet Allocation (LDA) to address the overfitting problem faced by pLSI by introducing a Dirichlet prior over topics and words.</p><p>Much work has been done based on the above models or their extensions. In <ref type="bibr" target="#b24">[25]</ref>, Wu et al. exploited pLSI for discovering latent semantic between social annotations in order to benefit Semantic Web. Zhou et al. in <ref type="bibr" target="#b27">[28]</ref> extends LDA to model the generation of both Web document and associated annotations for improving information retrieval. M. Rosen-Zvi et al. <ref type="bibr" target="#b25">[26]</ref> modeled author factor into document producing for document content characterization as well as author interest representation. Besides, X. Wang and A. McCallum <ref type="bibr" target="#b29">[30]</ref> combined time information with latent topic discovering for modeling topic variance over time.</p><p>Like the previous approaches, we treat interests of users as a multinomial distribution over latent topics, and each topic is a multinomial distribution over words too. Different from LDA <ref type="bibr" target="#b23">[24]</ref> and the above extensions, we introduce the category information of questions and answers, which is predefined by cQA services, into the process of discovering latent topics. It is proven to be positive information for question answering recommendation in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Expert Search</head><p>Different from question and answer finding problem which uses existing community knowledge directly to resolve the new questions, the task of question answerer recommendation is to predict the possible answerers for new questions based on the activity history of users. Similarly, expert search is to find a ranked list of domain experts for the given query. Nowadays, the main approach for expert search is candidate-centered, in which user profiles are constructed by aggregating information from documents related to corresponding users. When a query comes, the users are returned as a ranked list according to the similarity between the query and user-profiles. In <ref type="bibr" target="#b19">[20]</ref>, Mockus et al. proposed an expert finding system by using log data to facilitate software engineering. <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19]</ref> finding experts by mining experts and expertise from E-mail communications. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref> both proposed profile-based models for expert finding on general documents. In <ref type="bibr" target="#b15">[16]</ref>, Balog et al. compared two generative models for expert search resulted in emphasizing document topicality.</p><p>Although expert search is similar to our problem, there are some particular aspects that make question answerer recommendation different from expert search. Obviously, experts could be reasonable answerers in categories like Mathematics and Programming. However, according to the discussion in <ref type="bibr" target="#b20">[21]</ref>, there are some categories in cQA where questions are asking for neither expertise nor support, but rather opinion and conversation. In such categories, expert users might not be suitable question answerers, at least not the only possible answerers. Moreover, the interests of users in cQA are not as focus as expertise. Additionally, the motivation of expert search is focus on finding experts who can solve the need of users. But the objective of question answerer recommendation is to invite many possible answerers to provide answer in order to improve the user participation in cQA. Furthermore, the query type in question answerer recommendation is different from expert search. In traditional expert search, query often consists of several keywords. However, in question answerer recommendation, the query is a new question, which is a multi-field (question category, question title and question detail) natural language document. From this point of view, question answerer recommendation can be viewed as a general case of expert search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM STATEMENT</head><p>Let , , … , and , , … , denote all users and questions in the QA community respectively. and represents the number of questions answered and asked by user . Every question consists of three parts, question category, question title and question detail. Question category is the category the question belongs to, which is specified by question asker. Question title contains a brief description of the question. Optionally, the question asker can provide a more concrete explanation about the question with more words in question detail</p><p>. Every question has a list of associated answers to it. Additionally, and denotes the asker and the th answerer for question respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Answerer Recommendation.</head><p>For a new arrival question , the question answerer recommendation task is to suggest a ranked list of users , , … , who are possible to answer , where the higher ranked users are more possible to answer it. To tackle with the answerer recommendation problem, we need to resolve the following three sub-problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question representation</head><p>Regarding to this, the main challenge we face is how to represent the main focus of questions. In our approach, we combine the topic-level representation and term-level representation to express the main focus of questions. In topic-level, we use topics discovered by latent topic model. In term-level, we treat questions as multi-field documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User expertise and interest representation</head><p>On this issue, we need to describe the expertise and interest of users based on the activity history of users. Concretely, we combine terms in questions and answers which are related to the users as user-profiles. Additionally, the topic-level description of user-profiles is also exploited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking o c endation candidates f re omm</head><p>For the queried question , the critical part is to evaluate the score | for every user , which indicates the probability that user will answer . In our approach, we explore different weights to combine term-level similarity ranking and topic-level similarity ranking.</p><p>In the following sections, our approaches to handle the above three problems will be discussed in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MODELING COMMUNITY-BASED QUESTION ANSWERING</head><p>We propose a probabilistic generative model for QA community. The model defines the generation process of questions and answers posted by users in all categories. The motivation of modeling the data generation process in cQA is to simultaneously discover the latent topics contained by terms, categories and users. After topic analysis, we will exploit the topic distributions of terms and categories to analyze the content of new questions. The topic distributions of questions and users are the basis of topic-  or profile of user level answerer recommendation. In this section, we first introduce a general model in which answer content is influenced by question content. After that, we simplify it to obtain a tractable Bayesian network model, namely User-Question-Answer (UQA) Model. Finally, we will discuss the parameter estimation method for the UQA model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generative Model for Questions and Answers</head><p>Before introducing general generative model, we first give a brief review about the basic Latent Dirichlet Allocation (LDA) model. Our notations used in this paper are summarized in Table <ref type="table" target="#tab_1">1</ref>, and the graphic model representations of LDA model, general generative model and UQA model are shown in Figure <ref type="figure" target="#fig_1">2</ref>, Figure <ref type="figure" target="#fig_2">3</ref> and Figure <ref type="figure">4</ref> respectively. LDA models the generation of document content as two independent stochastic processes by introducing latent topic space. For an arbitrary word in document , (1) a topic is first sampled from the multinomial distribution , which is generated from the Dirichlet prior parameterized by , (2) and then the word is generated from multinomial distribution , which is generated from the Dirichlet prior parameterized by . The two Dirichlet priors for document-topic distributions and topic-word distributions reduce the As a background introduction, we here describe our understanding about the question asking and answering process in cQA. For question askers, they first have a question to be asked in mind, and then choose a category for the question and at last post the question in that category. For question answerers, they choose the question they would like to answer in one category and then post their answers according to the content of question. Based on this understanding and inspired by the discussion in <ref type="bibr" target="#b20">[21]</ref>, the characteristics of question asking and answering are quite divergent in different categories. Therefore, we intend to introduce category information about questions and answers into the general generative model.</p><p>The plate notation of general generative model is presented in Figure <ref type="figure" target="#fig_2">3</ref>. Inspired by related work on topic analysis <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>, we make the following assumptions about the probabilistic structure of general generative model. First, each question or answer is modeled as a multinomial distribution over latent topics, and each topic is modeled as a multinomial distribution over words and a multinomial distribution over categories. Second, the prior distributions for topics, words and categories follow different parameterized Dirichlet distribution, which is conjugate prior for multinomial distribution. On the question asking side (left-hand side), for each word in question asked by user , a topic is first drawn from the multinomial distribution , and then a word is sampled from the multinomial distribution and a category is also sampled from the multinomial distribution for the word. Repeating this process times, we get the content and category for one question. We obtain the whole question set by repeating the above process times. On the question answering side (right-hand side), for each word in answer provided by user , a topic is first drawn from multinomial distribution and conditioned on the content and category of the question, and then a word is sampled from the multinomial distribution</p><p>. Repeating this process times, we get the content of the answer. We obtain the whole answer set by repeating the process times. Since the topic set for questions and answers can be very similar but different, we model them differently in general model, and respectively. Additionally, we can acquire the topic analysis for users by combining the topics of questions they asked and answers provided by them.</p><p>From the discussion above, we find that the general generative model illustrated in Figure <ref type="figure" target="#fig_2">3</ref> is not quite applicable in practice. Because we have to estimate a lot of parameters: (1) document-topic multinomial distribution; <ref type="bibr" target="#b1">(2)</ref> topic-word multinomial distribution; <ref type="bibr" target="#b2">(3)</ref> conditional probabilities to express the correlation between words of question and the topics of answer; <ref type="bibr" target="#b3">(4)</ref> conditional probabilities to represent the correlation between category of question and the topics of answer. Moreover, there are some additional parameters which are difficult to tune in practice ( , , , , and ). Therefore, we will simplify the general model to a computationally tractable structure in next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">User-Question-Answer Model</head><p>In order to reduce the general generative model to a computationally tractable one, we first make four assumptions. First, we assume the topic space of question content is as same as that of answer content. This assumption means that we can treat the content of questions and answers in the same way. In fact, the variance of content is noted as a crucial problem in cQA <ref type="bibr" target="#b32">[33]</ref>, which indicates that the topics of many low quality answers might be far away from the topic of corresponding question. However, this is out of the scope of this paper so that we consider this assumption reasonable in our problem setting. Second, we assume the users have the same prior distribution type over topics for asking and answering. Third, the parameters for topics prior distribution are identical in asking and answering for the same user. Although the users might have different parameters for topic distribution in question asking and answering, or even different type of topic prior distribution, we here make this two assumptions for the sake of low computational complexity. Fourth, like other candidate-centric approaches for expert search, we assume that the user interests can be captured by the questions they asked, and answers they provided.</p><p>According to the above assumptions, we arrive at a simplified computable model, namely User-Question-Answer (UQA) Model. The plate notation of UQA is illustrated in Figure <ref type="figure">4</ref>. From the graphic representation of UQA, we can see that the main characteristic of UQA is that it is user-centric instead of question/answer-centric in general generative model. Each user is considered as a pseudo-document which is a combination of all questions he/she asked and answers he/she answered. After this transformation, the number of multinomial distribution over topics in UQA reduces to , which is much smaller than the number in general model, . And the topic prior distribution follows a symmetric Dirichlet parameterized by . In addition, the topic space of question asking and answering are merged into a single one, and the word distribution is chosen from a symmetric Dirichlet ( ) prior.</p><p>It is interesting to note the difference between our user-centric UQA model and the author-topic model in <ref type="bibr" target="#b25">[26]</ref>. In author-topic model, the authorship of an arbitrary word in the multi-author document is not known so that author-topic model assumes a uniform contribution of all document authors. However, in our problem setting, the author of every question and answer in cQA is explicitly presented. Actually, the authorship information of word is important to precisely identify user interests and expertise. Therefore, we model the word authorship information into UQA model. But, similar to LDA model, inference can not be done exactly in UQA model. Expectation-Maximization (EM) algorithm is a possible choice for estimating the parameters of models with latent variables. However, EM suffers from the possibility of running into local maxima and the high computational burden. Therefore, we employ an alternative approach, Gibbs sampling <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38]</ref>, which is gaining popularity in recent work on latent topic analysis <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>In Gibbs sampling, we evaluate the posterior distributions instead of estimating parameters directly. Note that we use the Dirichlet distribution which is the conjugate prior of multinomial distribution, thus we can integrate out , and easily and capture the uncertainty associated with them. We only need to estimate the conditional probability </p><formula xml:id="formula_0">∑ 1 1 ∑ 1 1 ∑ ∑<label>α, | , , , 1 ∑ 1 1</label></formula><p>where is the number of times of word are assigned to the topic , is the number of times of category are assigned to the topic , and is the number of words in user-profile are assigned to topic . The concrete derivation for equation ( <ref type="formula" target="#formula_0">1</ref>) is presented in Appendix A. In equation ( <ref type="formula" target="#formula_0">1</ref>), we have provided the conditional probability for asymmetric Dirichlet priors. However, we use symmetric Dirichlet priors in our experiments for simplicity that means are same for all topic . Similar assumptions are used for and in our experiments too. Algorithm 1 demonstrates the Gibbs sampling algorithm for UQA model training, where represents the current topic assignment of the th word in user-profile .</p><p>After model traini , w n ta parameters estimation as ng e ca ob in the</p><formula xml:id="formula_2">1 ∑ 1 1 ∑ 1 1 ∑ 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS 5.1 Dataset</head><p>We crawled 118510 resolved questions posted between Jun 12 2007 and Aug 04 2007 from Yahoo! Answers. In this question set , there are 150324 users, denoted by , involved in both asking and answering and 772962 answers. Additionally, questions in this dataset cover 20 different top categories of Yahoo! Answers. We divide the whole question set and user set , into six subsets according to the user participation degree and question category respectively. Additionally, we separate each subset into training set and testing set based on the ask time of questions. In each subset, there are about 9 10 ⁄ of all questions in training set, which posted before Aug 03 2007, and the rest are in testing set. For all training sets and testing sets, we remove the stop words and perform stemming for all words before further experiments.</p><p>The description and detail information of each subset are presented below and in Table <ref type="table" target="#tab_3">2</ref>. Each dataset contains a question set and an user set . Every question in contains three parts, respectively the title, the detail and the category. Additionally, every question has a list of associated answers to it. The user set contains all the answer providers for every associated answer and question askers. USER-15 and USER-10: Similar to subset USER-20, except the number of questions asked and answered by users in these subsets is not less than 15 and 10 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PETS:</head><p>contains all questions in the top category Pets. The associated answers to each question in are the same as the associated answers to it in .</p><p>ELEC and FINA: Similar to subset PETS, except the questions in these subsets are in the top category Consumer Electronics and Business &amp; Finance respectively.</p><p>In the top three subsets, they contain questions from all 20 top categories. We call these three subsets user-partitioned sets. Additionally, we call the other threes subsets category-partitioned sets. In term-level search process, we treat the questions as three-field documents, question title, question detail and question category. We regard user-profiles as eight-field documents too, respectively the title, detail and category of the questions asked answered by them, the answers provided by them and the associated answers to the questions asked by them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Topic Number Selection</head><p>In this section, we will concentrate on how to select proper topic numbers to obtain generative model with acceptable performance on testing sets and enough iteration number in Algorithm 1 to prevent overfitting on training sets. In order to achieve this objective, we use the standard measure for probability model, perplexity, to estimate the performance of our model. We calculate the perplexity value for each subset on a hold-out testing set, which is a seque , a s nce of tuples , , s follow</p><formula xml:id="formula_3">perplexity ∑ ln , | | | | |</formula><p>Here the probability , | is calculated according to the parameters trained from training set by a straightforward calculation as:</p><formula xml:id="formula_4">, | | | |</formula><p>We test perplexity value for each subset on different settings of topic number and iteration numbers. The results are shown in Figure <ref type="figure">5</ref> and Figure <ref type="figure">6</ref>. Note that the lower perplexity value indicates better generalization ability on the hold-out testing set.</p><p>In the first set of experiments, we demonstrate the influence of iteration number of Gibbs sampling on the model generalization ability. We fix the topic number as 100 and change the iteration number from 1 to 1000 in experiment. From Figure <ref type="figure">5</ref>, we can see the perplexity values decreases dramatically for the first 10 iterations on 6 datasets. Additionally, while the iteration number keeps increasing, the perplexity starts to grow after 50 iterations, which indicates an overfitting on the training set. It is worthwhile mentioning that the absolute perplexity value of user-partitioned sets is larger than that of category-partitioned sets due to the larger content diversity in user-partitioned sets.</p><p>In Figure <ref type="figure">6</ref>, the perplexity values for different settings of topic number are plotted. For each topic number, we stop model training when the perplexity decrement between two consecutive iterations is less than 1. The perplexity decreases when the number of topics starts to increase. However, after a certain point, the perplexity values begin to increase on all 6 subsets. For example, the perplexity value reaches its minimum for USER-20 at the point of 40 topics. And for PETS, the variance of perplexity on the change of topic number is very small, which demonstrate that the topic in PETS is quite concentrated.</p><p>Based on the above experiments, we train the UQA model for 50 topics and set the stop condition in Algorithm 1 as the perplexity decrement between two consecutive iterations is less than 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Discovered Topic Analysis</head><p>In this section, we illustrate some top words and categories for the topics discovered by UQA model in the subset USER-10 and ELEC to judge the quality. Some top words and categories for sample topics are illustrated in Table <ref type="table">3</ref>. The example topics demonstrate two kinds of phenomena, general topic cross different categories and sub-topics within same category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USER-10:</head><p>From the sample topics shown in Table <ref type="table">3</ref>, we can see that the same topic may appear in different categories. Like Topic 20, it concentrates on taking photos and appears in three different categories, which have strong semantic correlation, namely DIY, Camera and Photography.</p><p>ELEC: Different from the topics discovered in user-partitioned sets, the sample topics demonstrate sub-topics in the same category. For example, topic 12 and topic 17 are both focused in category Consumer Electronics&gt;Home Theater, but they focus on two different aspects, video and audio respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Question Answerer Recommendation</head><p>In this section, we propose our approach for question answerer recommendation which incorporates topics discovered by UQA model with term-level matching methods. As described in Section 3, every question in cQA consists of three distinct parts, question title, question detail and question category. Based on this observation, we treat the questions as multi-field documents and choose BM25F <ref type="bibr" target="#b2">[3]</ref> as the foundation of our solution to question answerer recommendation problem since BM25F is the classical and formal model for multi-field documents retrieval. Similarly, we treat user-profiles of the users for BM25F as multi-field documents too, in which there are 8 fields, respectively the title/detail/category of questions asked by them, the title/detail/category of questions answered by them, answers provided by them and associated answers to the questions asked by them. Next, we will compare the performance of following methods on question answerer recommendation task: Question-based search on content (QST-BM25): We find similar questions for query question in training set by BM25F first, and then return the answerers of these similar questions as possible answerers for new questions. The score of each answerer is the sum of BM25F score of all similar questions the answerer answered. After that, the answerers are ranked according to their score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T able 3. Top words and categories for some discovered topic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User-profile-based search on content (USER-BM25):</head><p>In this approach, we construct user-profiles as multi-field documents, and then use BM25F to find the "similar" users as the possible question answerers for new questions.</p><p>In the above two approaches, we heuristically train the field weighting in BM25 by 2-fold cross-validation on training sets of 6 datasets by trying each field weight from 1 to 10 at step length 1.</p><p>Question-based search on topic (QST-TOPIC): Questions in training set and query question are represented by a distribution over topics discovered by UQA. We obtain the topic distribution of a question by merging the topic distributions of words in question and question category equally. Formally, we have</p><formula xml:id="formula_5">| 1 1 | | | | | | |</formula><p>Then we match a question to new question with probability by assuming the questions and topics have the same prior probability. After that, for each similar question , we assign its probability equally to its answerers. Finally, we recommend answerers according to the probability that they will answer the new question. Evaluation: Instead of labeling recommended answerers manually, we evaluate the above 6 approaches by treating the actual answerers for questions in testing data as the ground truth, which are the users who provide answers in real-world data. We calculate the prediction precision for the top 1, 2, 5, 10 and suggested answerers, where is the real number of answers for test questions. The evaluation results are shown in Table <ref type="table">4</ref>. The experimental results show that the combination of topic-level and term-level matching benefits the performance of question answerer recommendation. According to the t-test between QST-BM25 and QST-BM25-TOPIC, we can see that the improvement is greater on category-partitioned sets than it is on user-partitioned sets. Star marks in Table <ref type="table">4</ref> indicate statistically significant differences in performance with a 95% confidence. The relatively small improvement on user-partitioned data may be caused by the relatively more topics in user-partitioned sets since they contain more categories. And the relieved data sparseness problem in user-partitioned sets makes the term-level methods effective enough. Additionally, the best performance is achieved when is about 0.8 for QST-USER-TOPIC and is about 0.2 for QST-BM25-TOPIC. It shows that the topic and user weighting should not be very large. Figure <ref type="figure" target="#fig_6">7</ref> illustrates the influence of and on the performance of QST-USER-TOPIC and QST-BM25-TOPIC in USER-20 dataset. When tuning parameter , we fix 0.5. Note that in real cQA data, many questions only have few answerers, like only one or two answerers. For these questions, the precision is very low even the methods suggest correct question answerers. For instance, if a question only has one answer (which is very common in cQA data), the P@10 is only 0.1 even the top 10 suggested users are all reasonable and contain the correct one. Actually, the average answer number of questions in the whole set is about 6.7. Therefore, we choose P@1, P@2 and P@5 as the Table <ref type="table">4</ref>. Evaluation results for 6 datasets. Stars indicate statistically significant differences in performance with a 95% confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USER-20</head><p>USER-15 USER-10 P@1 P@2 P@5 P@10 P@n P@1 P@2 P@5 P@10 P@n P@1 P@2 P@5 P@10 P@n QST-BM25 PETS ELEC FINA P@1 P@2 P@5 P@10 P@n P@1 P@2 P@5 P@10 P@n P@1 P@2 P@5 P@10 P@n QST-BM25 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION &amp; FUTURE WORK</head><p>In this paper, we observe the low participation problem in cQA caused by inefficiency of finding questions which interests and is solvable by users. We try to relieve the burden of searching questions for users by recommending possible question answerers to new questions, which may raise the overall participation rate in QA community. In order to suggest reasonable answerers to new questions, we first try to discover latent topics in cQA, which can simultaneously discover topic distribution for words, categories and users in QA community. A novel generative model, namely UQA model, is proposed for the generation of content in cQA.</p><p>The main contributions of this paper are:</p><p>(1) The proposal and formulation of question answerer recommendation problem, which might tap on the user participation in cQA effectively.</p><p>(2) The proposal of a computable probabilistic generative model for user behavior. Based on which, we try several ways to recommend possible answerers for questions.</p><p>(3) The study of several methods' performance on question answerer recommendation. The extensive experimental results on the real world cQA data show that combining topic-level information with term-level similarity significantly improves the performance of term-level only methods. For future work, we may discover some other applications or extensions for UQA model. In cQA, some answers may be spam that they never help to solve the question. Thus, detecting low quality answers in cQA is very important. We could measure the topic variances between the topic of questions and the corresponding answers by using the topics discovered by UQA model to identify the quality of answers. UQA is a very general model in which no service-specific feature is included. Additionally, inspired by <ref type="bibr" target="#b29">[30]</ref>, we could take the temporal dimension of questions and answers into consideration. After this extension for UQA, we may find the interest change of users over time, and then we can suggest answerers for questions by estimating the current interests of users, which is more reasonable. Besides ranking combination between topic-level and term-level model, we may apply Language Model as the term-level model and combine them with probability in future experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. User participation in our crawled Yahoo! Answers corpus, where AnsQ denotes the number of questions answered by a user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Latent Dirichlet Allocation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. General Generative Model probability of overfitting training documents and enhance the ability of inferring topic distribution for new documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 4. User-Question-Answer Model 4.3 Parameter Estimation As shown in the above process, the parameters of UQA model can be summarized as follows. We could estimate , and from data directly, however, for the simplicity, we use fixed Dirichlet prior ( 50 , 0.05 and 50 ) in our experiments like many previous work [26, 28, 30]. Now, the UQA model leaves three sets of parameters for us to estimate, namely user-topic distributions , topic-word distribution and topic-category distribution . | ~ Dirichlet | ~ Dirichlet | ~ Dirichlet | ~ Multinomial | ~ Multinomial | ~ Multinomial</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 5. Perplexities for 6 datasets as the iteration number increases</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>-profile-based search on topic (USER-TOPIC): Users in training set and query question are represented by a distribution over topics discovered by UQA. Then we matching each user in training set against new questions by using similar method for question matching. QST-TOPIC + USER-TOPIC (QST-USER-TOPIC): we combine the results of QST-TOPIC and USER-TOPIC by linear + QST-USER-TOPIC (QST-BM25-TOPIC): combine the user ranking in QST-USER-TOPIC and parameter 0,1 . Formally, we QST-BM25 with 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. The influence of different settings of and on P@5 in USER-20 for QST-USER-TOPIC and QST-BM25-TOPIC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . Notations used in this paper</head><label>1</label><figDesc></figDesc><table><row><cell>SYMBOL</cell><cell cols="3">DESCRIPTION</cell><cell></cell></row><row><cell></cell><cell cols="3">number of topics</cell><cell></cell></row><row><cell></cell><cell cols="3">number of users</cell><cell></cell></row><row><cell></cell><cell cols="3">number of questions</cell><cell></cell></row><row><cell></cell><cell cols="3">number of answers</cell><cell></cell></row><row><cell></cell><cell cols="5">number of unique words</cell></row><row><cell></cell><cell cols="5">number of unique af cate le</cell><cell>gories</cell></row><row><cell>/ /</cell><cell cols="5">number of distinct words in question</cell><cell>or answer</cell></row><row><cell></cell><cell cols="3">or pr ile of user of</cell><cell></cell></row><row><cell>/ /</cell><cell cols="5">multinomial distribution over topics specific to que</cell><cell>s-</cell></row><row><cell></cell><cell cols="2">tion</cell><cell>or answer</cell><cell cols="2">or profile of user</cell></row><row><cell></cell><cell cols="5">multin mial distribution over words s o</cell><cell>pecific to topic</cell></row><row><cell></cell><cell cols="5">multinomial dis ution over categories specific to trib</cell></row><row><cell></cell><cell cols="2">topic</cell><cell></cell><cell></cell></row><row><cell>/ /</cell><cell cols="3">the topic of the</cell><cell>w</cell><cell>ord in question</cell><cell>or answer</cell></row><row><cell></cell><cell>or</cell><cell cols="2">profile of user</cell><cell></cell></row><row><cell>/ /</cell><cell cols="3">the category of the</cell><cell></cell><cell>wo d in question r</cell><cell>or answer</cell></row><row><cell></cell><cell></cell><cell cols="2">o ofile of user r pr</cell><cell></cell></row><row><cell>/ /</cell><cell cols="2">the</cell><cell cols="3">word in question</cell><cell>or answer</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 . Details of 6 datasets. In each cell the total number is followed by the numbers in testing set and training set respec- tively in parentheses separated by a slash.</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>Question. Number.</cell><cell cols="2">Answer. Number.</cell><cell>User Number.</cell></row><row><cell cols="2">USER-20 3532 (343/3180)</cell><cell cols="2">42739 (4591/38148)</cell><cell>426 (339/426)</cell></row><row><cell cols="2">USER-15 10470 (1196/9274)</cell><cell cols="3">115206 (14755/100451) 1657 (1372/1656)</cell></row><row><cell cols="5">USER-10 29645 (3131/26514) 267929 (32323/235606) 7804 (5833/7797)</cell></row><row><cell>PETS</cell><cell>5542 (599/4943)</cell><cell cols="2">45679 (4832/40847)</cell><cell>16145 (3408/14921)</cell></row><row><cell>ELEC</cell><cell>5467 (512/4955)</cell><cell cols="2">17384 (1540/15844)</cell><cell>11565 (1611/10697)</cell></row><row><cell>FINA</cell><cell>5965 (501/5464)</cell><cell>2558</cell><cell>269/23 ) 8 (2 319</cell><cell>13884 (2047/12935)</cell></row><row><cell cols="2">USER-20: Two subsets</cell><cell></cell><cell>and</cell><cell>, in which every</cell></row><row><cell>user in</cell><cell cols="4">have asked and answered not less than 20 times in</cell></row><row><cell cols="5">. The asker and at least one answerer of each question in</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>main metric to evaluate the performance of question answerer recommendation. Another important thing is that the data sparseness in training dataset also leads to the low prediction precision, which means the categories or words a user used in testing sets may never appear in training sets.</figDesc><table><row><cell></cell><cell>0.148</cell><cell>0.146</cell><cell>0.098</cell><cell>0.071</cell><cell>0.085</cell><cell>0.093</cell><cell>0.087</cell><cell>0.059</cell><cell>0.041</cell><cell>0.081</cell><cell>0.123</cell><cell>0.087</cell><cell>0.059</cell><cell>0.039</cell><cell>0.059</cell></row><row><cell>USER-BM25</cell><cell>0.030</cell><cell>0.021</cell><cell>0.023</cell><cell>0.019</cell><cell>0.022</cell><cell>0.080</cell><cell>0.060</cell><cell>0.046</cell><cell>0.032</cell><cell>0.055</cell><cell>0.089</cell><cell>0.688</cell><cell>0.506</cell><cell>0.036</cell><cell>0.056</cell></row><row><cell>QST-TOPIC</cell><cell>0.135</cell><cell>0. 143</cell><cell>0. 096</cell><cell>0. 071</cell><cell>0. 083</cell><cell>0.117</cell><cell>0.102</cell><cell>0.055</cell><cell>0.037</cell><cell>0.073</cell><cell>0.133</cell><cell>0.090</cell><cell>0.066</cell><cell>0.044</cell><cell>0.072</cell></row><row><cell>USER-TOPIC</cell><cell>0.055</cell><cell>0.050</cell><cell>0.052</cell><cell>0.048</cell><cell>0.051</cell><cell>0.085</cell><cell>0.069</cell><cell>0.041</cell><cell>0.024</cell><cell>0.056</cell><cell>0.051</cell><cell>0.037</cell><cell>0.019</cell><cell>0.012</cell><cell>0.027</cell></row><row><cell>QST-USER-TOPIC</cell><cell>0.135</cell><cell>0.154</cell><cell>0.098</cell><cell>0.071</cell><cell>0.088</cell><cell>0.117</cell><cell>0.102</cell><cell>0.056</cell><cell>0.037</cell><cell>0.073</cell><cell>0.137</cell><cell>0.085</cell><cell>0.065</cell><cell>0.043</cell><cell>0.070</cell></row><row><cell>QST-BM25-TOPIC</cell><cell>0.176*</cell><cell>0. 163*</cell><cell>0. 109*</cell><cell>0. 080*</cell><cell>0. 097*</cell><cell>0.126*</cell><cell>0.095*</cell><cell>0.067*</cell><cell>0.046*</cell><cell>0.083</cell><cell>0.153*</cell><cell>0.103*</cell><cell>0.068*</cell><cell>0.046*</cell><cell>0.084*</cell></row><row><cell>p-value</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&gt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell><cell>&lt;0.05</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://answers.yahoo.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://zhidao.baidu.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://qna.live.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank IBM China Research Lab for its continuous support to and cooperation with Shanghai Jiao Tong University. We would also like to express our gratitude to the data preparation work by Bohai Yang. Besides, we also appreciate the valuable suggestions from Yuanjie Liu, Dingyi Han and Jason Liu. In the end, we would like to thank the anonymous reviewers for their elaborate and helpful comments</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A. GIBBS SAMPLING DERIVATION FOR UQA</head><p>We first derivate the joint probability </p><p>Using the chain rule, we can obtain the conditional probability for topic conditioned on all other word, category and topic asn n er-profile lows: signme ts i us as fol</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Bae-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m">Modern Information Retrieval</title>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simple BM25 Extension to Multiple Weighted Fields</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM&apos;04</title>
		<meeting>of CIKM&apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extracting Semantic Relations from Query Logs</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Baeza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Tiberi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of KDD&apos;07</title>
		<meeting>of KDD&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Wisdom of Crowds: Why the Many Are Smarter Than the Few and How Collective Wisdom Shapes Business</title>
		<author>
			<persName><forename type="first">James</forename><surname>Surowiecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Economies, Societies and Nations, Little and Brown</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Framework to Predict the Quality of Answers with Non-Textual Features</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Jiwoon Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joon</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soyeon</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR&apos;06</title>
		<meeting>of SIGIR&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="228" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding Similar Questions in Large Question and Answer Archives</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiwoon Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joon</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM&apos;05</title>
		<meeting>of CIKM&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="84" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finding Semantically Similar Questions Based on Their Answers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiwoon Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joon</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR&apos;05</title>
		<meeting>of SIGIR&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="617" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A CDD-based Formal Model for Expert Finding</title>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongjing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM&apos;07</title>
		<meeting>of CIKM&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="881" to="884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recommending Questions Using the MDL-based Tree Cut Model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hsiao-Wuen</forename><surname>Hon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW&apos;08</title>
		<meeting>of WWW&apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bridging the lexical chasm: statistical approaches to answer-finding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR&apos;00</title>
		<meeting>of SIGIR&apos;00</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Question answering from frequently asked question files: Experiences with the faq finder system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Kulyukin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lytinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tomuro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schoenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">High performances question/answering</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR&apos;01</title>
		<meeting>of SIGIR&apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="366" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated question answering using question templates that cover the conceptual model of the database</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sneiders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NLDB&apos;02</title>
		<meeting>of NLDB&apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="235" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2004 question answering track</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the TREC&apos;04</title>
		<meeting>of the TREC&apos;04</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Formal models for expert finding in enterprise corpora</title>
		<author>
			<persName><forename type="first">Hleif</forename><surname>Hh Krisztian Balogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hmaarten</forename><surname>Azzopardih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rijkeh</forename><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR&apos;06</title>
		<meeting>of SIGIR&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Expertise identification using email communications</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Maglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM&apos;03</title>
		<meeting>of CIKM&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="528" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">P@noptic expert: Searching for experts not just for documents</title>
		<author>
			<persName><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Vercoustre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wilkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Ausweb&apos;01</title>
		<meeting>of Ausweb&apos;01</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph-based ranking algorithms for e-mail expertise analysis</title>
		<author>
			<persName><forename type="first">Hiris</forename><surname>Hh Byron Domh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Halex</forename><surname>Eironh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyi</forename><surname>Cozzih</surname></persName>
		</author>
		<author>
			<persName><surname>Zhangh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGMOD workshop</title>
		<meeting>of SIGMOD workshop</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="42" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Expertise browser: a quantitative approach to identifying expertise</title>
		<author>
			<persName><forename type="first">Audris</forename><surname>Mockus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hjames</surname></persName>
		</author>
		<author>
			<persName><surname>Herbslebh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICSE&apos;02</title>
		<meeting>of ICSE&apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="503" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Everyone knows something: Examining knowledge sharing on Yahoo Answers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bakshy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Ackerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW&apos;08</title>
		<meeting>of WWW&apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASIS</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SI-GIR&apos;99</title>
		<meeting>of SI-GIR&apos;99</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Latent Dirichlet Allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploring social annotations for the semantic web</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW&apos;06</title>
		<meeting>of WWW&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The author-topic model for authors and documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of UAI &apos;04</title>
		<meeting>of UAI &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finding scientific topics</title>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Academy of Sciences</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring social annotation for information retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW&apos;08</title>
		<meeting>of WWW&apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="715" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Explaining the Gibbs Sampler</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1992-08">Aug, 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Topic over Time: A Non-Markov Continuous-Time Model of Topical Trends</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGKDD&apos;06</title>
		<meeting>of SIGKDD&apos;06</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="424" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Identifying the influential Bloggers in a community</title>
		<author>
			<persName><forename type="first">N</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM&apos;08</title>
		<meeting>of WSDM&apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="207" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An unsupervised model for exploring hierarchical semantics from social annotation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISWC&apos;07</title>
		<meeting>of ISWC&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="680" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Finding High-Quality Content in Social Media</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM&apos;08</title>
		<meeting>of WSDM&apos;08</meeting>
		<imprint>
			<biblScope unit="page" from="183" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">DBpedia: A Nucleus for a Web of Open Data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ISWC&apos;07</title>
		<meeting>of ISWC&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Weakly-Supervised Discovery of Named Entities Using Web Search Queries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM&apos;07</title>
		<meeting>of CIKM&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="683" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Organizing and Searching the World Wide Web of Facts -Step Two: Harnessing the Wisdom of the Crowds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WWW&apos;07</title>
		<meeting>of WWW&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Discovering Authorities in Question Answer Communities by Using Link Analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jurczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM&apos;07</title>
		<meeting>of CIKM&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="919" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Gibbs sampling in the generative model of Latent Dirichlet Allocation</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Griffiths</surname></persName>
		</author>
		<ptr target="http://www-psych.stanford.edu/~gruffydd/cogsci02/lda.ps" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
