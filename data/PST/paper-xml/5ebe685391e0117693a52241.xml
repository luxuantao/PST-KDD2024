<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NAT: Noise-Aware Training for Robust Neural Sequence Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-05-14">14 May 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marcin</forename><surname>Namysl</surname></persName>
							<email>marcin.namysl@iais.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer IAIS</orgName>
								<address>
									<settlement>Sankt Augustin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Autonomous Intelligent Systems</orgName>
								<orgName type="department" key="dep2">Computer Science Institute VI</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sven</forename><surname>Behnke</surname></persName>
							<email>sven.behnke@iais.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer IAIS</orgName>
								<address>
									<settlement>Sankt Augustin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Autonomous Intelligent Systems</orgName>
								<orgName type="department" key="dep2">Computer Science Institute VI</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joachim</forename><surname>Köhler</surname></persName>
							<email>joachimkoehler@iais.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer IAIS</orgName>
								<address>
									<settlement>Sankt Augustin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NAT: Noise-Aware Training for Robust Neural Sequence Labeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-05-14">14 May 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2005.07162v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sequence labeling systems should perform reliably not only under ideal conditions but also with corrupted inputs-as these systems often process user-generated text or follow an errorprone upstream component. To this end, we formulate the noisy sequence labeling problem, where the input may undergo an unknown noising process and propose two Noise-Aware Training (NAT) objectives that improve robustness of sequence labeling performed on perturbed input: Our data augmentation method trains a neural model using a mixture of clean and noisy samples, whereas our stability training algorithm encourages the model to create a noise-invariant latent representation. We employ a vanilla noise model at training time. For evaluation, we use both the original data and its variants perturbed with real OCR errors and misspellings. Extensive experiments on English and German named entity recognition benchmarks confirmed that NAT consistently improved robustness of popular sequence labeling models, preserving accuracy on the original input. We make our code and data publicly available for the research community.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sequence labeling systems are generally trained on clean text, although in real-world scenarios, they often follow an error-prone upstream component, such as Optical Character Recognition (OCR; <ref type="bibr" target="#b34">Neudecker, 2016)</ref> or Automatic Speech Recognition (ASR; <ref type="bibr" target="#b35">Parada et al., 2011)</ref>. Sequence labeling is also often performed on user-generated text, which may contain spelling mistakes or typos <ref type="bibr" target="#b15">(Derczynski et al., 2013)</ref>. Errors introduced in an upstream task are propagated downstream, diminishing the performance of the end-to-end system <ref type="bibr" target="#b3">(Alex and Burns, 2014)</ref>. While humans can easily cope with typos, misspellings, and the complete omission of letters when reading <ref type="bibr">(Rawlinson,</ref>  : An example of a labeling error on a slightly perturbed sentence. Our noise-aware methods correctly predicted the location (LOC) label for the first word, as opposed to the standard approach, which misclassified it as an organization (ORG). We complement the example with a high-level idea of our noise-aware training, where the original sentence and its noisy variant are passed together through the system. The final loss is computed based on both sets of features, which improves robustness to the input perturbations.</p><p>2007), most Natural Language Processing (NLP) systems fail when processing corrupted or noisy text <ref type="bibr" target="#b6">(Belinkov and Bisk, 2018)</ref>. Although this problem is not new to NLP, only a few works addressed it explicitly <ref type="bibr" target="#b38">(Piktus et al., 2019;</ref><ref type="bibr" target="#b25">Karpukhin et al., 2019)</ref>. Other methods must rely on the noise that occurs naturally in the training data.</p><p>In this work, we are concerned with the performance difference of sequence labeling performed on clean and noisy input. Is it possible to narrow the gap between these two domains and design an approach that is transferable to different noise distributions at test time? Inspired by recent research in computer vision <ref type="bibr" target="#b51">(Zheng et al., 2016)</ref>, Neural Machine Translation (NMT; <ref type="bibr" target="#b12">Cheng et al., 2018)</ref>, and ASR <ref type="bibr" target="#b45">(Sperber et al., 2017)</ref>, we propose two Noise-Aware Training (NAT) objectives that improve the accuracy of sequence labeling performed on noisy input without reducing efficiency on the original data. Figure <ref type="figure">1</ref> illustrates the problem and our approach.</p><p>Our contributions are as follows:</p><p>• We formulate a noisy sequence labeling problem, where the input undergoes an unknown noising process ( §2.2), and we introduce a model to estimate the real error distribution ( §3.1). Moreover, we simulate real noisy input with a novel noise induction procedure ( §3.2).</p><p>• We propose a data augmentation algorithm ( §3.3) that directly induces noise in the input data to perform training of the neural model using a mixture of noisy and clean samples.</p><p>• We implement a stability training method <ref type="bibr" target="#b51">(Zheng et al., 2016)</ref>, adapted to the sequence labeling scenario, which explicitly addresses the noisy input data problem by encouraging the model to produce a noise-invariant latent representation ( §3.4).</p><p>• We evaluate our methods on real OCR errors and misspellings against state-of-the-art baseline models <ref type="bibr" target="#b37">(Peters et al., 2018;</ref><ref type="bibr" target="#b2">Akbik et al., 2018;</ref><ref type="bibr" target="#b16">Devlin et al., 2019)</ref> and demonstrate the effectiveness of our approach ( §4).</p><p>• To support future research in this area and to make our experiments reproducible, we make our code and data publicly available<ref type="foot" target="#foot_0">1</ref> .</p><p>2 Problem Definition</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Sequence Labeling</head><p>Figure <ref type="figure" target="#fig_1">2</ref> presents a typical architecture for the neural sequence labeling problem. We will refer to the sequence labeling system as F (x; θ), abbreviated as F (x)<ref type="foot" target="#foot_1">2</ref> , where x = (x 1 , . . . , x N ) is a tokenized input sentence of length N , and θ represents all learnable parameters of the system. F (x) takes x as input and outputs the probability distribution over the class labels y(x) as well as the final sequence of labels ŷ = (ŷ 1 , . . . , ŷN ).</p><p>Either a softmax model (Chiu and Nichols, 2016) or a Conditional Random Field (CRF; <ref type="bibr" target="#b29">Lample et al., 2016)</ref> can be used to model the output distribution over the class labels y(x) from the logits l(x), i.e., non-normalized predictions, and to output the final sequence of labels ŷ. As a labeled entity can span several consecutive tokens within a sentence, special tagging schemes are often employed for decoding, e.g., BIOES, where the Beginning, Inside, Outside, End-of-entity and Single-tag-entity subtags are also distinguished <ref type="bibr" target="#b39">(Ratinov and Roth, 2009)</ref>. This method introduces strong dependencies between subsequent labels, which are modeled explicitly by a CRF <ref type="bibr" target="#b28">(Lafferty et al., 2001</ref>) that produces the most likely sequence of labels. In the standard scenario ( §2.1), the original sentence x is fed as input to the sequence labeling system F (x). Token embeddings e(x) are retrieved from the corresponding look-up table and fed to the sequence labeling model f (x), which outputs latent feature vectors h(x). The latent vectors are then projected to the class logits l(x), which are used as input to the decoding model (softmax or CRF) that outputs the distribution over the class labels y(x) and the final sequence of labels ŷ. In a realworld scenario ( §2.2), the input sentence undergoes an unknown noising process Γ, and the perturbed sentence x is fed to F (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Noisy Neural Sequence Labeling</head><p>Similar to human readers, sequence labeling should perform reliably both in ideal and sub-optimal conditions. Unfortunately, this is rarely the case. User-generated text is a rich source of informal language containing misspellings, typos, or scrambled words <ref type="bibr" target="#b15">(Derczynski et al., 2013)</ref>. Noise can also be introduced in an upstream task, like OCR <ref type="bibr" target="#b3">(Alex and Burns, 2014)</ref> or ASR <ref type="bibr" target="#b10">(Chen et al., 2017)</ref>, causing the errors to be propagated downstream.</p><p>To include the noise present on the source side of F (x), we can modify its definition accordingly (Figure <ref type="figure" target="#fig_1">2</ref>). Let us assume that the input sentence x is additionally subjected to some unknown noising process Γ = P (x i |x i ), where x i is the original i-th token, and xi is its distorted equivalent. Let V be the vocabulary of tokens and Ṽ be a set of all finite character sequences over an alphabet Σ. Γ is known as the noisy channel matrix <ref type="bibr" target="#b9">(Brill and Moore, 2000)</ref> and can be constructed by estimating the probability P (x i |x i ) of each distorted token xi given the intended token x i for every x i ∈ V and xi ∈ Ṽ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Named Entity Recognition</head><p>We study the effectiveness of state-of-the-art Named Entity Recognition (NER) systems in handling imperfect input data. NER can be considered as a special case of the sequence labeling problem, where the goal is to locate all named entity mentions in unstructured text and to classify them into pre-defined categories, e.g., person names, organizations, and locations <ref type="bibr" target="#b48">(Tjong Kim Sang and De Meulder, 2003)</ref>. NER systems are often trained on the clean text. Consequently, they exhibit degraded performance in real-world scenarios where the transcriptions are produced by the previous upstream component, such as OCR or ASR ( §2.2), which results in a detrimental mismatch between the training and the test conditions. Our goal is to improve the robustness of sequence labeling performed on data from noisy sources, without deteriorating performance on the original data. We assume that the source sequence of tokens x may contain errors. However, the noising process is generally label-preserving, i.e., the level of noise is not significant enough to affect the corresponding labels<ref type="foot" target="#foot_2">3</ref> . It follows that the noisy token xi inherits the ground-truth label y i from the underlying original token x i .</p><p>3 Noise-Aware Training</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Noise Model</head><p>To model the noise, we use the character-level noisy channel matrix Γ, which we will refer to as the character confusion matrix ( §2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural noise</head><p>We can estimate the natural error distribution by calculating the alignments between the pairs (x, x) ∈ P of noisy and clean sentences using the Levenshtein distance metric <ref type="bibr" target="#b30">(Levenshtein, 1966)</ref>, where P is a corpus of paired noisy and manually corrected sentences ( §2.2). The allowed edit operations include insertions, deletions, and substitutions of characters. We can model insertions and deletions by introducing an additional symbol ε into the character confusion matrix. The probability of insertion and deletion can then be formulated as P ins (c|ε) and P del (ε|c), where c is a character to be inserted or deleted, respectively. Synthetic noise P is usually laborious to obtain. Moreover, the exact modeling of noise might be impractical, and it is often difficult to accurately estimate the exact noise distribution to be encountered at test time. Such distributions may depend on, e.g., the OCR engine used to digitize the documents. Therefore, we keep the estimated natural error distribution for evaluation and use a simplified synthetic error model for training. We assume that all types of edit operations are equally likely:</p><formula xml:id="formula_0">c ∈ Σ\{ε} P ins (c|ε) = P del (ε|c) = c ∈ Σ\{c, ε} P subst (c|c),</formula><p>where c and c are the original and the perturbed characters, respectively. Moreover, P ins and P subst are uniform over the set of allowed insertion and substitution candidates, respectively. We use the hyper-parameter η to control the amount of noise to be induced with this method<ref type="foot" target="#foot_3">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Noise Induction</head><p>Ideally, we would use the noisy sentences annotated with named entity labels for training our sequence labeling models. Unfortunately, such data is scarce. On the other hand, labeled clean text corpora are widely available <ref type="bibr" target="#b48">(Tjong Kim Sang and De Meulder, 2003;</ref><ref type="bibr" target="#b7">Benikova et al., 2014)</ref>. Hence, we propose to use the standard NER corpora and to induce noise into the input tokens during training synthetically.</p><p>In contrast to the image domain, which is continuous, the text domain is discrete, and we cannot directly apply continuous perturbations for written language. Although some works applied distortions at the level of embeddings <ref type="bibr" target="#b32">(Miyato et al., 2017;</ref><ref type="bibr" target="#b50">Yasunaga et al., 2018;</ref><ref type="bibr" target="#b5">Bekoulis et al., 2018)</ref>, we do not have a good intuition how it changes the meaning of the underlying textual input. Instead, we apply our noise induction procedure to generate distorted copies of the input. For every input sentence x, we independently perturb each token x i = (c 1 , . . . , c K ), where K is the length of x i , with the following procedure (Figure <ref type="figure" target="#fig_2">3</ref>):</p><p>(1) We insert the ε symbol before the first and after every character of x i to get an extended token x i = (ε, c 1 , ε, . . . , ε, c K , ε).</p><p>(2) For every character c k of x i , we sample the replacement character c k from the corresponding probability distribution P (c k |c k ), which can be obtained by taking a row of the character confusion matrix that corresponds to c k .</p><p>As a result, we get a noisy version of the extended input token x i .</p><p>(3) We remove all ε symbols from x i and collapse the remaining characters to obtain a noisy token xi . Three examples correspond to insertion, deletion, and substitution errors. x i , x i , x i , and xi are the original, extended, extended noisy, and noisy tokens, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Augmentation Method</head><p>We can improve robustness to noise at test time by introducing various forms of artificial noise during training. We distinct regularization methods like dropout <ref type="bibr" target="#b46">(Srivastava et al., 2014)</ref> and task-specific data augmentation that transforms the data to resemble noisy input. The latter technique was successfully applied in other domains, including computer vision <ref type="bibr" target="#b27">(Krizhevsky et al., 2012)</ref> and speech recognition <ref type="bibr" target="#b45">(Sperber et al., 2017)</ref>.</p><p>During training, we artificially induce noise into the original sentences using the algorithm described in §3.2 and train our models using a mixture of clean and noisy sentences. Let L 0 (x, y; θ) be the standard training objective for the sequence labeling problem, where x is the input sentence, y is the corresponding ground-truth sequence of labels, and θ represents the parameters of F (x). We define our composite loss function as follows:</p><formula xml:id="formula_1">L augm (x, x, y; θ) = L 0 (x, y; θ) + αL 0 (x, y; θ),</formula><p>where x is the perturbed sentence, and α is a weight of the noisy loss component. L augm is a weighted sum of standard losses calculated using clean and noisy sentences. Intuitively, the model that would optimize L augm should be more robust to imperfect input data, retaining the ability to perform well on clean input. Figure <ref type="figure">4a</ref> presents a schematic visualization of our data augmentation approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Stability Training Method</head><p>Zheng et al. ( <ref type="formula">2016</ref>) pointed out the output instability issues of deep neural networks. They proposed a training method to stabilize deep networks against small input perturbations and applied it to the tasks of near-duplicate image detection, similar-image ranking, and image classification. Inspired by their idea, we adapt the stability training method to the natural language scenario.</p><p>Our goal is to stabilize the outputs y(x) of a sequence labeling system against small input perturbations, which can be thought of as flattening y(x) in a close neighborhood of any input sentence x. When a perturbed copy x is close to x, then y(x) should also be close to y(x). Given the standard training objective L 0 (x, y; θ), the original input sentence x, its perturbed copy x and the sequence of ground-truth labels y, we can define the stability training objective L stabil as follows:</p><formula xml:id="formula_2">L stabil (x, x, y; θ) = L 0 (x, y; θ) + αL sim (x, x; θ), L sim (x, x; θ) = D y(x), y(x) ,</formula><p>where L sim encourages the similarity of the model outputs for both x and x, D is a task-specific feature distance measure, and α balances the strength of the similarity objective. Let R(x) and Q(x) be the discrete probability distributions obtained by calculating the softmax function over the logits l(x) for x and x, respectively:</p><formula xml:id="formula_3">R(x) = P (y|x) = sof tmax l(x) , Q(x) = P (y| x) = sof tmax l(x) .</formula><p>We model D as Kullback-Leibler divergence (D KL ), which measures the correspondence between the likelihood of the original and the perturbed input: Figure <ref type="figure">4</ref>: Schema of our auxiliary training objectives.</p><formula xml:id="formula_4">L sim (x, x; θ) = i D KL R(x i ) Q(x i ) , D KL R(x) Q(x) = j P (y j |x) log P (y j |x) P (y j | x) , ( ) Γ  0  ̃ ( ) ( ) ̃<label>(</label></formula><p>x, x are the original and the perturbed inputs, respectively, that are fed to the sequence labeling system F (x). Γ represents a noising process. y(x) and y(x) are the output distributions over the entity classes for x and x, respectively. L 0 is the standard training objective. L augm combines L 0 computed on both outputs from F (x). L stabil fuses L 0 calculated on the original input with the similarity objective L sim .</p><p>where i, j are the token, and the class label indices, respectively. Figure <ref type="figure">4b</ref> summarizes the main idea of our stability training method.</p><p>A critical difference between the data augmentation and the stability training method is that the latter does not use noisy samples for the original task, but only for the stability objective<ref type="foot" target="#foot_4">5</ref> . Furthermore, both methods need perturbed copies of the input samples, which results in longer training time but could be ameliorated by fine-tuning the existing model for a few epochs<ref type="foot" target="#foot_5">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>Model architecture We used a BiLSTM-CRF architecture <ref type="bibr" target="#b24">(Huang et al., 2015)</ref> with a single Bidirectional Long-Short Term Memory (BiLSTM) layer and 256 hidden units in both directions for f (x) in all experiments. We considered four different text representations e(x), which were used to achieve state-of-the-art results on the studied data set and should also be able to handle misspelled text and out-of-vocabulary (OOV) tokens:</p><p>• FLAIR <ref type="bibr" target="#b2">(Akbik et al., 2018</ref>) learns a Bidi-rectional Language Model (BiLM) using an LSTM network to represent any sequence of characters. We used settings recommended by the authors and combined FLAIR with GloVe <ref type="bibr" target="#b36">(Pennington et al., 2014</ref>; FLAIR + GloVe) for English and Wikipedia FastText embeddings <ref type="bibr" target="#b8">(Bojanowski et al., 2017</ref>; FLAIR + Wiki) for German.</p><p>• BERT <ref type="bibr" target="#b16">(Devlin et al., 2019)</ref> employs a Transformer encoder to learn a BiLM from large unlabeled text corpora and sub-word units to represent textual tokens. We use the BERT BASE model in our experiments.</p><p>• ELMo <ref type="bibr" target="#b37">(Peters et al., 2018)</ref> utilizes a linear combination of hidden state vectors derived from a BiLSTM word language model trained on a large text corpus.</p><p>• Glove/Wiki + Char is a combination of pretrained word embeddings (GloVe for English and Wikipedia FastText for German) and randomly initialized character embeddings <ref type="bibr" target="#b29">(Lample et al., 2016)</ref>.</p><p>Training We trained the sequence labeling model f (x) and the final CRF decoding layer on top of the pre-trained embedding vectors e(x), which were fixed during training, except for the character embeddings (Figure <ref type="figure" target="#fig_1">2</ref>). We used a mixture of the original data and its perturbed copies generated from the synthetic noise distribution ( §3.1) with our noise induction procedure ( §3.2). We kept most of the hyper-parameters consistent with Akbik et al.</p><p>(2018)<ref type="foot" target="#foot_6">7</ref> . We trained our models for at most 100 epochs and used early stopping based on the development set performance, measured as an average F1 score of clean and noisy samples. Furthermore, we used the development sets of each benchmark data set for validation only and not for training.</p><p>Performance measures We measured the entitylevel micro average F1 score on the test set to compare the results of different models. We evaluated on both the original and the perturbed data using various natural error distributions. We induced OCR errors based on the character confusion matrix Γ ( §3.2) that was gathered on a large document corpus <ref type="bibr" target="#b33">(Namysl and Konya, 2019)</ref> using the Tesseract OCR engine <ref type="bibr" target="#b44">(Smith, 2007)</ref>. Moreover, we employed two sets of misspellings released by <ref type="bibr" target="#b6">Belinkov and Bisk (2018)</ref> and <ref type="bibr" target="#b38">Piktus et al. (2019)</ref>.</p><p>Following the authors, we replaced every original token with the corresponding misspelled variant, sampling uniformly among available replacement candidates. We present the estimated error rates of text that is produced with these noise induction procedures in Table <ref type="table" target="#tab_6">5</ref> in the appendix. As the evaluation with noisy data leads to some variance in the final scores, we repeated all experiments five times and reported mean and standard deviation.</p><p>Implementation We implemented our models using the FLAIR framework <ref type="bibr" target="#b1">(Akbik et al., 2019)</ref> <ref type="foot" target="#foot_7">8</ref> . We extended their sequence labeling model by integrating our auxiliary training objectives ( §3.3, §3.4). Nonetheless, our approach is universal and can be implemented in any other sequence labeling framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sequence Labeling on Noisy Data</head><p>To validate our approach, we trained the baseline models with and without our auxiliary loss objectives ( §3.3, §3.4)<ref type="foot" target="#foot_8">9</ref> . We used the CoNLL 2003 <ref type="bibr" target="#b48">(Tjong Kim Sang and De Meulder, 2003)</ref> and the GermEval 2014 <ref type="bibr" target="#b7">(Benikova et al., 2014)</ref> data sets in this setup<ref type="foot" target="#foot_9">10</ref> . The baselines utilized GloVe vectors coupled with FLAIR and character embeddings (FLAIR + GloVe, GloVe + Char), BERT, and ELMo embeddings for English. For German, we employed Wikipedia FastText vectors paired with FLAIR and character embeddings (FLAIR + Wiki, Wiki + Char) <ref type="foot" target="#foot_10">11</ref> . We used a label-preserving training setup (α = 1.0, η train = 10%).</p><p>Table <ref type="table" target="#tab_0">1</ref> presents the results of this experiment<ref type="foot" target="#foot_11">12</ref> . We found that our auxiliary training objectives boosted accuracy on noisy input data for all baseline models and both languages. At the same time, they preserved accuracy for the original input. The data augmentation objective seemed to perform slightly better than the stability objective. However, the chosen hyper-parameter values were rather ar-bitrary, as our goal was to prove the utility and the flexibility of both objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sensitivity Analysis</head><p>We evaluated the impact of our hyper-parameters on the sequence labeling accuracy using the English CoNLL 2003 data set. We trained multiple models with different amounts of noise η train and different weighting factors α. We chose the FLAIR + GloVe model as our baseline because it achieved the best results in the preliminary analysis ( §4.2) and showed good performance, which enabled us to perform extensive experiments.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> summarizes the results of the sensitivity experiment. The models trained with our auxiliary objectives mostly preserved or even improved accuracy on the original data compared to the baseline model (α = 0). Moreover, they significantly outperformed the baseline on data perturbed with natural noise. The best accuracy was achieved for η train from 10 to 30%, which roughly corresponds to the label-preserving noise range. Similar to <ref type="bibr" target="#b23">Heigold et al. (2018)</ref> and <ref type="bibr" target="#b11">Cheng et al. (2019)</ref>, we conclude that a non-zero noise level induced during training (η train &gt; 0) always yields improvements on noisy input data when compared with the models trained exclusively on clean data. The best choice of α was in the range from 0.5 to 2.0. α = 5.0 exhibited lower performance on the original data. Moreover, the models trained on the real error distribution demonstrated at most slightly better performance, which indicates that the exact noise distribution does not necessarily have to be known at training time<ref type="foot" target="#foot_12">13</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Error Analysis</head><p>To quantify improvements provided by our approach, we measured sequence labeling accuracy on the subsets of data with different levels of perturbation, i.e., we divided input tokens based on edit distance to their clean counterparts. Moreover, we partitioned the data by named entity class to assess the impact of noise on recognition of different entity types. For this experiment, we used both the test and the development parts of the English CoNLL 2003 data set and induced OCR errors with our noising procedure.</p><p>Figure <ref type="figure" target="#fig_6">6</ref> presents the results for the baseline and the proposed methods. It can be seen that our ap-  proach achieved significant error reduction across all perturbation levels and all entity types. Moreover, by narrowing down the analysis to perturbed tokens, we discovered that the baseline model was particularly sensitive to noisy tokens from the LOC and the MISC categories. Our approach considerably reduced this negative effect. Furthermore, as the stability training worked slightly better on the LOC class and the data augmentation was more accurate on the ORG type, we argue that both methods could be combined to enhance overall sequence labeling accuracy further. Note that even if the particular token was not perturbed, its context could be noisy, which would explain the fact that our approach provided improvements even for tokens without perturbations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Improving robustness has been receiving increasing attention in the NLP community. The most relevant research was conducted in the NMT domain.</p><p>Noise-additive data augmentation A natural strategy to improve robustness to noise is to augment the training data with samples perturbed using a similar noise model. <ref type="bibr" target="#b23">Heigold et al. (2018)</ref>  </p><formula xml:id="formula_5">LD = 0 LD = 1 LD = 2 LD = 3 LD 4</formula><p>Levenshtein Distance (LD) value.  at the maximum rate, only a subset of tokens is perturbed (20-50%, depending on the language). In contrast, we used a confusion matrix, which is better suited to model statistical error distribution and can be applied to all tokens, not only those present in the corresponding look-up tables.</p><p>Robust representations Another method to improve robustness is to design a representation that is less sensitive to noisy input. <ref type="bibr" target="#b51">Zheng et al. (2016)</ref> presented a general method to stabilize model predictions against small input distortions. <ref type="bibr" target="#b12">Cheng et al. (2018)</ref> continued their work and developed the adversarial stability training method for NMT by adding a discriminator term to the objective func-tion. They combined data augmentation and stability objectives, while we evaluated both methods separately and provided evaluation results on natural noise distribution. <ref type="bibr" target="#b38">Piktus et al. (2019)</ref> learned representation that embeds misspelled words close to their correct variants. Their Misspelling Oblivious Embeddings (MOE) model jointly optimizes two loss functions, each of which iterates over a separate data set (a corpus of text and a set of misspelling/correction pairs) during training. In contrast, our method does not depend on any additional resources and uses a simplified error distribution during training.</p><p>Adversarial learning Adversarial attacks seek to mislead the neural models by feeding them with adversarial examples <ref type="bibr" target="#b47">(Szegedy et al., 2014)</ref>. In a white-box attack scenario <ref type="bibr" target="#b22">(Goodfellow et al., 2015;</ref><ref type="bibr" target="#b18">Ebrahimi et al., 2018)</ref> we assume that the attacker has access to the model parameters, in contrast to the black-box scenario <ref type="bibr" target="#b4">(Alzantot et al., 2018;</ref><ref type="bibr" target="#b21">Gao et al., 2018)</ref>, where the attacker can only sample model predictions on given examples. Adversarial training <ref type="bibr" target="#b32">(Miyato et al., 2017;</ref><ref type="bibr" target="#b50">Yasunaga et al., 2018)</ref>, on the other hand, aims to improve the robustness of the neural models by utilizing adversarial examples during training.</p><p>The impact of noisy input data In the context of ASR, <ref type="bibr" target="#b35">Parada et al. (2011)</ref> observed that named entities are often OOV tokens, and therefore they cause more recognition errors. In the document processing field, <ref type="bibr" target="#b3">Alex and Burns (2014)</ref> studied NER performed on several digitized historical text collections and showed that OCR errors have a significant impact on the accuracy of the downstream task. <ref type="bibr" target="#b33">Namysl and Konya (2019)</ref> examined the efficiency of modern OCR engines and showed that although the OCR technology was more advanced than several years ago when many historical archives were digitized <ref type="bibr" target="#b26">(Kim and Cassidy, 2015;</ref><ref type="bibr" target="#b34">Neudecker, 2016)</ref>, the most widely used engines still had difficulties with non-standard or lower quality input.</p><p>Spelling-and post-OCR correction. A natural method of handling erroneous text is to correct it before feeding it to the downstream task. Most popular post-correction techniques include correction candidates ranking <ref type="bibr" target="#b19">(Fivez et al., 2017;</ref><ref type="bibr" target="#b20">Flor et al., 2019)</ref>, noisy channel modeling <ref type="bibr" target="#b9">(Brill and Moore, 2000;</ref><ref type="bibr">Duan and Hsu, 2011)</ref>, voting <ref type="bibr" target="#b49">(Wemhoener et al., 2013)</ref>, sequence to sequence models <ref type="bibr" target="#b0">(Afli et al., 2016;</ref><ref type="bibr" target="#b42">Schmaltz et al., 2017)</ref> and hybrid systems <ref type="bibr" target="#b43">(Schulz and Kuhn, 2017)</ref>.</p><p>In this paper, we have taken a different approach and attempted to make our models robust without relying on prior error correction, which, in case of OCR errors, is still far from being solved <ref type="bibr" target="#b13">(Chiron et al., 2017;</ref><ref type="bibr" target="#b41">Rigaud et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we investigated the difference in accuracy between sequence labeling performed on clean and noisy text ( §2.3). We formulated the noisy sequence labeling problem ( §2.2) and introduced a model that can be used to estimate the real noise distribution ( §3.1). We developed the noise induction procedure that simulates the real noisy input ( §3.2). We proposed two noise-aware training methods that boost sequence labeling accuracy on the perturbed text: (i) Our data augmentation approach uses a mixture of clean and noisy examples during training to make the model resistant to erroneous input ( §3.3). (ii) Our stability training algorithm encourages output similarity for the original and the perturbed input, which helps the model to build a noise invariant latent representation ( §3.4). Our experiments confirmed that NAT consistently improved efficiency of popular sequence labeling models on data perturbed with different error distributions, preserving accuracy on the original input ( §4). Moreover, we avoided expensive re-training of embeddings on noisy data sources by employing existing text representations. We conclude that NAT makes existing models applicable beyond the idealized scenarios. It may support an automatic correction method that uses recognized entity types to narrow the list of feasible correction candidates. Another application is data anonymization <ref type="bibr" target="#b31">(Mamede et al., 2016)</ref>.</p><p>Future work will involve improvements in the proposed noise model to study the importance of fidelity to real-world error patterns. Moreover, we plan to evaluate NAT on other real noise distributions (e.g., from ASR) and other sequence labeling tasks to support our claims further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Noise Model -Supplementary Materials</head><p>In this section, we present the extended description of our vanilla noise model introduced in §3.1. Let P edit = η/3 be the probability of performing a single character edit operation (insertion, deletion, or substitution) that replaces the source character c with a noisy character c, where c = c. Equation (1) defines the vanilla error distribution, which we use at training time:</p><formula xml:id="formula_6">P (c|c) =                        P edit |Σ\{ε}| , if c = ε and c = ε. 1 − P edit , if c = ε and c = ε. P edit |Σ\{c, ε}| , if c = ε and c = c. P edit , if c = ε and c = ε. 1−2P edit , if c = ε and c = c. (<label>1a</label></formula><formula xml:id="formula_7">) (1b) (1c) (1d) (1e)</formula><p>It consists of the following components:</p><p>(a) The insertion probability P ins (c|ε) in eq. ( <ref type="formula" target="#formula_6">1a</ref>).</p><p>It describes how likely it is to insert a nonempty character c = ε and it is uniform over the set of all characters from the alphabet Σ, except the ε symbol.</p><p>(b) The keep ε probability P keep (ε|ε) in eq. ( <ref type="formula" target="#formula_6">1b</ref>).</p><p>(c) The substitution probability P subst (c|c) in eq. ( <ref type="formula" target="#formula_6">1c</ref>). It is uniform over the set of all characters from the alphabet Σ, except the source character c and the ε symbol.</p><p>(d) The deletion probability P del (ε|c) in eq. ( <ref type="formula" target="#formula_6">1d</ref>).</p><p>(e) The keep probability P keep (c|c) in eq. (1e).</p><p>Equations ( <ref type="formula" target="#formula_6">1a</ref>) and (1b) correspond to the row in the character confusion matrix Γ, where c = ε and form a valid probability distribution:</p><formula xml:id="formula_8">P keep (ε|ε) + c ∈ Σ\{ε} P ins (c|c) = 1.</formula><p>Similarly, eqs. (1c) to (1e) correspond to the rows in the character confusion matrix Γ, where c ∈ Σ\{ε}, and are also valid probability distributions:</p><formula xml:id="formula_9">P del (ε|c) + P keep (c|c) + c ∈ Σ\{c, ε} P subst (c|c) = 1</formula><p>Finally, for comparison, we present visualizations of the confusion matrices used in our vanilla (Figure <ref type="figure" target="#fig_8">7a</ref>) and OCR error models (Figure <ref type="figure" target="#fig_8">7b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Sensitivity Analysis</head><p>In this section, we present the extended version of our sensitivity study ( §4.3). Figure <ref type="figure">8</ref> summarizes the results on the synthetic data distribution with various test-and training-time noise levels (η test and η train , respectively) and weighting factors α. We noticed a similar trend as in our initial analysis. As the level of noise η test increases, the overall accuracy decreases, but this trend is less pronounced for α = 0. At the same time, the gap between the models trained with and without our auxiliary objectives becomes larger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Qualitative Analysis</head><p>In this section, we compared the outputs generated by the baseline models trained with and without our auxiliary training objectives (Table <ref type="table" target="#tab_4">2</ref>). We found that the NAT method improved robustness to capitalization errors (the first and the fourth row in Table <ref type="table" target="#tab_4">2a</ref>) as well as to substitutions (the second, the third and the fifth row in Table <ref type="table" target="#tab_4">2a</ref> and the first, the second, the fourth and the fifth row in Table <ref type="table" target="#tab_4">2b</ref>), deletions (the fifth row in Table <ref type="table" target="#tab_4">2a</ref>) and insertions of characters (the third and the fifth row in Table <ref type="table" target="#tab_4">2b</ref>). Moreover, it better recognized the semantics of the sentence in the third row of Table <ref type="table" target="#tab_4">2a</ref>, where the location name was creatively rewritten (Brazland instead of Brazil).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Hyper-parameters</head><p>We present the detailed hyper-parameters of the sequence labeling model f (x) used in our experiments ( §4). Note that dropout was applied both before and after the LSTM layer (Table <ref type="table" target="#tab_2">3</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Data Set Statistics and Estimated Error Rates</head><p>In this section, we present the detailed statistics of the data sets used in our NER experiments (      The vanilla noise model assigns equal probability to all substitution errors, while the OCR error model is biased towards substitutions of characters with similar shapes like "I"→"l", "$"→"5", "O"→"0" or ","→".". Moreover, the vanilla model assumes that the deletion of a character c is as likely as the sum of substitution probabilities with all non-empty symbols: P del (ε|c) = c ∈ Σ\{ε} P subst (c|c).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure1: An example of a labeling error on a slightly perturbed sentence. Our noise-aware methods correctly predicted the location (LOC) label for the first word, as opposed to the standard approach, which misclassified it as an organization (ORG). We complement the example with a high-level idea of our noise-aware training, where the original sentence and its noisy variant are passed together through the system. The final loss is computed based on both sets of features, which improves robustness to the input perturbations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Neural sequence labeling architecture. In the standard scenario ( §2.1), the original sentence x is fed as input to the sequence labeling system F (x). Token embeddings e(x) are retrieved from the corresponding look-up table and fed to the sequence labeling model f (x), which outputs latent feature vectors h(x). The latent vectors are then projected to the class logits l(x), which are used as input to the decoding model (softmax or CRF) that outputs the distribution over the class labels y(x) and the final sequence of labels ŷ. In a realworld scenario ( §2.2), the input sentence undergoes an unknown noising process Γ, and the perturbed sentence x is fed to F (x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of our noise induction procedure.Three examples correspond to insertion, deletion, and substitution errors. x i , x i , x i , and xi are the original, extended, extended noisy, and noisy tokens, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>a) Data augmentation training objective Laugm. Stability training objective L stabil .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Sensitivity analysis performed on the English CoNLL 2003 test set ( §4.3). Each figure presents the results of models trained using one of our auxiliary training objectives on either original data or its variant perturbed with OCR errors. The bar marked as "OCR" represents a model trained using the OCR noise distribution. Other bars correspond to models trained using synthetic noise distribution and different hyper-parameters (α, η train ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Divided by the entity class (clean tokens). Divided by the entity class (perturbed tokens).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: Error analysis results on the English CoNLL 2003 data set with OCR noise. We presented the results of the FLAIR + GloVe model trained with the standard and the proposed objectives. The data was divided into the subsets based on the edit distance of a token to its original counterpart and its named entity class. The latter group was further partitioned into the clean and the perturbed tokens. The error rate is the percentage of tokens with misrecognized entity class labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>" # $ % &amp; ' ( ) * + , -. / 0 1 2 3 4 5 6 7 8 9 : ;= ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ]a b c d e f g h i j k l m n o p q r s t u v w x y Vanilla error distribution used at training time (η = 20%). " $ % &amp; ' ( ) * + , -. / 0 1 2 3 4 5 6 7 8 9 : ;= ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ]a b c d e f g h i j k l m n o p q r s t u v w x Real error distribution estimated from a large document corpus using the Tesseract OCR engine.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Confusion matrices for the vanilla and the OCR error distributions. Each cell represents P (c|c).The rows correspond to the original characters c and the columns represent the perturbed characters c. In this example, we include all symbols from the alphabet of the English CoNLL 2003 data set. The vanilla noise model assigns equal probability to all substitution errors, while the OCR error model is biased towards substitutions of characters with similar shapes like "I"→"l", "$"→"5", "O"→"0" or ","→".". Moreover, the vanilla model assumes that the deletion of a character c is as likely as the sum of substitution probabilities with all non-empty symbols: P del (ε|c) = c ∈ Σ\{ε} P subst (c|c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Evaluation results on the CoNLL 2003 and the GermEval 2014 test sets. We report results on the original data, as well as on its noisy copies with OCR errors and two types of misspellings released byBelinkov and  Bisk (2018)  </figDesc><table><row><cell>Data set</cell><cell cols="3">Model Train loss Original data</cell><cell>OCR errors</cell><cell>Misspellings  †</cell><cell>Misspellings  ‡</cell></row><row><cell></cell><cell>FLAIR + GloVe</cell><cell>L0 Laugm L stabil</cell><cell cols="2">92.05 92.56 (+0.51) 84.79±0.23 (+8.35) 76.44±0.45 91.99 (-0.06) 84.39±0.37 (+7.95)</cell><cell>75.09±0.48 83.57±0.43 (+8.48) 82.43±0.23 (+7.34)</cell><cell>87.57±0.10 90.50±0.08 (+2.93) 90.19±0.14 (+2.62)</cell></row><row><cell></cell><cell></cell><cell>L0</cell><cell>90.91</cell><cell>68.23±0.39</cell><cell>65.65±0.31</cell><cell>85.07±0.15</cell></row><row><cell></cell><cell>BERT</cell><cell>Laugm</cell><cell>90.84 (-0.07)</cell><cell cols="2">79.34±0.32 (+11.11) 75.44±0.28 (+9.79)</cell><cell>86.21±0.24 (+1.14)</cell></row><row><cell>English</cell><cell></cell><cell>L stabil</cell><cell cols="2">90.95 (+0.04) 78.22±0.17 (+9.99)</cell><cell>73.46±0.34 (+7.81)</cell><cell>86.52±0.12 (+1.45)</cell></row><row><cell>CoNLL 2003</cell><cell>ELMo</cell><cell>L0 Laugm</cell><cell>92.16 91.85 (-0.31)</cell><cell cols="3">72.90±0.50 84.09±0.18 (+11.19) 82.33±0.40 (+11.34) 89.50±0.16 (+0.91) 70.99±0.17 88.59±0.19</cell></row><row><cell></cell><cell></cell><cell>L stabil</cell><cell>91.78 (-0.38)</cell><cell cols="3">83.86±0.11 (+10.96) 81.47±0.29 (+10.48) 89.49±0.15 (+0.90)</cell></row><row><cell></cell><cell>GloVe + Char</cell><cell>L0 Laugm L stabil</cell><cell cols="2">90.26 90.83 (+0.57) 81.09±0.47 (+9.94) 71.15±0.51 90.21 (-0.05) 80.33±0.29 (+9.18)</cell><cell>70.91±0.39 79.47±0.24 (+8.56) 78.07±0.23 (+7.16)</cell><cell>87.14±0.07 88.82±0.06 (+1.68) 88.47±0.13 (+1.33)</cell></row><row><cell>German</cell><cell>FLAIR + Wiki</cell><cell>L0 Laugm L stabil</cell><cell cols="2">86.13 86.46 (+0.33) 75.90±0.63 (+8.97) 66.93±0.49 86.33 (+0.20) 75.08±0.29 (+8.15)</cell><cell>78.06±0.13 83.23±0.14 (+5.17) 82.60±0.21 (+4.54)</cell><cell>80.72±0.23 84.01±0.27 (+3.29) 84.12±0.26 (+3.40)</cell></row><row><cell>CoNLL 2003</cell><cell>Wiki + Char</cell><cell>L0 Laugm L stabil</cell><cell cols="2">82.20 82.62 (+0.42) 67.67±0.75 (+8.52) 59.15±0.76 82.18 (-0.02) 67.72±0.63 (+8.57)</cell><cell>75.27±0.31 78.48±0.24 (+3.21) 77.59±0.12 (+2.32)</cell><cell>71.45±0.15 79.14±0.31 (+7.69) 79.33±0.39 (+7.88)</cell></row><row><cell>Germ-</cell><cell>FLAIR + Wiki</cell><cell>L0 Laugm L stabil</cell><cell>85.05 84.84 (-0.21) 84.43 (-0.62)</cell><cell cols="3">58.64±0.51 72.02±0.24 (+13.38) 78.59±0.11 (+10.63) 81.55±0.12 (+12.91) 67.96±0.23 68.64±0.28 70.15±0.27 (+11.51) 75.67±0.16 (+7.71) 79.31±0.32 (+10.67)</cell></row><row><cell>Eval 2014</cell><cell>Wiki + Char</cell><cell>L0 Laugm L stabil</cell><cell cols="3">80.32 80.68 (+0.36) 63.74±0.31 (+11.26) 70.83±0.09 (+8.84) 52.48±0.31 61.99±0.35 80.00 (-0.32) 62.29±0.35 (+9.81) 68.23±0.23 (+6.24)</cell><cell>54.86±0.15 75.66±0.11 (+20.80) 72.40±0.29 (+17.54)</cell></row></table><note>† and Piktus et al. (2019)  ‡ . L 0 is the standard training objective. L augm and L stabil are the data augmentation and the stability objectives, respectively. We report mean F1 scores with standard deviations from five experiments and mean differences against the standard objective (in parentheses).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Hyper-parameters of the sequence labeling model f (x) used in our experiments.</figDesc><table><row><cell>Parameter name</cell><cell>Parameter value</cell></row><row><cell>Tagging schema</cell><cell>BIOES</cell></row><row><cell>Mini batch size</cell><cell>32</cell></row><row><cell>Max. epochs</cell><cell>100</cell></row><row><cell>LSTM # hidden layers</cell><cell>1</cell></row><row><cell>LSTM # hidden units</cell><cell>256</cell></row><row><cell>Optimizer</cell><cell>SGD</cell></row><row><cell>Initial learning rate</cell><cell>0.1</cell></row><row><cell>Learning rate anneal factor</cell><cell>0.5</cell></row><row><cell>Minimum learning rate</cell><cell>0.0001</cell></row><row><cell>Word dropout level</cell><cell>0.05</cell></row><row><cell>Variational dropout level</cell><cell>0.5</cell></row><row><cell>Patience</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Outputs produced by the models trained with and without our auxiliary NAT objectives (NAT output and Baseline output, respectively). We demonstrate examples that contain misspellings and OCR errors, where the models trained with the auxiliary NAT objectives correctly recognized all tags, while the baseline models either misclassified or completely missed some entities.</figDesc><table><row><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell><cell>Total</cell></row><row><cell cols="5">Sentences 14,041 3,250 3,453 20744</cell></row><row><cell>Tokens</cell><cell cols="4">203,621 51,362 46,435 301418</cell></row><row><cell>PER</cell><cell cols="4">6,600 1,842 1,617 10059</cell></row><row><cell>LOC</cell><cell cols="4">7,140 1,837 1,668 10645</cell></row><row><cell>ORG</cell><cell cols="3">6,321 1,341 1,661</cell><cell>9323</cell></row><row><cell>MISC</cell><cell>3,438</cell><cell>922</cell><cell>702</cell><cell>5062</cell></row><row><cell></cell><cell cols="3">(a) English CoNLL 2003.</cell><cell></cell></row><row><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell><cell>Total</cell></row><row><cell cols="5">Sentences 12,705 3,068 3,160 18933</cell></row><row><cell>Tokens</cell><cell cols="4">207,484 51,645 52,098 311227</cell></row><row><cell>PER</cell><cell cols="3">2,801 1,409 1,210</cell><cell>5420</cell></row><row><cell>LOC</cell><cell cols="3">4,273 1,216 1,051</cell><cell>6540</cell></row><row><cell>ORG</cell><cell cols="2">2,154 1,090</cell><cell>584</cell><cell>3828</cell></row><row><cell>MISC</cell><cell>780</cell><cell>216</cell><cell>206</cell><cell>1202</cell></row><row><cell cols="4">(b) German CoNLL 2003.</cell><cell></cell></row><row><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell><cell>Total</cell></row><row><cell>Sentences</cell><cell cols="4">24,000 2,200 5,100 31300</cell></row><row><cell>Tokens</cell><cell cols="4">452,853 41,653 96,499 591005</cell></row><row><cell>PER</cell><cell>7,679</cell><cell cols="3">711 1,639 10029</cell></row><row><cell>PER-deriv</cell><cell>62</cell><cell>2</cell><cell>11</cell><cell>75</cell></row><row><cell>PER-part</cell><cell>184</cell><cell>18</cell><cell>44</cell><cell>246</cell></row><row><cell>LOC</cell><cell>8,281</cell><cell cols="3">763 1,706 10750</cell></row><row><cell>LOC-deriv</cell><cell>2,808</cell><cell>235</cell><cell>561</cell><cell>3604</cell></row><row><cell>LOC-part</cell><cell>513</cell><cell>52</cell><cell>109</cell><cell>674</cell></row><row><cell>ORG</cell><cell>5,255</cell><cell cols="2">496 1,150</cell><cell>6901</cell></row><row><cell>ORG-deriv</cell><cell>41</cell><cell>3</cell><cell>8</cell><cell>52</cell></row><row><cell>ORG-part</cell><cell>805</cell><cell>91</cell><cell>172</cell><cell>1068</cell></row><row><cell>MISC</cell><cell>3,024</cell><cell>269</cell><cell>697</cell><cell>3990</cell></row><row><cell>MISC-deriv</cell><cell>236</cell><cell>16</cell><cell>39</cell><cell>291</cell></row><row><cell>MISC-part</cell><cell>190</cell><cell>18</cell><cell>42</cell><cell>250</cell></row><row><cell></cell><cell cols="2">(c) GermEval 2014.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Statistics of the data sets used in our NER experiments ( §4). We present statistics of the training (Train) development (Dev) and test (Test) sets, including the number of sentences, tokens, and entities: person names (PER), locations (LOC), organizations (ORG) and miscellaneous (MISC). The Ger-mEval 2014 data set defines two additional fine-grained sub-labels: "-part" and "-deriv" that mark derivation and compound words, respectively, which stand in direct relation to Named Entities.</figDesc><table><row><cell></cell><cell>OCR noise</cell><cell>Mis-spellings  †</cell><cell>Mis-spellings  ‡</cell></row><row><cell>English CoNLL 2003</cell><cell>8.9%</cell><cell>16.5%</cell><cell>9.8%</cell></row><row><cell>German CoNLL 2003</cell><cell>9.0%</cell><cell>8.3%</cell><cell>8.0%</cell></row><row><cell>GermEval 2014</cell><cell>9.3%</cell><cell>8.6%</cell><cell>8.2%</cell></row><row><cell cols="3">(a) Character Error Rates.</cell><cell></cell></row><row><cell></cell><cell>OCR noise</cell><cell>Mis-spellings  †</cell><cell>Mis-spellings  ‡</cell></row><row><cell cols="2">English CoNLL 2003 35.6%</cell><cell>55.4%</cell><cell>48.3%</cell></row><row><cell cols="2">German CoNLL 2003 39.5%</cell><cell>26.5%</cell><cell>45.5%</cell></row><row><cell>GermEval 2014</cell><cell>41.2%</cell><cell>27.0%</cell><cell>47.9%</cell></row><row><cell cols="3">(b) Word Error Rates.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Error rate estimation for different noise distributions. OCR noise is modeled with the character confusion matrix, whereas misspellings are induced using look-up tables released byBelinkov and Bisk (2018)  † and Piktus et al. (2019) ‡ .</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">NAT repository on GitHub: https://github.com/ mnamysl/nat-acl2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">We drop the θ parameter for brevity in the remaining of the paper. Nonetheless, we still assume that all components of F (x; θ) and all expressions derived from it also depend on θ.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Moreover, a human reader should be able to infer the correct label yi from the token xi and its context. We assume that this corresponds to a character error rate of ≤ 20%.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">We describe the details of our vanilla error model along with the examples of confusion matrices in the appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">Both objectives could be combined and used together. However, our goal is to study their impact on robustness separately, and we leave further exploration to future work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">We did not explore this setting in this paper, leaving such optimization to future work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">We list the detailed hyper-parameters in the appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"> We used FLAIR v0.4.2.   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8">We experimented with a pre-processing step that used a spell checking module, but it did not provide any benefits and even decreased accuracy on the original data. Therefore we did not consider it a viable solution for this problem.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9">We present data set statistics and sample outputs from our system in the appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10">This choice was motivated by the availability of pretrained embedding models in the FLAIR framework.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11">  12  We did not replicate the exact results from the original papers because we did not use development sets for training, and our approach is feature-based, as we did not fine-tune embeddings on the target task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12">Nevertheless, the aspect of mimicking an empirical noise distribution requires more thoughtful analysis, and therefore we leave to future work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13">The revisited annotations are available on the official website of the CoNLL 2003 shared task: https://www. clips.uantwerpen.be/conll2003/ner/.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the reviewers for the time they invested in evaluating our paper and for their insightful remarks and valuable suggestions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using SMT for OCR error correction of historical texts</title>
		<author>
			<persName><forename type="first">Haithem</forename><surname>Afli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengwei</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Páraic</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
				<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>Portorož</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="962" to="966" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">FLAIR: An easy-to-use framework for state-of-theart NLP</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-4010</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
				<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
				<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Estimating and rating the quality of optically character recognised text</title>
		<author>
			<persName><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Burns</surname></persName>
		</author>
		<idno type="DOI">10.1145/2595188.2595214</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage, DATeCH &apos;14</title>
				<meeting>the First International Conference on Digital Access to Textual Cultural Heritage, DATeCH &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating natural language adversarial examples</title>
		<author>
			<persName><forename type="first">Moustafa</forename><surname>Alzantot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo-Jhang</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mani</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1316</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2890" to="2896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adversarial training for multi-context joint entity and relation extraction</title>
		<author>
			<persName><forename type="first">Giannis</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1307</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2830" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Synthetic and natural noise both break neural machine translation</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30">2018. April 30 -May 3, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">NoSta-d named entity annotation for German: Guidelines and dataset</title>
		<author>
			<persName><forename type="first">Darina</forename><surname>Benikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Reznicek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014)</title>
				<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC-2014)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<publisher>European Languages Resources Association (ELRA</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2524" to="2531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00051</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An improved error model for noisy channel spelling correction</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.3115/1075218.1075255</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 38th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mitigating the impact of speech recognition errors on chatbot using sequence-to-sequence model</title>
		<author>
			<persName><forename type="first">Pin-Jung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I-Hung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><forename type="middle">Yao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASRU.2017.8268977</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Automatic Speech Recognition and Understanding Workshop</title>
				<meeting><address><addrLine>Okinawa, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-16">2017. December 16-20, 2017</date>
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page" from="497" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust neural machine translation with doubly adversarial inputs</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4324" to="4333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards robust neural machine translation</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1163</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1756" to="1766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ICDAR2017 competition on post-OCR text correction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chiron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coustaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moreux</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2017.232</idno>
	</analytic>
	<monogr>
		<title level="m">2017 14th IAPR International Conference on Document Analysis and Recognition (IC-DAR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="1423" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional LSTM-CNNs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><surname>Nichols</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00104</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Twitter part-of-speech tagging for all: Overcoming sparse and noisy data</title>
		<author>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013</title>
				<meeting>the International Conference Recent Advances in Natural Language Processing RANLP 2013<address><addrLine>Shoumen, BULGARIA</addrLine></address></meeting>
		<imprint>
			<publisher>Hissar, Bulgaria. INCOMA Ltd</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="198" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Online spelling correction for query completion</title>
		<author>
			<persName><forename type="first">Huizhong</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo-June</forename></persName>
		</author>
		<idno type="DOI">10.1145/1963405.1963425</idno>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">HotFlip: White-box adversarial examples for text classification</title>
		<author>
			<persName><forename type="first">Javid</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anyi</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2006</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Unsupervised context-sensitive spelling correction of clinical free-text with word and character n-gram embeddings</title>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Fivez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Šuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2317</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="143" to="148" />
			<pubPlace>Vancouver, Canada</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A benchmark corpus of English misspellings and a minimally-supervised model for spelling correction</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Flor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-4407</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="76" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Black-box generation of adversarial text sequences to evade deep learning classifiers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Soffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<idno type="DOI">10.1109/SPW.2018.00016</idno>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Security and Privacy Workshops (SPW)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">How robust are characterbased word embeddings in tagging and MT against wrod scramlbing or randdm nouse?</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stalin</forename><surname>Varanasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Günter</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the Association for Machine Translation in the Americas</title>
				<meeting>the 13th Conference of the Association for Machine Translation in the Americas<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Research Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="68" to="80" />
		</imprint>
	</monogr>
	<note>Association for Machine Translation in the Americas</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Training on synthetic noise improves robustness to natural noise in machine translation</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</title>
				<meeting>the 5th Workshop on Noisy User-generated Text (W-NUT 2019)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finding names in trove: Named entity recognition for Australian historical newspapers</title>
		<author>
			<persName><forename type="first">Sunghwan</forename><surname>Mac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Cassidy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Association Workshop</title>
				<meeting>the Australasian Language Technology Association Workshop<address><addrLine>Parramatta, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="57" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
		<idno type="DOI">10.1145/3065386</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Neural Information Processing Systems</title>
				<meeting>the 25th International Conference on Neural Information Processing Systems<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
				<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1030</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Iosifovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levenshtein</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Physics-Doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automated anonymization of text documents</title>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Mamede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Baptista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Dias</surname></persName>
		</author>
		<idno type="DOI">10.1109/CEC.2016.7743936</idno>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Congress on Evolutionary Computation (CEC)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1287" to="1294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adversarial training methods for semi-supervised text classification</title>
		<author>
			<persName><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24">2017. 2017. April 24-26, 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Conference Track Proceedings</note>
	<note>Goodfellow</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Efficient, lexicon-free OCR using deep learning</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Namysl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iuliu</forename><surname>Konya</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2019.00055</idno>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="295" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An open corpus for named entity recognition in historic newspapers</title>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Neudecker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)</title>
				<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4348" to="4352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">OOV sensitive named-entity recognition in speech</title>
		<author>
			<persName><forename type="first">Carolina</forename><surname>Parada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2011, 12th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-08-27">2011. August 27-31, 2011</date>
			<biblScope unit="page" from="2085" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Misspelling oblivious word embeddings</title>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bora</forename><surname>Necati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Edizel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><surname>Silvestri</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1326</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3226" to="3234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning</title>
				<meeting>the Thirteenth Conference on Computational Natural Language Learning<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009. CoNLL-2009</date>
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The significance of letter position in word recognition</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Rawlinson</surname></persName>
		</author>
		<idno type="DOI">10.1109/MAES.2007.327521</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Aerospace and Electronic Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="27" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">ICDAR 2019 competition on post-OCR text correction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rigaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coustaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moreux</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2019.00255</idno>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Document Analysis and Recognition (ICDAR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1588" to="1593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adapting sequence models for sentence correction</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Schmaltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1298</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2807" to="2813" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multi-modular domain-tailored OCR post-correction</title>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1288</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2716" to="2726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An overview of the Tesseract OCR engine</title>
		<author>
			<persName><forename type="first">Ray</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2007.4376991</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)</title>
				<meeting>the Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="629" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Toward robust neural machine translation for noisy input sequences</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Workshop on Spoken Language Translation (IWSLT)</title>
				<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno>ICLR 2014</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
				<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Creating an improved version using noisy OCR from multiple editions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wemhoener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Z</forename><surname>Yalniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2013.39</idno>
	</analytic>
	<monogr>
		<title level="m">2013 12th International Conference on Document Analysis and Recognition</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="160" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust multilingual part-of-speech tagging via adversarial training</title>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1089</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="976" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Improving the robustness of deep neural networks via stability training</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.485</idno>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016</title>
				<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-27">2016. June 27-30, 2016</date>
			<biblScope unit="page" from="4480" to="4488" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
