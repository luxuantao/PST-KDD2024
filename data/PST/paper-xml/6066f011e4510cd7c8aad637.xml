<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Market-oriented job skill valuation with cooperative composition neural network</title>
				<funder ref="#_QeM2Gcw">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_pGbck24">
					<orgName type="full">Project of Youth Innovation Promotion Association CAS</orgName>
				</funder>
				<funder ref="#_88mZa26 #_JbYhsTR #_RwzEwCU #_MtXqQZv #_48s3qPP">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ying</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
							<email>zhuangfuzhen@ict.ac.cn</email>
							<idno type="ORCID">0000-0002-0520-2619</idno>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
							<email>zhuhengshu@baidu.com</email>
							<idno type="ORCID">0000-0003-4570-643X</idno>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
							<idno type="ORCID">0000-0003-2942-7430</idno>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qing</forename><surname>He</surname></persName>
							<idno type="ORCID">0000-0001-8833-5398</idno>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS)</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
							<email>hxiong@rutgers.edu</email>
							<affiliation key="aff5">
								<orgName type="institution">the State University of New Jersey</orgName>
								<address>
									<settlement>Rutgers, Newark</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Market-oriented job skill valuation with cooperative composition neural network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1038/s41467-021-22215-y</idno>
					<note type="submission">Received: 10 July 2020; Accepted: 3 March 2021;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The value assessment of job skills is important for companies to select and retain the right talent. However, there are few quantitative ways available for this assessment. Therefore, we propose a data-driven solution to assess skill value from a market-oriented perspective. Specifically, we formulate the task of job skill value assessment as a Salary-Skill Value Composition Problem, where each job position is regarded as the composition of a set of required skills attached with the contextual information of jobs, and the job salary is assumed to be jointly influenced by the context-aware value of these skills. Then, we propose an enhanced neural network with cooperative structure, namely Salary-Skill Composition Network (SSCN), to separate the job skills and measure their value based on the massive job postings. Experiments show that SSCN can not only assign meaningful value to job skills, but also outperforms benchmark models for job salary prediction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I</head><p>n the era of knowledge economy, skilled talents are always precious treasures. Modern jobs require talents to have substantial and continuous investment on their job skills <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> . Therefore, understanding the value of job skill will fulfill the socalled "Skill Gap" <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5</ref> between employers and talents, and bring them competitive edge to cope with the accelerating pace of technological changes. At the micro level, it can not only help individuals to proactively assess their competencies and decide what are the right skills to learn, but also help companies to develop the right salary system of their job positions for attracting and retaining the best possible talent. Moreover, at the macro level, the job skill value is an important indicator of the economic equilibrium of labour market and shows the supply and demand relationship associated with knowledge investments <ref type="bibr" target="#b5">6</ref> .</p><p>During the past decades, researchers have devoted large efforts to assess the value of job skills in different manners. Many surveys and studies have shown evidence of a worldwide positive association between the distributions of job skill mastery and job salary <ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8</ref> . However, due to the dynamic and indistinct nature of job skill value, traditional market survey-based approaches usually fail to provide a fine-grained and up-to-date analysis. In recent years, the newly available online recruitment services have accumulated abundant job advertisement data <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10</ref> , which provides an unparalleled chance for Labour Market Intelligence <ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12</ref> and data-driven job skill analysis <ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14</ref> . Nevertheless, most existing studies are focused on job skill demand modeling <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16</ref> , but there still lacks a quantitative way to assess the value of job skills from the perspective of their influence on job salary.</p><p>Indeed, achieving quantitative job skill value assessment is far from a trivial task. Specifically, on one hand, the value of a specific skill is not immutable but varies with respect to different job contexts. For example, the talents experienced with algorithm related skills will be appreciated with high-paid jobs for a hightech AI company, while the engineering skills may be the most valuable ones in a traditional software company. On the other hand, the job skills are usually not isolated, but integrated with each other as a holistic requirement for deciding the job salary. Indeed, along this line, the most critical challenge is that there usually lack of ground truth data of skill value for building an effective and quantitative assessment model. Therefore, how to separately assess the value of job skills and model their impact on job salary under various job contexts is still open to be explored.</p><p>To this end, in this paper, we propose a data-driven solution to skill value assessment from a market-oriented perspective through mining the job advertisement data. Specifically, we introduce a market-oriented definition of skill value, and formulate the task of skill value assessment as the Salary-Skill Value Composition Problem, where each job position is regarded as the composition of a set of required skills attached with the job's contextual information, and the job salary is assumed to be influenced by the context-aware value of these skills. Along this line, we propose an enhanced neural network with cooperative structure, namely Salary-Skill Composition Network (SSCN), to separate the job skills and measure their value from the massive job postings. SSCN regards salary prediction as a cooperative task for skill valuation and holistically models the relationship between skills and the job salary, considering both skill value and domination. Figure <ref type="figure" target="#fig_1">1</ref> shows the schematic diagram of the key idea in this study. Indeed, SSCN provides a cooperative framework to train neural network models for knowledge discovery from unlabeled data, by quantitatively linking them with a supervised learning task. Extensive experiments on a real-world dataset clearly validate that SSCN can not only assign meaningful value to job skills in various job contexts, but also outperforms state-of-the-art models in terms of job salary prediction.</p><p>Meanwhile, based on the results of SSCN, many interesting findings can be revealed, such as which skills will lead to highpaid jobs.</p><p>As a long-standing research direction, the value of job skills in the market is always abstract and has different measurements with respect to different application scenarios <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17</ref> . Different from existing studies, in this paper, we aim to introduce a marketoriented definition of skill value with job context awareness, emphasizing the direct impact of skills on job salary. To be specific, the value of a skill is defined as the expected salary of a job that only requires this skill, given a specific job context. It should be noticed that in this paper, context refers to all the factors other than the skill requirement that can influence the job salary, such as the company, recruitment time, work location, and required working experience. Indeed, the above definition directly measures how much salary a skill will bring when people make full use of it in the job. The motivation behind this definition is to guarantee that the value of different skills can be measured in an independent and comparable manner. In order to precisely estimate this value under various job contexts, we train a model f with parameter ? that calculates the skill value v = f(s, lv, C|?) given a set of observable job contexts C and a skill s with level lv (i.e., the degree of mastery, refer to Fig. <ref type="figure" target="#fig_2">2a</ref> for examples). To train the model, it is essential to obtain a set of training data containing job postings that only require one skill. However, in the real-world scenario, the job requirements are always complicated and cannot be qualified with only one skill. As a result, each job posting is always associated with multiple required skills, which makes it difficult to train the skill valuation model under the supervised learning paradigm.</p><p>Fortunately, the job salary can be regarded as a mixed value of corresponding required skills, and a job requiring many valuable skills should have a high salary. This intuition implies effective supervision for skill value assessment in an indirect way. In other words, if we can model the relationship between skill value and job salary, we can use job salary data to supervise the training of skill valuation model. Specifically, the job postings can be formulated as J ? f?C j ; S j ; Y j ?jj ? 1; 2; ? ? ? g, where C j denotes a set of job contexts, S j denotes required skill set, Y j denotes the job salary. In particular, S j consists of the corresponding skill-level pairs S j ? f?s ?i? j ; lv ?i? j ?ji ? 1; 2; ? ? ? g; where s ?i? j is a skill and lv ?i? j is the level. If we have a model that can precisely estimate the salary Y j of a job posting given the value of its required skills, a proper estimation on skill value can lead to a good estimation on the job salary. So in this paper, we regard job salary prediction as a cooperative task for skill valuation. Formally, we define the task of this paper as a Salary-Skill Value Composition Problem, which aims to jointly learn a context-aware skill value assessment model f: (skill, context ? value) and a skill-based salary prediction model g: (&lt;skill, value&gt; ? salary) from the job postings set J . It should be noticed that, although there might exist more complicated relationships among job skills, context and salary, in the problem formulation, we only consider the skill value is contextaware and can be combined together in a linear way to reflect the job salary. In this way, our model can facilitate the measurement of the influence of contexts on individual skills as well as the influence of skills on job salary.</p><p>Based on the above, the salary of a job j can be formulated as e y j ? g?f?s To solve the Salary-Skill Value Composition Problem, we propose the SSCN that is a cooperative neural network containing two steps of modeling to achieve skill valuation (the main task) and salary prediction (the cooperative task) simultaneously. The structure of SSCN is shown in Fig. <ref type="figure" target="#fig_2">2b</ref>. Specifically, SSCN takes a job posting as the input, calculates the value of all the involved skills and then combines them into the job salary in a straightforward but interpretable way.</p><p>The first part of SSCN is a specially designed Context-aware Skill Valuation Network (CSVN), as shown in Fig. <ref type="figure" target="#fig_2">2c</ref>. It dynamically models the skills, extracts the context-skill interaction and estimates the context-aware skill value. According to our definition, skill value can be regarded as a special case of job salary, and since salary is given as a range in our data, CSVN models the skill value as a range. Specifically, CSVN assigns each skill with a non-negative lower bound and a non-negative upper bound, constraining that the upper bound is no less than the lower bound.</p><p>In the real-world working scenario, the employees allocate their time and effort among the skills according to the importance of different job duties. Intuitively, the more you use a specific skill during work, the more it will influence your salary. Simulating this process, we propose to model the job salary as the weighted average of the skill value. We call the weight as skill domination. This agrees with our definition of skill value because when a job only involves one skill, the only skill has full domination and the salary degenerates into its value. In this way, the skill value is comparable and independent with each other. Considering that skills may have combinatorial influences on salary, we let the model catch skill interactions through modeling the domination. Specifically, the skill co-appearance is considered to influence the domination of each skill, which assures the model to peel explainable skill value that is only context-dependent while maintaining the model's fitting ability to general job postings. To model the domination, the second part of SSCN is a specially designed Attentive Skill Domination Network (ASDN), as shown in Fig. <ref type="figure" target="#fig_2">2d</ref>. Considering that the skill domination can be affected by the related skills (e.g., one skill may play an important role in the job when many related skills are also required), ASDN models the domination with a graph-based approach. Specifically, we attach each job posting with a skill graph, where the node represents the involved skills, and the edge between two skills represents their relationship. ASDN combines this skill graph with context-skill interaction information extracted from CSVN and calculates skill domination with graph-based attention mechanism. Considering that the two salary bounds may correspond to different job duty allocation, for example, common skills may raise the salary lower bound instead of the upper bound, ASDN outputs different skill domination for the two bounds. The details of training both CSVN and ASDN can be found in "Methods".</p><p>Indeed, SSCN models the relationship among skills, context and salary based on the observations of job advertisement data in an end-to-end manner. As a common issue of deep learning models, all the influencing factors and their complicated relationships are implicitly modeled as a blackbox, which is hard to be interpreted in a theoretical way. Nevertheless, it also brings the advantage that we only need to pay attention on the input (i.e., context and job skills) and output (i.e., job salary and skill value), while other latent influencing factors and relationships will be automatically learned by the hidden layers. In this way, the model is easy to be operated, and meanwhile, the skill value influenced by observable contexts can be explicitly estimated, which strongly supports further explainable analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>To validate the models proposed in this paper, we collected ITrelated job postings from a popular online recruitment website in China, namely Lagou (https://www.lagou.com/). Our dataset contains over 800,000 postings of various job positions across a time span of 36 months, ranging from July 2016 to June 2019. (1) Our main task is to train a skill valuation model with machine learning technology. Under the paradigm of supervised learning, we need a set of training data with explicit labels of skill value to provide supervision for the model. Then the model can learn a function that maps the input (i.e., context and skills) to the observation (i.e., skill value). However, the labeled data of skill value is unavailable in our dataset. (2) We have abundant data of job postings with labels of salary, which can provide supervision for training a salary prediction model. Therefore, with the intuition that valuable skills should lead to high job salary, we regard salary prediction as a cooperative task that provides indirect supervision for skill valuation model. (3) We propose a model, SSCN, to simultaneously achieve skill valuation and salary prediction tasks, where the skill valuation model is a component of the salary prediction model. Specifically, SSCN estimates the skill value and composes skill value into job salary. In this way, the skill valuation model can be trained with feedbacks from the salary prediction task.</p><p>After filtering the data with some preprocessing steps, we got 215,308 samples. We used these samples to train and validate our model. The details of data preprocessing, feature selection, network configurations, numerical statistics, and additional experimental results can be found in Methods and Supplementary Information. In particular, we also conducted supplementary experiments on an additional designer-related job posting dataset to validate the generalization of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skill value analysis under different job contexts.</head><p>Here we demonstrate the value of skills estimated by CSVN considering different kinds of job contexts. During our experiments, we found that the lower bound and upper bound of skill value always have a similar trend, so we mainly introduce the results of the lower bound, unless noted otherwise.</p><p>We define level influence as the average ratio of value increase when a level is specified. Figure <ref type="figure" target="#fig_3">3a</ref> shows the levels' average influence (see Supplementary Fig. <ref type="figure">S8a</ref> for influence distribution), where we have used all the skill-level pair instances involving each level for the estimation. The detailed information on sample size and influence distribution can be found in Supplementary Table <ref type="table" target="#tab_0">S10</ref>. We can observe that CSVN can significantly distinguish the impact of different levels. In general, most levels have a similar influence on both bounds, and sophisticated levels raise skill value more. In particular, the level Can Read, i.e., the lowest degree of mastery in our dataset, will decrease the skill value by 10%, while the level Versatile can contribute about 10% increase to the value. To get more insights, we show level influence on some specific skills in Table <ref type="table" target="#tab_0">1</ref>. In addition, we conducted significance test for better validating the results. It can be observed that, by ignoring the insignificant entries (i.e., p-value &gt; 0.05), the table is generally consistent with the averaged influence. Nevertheless, the model also learns bias for some special cases. For example, while Know is a relatively low level of mastery, it has positive influence on skill value when describing JavaScript. The reason is that while JavaScript mostly appears in jobs that related to web development, the statement Know JavaScript usually acts as an additional requirement for some complicated and higher-paid jobs like architecture design. Therefore, the model overestimates the skill value due to the imbalanced data distribution. Indeed, this result is explainable from a market-oriented view. Specifically, the mastery level of a specific skill usually indicates the role that it plays in the job; and therefore, the skill value highly depends on the market pricing on the relevant jobs. However, as shown in Fig. <ref type="figure" target="#fig_3">3</ref> (a), the model will still work for the general cases. Furthermore, we calculated the ratio of skill-level observations that might cause the biased level influence estimations. The result shows that only very few samples (0.96% of the whole dataset) encounter this bias. The detailed calculation can be found in the Supplementary Information. A possible solution for alleviating this kind of bias is to enlarge the diversity of the recruitment market data, which is a valuable direction for our future studies. Supplementary Fig. <ref type="figure">S6a</ref> shows the level influence on the designer dataset. The result slightly differs from the result on the IT dataset, which further indicates that level influence varies with respect to occupations. In this study, time is also regarded as one kind of job context. CSVN assigns the skills with temporal embeddings, this supports dynamic skill value analysis. From Fig. <ref type="figure" target="#fig_3">3b</ref>, we can observe that fluctuations exist on skill value, and the skills have different trends of value change (see Supplementary Table <ref type="table" target="#tab_1">S12</ref> for numerical statistics). Some interesting findings can also be observed from the figure. On the whole, Architecture has a relatively stable trend of value increase. Specifically, in 2016-H2, its value is 21.8 K RMB on average. Then, it increased 5% on average for every half-year and reached 27.6 K RMB in 2019-H1. This indicates a rising market demand for this skill, which is good news for architects. However, some hot skills like GoLang and Recommender System seem to be less stable. Especially, GoLang has sharp value increase and decrease. For example, in 2019-H1, its value decreased by 26%, from 28.2 K RMB to 20.8 K RMB on average. This reminds students not to simply pursue the hottest new skills on the market, because their related industry may be still unstable. According to our experiment, we find that many skills with high value meet value decrease in the first half of 2019. We guess this phenomenon is due to the so-called Internet Winter of China this year. The trend of value for designer skills can be found in Supplementary Fig. <ref type="figure">S6b</ref>. Interestingly, the designer skills are stable and there is no general value decrease in the first half of 2019, which indicates that recent market changes have more influence on IT practitioners than designers.</p><p>Skill value under different experience requirements can provide talents with a long-term reference on choosing skills to learn. CSVN considers working experience requirements as one kind of job context and has a strong ability on inferring the experienceaware value, even for new skills. For example, although GoLang was officially released in 2009, we can still estimate its value with the working experience of longer than 10 years as 32.0 K RMB by smoothly extending the line. Figure <ref type="figure" target="#fig_3">3c</ref> shows that longer experience leads to higher skill value (see Supplementary Table <ref type="table" target="#tab_2">S13</ref> for numerical statistics). Compared with the graduates, 10 years of working experience increases the skill value by 2.5 times on average. This is reasonable because a highly experienced talent usually can get a higher salary. But the speed of value rise has some differences among the skills. For example, Architecture and Project Management increase slowly in the first several years, while quickly after 3-5 years. Specifically, although Algorithm has a higher value (12.8 K RMB) for graduates, in the long term, the value of Project Management (10.2 K RMB for graduates) increases faster and achieves the similar value as Algorithm after 10 years. Similarly, Machine Learning has a higher value (16.8 K RMB) than Architecture (16.4 K RMB) for graduates and increases fast in the first several years. It can be observed that, with 1-3 years' experience, the value of Machine Learning (24.2 K RMB) is 20% higher than Architecture (19.9 K RMB). However, the rank is reversed after 5 years. This result makes sense, because the ability on Architecture and Project Management accumulates during work, while talents' programming skills usually gain fast the first several years of their career and may decrease as they get older. We can conclude that CSVN can provide good experienceaware skill value assessment. This provides students a reference to consider their longer future career when choosing a skill to learn, instead of only comparing the job salary at an entry-level. In addition to skills that get you a fortune at the moment you graduate from school, learning skills that are valuable for you in the future may also be a good choice. We also show the experience influence on designer skills in Supplementary Fig. <ref type="figure">S6c</ref>, which shows the similar trend with that of the IT dataset.</p><p>For job seekers, the best choice is to work in companies that treasure the skills they possess. Figure <ref type="figure" target="#fig_3">3d</ref> shows skill value distribution in different companies, where we have used all the skill-company pair instances involving each corresponding skillcompany pair for the estimation. The detailed information on sample size and numerical statistics can be found in Supplementary Table <ref type="table" target="#tab_4">S14</ref>. It can be observed that, due to the differences in business strategy, skills are valued differently by different companies. This reveals the traits of companies. For example, while most of these companies give a much higher value to Architecture than Algorithm, ByteDance values them similarly. Besides, ByteDance is the only company that values Python (23.9 K RMB on average) more than Java (21.0 K RMB on average). This implies ByteDance attaches high importance to some research works. In JD.com, Java has a larger range of value distribution than in other companies. Specifically, the gap between the two quartiles of Java in JD.com is 13 K RMB, which is much larger than the gaps of 7 K RMB in the other 4 companies. This implies the higher possibility of salary increase for a Java engineer in JD.com. Meanwhile, different from others, the value of skills in Baidu is quite stable, which means the demand for different skills is more comprehensive. In Supplementary Fig. <ref type="figure">S6d</ref>, we show the distribution of designer-related skill value on these companies. It can be observed that the companies also have different preferences in designer-related skills.</p><p>Evaluation on salary prediction. We compared the performance of SSCN on salary prediction with several baseline methods (see details in "Methods"). The performance is evaluated with root mean square error (RMSE) and mean absolute error (MAE) <ref type="bibr" target="#b17">18</ref> , which are both popular metrics for difference measurement between the observations and the predictions. The results of the evaluation are listed in Table <ref type="table" target="#tab_1">2</ref>. There are several observations. First, SSCN outperforms all the baseline models, especially in terms of RMSE where there is a 3.5% decrease on lower bound prediction and 5.2% decrease on upper bound prediction compared to BERT, which outperforms the rest of the baseline models. Though SSCN has a larger variance due to its complex structure, its worst performance is still significantly better than the others' best performances. Second, SSCN outperforms the linear models (i.e., SVM and LR). To assure the physical meanings of the skill value, SSCN simplifies the last layer of skill composition into a linear form. However, SSCN is still a complicated non-linear deep learning model that can seize the complicated relation between skill, context and salary. So it performs much better than the real linear models. Third, since accurately predict context-aware job salary is a more difficult problem than standard salary benchmarking, HSBMF performs not well. But SSCN can achieve more accurate salary prediction under specific job contexts. Fourth, by replacing ASDN with a mean pooling layer, the model's performance decreased a lot. This proves the effectiveness of skill domination on job salary modeling. Fifth, simultaneously estimating the two bounds of the range in a single model improves the performance. This is because the lower bound and upper bound of job salary are strongly correlated. In addition to giving constraints on the bounds, CSVN also extracts a shared shallow representation for them. In this way, the two bounds can get part of the supervision from each other, which reduces the chance of over-fitting. The experimental results on salary prediction on the designer dataset can be found in Supplementary Table <ref type="table">S8</ref>, which are consistent with the results of the IT dataset. Furthermore, we conducted parameter experiments to demonstrate the robustness of our model, which can be found in Supplementary Fig. <ref type="figure">S5</ref> and Supplementary Table <ref type="table">S7</ref>. The results show that SSCN is parameter insensitive and can be easily adopted without carefully tuning the hyper-parameters. We randomly picked some skills related to programming language and listed the influence of several levels on them. To better reveal the influence and distinguish occasional results, we conducted two-sided t-test for the significance of each skill-level pair in the table and listed the corresponding p-value.</p><p>It can be concluded that, with the cooperation of the salary prediction task, SSCN trains a quantitative and accurate skill valuation model without using any labeled skill value data. Since skill valuation is an essential component of job salary prediction in SSCN, SSCN's performance on job salary prediction also quantitatively demonstrated the effectiveness of our skill valuation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>With the Salary-Skill composition structure, SSCN decouples the job salary into the value of every involved skills by modeling skill domination. Here, we analyze this composition process holistically and show the effect of its factors.</p><p>Skill domination versus skill value. The multiplication of value and domination of some skill in a job posting is its actual contribution to the salary. To analyze the effect of domination and value, we display the averaged value, domination, and salary contribution of machine learning-related skills in Fig. <ref type="figure" target="#fig_4">4</ref>. The numerical statistics can be found in Supplementary Table <ref type="table" target="#tab_0">S16</ref>-S18. On the whole, more generic skills have higher domination, while more specific skills have higher value. For example, Unsupervised Learning (with domination 37.8% on average) and Multivariable Regression (with domination 46% on average) have high domination, showing many jobs need them. Graph Algorithm (with domination 18.2% on average) has lower domination but higher value (with value 35.2 K RMB on average), indicating that although there are fewer jobs that can make full use of it, you can easily get high salary if you find one. Indeed, most jobs in the market are not so professional and are dominated by some generic skills. In these jobs, some high-value skills may also be involved, but they are usually not a major part of the work. Also, the rapidly-emerging new skills with the fast technology changes enlarge the skill gap between job candidates and employers <ref type="bibr" target="#b18">19</ref> . As a result, from the viewpoint of the employers, although it is usually difficult to find candidates who perfectly meet their specific skill requirements, the talents owning generic skills are usually able to quickly learn and adapt to the required skills <ref type="bibr" target="#b19">20</ref> . Accordingly, higher education in recent years have been focusing on teaching theoretical and basic knowledge, and cultivating students' learning ability and problem-solving skills rather than teaching specific skills <ref type="bibr" target="#b20">21</ref> . This phenomenon enlarges the domination of more generic skills in the job market.</p><p>Our experimental result implies that the breadth of your knowledge decides how easy you can find a job, while the depth of your skill helps to raise your salary. In this way, it becomes a trade-off between domination and value when choosing a skill to learn, the averaged contribution becomes a good reference, as is shown in Fig. <ref type="figure" target="#fig_4">4c</ref>, Topic Model (with contribution 8.5 K RMB on average) is a good learning choice. It should be noticed that having a low averaged domination does not mean the skill never dominates a job. When you have excellent knowledge of some specific skills (which is always true for Ph.D. students), you should be confident that you can find somewhere to make full use of your ability. Wordclouds for the designer dataset can be found in Supplementary Fig. <ref type="figure">S7</ref>, where we can distinguish generic and specific skills for designer-related jobs.</p><p>The influence of skill on job salary. For a skill required in a job posting, we can estimate its influence by calculating how much will the salary decrease if we remove this skill from the requirement. By fixing the domination of the other skills and getting their weighted average of value, the new salary can be estimated as y 0 ? y?v 1?d ; where v and d represents the value and domination of the removed skill. The ratio of decrease is r ? y?y 0 y ; where y denotes the previous job salary. In Table <ref type="table" target="#tab_2">3</ref>, we can observe that generally, high value and high domination lead to high influence. For example, Matrix Calculation has a high value and high domination, by dropping it, the job salary will decrease by 18.4% on average. According to this table, machine learning-related skills have positive influence on job salary. We will show in the next part that some skills may have negative influences on job salary.</p><p>Case study on a job posting. Everyone wants a job where they can give full play to their ability. However, the job descriptions may contain job duties both you are good at and not good at. Understanding the role of each required skill in a job can help job seekers to decide if a job is suitable for them. For each job posting, SSCN predicts the value of each skill under the specified context, calculates the skill domination based on the skill co-appearance, and finally combines the skill value into the job salary according to the domination. Figure <ref type="figure" target="#fig_4">4d</ref> shows the case study to illustrate how SSCN works on a job posting. Specifically, we used the trained SSCN to decompose a randomly selected job posting and analyzed the domination, contribution, and overall influence on salary of the involved skills. This job description is to employ an algorithm engineer who has two parts of job duties, which are data mining with business data and product development.</p><p>Compared with the coding skills, Machine Learning and Deep Learning have much higher domination and contribution on the job salary, indicating that the job expects a data mining expert instead of an experienced engineer. Though with similar domination, Deep Learning has a much higher contribution than Machine Learning, which is because it has a higher value under its job context. We can also observe that Deep Learning contributes a lot to the higher-bound salary, which agrees with the job description where Deep Learning is listed as the additional requirement. From the above analysis, we can find that the job seekers can try this job if they are good at machine learning and deep learning, there is no need to worry much if they are mediocre at coding. Also, it can be observed that data mining duty has a positive influence while the development duty has a negative influence on the salary. This indicates that if you are an expert in data mining, maybe you should look for a full-time data mining job, it may bring you a higher salary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Potential applications.</head><p>Through the experiments, we show that our skill valuation model has the potential to be applied to various real-world applications. First, our model can be applied to talent recruitment. As can be observed in Table <ref type="table" target="#tab_1">2</ref>, our model achieves high performance on salary prediction. Therefore, it can provide salary references for jobs in the market when the job descriptions are specified. With the predicted salary information, the recruiters can evaluate the market competitiveness of their offered salaries; and the job seekers can get an idea about their salary expectations. Second, our model can be directly applied to business market analysis. For example, as can be observed in Fig. <ref type="figure" target="#fig_3">3b</ref>, our model reveals the overall trend of skill value in the market. Third, our model can be applied to student education. Specifically, the skill value provides the students with marketoriented guidance for skill learning. For example, with the experience-aware skill value shown in Fig. <ref type="figure" target="#fig_3">3c</ref>, students are able to make better personalized curriculum choices to achieve long-term career development. Fourth, our model can be applied to knowledge management and talent development. For example, as shown in Fig. <ref type="figure" target="#fig_3">3d</ref>, the companies can analyze the value of skills for their own business. Then, they can develop specific curriculums to continuously train their employees for valuable skills. Fifth, our model can be applied to job recommendation. For example, by  We show the averaged influence of some machine learning-related skills, together with their averaged value (K RMB) and domination, and the averaged salary (K RMB) of jobs involving them.</p><p>measuring the average value of skills in companies, as shown in Fig. <ref type="figure" target="#fig_3">3d</ref>, job seekers can receive effective guidance on which company is more suitable for them to pursue.</p><p>Technical contribution. Since indirect supervision is common in the real-world, we believe that this work not only provides an intelligent and accurate solution for the skill valuation problem but also can be an inspiration for readers who work on data analysis in other fields of applications. Specifically, in many realworld scenarios, obtaining labeled training data is far from an easy job. It is often the case that we can only obtain indirect supervision from a related task. Learning skill valuation model from job salary data is one of these kinds of problems. In this problem, we have no labeled data of skill value, but we have job salary data as indirect supervision information, with the intuition that high skill value usually leads to high job salary. To this end, we proposed a machine learning-based solution that uses neural network with cooperative structure to model the relationship between job and skills, where the salary prediction is regarded as a cooperative task for training the skill valuation model. In this way, we obtain an effective skill valuation model under the indirect supervision of job salary data.</p><p>Limitations. The first limitation of this paper is the limited data. On the one hand, since our work is based on the accumulated job advertisements in online recruitment website, which has a short history, we are not able to provide insights about the long-term job skill development. On the other hand, since our research has certain requirements on the data quality (e.g., detailed skill requirement, job salary and contextual information), in this paper we only evaluated our model with two datasets collected from one of the largest and most popular Chinese online recruitment website of Internet-related industry. This may bring bias to the analysis. If provided with more large-scale and comprehensive data, our model will obtain more significant insights. The second limitation is the empirical validation of skill value. Since marketoriented skill valuation is a new research problem, we are not able to obtain ground truth for quantitatively validating the accuracy of our model. Therefore, in this paper, we evaluated the performance of our model with the task of salary prediction. The rational behind our evaluation is that, with the explicitly formulated relationship between salary and skill, the effectiveness of skill value will be revealed from the salary prediction performance. In the future, we plan to continuously update our research by seeking more data sources and collaborations for further validating our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Job posting formulation. A summary of the notations in this paper can be found in Supplementary Table <ref type="table" target="#tab_1">S2</ref>. As shown in Fig. <ref type="figure" target="#fig_2">2a</ref>, we formulate a job posting J j as (C j , S j , Y j ), where C j denotes a set of job contexts, S j denotes required skill set, and Y j denotes the expected range of job salary. S j ? f?s ?i? j ; lv ?i? j ?ji ? 1; 2; ? ? ? g is a set of skill-level pairs involved in the job description, where s ?i? j is a skill and lv ?i? j is its level on the degree of mastery, for example Proficient in JavaScript. Considering that the relations between involved skills may affect job salary (e.g., a skill affects the job salary more if many skills related to it are also required), we attach S j with a skill graph A j , where each node represents an involved skill and the edge weights represent the co-appearing relations between them. Data preprocessing. We extracted 14 level words and 1374 IT-related skill words, so that the job descriptions can be formulated into structured records. The detailed descriptions of data preprocessing can be found in Supplementary Information. Then, we counted the co-appearing frequency of every two skills in the job advertisements. If the frequency is larger than a pre-defined threshold, we added an edge between these two skills, whose weight is the normalized co-appearing frequency. To reduce noise, we first filtered full-time job postings. Next, we ranked the cities according to the number of the samples they involve and filtered the job postings of the top 16 cities, which covers over 90% of the data. Then, we dropped the records whose upper-bound or lower-bound salary is a boxplot outlier <ref type="bibr" target="#b21">22</ref> in the dataset (see Supplementary Fig. <ref type="figure" target="#fig_3">S3</ref> for the salary distribution). Finally, we ranked the companies according to the number of involved samples and filtered job postings of the top 1000 companies. After the above preprocessing, we got 215,308 job postings. Based on the observable contexts, we extracted continuous and discrete features to form the input of the model. The detailed descriptions of feature extraction can be found in Supplementary Table <ref type="table" target="#tab_4">S4</ref> Context-aware skill valuation network Temporal skill embedding. Considering that the skills' traits change over time, CSVN assigns temporal embeddings for skills at each time interval. To reduce model complexity, we use the idea of Matrix Factorization <ref type="bibr" target="#b22">23</ref> and assume the skill embedding is composed of a low-ranked embedding and a latent projecting matrix. Formally, E ?t? s ? ?W us ? ?t? W vs ; t ? 1; 2; ? ? ? ; T; where E ?t? s 2 R N s de stores the skill embeddings of the t-th time interval, T is the number of time intervals, N s denotes the size of the skill vocabulary, ?W us ? ?t? 2 R N s dl is the low-ranked skill embeddings of the t-th time interval, W vs 2 R dl de is the latent projection shared by all the time intervals, de is the embedding dimension, dl is the number of latent factors. Though the temporal embedding gives CSVN the ability to model skills' dynamic changes, it brings higher model complexity. To avoid over-fitting, we add a temporal regularization to the model, formulated as</p><formula xml:id="formula_0">L t ? ? T?1 t?1 k ?E s ? ?t?1? ? ?E s ? ?t? k F ;<label>?1?</label></formula><p>where ? ? ? F denotes the Frobenious norm. L t constrains the temporal embeddings not to change sharply. With the temporal skill embedding, our model can distinguish the development and change on skill semantic over time and maintains low model complexity. However, it should also be noticed that our model is not a forecasting model as training data of each time period is needed to train the corresponding embedding.</p><p>Skill-context interaction extraction. To increase fitting ability, CSVN takes both continuous context vectors (e.g., salary statistics of a city) and discrete contexts (e.g., city index) as inputs. Then, inspired by the famous CTR prediction model DeepFM <ref type="bibr" target="#b23">24</ref> in the field of recommender system, CSVN extracts both deep and shallow interactions between these job contexts and the skill. Specifically, the input contexts are processed in different manners and go though linear projection, multiplicative operation and Multi-Layer Perceptron (MLP) to extract interaction of different orders. Formally, each continuous context i 2 C inputs a feature vector, written as o c i 2 R d i , where C denotes continuous job contexts. Each discrete context i 2 D inputs an index, CSVN encodes it into an one-hot representation o d i 2 R m i , where m i is the maximum possible value of this context. Then the linear projection extracts the first-order interaction as</p><formula xml:id="formula_1">h 1 ? ? i2C W cl i o c i ? ? i2D W dl i o d i ? W sl e s ? b l ;<label>?2?</label></formula><p>where e s 2 R de denotes the input skill's current embedding vector,</p><formula xml:id="formula_2">W cl i 2 R do 1 d i ; W dl i 2 R do 1 m i , W sl i 2 R do 1</formula><p>de and b l 2 R do 1 are the trainable parameters, do 1 is the output dimension. Then, multiplicative operation extracts the second-order interactions. Specifically, each discrete context i 2 D is first assigned with an embedding e d i ? o d i W e i where W e i 2 R m i de stores the value embeddings of context i. For continuous context i 2 C, we project the feature vector into the space of discrete job contexts, written as e c i ? o c i W p i ? b p ; where W p i 2 R d i de and b p 2 R de are trainable parameters. The multiplicative operation is formulated as</p><formula xml:id="formula_3">h 2 ? ? i2C ? i?j;j2C e c i e c j ? ? i2D ? i?j;j2D e d i e d j ? ? i2C ? j2D e c i e d j ? e s ? ? i2C e c i ? ? i2D e d i ?;<label>?3?</label></formula><p>where ? denotes element-wise multiplication. At last, MLP extracts the higher order information, which is tiled by several fully connected layers, formulated as</p><formula xml:id="formula_4">x ?0? ? o c 0 jo c 1 j ? ? ? je d 0 je d 1 je s ; x ?k? ? ??x ?k?1? ?W m ? ?k? ?; k ? 1; 2; ? ? ? ; K<label>?4?</label></formula><p>where K is the depth, ?W m ? ?k? 2 R d ?k?1? m d ?k? m and x (k) denotes the parameter and the output of the k-th layer, ? denotes the activation function, *|* denotes concatenating two vectors. We set the final output x (K) as the high-order interaction h 3 .</p><p>To provide context-skill representation for domination modeling, this MLP has a multi-head structure. Specifically, since outputs of the shallow layers are general context-skill interactions, while the whole MLP extracts value related information, the output of some shallow middle layer is fed into ASDN to extract domination related features. The details will be described in the salary prediction part.</p><p>Constrained value range modeling. CSVN estimates the value range by predicting its bounds. To assure that the predicted bounds can form a meaningful value range, we have two constraints. First, since skill value is a special case of salary, its lower bound is non-negative. Second, the upper-bound value is no less than the lowerbound value. We concatenate the extracted interaction of different orders, then estimate the range with two constrained linear projection, formulated as</p><formula xml:id="formula_5">v l ? ?h 1 jh 2 jh 3 W l ? b l ; v u ? ?h 1 jh 2 jh 3 W u ? b u ; s:t: 0 ? v l ? v u :<label>?5?</label></formula><p>As v l and v u are intermediate variables of SSCN, its whole training process becomes a constrained optimization. However, it is hard for deep learning models to deal with constraints. Though we can add a soft constraint regularization to the loss function, it cannot guarantee the constraints are strictly satisfied and can easily cause the model fail to converge. To avoid constrained optimization and enable gradient descent, we adjust the network structure so that the constraints are naturally satisfied. Specifically, we add a non-negative activation to the lowerbound output, formulated as</p><formula xml:id="formula_6">v l ? max??h 1 jh 2 jh 3 W l ? b l ; 0?:<label>?6?</label></formula><p>Next, instead of directly predicting the upper-bound value, we change the mission of the second linear projection to output the gap p between the bounds, the upper bound is thus calculated as v u = v l + p. The upper bound is guaranteed to be no smaller than the lower bound if we constrain the gap to be non-negative, formulated as p ? max??h 1 jh 2 jh 3 W g ? b g ; 0?:</p><p>Attentive skill domination network. In Fig. <ref type="figure" target="#fig_2">2d</ref>, we show the structure of ASDN. ASDN use features extracted by CSVN as the input, denoted by IA. From IA, it first independently extracts two kinds of skill representations with MLP. ASDN first extracts an important representation for each skill, which implicates the traits of the skill that impact their domination, e.g., some skills may be common and easy to become the major part of the jobs. Meanwhile, ASDN extracts an influence representation for each skill to model their influence on domination to each other. We use X imp 2 R N dp and X inf 2 R N di to denote the importance/influence representation, where each row of them is a skill's representation and N denotes the number of appeared skills.</p><p>ASDN supposes the domination of skill is affected by three factors, which are its own importance, the global influence from all the skills, and the local influence from the related skills. The global influence is calculated as the averaged influence vector of all the skills, written as Q ? 1 T X inf N ; where 1 2 R N s is a vector whose elements are all 1. The global influence is the same for all the skills, we regard it as the query in the attention mechanism. To model the influence from the neighboring skills, we apply a simple Graph Convolutional Network (GCN) <ref type="bibr" target="#b24">25</ref> on the skill graph to extract the local influence, formulated as</p><formula xml:id="formula_7">U ?0? ? X inf ; U ?k? ? ??AU ?k?1? ?W g ? ?k? ?; k ? 1; 2; ? ? ? ; K c ;<label>?7?</label></formula><p>where K c is the depth of GCN, A 2 R N N is the adjacency matrix of the skill graph, A i,j denotes the edge weight from skill i to skill j, U ?k? 2 R N d ?l? stores the output vectors of all the nodes in the k-th layer, d (k) is the output dimension, and</p><formula xml:id="formula_8">W g 2 R d ?k? d<label>?k?1?</label></formula><p>is the trainable parameter. We concatenate the importance vectors with the local influence vectors as the keys and calculates the dominations of each skill with an attention layer, formulated as</p><formula xml:id="formula_9">e a ? tanh QW q ? ?U ?K c ? jX imp W k W v ; a ? softmax?e a?;<label>?8?</label></formula><p>where a 2 R N , the element a i represents domination of the i-th skill, W q 2 R di da ; W k 2 R ?d ?k? ?dp? da and W v 2 R da are the trainable parameters. To guarantee that each skill has separate domination factors for lower-bound and upper-bound salary, ASDN trains two sets of the above attentional parameters.</p><p>Job salary prediction. For a job posting J j , SSCN models its job salary as the weighted average of the skill value. The lower bound salary e y l j and upper bound salary e y u j is estimated as e y l j ? ?</p><formula xml:id="formula_10">jS j j i ?v l ? ?i? j ?a l ?</formula><p>?i? j e y u j ? ?</p><formula xml:id="formula_11">jS j j i ?v u ? ?i? j ?a u ? ?i? j ;<label>?9?</label></formula><p>where ?v ? ? i j represents the value bound of the i-th skill in J j , ?a ? ? i j represents the corresponding domination factor. We set the loss function to be the difference between the predicted and the real salary bounds, formulated as</p><formula xml:id="formula_12">L s ? ? l jJ j ? jJ j j ?e y l j ? y l j ? 2 ? ? u jJ j ? jJ j j ?e y u j ? y u j ? 2 ;<label>?10?</label></formula><p>where y ? j denote the observation of job salary bounds, ? l and ? u are hyperparameters for balancing the importance of these two loss, jJ j denotes the job postings set.</p><p>Combining the L s with the skills' temporal regularizer L t , we formulate the loss function of SSCN as</p><formula xml:id="formula_13">L ? ? l jJ j ? j ?e y l j ? y l j ? 2 ? ? u jJ j ? j ?e y u j ? y u j ? 2 ? ? ? T?1 t?1 k E ?t?1? s ? E ?t? s k F ;<label>?11?</label></formula><p>where ? is a hyperparameter balancing the importance of the temporal regularizer.</p><p>Network configuration. The network configurations can be found in Table <ref type="table" target="#tab_4">4</ref>.</p><p>Since the lower-bound salary is smaller than the upper bound, we set ? l and ? u to be 2 and 1. The time regularizer ? was set to be 0.004. We use residual structure <ref type="bibr" target="#b25">26</ref> to accelerate the training and Leaky ReLU <ref type="bibr" target="#b26">27</ref> as the activation function. The weights are initialized with glorot normal initializer <ref type="bibr" target="#b27">28</ref> . For optimization, we use Adam optimizer <ref type="bibr" target="#b28">29</ref> . We found slight changes in parameters did not affect much on the performance. Specifically, the additional parameter experiments can be found in Supplementary Information.</p><p>Baseline methods for salary prediction. Our baseline methods for salary prediction including four parts:</p><p>? Classic regression models including linear regression (LR), Support Vector Machine (SVM), and Gradient Boosting Decision Tree (GBDT). Since these methods process the structured feature vectors of fixed size, we concatenated the one-hot skillset representation, the averaged features of skills, and job context as their input.</p><p>? Deep Neural Network with the same depth and a similar number of variables as SSCN for fairness of comparison. The input was also the concatenated feature vector.</p><p>? Holistic Salary Benchmarking Matrix Factorization (HSBMF) <ref type="bibr" target="#b29">30</ref> . HSBMF is the state-of-the-art salary benchmarking model. HSBMF groups the job advertisements into posts and predict their salary with matrix factorization. We used the job contextual information and skill requirements for building regularization matrices in HSBMF to assure it considers the same information as SSCN.</p><p>? State-of-the-art text mining-based methods. We compared two groups of typical methods that model the job postings as texts. The first group consists of well-adopted Natural Language Processing (NLP) network architectures trained in an end-to-end manner with our data, including Convolutional Neural Network (TextCNN) <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32</ref> , Hierarchical Attention Network (HAN) <ref type="bibr" target="#b32">33</ref> , and the recently proposed Transformer-XL <ref type="bibr" target="#b33">34</ref> . In these models, we used pretrained Chinese word embeddings <ref type="bibr" target="#b34">35</ref> to initialize the parameters. The second group consists of state-of-the-art pre-trained models, including Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" target="#b35">36</ref> , Robustly optimized BERT approach (RoBERTa) <ref type="bibr" target="#b36">37</ref> , and XLNet 38 . To better process our input data, we have adopted models trained with Chinese corpus <ref type="bibr" target="#b38">39</ref> .</p><p>We also disabled some parts of SSCN to show their effectiveness, including two parts:  [16, 16, 16]  GCN layers [16, 16]  Importance MLP [16, 16, 16]  formulated the problem of Salary-Skill Value Composition Problem. Y.S. designed and implemented Salary-Skill Network under the guidance of F.Z.Z. and H.S.Z. Q.Z. gave important advice on model structure. Y.S. and Q.Z. processed the data. Y.S., F.Z.Z., and H.S.Z. conceived the experiments and evaluated the results. F.Z.Z., H.S.Z., Q.H. and H.X. advised on the literature review, data process and technical design of this work. Y.S., H.S.Z. and H.X. wrote the paper. H.S.Z., F.Z.Z. and H.X. managed this project.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>?i? j ; lv ?i? j ; v ?i? j ?ji ? 1; 2; ? ? ? g; C j j??; where ? and ? denote the parameters, v ?i? j ? f ?s ?i? j ; lv ?i? j ; C j j??. By comparing the predicted job salary with the real salary, both the skill value assessment model f and skill-based salary prediction model g can be trained simultaneously.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 A</head><label>1</label><figDesc>Fig.1A schematic diagram of the key idea in this study.(1) Our main task is to train a skill valuation model with machine learning technology. Under the paradigm of supervised learning, we need a set of training data with explicit labels of skill value to provide supervision for the model. Then the model can learn a function that maps the input (i.e., context and skills) to the observation (i.e., skill value). However, the labeled data of skill value is unavailable in our dataset.(2) We have abundant data of job postings with labels of salary, which can provide supervision for training a salary prediction model. Therefore, with the intuition that valuable skills should lead to high job salary, we regard salary prediction as a cooperative task that provides indirect supervision for skill valuation model. (3) We propose a model, SSCN, to simultaneously achieve skill valuation and salary prediction tasks, where the skill valuation model is a component of the salary prediction model. Specifically, SSCN estimates the skill value and composes skill value into job salary. In this way, the skill valuation model can be trained with feedbacks from the salary prediction task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 A</head><label>2</label><figDesc>Fig. 2 A schematic diagram of SSCN based skill valuation framework. a An example of job posting in our data, which consists of some structured contextual information (e.g., company name, timestamp of publishing, work location, and required working experience), expected range of monthly salary (i.e., lower/upper bound in RMB), and detailed job description that introduces the requirements on candidates' job skills. In particular, each skill usually has a descriptive requirement on the degree of mastery, such as Proficient in JavaScript, and Familiar with AS. b We formulate the job posting as a set of skills formed in a skill graph, and some contextual inputs. Our proposed SSCN estimates skill value and combines them into the job salary. The color gray, blue, yellow and pink indicate inputs, model structures, outputs, and loss functions, respectively. c The detailed structure of CSVN. d The detailed structure of ASDN.</figDesc><graphic url="image-1.png" coords="4,73.84,154.34,183.40,194.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Skill valuation concerning different job contests. a We calculated the influence of level lv as r lv s ? ? i;j 1flv ?i? j ?lvg?v ?i? j ?v s ?i? j ?=v s ?i? j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Visualizations skill salary decompositions. a We calculated the averaged context-aware skill value estimated by CSVN and drew word cloud of machine learning-related skills, where the size of each word shows the skill value. b Similar to the word cloud of skill value, we drew word cloud for averaged skill domination estimated by ASDN. c For each skill in a job posting, we can calculate the actual salary contribution of it by calculating the multiplication of its value and domination, and show the averaged contribution of each skill on the word cloud. d A case study on a job posting, the role of each skill is analyzed by calculating their domination, contribution, and influence on job salary. The color of words in the job description shows the skills' influence on salary, blue/yellow/red means the salary will increase/remain/decrease by dropping the skill. The pie plots show skill domination and contribution where the colors distinguish different skills.</figDesc><graphic url="image-2.png" coords="8,66.40,55.79,437.08,227.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The level influence on 6 kinds of programming skills.</figDesc><table><row><cell>p-value</cell><cell>0.326</cell><cell>0.040</cell><cell>0.005</cell><cell>0.485</cell><cell>0.948</cell><cell>0.006</cell></row><row><cell>Rich</cell><cell>8.61%</cell><cell>9.29%</cell><cell>10.91%</cell><cell>10.59%</cell><cell>0.19%</cell><cell>65.44%</cell></row><row><cell>p-value</cell><cell>0.365</cell><cell>0.210</cell><cell>0.010</cell><cell>0.609</cell><cell>&lt;0.001</cell><cell>0.051</cell></row><row><cell>Understand</cell><cell>3.88%</cell><cell>-14.67%</cell><cell>-15.96%</cell><cell>13.42%</cell><cell>12.30%</cell><cell>61.15%</cell></row><row><cell>p-value</cell><cell>0.034</cell><cell>0.856</cell><cell>0.204</cell><cell>0.007</cell><cell>&lt;0.001</cell><cell>0.411</cell></row><row><cell>Familiar</cell><cell>-1.27%</cell><cell>0.15%</cell><cell>-0.41%</cell><cell>-3.19%</cell><cell>-3.06%</cell><cell>-1.50%</cell></row><row><cell>p-value</cell><cell>0.835</cell><cell>0.413</cell><cell>0.038</cell><cell>&lt;0.001</cell><cell>&lt;0.001</cell><cell>0.023</cell></row><row><cell>Can use</cell><cell>-0.33%</cell><cell>1.93%</cell><cell>-1.49%</cell><cell>15.73%</cell><cell>-5.10%</cell><cell>10.73%</cell></row><row><cell>p-value</cell><cell>&lt;0.001</cell><cell>0.026</cell><cell>0.540</cell><cell>0.913</cell><cell>&lt;0.001</cell><cell>0.127</cell></row><row><cell>Know</cell><cell>8.11%</cell><cell>-9.33%</cell><cell>-0.81%</cell><cell>-0.57%</cell><cell>-5.24%</cell><cell>-10.86%</cell></row><row><cell>Value</cell><cell>15.74</cell><cell>12.58</cell><cell>18.43</cell><cell>21.41</cell><cell>19.57</cell><cell>9.35</cell></row><row><cell>Skill</cell><cell>JavaScript</cell><cell>c/c++</cell><cell>Python</cell><cell>scala</cell><cell>Java</cell><cell>c#</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Performance evaluation on salary prediction.Bold formatting indicates the best performance among all these models. 10 times of hold-out validation were repeated on each model, where we randomly split the data for training and testing with a ratio of 4:1 at each time. The results of RMSE and MAE are listed in the form of mean ? standard deviation.</figDesc><table><row><cell>Model</cell><cell>Lower</cell><cell></cell><cell>Upper</cell><cell></cell></row><row><cell></cell><cell>RMSE</cell><cell>MAE</cell><cell>RMSE</cell><cell>MAE</cell></row><row><cell>SVM</cell><cell>5.675 ? 0.215</cell><cell>4.120 ? 0.028</cell><cell>10.404 ? 1.202</cell><cell>7.177 ? 0.038</cell></row><row><cell>LR</cell><cell>5.386 ? 0.021</cell><cell>4.033 ? 0.013</cell><cell>9.545 ? 0.049</cell><cell>7.139 ? 0.028</cell></row><row><cell>GBDT</cell><cell>4.878 ? 0.023</cell><cell>3.651 ? 0.017</cell><cell>8.763 ? 0.032</cell><cell>6.568 ? 0.027</cell></row><row><cell>DNN</cell><cell>6.498 ? 0.031</cell><cell>4.999 ? 0.036</cell><cell>11.801 ? 0.021</cell><cell>9.460 ? 0.020</cell></row><row><cell>HSBMF</cell><cell>5.291 ? 0.017</cell><cell>3.939 ? 0.015</cell><cell>9.188 ? 0.036</cell><cell>6.800 ? 0.028</cell></row><row><cell>TextCNN</cell><cell>4.999 ? 0.028</cell><cell>3.712 ? 0.018</cell><cell>8.800 ? 0.057</cell><cell>6.554 ? 0.057</cell></row><row><cell>HAN</cell><cell>4.761 ? 0.043</cell><cell>3.497 ? 0.054</cell><cell>8.333 ? 0.069</cell><cell>6.111 ? 0.092</cell></row><row><cell>Transformer-XL</cell><cell>5.459 ? 0.016</cell><cell>4.097 ? 0.045</cell><cell>9.663 ? 0.061</cell><cell>7.278 ? 0.074</cell></row><row><cell>BERT</cell><cell>4.592 ? 0.010</cell><cell>3.331 ? 0.011</cell><cell>8.110 ? 0.136</cell><cell>5.841 ? 0.137</cell></row><row><cell>RoBERTa</cell><cell>4.642 ? 0.014</cell><cell>3.377 ? 0.011</cell><cell>8.400 ? 0.076</cell><cell>6.122 ? 0.058</cell></row><row><cell>XLNet</cell><cell>4.566 ? 0.015</cell><cell>3.333 ? 0.011</cell><cell>8.254 ? 0.060</cell><cell>5.995 ? 0.044</cell></row><row><cell>CSVN + Mean</cell><cell>6.758 ? 0.041</cell><cell>5.085 ? 0.038</cell><cell>11.46 ? 0.118</cell><cell>8.640 ? 0.084</cell></row><row><cell>SSCN (Independ)</cell><cell>4.762 ? 0.063</cell><cell>3.484 ? 0.052</cell><cell>8.278 ? 0.091</cell><cell>6.021 ? 0.079</cell></row><row><cell>SSCN</cell><cell>4.435 ? 0.061</cell><cell>3.244 ? 0.048</cell><cell>7.686 ? 0.086</cell><cell>5.627 ? 0.060</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Skill's average influence on salary.</figDesc><table><row><cell>Skill</cell><cell>Salary</cell><cell>Value</cell><cell>Domination</cell><cell>Influence</cell></row><row><cell>Matrix calculation</cell><cell>19.872</cell><cell>32.306</cell><cell>25.2%</cell><cell>+18.4%</cell></row><row><cell>POS Analysis</cell><cell>22.994</cell><cell>29.179</cell><cell>29.5%</cell><cell>+15.6%</cell></row><row><cell>Information theory</cell><cell>21.425</cell><cell>26.794</cell><cell>28.7%</cell><cell>+13.7%</cell></row><row><cell>Computational</cell><cell>20.725</cell><cell>24.632</cell><cell>23.8%</cell><cell>+12.0%</cell></row><row><cell>linguistics</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Voiceprint</cell><cell>20.694</cell><cell>33.235</cell><cell>10.2%</cell><cell>+8.8%</cell></row><row><cell>recognition</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>plsa</cell><cell>23.600</cell><cell>28.043</cell><cell>14.5%</cell><cell>+4.7%</cell></row><row><cell>xgboost</cell><cell>21.300</cell><cell>29.211</cell><cell>7.8%</cell><cell>+3.6%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>.</head><label></label><figDesc>Overall process. The pseudocode of the overall model training and applying process of this paper can be found in Algorithm 1. Y pred , Y true ? empty lists; 12: for each (skillset, context, y) ? D test do 13: Predict salary range e y ? M?skillset; context; ??; 14: Store e y in Y pred ; 15: Store y in Y true ; 16: Calculate MAE(Y pred , Y true ) and RMSE(Y pred , Y true ); 17: /**Value Estimation**/ 18: For (skillset, context, y) ? D train ? D test do 19: For each (level, skill) ? skillset do 20: Estimate value v and domination d for (level, skill, context) with M??; ??. 21: Analyze skill value;</figDesc><table><row><cell cols="2">Algorithm 1. Overall process</cell><cell></cell></row><row><cell cols="3">Require: D train : training set; D test : testing set; ?: learning rate; MaxIter: the number</cell></row><row><cell cols="2">of training iterations.</cell><cell></cell></row><row><cell cols="2">1: Build model M with initial parameter ?;</cell><cell></cell></row><row><cell cols="2">2: /**Training**/</cell><cell></cell></row><row><cell cols="2">3: For it ? 1 ? MaxIter do</cell><cell></cell></row><row><cell cols="3">4: S batch ? randomly split D train into batches;</cell></row><row><cell cols="2">5: For each D batch ? S batch do</cell><cell></cell></row><row><cell>6:</cell><cell>d? = 0;</cell><cell></cell></row><row><cell>7:</cell><cell cols="2">For each (skillset, context, y) ? D batch do</cell></row><row><cell>8: 9:</cell><cell>d? ? d? ? ?Loss?M?skillset;context;??;y? ?? ? = ? -?d?;</cell><cell>;</cell></row><row><cell cols="2">10: /**Validation**/</cell><cell></cell></row><row><cell>11:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>The network configurations.</figDesc><table><row><cell>Name</cell><cell>Value</cell><cell>Name</cell><cell>Value</cell></row><row><cell cols="2">Embedding Size 16</cell><cell cols="2">Latent Factor Size 6</cell></row><row><cell>CSVN MLP</cell><cell cols="2">[64, 64, 64, 16, 16, 16] Shared Depth</cell><cell>3</cell></row><row><cell>Influence MLP</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>NATURE COMMUNICATIONS | (2021) 12:1992 | https://doi.org/10.1038/s41467-021-22215-y | www.nature.com/naturecommunications</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank the members of the <rs type="institution">Baidu Talent Intelligence Center</rs> for their support, ideas, and encouragement. The research work supported by the <rs type="funder">National Key Research and Development Program of China</rs> (Grant No. <rs type="grantNumber">2018YFB1004300</rs>), the <rs type="funder">National Natural Science Foundation of China</rs> (Grant Nos. <rs type="grantNumber">U1836206</rs>, <rs type="grantNumber">U1811461</rs>, <rs type="grantNumber">61773361</rs>, <rs type="grantNumber">91746301</rs>, and <rs type="grantNumber">61836013</rs>), the <rs type="funder">Project of Youth Innovation Promotion Association CAS</rs> (Grant No. <rs type="grantNumber">2017146</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QeM2Gcw">
					<idno type="grant-number">2018YFB1004300</idno>
				</org>
				<org type="funding" xml:id="_88mZa26">
					<idno type="grant-number">U1836206</idno>
				</org>
				<org type="funding" xml:id="_JbYhsTR">
					<idno type="grant-number">U1811461</idno>
				</org>
				<org type="funding" xml:id="_RwzEwCU">
					<idno type="grant-number">61773361</idno>
				</org>
				<org type="funding" xml:id="_MtXqQZv">
					<idno type="grant-number">91746301</idno>
				</org>
				<org type="funding" xml:id="_48s3qPP">
					<idno type="grant-number">61836013</idno>
				</org>
				<org type="funding" xml:id="_pGbck24">
					<idno type="grant-number">2017146</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>The job posting data that support the findings of this study are available in figshare with the identifier "10.6084/m9.figshare.14060498" <ref type="bibr" target="#b39">40</ref> . All data generated or analyzed during this study are included in this published article (and its Supplementary information files). Source data are provided with this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p>Codes of this paper are available in CodeOcean with the identifier "10.24433/ CO.0239280.v1" <ref type="bibr" target="#b40">41</ref> .</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>? "CSVN + Mean", where we replaced ASDN a mean pooling layer.</p><p>? "SSCN (Independ)", where we disabled the range prediction part and train the models for the upper bound and lower bound independently.</p><p>For all the compared methods that are not designed for range prediction, we separately train the lower-bound and upper-bound regression model with them and validate their performances independently.</p><p>Validation. We repeated 10 times of hold-out validation on the models. Specifically, at each time, we randomly split the data into training and testing set with a ratio of 4:1. We used the training data for model training and used the testing data for performance evaluation.</p><p>Reporting summary. Further information on research design is available in the Nature Research Reporting Summary linked to this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>This work was accomplished when Y.S. and Q.Z. working as interns in Baidu supervised by H.S.Z. H.S.Z. came up with the idea of market-oriented skill valuation. Y.S. and H.S.Z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>H.S.Z. is currently affiliated with Baidu. Y.S. and Q.Z. are currently affiliated with Baidu as research interns. The other authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary information</head><p>The online version contains supplementary material available at https://doi.org/10.1038/s41467-021-22215-y.</p><p>Correspondence and requests for materials should be addressed to F.Z., H.Z. or H.X.</p><p>Peer review information Nature Communications thanks Fabio Mercorio and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p><p>Reprints and permission information is available at http://www.nature.com/reprints Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A conservation of resources perspective on career hurdles and salary attainment</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vocat. Behav</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="156" to="168" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Trade liberalization and the skill premium: a local labor markets approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dix-Carneiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Kovak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Econ. Rev</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="551" to="557" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">International trade, technology, and the skill premium</title>
		<author>
			<persName><forename type="first">A</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Political Econ</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="1356" to="1412" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring the popularity of job skills in recruitment market: A multi-criteria approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI 2018</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Trend-aware tensor factorization for job skill demand analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Skill-biased technological change and rising wage inequality: some problems and puzzles</title>
		<author>
			<persName><forename type="first">D</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dinardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Labor Econ</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="733" to="783" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Oecd skills outlook 2013: first results from the survey of adult skills</title>
		<author>
			<persName><forename type="first">R</forename><surname>Desjardins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Econom</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1144" to="1168" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Skills matter: Further results from the survey of adult skills. oecd skills studies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kankara?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paccagnella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quintini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Thorn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>OECD Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interview choice reveals your preference on the market: to improve job-resume matching through profiling memories</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM KDD 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Person-job fit: Adapting the right talent for the right job with joint representation learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Management Information Systems</title>
		<imprint>
			<biblScope unit="issue">TMIS</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Boselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mercorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mezzanzanica</surname></persName>
		</author>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="330" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wolmis: a labor market intelligence system for classifying web job vacancies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Boselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. intell. inform. Syst</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="477" to="502" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m">for the Development of Vocational Training (Cedefop), E. C. The online job vacancy market in the eu: driving forces and emerging trends</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">for the Development of Vocational Training (Cedefop), E. C. Online job vacancies and skills analysis: a cedefop pan-european approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Skills in demand for ict and statistical occupations: Evidence from web-based job vacancies</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Lovaglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mercorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mezzanzanica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Anal. Data Min</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="78" to="91" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Applying machine learning tools on web vacancies for labour market and skill analysis. Terminator or the Jetsons?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mercorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mezzanzanica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Economics and Policy Implications of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Career path development for the most wanted skills in the mis job market</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Arnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Litecky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Syst. Manag</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Advantages of the mean absolute error (mae) over the root mean square error (rmse) in assessing average model performance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Willmott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Matsuura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clim. Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="79" to="82" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcgowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Andrews</surname></persName>
		</author>
		<title level="m">Skill mismatch and public policy in oecd countries</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Developing generic skills through university study: a study of arts, science and engineering in australia</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Badcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Pattison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="441" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Council</surname></persName>
		</author>
		<title level="m">Education for Life and Work: Developing Transferable Knowledge and Skills in the 21st Century</title>
		<imprint>
			<publisher>National Academies Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">How significant is a boxplot outlier?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dawson</surname></persName>
		</author>
		<ptr target="https://www.amstat.org/publications/jse/v19n2/dawson.pdf" />
	</analytic>
	<monogr>
		<title level="j">J. Stat. Educ</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Algorithms for non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deepfm: a factorization-machine based neural network for ctr prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence<address><addrLine>Sierra, C; California</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1725" to="1731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations (ICLR</title>
		<meeting>the 5th International Conference on Learning Representations (ICLR<address><addrLine>California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR 2016</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. icml</title>
		<meeting>icml</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations<address><addrLine>California</addrLine></address></meeting>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Intelligent salary benchmarking for talent recruitment: A holistic matrix factorization approach</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICDM 2018</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="649" to="657" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</title>
		<meeting>the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Transformer-XL: Attentive language models beyond a fixedlength context</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2978" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Analogical reasoning on chinese morphological and semantic relations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Short Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="138" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1907.11692v" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5753" to="5763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Revisiting pre-trained models for Chinese natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="657" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://figshare.com/articles/dataset/Job_Posting_Data/14060498/1" />
		<title level="m">Job posting data</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Market-oriented job skill valuation with cooperative composition neural network (code)</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://codeocean.com/capsule/7695173/tree/v1" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
