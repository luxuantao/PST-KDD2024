<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data-driven cybersecurity incident prediction: A survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nan</forename><surname>Sun</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jun</forename><surname>Zhang</surname></persName>
							<email>junzhang@swin.edu.au</email>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Rimba</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shang</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Xiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Leo</surname></persName>
						</author>
						<author>
							<persName><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Deakin University</orgName>
								<address>
									<addrLine>Waurn Ponds, VIC 3216</addrLine>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Software and Electrical Engineering</orgName>
								<orgName type="institution">Swinburne University of Technology</orgName>
								<address>
									<postCode>3122</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">CSIRO</orgName>
								<address>
									<postCode>2015</postCode>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Swinburne University of Technology</orgName>
								<address>
									<postCode>3122</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data-driven cybersecurity incident prediction: A survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E1915C8D9E2859A82F3056FC54CE467D</idno>
					<idno type="DOI">10.1109/COMST.2018.2885561</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2018.2885561, IEEE Communications Surveys &amp; Tutorials IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS 1 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/COMST.2018.2885561, IEEE Communications Surveys &amp; Tutorials IEEE COMMUNICATIONS SURVEYS &amp; TUTORIALS 2</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cybersecurity incidents</term>
					<term>data mining</term>
					<term>datadriven</term>
					<term>discovery</term>
					<term>machine learning</term>
					<term>prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Driven by the increasing scale and high profile cybersecurity incidents related public data, recent years we have witnessed a paradigm shift in understanding and defending against the evolving cyber threats, from primarily reactive detection towards proactive prediction. Meanwhile, governments, businesses, and individual internet users show the growing public appetite to improve cyber resilience that refers to their ability to prepare for, combat and recover from cyber threats and incidents. Undoubtedly, predicting cybersecurity incidents is deemed to have excellent potential for proactively advancing cyber resilience. Research communities and industries have begun proposing cybersecurity incident prediction schemes by utilizing different types of data sources, including organization's reports and datasets, network data, synthetic data, data crawled from webpages, and data retrieved from social media. With a focus on the dataset, this survey paper investigates the emerging research by reviewing recent representative works appeared in the dominant period. We also extract and summarize the datadriven research methodology commonly adopted in this fastgrowing area. In consonance with the phases of the methodology, each work that predicts cybersecurity incident is comprehensively studied. Challenges and future directions in this field are also discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>C YBERsecurity incident as an ever-present threat to or- ganizations, governments, and enterprises is increasing in frequency, scale, sophistication and severity <ref type="bibr" target="#b0">[1]</ref>. Like natural disasters (e.g., hurricanes, floods, and earthquakes) and human-made disasters (e.g., military nuclear accidents and financial crashes), cybersecurity incidents that involve extreme events can lead to unintended consequences or even catastrophic damage <ref type="bibr" target="#b1">[2]</ref>. A cybersecurity incident can be defined as an event whereby an intruder employs a tool to implement an action that exploits a vulnerability on an objective, making an unauthorized outcome that satisfies the attacker's intentions <ref type="bibr" target="#b2">[3]</ref>. According to the latest Australia Cyber Security Center (ACSC) survey <ref type="bibr" target="#b3">[4]</ref>, 90% organizations suffered from some form of attempted or successful cybersecurity compromises during the 2015-2016 financial year. Furthermore, over half of the organizations (58%) experienced at least one cybersecurity incident that successfully compromised their data or system <ref type="bibr" target="#b3">[4]</ref>.</p><p>Under urgent threats from cybersecurity incidents, the good news is that research communities and industries are well aware of these cybersecurity threats and show great foresight in building cyber resilience. The 2018 Annual Cyber Security report <ref type="bibr" target="#b4">[5]</ref> published by Cisco indicates that organizations and enterprises have implemented cyber-awareness programmes, including looking for outsourcing service to strengthen defenses on cybersecurity incidents <ref type="bibr" target="#b5">[6]</ref>. For instance, 49% global respondents outsourced monitoring service as part of their cyber preparation strategy in 2017, compared with 44% in 2015. Suppose the incidents can be predicted in advance, the governments, businesses, Information and Communication Technology (ICT) providers, and even individual users can be protected from damages caused by security issues. Hence, proactively predicting cybersecurity incident is deemed as a potential and immediate problem that imperatively demands to solve. That is to say, cybersecurity incident prediction is entirely an area of research that is in the exciting early development.</p><p>At present, no system can be considered invulnerable. The security community has begun to realize that the current evolution is a never-ending competition between attackers and defenders. Therefore, it is significant to foreshadow the threat in advance, which prioritizes recommendations to organizations, and as such reduces damage from various kinds of cyber attacks. To date, numerous works have extensively studied various aspects of cybersecurity incidents and threats. They focus on analysis, detection, and prevention. However, few exhibited prediction schemes that can provide proactive measures to avoid the damage. These works utilized website features <ref type="bibr" target="#b6">[7]</ref>  <ref type="bibr" target="#b7">[8]</ref>, incident reports <ref type="bibr" target="#b8">[9]</ref>, log files <ref type="bibr" target="#b9">[10]</ref> or other security postures to predict cybersecurity incidents. The corresponding techniques are focused on machine learning (ML), data mining (DM), deep learning, and graph mining, which are specifically illustrated in Sections II and III. A representative result is that the RiskTeller system proposed in <ref type="bibr" target="#b9">[10]</ref> which can achieve 96% true positive rates (TPRs, the proportion of actual positives that are correctly identified as such) for predictions at a machinelevel granularity. The results of these studies are promising and suggest the possibility of accurately anticipating cybersecurity incidents, which is crucial to strengthen cyber resilience.</p><p>Furthermore, faced with the constant stream of news on cybersecurity incidents, the industrial circles also actively seek for proactive defenses. Usually, businesses adopt multiple layers of security protection to prioritize the entities which are at high risk of being attacked and to minimize the damages caused by incidents. As we observed, there are two kinds of businesses that are dedicated to cybersecurity by deploying the prediction model: one is to help companies find and stop cyber attacks before they cause harm, another is to incorporate cyber insurance after risk assessment. Both had been developing steadily in recent years. For instance, Chronicle <ref type="bibr" target="#b10">[11]</ref> is a new business that is devoted to cybersecurity by utilizing machine learning and cloud computing techniques. BizCover <ref type="bibr" target="#b11">[12]</ref> is an insurance company that will cover expenses on cybersecurity incidents.</p><p>There are several survey papers which are devoted to investigating different kinds of security threats and attempting to mitigate damage caused by security incidents reactively. Jang-Jaccard et al. <ref type="bibr" target="#b12">[13]</ref> studied the existing security vulnerabilities and critically analyzed the mitigation techniques in their survey paper. Liu et al.'s survey <ref type="bibr" target="#b13">[14]</ref> was the latest one that identified cyber insider threats and looked into a large number of systems and schemes against insider threats. Moreover, Buczak et al. <ref type="bibr" target="#b14">[15]</ref> focused on data mining and machine learning methods for cybersecurity intrusion detection. They provided thorough descriptions of the ML/DM methods and their applications in cybersecurity to readers. All of these works contribute to the understanding of the emerging cyber threats and supply comprehensive reactive detection guides. However, when a cybersecurity threat is detected, there is a high possibility that severe damages have already been caused, such as data leakage, financial losses, and even reputation damages <ref type="bibr" target="#b3">[4]</ref>. Proactively predicting cyber incidents based on observed indicators of cybersecurity threats can fill the gap, which motivates us to perform a literature review of existing cybersecurity incident prediction work.</p><p>Different from existing arts that focus on detection, the scope of this survey paper mainly emphasizes on cybersecurity incident prediction. To make it clear, one may think that the distinction between detection and prediction can be analogous to the circumstance of diagnosing the sickness of a patient (e.g., by applying biopsy) and predicting whether a currently healthy person will suffer from a specific disease in future (e.g., by using genetic testing) <ref type="bibr" target="#b8">[9]</ref>. In more detail, detection usually leverages identified features of a target to be detected, while prediction leans on the factors believed to connect with the prediction objective <ref type="bibr" target="#b8">[9]</ref>. From the consequences and applications point of view, detection enables to detect and mitigate threats while prediction understands the riskiest parts of a given system, acts proactively and provides the administrator with a vulnerability index used for defending and hardening their network. Furthermore, discovering an unknown is also defined as a kind of prediction in this survey. Compared to time-based prediction, discovery has a more general goal, which utilizes numerous amount of data to extract previously unknown or potentially useful new knowledge <ref type="bibr" target="#b15">[16]</ref>.</p><p>In a nutshell, this survey is based on 19 core papers which utilize data from different domains to forecast and discover cyber incidents. Paper selection focuses on English publications that meet specified inclusion criteria. Queries on four cybersecurity top conferences were performed using "predict" and "incident", "forecast" and "incident", and "discover" and "incident". The four conferences, including ACM Computer and Communications Security (CCS), IEEE Symposium on Security and Privacy (S&amp;P), the Network and Distributed System Security (NDSS) and Usenix Security Symposium, are deemed as the top four cybersecurity conferences by security research communities. However, it was recognized that this emphasis might overlook papers appeared in other conferences or journals. Based on the collected papers, we also distilled the references of these papers and those that referenced the collected papers. To catch up with the trend of cyber incident prediction, as well as to cover new and emerging datasets, we try our best to include representative works published in recent years in this survey. In short, this survey is intended to introduce the new rising topic to readers, attract and appeal for more readers to begin research in this field. For this aim, great emphasis is placed on a thorough description of existing work, and references to primary datasets for each work are provided.</p><p>When trying to predict cybersecurity incidents, it should be understood that data plays the crucial role in the process of analyzing cyber threats, modeling prediction problems and discovering security incidents. Driven by more and more publicly available data, predicting security trend and discovering indicators of cyber incidents seem to be much more feasible than ever before. From the collected literature, the data sources can be categorized as follows: <ref type="bibr" target="#b0">(1)</ref> Organization reports and datasets: some organizations regularly update their datasets or reports to publish security-related information. For example, VERIS Community Database (VCDB) <ref type="bibr" target="#b16">[17]</ref> records security incidents in a common format. Important examples that leverage organization reports or datasets as their data source include <ref type="bibr" target="#b8">[9]</ref> [18] <ref type="bibr" target="#b18">[19]</ref>. <ref type="bibr" target="#b1">(2)</ref> Executables datasets: Executable code, file or program that is able to run by a computer is served as the dataset in work <ref type="bibr" target="#b19">[20]</ref> [21] <ref type="bibr" target="#b21">[22]</ref>. (3) Network datasets: network datasets typically record the structure, properties, traffic or symptoms of a network. Specifically, there are four kinds of network datasets in this survey: log files <ref type="bibr" target="#b22">[23]</ref>, network mismanagement symptoms <ref type="bibr" target="#b23">[24]</ref>, temporal networks from different domains <ref type="bibr" target="#b24">[25]</ref> and network traffic <ref type="bibr" target="#b25">[26]</ref>. (4) Synthetic datasets: synthetic data is generated according to specific needs and under certain conditions. In <ref type="bibr" target="#b24">[25]</ref>  <ref type="bibr" target="#b26">[27]</ref>, the prediction model was established and evaluated by using synthetic data. <ref type="bibr" target="#b4">(5)</ref> Webpage data: web contents crawled from webpages can also be used as data source as shown in paper <ref type="bibr" target="#b6">[7]</ref> [8] <ref type="bibr" target="#b27">[28]</ref>. <ref type="bibr" target="#b5">(6)</ref> Social media data: social media is a platform that covers up-to-date insights and information from users around the world. Existing studies in <ref type="bibr" target="#b28">[29]</ref>  <ref type="bibr" target="#b29">[30]</ref> [31] <ref type="bibr" target="#b31">[32]</ref>  <ref type="bibr" target="#b32">[33]</ref> collected data from Tweets, articles and reviews. <ref type="bibr" target="#b6">(7)</ref> Mixedtype datasets: some examples in <ref type="bibr" target="#b24">[25]</ref>  <ref type="bibr" target="#b31">[32]</ref> [33] made use of two or more of the above data sources as mixed-type datasets to collect groundtruth, set up model and conduct validation. Corresponding to the above six types of data sources, we emphasize on the thorough description of the datasets and provide references to seminal work for each dataset.</p><p>Our contributions:</p><p>• The principal contribution is the collection and investigation of state-of-the-art cybersecurity incident prediction schemes, methods and datasets, which highlights the existing work in this field. • The collected works are novelty classified into six categories according to utilized datasets: organization reports and dataset, network dataset, synthetic dataset, webpage data, social media data, and mixed-type data. The datasets used in each work are identified and referenced in minute detail and depicted in the form of tables for clarification. • The modeling methodology commonly adopted by cybersecurity incident prediction is summarized. As stated in each phase of the methodology, challenges and future directions are discussed. This survey is organized as follows. Firstly, Section II summarizes the overview of cybersecurity incident prediction, including the definition of cybersecurity incident and research methodology. Section III presents a detailed view of existing work in the area of cybersecurity incident prediction according to our categorized datasets. In line with the research methodology, Section IV discusses the challenges &amp; future direction in this area. Finally, Section V concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OVERVIEW OF CYBERSECURITY INCIDENT PREDICTION</head><p>In this section, an overview of cybersecurity incident prediction is given in the following two specifications: the definition of cybersecurity incident and the research methodology for prediction. The definition aims to clarify the meaning of cybersecurity incident prediction as well as to determine the scope of this survey. Moreover, the definition contributes to the explanation of the methodology deployed in this field, providing the roadmap for researchers who want to engage in related fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cybersecurity incident definition</head><p>There are many definitions of the term "cybersecurity incident" in the literature. This raises the challenge of giving a standard definition and taxonomy for describing incidents and limiting the scope of the survey paper. Particularly, the definition of "incident" varies from team to team and from project to project. Sample definitions in literature review are as follows: (1) a general definition for a cybersecurity incident might be "any real or suspected adverse event in relation to the security of computer systems or computer networks" <ref type="bibr" target="#b33">[34]</ref>; (2) Australian Computer Emergency Response Team (AusCERT) <ref type="bibr" target="#b34">[35]</ref> defined an incident as "any type of computer network attack, computer-related crime, and the misuse or abuse of network resources or access"; (3) the SANS Institute <ref type="bibr" target="#b35">[36]</ref> and Department of the Navy <ref type="bibr" target="#b36">[37]</ref> described an incident as "an adverse event in an information system and/or network, or the threat of the occurrence of such an event" in their incident response guidebooks; (4) Computer Security Incident Response Team (CSIRT) <ref type="bibr" target="#b37">[38]</ref> defined the incident as "unauthorized activity against a computer or network that results in a violation of a security policy". Based on the above definitions, one can conclude that although there are many definitions of "incidents", all of these show a substantial content of similarities. Hence, in this survey, we define the cybersecurity Furthermore, the term "cybersecurity incident" has been defined with appropriate taxonomy in a few literature <ref type="bibr" target="#b38">[39]</ref> [40] <ref type="bibr" target="#b40">[41]</ref>. A list of single and defined terms is a popularly adopted taxonomy as a simple and clear method. David et al. <ref type="bibr" target="#b38">[39]</ref> used a list that includes 24 terms to define a cybersecurity incident, such as "Viruses and Worms", "Unauthorized Data Copying", "Logic Bombs" and "Denial-of-Service". Although this classification is easy to implement, for covering all types of cyber incidents, the list needs to contain encyclopedic volumes of defined terms. Besides, the definitions of some specific terms are hard to accept. Consequently, some literature employed a list of categories to define cyber incidents <ref type="bibr">[40] [41]</ref>. According to Computer Security Incident Handling Guide published by U.S. National Institute of Standards and Technology (NIST) <ref type="bibr" target="#b39">[40]</ref>, incidents are tagged into four types: Denial of Service (DoS), malicious code, unauthorized access, or inappropriate usage. Furthermore, some taxonomies focus on the action of cybersecurity incident <ref type="bibr" target="#b41">[42]</ref> or the result triggered by the incidents <ref type="bibr" target="#b42">[43]</ref>.</p><p>Inspired by the above cyber incident taxonomies, we organize the incidents from the collected literature into our proposed categorization method as shown in Figure <ref type="figure" target="#fig_0">1</ref>, to better analyze and define cybersecurity incident, as well as clarifying the scope of incidents. The first hierarchy of indexes in our category adopts the NIST cyber incident taxonomy that tags each incident as either inappropriate usage, DoS, malicious code or unauthorized access. Furthermore, we herein categorize incident of each reviewed work in the manner of "list of terms" by David et al. <ref type="bibr" target="#b38">[39]</ref>, as well as providing references to the relevant paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Research methodology</head><p>The methodology, shown in Figure <ref type="figure" target="#fig_1">2</ref> illustrates common steps to predict and discover cybersecurity incidents. The model is composed of six steps, which constitutes a circle as a continuous and incremental process: (1) cybersecurity incident analysis; (2) security problem modeling; (3) data collection and processing; (4) feature engineering/ representation learning; (5) model customization; (6) evaluation.</p><p>1) Cybersecurity incident analysis: The first step is to "know the enemy". In the face of overwhelming cybersecurity incidents, the first thing we have to do is to target one or more specific cybersecurity incident types. In order to achieve the goal of predicting and discovering cybersecurity incidents, many efforts have been devoted to finding more indicators that may relate to incidents by comprehensively analyzing an incident. Moreover, fully understanding a cybersecurity incident is helpful to see some aspect of the problem at which to chip away.</p><p>As referred to in Section II-A, cybersecurity incident is the activity with evil intentions which results in threats or damages on cybersecurity in general definition. Depending on different perspectives, researchers discerned and analyzed cybersecurity incidents in distinct ways as shown in Figure <ref type="figure" target="#fig_0">1</ref>. In this step, we provide ways on how to analyze cybersecurity incidents. Generally, a type of incident can first be compared and contrasted with similar events. From the technical level, techniques, tools, and methods utilized to achieve the attack are considered nontrivial for analyzing a cybersecurity incident. Besides, the infrastructure, environment and occurrence time of the incidents are also worth analyzing. Last but least, actors involved in the incident may affect the development of incidents, which can be potential factors for prediction and discovery objective <ref type="bibr" target="#b33">[34]</ref>  <ref type="bibr" target="#b37">[38]</ref>. During the process of analysis, a small number of samples may be required to extrapolate the entire incident and reflected details of the case.</p><p>2) Security problem modeling: After profoundly analyzing the previous target cybersecurity incidents, the research problem shaped by project requirements should be determined in this step. Roughly speaking, there are two ways of thinking about how to define cybersecurity incident prediction or discovery problem: one way is to design a method that ultimately aims to apply to all kinds of security incidents to predict/discover security incidents and related information. Such a method can demonstrate its feasibility by choosing one or more specific incident types to conduct proof-of-concept; the other way is to solve a particular prediction or discovery problem investigated in the process of analyzing a kind of cybersecurity incident, such as predicting whether a currently benign website will become malicious <ref type="bibr" target="#b6">[7]</ref> or discovering black keywords used by the online underground economy <ref type="bibr" target="#b27">[28]</ref>.</p><p>On the basis of the research problem, a model to solve the problem will be set up. Several samples can be applied to validate the feasibility and practicality of the implementation alternatives to help determine whether the idea is worth taking on to the next stage.</p><p>Hereon, we will briefly introduce related modeling approaches and techniques for cybersecurity incident prediction. Typically, techniques in support of establishing security models focus on ML and DM. As ML and DM often employ the same methods, there is considerable overlap between the two terms <ref type="bibr" target="#b14">[15]</ref>. Regarding cybersecurity incident prediction and discovery, ML concentrates on prediction, based on the knowledge learned from the training data. The task of predicting the elements in a given dataset should belong to which one of two groups that can be cast as a binary classification problem, using existing techniques, such as those proposed in <ref type="bibr" target="#b8">[9]</ref>  <ref type="bibr" target="#b17">[18]</ref>. Similarly, where more than two labels can be assigned to each observation, multi-label classification is applied to solve a specific problem in <ref type="bibr" target="#b29">[30]</ref>. Furthermore, when the prediction problem is designed to explore the relationship between variables, regression is an elective solution, as proposed in <ref type="bibr" target="#b26">[27]</ref>. On the other side, DM focuses on discovering previously unknown knowledge in the datasets. To put it in practical terms, the task of grouping a batch of objects in such an approach that objects in the same group are more similar to each other than to those in other groups is typically considered as a clustering problem <ref type="bibr" target="#b7">[8]</ref>  <ref type="bibr" target="#b30">[31]</ref>.</p><p>Besides ML/DM, other techniques should be considered when setting up model and dealing with specific issues. For instance, as security incidents are normally recorded in natural language, Natural Language Processing (NLP) is extensively used to process data as in <ref type="bibr" target="#b23">[24]</ref> [28] <ref type="bibr" target="#b30">[31]</ref> [32] <ref type="bibr" target="#b32">[33]</ref>. In addition, some work unitizes statistical and graph mining <ref type="bibr" target="#b24">[25]</ref> approaches to achieve their goals. Note that we delay the detailed analysis of how security problems of the selected works are modeled to Section III. As an introduction, Table <ref type="table">II</ref> summarizes the research problems and techniques applied to establish model in the reviewed works.</p><p>3) Data collection and processing: After the above two steps, we need to obtain sufficient data. Predicting cybersecurity incidents is firmly bound up with data. Collecting data is a critical step, which forms a connecting link between the preceding and following steps in this methodology. The quality and quantity of data decide the feasibility of solving the research problem proposed in the last step. Also, data can serve as the source for setting up groundtruth and affect the performance of the prediction model. We have witnessed the enormous increase of both the scope and variety of security-related datasets in recent years, which provides us with valuable resources to predict and discover cybersecurity incidents.</p><p>So how to collect valuable and unique needs data from the large volumes of different kinds of data sources? The general steps to manage big data begin with gathering data from diverse data sources according to the research problem and project purpose. After collecting the vast amount of raw data, we should consider how to store these data to perform further processing. Physical foundation, as well as cloud storage services, are usually required to put the data into appropriate databases or storage services <ref type="bibr" target="#b43">[44]</ref>. The third step is to organize and process data before knowledge discovery from databases. That includes cleaning up noisy data, mapping data sources to each other, merging data and converting data to structured formats. High quality label for data is necessary if the prediction model is built by supervised learning, which is a process of learning a function that maps an input to an output based on example input-output pairs <ref type="bibr" target="#b44">[45]</ref>. Some data may need to be labeled by specialists and experts.</p><p>Last but least, by investigating the previous work on data collection, we have some insights on the data collection for cybersecurity incident prediction. We find that certain kinds of data are easy to access; a few others are difficult to obtain for researchers. To be specific, data published on the web are usually available for web crawling. For instance, we can readily obtain vulnerability records in the National Vulnerability Database (NVD) <ref type="bibr" target="#b45">[46]</ref> and find historical incident reports in Verizon annual Data Breach Investigations Reports (DBIR) <ref type="bibr" target="#b46">[47]</ref>. Also, by leveraging APIs provided by various kinds of social media, such as Twitter, we can mine social media data. However, some data are relatively difficult to acquire, especially when privacy information is involved. A case example is that of log files that are utilized in the work of <ref type="bibr" target="#b9">[10]</ref>. 4) Feature engineering/representation learning: The fourth crucial step of the methodology is to extract features from the collected data, which is not only critical to achieving ideal prediction results but also fundamental to the application of machine learning. The performance of ML methods is heavily contingent on the selection of features or representation of data to which they are applied on <ref type="bibr" target="#b47">[48]</ref>. Feature engineering refers to a process of relating domain knowledge of data to manually create features, and thus relies heavily on specific domain knowledge. Feature engineering begins typically with brainstorming by investigating data as well as considering research problems. Sometimes, we can also use the experience of other literature or projects. In general, both automatic feature extraction algorithms and manual construction methods are severed for devising features.</p><p>However, sometimes, coming up with appropriate features is challenging, time-consuming, and lacks expert knowledge <ref type="bibr" target="#b48">[49]</ref>. On the other hand, real-world data, such as image, video and other sensory data, are hard to yield specific features by traditional feature engineering methods. Representation learning as an alternative way of feature engineering attempts to recognize and disengage the potential explanatory factors buried in the data <ref type="bibr" target="#b47">[48]</ref>. In other words, learning representations of the data can aid in extracting valuable information when developing classifiers or further predictors. Practically, capturing the posterior distribution of the hidden factors for the observed data is a good representation for the probabilistic model. Additionally, efficient representation is beneficial as input to supervised, unsupervised and deep learning predictors with suitable representation learning algorithms, such as supervised dictionary learning <ref type="bibr" target="#b49">[50]</ref> and principal component analysis <ref type="bibr" target="#b50">[51]</ref>.</p><p>It is well-known that feature engineering or representation learning is a typical process in machine learning and deep learning. What should be especially considered in cybersecurity incident prediction? It is vital that features reflect the condition before the incidents. In other words, the features may not be necessarily directly related to the cybersecurity incident but must be an indicator of the threat. To give an example, when Liu et al. <ref type="bibr" target="#b8">[9]</ref> forecasted cybersecurity incident on an organization-level granularity, they made use of features that revealed mismanagements on the network and infrastructure instead of known characteristics of the incident. Based on the special attributes of prediction, the representation learning has the chance to enhance the potential for identifying indicators of cybersecurity incidents and therefore to make a successful prediction. 5) Model customization: Generally, the prediction model is built by applying data mining and machine learning algorithms and optimizing parameters to fit the best model. Traditional ML/DM methods can achieve acceptable performance on certain domains. However, the same performance cannot be guaranteed when it comes to a specific research problem related to cybersecurity incident prediction. To solve this problem, if the traditional ML/DM algorithms can be customized according to the specific research problem instead of directly using packaged tools, the model will be effectively implemented to achieve maximum data efficiency. Thus, the efficiency (e.g., running speed) and efficacy (e.g., accuracy and other performance measurements) of predictive model can also improve significantly.</p><p>Deep learning (DL), a member of a broader family of machine learning techniques that hinges on learning data representations, is moving beyond its early breakthroughs in pattern recognition and towards innovative applications in distinct domains and industries <ref type="bibr" target="#b51">[52]</ref>. There is a promising trend of applying DL to analyze tremendous volumes of data with high computational efficiency <ref type="bibr" target="#b52">[53]</ref>. For instance, in the field of cybersecurity, researchers recently leveraged DL to detect spam <ref type="bibr" target="#b53">[54]</ref>, to discover vulnerability <ref type="bibr" target="#b21">[22]</ref> and have introduced DL for IoT-based system <ref type="bibr" target="#b54">[55]</ref>  <ref type="bibr" target="#b55">[56]</ref>. Therefore, it is an opportunity to solve problems for cybersecurity incident prediction if we rationally utilize and customize DL in this field.</p><p>The ways and insights of customizing model can be explored based on thoroughly understanding of traditional ML/DM algorithms and data structures knowledge in classical computer science. Furthermore, combined with the specific research problem, the improvements tend to be more problem specialized.</p><p>6) Evaluation: The last step is the evaluation of the model to determine whether the results meet our objective. That is, evaluating the model with appropriate metrics to verify research goals are reached.</p><p>In Section III, the evaluation method and metrics of each work will be described in details. For earlier understanding, we list the definitions of evaluation metrics used throughout the paper.</p><p>The evaluation metrics are calculated from confusion matrix that reports False Positives (FP), False Negatives (FN), True Positives (TP) and True Negatives (TN), as shown in Table <ref type="table">I</ref>. The evaluation metrics frequently used for reviewed work are:</p><p>• Accuracy -it is defined as percentage of correctly predicted items among the total number of items, which is calculated as (T P + T N)/(T P + T N + FP + F N).</p><p>• Recall -it also called sensitivity or TPR. It refers to percentage of numbers of class X correctly predicted as belonging to class X, which is calculated as T P/(T P + FP). • Precision -it illustrates percentage of items correctly predicted as X among all items classified as X, which is calculated as T P/(T P + F N). • False Positive Rate (FPR) -it indicates percentage of items incorrectly classified as class X to all items that belong to a class not X, which is calculated as FP/(T N + FP). • F-measure -it is another measurement of accuracy combining precision and recall, which is calculated as 2 • Precision • Recall/(Precision + Recall). Also, some work utilizes a graphical plot that is called Receive Operating Characteristic (ROC) curve to illustrate the prediction ability of a binary predictor. Specifically, a ROC space is created by plotting TPR as y-axis against FPR as xaxis, which demonstrates relative trade-offs between benefits (TP) and costs (FP).</p><p>In addition, some work utilizes a graphical plot that is called Receive Operating Characteristic (ROC) curve to illustrate the prediction ability of a binary predictor. Specifically, a ROC space is created by plotting TPR as y-axis against FPR as xaxis, which demonstrates relative trade-offs between benefits (TP) and costs (FP).</p><p>Regularly, the FPR is always a significant challenge to cybersecurity, which hampers the effectiveness of security tools <ref type="bibr" target="#b56">[57]</ref>  <ref type="bibr" target="#b57">[58]</ref>. For the detection problem, FPs always result in massive cost. For instance, a work which is used by one specific software must be interrupted if the software is detected as malware. Therefore, the goal of the detection problem is usually to maximize the TPR while keeping the FPR minimize. However, regarding the prediction problem, the cost of FPs are more complicated to avoid, but the cost of FPs is lower compared to the detection problem. This also agrees with the goal of prediction: to discover all possible incidents for the implementing of proactive measures, prioritize alerts and supply security training in advance. For an insurance company, 20% false positives can be entirely accepted, according to the recent work <ref type="bibr" target="#b22">[23]</ref>.</p><p>By leveraging comprehensive evaluation methods and metrics, we can check whether the results are satisfactory. If the goal failed to achieve, the circulation from analyzing cyber incident should restart incrementally to find a better solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DATA-DRIVEN PREDICTION AND DISCOVERY</head><p>In this section, we review the significant cybersecurity incident prediction and discovery works by the category of data sources as follows: (1) organization reports and datasets;</p><p>(2) executables datasets; (3) networks datasets; (4) synthetic datasets; (5) webpage data; (6) social media data; <ref type="bibr" target="#b6">(7)</ref> mixedtype dataset.</p><p>Using the methodology of data-driven cyber incident prediction proposed in Section II as the main line, we review the critical points and details of each work in the following subsections. Table <ref type="table">II</ref>   Besides the text description of the employed datasets in each work, we also produce Table <ref type="table">III</ref> to Table VIII to summarize these datasets. This information can help the research practice with understanding, repeating and improving works in cybersecurity incident prediction. Also, we provide more details about relevant datasets on our GitHub repository<ref type="foot" target="#foot_0">1</ref> , such as release information and some sample data, which may enlighten new researchers to find new solutions.</p><p>A. Organization reports and datasets 1) Predicting data breach incidents: Data breach refers to "a security incident in which sensitive, protected or confidential data is copied, transmitted, viewed, stolen or used by an individual unauthorized to do so" in <ref type="bibr" target="#b58">[59]</ref>. It has been a severe problem in the security field for a long time, many researchers and communities are devoted to detecting it. While, the fact is that, it is already too late when the data breach is detected because the severe damage may have already occurred. If a data breach incident can be forecasted in advance, the organization may survive in, instead of suffering from, a cybersecurity incident.</p><p>Liu et al. <ref type="bibr" target="#b8">[9]</ref> presented a method to proactively predict organization's breach incidents based on the externally observed organization's network symptoms data. Firstly, the authors analyzed cybersecurity incidents referenced by Verizon annual Data DBIR <ref type="bibr" target="#b16">[17]</ref> and characterized the extent to which cybersecurity incidents could be predicted. Standing on observations on cyber incidents, the author framed the research problem as a binary prediction problem of identifying whether an organization will encounter a data breach incident in the near future based upon externally observed organizations' Internet data instead of data from internal workings of an organization's network.</p><p>The authors adopted machine learning method to train and test the classifiers by utilizing organization's reports and datasets data, including security incident data and security posture data. On one hand, security incident data comes from VERIS community database <ref type="bibr" target="#b16">[17]</ref>, Hackmageddon <ref type="bibr" target="#b59">[60]</ref> and the Web Hacking Incidents Database <ref type="bibr" target="#b60">[61]</ref>, serve as groundtruth. These three datasets cover the cyber incident events ranging from mid-2013 to 2014. On the other hand, security posture is quantitatively measured in the level of malicious activities from an organization and five mismanagement symptoms. The malicious activities are measured in not only the amounts of those but also their dynamic behaviors, by applying various reputation blacklists, including CBL <ref type="bibr" target="#b61">[62]</ref>, SBL <ref type="bibr" target="#b62">[63]</ref>, SpamCop <ref type="bibr" target="#b63">[64]</ref>, WPBL <ref type="bibr" target="#b64">[65]</ref>, UCEPROTECT <ref type="bibr" target="#b65">[66]</ref>, SURBL <ref type="bibr" target="#b66">[67]</ref>, PhishTank [68], hpHosts <ref type="bibr" target="#b67">[69]</ref>, Darknet scanners list, Dshield [70] and OpenBL <ref type="bibr">[71]</ref>. Furthermore, mismanagement symptoms are obtained based on observation from open Recursive Resolvers, DNS Source Port Randomization, BGP misconfiguration, Untrusted HTTPS Certificates, and Open SMTP Mail Relays <ref type="bibr" target="#b23">[24]</ref> via using databases that record and assess the organization's network. After pre-processing and mapping, 258 externally measurable features are extracted from security posture data. Also, each organization is labeled as "victim" or "non-victim" according to the security incident reports.</p><p>There are two prediction scenarios proposed in paper <ref type="bibr" target="#b8">[9]</ref>, namely short-term prediction and long-term prediction. Experiments were conducted by using random forest algorithm. In addition, training datasets are composed of a random subset of victim organizations and non-victim organizations. In the short-term prediction scenario, features are extracted from the most up-to-date time ahead of an incident. In the long-term prediction scenario, features are extracted from the periods prior to the first incident happened in the testing dataset.</p><p>As to the evaluation of the prediction performance, besides of traditional evaluation metrics (including accuracy, true positive, false positive and ROC curve as defined in Section II), the authors analyzed top data breaches incidents in 2014 to illustrate the power of the prediction model. Their prediction model can reach a combination of 90% TPR and 10% FPR. Moreover, according to <ref type="bibr" target="#b68">[72]</ref>, the top five data breach incidents in 2014 are separately happening in JP Morgan Chase, Sony pictures, eBay, Home Depot and Target. The proposed prediction model accurately forecasted most of the data breach incidents, except the Target one.</p><p>Sometimes, the attackers may establish the fake network with clean data (no malicious activities) but with counterfeit reported incidents, or the opposite way, to mislead the predictor. This is referred to as adversarial machine learning. In paper <ref type="bibr" target="#b8">[9]</ref>, the author assumed the data are uncompromisingly real. In other words, they ignored the noise and error in the dataset. The complete solution remains a direction for future study.</p><p>2) Predicting risk distributions over fine-grained data breach types: Nowadays, every business is facing various kinds of security incidents, including targeted attacks and internal errors. Once a security incident happens, the business data involving private, as well as public information, has the extremely high possibility to be leaked. Furthermore, the business will be affected not only on its assets but also on its reputation. Therefore, organizations are devoted to assigning resources to prevent themselves from ever-changing security incidents. If the risk distributions can be assessed and predicted, organizations can prioritize the protection, so as to achieve more effective protection and save the more resources.</p><p>Sarabi et al. <ref type="bibr" target="#b17">[18]</ref> leveraged the business details to train and test a sequence of predictors, which can help organizations prioritize the preventive resource allocation. When the authors analyzed security incidents, they found that no business gravitates toward a single sort of incident. Meanwhile, they noticed that incidents reports usually provide security recommendations based individually on business sector information. Hence, different from work in <ref type="bibr" target="#b17">[18]</ref>, the ultimate goal of the paper is to employ business details about an organization to predict a sparser set of incidents types compared with <ref type="bibr" target="#b8">[9]</ref>, so as to provide protection resource allocation recommendations to an arbitrary organization.</p><p>For the study, the incidents happened in 2013 and 2014, including 1729 and 592 entries were collected respectively from the VERIS Community Database <ref type="bibr" target="#b16">[17]</ref> as groundtruth. In order to achieve fine-grained cyber incident prediction, each incident was labeled from three fields. The first field is the type of the cyber incident, including environmental, error, hacking, malware, misuse, physical or social. The second is the responsible actor for the attack, labeled as the external, internal or partner. The last is the compromised assets in the incident, containing kiosk/terminal, media, social, network, people, server and device.</p><p>Features gathered for training and testing the predictors are business details from the organization's profiles and websites, which combine information obtained from the VCDB and Alexa Web Information Service (AWIS). The industry code, number of employees, and the region of operation of the victim organization are three business profiles features extracted from VCDB. AWIS provides the organization's website and statistics information, including the traffic volume of the website, number of visitors, speed, number of pages linking to the website, and information about the organization that maintains the website (e.g., address, contact information and stock ticker symbol).</p><p>To forecast the risk of various kinds of data breach incidents, the authors designed multi-label classifiers by using random forest algorithm. Specifically, each binary classifier predicted a field of the incident signature, which is namely action type, actor type or asset type, as mentioned above.</p><p>Concerning evaluation, predictors were trained on the 2013 incidents data and tested them using the 2014 data. The prediction model was evaluated from the risk profiles of the company and the accuracy of the risk assessment model. The result showed that an organization can evade 90% incidents by using 70% of incident types on average.</p><p>It is worth mentioning that the prediction results seem to be too ambiguous to operate. That is, more practical recommendations can be provided for a security ignorant business operator. For instance, the SANS <ref type="bibr" target="#b69">[73]</ref> contributes 20 kinds of security controls that specify the operable guidance to the business to increase their security level. Hence, transferring the risk profiles to more actionable security recommendations could be a future direction.</p><p>3) Discovering previous unknown malware with downloader graph analytics: Malicious software, commonly known as malware, has been a vital threat to cybersecurity for a long time. Reported by the PandaLabs, 18 million new malware samples were captured in the third quarter of 2016, an average of 200,000 each day <ref type="bibr" target="#b70">[74]</ref>. Due to human error, zero-day exploits or other factors, it is possible to be infected even for the most protected and state-of-the-art system in the world. Hence, detecting the malware which are previously unknown to the public as early as possible is an effective way to minimize stress, time cost, and damage as well as defeating incidents from its very beginning. However, some malware are hard to be detected by using the traditional malware detection methods that focus on analyzing the content and behavior of software. Downloader graphs have the potential of providing indicators of malicious activities and discovering the vast majority of the malware download activities that may otherwise remain undetected.</p><p>Kwon et al. <ref type="bibr" target="#b18">[19]</ref> presented a malware early-detection system based on the insights from analyzing downloader graphs. The authors investigated that, due to social engineering or drive-by attacks, users may download additional malware even if they are downloading benign applications. Hence, they proposed a graph-based abstraction model to describe the download activities on end hosts. Based on the abstraction model, they performed a large-scale measurement to investigate the differences in the growth patterns between malicious and benign downloader graphs. Lastly, they employed features extracted from measurements to build a malware early-detection system.</p><p>The dataset used to build for the malware early-detection system consists of malicious and benign download activities graphs. The graphs are generated by reconstructing download events obtained by anti-virus (AV) telemetry and Symantec's intrusion prevention systems (IPS). To represent the download activities, 19 million influence graphs, in which the downloaders have caused on 5 million real hosts, were included in the dataset. Explicitly, the nodes of a graph indicated that the Portable Executable (PE) files (including benign downloaders and malicious downloaders), and the edges of the graph represented the download events. According to the groundtruth of malicious and benign downloaders, 15 million of the influence graphs (IG) were labeled as benign, and 0.25 million as malicious. The groundtruth was checked by three data sources, containing the downloader records from VirusTotal, the National Software Reference Library (NSRL), and a supplementary groundtruth data derived from Symantec.</p><p>To explore the differences between malicious and benign downloaders' IGs, the authors conducted an extensive measurement, providing the features to be utilized by malware early-detection system. According to the analysis, there are four apparent indicators of malicious activities: (1) IGs with a large diameter are mostly malicious. (2) IGs with slow growth rates are primarily malicious. (3) URL access patterns can be distinguished between malicious and benign downloaders. ( <ref type="formula">4</ref>) Malware is more prone to download fewer files per domain. Based on the observation, 16 features (including four internal dynamic features, three domain properties features, two downloader score properties features, four life cycle features and three globally behavior features) were calculated from the IGs.</p><p>Utilizing the features obtained from the measurements and adopting random forest classifiers, the malware early detection system was built. To evaluate how early the detection system can detect the previously unknown malicious executables, the authors defined "early detection" as "we can flag unknown executables as malicious before their first submission to Virus-Total" according to <ref type="bibr" target="#b18">[19]</ref>. On average, it is shown that this early-detection system can detect unknown malware 9.24 days on average earlier than VirusTotal anti-virus product. Besides, the authors attempted to perform online detection experiments, simulating the early detection system employed operationally. In the experiment, the training dataset contained data collected before the year 2014, including 21,543 malicious and 21,755 benign data. For the testing dataset, 12,299 malicious and 12,594 benign data were gathered from the year 2014. The resultant 99.8% TPR and 1.9% FPR demonstrate the robustness of the system. Although there is a limitation that droppers with rootkit functionality would escape this technique, this method still provides a novel signal and complementary to the current anti-virus mechanism.</p><p>As a concluding remark for this section, an overall description for organization's reports and datasets is produced in Table <ref type="table">III</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Executables datasets 1)</head><p>Early-Stage malware prediction using recurrent neural networks: In the face of rapidly increasing rate and the number of new malware, both research communities and industries are devoted to detecting malware. Static malware analysis derived from analyzing static code can be conducted quickly and easily. However, static analysis is vulnerable to obfuscation techniques and performs poorly when facing entirely new malware. Behavioral data generated from file execution for dynamic malware analysis is more difficult to be obfuscated. But VERIS community database <ref type="bibr" target="#b16">[17]</ref> Cybersecurity events record Each organization is labeled as victim or non-victim according to the security incident reports Hackmageddon <ref type="bibr" target="#b59">[60]</ref> Web Hacking Incidents Database <ref type="bibr" target="#b60">[61]</ref> [18]</p><p>VERIS community database <ref type="bibr" target="#b16">[17]</ref> Cybersecurity events record The data incident of each organization is fine-grained labeled by action type (as environmental, error, hacking, malware, misuse, physical or social), actor type (as external, internal or partner.) and asset type (as kiosk/terminal, media, social, network, people, server and user device) <ref type="bibr" target="#b18">[19]</ref> VirusTotal downloader records Downloader records Each downloader graph is labeled as malicious or benign according to downloader records National Software Reference Library (NSRL) Symantec downloader records <ref type="bibr" target="#b31">[32]</ref> ExploitDB <ref type="bibr" target="#b71">[75]</ref> Vulnerability exploits records Each vulnerability is labeled as exploited or not exploited according to vulnerability exploits records Microsoft's Exploitability Index <ref type="bibr" target="#b72">[76]</ref> Symantec's Worldwide Intelligence Network Environment (WINE) <ref type="bibr" target="#b73">[77]</ref>  the process of file execution takes longer time, which indicates the malware may have been delivered before detection. The security protection personnel, instead of repairing damage after detection, can block malicious payloads if the prediction works before any damage taken place. Rhode et al. <ref type="bibr" target="#b19">[20]</ref> proposed an early-stage malware prediction method, which can leverage the first five seconds of execution behavioral data to predict whether a file is malicious or not by using a recurrent neural network (RNN).</p><p>During the data collection process, the authors firstly gathered 1,000 malicious and 600 benign Windows 7 executables from VirusTotal <ref type="bibr" target="#b74">[78]</ref> as well as 800 benign samples from a fresh Windows 7 64-bit installation's system files. The authors also collected extra 4,000 Windows 7 applications from free software sources (e.g., Softonic <ref type="bibr" target="#b75">[79]</ref>, PortableApps <ref type="bibr" target="#b76">[80]</ref> and SourceForge <ref type="bibr" target="#b77">[81]</ref>) to better represent the real workload of the anti-virus system. The 4,000 Windows 7 applications were labeled as "malicious" or "benign" by around 60 anti-virus engines from VirusTotal API <ref type="bibr" target="#b74">[78]</ref>. Finally, the dataset included 2,345 benign samples and 2,286 malicious samples.</p><p>After collecting data, the executable samples were executed using Cuckoo Sandbox <ref type="bibr" target="#b78">[82]</ref>. During the execution, ten sequential machine activity metrics were taken as features by employing Python Pustul Library <ref type="bibr" target="#b79">[83]</ref> and then applied as input data to the neural network. The captured activities that were recorded every second in the process of sample execution included system CPU usage, user CPU usage, packets sent, packets received, bytes sent, bytes received, memory use, swap use, the total number of processes currently running and the maximum process ID assigned. Regarding setting up the prediction model, the architecture of the model is based on RNNs along with Gated Recurrent Units (GRUs). On one hand, RNN has the capability of catching input features, processing timeseries data, as well as capturing information that changes over time. On the other hand, GRUs cells are used for quickening the speed of training process. Furthermore, to face the rapid evolution of malware, the authors adopted a random search of the hyperparameter space to adjust the hyperparameter of the model. Finally, the customized configuration was the settings that achieve the best performance on 10-fold cross-validation over the training set.</p><p>Malware prediction radically transforms the defensive strategy from recovery to prevention. The performance of the malware prediction method was evaluated from 3 aspects:</p><p>• The authors set the goal of prediction as "predict malware quickly enough that user experience would not (significantly) suffer from the time delay." The testing dataset only used samples that were first seen by VirusTotal after an exact time on 10th October 2017. Also, they tested the method against Random Forest, Support Vector Machine, Naive Bayes, J48 Decision Tree, K-Nearest Neighbor and Multi-layer Perceptron algorithms used in previous research. The results showed that the RNN model outperformed other algorithms after one second, achieved 91% accuracy after four seconds and 96% accuracy after 19 seconds of execution. The results demonstrated that the few seconds of execution's dynamic data was adequate to forecast whether an executable file is malicious or not.</p><p>• The authors explored the robustness of the model to discover the malware families and variants which are previously unknown. To simulate "zero-day", the authors collected variants listed as advanced persistent threats (APTs). They found that during the first second of execution, the variant detection rate was over 89%, which indicates the capability of the model to discover "zeroday" malware. • A case study on ransomware was conducted using 3,000 ransomware samples. The results showed that the accuracy of prediction reaches 94% after one second of execution without prior exposure to samples of ransomware. As mentioned in <ref type="bibr" target="#b19">[20]</ref>, There are three main limitations as well as future directions. Firstly, they only examined Windows 7 executables. In this concern, checking if the model is capable of detecting some other potential carriers for malware or operating systems is essential. Secondly, due to the easiness of the first 5 seconds of the malicious file tampering with adversaries, the robustness of the prediction model should be evaluated by adversarially crafted samples. Lastly, with good practical value, the model should have the capability to block the malicious payload if the predictor determines the process is malicious or suspects the process might be malicious.</p><p>2) Hidden sensitive operations discovery in Android Apps: Sensitive operations are only conducted on certain conditions to hide from automated runtime analysis, which is called Hidden Sensitive Operations (HSOs). HSOs are increasingly used by malicious mobile apps or other potential-harmful apps (PHAs) to evade detection. Finding previous unknown HSO is critical to mitigating the emerging mobile threats. However, existing static analysis approaches rely on known beforehand trigger conditions and hidden behaviors. Therefore, discovering unknown HSO is invaluable to understand the HSO techniques evolving trends and provide insights about how to defend against incidents caused by mobile security threats, which encourages the researchers to devote themselves to this trend.</p><p>The branching structure of an HSO usually consists of one condition and multiple paths. From the observation on HSO branch, Pan et al. <ref type="bibr" target="#b20">[21]</ref> proposed machine learning based approach that employed a set of lightweight features extracted from an app to conduct a large-scale unknown HSO discovery.</p><p>There are three unique observations concerning an HSO condition, its paths, and relations between condition and paths as follows: (1) HSO trigger conditions are always only relevant to system input (time, location, screen touches, etc.), rather than the hosting app's internal input. <ref type="bibr" target="#b1">(2)</ref> Behaviors between two paths are considerably different in HSO. (3) Data and semantic dependency between conditions and paths in HSO are remarkably weak. Inspired by the above unique observations, three sets of features were extracted from trigger conditions and the corresponding paths: (1) System Input (SI) is a binary feature indicates whether the trigger condition contains system input. The system input refers to system properties (e.g., hardware traces of a mobile phone) or environment parameters (e.g., time, location, user input etc.). (2) Activity Distance (AD) and Data Distance (DD) are features used to measure the similarity of two paths in an HSO branch statement. Both of them were calculated by Jaccard Distance. Specifically,</p><formula xml:id="formula_0">AD = 1 -( O l O r O l O r ),</formula><p>where O l and O r represent sets of sensitive operations on two paths of an HSO branch. While dealing with DD, it is set to</p><formula xml:id="formula_1">1 -1 2 ( V l V r V l V r + F l F r F l F r</formula><p>), V l , V r and F l , F r are respectively sets of variables and references class fields of a branch statement. (3) Data Dependency (DF) and Implicit Relation (IR) are features that describe the relationship between trigger conditions and behavior. DF refers to the ratio of the variables on a path connected to the condition through data flows; the latter is the number of variables, keys, and APIs implicitly related to the condition.</p><p>Support vector machine (SVM) was chosen as the machine learning algorithm for implementation of the approach. The evaluation was conducted by leveraging three datasets: (1) A labeled good dataset: This dataset contains 213 benign apps with non-HSO branches from Google Play that have never been flagged by VirusTotal <ref type="bibr" target="#b80">[84]</ref>. ( <ref type="formula">2</ref> Eventually, 63,372 apps with 70,660 branches were labeled as HSO by implementing this approach. For evaluation of this approach, the researchers in <ref type="bibr" target="#b20">[21]</ref> randomly sampled 125 apps and manually inspected each of app. It is shown that the new approach can achieve 98% precision and over 94% coverage. Furthermore, the approach was used in a measurement study, which aims to discover the new knowledge on HSO. By applying the approach on 338,354 apps in the wild, the researchers presented evolving trends and discoveries on HSO activities, which contributes to more effective defense against the mobile phone threats.</p><p>One point should be affirmed is that the work in <ref type="bibr" target="#b20">[21]</ref> is significant to understand and defeat HSO. However, this is still a preliminary work in this field. A few limitations could be observed. For instance, the accuracy and completeness could be improved. Also, it should be validated whether the model can evade carefully crafted HSO techniques. Lastly, the current existing few heavyweight techniques can be optimized to improve the scalability of the approach.</p><p>3) Code vulnerability discovery: Exploitable software vulnerabilities are one of the primary causes of security incidents and data breaches <ref type="bibr" target="#b81">[85]</ref>  <ref type="bibr" target="#b82">[86]</ref>. For instance, a recently disclosed vulnerability in the Server Message Block (SMB) protocol that was exploited by the WannaCry ransomware affected a large number of users and systems worldwide. This resulted in not only financial loss but also the companies and organizations reputation damage.</p><p>Efficiently discovering previously unknown vulnerabilities can be a feasible solution against potential attacks. Lin et al. <ref type="bibr" target="#b21">[22]</ref> proposed a framework to discover vulnerabilities in function-level granularity. Besides that, by utilizing the transfer representation learning based on a deep learning algorithm, the approach they proposed can be applied to within-project and cross-project vulnerability discovery.</p><p>The authors claimed that the function level vulnerabilities groundtruth dataset is scarce. Hence, they collected six opensource projects' codes from GitHub. The six projects are respectively LibTIFF, LibPNG, FFmpeg, Pidgin, VLC Media Player, and Asterisk. For each project, the authors manually labeled the vulnerabilities in the function level according to Common Vulnerability and Exposures (CVE) and National Vulnerability Database data repositories. Finally, they obtained 457 vulnerable functions and 32,531 non-vulnerable functions.</p><p>After setting up the groundtruth dataset, the authors need to extract features from functions so as to discover vulnerabilities at function level.. Firstly, each function was converted to Abstract Syntax Trees (ASTs) in a serialized form. All of the serialized ASTs are processed in the same length on the condition that preserves the structural and semantic features. As usual, the second step is to craft feature. It is worth mentioning that convention feature engineering that requires specific domain knowledge was not adopted in this framework. Instead, the authors applied a long short-term memory (LSTM) <ref type="bibr" target="#b83">[87]</ref> based on recurrent neural network (RNN) with Word2vec <ref type="bibr" target="#b84">[88]</ref> embeddings to learn representations of programming patterns that help to differentiate between vulnerable and nonvulnerable functions. Besides, for a target project with a small number of labeled data, same representation learning method is applied and as a complementary to feed into the pretrained network. Lastly, a random forest classifier is trained by leveraging these learned representations.</p><p>The evaluation was generally based on the comparison with traditional code metrics (CMs) feature extraction method, which is commonly adopted in finding vulnerabilities. On one hand, top-k precision was applied to measure the performance of the model. Top-k precision <ref type="bibr" target="#b85">[89]</ref> is widely adopted in information retrieval systems. For instance, when measuring search engines performance, Top-k precision indicated that how many relevant information is retrieved in all of the Topk information. In this work <ref type="bibr" target="#b21">[22]</ref>, top-k precision suggests the percentage of functions that are vulnearble in the top-k fetched functions. On the other hand, they defined Function Inspection Reduction Rate (FIRR) to measure cost reduction. In other words, the effort saved by applying the proposed method contrasted with traditional feature extraction approach is calculated. The empirical results showed the transfer representation learning for vulnerability discovery method was more effective than the method based on CMs, both in the within-project and the cross-project detection scenarios.</p><p>However, the classification is not fine-grained enough at the function-level. As a future direction, code-gadget level and statement level classification can be considered. Also, although the imbalance problem was solved using the random forest to a certain extent, it should be concerned about employing the oversampling and undersampling method to furtherly addressing this problem. As a concluding remark for this section, an overall description for executables datasets is produced in Table <ref type="table">IV</ref>.</p><p>C. Network datasets 1) Mismanagement and maliciousness of networks: There is a hypothesis that mismanagement is correlated with maliciousness. Mismanaged networks are more likely to expose more attack vectors, resulting in bringing about more attackers and infected hosts <ref type="bibr" target="#b100">[105]</ref>. Moreover, mismanagement networks have less opportunity to adopt reactive approaches to reduce the bad impact of compromise.</p><p>In other words, mismanagement networks might take charge of wide-ranging malicious networks and security incidents. Hence, exploring the relationship between mismanagement and maliciousness of a network is a stepping stone to discover security incidents. Zhang et al. <ref type="bibr" target="#b23">[24]</ref> found a statistic correlation between the mismanagement of networks and maliciousness of the systems. By utilizing the information drawn from mismanagement leading to maliciousness, proactive protection could be applied to prevent compromises and damages.</p><p>Mismanagement is defined as "the failure to adopt commonly accepted guidelines or policies when administrating and operating networks" in paper <ref type="bibr" target="#b23">[24]</ref>. Eight network mismanagement symptoms are collected as follows:</p><p>• Open DNS recursive resolver: Open recursive queries can be exploited in an amplification attack, which poses a direct threat to the networks.  BGP Misconfiguration dataset <ref type="bibr" target="#b88">[93]</ref> Without egress filtering dataset <ref type="bibr" target="#b89">[94]</ref> Untrusted HTTPS certificates dataset <ref type="bibr" target="#b90">[95]</ref> Open SMTP server relaying dataset SBL <ref type="bibr" target="#b93">[98]</ref> SpamCop <ref type="bibr" target="#b94">[99]</ref> WPBL <ref type="bibr" target="#b95">[100]</ref> UCEPROTECT <ref type="bibr" target="#b96">[101]</ref> SURBL <ref type="bibr">[</ref>  <ref type="bibr" target="#b23">[24]</ref> indicates that an IP address is labeled as sending SPAM messages, hosting phishing websites, or performing malicious port scans by IP blacklists (including BRBL <ref type="bibr" target="#b91">[96]</ref>, CBL <ref type="bibr" target="#b92">[97]</ref>, SBL <ref type="bibr" target="#b93">[98]</ref>, SpamCop <ref type="bibr" target="#b94">[99]</ref>, WPBL <ref type="bibr" target="#b95">[100]</ref>, UCEPROTECT <ref type="bibr" target="#b96">[101]</ref>, SURBL <ref type="bibr" target="#b97">[102]</ref>, PhishTank [68], hpHosts <ref type="bibr" target="#b67">[69]</ref>, Darknet Scanners list, Dshield [70] and OpenBL <ref type="bibr">[71]</ref>).</p><p>The authors of paper <ref type="bibr" target="#b23">[24]</ref> leveraged statistical analysis method to demonstrate the relationship between mismanagement and maliciousness. Autonomous system (AS) level was chosen as aggregated granularity to quantify the mismanagement and maliciousness of a network. On one hand, eight mismanagement symptoms were normalized as eight corresponding mismanagement metrics. The whole network mismanagement metric was also considered by combining the individual symptoms into an overall metric. On the other hand, the maliciousness of an AS was normalized by malicious IPs based on IP blacklists.</p><p>The hypothesis is that mismanagement is positively correlated with maliciousness. To prove it, firstly, Spearman's correlation was calculated between maliciousness and each mismanagement symptom. The results showed that a statistically significant positive relationship existing between all of the symptoms and the network's maliciousness. Given the overall mismanagement metric, the mismanagement metric has the strongest correlation with the maliciousness metric, which encourages the researchers to consider the overall network health instead of specific vulnerabilities or symptoms. Furthermore, the authors explored whether the mismanagement will lead to maliciousness if social and economic elements are controlled. Ultimately, by using Fast Causal Inference (FCI) algorithm <ref type="bibr" target="#b103">[108]</ref>, they found an inferred casual relationship between mismanagement and maliciousness considering social and economics.</p><p>This paper <ref type="bibr" target="#b23">[24]</ref> demonstrated that different kinds of mismanagement symptoms are profoundly correlated to the net-work's maliciousness and will ultimately lead to maliciousness. Security community should pay attention to the networks with mismanagement symptoms in order to prevent security incidents. For example, the symptoms of mismanagement can be utilized to develop a prediction system that can proactively predict which network has a high probability to be worked maliciously instead of waiting to behave maliciously in future.</p><p>There are several limitations regarding data in this work <ref type="bibr" target="#b23">[24]</ref>. Firstly, not all symptoms that reveal network mismanagement are collected and observed. To be specific, besides of the case of the Open DNS recursive resolver which can be maliciously used for DDoS attacks by amplification, there are other amplification vector attacks, such as UDP Memcached servers, to be considered. More generally, servers exposed to the Internet and accessible without authentication can also be observed. Secondly, the collection methodology, coverage and time frames are inconsistent, which may contain biases. Thirdly, the data collection and processing focus on the AS level, which may of independent interest to extend them to a more granular level in future work.</p><p>2) Discovering zero-day applications in traffic classification systems: Network traffic analytics as a critical technology is widely applied in intrusion detection, malware analysis and botnet detection, according to Miao et al. <ref type="bibr" target="#b104">[109]</ref> recent review. By capturing abnormal patterns in traffic data, traffic classification is fundamental to cybersecurity and network management. Furthermore, discovering past unknown zeroday traffic discrimination can significantly improve the accuracy of traffic classification, which is critical to improve incident response and mitigate cybersecurity incidents.</p><p>To solve the zero-day applications problem, Zhang et al. <ref type="bibr" target="#b25">[26]</ref> proposed a Robust Traffic Classification (RTC) scheme to discover previously unknown applications in traffic classification systems by utilizing supervised and unsupervised machine learning techniques.</p><p>RTC framework is composed of three modules, namely unknown discovery, "bag of flows" (BoF)-based traffic classification and system update. In the unknown discovery module, the k-means based clustering algorithm is first applied to unlabeled and labeled mixed data. If a cluster does not include any prelabeled samples, this cluster is a zero-day cluster. However, the rough estimation can lead to high TP rate. Thus, the authors set up a multiclass random forest classifier with various known classes and one unknown class to purify zero-day samples. In the "bag of flows" (BoF)based traffic classification module, the authors <ref type="bibr" target="#b105">[110]</ref> proposed a novel classification method that leverages flow correlation <ref type="bibr" target="#b105">[110]</ref> in real-world traffic to conduct traffic classification and aggregated the prediction results. Finally, the system update module was designed to learn newly identified zero-day traffic as a complementary knowledge to the system, by repeating kmeans based clustering and inspecting manually.</p><p>The datasets used for evaluation experiments combined four disparate Internet traffic traces, in order to minimize the effects of data bias caused by heterogeneous sampling points. Specifically, three traces were gathered from the public traffic data repository. And another one was captured by using a probe from an Australia's Internet service provider.</p><p>The groundtruth was set up by using previous experiences and tools concerning the signatures of applications. Besides, 20 unidirectional flow statistical features were extracted to represent traffic flows, including 2 features about packets, 2 features regarding bytes, 8 features describing packet size and 8 features concerning inter-packet size.</p><p>The authors of paper <ref type="bibr" target="#b25">[26]</ref> designed comprehensive experiments to evaluate the performance of the RTC framework. They compared their method with four state-of-the-art traffic classification methods, which are respectively random forest <ref type="bibr" target="#b106">[111]</ref>, the BoF-based method <ref type="bibr" target="#b105">[110]</ref>, the semi-supervised method <ref type="bibr" target="#b107">[112]</ref> and one-class SVM <ref type="bibr" target="#b108">[113]</ref>. Accuracy and Fmeasure were used as evaluation metrics and 100-time experiments were conducted to illustrate that the results are stable. Besides, they also explored the robustness of their method when considering various training datasets, zero-day applications, and performance with vs. without a system update module. All of the results showed that the RTC framework significantly outperformed the other four methods.</p><p>Network data in computer networks is usually encapsulated in packets, each of which consists of the packet header and packet payload. Moreover, network flow refers to a sequence of packets that originate from a source computer and are destined for a destination. This work <ref type="bibr" target="#b105">[110]</ref> demonstrated traffic data is capable of conducting intrusion detection and therefore for incident prediction as well. In general, the works that inspect the traffic at the level of the packet payload focus on textual-based protocols, while the work in <ref type="bibr" target="#b105">[110]</ref> that focuses on the statistics of network flow information is more generic.</p><p>3) Predicting which machines are at risk of infection: The current situation of the cyber-threat ecosystem is that no system seems to be invulnerable. Hence, the IT administrators are progressively shifting to look for proactive measures that can reduce the damage caused by cybersecurity incidents. As discussed earlier, Liu et al. <ref type="bibr" target="#b8">[9]</ref> utilized organizations' historical incident reports to predict cyber incidents. In a finer grained, Bilge et al. <ref type="bibr" target="#b22">[23]</ref> employed binary file appearance logs to forecast whether an enterprise machine would be infected.</p><p>The authors of paper <ref type="bibr" target="#b22">[23]</ref> come from Symantec Research Labs <ref type="bibr" target="#b109">[114]</ref>, which indicates that they can comparatively readily collect data in respect to the binaries appearing on machines. In total, the data was collected from 600K machines involving 18 enterprises. Based on the analysis, 4.4 billion binary file appearance events were reported among these machines. 89 features were designed to establish the profiles of the machines, including file download statistics, vulnerability patching behavior, application download behavior, and historical threat analysis. These features were extracted from file appearance logs of each machine, which captured the pattern of the usage and user behavior of a device.</p><p>Each machine was identified as "clean" or "infected" by using three different datasets, which were respectively a labeled dataset obtained from the AV company about known benign and malware, a dataset acquired from the AV product concerning known malware, and a telemetry dataset generated by IPS product regarding infection records. On the one hand, it is generally acknowledged that the quality of groundtruth is vital to the quality of predictors. On the other hand, the number of data waiting to be labeled is enormous. To address these problems, Bilge et al. <ref type="bibr" target="#b22">[23]</ref> introduced the semisupervised method that made use of profile similarity with labeled machines to infer fuzzy labels for unlabeled machines.</p><p>Once the features and labels of machines were well prepared, the predictive model was established by using random forest machine learning algorithm. Followed by that, a comprehensive evaluation was conducted to evaluate the predictor. As reported in paper <ref type="bibr" target="#b22">[23]</ref>, the prediction could reach 96% TPR with only 5% FPR, which is the best result in a machinelevel granularity up to now. Additionally, the semi-supervised learning method proposed to estimate labels of the unlabeled dataset is proved to enrich the groundtruth as well as remain consistently accurate.</p><p>As a concluding remark for this section, an overall description for network datasets is produced in Table <ref type="table">V</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Synthetic dataset</head><p>1) Predicting the resilience of obfuscated code against automated attacks: Code obfuscation applies transformations to the original code with the intention of improving the difficulty of analysis and tampering but maintaining the functionality of the program. Obfuscating code transformation technique is motivated by request to hide the particular implementation of a program from the unauthorized reverse engineering process <ref type="bibr" target="#b111">[116]</ref>. If attackers exploit the hidden information/code, not only will intellectual property be stolen, but also threats and incidents may happen. However, it is known that attackers can reverse engineer if given enough time and resources. Therefore, estimating the period when an obfuscated program can withstand a given reverse engineering attack is an open challenge for software obfuscation. Banescu et al. <ref type="bibr" target="#b26">[27]</ref> proposed a framework to predict the resilience of different obfuscated transformations against automated attacks.</p><p>Resilience is defined as a function of deobfuscator effort and programmer effort, namely, the time spent on deobfuscation process <ref type="bibr" target="#b112">[117]</ref>. The authors of paper <ref type="bibr" target="#b26">[27]</ref> proposed an approach to predict deobfuscation time given by software relevant features.</p><p>The groundtruth data was obtained by running automated attacks on the obfuscation C code and recording the deobfuscation effort that was assessed by execution time needed to complete an attack successfully. Ideally, the obfuscation C code should be collected from real-world as presented in <ref type="bibr" target="#b113">[118]</ref>. However, the authors found that it was hard to obtain enough amount of program data with security checks required by the study from code sharing platforms (e.g., GitHub). Therefore, synthetic code datasets were generated for the proposed approach as a substituted solution. A C program generator was designed, and 4608 C programs with various license checking algorithms were produced. After applying five obfuscating transformations <ref type="bibr" target="#b110">[115]</ref> to each of raw C programs, 23,040 synthetic obfuscation programs were created. Afterward, the deobfuscation process based on the symbolic execution attack was conducted by using free and open source software tools (e.g., KLEE <ref type="bibr" target="#b114">[119]</ref>, angr <ref type="bibr" target="#b115">[120]</ref>, etc.). Additionally, the time spent on completing the attack was recorded. After setting up groundtruth dataset, the next step is extracting features. There were 64 features extracted from synthetic programs, including 49 features characterizing the complexity of symbolic variables and 15 program features characterizing the code. By utilizing two light-weight feature selection algorithms (Pearson correlation and variable importance respectively), the top 15 most relevant features were selected.</p><p>For prediction, the approach utilized the top best 15 features to construct a regression model via several machine learning algorithms, including support vector machine (SVM), random forest (RF), genetic programming (GP) and neural networks (NNs). It can be found the authors directly used packages for regression algorithms in R <ref type="bibr" target="#b116">[121]</ref> to do statistical computing.</p><p>Lastly, the evaluation of the approach was conducted from the following two aspects: (1) The accuracy of prediction was calculated. (2) The Smart Obfuscation Engine (SObE) was proposed to combine the approach with obfuscation tools. The accuracy of predicting execution time of the symbolic execution-based deobfuscation attacks could achieve 90% for 80% programs in their synthetic dataset. Also, the approach could be applied to SObE, which compared the prediction of deobfuscation time with the attacker's budget. If the prediction time is longer than the attacker's budget, the obfuscated program is the output. Otherwise, the developers should change the obfuscation transformation method to protect their code and withstand attack. Although this work is significant in software protection as well as decrementing the risk of cybersecurity attacks, the real word programs should be considered to add into the dataset to improve the robustness of the model.</p><p>As a concluding remark for this section, an overall description for synthetic datasets is produced in Table <ref type="table">VI</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Webpage data</head><p>1) Discovering black keywords used by underground economy: Yang et al. <ref type="bibr" target="#b27">[28]</ref> developed Keyword Detection and Expansion System (KDES) to discover black keywords used by the underground economy automatically. The underground economy is a kind of activity which transacts illegal products between buyers and merchants. Communicating online with Black keywords is commonly used by the underground economy to evade outsiders. Nonetheless, black keywords are continually changing and updating. Consequently, capturing black keywords without coming to the surface is significant in predicting future online shady business and destroying the underground economy.</p><p>KDES took advantages of blackhat search engine optimization (SEO) web pages as data source to extract unknown black keywords. The reasons why the blackhat SEO web pages are appropriate to discover black keywords are two-fold: first, due to the illegal transaction, the underground merchants rely on using black keywords to present and promote their products; second, the underground merchants tend to make use of blackhat SEO facilitating their websites ranking for taking up online marketplace. Based on these two reasons, the raw data collected in paper <ref type="bibr" target="#b27">[28]</ref> was web page data, including 2,733,728 SEO pages, 60,000 porn pages and 3,424 gambling pages marked as "evil" by Baidu. KDES suggests a new direction which is big data analytics in dealing with security problems believed difficult by traditional strategies.</p><p>There are three components involved in the KDES architecture: (1) keywords extraction; (2) keywords expansion;</p><p>(3) core words identification. Keywords extraction module extracted keywords from text inside the HTML tag a href. After removing the duplicate words, a gigantic word list has been left. By restricting the length of keywords and exploring the consequences resulted in the keywords, the range of keywords greatly narrowed down. The similar keywords were added to the keywords list in the keyword expansion system, which leveraged the functionality of related search. However, the great amount of keywords is a heavy burden on the security analysts. To solve this problem, core words identification module distinguished the "core word" (closely related to underground economy) from "filter word" (less meaningful words). The remaining keywords list was important for analysts to investigate and understand the online underground economy as well as prioritizing their tasks.</p><p>The performance of KDES system was evaluated on the accuracy of identifying keywords as black. For those black keywords, the security analysts queried them on popular online underground economy communication channels, including Baidu Tieba, QQ groups, and Baidu. They sampled 1000 keywords and verified 943 keywords as black (94.3% accuracy). Based on the obtained black keywords, an extensive measurement regarding the online underground economy in China was carried out regarding the underlying infrastructure, the criminals behind, and the impact on the cyber environment, which effectively provided solutions to prevent the illegal promotion by the underground economy. However, the system resilience can be strengthened. For instance, the attackers could relocate the black keywords in anchors to other sections under the page, which can escape from the parser. Meanwhile, the KDES can be advanced by defending evasion implemented by adversaries. Malicious websites Each website is labeled as malicious or benign 14,425 websites from the "search-redirection attacks" list <ref type="bibr" target="#b117">[122]</ref>  <ref type="bibr" target="#b118">[123]</ref> 336,671 benign websites from entire.com zone file (Validating by PhishTank blacklists [68], "search-redirection attacks" list <ref type="bibr" target="#b117">[122]</ref> [123], DNS-BH <ref type="bibr" target="#b119">[124]</ref>, Google SafeBrowsing <ref type="bibr" target="#b120">[125]</ref>, and hpHosts blacklists <ref type="bibr" target="#b121">[126]</ref>)</p><p>Benign websites <ref type="bibr" target="#b7">[8]</ref> 26 2) Predicting website will become malicious or not: Successfully detecting whether a target website is malicious or benign with high accuracy has been achieved with concerted efforts by researchers. While, there is a more effective and less passive method proposed, which is to forecast whether the website will become malicious or not in advance. Soska et al. <ref type="bibr" target="#b6">[7]</ref> proposed a classification system which can predict whether a currently benign website has the high risk of becoming malicious in future. This system is not only beneficial to search engines but also useful to blacklists and website operators.</p><p>The authors designed, implemented and evaluated a machine learning classifier which could proactively identify whether a website would be compromised or not within one year. When it comes to the groundtruth, both the benign and malicious websites were included in the dataset to set up machine learning classifier. Two blacklists were used as groundtruth for malicious websites: PhishTank [68] and a list of websites that have been injected by "search-redirection attacks" <ref type="bibr">[122] [123]</ref>. 34,922 websites from PhishTank and 14,425 websites from the "search-redirection attacks" list were archived as the groundtruth for malicious websites. To collect benign websites, the authors randomly sampled entire.com zone file and yielded 337,191 website archives. Among these 337,191 websites, 27 websites infected by "search-redirection attacks" and 72 websites matching PhishTank entries were discarded. In addition, a complementary 421 sites collected from the DNS-BH <ref type="bibr" target="#b119">[124]</ref>, Google SafeBrowsing <ref type="bibr" target="#b120">[125]</ref>, and hpHosts <ref type="bibr" target="#b121">[126]</ref> blacklists were removed from the benign corpus. Eventually, the number of websites in benign corpus was 336,671.</p><p>Features are critical to the decisions of a classifier. To effectively differentiate the websites that will become malicious, features derived for the classifier should characterize the websites from various perspectives, including the appearance of the website, traffic information and textual contexts, and so on. In paper <ref type="bibr" target="#b6">[7]</ref>, the classifier adopted two main features by referencing the Alexa Web Information Service (AWIS) <ref type="bibr" target="#b87">[92]</ref> and the content information of a website. AWIS information covers the popularity ranking of a website, the number of links to the website, load percentile, adult site or not and the number of reach per million; the content information of a website includes the lists of tags from all the pages survived from the acquisition and filtering process. To yield the best classification performance, statistic-based dynamic feature extraction was conducted. For each tag, the balanced accuracy of a tag was calculated and ranked. When dealing with the problem that the tags used for classification may change due to the attacks against websites evolve, the windowing technique was applied to the feature extraction process. However, the limitations of dynamic features introduce the possibility that adversarial machine learning approach affects the performance of the system, which deserves further analysis.</p><p>C4.5 decision trees classifier was chosen as the prediction model in this system. It is hard to evaluate whether the prediction result is correct or not immediately, so the alternative method is to use the past data to simulate the prediction done in the past and evaluate the prediction results by using the present data. A ROC curve was generated for the evaluation of the classifier's performance. Within a one-year time horizon, the prediction model could achieve 66% true positives and 17% false positives.</p><p>3) Automatic identification of unknown web-based infection campaigns: While people enjoy various kinds of wonderful services online and communicate globally, software used to support the functionality of a website might be vulnerable to attackers. The attackers inject malicious code snippets by exploiting the server-side vulnerabilities. If users download or install the malware deriving from the client-side vulnerabilities, they will be infected. For the attackers, finding a vulnerability and generating a malicious code snippet need investing lots of time and effort. To save resources, the attackers usually launch an infection campaign throughout multiple websites (potentially thousands) by using carefully crafted infection vectors. For this reason, it is a great opportunity to discover probably thousands of malicious websites if an unknown infection campaign is identified.</p><p>Borgolte et al. <ref type="bibr" target="#b7">[8]</ref> proposed a δ-system that can automatically identify web-based infection campaigns. The system adopted static analysis method to discover previously unknown infection campaigns which may involve thousands of malicious websites. In the prior work, researchers were devoted to detecting the malicious activities based on single website/URL detection by using dynamic analysis approach. However, the δ-system is able to identify the infection campaigns and predict malicious websites which are under surface before. The δ-system follows a four-step process. The first step is to retrieve and normalize the website. The current version and the base version of a website are retrieved, and the source code is saved after normalization. The normalization includes normalizing capitalization, reordering attributes, discarding invalid attributes and normalizing attribute's value. Secondly, the similarity between the base and up-to-date version of the website is measured. The similarities are computed via fuzzy tree difference algorithm, which performs the comparison between the Domain Object Model (DOM) tree of the base website and the DOM tree of the current website. Thirdly, the similarity vector is clustered based on similarity measurement. The density-based clustering algorithm is applied for this step, named Ordering Points To Identify the Clustering Structure, with Outlier Factors (OPTICS-OF) algorithm proposed by Breunig et al. <ref type="bibr" target="#b122">[127]</ref>. The outputs of the clustering are defined as infection campaign, benign trend and new campaign separately. The δ-system relies on an external detection system instead of detecting the malicious behaviors by itself. The last step is to generate the identifying signature. A signature is simply generated by illustrating each node's textual representation as a Deterministic Finite Automaton (DFA). The identified signature can be served to security analysts and intrusion detection/prevention system.</p><p>The dataset in paper <ref type="bibr" target="#b7">[8]</ref> contains the websites being crawled from January 2013 to May 2013 (4 months), counting as 26,459,103 distinct website pairs. Also, there are six main features selected for clustering, including three kinds of binary features (template propagation, script inclusion, and inline frames respectively) and three categories of attribute values (Shannon entropy, character count and Kolmogorov complexity respectively). The δ-system successfully identified the infection campaigns that were previously unknown to the public. Once a new infection campaign is identified, the websites in the same clusters have the significantly high probability of being infected by the same infection campaigns in the past or future. For the potential malicious websites, the prediction is significant to the websites and users for the preventative purpose. A real case which was successfully identified by δ-system was the cool exploit kit infections of Discuz!X. 15 different websites in the same cluster were using the discussion platform "Discuz!X" that redirected to a specific infection campaign. It has been proved that the system significantly improved the detection speed and reduced the evaluation overheads compared with the previous work via in-depth analysis and evaluation, which contributes to the real-world deployment. Nevertheless, some limitations, such as relying on the external analysis system that utilizes dynamic analysis, defending step-by-step injection, and countering evolution of infection vectors, still exist in the detection system.</p><p>As a concluding remark for this section, an overall description for webpage data is produced in Table <ref type="table">VII</ref>.</p><p>F. Social media data 1) IOC discovery: Cyber Threat Intelligence (CTI) is defined as "evidence-based knowledge, including context, mechanisms, indicators, implications and actionable advice, about an existing or emerging menace or hazard to assets that can be used to inform decisions regarding the subject's response to that menace or hazard", according to Gartner <ref type="bibr" target="#b125">[130]</ref>. CTI is usually collected in the manner of indicators of compromise (IOC), which can be automatically transformed and deployed to different kinds of security defense mechanisms, such as intrusion detection system, when IOCs are recorded in a format of a specific threat information sharing standard. IOC is significant for an organization to gain visibility into ever-changing security threats, identify early indicators of threats and change protection strategies. However, facing the tremendous growth of information sources, discovering and generating high-quality IOC is a challenge as well as an opportunity.</p><p>Liao et al. <ref type="bibr" target="#b28">[29]</ref> implemented iACE system to automatically discover IOC and generate OpenIOC (a kind of IOC standard framework) compatible, semantic-rich intelligence from popular technical blogs (including AlienVault, Malwarebytes, Webroot, etc.). Furthermore, the insights gained from more than 71,000 articles gathered from 45 popular technical blogs shed light on the unknown relationships across different security attack incidents, especially their shared infrastructure resources, and the impacts on security protection and attack evaluations.</p><p>The architecture of iACE consists of 5 modules: (1) Blog Scraper (BS): BS is designed to crawl technical articles from technical blogs. (2) Blog Preprocessor (BP): By leveraging NLP techniques, the IOC-irrelevant articles are filtered out in the BP. (3) Relevant-content Picker (RCP): RCP converts pictures and other special contents in the articles to text, splits sentences and selects the candidate sentences by allocating with a kit of context terms and regexes. (4) The relation checker (RC): RC parses the grammatical structure correlating the context terms and the IOC candidates, and decides whether the latter is indeed an IOC. (5) IOC Generator (IG): according to the OpenIOC standard, IG automatically generates header and definition parts for all identified IOCs.</p><p>There are two machine learning classifiers deployed in the system. The first is a topic classifier used in RCP module, separating the non-IOC articles from the IOC articles. The classifier is trained on a dataset including 150 IOC articles and 300 non-IOC articles by using support vector machine (SVM) algorithm. It is worth mentioning that the IOC files are from 2 public feeds, including iocbucket <ref type="bibr" target="#b126">[131]</ref> and openiocdb <ref type="bibr" target="#b127">[132]</ref>. Topic words, article length and dictionary-word density are calculated and used as features. The second classifier is a relation checker, confirming the presence of IOC relationships between a context term and an IOC candidate within a sentence. The classifier utilizes logistic regression algorithm based on the features calculated from dependency graphs which are transformed from the candidate sentences consisting of IOC candidates and context terms. 1,500 true IOC sentences and 3,000 false IOC sentences constitute the training dataset. The dataset used for evaluation was collected from 45 security-related technical blogs between April 2003 and May 2016, counting as 71K articles. The system can achieve 98% precision and 100% recall when dealing with finding IOC articles problem. In terms of identifying true IOCs and context terms, the classifier can reach 98% precision and 92% recall. On average, inspecting a real-world article cost about 0.25 seconds. The accuracy and performance of the system can satisfy the demand of discovering high-quality IOCs, which provides immediate protection to organization security systems.</p><p>Eventually, the iACE system automatically discovered 900K IOC with the context. By inspecting and analyzing the IOCs, the authors reported unprecedented findings which gave valuable guides and warnings to protect organizations' assets. Some examples: (1) The authors found that unrelated attack incidents were related, such as sharing the same infrastructures. (2) For the attackers, they might change the attack strategies facing with the new release of exposed IOCs. (3) But, for organizations, they usually react slowly to the release of IOCs. ( <ref type="formula">4</ref>) Regarding open-source intelligence' quality, they found the Hexacorn and Naked Security can provide timely and comprehensive messages about an emerging attack. These findings uncovered the security insights that were never known before, as well as providing profound suggestions on security defense and protection.</p><p>The limitations of NLP techniques and presentation methods affect the discovery results. How to design and develop domain-and topic-specific tools is crucial in this field. On the other hand, other intelligence sources, such as research papers, can be considered to gather to extend this system.</p><p>2) Extracting and encoding cyber attacks: Social media as a gold mine of information is popularly used as a sensor for different kinds of events, such as earthquake prediction, disease outbreak forecast, and presidential elections prediction <ref type="bibr" target="#b128">[133]</ref> [134] <ref type="bibr" target="#b130">[135]</ref>. It is an opportunity to make use of social media as the crowdsourced sensor of cyber attacks (e.g., data breaches, distributed denial of service (DDoS) attacks, and account hijacking). Gaining insights into cyber incidents is helpful to prevent the individuals, organizations and nations from the losses and threats coming from various cyber attacks. Khandpur et al. <ref type="bibr" target="#b30">[31]</ref> proposed a dynamic event trigger expansion (DETE) approach to extract cyber events accordingly providing situational awareness into cybersecurity events. Compared with <ref type="bibr" target="#b32">[33]</ref>, this approach extracted and furthermore characterized the security events evolving over time in a weakly supervised method.</p><p>The approach consists of three modules, including target domain generation, dynamic typed query expansion, and event extraction. The module of target domain generation is designed for filtering related tweets which serve as the source of cyber event extraction. Given a limited and fixed seed query for cyber attack events and the collection of tweets, the tweets most related to the seed query are retrieved in this step. After converting the tweets and given seed query into dependency tree form, the convolution tree kernel <ref type="bibr" target="#b131">[136]</ref> algorithm is used to calculate the similarities between seed query and all collected tweets based on shared longest common paths. Both the semantic and syntactic constraints are considered when measuring the similarities between seed queries and tweets, to filter out noise tweets. Secondly, the authors proposed a dynamically typed query expansion method by leveraging convolution kernels as well as dependency parses. A set of expanded queries are generated which represent the relevant concepts delivered by tweets from the target domain. The final step is event extraction. The query expansions are clustered by using affinity propagation <ref type="bibr" target="#b132">[137]</ref> algorithm. The representatives of the clusters are extracted as exemplars and annotated to the type of cyber attack. The representative of the clusters comes from the expanded queries with the highest similarity value matching seed query. Finally, an event is represented by the representative (discovered event), date and seed query (event type).</p><p>A large stream of tweets was gathered from August 2014 to October 2016. After removing retweets, the number of collected tweets is 5,146,666,178. To evaluate the approach, the authors used the Gold Standard Reports (GSR) on cybersecurity incidents to severe as groundtruth, including Hackmageddon <ref type="bibr" target="#b123">[128]</ref> and Privacy rights <ref type="bibr" target="#b124">[129]</ref>. From the above two sources, the security event type, date, victim organization as well as description can be checked.</p><p>Regarding the performance evaluation, the experiments focused on three high impact security incidents, which are namely data breach, DDoS and account hijacking. Two highlycited previous work were chosen as baselines for comparison, specifically, using expectation regularization to generate target domain <ref type="bibr" target="#b32">[33]</ref> and using bursty keywords to discover cyber event <ref type="bibr" target="#b133">[138]</ref>. The approach can achieve around 80% precision for data breach and DDoS events, and 66% precision for account hijacking respectively, outperforming the two baselines. The authors also used case studies to illustrate the performance of their method. It is shown that this approach not only discovered typical security events ( e.g., targeted DDoS attacks on Sony and Dyn, Ashley Madison website data breach and Twitter account hijacking) but also successfully extracted the cybersecurity attack events that haven't been recorded in the GSR, by validating the results using Google search. The class of attacks can be broadened in future work. Besides, the sequential dependencies of a kind of attack can be modeled to characterize the prevalence of the cybercrime.</p><p>3) Predicting mobile app security-related behaviors: As the popularity of mobile phones, the security and privacy of mobile apps become a concern to end users, app developers and app market <ref type="bibr" target="#b134">[139]</ref>. Google Play provides a platform on which users can post valuable reviews from end users' perspective. Kong et al. <ref type="bibr" target="#b29">[30]</ref> designed a system named AUTOREB, which leveraged the reviews from Google Play to predict the app security behaviors. Although the security-related behaviors are restricted to spamming, financial issue, over-privileged permission and data leakage in this work. This is the first work that infers the security-related behaviors of an app according to users' reviews.</p><p>The goal of the system is to automatically predict the security-related behaviors based on the numerous users' reviews. Due to one review can be assigned to more than one security behavior categories, the prediction model should be set up by using multi-label classifier. The authors proposed to predict the security behavior of an app from review-level as well as app-level. The review-level security behavior inference engine aims to label a review to a particular behavior category automatically. The latter one utilizes crowdsourcing technique to predict the security behavior of an app, by assigning more credit to trustworthy users.</p><p>Each review is treated as a sample, being fed into machine learning model after labeled manually corresponding to security-related behaviors and extracted security-related features. In respect to review-level security behavior inference, three annotators are working together to decide the label of each user review. The security-related features are extracted from each review, including words and phrases closely related to the four security concerned categories. In addition, the features are augmented and expanded by adopting "relevance feedback" information retrieval technique <ref type="bibr" target="#b135">[140]</ref> to add more "relevant" words and phrases. Each review is abstracted into a feature vector denoted by a bag-of-words (BOW). The features and labels of instances are fed into sparse SVM machine learning classifier to train a multi-label classifier. For the app-level security behavior inference engine, crowdsourcing technique <ref type="bibr" target="#b136">[141]</ref> is applied to aggregate the security labels from review-level to app-level. By considering the credibility of different users, the trustworthy users are given more credit based on two-coin model <ref type="bibr" target="#b136">[141]</ref> instead of majority voting model <ref type="bibr" target="#b136">[141]</ref>.</p><p>The dataset includes reviews clawed from Google Play. One dataset L was collected for validating review-level security behaviors inference during November 2014, which contains 19,413 user reviews on 3,174 apps. Each review was labeled by three workers reaching a consensus. The other dataset D was collected for validating the effectiveness of app-level security behavior inference during December 2013 to May 2014, which includes 12,783 apps with 13,129,783 reviews from 2,614,186 users. The authors did not hire enough labors to label security behaviors of each app in dataset D.</p><p>For review-level security behavior inference, the dataset L is evenly split into training set and testing set. The metrics used for evaluation are precision, recall and F1 value. The accuracies of the classifier for identifying "spamming", "over-privileges permission", and "data leakage" are 91.96%, 95.99% and 93.46% respectively. The exceptional case is that regardless of "financial issue", the classifier labeled the reviews as "financial issues", while the users did not complain about the "financial issues". Besides, a base-line using keyword-based method was compared with AUTORBF. AUTORBF exceeded a large margin with 51.36% in accuracy. For app-level security behavior inference, due to the lack of groundtruth, the authors listed 50 apps that existed user complaints about security issues. The security-related behaviors predicted by AUTOREB can be regarded as cyber threats indicators to alert users, mobile app developers, and app market administrators.</p><p>In general, this is the first work leveraging user reviews to analyze the security risk of an app. The four kinds of security behaviors intuitively come from common sense, which can be extended to other categories of risk behaviors.</p><p>As a concluding remark for this section, an overall description for synthetic datasets is produced in Table <ref type="table">VIII</ref>.</p><p>G. Mixed-type data 1) Vulnerability exploits prediction: The number of software vulnerabilities is dramatically growing in these years. Certain vulnerabilities might be exploited after a long time, while numerous vulnerabilities need to be quickly responded. Hence, it is of great importance to prioritize the response to the vulnerabilities.</p><p>Before the vulnerabilities being exploited, hackers, security vendors and system administrators frequently discuss the vulnerabilities on social media, such as Twitter, to discuss technical details and sharing experiences. Sobottke et al. <ref type="bibr" target="#b31">[32]</ref> designed an exploit detector based on Twitter, which can predict the vulnerabilities to be exploited in real-world.</p><p>Based on the groundtruth about exploits and the information posted on the Twitter before vulnerabilities being exploited, the exploit detector was set up by using supervised machine learning techniques. The authors collected 287,717 tweets in total which included explicit CVE IDs. The groundtruth about exploits comes from three data sources, according to CVE IDs mentioned in the descriptions of Symantec's anti-virus (AV) <ref type="bibr" target="#b72">[76]</ref> and intrusion-protection (IPS) signatures <ref type="bibr" target="#b137">[142]</ref>: (1) public proof-of-concept exploits by querying ExploitDB <ref type="bibr" target="#b71">[75]</ref>; (2) private proof-of-concept exploits by querying Microsoft security advisories' Exploitability Index <ref type="bibr" target="#b72">[76]</ref>; (3) real-world exploits by querying Symantec's Worldwide Intelligence Network Environment (WINE) <ref type="bibr" target="#b73">[77]</ref>. The dates of each vulnerability known to the security community and vulnerability exploited were both recorded. Furthermore, the vulnerabilities are labeled as "real-world exploits" or "not exploited".</p><p>Features selected for the classifiers include Twitter features and database information features. Twitter features are extracted from the word distributions of tweets containing the keyword "CVE" and the Twitter traffic data (e.g., number of tweets) involving the corresponding CVEs. In order to improve the performance and robustness of the detector, Common Vulnerability Scoring System (CVSS) (e.g., CVSS score) and database (including National Vulnerability Database (NVD), and Open Sourced Vulnerability Database (OSVDB)) features (e.g., NVD last modified date and OSVDB category) are considered in this study, which are proven useful in previous work for predicting exploits <ref type="bibr" target="#b138">[143]</ref>. After the mutual informationbased feature selection process, 67 features are reserved for training and testing the exploits classifier.</p><p>After feature engineering, these features are fed into a support vector machine (SVM) classifier. The output of the binary classifier is whether the vulnerability mentioned in tweets will be exploited or not. Samples are randomly selected from the dataset after shuffling ten times. For each round of sampling, 50% of the available data is used for training, and the remaining 50% data is used for testing.</p><p>The detector is evaluated for the precision and recall, and assessed by the detection time leading up to the real-world existing time recorded in the dataset. The detector can detect the exploits in advance of the existing datasets two days in median. It is shown that the Twitter-based detector has fewer false positive compared with Common Vulnerability Scoring System (CVSS) detector and increases the precision by one order of magnitude. Moreover, the authors introduced three kinds of adversary machine learning attacks to the exploit detector, which are randomly posting tweets without knowledge of features (blabbering adversary), mirroring words' statistic information according to exploited vulnerabilities (word copycat adversary) and manipulating all Twitter features (full copycat adversary). They also simulated the above three types of adversaries and presented the bounds for the damage to their Twitter-based exploits detector for the evaluation, which illustrates the robustness of their method.</p><p>Lastly, it should be mentioned that there are still two limitations in the above method. Firstly, the training and testing data are randomly split, which results in temporal mixing of future and past data. Secondly, although the authors evaluated the utility of tweets data, they never compared it with those utilizing readily available summary on the vulnerability.</p><p>2) Predicting the future structural changes of the network: Network datasets include abundant data recording the interactions and/or communications among different activities (for example, personal communications via phone or e-mail, interactions on social media, network traffic information between hosts and servers, and so on).</p><p>The structure of an active network has a notable pattern and will change as time goes on. The temporal dynamics are critical to a system, which facilitates finding anomalies in the system, detecting fraud and intrusions and allocating increasing resources. Rossi et al. <ref type="bibr" target="#b24">[25]</ref> proposed a dynamic behavioral mixed-membership (DBMM) model to capture the "roles" of individual nodes in the network graph and predict how they change over time.</p><p>Given a sequence of time-evolving network snapshots, the authors proposed a DBMM framework that can investigate the property of the network, understand behaviors of the network, detect anomalies in the system and predict future structural changes through the following steps: (1) The first step is to automatically learn representative feature that represents each node in a given graph by leveraging method proposed in <ref type="bibr" target="#b139">[144]</ref>. <ref type="bibr" target="#b1">(2)</ref> The second step is to extract features from each graph. (3) The third step is to discover behavioral roles that represent the common patterns of behaviors based on extracted features by assigning a probability distribution to each node in the network. (4) Next step is to extract these roles according to the network snapshots iteratively. ( <ref type="formula">5</ref>) Finally, a predictive model which depicts these time-varying behaviors is learned. Therefore, abnormal behavior can be found from unusual structural changes. In a nutshell, DBMN has four main advantages: (1) User-defined parameters are not required in this algorithm. (2) By parallel computing, the features, roles and transition models are learned individually, improving the scalability of the model. (3) The behavior representation is interpretable. (4) The model is flexible and applicable to all kinds of networks which change over time.</p><p>In order to validate the DBMM, real-world datasets and synthetic datasets were both applied to the model. Nine real-world datasets were respectively Twitter "who-followswhom" network dataset, Twitter "reply-to-messages" network dataset, University emails network dataset, enterprise network traces, Facebook network dataset <ref type="bibr" target="#b98">[103]</ref>, Enron Inc. email communications network dataset <ref type="bibr" target="#b99">[104]</ref>, Oregon RouteViews project internet dataset <ref type="bibr" target="#b88">[93]</ref>, internet movie database and MIT mobile-phone communications network dataset. Besides, the synthetic data was generated in the form of graphs that were probabilistically constructed with four main patterns: "center of a star", "edge of a star", "bridge nodes" (connecting stars/cliques), and "clique nodes". Based on the above realworld and synthetic datasets, the performance of predicting future behavior of nodes was evaluated in two ways: (1) using loss function to compare the predicted behavioral snapshot to true behavioral snapshot; (2) using predicted behavioral snapshot to predict the role of each node in the network, and then evaluating the predictions by using Area Under the ROC curve (AUC). The result showed that the model could outperform the sensible baseline models with few exceptions. When using the synthetic dataset to validate the model, the accuracy in detecting anomalous behavior could achieve 88.5%.</p><p>3) Discovering security events on a specific event category: Twitter, as a popular social media platform, contains rich and timely information including the events happening in the world. Abundant information from social media not only facilitates people's life but also boosts the economy. However, information overload has become more and more common as ever-increasing amounts of information spread online. When it comes to security events, most users prefer to get a simple indicator (e.g., breaking news) or prediction of a specific attack rather than receiving a great number of aimless security-related information. For the security analysts, the enormous amount of messages spread in social media are hard to monitor and analyze.</p><p>Faced with the overload security-related social media information, Ritter et al. <ref type="bibr" target="#b32">[33]</ref> proposed an approach to discover cybersecurity-related events by using a weakly supervised method. This approach is the beginning work to discover and look into security-related incidents from social media. The approach automatically extracts and defines the new security event category based on the raw Twitter stream by given a handful of historical seed event samples.</p><p>The architecture of the approach consists of two modules: extracting event candidates from Twitter, and training a classifier with positive seed and unlabeled event candidate data to determine whether the event candidate can describe a new instance of the event category.</p><p>Three traditional security event categories were studied in this work as a proof-of-concept, namely, Denial of Service (DoS) attacks, account hijacking and data breach. The historical seed event was symbolised by the entity involved in the event, as well as the event date. The number of seeds for each category of events as mentioned above is respectively 15 (e.g., (Spamhaus, 2013/03/18)), 10 (e.g., (associated press, 2013/04/23)) and 11 (e.g., (citi, 2011/06/09)). The unlabeled event candidates were collected from January 17, 2014, until February 20 by tracking user-provided keywords associated with the event type. In their experiment, keywords were respectively DDoS, hacked and breach for DoS attacks, account hijacking and data breaches. Candidate events matching keywords associated with the event type were gathered by using Twitter API. Finally, there were 570 candidate DDoS attacks events, 4,014 extracted candidate account hijacking events, and 1,728 data breach events being gathered during the data collection process.</p><p>For feature engineering, two collections of binary features were considered for identifying event type. The first feature set defined the entity by extracting the contextual words and parts of speech nearby the entity. The second set consisted of contextual features around the tracked keyword. In total, there were 3,790 features for DDoS attacks, 52,995 features for account hijacking and 11,271 features for data breach being extracted.</p><p>Due to the fact that not all of the event candidate will fit the event category, the classifier was designed to determine which event candidate fits the event category and remove distractors. For example, some event candidates only present a general knowledge of an event category or promote a product, which should be filtered out. In traditional information extraction, the approach is to require substantial annotation effort to create a comprehensive event triggers and arguments corpus by security experts. According to the annotations, a supervised machine learning classifier was set up to extract new event instances. In this paper, the authors customized the learning problem by using positive and unlabeled examples and proposed a new strategy that regularized the label distribution over unlabeled samples in the direction of a user-specified expectation of label distribution for the keyword.</p><p>To evaluate the performance of the model, the authors manually sampled candidate events for each event category and compared the model's prediction results against expert judgments. Furthermore, the confirmation of a discovered event was also validated and confirmed by measuring computer network traffic. The precision and recall curves of the model were presented and observed compared with three baselines (including heuristically labeling negative examples <ref type="bibr" target="#b140">[145]</ref>, one-class SVMs <ref type="bibr" target="#b141">[146]</ref> and semi-supervised EM). It was demonstrated that the approach dramatically outperforms, compared with the other two novel and competitive baselines. Aggregating multiple sources of social media to discover security events should be considered as a future direction.</p><p>We put the description of datasets mentioned in this Section in corresponding Table <ref type="table">III</ref> to Table <ref type="table">IV</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CHALLENGES AND FUTURE DIRECTIONS</head><p>In the preceding section, we have surveyed the state-ofthe-art systems/schemes of predicting and discovering cybersecurity incidents. Nevertheless, the progress is still in the infant stage, and many critical issues might have been overlooked for simplicity. In the following, we discuss crucial research challenges that need to be addressed and propose future directions for researchers who are interested in this area, in line with the research methodology described in Section II.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cybersecurity incident analysis</head><p>The first step of predicting and discovering cybersecurity incident is to analyze cybersecurity incident from the different point of view as illustrated in Section II. The security model is set up based on observations from cyber incident analysis. From Table <ref type="table">IX</ref>, we find that most of the work analyzed cyber incidents in different perspectives, except <ref type="bibr" target="#b24">[25]</ref> which proposed a model to detect anomalies in extensive network data instead of targeting a specific cyber incident.</p><p>To thoroughly analyze a cybersecurity incident, some analysts attempted to find information that reflects cybersecurity incident from the side. In <ref type="bibr" target="#b29">[30]</ref>, the researchers found few of the mobile apps reviews may relate to security and privacy issues when trying to utilize reviews from Google Play to discover potentially malicious apps. Also, some researchers <ref type="bibr" target="#b31">[32]</ref> [33] <ref type="bibr" target="#b30">[31]</ref> made an attempt to get indirect evidence on cybersecurity incidents from Twitter, however, they found that only a small subset of Twitter users discuss vulnerability exploits <ref type="bibr" target="#b31">[32]</ref> and security incidents <ref type="bibr" target="#b30">[31]</ref>  <ref type="bibr" target="#b32">[33]</ref>. Although these kinds of information are valuable, relevant information is hard to extract with high quality and sufficient number, which challenges to infer security incident related characteristics. Hence, expanding the way of thinking rather than focusing on a single angle can be helpful to analyze a security incident. As a complementary solution, Howard and Longstaff's security incident taxonomy provides us a future direction to comprehensively analyze an incident. Specifically, as shown in Figure <ref type="figure" target="#fig_3">3</ref>, an incident can be analyzed through observation by seven viewpoints, including types of attackers, exploit tools, vulnerabilities that have been exploited, attackers' actions, targets, unauthorized results of incident and objectives of attackers step by step <ref type="bibr" target="#b142">[147]</ref>  <ref type="bibr" target="#b143">[148]</ref>. Also, the taxonomy gives some tips for collecting data related to cyber incidents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Security problem modeling</head><p>It is worth mentioning that the ultimate objective of cybersecurity incident prediction and discovery is to protect organizations, governments, business operators, even end users from incident instead of generating an ambiguous prediction result. If the result of prediction or discovery is unable to act upon for a security unaware operator, there seems to be little point in the forecast.</p><p>Although the existing work has defined and modeled prediction/discovery problems, in accordance with different kinds of incidents, as summarized in Table <ref type="table">II</ref>, there is still a long way to make the problem refined, as well as making it possible to improve cyber resilience defined as "the ability to continuously deliver the intended outcome despite adverse cyber events" <ref type="bibr" target="#b144">[149]</ref>. For example, translating risk profiles into actionable security recommendations is a direction for future work <ref type="bibr" target="#b17">[18]</ref>  <ref type="bibr" target="#b9">[10]</ref>. Also, by obtaining information on the monetary impact of each incident type, the prediction can provide more economically-informed recommendations. Recent work has shown that developing new technical solutions may be less efficient than giving social or financial incentives for improving overall security <ref type="bibr" target="#b145">[150]</ref>  <ref type="bibr" target="#b146">[151]</ref>. It is shown that proper incentives to encourage management that one may reduce incident is worthwhile to study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Data collection and processing</head><p>Predicting and discovering cybersecurity incident is a datadriven problem. Forecasting future incident with high accuracy rises with the assumption that the dataset is representative, authentic and comprehensive. Hence, how to guarantee that the collected data satisfying the above three criteria is a challenge.</p><p>Firstly, the representative data refers to the samples with no biases and are typical of the incident to which they belong can be described. Whether the results of the model can generalize for incidents that were not reported, depends on For example, benign websites are validated by five reputation blacklists in <ref type="bibr" target="#b6">[7]</ref>, which must have never been issued in any blacklist. Moreover, Kong et al. <ref type="bibr" target="#b29">[30]</ref> adopt crowdsourcing approach to pay more credits to trustworthy users, which proposes a solution to distinguish and sort out more reliable samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Feature engineering/representation learning</head><p>The performance of machine learning algorithm heavily depends on the choice of features or data representation. On this account, lots of efforts are directed towards data preprocessing and transformations that can lead to a representation of data to support efficient machine learning. From Table <ref type="table">IX</ref>, it is shown that most of the work adopted feature engineering relies on human ingenuity to extract discriminative features from data, which is essential but requires domain-specific expert knowledge, human resources and wealth. Sometimes, critical underlying factors hidden behind the data are even overlooked by the human. Representation learning is highly desirable and has achieved remarkable success both in academia and in industry, including speech recognition and signal processing, object recognition, natural language processing, and transfer learning. Bengio et al. <ref type="bibr" target="#b47">[48]</ref> summarized the recent work in representation learning, providing multiple solutions for generating a good representation. Using representation learning that identifies and disentangles the underlying explanatory factors hidden in the observed data, significant advances could be made to cybersecurity incident prediction and discovery. If successful, tremendous breakthroughs are possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Model customization</head><p>When dealing with security incident related problems, the existing DM/ML algorithms and models, and NLP tools are seemed hard to use without customization, let alone achieving satisfied performance directly.</p><p>When it comes to DM/ML algorithms and models, except that few work customizes the model according to the research problem, features, and outcome as shown in table IX, most of the work directly uses machine learning model as a black-box by running packages in Python or R.</p><p>The challenge is also pretty apparent when processing security-related text. On the one hand, it is known that NLP is highly domain-specific. Those NLP systems designed for one domain hardly work with high quality on the other domains. On the other hand, the cybersecurity-related vocabularies (e.g., online underground black keywords <ref type="bibr" target="#b27">[28]</ref> and IOCs <ref type="bibr" target="#b28">[29]</ref>) are rapidly evolving and significantly different from the commonly used vocabularies.</p><p>In a nutshell, customizing model according to the project requirement and designing domain-specific NLP tools are possible to be a stepping stone to achieve higher performance cybersecurity incident prediction and discovery approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Evaluation</head><p>The output of prediction should be a fact about future. No one can give the right answers until the day really comes.</p><p>Similarly, the outcome of discovery is supposed to be a previously unknown issue. Due to lack of knowledge of the future and significant amount of new findings, challenges are risen from how to evaluate the results of prediction and discovery properly.</p><p>In respect to verifying prediction result, the alternative approach for waiting for the arrival of future is to use past data to simulate a prediction done in the past. That is, past data is applied to the training phase to set up prediction model, and data at present is used to validate prediction result. This approach is commonly adopted in the existing cybersecurity incident prediction work <ref type="bibr">[7] [9]</ref> [18] <ref type="bibr" target="#b31">[32]</ref>.</p><p>For the discovery of problem, the results of discovery are supposed to be a previously unknown issue. Performing manual check on the results of discovery seems to be unrealistic and time-consuming. Hence, the solution is to sample discovered results and then validate manually. For example, in <ref type="bibr" target="#b27">[28]</ref>, after finding new black keywords, the authors sampled 1,000 keywords randomly and manually validated by querying forums, chat groups and search engines to determine their real meanings.</p><p>After performing the above processes, the traditional evaluation metrics can be applied to evaluate the designed model. Table <ref type="table">IX</ref> addresses the evaluation metrics used in the reviewed work. It can be found that most of the work presently applied simple evaluation metrics to evaluate the model. There is still a lot of space for further research in this step. For example, while most of the models can achieve high accuracy on sample data, the models' usability needs to be carefully evaluated. Besides, with the passing of time and the development of technology, whether the performance of the models remains stable worths investigation. Furthermore, to achieve the ultimate goal that enhances the cyber resilience for governments, enterprises and individual users, time, speed, deployment requirements, and other considerations are also required to assess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this survey, we presented an overview and research outlook of the emerging field that is cybersecurity incident prediction. Firstly, we summarized the research methodology on critical phases of predicting cybersecurity incident, which is an incremental circular process composed of cybersecurity incident analysis, security problem modeling, data collection and processing, feature engineering/representation learning, model customization and evaluation. Based on the research methodology, a thorough literature review is conducted on recent research efforts on schemes and methods of cybersecurity incident prediction. Furthermore, since data is an essential and indispensable element, which drives security problems, determines representation methods, and supports model setup, we categorized all of the reviewed work into six data types. They are respectively the organization's report and dataset, network dataset, synthetic dataset, webpage data, social media data, and mixed-type dataset. References and crucial information of each dataset are organized and made public. Finally, conforming to research methodology, many challenges existing in the infant stage research area were addressed, as well as future directions were elaborated. Hopefully, cybersecurity incident prediction can raise concern among academia and industry. Also, the survey can help to characterize the latency and serve as a useful reference and valuable guideline for further research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Reviewed cybersecurity incidents categories</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Methodology of data-driven cybersecurity incident prediction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) A labeled bad dataset: This dataset includes 213 PHAs. Each of PHA has one HSO branch. (3) An unknown dataset: This dataset comprises 124,207 apps downloaded from Google Play, and 214,147 collected from VirusTotal. The labeled dataset was used for training, and the unlabeled dataset was applied to testing and discover new knowledge.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Howard and Longstaff's security incident taxonomy</figDesc><graphic coords="23,86.32,56.07,439.37,355.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>introduces the overall reviewed papers</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The authors considered the hosts supporting open DNS recursive queries as misconfigured. According to the data provided by the Open Resolver Project [90] from June 2013, there were 27 million open DNS recursive resolvers.</figDesc><table><row><cell>The source ports without randomization are considered</cell></row><row><cell>as misconfigured. Data were collected by analyzing a</cell></row><row><cell>series of DNS queries against top-level domain (TLD)</cell></row><row><cell>servers on February 2013. Totally, 226,976 DNS resolvers</cell></row><row><cell>without being patched with source port randomization</cell></row><row><cell>were collected.</cell></row><row><cell>• Consistent A and PTR records: According to DNS</cell></row><row><cell>configuration guidelines (RFC1912 [106]), every Address</cell></row><row><cell>(A) record should have a matching Pointer (PTR) record.</cell></row><row><cell>By utilizing the records stored in VeriSign zone files [91]</cell></row><row><cell>and the Alexa Top 1 Million popular websites [92], 27.4</cell></row><row><cell>million A records without a corresponding PTR record</cell></row><row><cell>were gathered.</cell></row></table><note><p><p><p><p><p>• DNS source port randomization: Randomizing source ports can prevent DNS cache poisoning to some extent. • BGP misconfiguration: According to Mahajan et al.</p><ref type="bibr" target="#b102">[107]</ref></p>, 90% announcements made in less than 24 hours are due to Border Gateway Protocol (BGP) misconfiguration. By using this heuristic, 42.4 million short-lived routes were detected in the Route Views project</p><ref type="bibr" target="#b88">[93]</ref></p>.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://nansunsun.github.io/Cybersecurity-incident-prediction-anddiscovery-data/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors wish to acknowledge the anonymous reviewers for their valuable comments and special thanks to Xiaoxing Mo (Deakin University) for helping to prepare this manuscripts.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>how representative their incident samples are, as stated in <ref type="bibr" target="#b17">[18]</ref>. Specifically, the authors in <ref type="bibr" target="#b17">[18]</ref> clarified that self-reporting incidents externally detected by a third party usually have high biases. In the reviewed work, the researchers attempted to employ different ways to collect vast amounts of data. However, the representativeness of data may not be promised. For instance, in <ref type="bibr" target="#b26">[27]</ref>, the researchers cannot find representative real-world programs containing the sorts of security checks required by their study. To resolve this problem, they designed a C program generator which produced a large number of programs with various license checking algorithms. Nonetheless, compared with real-world data, synthetic programs seem to be questionable when facing with the new and existing obfuscation and deobfuscation techniques.</p><p>Secondly, the comprehensive data indicates that the dataset includes everything needed or relevant. In the existing work <ref type="bibr" target="#b8">[9]</ref> [18], when dealing with the problem that forecasts whether an organization meets data breach incident in future, both of the authors leverage VERIS community database <ref type="bibr" target="#b16">[17]</ref> to collect previous incident records. Actually, the reports from the VERIS community database mainly focus on US incidents. A possible solution is to utilize more comprehensive sources of data breaches (e.g., Hackmageddon <ref type="bibr" target="#b59">[60]</ref>, Web Hacking Incidents Database <ref type="bibr" target="#b60">[61]</ref> and incidents reports from Australia Cyber Security Centre <ref type="bibr" target="#b147">[152]</ref>) and aggregate together by the granularity of organization. Another case is in <ref type="bibr" target="#b23">[24]</ref>. Facing many symptoms that reflect poor management, the authors attempt to comprehensively describe all manners in which a network could be mismanaged. Combining eight misconfigured symptoms into one mismanagement metric and aggregating these symptoms at autonomous system level might be a solution to capture mismanagement characteristics as comprehensive as possible.</p><p>Thirdly, the authentic data represents the data that needs to be reliable and accurate. That is to say, the quality of groundtruth determines the performance of prediction. Filtering and validating samples by using multiple criteria might be able to confirm the authenticity of data to a certain degree. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Australia cyber security centre threat report 2017</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Centre</surname></persName>
		</author>
		<idno>02/04/2018</idno>
		<ptr target="https://www.acsc.gov.au/publications/ACSC_Threat_Report_2017.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An empirical analysis of cyber security incidents at a large organization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kuypers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Maillart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pate-Cornell</surname></persName>
		</author>
		<ptr target="http://fsi.stanford.edu/sites/default/files/kuypersweis_v7.pdf" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
		<respStmt>
			<orgName>Department of Management Science and Engineering, Stanford University, School of Information, UC Berkeley</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A security ontology for incident analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Annual Workshop on Cyber Security and Information Intelligence Research</title>
		<meeting>the Sixth Annual Workshop on Cyber Security and Information Intelligence Research</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Australian cyber security centre survey 2016</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Centre</surname></persName>
		</author>
		<idno>02/04/2018</idno>
		<ptr target="https://www.acsc.gov.au/publications/ACSC_Cyber_Security_Survey_2016.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><surname>Cisco</surname></persName>
		</author>
		<idno>pdf?dtid=odicdc000016 &amp;ccid=cc000160&amp;oid=anrsc005679&amp;ecid=8196&amp;elqTrackId=686210 143d34494fa27ff73da9690</idno>
		<ptr target="https://www.cisco.com/c/dam/m/digital/elq-cmcglobal/witb/acr2018/acr" />
		<title level="m">Cisco 2018 annual cybersecurity report</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="9452" to="9452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Securely outsourcing attribute-based encryption with checkability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel &amp; Distributed Systems</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatically detecting vulnerable websites before they turn malicious</title>
		<author>
			<persName><forename type="first">K</forename><surname>Soska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Christin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="625" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Delta: automatic identification of unknown web-based infection campaigns</title>
		<author>
			<persName><forename type="first">K</forename><surname>Borgolte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kruegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGSAC conference on Computer and communications security</title>
		<meeting>the 2013 ACM SIGSAC conference on Computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="109" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cloudy with a chance of breach: Forecasting cyber security incidents</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Naghizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1009" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Activetrust: secure and trustable routing in wireless sensor networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2013" to="2027" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Chronicle</title>
		<ptr target="https://chronicle.security/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m">BizCover: Compare Small Business Insurance Quotes Australia</title>
		<imprint/>
	</monogr>
	<note>ht tps://www.bizcover.com.au</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey of emerging threats in cybersecurity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jang-Jaccard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="973" to="993" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detecting and preventing cyber insider threats: A survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">De</forename><surname>Vel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey of data mining and machine learning methods for cyber security intrusion detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Buczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Guven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1153" to="1176" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Knowledge discovery in texts: a definition, and applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kodratoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Methodologies for Intelligent Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="16" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">VERIS Community Database (VCDB)</title>
		<author>
			<persName><surname>Veris</surname></persName>
		</author>
		<ptr target="http://veriscommunity.net/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Prioritizing security spending: A quantitative analysis of risk distributions for different business profiles</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sarabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Naghizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Workshop on the Economics of Information Security (WEIS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The dropper effect: Insights into malware distribution with downloader graph analytics</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bilge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dumitras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 22nd ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1118" to="1129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Early-stage malware prediction using recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rhode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burnap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Security</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="578" to="594" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dark hazard: Learning-based, large-scale discovery of hidden sensitive operations in android apps</title>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Network and Distributed System Security (NDSS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cross-project transfer representation learning for vulnerable function discovery</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vel</surname></persName>
		</author>
		<author>
			<persName><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Riskteller: Predicting the risk of cyber incidents</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bilge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dell'amico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2017 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1299" to="1311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the mismanagement and maliciousness of networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Durumeric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Network and Distributed System Security (NDSS)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Modeling dynamic behavior in large evolving graphs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM international conference on Web search and data mining</title>
		<meeting>the sixth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust network traffic classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking (TON)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1257" to="1270" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Predicting the resilience of obfuscated code against symbolic execution attacks via machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Banescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Collberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pretschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th USENIX Security Symposium</title>
		<meeting>the 26th USENIX Security Symposium</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How to learn klingon without a dictionary: Detection and measurement of black keywords used by the underground economy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (S&amp;P), 2017 IEEE Symposium</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="751" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Acing the ioc game: Toward automatic discovery and analysis of open-source cyber threat intelligence</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beyah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2016 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="755" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Autoreb: Automatically understanding the review-to-behavior fidelity in android applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 22nd ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="530" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Crowdsourcing cybersecurity: Cyber attack detection using social media</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Khandpur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1049" to="1057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Vulnerability disclosure in the age of social media: Exploiting twitter for predicting real-world exploits</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sabottke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dumitras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1041" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weakly supervised extraction of computer security events from twitter</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Casey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="896" to="905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Cert/cc. computer security incident response team frequently asked questions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Team</surname></persName>
		</author>
		<idno>03/04/2018</idno>
		<imprint/>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Auscert is a leading cyber emergency response team (cert) in australia and the asia/pacific region</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C E R</forename><surname>Team</surname></persName>
		</author>
		<idno>03/04/2018</idno>
		<ptr target="http://www.auscert.org.au/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Computer security incident handling step-by-step</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Institute</surname></persName>
		</author>
		<idno>03/04/2018</idno>
		<ptr target="https://www.sans.org/reading-room/whitepapers/incident/incident-handlers-handbook-33901" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Computer incident response guidebook</title>
		<author>
			<persName><forename type="first">D</forename><surname>Navy</surname></persName>
		</author>
		<idno>03/04/2018</idno>
		<ptr target="http://www.csirt.org/publications/navy.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">State of the practice of computer security incident response teams (csirts)</title>
		<author>
			<persName><forename type="first">G</forename><surname>Killcrece</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-P</forename><surname>Kossakowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ruefle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zajicek</surname></persName>
		</author>
		<idno>ESC-TR-2003-001</idno>
	</analytic>
	<monogr>
		<title level="j">CSIRT Development Team, Tech. Rep</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="report_type">technical Report</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Computer Crime: A Crime Fighter&apos;s Handbook</title>
		<author>
			<persName><forename type="first">I</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>O&apos;Reilly Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Computer security incident handling guide</title>
		<author>
			<persName><forename type="first">T</forename><surname>Grance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIST Special Publication</title>
		<imprint>
			<biblScope unit="volume">800</biblScope>
			<biblScope unit="issue">61</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Cheswick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Bellovin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Rubin</surname></persName>
		</author>
		<title level="m">Firewalls and Internet security: Repelling the Wily Hacker</title>
		<imprint>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Network and Internetwork Security: Principles and Practice</title>
		<author>
			<persName><forename type="first">W</forename><surname>Stallings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Prentice Hall Englewood Cliffs</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Protection and Security on the Information Superhighway</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Secure attribute-based data sharing for resource-limited users in cloud computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Security</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Artificial intelligence: a modern approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>Malaysia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">National Vulnerability Database</title>
		<ptr target="https://nvd.nist.gov/vuln" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<ptr target="https://www.verizonenterprise.com/verizon-insights-lab/dbir/" />
		<title level="m">Verizon annual Data Breach Investigations Report</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Machine learning and ai via brain simulations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<idno>on 03/05/2018</idno>
		<ptr target="http://ai.stanford.edu/Ëoeang/slides/DeepLearning-Mar2013.pptx" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Supervised dictionary learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1033" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Esbensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Geladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chemometrics and intelligent laboratory systems</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="37" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)</title>
		<meeting>workshop on machine learning systems (LearningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep learning applications and challenges in big data analytics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Najafabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Villanustre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Seliya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muharemagic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multistage and elastic spam detection in mobile social networks through deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning iot in edge: deep learning for the internet of things with edge computing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="101" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">When weather matters: Iot-based electrical load forecasting for smart grid</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="46" to="51" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Anomaly-based network intrusion detection: Techniques, systems and challenges</title>
		<author>
			<persName><forename type="first">P</forename><surname>Garcia-Teodoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Diaz-Verdejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Maciá-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vázquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">computers and security</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="18" to="28" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The base-rate fallacy and its implications for the difficulty of intrusion detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Axelsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM Conference on Computer and Communications Security</title>
		<meeting>the 6th ACM Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">United states department of health and human services , information memorandum</title>
		<author>
			<persName><forename type="first">A</forename><surname>Children</surname></persName>
		</author>
		<author>
			<persName><surname>Families</surname></persName>
		</author>
		<idno>03/05/2018</idno>
		<ptr target="https://www.acf.hhs.gov/sites/default/files/cb/im1504.pdf" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">U. Route Views Project</title>
		<author>
			<persName><forename type="first">O</forename><surname>Oregon</surname></persName>
		</author>
		<ptr target="http://www.routeviews.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Web-Hacking-Incident-Database</title>
		<author>
			<persName><forename type="first">"</forename><forename type="middle">T W A S</forename><surname>Veris</surname></persName>
		</author>
		<ptr target="http://projects.webappsec.org/w/page/13246995/Web-Hacking-Incident-Database" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Composite Blocking List</title>
		<ptr target="http://cbl.abuseat.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Pbl</forename><surname>Xbl</surname></persName>
		</author>
		<author>
			<persName><surname>Lists</surname></persName>
		</author>
		<ptr target="http://www.spamhaus.org/" />
		<title level="m">The SPAMHAUS project: SBL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">SpamCop Blocking List</title>
		<ptr target="http://www.spamcop.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">WPBL: Weighted Private Block List</title>
		<ptr target="http://wpbl.info/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">UCEPROTECTOR Network</title>
		<ptr target="http://uceprotect.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">SURBL: URL REPUTATION DATA</title>
		<ptr target="http://www.surbl.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">hpHosts for your pretection</title>
		<ptr target="http://hosts-file.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Top data breaches of 2014</title>
		<author>
			<persName><forename type="first">B</forename><surname>Prince</surname></persName>
		</author>
		<idno>03/05/2018</idno>
		<ptr target="www.securityweek.com/top-data-breaches-2014" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Csans institute critical security controls</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Institute</surname></persName>
		</author>
		<ptr target="https://www.sans.org/critical-security-controls" />
		<imprint>
			<date type="published" when="2018-08-20">20/08/2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Cybercrime reaches new heights in the third quarter</title>
		<author>
			<persName><surname>Pandalabs</surname></persName>
		</author>
		<idno>on 03/05/2018</idno>
		<ptr target="https://www.pandasecurity.com/mediacenter/pandalabs/pandalabs-q3/" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Exploits database by offensive security</title>
		<ptr target="http://exploit-db.com/" />
		<imprint>
			<date type="published" when="2014-12">December 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">A Bounds Check on the Microsoft Exploitability Index The Value of an Exploitability Index Exploitability</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Researcher</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Toward a standard benchmark for computer security research: The worldwide intelligence network environment (wine)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dumitras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security</title>
		<meeting>the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Quintero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Manuel Alvarezv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hiramoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Canto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bermudez</surname></persName>
		</author>
		<ptr target="https://virustotal.com/" />
	</analytic>
	<monogr>
		<title level="j">Virustotal</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title/>
		<ptr target="https://en.softonic.com/" />
	</analytic>
	<monogr>
		<title level="j">Softonic.com</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title/>
		<ptr target="https://portableapps.com/" />
	</analytic>
	<monogr>
		<title level="j">Portableapps.com</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title/>
		<ptr target="https://sourceforge.net/" />
	</analytic>
	<monogr>
		<title level="j">Sourceforge.net</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">The cuckoo sandbox</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guarnieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tanasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schloesser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Foundation</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psutil python library</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Virustotal-free online virus, malware and url scanner</title>
		<ptr target="https://www.virustotal.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zulkernine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems Architecture</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="294" to="313" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Chucky: Exposing missing checks in source code for vulnerability discovery</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wressnegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gascon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGSAC conference on Computer and communications security</title>
		<meeting>the 2013 ACM SIGSAC conference on Computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="499" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Introduction to information retrieval</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="852" to="853" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Open Resolver Project</title>
		<ptr target="http://openresolverproject.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Alexa Web Information Service</title>
		<ptr target="http://aws.amazon.com/awis" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">U. of Oregon RouteViews Project</title>
		<ptr target="http://www.routeviews.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<ptr target="http://spoofer.cmand.org/index.php" />
		<title level="m">Spoofer project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Zmap: Fast internetwide scanning and its security applications</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Durumeric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wustrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Halderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="47" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Barracuda Reputation Blocklist</title>
		<ptr target="http://www.barracudacentral.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">CBL: Composite Blocking List</title>
		<ptr target="http://cbl.abuseat.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">Pbl</forename><surname>Xbl</surname></persName>
		</author>
		<author>
			<persName><surname>Lists</surname></persName>
		</author>
		<ptr target="http://www.spamhaus.org/" />
		<title level="m">The SPAMHAUS project: SBL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">SpamCop Blocking List</title>
		<ptr target="http://www.spamhaus.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">WPBL: Weighted Private Block List</title>
		<ptr target="http://www.wpbl.info/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">UCEPROTECTOR Network</title>
		<ptr target="http://www.uceprotect.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">SURBL: URL REPUTATION DATA</title>
		<ptr target="http://www.surbl.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">On the evolution of user interaction in facebook</title>
		<author>
			<persName><forename type="first">B</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd ACM workshop on Online Social Networks</title>
		<meeting>the 2nd ACM workshop on Online Social Networks</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Enron email dataset</title>
		<ptr target="http://www.cs.cmu.edu/enron/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Hackers focus on misconfigured networks</title>
		<idno>03/05/2018</idno>
		<ptr target="http://forums.cnet.com/7726-6132102-3366976.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Common DNS Operational and Configuration Errors. Internet Request for Comments (RFC 1912</title>
		<author>
			<persName><forename type="first">D</forename><surname>Barr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Understanding BGP misconfiguration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wetherall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Causal inference in the presence of latent variables and selection bias</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Eleventh Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Automated big traffic analytics for cyber security</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.09023</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Network traffic classification using correlation information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="104" to="117" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Offline/realtime traffic classification using semi-supervised learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Erman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arlitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Performance Evaluation</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">9-12</biblScope>
			<biblScope unit="page" from="1194" to="1213" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Support vector machines for tcp traffic classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Este</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gringoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Salgarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2476" to="2490" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Symantec Research Labs</title>
		<ptr target="https://www.symantec.com/about/corporate-profile/technology/research-labs" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Distributed application tamper detection via continuous software updates</title>
		<author>
			<persName><forename type="first">C</forename><surname>Collberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nagra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual Computer Security Applications Conference</title>
		<meeting>the 28th Annual Computer Security Applications Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="319" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Protecting software through obfuscation: Can it keep pace with progress in code analysis?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katzenbeisser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Merzdovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weippl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">A taxonomy of obfuscating transformations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Collberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Thomborson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Low</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, The University of Auckland, New Zealand</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Code obfuscation against symbolic execution attacks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Banescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Collberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Newsham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pretschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual Conference on Computer Security Applications</title>
		<meeting>the 32nd Annual Conference on Computer Security Applications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="189" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cadar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dunbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Engler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Symposium on Operating System Design and Implementation</title>
		<meeting>the USENIX Symposium on Operating System Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="209" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Firmalice-automatic detection of authentication bypass vulnerabilities in binary firmware</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoshitaishvili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kruegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Network and Distributed System Security (NDSS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<ptr target="https://www.r-project.org/" />
		<title level="m">The R Project for Statistical Computing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Measuring and analyzing search-redirection attacks in the illicit online prescription drug trade</title>
		<author>
			<persName><forename type="first">N</forename><surname>Leontiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Christin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Surf: detecting and measuring search poisoning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Perdisci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Computer and Communications Security</title>
		<meeting>the 18th ACM Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="467" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">DNS-BH: Malware domain blocklist</title>
		<ptr target="http://www.malwaredomains.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Google</title>
		<ptr target="https://code.google.com/apis/safebrowsing/" />
	</analytic>
	<monogr>
		<title level="m">Google Safe Browsing API</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title level="m" type="main">MalwareBytes. hphosts online</title>
		<ptr target="http://www.hosts-file.net/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Optics-of: Identifying local outliers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Data Mining and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Hackmageddon</title>
		<ptr target="https://www.hackmageddon.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Privacy Rights</title>
		<ptr target="https://www.privacyrights.org/data-breaches" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Open Threat Intelligence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mcmillan</surname></persName>
		</author>
		<ptr target="https://www.gartner.com/doc/2487216/definition-threat-intelligence" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">IOCbucket</title>
		<ptr target="https://www.iocbucket.com/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">A community OpenIOC resource</title>
		<ptr target="https://openiocdb.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Earthquake shakes twitter users: real-time event detection by social sensors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sakaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on World Wide Web</title>
		<meeting>the 19th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="851" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">The use of twitter to track levels of disease activity and public concern in the us during the influenza A H1N1 pandemic</title>
		<author>
			<persName><forename type="first">A</forename><surname>Signorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Segre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Polgreen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS) One</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2011">19467. 2011</date>
			<publisher>Public Library of Science</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Predicting elections with twitter: What 140 characters reveal about political sentiment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tumasjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Sprenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sandner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Welpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Weblogs and Social Media (ICWSM)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">A dependency-based word subsequence kernel</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Kate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="400" to="409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Clustering by passing messages between data points</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="issue">5814</biblScope>
			<biblScope unit="page" from="972" to="976" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Bursty and hierarchical structure in streams</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="373" to="397" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Mobile phone sensing systems: A survey</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Z</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Aalsalem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Arshad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="402" to="427" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Query expansion using local and global document analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Learning from crowds</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Valadez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Florin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bogoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1297" to="1322" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Symantec attack signatures</title>
		<ptr target="http://www.symantec.com/security_response/attacksignatures/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Annual Workshop on Computational Learning Theory</title>
		<meeting>the 5th Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">It&apos;s who you know: graph mining using recursive structural features</title>
		<author>
			<persName><forename type="first">K</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="663" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Estimating the support of a high-dimensional distribution</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1443" to="1471" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">An analysis of security incidents on the internet 1989-1995</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon Univ Pittsburgh PA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">A common language for computer security incidents</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Longstaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sandia National Labs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Cyber Resilience-Fundamentals for a Definition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Björck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stirna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zdravkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Contributions in Information Systems and Technologies</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="311" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">How bad are selfish investments in network security?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anantharam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Walrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="549" to="560" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">A hierarchical security framework for defending against sophisticated attacks on wireless sensor networks in smart cities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="416" to="424" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Nan Sun received the bachelor&apos;s degree in information technology</title>
		<ptr target="https://www.acsc.gov.au/incident.html" />
	</analytic>
	<monogr>
		<title level="m">2016, where she is currently pursuing the Ph.D. degree in information technology. Her current research interests include cybersecurity and social network security</title>
		<meeting><address><addrLine>Geelong, VIC, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Australia Cyber Security Centre</publisher>
		</imprint>
		<respStmt>
			<orgName>Hons.) from Deakin University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
