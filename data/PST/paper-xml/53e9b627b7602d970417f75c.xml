<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Progressive Image Denoising Through Hybrid Graph Laplacian Regularization: A Unified Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Xianming</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Deming</forename><surname>Zhai</surname></persName>
							<email>zhaideming@gmail.com</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Debin</forename><surname>Zhao</surname></persName>
							<email>dbzhao@hit.edu.cn</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Guangtao</forename><surname>Zhai</surname></persName>
							<email>zhaiguangtao@gmail.com</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Wen</forename><surname>Gao</surname></persName>
							<email>wgao@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><surname>Zhao</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Image Communication and Information Processing</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Electrical Engineering and Computer Science</orgName>
								<orgName type="laboratory">National Engineering Laboratory for Video Technology, and Key Laboratory of Machine Perception</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Progressive Image Denoising Through Hybrid Graph Laplacian Regularization: A Unified Framework</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1236F6E1F7626227FBEFFF970D15CC4B</idno>
					<idno type="DOI">10.1109/TIP.2014.2303638</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image denoising</term>
					<term>graph Laplacian</term>
					<term>kernel theory</term>
					<term>local smoothness</term>
					<term>non-local self-similarity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recovering images from corrupted observations is necessary for many real-world applications. In this paper, we propose a unified framework to perform progressive image recovery based on hybrid graph Laplacian regularized regression. We first construct a multiscale representation of the target image by Laplacian pyramid, then progressively recover the degraded image in the scale space from coarse to fine so that the sharp edges and texture can be eventually recovered. On one hand, within each scale, a graph Laplacian regularization model represented by implicit kernel is learned, which simultaneously minimizes the least square error on the measured samples and preserves the geometrical structure of the image data space. In this procedure, the intrinsic manifold structure is explicitly considered using both measured and unmeasured samples, and the nonlocal self-similarity property is utilized as a fruitful resource for abstracting a priori knowledge of the images. On the other hand, between two successive scales, the proposed model is extended to a projected high-dimensional feature space through explicit kernel mapping to describe the interscale correlation, in which the local structure regularity is learned and propagated from coarser to finer scales. In this way, the proposed algorithm gradually recovers more and more image details and edges, which could not been recovered in previous scale. We test our algorithm on one typical image recovery task: impulse noise removal. Experimental results on benchmark test images demonstrate that the proposed method achieves better performance than state-of-the-art algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>many practical image processing problems, observed images often contain noise that should be removed beforehand for improving the visual pleasure and the reliability of subsequent image analysis tasks. Images may be contaminated by various types of noise. Among them, the impulse noise is one of the most frequently happened noises, which may be introduced into images during acquisition and transmission. For example, it may be caused by malfunctioning pixels in camera sensors, faulty memory locations in hardware or transmission in a noisy channel <ref type="bibr" target="#b0">[1]</ref>. In this paper, we focus on the task of impulse noise removal.</p><p>Removing impulse noise from images is a challenging image processing problem, because edges which can also be modeled as abrupt intensity jumps in a scan line are highly salient features for visual attention. Therefore, besides impulse noise removal, another important requirement for image denoising procedures is that they should preserve important image structures, such as edges and major texture features.</p><p>A vast variety of impulse noise removal methods are available in the literature, touching different fields of signal processing, mathematics and statistics. From a signal processing perspective, impulse noise removal poses a fundamental challenge for conventional linear methods. They typically achieve the target of noise removal by low-pass filtering which is performed by removing the high-frequency components of images. This is effective for smooth regions in images. But for texture and detail regions, the low-pass filtering typically introduces large, spurious oscillations near the edge known as Gibb's phenomena <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Accordingly, nonlinear filtering techniques are invoked to achieve effective performance. One kind of the most popular and robust nonlinear filters is the so called decision-based filters, which first employ an impulsenoise detector to determine which pixels should be filtered and then replace them by using the median filter or its variants, while leaving all other pixels unchanged. The representative methods include the adaptive median filter (AMF) <ref type="bibr" target="#b3">[4]</ref> and the adaptive center-weighted median filter (ACWMF) <ref type="bibr" target="#b4">[5]</ref>.</p><p>Besides, many successful frameworks for impulse noise removal can be derived from the energy method. In this framework, image denoising is considered as a variational problem where a restored image is computed by a minimization of some energy functions. Typically, such functions consist of a fidelity term such as the norm difference between the recovered image and the noisy image, and a regularization term which penalizes high frequency noise. For example, Chan et al. <ref type="bibr" target="#b5">[6]</ref> propose a powerful two-stage scheme, in which noise candidates are selectively restored using an objective function with an 1 data-fidelity term and an edge-preserving regularization term. Under the similar scheme, Cai et al. <ref type="bibr" target="#b6">[7]</ref> propose a enhanced algorithm used for deblurring and denoising, and achieve wonderful objective and subjective performance. Different from Chan and Cai's work, Li et al. <ref type="bibr" target="#b7">[8]</ref> formulate the problem with a new variational functional, in which the content-dependent fidelity assimilates the strength of fidelity terms measured by the 1 and 2 norms, and the regularizer is formed by the 1 norm of tight framelet coefficients of the underlying image.</p><p>From a statistical perspective, recovering images from degraded forms is inherently an ill-posed inverse problem. It often can be formulated as an energy minimization problem in which either the optimal or most probable configuration is the goal. The performance of an image recovery algorithm largely depends on how well it can employ regularization conditions or priors when numerically solving the problem, because the useful prior statistical knowledge can regulate estimated pixels. Therefore, image modeling lies at the core of image denoising problems.</p><p>One common prior assumption for natural images is intensity consistency, which means: (1) nearby pixels are likely to have the same or similar intensity values; and (2) pixels on the same structure are likely to have the same or similar intensity values. Note that the first assumption means images are locally smooth, and the second assumption means images have the property of non-local self-similarity. Accordingly, how to choose statistical models that thoroughly explore such two prior knowledge directly determines the performance of image recovery algorithms. Another important characteristic of natural images is that they are comprised of structures at different scales. Through multi-scale decomposition, the structures of images at different scales become better exposed, and hence be more easily predicted. At the same time, the availability of multi-scale structures can significantly reduce the dimension of problem, hence, make the ill-posed problem to be better posed <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p><p>Early heuristic observation about the local smoothness of image intensity field has been quantified by several linear parametric models, such as the piecewise autoregressive (PAR) image model <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Moreover, the study of natural image statistics reveals that the second order statistics of natural images tends to be invariant across different scales, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref> (denoted by inter-scale correlation). And those scale invariant features are shown to be crucial for human visual perception <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. This observation inspires us to learn and propagate the statistical features across different scales to keep the local smoothness of images. On the other hand, the idea of exploiting the non-local self-similarity of images has attracted increasingly more attention in the field of image processing <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. Referring to Fig. <ref type="figure" target="#fig_0">1</ref> (denoted by intra-scale correlation), the non-local self-similarity is based on the observation that image patches tend to repeat themselves in the whole image plane, which in fact reflects the intra-scale correlation. All those findings tell us that localnonlocal redundancy and intra-inter-scale correlation can be thought of as two sides of the same coin. The multiscale framework provides us a wonderful choice to efficiently combine the principle of local smoothness and non-local similarity for image recovery.</p><p>Moreover, recent progress in semi-supervised learning gives us additional inspiration to address the problem of image recovery. Semi-supervised learning is motivated by a considerable interest in the problem of learning from both labeled (measured) and unlabeled (unmeasured) points <ref type="bibr" target="#b16">[17]</ref>. Specially, geometry-based semi-supervised learning methods show that natural images cannot possibly fill up the ambient Euclidean space rather it may reside on or close to an underlying submanifold <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. In this paper, we try to extract this kind of low dimensional structure and use it as prior knowledge to regularize the process of image denoising. In another word, in the algorithm design, we will explicitly take into account the intrinsic manifold structure by making use of both labeled and unlabeled data points.</p><p>Motivated by the above observation, the well-known theory of kernels <ref type="bibr" target="#b19">[20]</ref> and works on graph-based signal processing <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref>, in this paper, we propose a powerful algorithm to perform progressive image recovery based on hybrid graph Laplacian regularized regression. Part of our previous work has been reported in <ref type="bibr" target="#b20">[21]</ref>. In our method, a multi-scale representation of the target image is constructed by Laplacian pyramid, through which we try to effectively combine local smoothness and non-local self-similarity. On one hand, within each scale, a graph Laplacian regularization model represented by implicit kernel is learned which simultaneously minimizes the least square error on the measured samples and preserves the geometrical structure of the image data space by exploring non-local self-similarity. In this procedure, the intrinsic manifold structure is considered by using both measured and unmeasured samples. On the other hand, between two scales, the proposed model is extended to the parametric manner through explicit kernel mapping to model the interscale correlation, in which the local structure regularity is learned and propagated from coarser to finer scales.</p><p>It is worth noting that the proposed method is a general framework to address the problem of image recovery. We choose one typical image recovery task, impulse noise removal, but not limit to this task, to validate the performance of the proposed algorithm. Moreover, in our method the objective functions are formulated in the same form for intra-scale and inter-scale processing, but with different solutions obtained in different feature spaces: the solution in the original feature space by implicit kernel is used for intra-scale prediction, and the other solution in a higher feature space mapped by explicit kernel is used for inter-scale prediction. Therefore, the proposed image recovery algorithm actually casts the consistency of local and global correlation through the multi-scale scheme into a unified framework.</p><p>The rest of the paper is organized as follows: In Section II, we introduce the proposed graph Laplacian regularized model and its kernel-based optimization solutions. Section III details the proposed multi-scale image recovery framework. Section IV presents some experimental results and comparative studies. Section V concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. IMAGE RECOVERY VIA GRAPH LAPLACIAN REGULARIZED REGRESSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Description</head><p>Given a degraded image X with n pixels, each pixel can be described by its feature vector</p><formula xml:id="formula_0">x i = [u i , b i ] ∈ m+2</formula><p>, where u i = (h, w) is the coordinate and b i ∈ m is a certain context of x i which is defined differently for different tasks. All pixels in the image construct the sample set χ = {x 1 , x 2 , . . . , x n }. We call the grayscale value y i as the label of x i .</p><p>For image impulse noise removal, when image measures are noise-dominated, the performance of image recovery can be improved by implementing it in two steps <ref type="bibr" target="#b5">[6]</ref>: The first step is to classify noisy and clean samples by using the adaptive median filter or its variant, which depends on the noise type. Then, noisy samples are treated as unlabeled ones with their intensity values to be re-estimated, and the rest clean samples are treated as labeled ones with intensity values unchanged. The second step is to adjust the inference to give a best fit to labeled measures and uses the fitted model to estimate the unlabeled samples. In view of machine learning, this task can be addressed as a problem of semi-supervised regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph Laplacian Regularized Regression (GLRR)</head><p>What we want to derive is the prediction function f , which gives the re-estimated values of noisy samples. Given labeled samples X l = {(x 1 , y 1 ), . . . , (x l , y l )} as the training data, one direct approach of learning the prediction function f is to minimize the prediction error on the set of labeled samples, which is formulated as follows:</p><formula xml:id="formula_1">arg min f ∈H κ J ( f ) = arg min f ∈H κ l i=1 y i -f (x i ) 2 + λ f 2 , (1)</formula><p>where H κ is the Reproducing Kernel Hilbert Space (RKHS) associated with the kernel κ. H κ will be the completion of the linear span given by κ(x i , •) for all x i ∈ χ, i.e.,</p><formula xml:id="formula_2">H κ = span{κ(x i , •)|x i ∈ χ}.</formula><p>The above regression model only makes use of the labeled samples to carry out inference. When the noise level is heavy, which means there are few labeled samples, it is hard to achieve a robust recovery of noisy image. Moreover, it fails to take into account the intrinsic geometrical structure of the image data. Note that we also have a bunch of unlabeled samples {x l+1 , . . . , x n } at hand. In the field of machine learning, the success of semi-supervised learning <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b24">[25]</ref> is plausibly due to effective utilization of the large amounts of unlabeled data to extract information that is useful for generalization. Therefore, it is reasonable to leverage both labeled and unlabeled data to achieve better predictions.</p><p>In order to make use of unlabeled data, we follow the well-known manifold assumption, which is implemented by a graph structure. Specially, the whole image sample set is modeled as a undirected graph, in which the vertices are all the data points and the edges represent the relationships between vertices. Each edge is assigned a weight to reflect the similarity between the connected vertices. As stated by the manifold assumption <ref type="bibr" target="#b17">[18]</ref>, data points in the graph with larger affinity weights should have similar values. Meanwhile, with the above definition, the intrinsic geometrical structure of the data space can be described by the graph Laplacian. Through the graph Laplacian regularization, the manifold structure can be incorporated in the objective function. Mathematically, the manifold assumption can be implemented by minimizing the following term:</p><formula xml:id="formula_3">R( f ) = 1 2 n i, j ( f (x i ) -f (x j )) 2 W i j . (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where W i j is in inverse proportion to d 2 (x i , x j ). W i j is defined as the edge weight in the data adjacency graph which reflects the affinity between two vertices x i and x j . In graph construction, edge weights play a crucial role. In this paper, we combine the edge-preserving property of bilateral filter <ref type="bibr" target="#b15">[16]</ref> and the robust property of non-local-means weight <ref type="bibr" target="#b14">[15]</ref> to design the edge weights, which are defined as follows:</p><formula xml:id="formula_5">W i j = 1 C exp - ||u j -u i || 2 σ 2 exp - ||b j -b i || 2 ε 2 , σ &gt; 0, ε &gt; 0. (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>where b i (b j ) is defined as the local patch centered on u i (u j ). The first exponential term considers the geometrical nearby, and the second one considers the structural similarity.</p><p>Let D be a diagonal matrix, whose diagonal elements are the row sums of W, i.e., D(i, i ) = j W i j . We define L = D -W ∈ n×n as the graph Laplacian. With above definition, Eq.( <ref type="formula" target="#formula_3">2</ref>) can be further written as:</p><formula xml:id="formula_7">R( f ) = n i=1 f (x i ) 2 n j =1 W i j - n i, j W i j f (x i ) f (x j ) = f T Df -f T Wf = f T Lf,<label>(4)</label></formula><p>where</p><formula xml:id="formula_8">f = { f (x 1 ), . . . , f (x n )}.</formula><p>Combining this regularization term with Eq.( <ref type="formula">1</ref>), we obtain the objective function of Laplacian regularized least square (LapRLS):</p><formula xml:id="formula_9">arg min f ∈H κ {J ( f ) = y L -f L 2 + λ f 2 + γ f T Lf},<label>(5)</label></formula><p>where</p><formula xml:id="formula_10">y L = [y 1 , . . . , y l ] T , f L = [ f (x 1 ), . . . , f (x l )] T and f = [ f (x 1 ), . . . , f (x n )] T .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimization by Implicit Kernel</head><p>In order to obtain the optimal solution for the above objective function, we exploit a useful property of RKHS, the so called representer theorem. It states that minimizing of any optimization task in Hilbert space H has finite representation in H.</p><p>Theorem 1. (Representer Theorem <ref type="bibr" target="#b17">[18]</ref>). Let χ be a nonempty set and κ a positive-definite real-valued kernel on χ ×χ with corresponding reproducing kernel Hilbert space H. Given a set of labeled samples {(x 1 , y 1 ), . . . , (x l , y l )} ∈ χ × , a strictly monotonic increasing function : [0, ∞) → , and a loss function c :</p><formula xml:id="formula_11">(χ × ) 2 → ∪ {∞}, each minimizer f ∈ H of the regularized risk functional c((y 1 , f (x 1 )), . . . , (y l , f (x l ))) + f H (6)</formula><p>admits a representation of theory</p><formula xml:id="formula_12">f (x) = l i=1 α i κ(x i , x).<label>(7)</label></formula><p>In this paper, the loss function c is specified as the quadratic loss, and the regularization term f H takes the form f H = λ f 2 = λ f T f . The Representer Theorem above allows us to express the solution of regularized least square (RLS) formulated in Eq.( <ref type="formula">1</ref>) directly in terms of the labeled data and the kernels. As stated in the above subsection, we extend the RLS to LapRLS formulated in Eq.( <ref type="formula" target="#formula_9">5</ref>) to utilize both labeled and unlabeled information in regression. The following extended version of the Representer Theorem shows that the minimizer has an expansion in terms of both labeled and unlabeled samples and it is a key to our algorithm.</p><p>Theorem 2. (Representer Theorem for Semi-supervised Learning <ref type="bibr" target="#b17">[18]</ref>) Given a training sample set including both labeled and unlabeled samples {(x 1 , y 1 ), . . . , (x n , y n )}∈ χ× , the minimizer of the optimization problem formulated in</p><formula xml:id="formula_13">c((y 1 , f (x 1 )), . . . , (y l , f (x l ))) + f H + γ f T Lf (8)</formula><p>admits an expansion</p><formula xml:id="formula_14">f (x) = n i=1 α i κ(x i , x)<label>(9)</label></formula><p>in terms of both labeled and unlabeled samples. With the above exteneded Representer Theorem, we define the solution f of Eq.( <ref type="formula" target="#formula_9">5</ref>) as:</p><formula xml:id="formula_15">f = ⎡ ⎢ ⎣ f (x 1 ) . . . f (x n ) ⎤ ⎥ ⎦ = ⎡ ⎢ ⎣ n i=1 α i κ(x i , x 1 ) . . . n i=1 α i κ(x i , x n ) ⎤ ⎥ ⎦ = Ka. (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>where K is the kernel gram matrix with</p><formula xml:id="formula_17">K i j = κ(x i , x j ), a = [α 1 , . . . , α n ] T .</formula><p>Denoting K L as the submatrix consisting of rows of K corresponding to those labeled samples in the set X L , we have</p><formula xml:id="formula_18">f L = K L a.</formula><p>Mathematically, the kernel function is defined as:</p><formula xml:id="formula_19">κ(x i , x) = (x i ), (x) = (x i ) T (x)</formula><p>, where •, • is the inner product operator; and</p><p>: χ → H is the kernel induced feature mapping, which maps the points in χ to a higher-dimensional RHKS space H. According to the above definition, Eq.( <ref type="formula" target="#formula_14">9</ref>) can be further written as:</p><formula xml:id="formula_20">f (x) = ( n i=1 α i (x i ) T ) (x). (<label>11</label></formula><formula xml:id="formula_21">)</formula><p>f in the second term of Eq. ( <ref type="formula" target="#formula_9">5</ref>) is referred to as the coefficient vector of the mapped feature (x) in RHKS space, which is derived as</p><formula xml:id="formula_22">f = ( n i=1 α i (x i ) T ) = [ (x 1 ), . . . , (x n )]a. (<label>12</label></formula><formula xml:id="formula_23">)</formula><p>As a result, we have</p><formula xml:id="formula_24">f 2 = a T [ (x 1 ), . . . , (x n )] T [ (x 1 ), . . . , (x n )]a = a T Ka,<label>(13)</label></formula><p>With above representations, the objective function defined in Eq. ( <ref type="formula" target="#formula_9">5</ref>) can be rewritten as:</p><formula xml:id="formula_25">arg min a∈R n {J (a) = y L -K L a 2 + λa T Ka + γ a T KLKa}. (<label>14</label></formula><formula xml:id="formula_26">)</formula><p>Therefore, the original minimization problem converts to a quadratic problem with respect to the representation coefficient vector a. By taking ∂ J (a)/∂a = 0, we can derive a closedform solution as:</p><formula xml:id="formula_27">a * = K L K T L + λK + γ KLK -1 K L y L . (<label>15</label></formula><formula xml:id="formula_28">)</formula><p>Substituting this optimal coefficient vector into Eq. ( <ref type="formula" target="#formula_15">10</ref>), we can get the optimal predicted values for all samples. How to define K i j = κ(x i , x j ) will be elaborated in next section. We call the above model as implicit kernel GLRR (IK-GLRR), since the form of kernel function κ(x i , x j ) is directly given (as formulated in Eq. ( <ref type="formula" target="#formula_38">21</ref>) and Eq. ( <ref type="formula" target="#formula_40">22</ref>)), without relying on any concrete definition of . The above implicit kernel induced framework addresses the problem of nonlinear estimation in a nonparametric manner, which relies on the data itself to dictate the structure of the model. It provides us an effective approach to explore the intra-scale similarity, and can handle image recovery from very sparse data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Optimization by Explicit Kernel</head><p>We further consider explicitly mapping samples to a high dimensional feature space in order to reformulate the proposed graph Laplacian regularized model in a linear manner in that space. This is equivalent to solving a nonlinear problem in the original space. This will bring us additional insights to address the current ill-posed problem.</p><p>More specifically, after the process of feature mapping, we get x i = (x i ), which is a projected point in the highdimensional space. Then we define a linear kernel function in this higher-dimensional feature space as κ ( x i , x) = x T i x. With the definition, the representer theorem formulated in Eq. ( <ref type="formula" target="#formula_14">9</ref>) can be written as:</p><formula xml:id="formula_29">f ( x) = n i=1 α i κ ( x i , x) = n i=1 α i x T i x.<label>(16)</label></formula><p>Denoting w T = n i=1 α i x T i , then f ( x) converts to a linear function with the coefficient vector w. And f can be written as:</p><formula xml:id="formula_30">f = ⎡ ⎢ ⎣ f ( x 1 )</formula><p>. . .</p><formula xml:id="formula_31">f ( x n ) ⎤ ⎥ ⎦ = ⎡ ⎢ ⎣ w T x 1 . . . w T x n ⎤ ⎥ ⎦ = X T w,<label>(17)</label></formula><p>where X = [ x 1 , . . . , x n ] is the feature matrix in the mapped high-dimensional space. Since f in Eq.( <ref type="formula" target="#formula_9">5</ref>) indicates the coefficient vector of the mapped feature (x) in RHKS space, we have f = w for explicit kernel optimization. Thus, Substituting Eq. ( <ref type="formula" target="#formula_31">17</ref>) into Eq. ( <ref type="formula" target="#formula_9">5</ref>), the objective function can be formulated into a parametric quadratic form with respect to w:</p><formula xml:id="formula_32">f H = λ f 2 = λw T w.</formula><formula xml:id="formula_33">arg min w {J (w) = y L -X T L w 2 + λw T w + γ w T XL Xw},<label>(18)</label></formula><p>where X L = { x 1 , . . . , x l }. By taking ∂ J (w)/∂w = 0, we derive a closed-form solution as:</p><formula xml:id="formula_34">w * = X L X T L + λI + γ XL X -1 X L y L . (<label>19</label></formula><formula xml:id="formula_35">)</formula><p>Here, I is the identity matrix. We call the above model as explicit kernel GLRR (EK-GLRR), since it relies on an explicitly defined feature mapping , which will be detailed as follows.</p><p>The kernel trick described above maps the non-linear features into a higher dimensional linear feature space, in which we can obtain a linear relationship between mapped features. In the field of image processing, some linear models, such as autoregressive (AR) model, have been widely used to quantify the local smoothness of image intensity field <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. It inspires us that the EK-GLRR model also can be used to finish similar tasks. Moreover, the study of natural image statistics reveals that the second order statistics of natural images tends to be invariant across different scales. Based on such an observation, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>, we first estimate the EK-GLRR model from the recovered image at a coarse scale and then use the model to adapt the reconstruction at the finer scale based on the geometric duality across different scales. In this way, we can learn and propagate the statistical features across different scales to keep the local smoothness of images. In practical design, the explicit projection : R → R 4 is defined as mapping one pixel to 4-dimensional vector including its four 8-connected neighbors along two diagonal directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Discussion</head><p>The IK-GLRR and EK-GLRR models described above supply complementary views towards the regularity in natural images: The former model operated in the original feature space is derived from the perspective of global geometry consistency, which attempts to explore the property of nonlocal self-similarity among image samples, and connect the labeled and unlabeled samples through the graph Laplacian regularization; while the latter model is derived from the perspective of local structure preservation, which explicitly map the image data points to a high dimensional feature space, and establish a direct connection between the inter-scale correlation and the linear regression in the mapped feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROGRESSIVE HYBRID GRAPH LAPLACIAN REGULARIZATION</head><p>As stated in the above section, the IK-GLRR and EK-GLRR models provide two complementary views about the current image recovery task. A natural question is how to combine them together into an elegant framework. In this paper, we propose to use a simple multi-scale framework to achieve such a purpose. There are at least several reasons why we use the multi-scale framework. First, one important characteristic of natural images is that they are comprised of structures at different scales. Through multi-scale decomposition, the structures of images at different scales become better exposed, and hence be more easily predicted. Second, a multi-scale scheme will give a more compact representation of imagery data because it encodes low frequency parts and high frequency parts separately. As well known, the second order statistics of natural images tends to be invariant across different scales <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Therefore, the low frequency parts can be extracted from much smaller downsampled image. Third, the stronger correlations among adjacent image blocks will be captured in the downsampled images because every four image blocks are merged into one block in the downsampled image. As a consequence, in this paper, we propose an effective approach to recover noisy imagery data by combining hybrid models and the multi-scale paradigm.</p><p>We now introduce the multiscale implementation of the proposed method. To give a clear illustration, we summary the proposed multi-scale scheme in Fig. <ref type="figure" target="#fig_2">3</ref>, where 90% samples in the test image Peppers are corrupted. We use the subscript l to indicate the level in the pyramid of downsampled images. The finest level (the original image) is indicated by l = 0. The larger is l, the coarser is the downsampled image. We denote the highest level to be l = L.</p><p>First, the level-l image I l passes a low-pass filter F, which is implemented in our method by averaging the existing pixels in a 2 × 2 neighborhood on higher resolution. Then, the filter image is downsampled by 2 to get a coarser image I l+1 .</p><formula xml:id="formula_36">I l+1 . = F(I l ) ↓ 2, l = 0, . . . , L -1. (<label>20</label></formula><formula xml:id="formula_37">)</formula><p>In this way, we can construct a Laplacian pyramid. In the practical implementation, we construct a tree-level Laplacian pyramid.</p><p>At the beginning, we have the image I 2 at scale 2 at hand, which is defined on the coarsest grid of pixels G 2 . This initial image lacks a fraction of its samples. We start off by recovering the missing samples using the proposed IK-GLRR model, which has been detailed in Section II-C, to get a more complete grid I 2 . This procedure can be performed iteratively by feeding the processing results I 2 to the GLRR model as a prior for computing the kernel distance κ. In the practical experiments, two iterations was found to be effective in improving the processing results in such type of operations. Specially, in the first iteration, since there is only coarsest degraded image I 2 at hand, we construct the kernel distance by Gaussian kernel:</p><formula xml:id="formula_38">κ(x i , x j ) = ex p( u i -u j 2 /σ 2 ), (<label>21</label></formula><formula xml:id="formula_39">)</formula><p>where u i and u j are the location coordinates of x i and x j respectively. For the rest iteration and iterations in other higher level, we use non-local means kernel to explore the global correlation among the whole image samples:</p><formula xml:id="formula_40">κ(x i , x j ) = ex p( b i -b j 2 /σ 2 ). (<label>22</label></formula><formula xml:id="formula_41">)</formula><p>Here, b i and b j are the local patches centered on x i and x j respectively, which represent the context information around x i and x j . The recovered image I 2 is then interpolated to a finer grid G 1 using the proposed EK-GLRR model, which has been detailed in Section II-D. The upsampled image I 1 can be used as a prior estimation for the IK-GLRR model towards a refined estimate I * 1 . Then I * 1 can be upconverted to I 0 in the original resolution grid G 0 by the EK-GLRR model. And the refined estimate I 0 can be combined with I 0 into another IK-GLRR recovery procedure towards the final results I * 0 . Using the above progressive recovery based on intra-scale and inter-scale correlation, we gradually recover an image with few artifacts.</p><p>Note that the basic scheme we use is closely related to the work <ref type="bibr" target="#b26">[27]</ref>. However, we replace most of the components it uses with application-specific ones that we describe in the above section. The first contribution is that we explicitly take into account the intrinsic manifold structure by making use of both labeled and unlabeled data points. This is especially useful for the current impulse noise removal task, in which the number of clean samples is usually not enough to train a robust predictor when the noise level is heavy. The large amounts of unlabeled data can be effectively utilized to extract information that is useful for generalization. The second contribution is that we propose to use the model induced by implicit kernel to consider the property of scale-invariant of natural image, which are shown to be essential for visual perception. This model can effectively learn and propagate the statistical features across different scales to keep the local smoothness of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS AND ANALYSIS</head><p>In this section, extensive experimental results are presented to demonstrate the superiority of the proposed algorithm on the task of impulse noise removal. In experiments, we test two cases: only denoising and both denoising and deblurring, to show the power of our method on handling different distortion. For these two cases, we test two kinds of impulse noise: salt-and-pepper noise and random-value noise. For thoroughness of our comparison study, we select seven widely used images in the literature as test images, as illustrated in Fig. <ref type="figure" target="#fig_3">4</ref>. The images are all sized of 512 × 512. There are a few parameters involved in the proposed algorithm. σ 2 and ε 2 are fixed to 0.5. λ and γ are set as 0.5 and 0.01 respectively.</p><p>For comprehensive comparison, the proposed algorithm is compared with some state-of-the-art work in the literature. More specifically, four approaches are included in our comparative study: (1) kernel regression (KR) based methods <ref type="bibr" target="#b21">[22]</ref>;</p><p>(2) two-phase method proposed by Cai et al. <ref type="bibr" target="#b6">[7]</ref>; (3) iterative framelet-based method (IFASDA) proposed by Li et al. <ref type="bibr" target="#b7">[8]</ref>; (4) our method. The source code of our method can be available from http://homepage.hit.edu.cn/pages/xmliu.  For the first stage, we use the adaptive median filter (AMF) for salt-and-peppers noise detection, and use the adaptive center-weighted median filter (ACWMF) for random-value noise detection. Suppose that f be a noisy image with impulse noise and y be the filtered result by median-type filter, A be the image plane. The candidates of noisy pixels contaminated by impulse noise can be determined as follows:</p><p>(1) For salt-and-peppers noise:</p><formula xml:id="formula_42">N = {(i, j ) ∈ A : y i j = f i j and f i j ∈ {d min , d max }},<label>(23)</label></formula><p>(2) For random-valued impulse noise:</p><formula xml:id="formula_43">N = {(i, j ) ∈ A : y i j = f i j }<label>(24)</label></formula><p>Then the detected noisy pixels are treated as missing pixels (filled with 0) and the rest clean pixels are kept their original value to get the reference image. For more information about the methods of noise detection, we refer the interested readers to <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Salt-and-Pepper Noise Removal</head><p>We first examine the performance comparison on restoring images contaminated by salt-and-pepper noise only. The test images are corrupted by salt-and-pepper noise with high noise rates: 80%, 85%, 90%. For detecting salt-and-pepper noise, we use the AM filter <ref type="bibr" target="#b4">[5]</ref> with a maximum window size of 19. We quantify the objective performance of all methods by PSNR. Table <ref type="table" target="#tab_0">I</ref> tabulates the objective performance of the compared methods. It is clear to see that for all images our method gives highest PSNR values among the compared methods. The average PSNR gain is up to 0.53dB compared with second best perform algorithm. For Lena, the performance gain is 1.01dB when the noise level is 85%.</p><p>It is worth mentioning that KR can be regarded as a special case of our method, which only performs single-scale estimation. KR fails to handle high noise levels, such as 90%. At noise levels 80% and 85%, our method works better than KR for all images except Barbara. In Barbara, there are many globally repeated textures with regular directions. Since such regions are not piecewise stationary, the geometric duality across different scales does not exist. Therefore, the multiscale framework does not work well in this case. In contrast, the single-scale and patch-based kernel regression works better. For images with repetitive structures like Barbara, we can degenerate the proposed scheme to single-scale to get better results.</p><p>Given the fact that human visual system (HVS) is the ultimate receiver of the restored images, we also show the subjective comparison results. The recovered results for Lena, Peppers and Boat are illustrated in Fig. <ref type="figure" target="#fig_4">5</ref>, corresponding to 90% salt-and-peppers noise. The contents of these noisy images are almost not invisible. From the results, we can find that, under high noise levels, the kernel regression methods generate some spurious high frequency artifacts; Cai's method overblurs the results and cannot keep the edge structure well; while the IFASDA approach causes irregular outliers along edges and textures. It can be clearly observed that the proposed algorithm achieves the best overall visual quality through combining the intra-scale and inter-scale correlation: the image is sharper due to the property of local smoothness preservation when using inter-scale correlation, and the edges are more consistent due to the exploration of non-local self-similarity when using intra-scale correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Random-Valued Impulse Noise Removal</head><p>We now consider the case that test images are corrupted by random-valued impulse noise only. The random noise  therefore, clearly random-valued impulse noise are more difficult to detect than salt-and-pepper noise. And the task of random-valued noise removal is expected to be more difficult compared with salt-and-peppers noise removal. Therefore, for random-valued impulse noise removal, we test three medium noise levels: 40%, 50% and 60%. In our experiments, the noise is detected by ACWMF <ref type="bibr" target="#b13">[14]</ref>, which is successively performed four times with different parameters for one image. The parameters are chosen to be the same as those in <ref type="bibr" target="#b22">[23]</ref>.</p><p>In Table <ref type="table" target="#tab_1">II</ref>, we show the PSNR values when restoring the corrupted images with random-valued impulse noise. As  depicted in this table, our method also achieves the best objective performance among the compared methods. The proposed algorithm achieves the highest average PSNR value for all cases. The average PSNR gain is up to 0.55dB compared with second best perform algorithm. The recovered results for Lena, Peppers and Boat are illustrated in Fig. <ref type="figure" target="#fig_5">6</ref>, corresponding to 50% random-valued impulse noise. From the results, we can find after noise removal Cai's method and IFASDA still have some regions with noise, such the face region of Lena, the region between two peppers in Peppers, and the mast region of Boat. Our method produces more clear results compared with other methods.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Salt-and-Pepper Noise Removal and Deblurring</head><p>Next, let us examine the performance of compared methods on mixed distortion, that is, performing denoising and deblurring simultaneously, where the test images are first blurred and then added with impulse noise. The blurring operators are Gaussian blur with a window size of 7 × 7 and a standard deviation of 1. We first test salt-and-peppers noise. The added impulse noise is still with three heavy levels: 80%, 85%, 90%. Table <ref type="table" target="#tab_2">III</ref> illustrates the quantitative comparison on these test images. It can be observed that the proposed algorithm achieves the highest PSNR values for all test images. The average PSNR gain is up to 1.46dB compared with second best perform algorithm.</p><p>We also test the subjective quality comparison. The recovered results for Lena, Peppers and Boat are illustrated in Fig. <ref type="figure" target="#fig_6">7</ref>,  corresponding to 90% salt-and-peppers noise and blurring. Our method produces the most visually pleasant results among all comparative studies. Even under blur and impulse noise simultaneously, the proposed algorithm is still capable of restoring major edges and repetitive textures of the images.</p><p>It is noticed that the proposed method can more accurately recover global object contours, such as the edge along the shoulder in Lena, the edge along the pepper in Peppers, and the edges along the mast in Boat. It is easy to find that the edge across the region with heavy noise cannot be well recovered with other methods. This further demonstrates the power of the proposed multi-scale impulse noise removal algorithm. The strength of the proposed progressively recovery approach comes from its full utilization of the intra-scale and inter-scale correlations, which are neglected by the currently available single-scale methods. And many large-scale structures can be well recovered based upon the progressively computed lowlevel results, which is impossible for traditional single level impulse noise removal algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Random-Valued Noise Removal and Deblurring</head><p>We now consider the case that blurred images are corrupted by random-valued impulse noise. We still test three medium noise levels: 40%, 50% and 60%. Table <ref type="table" target="#tab_3">IV</ref> tabulates the objective quality comparison with respect to PSNR of the four test methods. From this table, we can find at lower noise levels, such as 40%, for test images Wheel and Man, the proposed method loses slightly compared with IFASDA. But the average PSNR is still higher than IFASDA. From higher noise levels, such as 50% and 60%, the proposed method works the best among the compared methods for all test images. The average gain is up to 0.65dB. This demonstrates our method can handle more difficult cases. Fig. <ref type="figure" target="#fig_7">8</ref> illustrates the subjective quality comparison for Lena, Peppers and Boat when the noise level is 50%. It is noticed that the proposed method can more accurately recover images. Both the superior subjective and objective qualities of the proposed algorithm convincingly demonstrate the potential of the proposed hybrid graph Laplacian regularized regression for impulse noise removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Running Time vs. Performance Comparison</head><p>Another major issue needed to consider in image denoising is the computational complexity. Here we use random-valued noise removal and deblurring as an example to show the practical processing time and performance comparison among the compared methods. Table <ref type="table" target="#tab_4">V</ref> gives the PSNR versus average processing times results on a typical computer (2.5GHz Intel Dual Core, 3G Memory). All of the compared algorithm are running on Matlab R2012a. As depicted in Table V, the computational complexity of the proposed method is higher than KR but lower than two other state-of-the-art image impulse noise removal algorithms, and achieves much better quality with respect to PSNR than other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we present an effective and efficient image impulse noise removal algorithm based on hybrid graph Laplacian regularized regression. We utilize the input space and the mapped high-dimensional feature space as two complementary views to address such an ill-posed inverse problem. The framework we explored is a multi-scale Laplacian pyramid, where the intra-scale relationship can be modeled with the implicit kernel graph Laplacian regularization model in input space, while the inter-scale dependency can be learned and propagated with the explicit kernel extension model in mapped feature space. In this way, both local and nonlocal regularity constrains are exploited to improve the accuracy of noisy image recovery. Experimental results demonstrate our method outperforms the state-of-the-art methods in both objective and subjective quality. Moreover, the proposed framework is powerful and general, and can be extended to deal with other ill-posed image restoration tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Intra-scale and inter-scale correlation.</figDesc><graphic coords="2,49.43,58.25,250.10,123.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Model duality across different scales. Black dots represent samples at coarser scale, black dots and blank dots together represent samples at finer scale. The information of second order statistics is scale invariant, and therefore can be propagated from coarser scale to finer scale.</figDesc><graphic coords="5,48.95,58.61,250.10,114.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Diagram of the proposed method.</figDesc><graphic coords="6,113.03,58.85,385.70,249.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Seven sample images in the test set.</figDesc><graphic coords="7,51.47,58.61,509.06,73.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Subjective quality comparison on salt-and-pepper noise removal with the noise level 90%. Column 1: the noisy images; Column 2: the results of KR; Column 3: Cai's results; Column 4: the results of IFASDA; Column 4: our results.</figDesc><graphic coords="8,48.95,58.37,514.10,399.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Subjective quality comparison on random-valued noise removal with the noise level 50%, Column 1: the noisy image; Column 2: the results of KR; Column 3: Cai's results; Column 4: the results of IFASDA; Column 4: our results.</figDesc><graphic coords="9,51.47,58.85,509.06,397.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Subjective quality comparison on deblurring and denoising simultaneously for salt-and-peppers noise with noise level 90%. Column 1: the noisy image; Column 2: the result of KR; Column 3: Cai's result; Column 4: the results of IFASDA; Column 4: our results.</figDesc><graphic coords="10,48.95,58.97,514.10,399.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Subjective quality comparison on deblurring and denoising simultaneously for random-valued impulse noise with noise level 50%. Column 1: the noisy image; Column 2: the result of KR; Column 3: Cai's result; Column 4: the results of IFASDA; Column 4: our results.</figDesc><graphic coords="11,48.95,58.49,514.22,381.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I OBJECTIVE</head><label>I</label><figDesc>QUALITY COMPARISON OF FOUR ALGORITHMS (IN dB) FOR SALT-AND-PEPPER NOISE REMOVAL</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II OBJECTIVE</head><label>II</label><figDesc>QUALITY COMPARISON OF FOUR ALGORITHMS (IN dB) FOR RANDOM-VALUED IMPULSE NOISE REMOVAL values are identically and uniformly distributed in [d min , d max ],</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III OBJECTIVE</head><label>III</label><figDesc>QUALITY COMPARISON OF FOUR ALGORITHMS (IN dB) FOR SALT-AND-PEPPER NOISE REMOVAL AND DEBLURRING SIMULTANEOUSLY</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV OBJECTIVE</head><label>IV</label><figDesc>QUALITY COMPARISON OF FOUR ALGORITHMS(IN dB) FOR RANDOM-VALUED NOISE REMOVAL AND DEBLURRING SIMULTANEOUSLY</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V OBJECTIVE</head><label>V</label><figDesc></figDesc><table /><note><p>QUALITY VERSUS AVERAGE PROCESSING TIMES (dB/SECONDS) RESULTS</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. J.-F. Cai of University of Iowa, and Dr. Y.-R. Li of Shenzhen University for sharing their source codes for comparison. The authors also would like to thank the anonymous reviewers for their constructive suggestions which helped them improve the manuscript.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the National Science Foundation of China under Grants 61300110, 61272386, and 61371146. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Damon M. Chandler.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Plataniotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Venetsanopoulos</surname></persName>
		</author>
		<title level="m">Color Image Processing and Applications</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<title level="m">A Wavelet Tour of Signal Processing, the Sparse Way</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalized methods and solvers for noise removal from piecewise constant signals</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc., Math</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="issue">2135</biblScope>
			<biblScope unit="page" from="3088" to="3114" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive median filters: New algorithms and results</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Haddad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="499" to="502" />
			<date type="published" when="1995-04">Apr. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Center weighted median filters and their applications to image enhancement</title>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="984" to="993" />
			<date type="published" when="1991-09">Sep. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An efficient two-phase L1-TV method for restoring blurred images with impulse noise</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hintermüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1731" to="1739" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast two-phase image deblurring under impulse noise</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Framelet algorithms for deblurring images corrupted by impulse plus Gaussian noise</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1822" to="1837" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiscale hybrid linear models for lossy image representation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3655" to="3671" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image reconstruction from random samples with multiscale hybrid parametric and nonparametric modeling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1554" to="1563" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image interpolation via regularized local linear regression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3455" to="3469" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image interpolation by adaptive 2-D autoregressive modeling and soft-decision estimation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="887" to="896" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Statistics of natural images: Scaling in the woods</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Ruderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="814" to="817" />
			<date type="published" when="1994-08">Aug. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On advances in statistical modeling of natural images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vis</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="33" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Nonlocal image and movie denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="139" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 6th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 6th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. Wisconsin</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Madison, WI, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. 1530</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from examples</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic dyadic data analysis with local and global consistency</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th ICML</title>
		<meeting>26th ICML</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Input space versus feature space in kernel-based methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Knirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ratsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1000" to="1017" />
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Progressive image restoration through hybrid graph Laplacian regularization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Data Compress</title>
		<meeting>IEEE Data Compress<address><addrLine>Snowbird, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-03">Mar. 2013</date>
			<biblScope unit="page" from="103" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Kernel regression for image processing and reconstruction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE. Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="366" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An iterative procedure for removing random-valued impulse noise</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="921" to="924" />
			<date type="published" when="2004-12">Dec. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A tour of modern image filtering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="106" to="128" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending highdimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013-02">Feb. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image interpolation via graph-based Bayesian label propagation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1084" to="1096" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Progressive inter-scale and intra-scale non-blind image deconvolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
