<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Matrix Chernoff Bound for Markov Chains and Its Application to Co-occurrence Matrices</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chi</forename><surname>Wang</surname></persName>
							<email>wang.chi@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Liao</surname></persName>
							<email>bliao@tencent.com</email>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Peng</surname></persName>
							<email>rpeng@cc.gatech.edu</email>
						</author>
						<author>
							<persName><forename type="first">Georgia</forename><surname>Tech</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Tencent Quantum Lab</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Matrix Chernoff Bound for Markov Chains and Its Application to Co-occurrence Matrices</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We prove a Chernoff-type bound for sums of matrix-valued random variables sampled via a regular (aperiodic and irreducible) finite Markov chain. Specially, consider a random walk on a regular Markov chain and a Hermitian matrix-valued function on its state space. Our result gives exponentially decreasing bounds on the tail distributions of the extreme eigenvalues of the sample mean matrix. Our proof is based on the matrix expander (regular undirected graph) Chernoff bound [Garg et al. STOC '18]  and scalar Chernoff-Hoeffding bounds for Markov chains [Chung et al. STACS '12]. Our matrix Chernoff bound for Markov chains can be applied to analyze the behavior of co-occurrence statistics for sequential data, which have been common and important data signals in machine learning. We show that given a regular Markov chain with n states and mixing time τ , we need a trajectory of length O(τ (log n + log τ )/ 2 ) to achieve an estimator of the co-occurrence matrix with error bound . We conduct several experiments and the experimental results are consistent with the exponentially fast convergence rate from theoretical analysis. Our result gives the first bound on the convergence rate of the co-occurrence matrix and the first sample complexity analysis in graph representation learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Chernoff bound <ref type="bibr" target="#b4">[5]</ref>, which gives exponentially decreasing bounds on tail distributions of sums of independent scalar-valued random variables, is one of the most basic and versatile tools in theoretical computer science, with countless applications to practical problems <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b34">35]</ref>. There are two notable limitations when applying Chernoff bound in analyzing sample complexity in real-world machine learning problems. First, in many cases the random variables have dependence, e.g., Markov dependence <ref type="bibr" target="#b19">[20]</ref> in MCMC <ref type="bibr" target="#b17">[18]</ref> and online learning <ref type="bibr" target="#b47">[48]</ref>. Second, applications are often concerned with the concentration behavior of quantities beyond scalar-valued random variables, e.g., random features in kernel machines <ref type="bibr" target="#b39">[40]</ref> and co-occurrence statistics which are random matrices <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>Existing research has attempted to extend the original Chernoff bound in one of these two limitations <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b49">50]</ref>. Wigderson and Xiao <ref type="bibr" target="#b52">[53]</ref> conjectured that Chernoff bounds can be generalized to both matrix-valued random variables and Markov dependence, while restricting the Markov dependence to be a regular undirected graph. It was recently proved by Garg et al. <ref type="bibr" target="#b9">[10]</ref>, based on a new multi-matrix extension of the Golden-Thompson inequality <ref type="bibr" target="#b44">[45]</ref>. However, the regular undirected graph is a special case of Markov chains which are reversible and have a uniform stationary distribution, and does not apply to practical problems such as random walk on generic graphs. It is an open question for the Chernoff bound of matrix-valued random matrices with more generic Markov dependence.</p><p>In this work, we establish large deviation bounds for the tail probabilities of the extreme eigenvalues of sums of random matrices sampled via a regular Markov chain <ref type="foot" target="#foot_1">1</ref> starting from an arbitrary distribution (not necessarily the stationary distribution), which significantly improves the result of Garg et al. <ref type="bibr" target="#b9">[10]</ref>. More formally, we prove the following theorem: Theorem 1 (Markov Chain Matrix Chernoff Bound). Let P be a regular Markov chain with state space [N ], stationary distribution π and spectral expansion λ. Let f : [N ] → C d×d be a function such that (1) ∀v ∈ [N ], f (v) is Hermitian and</p><formula xml:id="formula_0">f (v) 2 ≤ 1; (2) v∈[N ] π v f (v) = 0. Let (v 1 , • • • , v k )</formula><p>denote a k-step random walk on P starting from a distribution φ. Given ∈ (0, 1),</p><formula xml:id="formula_1">P λmax 1 k k j=1 f (vj) ≥ ≤ 4 φ π d 2 exp −( 2 (1 − λ)k/72) P λmin 1 k k j=1 f (vj) ≤ − ≤ 4 φ π d 2 exp −( 2 (1 − λ)k/72) .</formula><p>In the above theorem, • π is the π-norm (which we define formally later in Section 2) measuring the distance between the initial distribution φ and the stationary distribution π. Our strategy is to incorporate the concentration of matrix-valued functions from <ref type="bibr" target="#b9">[10]</ref> into the study of general Markov chains from <ref type="bibr" target="#b5">[6]</ref>, which was originally for scalars. The co-occurrence statistics have recently emerged as common and important data signals in machine learning, providing rich correlation and clustering information about the underlying object space, such as the word co-occurrence in natural language processing <ref type="bibr">[32-34, 26, 37]</ref>, vertex co-occurrence in graph learning <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b38">39]</ref>, item co-occurrence in recommendation system <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b28">29]</ref>, action co-occurrence in reinforcement learning <ref type="bibr" target="#b48">[49]</ref>, and emission co-occurrence of hidden Markov models <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">30]</ref>. Given a sequence of objects (v 1 , • • • , v L ), the co-occurrence statistics are computed by moving a sliding window of fixed size T over the sequence and recording the frequency of objects' co-occurrence within the sliding window. A pseudocode of the above procedure is listed in Algorithm 1, which produces an n by n co-occurrence matrix where n is the size of the object space.</p><p>A common assumption when building such co-occurrence matrices is that the sequential data are long enough to provide an accurate estimation. For instance, Mikolov et al. <ref type="bibr" target="#b32">[33]</ref> use a news article dataset with one billion words in their Skip-gram model; Tennenholtz and Mannor <ref type="bibr" target="#b48">[49]</ref> train their Act2vec model with action sequences from over a million StarCraft II game replays, which are equivalent to 100 years of consecutive gameplay; Perozzi et al. <ref type="bibr" target="#b37">[38]</ref> samples large amounts of random walk sequences from graphs to capture the vertex co-occurrence. A recent work by Qiu et al. <ref type="bibr" target="#b38">[39]</ref> studies the convergence of co-occurrence matrices of random walk on undirected graphs in the limit (i.e., when the length of random walk goes to infinity), but left the convergence rate an open problem. It remains unknown whether the co-occurrence statistics are sample efficient and how efficient they are.</p><p>In this paper, we study the situation where the sequential data are sampled from a regular finite Markov chain (i.e., an aperiodic and irreducible finite Markov chain), and derive bounds on the sample efficiency of co-occurrence matrix estimation, specifically on the length of the trajectory needed in the sampling algorithm shown in Algorithm 1. To give a formal statement, we first translate Algorithm 1 to linear algebra language. Given a trajectory (v 1 , • • • , v L ) from state space [n] and step weight coefficients (α 1 , • • • , α T ), the co-occurrence matrix is defined to be</p><formula xml:id="formula_2">C 1 L − T L−T i=1 Ci, where Ci T r=1 αr 2 ev i e v i+r + ev i+r e v i .</formula><p>Here C i accounts for the co-occurrence within sliding window</p><formula xml:id="formula_3">(v i , • • • , v i+T )</formula><p>, and e vi is a length-n vector with a one in its v i -th entry and zeros elsewhere. Thus e vi e vi+r is a n by n matrix with its (v i , v i+r )-th entry to be one and other entries to be zero, which records the co-occurrence of v i and v i+r . Note that Algorithm 1 is a special case when step weight coefficients are uniform, i.e., α r = 1/T, r ∈ [T ], and the co-occurrence statistics in all the applications mentioned above can be formalized in this way. When trajectory</p><formula xml:id="formula_4">(v 1 , • • • , v L</formula><p>) is a random walk from a regular Markov chain P with stationary distribution π, the asymptotic expectation of the co-occurrence matrix within sliding window</p><formula xml:id="formula_5">(v i , • • • , v i+L ) is AE[Ci] lim i→∞ E(Ci) = T r=1 αr 2 ΠP r + (ΠP r ) ,</formula><p>where Π diag(π). Thus the asymptotic expectation of the co-occurrence matrix is</p><formula xml:id="formula_6">AE[C] lim L→∞ E [C] = lim L→∞ 1 L − T L−T i=1 E(Ci) = T r=1 αr 2 ΠP r + (ΠP r ) .<label>(1)</label></formula><p>Our main result regarding the estimation of the co-occurrence matrix is the following convergence bound related to the length of the walk sampled. </p><formula xml:id="formula_7">. Let (v 1 , • • • , v L ) denote a L-step random walk on P starting from a distribution φ on [n]. Given step weight coefficients (α 1 , • • • , α T ) s.t. T r=1 |α r | = 1</formula><p>, and ∈ (0, 1), the probability that the co-occurrence matrix C deviates from its asymptotic expectation AE[C] (in 2-norm) is bounded by:</p><formula xml:id="formula_8">P C − AE[C] 2 ≥ ≤ 2 (τ + T ) φ π n 2 exp − 2 (L − T ) 576 (τ + T ) .</formula><p>Specially, there exists a trajectory length L = O (τ + T )(log n + log (τ + T ))/<ref type="foot" target="#foot_2">2</ref> + T such that</p><formula xml:id="formula_9">P [ C − AE[C] 2 ≥ ] ≤ 1 n O(1) . Assuming T = O(1) gives L = O τ (log n + log τ )/ 2 .</formula><p>Our result in Theorem 2 gives the first sample complexity analysis for many graph representation learning algorithms. Given a graph, these algorithms aim to learn a function from the vertices to a low dimensional vector space. Most of them (e.g., DeepWalk <ref type="bibr" target="#b37">[38]</ref>, node2vec <ref type="bibr" target="#b11">[12]</ref>, metapath2vec <ref type="bibr" target="#b6">[7]</ref>, GraphSAGE <ref type="bibr" target="#b12">[13]</ref>) consist of two steps. The first step is to draw random sequences from a stochastic process defined on the graph and then count co-occurrence statistics from the sampled sequences, where the stochastic process is usually defined to be first-order or higher-order random walk on the graph. The second step is to train a model to fit the co-occurrence statistics. For example, DeepWalk can be viewed as factorizing a point-wise mutual information matrix <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b38">39]</ref> which is a transformation of the co-occurrence matrix; GraphSAGE fits the co-occurrence statistics with a graph neural network <ref type="bibr" target="#b21">[22]</ref>. The common assumption is that there are enough samples so that the cooccurrence statistics are accurately estimated. We are the first work to study the sample complexity of the aforementioned algorithms. Theorem 2 implies that these algorithms need O(τ (log n + log τ )/ 2 ) samples to achieve a good estimator of the co-occurrence matrix.</p><p>Previous work Hsu et al. <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref> study a similar problem. They leverage the co-occurrence matrix with T = 1 to estimate the mixing time in reversible Markov chains from a single trajectory. Their main technique is a blocking technique <ref type="bibr" target="#b54">[55]</ref> which is in parallel with the Markov chain matrix Chernoff-bound used in this work. Our work is also related to the research about random-walk matrix polynomial sparsification when the Markov chain P is a random walk on an undirected graph. In this case, we can rewrite P = D −1 A where D and A is the degree matrix and adjacency matrix of an undirected graph with n vertices and m edges, and the expected co-occurrence matrix in Equation 1 can be simplified as 2 which is known as random-walk matrix polynomials <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. <ref type="bibr">Cheng et al. [4]</ref> propose an algorithm which needs O(T 2 m log n/ 2 ) steps of random walk to construct an -approximator for the random-walk matrix polynomials. Our bound in Theorem 2 is stronger than the bound proposed by Cheng et al. <ref type="bibr" target="#b3">[4]</ref> when the Markov chain P mixes fast. Moreover, Cheng et al. <ref type="bibr" target="#b3">[4]</ref> require α r to be non-negative, while our bound can handle negative step weight coefficients.</p><formula xml:id="formula_10">AE [C] = 1 vol (G) T r=1 α r D(D −1 A) r ,</formula><p>Organization The rest of the paper is organized as follows. In Section 2 we provide preliminaries, followed by the proof of matrix Chernoff bound in Section 3 and the proof of convergence rate of co-occurrence matrices in Section 4. In Section 5, we conduct experiments on both synthetic and real-world datasets. Finally, we conclude this work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this paper, we denote P to be a finite Markov chain on n states. P could refer to either the chain itself or the corresponding transition probability matrix -an n by n matrix such that its entry P ij indicates the probability that state i moves to state j. A Markov chain is called an ergodic Markov chain if it is possible to eventually get from every state to every other state with positive probability. A Markov chain is regular if some power of its transition matrix has all strictly positive entries. A regular Markov chain must be an ergodic Markov chain, but not vice versa. An ergodic Markov chain has unique stationary distribution, i,e., there exists a unique probability vector π such that π = π P . For convenience, we denote Π diag(π).</p><p>The time that a regular Markov chain<ref type="foot" target="#foot_3">3</ref> needs to be "close" to its stationary distribution is called mixing time. Let x and y be two probability vectors. The total variation distance between them is x − y T V 1 2 x − y 1 . For δ &gt; 0, the δ-mixing time of regular Markov chain P is τ (P ) min t : max x (x P t ) − π T V ≤ δ , where x is an arbitrary probability vector.</p><p>The stationary distribution π also defines a inner product space where the inner product (under πkernel) is defined as x, y π y * Π −1 x for ∀x, y ∈ C N , where y * is the conjugate transpose of y. A naturally defined norm based on the above inner product is x π</p><p>x, x π . Then we can define the spectral expansion λ(P ) of a Markov chain P <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b5">6]</ref> as λ(P ) max x,π π =0,x =0 (x * P ) * π x π . The spectral expansion λ(P ) is known to be a measure of mixing time of a Markov chain. The smaller λ(P ) is, the faster a Markov chain converges to its stationary distribution <ref type="bibr" target="#b53">[54]</ref>. If P is reversible, λ(P ) is simply the second largest absolute eigenvalue of P (the largest is always 1). The irreversible case is more complicated, since P may have complex eigenvalues. In this case, λ(P ) is actually the square root of the second largest absolute eigenvalue of the multiplicative reversiblization of P <ref type="bibr" target="#b8">[9]</ref>. When P is clear from the context, we will simply write τ and λ for τ (P ) and λ(P ), respectively. We shall also refer 1 − λ(P ) as the spectral gap of P .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Matrix Chernoff Bounds for Markov Chains</head><p>This section provides a brief overview of our proof of Markov chain Martrix Chernoff bounds. We start from a simpler version which only consider real-valued symmetric matrices, as stated in Theorem 3 below. Then we extend it to complex-valued Hermitian matrices, as stated in in Theorem 1. Theorem 3 (A Real-Valued Version of Theorem 1). Let P be a regular Markov chain with state space [N ], stationary distribution π and spectral expansion λ. Let f :</p><formula xml:id="formula_11">[N ] → R d×d be a function such that (1) ∀v ∈ [N ], f (v) is symmetric and f (v) 2 ≤ 1; (2) v∈[N ] π v f (v) = 0. Let (v 1 , • • • , v k )</formula><p>denote a k-step random walk on P starting from a distribution φ on [N ]. Then given ∈ (0, 1),</p><formula xml:id="formula_12">P λmax 1 k k j=1 f (vj) ≥ ≤ φ π d 2 exp −( 2 (1 − λ)k/72) P λmin 1 k k j=1 f (vj) ≤ − ≤ φ π d 2 exp −( 2 (1 − λ)k/72) .</formula><p>Due to space constraints, we defer the full proof to Section B in the supplementary material and instead present a sketch here. By symmetry, we only discuss on bounding λ max here. Using the exponential method, the probability in Theorem 3 can be upper bounded for any t &gt; 0 by:</p><formula xml:id="formula_13">P   λmax   1 k k j=1 f (vj )   ≥   ≤ P   Tr   exp   t k j=1 f (vj )     ≥ exp (tk )   ≤ E Tr exp t k j=1 f (vj ) exp (tk )</formula><p>,</p><p>where the first inequality follows by the tail bounds for eigenvalues (See Proposition 3.2.1 in Tropp <ref type="bibr" target="#b49">[50]</ref>) which controls the tail probabilities of the extreme eigenvalues of a random matrix by producing a bound for the trace of the matrix moment generating function, and the second inequality follows by Markov's inequality. The RHS of the above equation is the expected trace of the exponential of a sum of matrices (i.e., tf (v j )'s). When f is a scalar-valued function, we can easily write exponential of a sum to be product of exponentials (since exp(a + b) = exp(a) exp(b) for scalars). However, this is not true for matrices. To bound the expectation term, we invoke the following multi-matrix Golden-Thompson inequality from <ref type="bibr" target="#b9">[10]</ref>, by letting</p><formula xml:id="formula_14">H j = tf (v j ), j ∈ [k].</formula><p>Theorem 4 (Multi-matrix Golden-Thompson Inequality, Theorem 1.5 in <ref type="bibr" target="#b9">[10]</ref>). Let H The key point of this theorem is to relate the exponential of a sum of matrices to a product of matrix exponentials and their adjoints, whose trace can be further bounded via the following lemma by letting e iφ = γ + ib. Lemma 1 (Analogous to Lemma 4.3 in <ref type="bibr" target="#b9">[10]</ref>). Let P be a regular Markov chain with state space [N ] with spectral expansion λ. Let f be a function f</p><formula xml:id="formula_15">: [N ] → R d×d such that (1) v∈[N ] π v f (v) = 0; (2) f (v) 2 ≤ 1 and f (v) is symmetric, v ∈ [N ]. Let (v 1 , • • • , v k ) denote a k-step random walk on P starting from a distribution φ on [N ]. Then for any t &gt; 0, γ ≥ 0, b &gt; 0 such that t 2 (γ 2 + b 2 ) ≤ 1 and t γ 2 + b 2 ≤ 1−λ 4λ , we have E   Tr   k j=1 exp tf (vj )(γ + ib) 2 1 j=k exp tf (vj )(γ − ib) 2     ≤ φ π d exp kt 2 (γ 2 + b 2 ) 1 + 8 1 − λ .</formula><p>Proving Lemma 1 is the technical core of our paper. The main idea is to write the expected trace expression in LHS of Lemma 1 in terms of the transition probability matrix P , which allows for a recursive analysis to track how much the expected trace expression changes as a function of k.</p><p>The analysis relies on incorporating the concentration of matrix-valued functions from <ref type="bibr" target="#b9">[10]</ref> into the study of general Markov chains from <ref type="bibr" target="#b5">[6]</ref>, which was originally for scalars. Key to this extension is the definition of an inner product related to the stationary distribution π of P , and a spectral expansion from such inner products. In contrast, the undirected regular graph case studied in <ref type="bibr" target="#b9">[10]</ref> can be handled using the standard inner products, as well as the second largest eigenvalues of P instead of the spectral expansion. Detailed proofs of Theorem 3 and Lemma 1 can be found in Appendix B.2 and Appendix B.3 of the supplementary material, respectively.</p><p>Our result about real-valued matrices can be further generalized to complex-valued matrices, as stated in Theorem 1. Our main strategy is to adopt complexification technique <ref type="bibr" target="#b7">[8]</ref>, which first relate the eigenvalues of a d × d complex Hermitian matrix to a 2d × 2d real symmetric matrix, and then deal with the real symmetric matrix using Theorem 3. The proof of Theorem 1 is deferred to Appendix B.4 in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Convergence Rate of Co-occurrence Matrices of Markov Chains</head><p>In this section, we first apply the matrix Chernoff bound for regular Markov chains from Theorem 3 to obtain our main result on the convergence of co-occurrence matrix estimation, as stated in Theorem 2, and then discuss its generalization to Hidden Markov models in Corollary 1. Informally, our result in Theorem 3 states that if the mixing time of the Markov chain P is τ , then the length of a trajectory needed to guarantee an additive error (in 2-norm) of is roughly O (τ + T )(log n + log τ + T )/ 2 + T , where T is the co-occurrence window size. However, we cannot directly apply the matrix Chernoff bound because the co-occurrence matrix is not a sum of matrix-valued functions sampled from the original Markov chain P . The main difficulty is to construct the proper Markov chain and matrix-valued function as desired by Theorem 3. We formally give our proof as follows:</p><p>Proof. (of Theorem 2) Our proof has three main steps: the first two construct a Markov chain Q according to P , and a matrix-valued function f such that the sums of matrix-valued random variables sampled via Q is exactly the error matrix C − AE[C]. Then we invoke Theorem 3 to the constructed Markov chain Q and function f to bound the convergence rate. We give details below.</p><p>Step One Given a random walk</p><formula xml:id="formula_16">(v 1 , • • • , v L ) on Markov chain P , we construct a sequence (X 1 , • • • , X L−T ) where X i (v i , v i+1 , • • • , v i+T ), i.e., each X i is a size-T sliding window over (v 1 , • • • , v L ).</formula><p>Meanwhile, let S be the set of all T -step walks on Markov chain P , we define a new Markov chain</p><formula xml:id="formula_17">Q on S such that ∀(u 0 , • • • , u T ), (w 0 , • • • , w T ) ∈ S: Q (u 0 ,••• ,u T ),(w 0 ,••• ,w T ) Pu T ,w T if (u1, • • • , uT ) = (w0, • • • , wT −1); 0 otherwise.</formula><p>The following claim characterizes the properties of Q, whose proof is deferred to Appendix A.1 in the supplementary material.</p><p>Claim 1 (Properties of Q). If P is a regular Markov chain, then Q satisfies:</p><formula xml:id="formula_18">1. Q is a regular Markov chain with stationary distribution σ (u0,••• ,u T ) = π u0 P u0,u1 • • • P u T −1 ,u T ; 2. The sequence (X 1 , • • • X L−T ) is a random walk on Q starting from a distribution ρ such that ρ (u0,••• ,u T ) = φ u0 P u0,u1 • • • P u T −1 ,u T , and ρ σ = φ π . 3. ∀δ &gt; 0, the δ-mixing time of P and Q satisfies τ (Q) &lt; τ (P ) + T ; 4. ∃P with λ(P ) &lt; 1 s.t. the induced Q has λ(Q) = 1, i.e. Q may have zero spectral gap.</formula><p>Parts 1 and 2 imply that the sliding windows (i.e., X 1 , X 2 , • • • ) correspond to the state transition in a regular Markov chain Q, whose mixing time and spectral expansion are described in Parts 3 and 4. A special case of the above construction when T = 1 can be found in Lemma 6.1 of <ref type="bibr" target="#b53">[54]</ref>.</p><p>Step Two Defining a matrix-valued function f :</p><formula xml:id="formula_19">S → R n×n such that ∀X = (u 0 , • • • , u T ) ∈ S: f (X) 1 2 T r=1 αr 2 eu 0 e ur + eu r e u 0 − T r=1 αr 2 ΠP r + (ΠP r ) .<label>(2)</label></formula><p>With this definition of f (X), the difference between the co-occurrence matrix C and its asymptotic expectation AE[C] can be written as:</p><formula xml:id="formula_20">C − AE[C] = 2( 1 L−T L−T i=1 f (X i ))</formula><p>. We can further show the following properties of this function f :</p><formula xml:id="formula_21">Claim 2 (Properties of f ). The function f in Equation 2 satisfies (1) X∈S σ X f (X) = 0; (2) f (X) is symmetric and f (X) 2 ≤ 1, ∀X ∈ S.</formula><p>This claim verifies that f in Equation 2 satisfies the two conditions of matrix-valued function in Theorem 3. The proof of Claim 2 is deferred to Appendix A.2 of the supplementary material.</p><p>Step Three The construction in step two reveals the fact that the error matrix C − AE[C] can be written as the average of matrix-valued random variables (i.e., f (X i )'s), which are sampled via a regular Markov chain Q This encourages us to directly apply Theorem 3. However, note that (1) the error probability in Theorem 3 contains a factor of spectral gap (1 − λ); and (2) Part 4 of Claim 1 allows for the existence of a Markov chain P with λ(P ) &lt; 1 while the induced Markov chain Q has λ(Q) = 1. So we cannot directly apply Theorem 3 to Q. To address this issue, we utilize the following tighter bound on sub-chains. </p><formula xml:id="formula_22">(Q), then λ Q τ (Q) ≤ √ 2δ. In particular, setting δ = 1 8 implies λ(Q τ (Q) ) ≤ 1 2 .</formula><p>The above claim reveals the fact that, even though Q could have zero spectral gap (Part 4 of Claim 1), we can bound the spectral expansion of Q τ (Q) . We partition 4 , such that the i-th group consists of a sub-chain</p><formula xml:id="formula_23">(X 1 , • • • X L−T ) into τ (Q) groups</formula><formula xml:id="formula_24">(X i , X i+τ (Q) , X i+2τ (Q) , • • • ) of length k (L−T )/τ (Q).</formula><p>The sub-chain can be viewed as generated from a Markov chain Q τ (Q) . Apply Theorem 3 to the i-th sub-chain, whose starting distribution is ρ i Q i−1 ρ, we have</p><formula xml:id="formula_25">P λmax 1 k k j=1 f (X i+(j−1)τ (Q) ≥ ≤ ρi σ n 2 exp − 2 1 − λ Q τ (Q) k/72 ≤ ρi σ n 2 exp − 2 k/144 ≤ φ π n 2 exp − 2 k/144 ,</formula><p>where that last step follows by</p><formula xml:id="formula_26">ρ i σ ≤ ρ i−1 σ ≤ • • • ρ 1 σ = ρ σ and ρ σ = φ π (Part 2 of Claim 1</formula><p>). Together with a union bound across each sub-chain, we can obtain:</p><formula xml:id="formula_27">P [λmax (C − AE[C]) ≥ ] = P λmax 1 L − T L−T j=1 f (Xj) ≥ 2 =P   λmax   1 τ (Q) τ (Q) i=1 1 k k j=1 f (X i+(j−1)τ (Q) )   ≥ 2   ≤ τ (Q) i=1 P λmax 1 k k j=1 f (X i+(j−1)N ) ≥ 2 ≤ τ (Q) φ π n 2 exp − 2 k/576 .</formula><p>The bound on λ min also follows similarly. As C − AE[C] is a real symmetric matrix, its 2-norm is its maximum absolute eigenvalue. Therefore, we can use the eigenvalue bound to bound the overall error probability in terms of the matrix 2-norm:</p><formula xml:id="formula_28">P C − AE[C] 2 ≥ = P [λmax(C − AE[C]) ≥ ∨ λmin(C − AE[C]) ≤ − ] ≤2τ (Q)n 2 φ π exp − 2 k/576 ≤ 2 (τ (P ) + T ) φ π n 2 exp − 2 (L − T ) 576 (τ (P ) + T ) ,</formula><p>where the first inequality follows by union bound, and the second inequality is due to τ (Q) &lt; τ (P ) + T (Part 3 of Claim 1). This bound implies that the probability that C deviates from Our analysis can be extended to Hidden Markov models (HMM) as shown in Corollary 1, and has a potential to solve problems raised in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30]</ref>. Our strategy is to treat the HMM with observable state space Y and hidden state space X as a Markov chain with state space Y × X . The detailed proof can be found in Appendix A.3 in the supplementary material.</p><p>Corollary 1 (Co-occurrence Matrices of HMMs). For a HMM with observable states y t ∈ Y and hidden states x t ∈ X , let P (y t |x t ) be the emission probability and P (x t+1 |x t ) be the hidden state transition probability. Given an L-step trajectory observations from the HMM, (y</p><formula xml:id="formula_29">1 , • • • , y L ), one needs a trajectory of length L = O(τ (log |Y| + log τ )/ 2</formula><p>) to achieve a co-occurrence matrix within error bound with high probability, where τ is the mixing time of the Markov chain on hidden states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we show experiments to illustrate the exponentially fast convergence rate of estimating co-occurrence matrices of Markov chains. We conduct experiments on three synthetic Markov chains (Barbell graph, winning streak chain, and random graph) and one real-world Markov chain (BlogCatalog). For each Markov chain and each trajectory length L from the set {10 1 , • • • , 10 7 }, we measure the approximation error of the co-occurrence matrix constructed by Algorithm 1 from a L-step random walk sampled from the chain. We performed 64 trials for each 4 Without loss of generality, we assume L − T is a multiple of τ (Q). experiment, and the results are aggregated as an error-bar plot. We set T = 2 and α r to be uniform unless otherwise mentioned. The relationship between trajectory length L and approximation error C − AE[C] 2 is shown in Figure <ref type="figure" target="#fig_3">1</ref> (in log-log scale). Across all the four datasets, the observed exponentially fast convergence rates match what our bounds predict in Theorem 2. Below we discuss our observations for each of these datasets.</p><p>Barbell Graphs <ref type="bibr" target="#b42">[43]</ref> The Barbell graph is an undirected graph with two cliques connected by a single path. Such graphs' mixing times vary greatly: two cliques with size k connected by a single edge have mixing time Θ(k 2 ); and two size-k cliques connected by a length-k path have mixing time about Θ(k 3 ). We evaluate the convergence rate of co-occurrence matrices on the two graphs mentioned above, each with 100 vertices. According to our bound that require L = O(τ (log n + log τ )/ 2 ), we shall expect the approximate co-occurrence matrix to converge faster when the path bridging the two cliques is shorter. The experimental results are shown in Figure <ref type="figure" target="#fig_3">1a</ref>, and indeed display faster convergences when the path is shorter (since we fix n = 100, a Barbell graph with clique size 50 has a shorter path connecting the two cliques than the one with clique size 33).</p><p>Winning Streak Chains (Section 4.6 of <ref type="bibr" target="#b24">[25]</ref>) A winning streak Markov chain has state space [n], and can be viewed as tracking the number of consecutive 'tails' in a sequence of coin flips. Each state transits back to state 1 with probability 0.5, and the next state with probability 0.5. The δ-mixing time of this chain satisfies τ ≤ log 2 (1/δ) , and is independent of n. This prompted us to choose this chain, as we should expect similar rates of convergence for different values of n according to our bound of L = O(τ (log n + log τ )/ 2 ). In our experiment, we compare between n = 50 and n = 100 and illustrate the results in Figure <ref type="figure" target="#fig_3">1b</ref>. As we can see, for each trajectory length L, the approximation errors of n = 50 and n = 100 are indeed very close.</p><p>BlogCatalog Graph <ref type="bibr" target="#b46">[47]</ref> is widely used to benchmark graph representation learning algorithms <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b38">39]</ref>. It is an undirected graph of social relationships of online bloggers with 10,312 vertices and 333,983 edges. The random walk on the BlogCatalog graph has spectral expansion λ ≈ 0.57. Following Levin and Peres <ref type="bibr" target="#b24">[25]</ref>, we can upper bound its 1  8 -mixing time by τ ≤ 36. We choose T from {2, 4, 8} and illustrate the results in Figure <ref type="figure" target="#fig_3">1c</ref>. The convergence rate is robust to different values of T . Moreover, the variance in BlogCatalog is much smaller than that in other datasets.</p><p>We further demonstrate how our result could be used to select parameters for a popular graph representation learning algorithm, DeepWalk <ref type="bibr" target="#b37">[38]</ref>. We set the window size T = 10, which is the default value of DeepWalk. Our bound on trajectory length L in Theorem 1 (with explicit constant) is L ≥ 576(τ + T )(3 log n + log (τ + T ))/ 2 + T . The error bound might be chosen in the range of [0.1, 0.01], which corresponds to L in the range of [8.4 × 10 7 , 8.4 × 10 9 ]. To verify that is a meaningful range for tuning L, we enumerate trajectory length L from {10 4 , • • • , 10 10 }, estimate the co-occurrence matrix with the single trajectory sampled from BlogCatalog, convert the co-occurrence matrix to the one implicitly factorized by DeepWalk <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>, and factorize it with SVD. For comparison, we also provide the result at the limiting case (L → +∞) where we directly compute the asymptotic expectation of the co-occurrence matrix according to Equation 1.</p><p>The limiting case involves computing a matrix polynomial and could be very expensive. For node classification task, the micro-F1 when training ratio is 50% is As we can see, it is reasonable to choose L in the predicted range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Graph</head><p>The small variance observed on BlogCatalog leads us to hypothesize that it shares some traits with random graphs. To gather further evidence for this, we estimate the cooccurrence matrices of an Erdős-Rényi random graph for comparison. Specifically, we take a random graph on 100 vertices where each undirected edge is added independently with probability 0.1, aka. G(100, 0.1). The results Figure <ref type="figure" target="#fig_3">1d</ref> show very similar behaviors compared to the BlogCatalog graph: small variance and robust convergence rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we analyze the convergence rate of estimating the co-occurrence matrix of a regular Markov chain. The main technical contribution of our work is to prove a Chernoff-type bound for sums of matrix-valued random variables sampled via a regular Markov chain, and we show that the problem of estimating co-occurrence matrices is a non-trivial application of the Chernoff-type bound.</p><p>Our results show that, given a regular Markov chain with n states and mixing time τ , we need a trajectory of length O(τ (log n + log τ )/ 2 ) to achieve an estimator of the co-occurrence matrix with error bound . Our work leads to some natural future questions:</p><p>• Is it a tight bound? Our analysis on convergence rate of co-occurrence matrices relies on union bound, which probably gives a loose bound. It would be interesting to shave off the leading factor τ in the bound, as the mixing time τ could be large for some Markov chains.</p><p>• What if the construction of the co-occurrence matrix is coupled with a learning algorithm? For example, in word2vec <ref type="bibr" target="#b32">[33]</ref>, the co-occurrence in each sliding window outputs a mini-batch to a logistic matrix factorization model. This problem can be formalized as the convergence of stochastic gradient descent with non-i.i.d but Markovian random samples.</p><p>• Can we find more applications of the Markov chain matrix Chernoff bound? We believe Theorem 3 could have further applications, e.g., in reinforcement learning <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>Our work contributes to the research literature of Chernoff-type bounds and co-occurrence statistics.</p><p>Chernoff-type bound have become one of the most important probabilistic results in computer science.</p><p>Our result generalize Chernoff bound to Markov dependence and random matrices. Co-occurrence statistics have emerged as important tools in machine learning. Our work addresses the sample complexity of estimating co-occurrence matrix. We believe such better theoretical understanding can further the understanding of potential and limitations of graph representation learning and reinforcement learning.</p><p>assume for a moment the x, y, σ, π are row vectors. We can see that:</p><formula xml:id="formula_30">yQ τ (P )+T −1 − σ T V = 1 2 yQ τ (P )+T −1 − σ 1 = 1 2 (v 1 ,••• ,v T )∈S yQ τ (P )+T −1 − σ v 1 ,••• ,v T = 1 2 (v 1 ,••• ,v T )∈S xP τ (P ) v 1 Pv 1 ,v 2 • • • Pv T −1 ,v T − πv 1 Pv 1 ,v 2 • • • Pv T −1 ,v T = 1 2 (v 1 ,••• ,v T )∈S xP τ (P ) v 1 − πv 1 Pv 1 ,v 2 • • • Pv T −1 ,v T = 1 2 v 1 xP τ (P ) v 1 − πv 1 (v 1 ,••• ,v T )∈S Pv 1 ,v 2 • • • Pv T −1 ,v T = 1 2 v 1 xP τ (P ) v 1 − πv 1 = 1 2 xP τ (P ) − π 1 = xP τ (P ) − π T V ≤ δ.</formula><p>which indicates τ (Q) ≤ τ (P ) + T − 1 &lt; τ (P ) + T .</p><p>Part 4 This is an example showing that λ(Q) cannot be bounded by λ(P ) -even though P has λ(P ) &lt; 1, the induced Q may have λ(Q) = 1. We consider random walk on the unweighted undirected graph and T = 1. The transition probability matrix P is:</p><formula xml:id="formula_31">P =    0 1/3 1/3 1/3 1/2 0 1/2 0 1/3 1/3 0 1/3 1/2 0 1/2 0    with stationary distribution π = [0.3 0.2 0.3 0.2] and λ(P ) = 2 3 . When T = 1, the induced Markov chain Q has stationary distribution σ u,v = π u P u,v = du 2m 1 du = 1</formula><p>2m where m = 5 is the number of edges in the graph. Construct y ∈ R |S| such that</p><formula xml:id="formula_32">y (u,v) =      1 (u, v) = (0, 1), −1 (u, v) = (0, 3), 0 otherwise.</formula><p>The constructed vector y has norm</p><formula xml:id="formula_33">y σ = y, y σ = (u,v)∈S y (u,v) y (u,v) σ (u,v) = y (0,1) y (0,1) σ (0,1) + y (0,3) y (0,3) σ (0,3) = 2 √ m.</formula><p>And it is easy to check y ⊥ σ, since y, σ σ = (u,v)∈S</p><formula xml:id="formula_34">σ (u,v) y (u,v) σ (u,v)</formula><p>= y (0,1) + y (0,3) = 0. Let x = (y * Q) * , we have for (u, v) ∈ S:</p><formula xml:id="formula_35">x (u,v) =      1 (u, v) = (1, 2), −1 (u, v) = (3, 2), 0 otherwise.</formula><p>This vector has norm:</p><formula xml:id="formula_36">x σ = x, x σ = (u,v)∈S x (u,v) x (u,v) σ (u,v) = y (1,2) y (1,2) σ (1,2) + y (3,2) y (3,2) σ (3,2) = 2 √ m</formula><p>Thus we have</p><formula xml:id="formula_37">(y * Q) * σ y σ = 1.</formula><p>Taking maximum over all possible y gives λ(Q) ≥ 1. Also note that fact that λ</p><formula xml:id="formula_38">(Q) ≤ 1, so λ(Q) = 1. A.2 Proof of Claim 2 Claim 2 (Properties of f ). The function f in Equation 2 satisfies (1) X∈S σ X f (X) = 0; (2) f (X) is symmetric and f (X) 2 ≤ 1, ∀X ∈ S.</formula><p>Proof. Note that Equation 2 is indeed a random value minus its expectation, so naturally Equation 2 has zero mean, i.e., X∈S σ X f (X) = 0. Moreover, f (X) 2 ≤ 1 because</p><formula xml:id="formula_39">f (X) 2 ≤ 1 2 T r=1 |αr| 2 ev 0 e vr 2 + ev r e v 0 2 + T r=1 |αr| 2 Π 2 P r 2 + P r 2 Π 2 ≤ 1 2 T r=1 |αr| + T r=1 |αr| = 1.</formula><p>where the first step follows triangle inequaity and submultiplicativity of 2-norm, and the third step follows by (1) e i e j 2 = 1;</p><formula xml:id="formula_40">(2) Π 2 = diag(π) 2 ≤ 1 for distribution π; (3) P 2 = P 2 = 1.</formula><p>A. </p><formula xml:id="formula_41">A ⊗ B =    A1,1B • • • A1,N 1 B . . . . . . . . . AM 1 ,1B • • • AM 1 ,N 1 B    .</formula><p>Kronecker product has the mixed-product property. If A, B, C, D are matrices of such size that one can from the matrix products AC and BD, then</p><formula xml:id="formula_42">(A ⊗ B)(C ⊗ D) = (AC) ⊗ (BD).</formula><p>Vectorization For a matrix X ∈ C d×d , vec(X) ∈ C d 2 denote the vertorization of the matrix X, s.t. vec(X) = i∈[d] j∈[d] X i,j e i ⊗ e j , which is the stack of rows of X. And there is a relationship between matrix multiplication and Kronecker product s.t. vec(AXB) = (A ⊗ B ) vec(X).</p><p>Matrices and Norms For a matrix A ∈ C N ×N , we use A to denote matrix transpose, use A to denote entry-wise matrix conjugation, use A * to denote matrix conjugate transpose (A * = A = A ). The vector 2-norm is defined to be x 2 = √ x * x, and the matrix 2-norm is defined to be</p><formula xml:id="formula_43">A 2 = max x∈C N ,x =0 Ax 2 x 2 .</formula><p>We then recall the definition of inner-product under π-kernel in Section 2. The inner-product under π-kernel for C N is x, y π = y * Π −1 x where Π = diag(π), and its induced π-norm x π =</p><p>x, x π . The above definition allow us to define a inner product under π-kernel on C N d 2 :</p><p>Definition 1. Define inner product on C N d 2 under π-kernel to be x, y π = y * Π −1 ⊗ I d 2 x.</p><p>Remark 1. For x, y ∈ C N and p, q ∈ C d 2 , then inner product (under π-kernel) between x ⊗ p and y ⊗ q can be simplified as</p><formula xml:id="formula_44">x ⊗ p, y ⊗ q π = (y ⊗ q) * Π −1 ⊗ I d 2 (x ⊗ p) = (y * Π −1 x) ⊗ (q * p) = x, y π p, q .</formula><p>Remark 2. The induced π-norm is x π =</p><p>x, x π . When x = y ⊗ w, the π-norm can be simplified to be: x π = y ⊗ w, y ⊗ w π = y, y π w, w = y π w 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Matrix Exponential</head><p>The matrix exponential of a matrix A ∈ C d×d is defined by Taylor expansion exp (A) = +∞ j=0</p><p>A j j! . And we will use the fact that exp(A) ⊗ exp(B) = exp(A ⊗ I + I ⊗ B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Golden-Thompson Inequality</head><p>We need the following multi-matrix Golden-Thompson inequality from from Garg et al. <ref type="bibr" target="#b9">[10]</ref>. Theorem 4 (Multi-matrix Golden-Thompson Inequality, Theorem 1.5 in <ref type="bibr" target="#b9">[10]</ref>). Let </p><formula xml:id="formula_45">f : [N ] → R d×d be a function such that (1) ∀v ∈ [N ], f (v) is symmetric and f (v) 2 ≤ 1; (2) v∈[N ] π v f (v) = 0. Let (v 1 , • • • , v k )</formula><p>denote a k-step random walk on P starting from a distribution φ on [N ]. Then given ∈ (0, 1),</p><formula xml:id="formula_46">P λmax 1 k k j=1 f (vj) ≥ ≤ φ π d 2 exp −( 2 (1 − λ)k/72) P λmin 1 k k j=1 f (vj) ≤ − ≤ φ π d 2 exp −( 2 (1 − λ)k/72) .</formula><p>Proof. Due to symmetry, it suffices to prove one of the statements. Let t &gt; 0 be a parameter to be chosen later. Then</p><formula xml:id="formula_47">P λmax 1 k k j=1 f (vj) ≥ = P λmax k j=1 f (vj) ≥ k ≤ P Tr exp t k j=1 f (vj) ≥ exp (tk ) ≤ Ev 1 ••• ,v k Tr exp t k j=1 f (vj) exp (tk )</formula><p>.</p><p>(</p><formula xml:id="formula_48">)<label>3</label></formula><p>The second inequality follows Markov inequality.</p><formula xml:id="formula_49">Next to bound E v1••• ,v k Tr exp t k j=1 f (v j )</formula><p>. Using Theorem 4, we have:</p><formula xml:id="formula_50">log Tr exp t k j=1 f (vj) ≤ 4 π π 2 − π 2 log   Tr   k j=1 exp e iφ 2 tf (vj) 1 j=k exp e −iφ 2 tf (vj)     dµ(φ) ≤ 4 π log π 2 − π 2 Tr   k j=1 exp e iφ 2 tf (vj) 1 j=k exp e −iφ 2 tf (vj)   dµ(φ),</formula><p>where the second step follows by concavity of log function and the fact that µ(φ) is a probability distribution on [− π 2 , π 2 ]. This implies</p><formula xml:id="formula_51">Tr exp t k j=1 f (vj) ≤   π 2 − π 2 Tr   k j=1 exp e iφ 2 tf (vj) 1 j=k exp e −iφ 2 tf (vj)   dµ(φ)   4 π</formula><p>.</p><p>Note that x p ≤ d 1/p−1 x 1 for p ∈ (0, 1), choosing p = π/4 we have</p><formula xml:id="formula_52">Tr exp π 4 t k j=1 f (vj) 4 π ≤ d 4 π −1 Tr exp t k j=1 f (vj) .</formula><p>Combining the above two equations together, we have</p><formula xml:id="formula_53">Tr exp π 4 t k j=1 f (vj) ≤ d 1− π 4 π 2 − π 2 Tr   k j=1 exp e iφ 2 tf (vj) 1 j=k exp e −iφ 2 tf (vj)   dµ(φ). (4)</formula><p>Write e iφ = γ + ib with γ 2 + b 2 = |γ + ib| 2 = e iφ 2 = 1:</p><p>Lemma 1 (Analogous to Lemma 4.3 in <ref type="bibr" target="#b9">[10]</ref>). Let P be a regular Markov chain with state space [N ] with spectral expansion λ. Let f be a function f</p><formula xml:id="formula_54">: [N ] → R d×d such that (1) v∈[N ] π v f (v) = 0; (2) f (v) 2 ≤ 1 and f (v) is symmetric, v ∈ [N ]. Let (v 1 , • • • , v k ) denote a k-step random walk on P starting from a distribution φ on [N ]. Then for any t &gt; 0, γ ≥ 0, b &gt; 0 such that t 2 (γ 2 + b 2 ) ≤ 1 and t γ 2 + b 2 ≤ 1−λ 4λ , we have E   Tr   k j=1 exp tf (vj )(γ + ib) 2 1 j=k exp tf (vj )(γ − ib) 2     ≤ φ π d exp kt 2 (γ 2 + b 2 ) 1 + 8 1 − λ .</formula><p>Assuming the above lemma, we can complete the proof of the theorem as:</p><formula xml:id="formula_55">Ev 1 ••• ,v k Tr exp π 4 t k j=1 f (vj) ≤d 1− π 4 Ev 1 ••• ,v k   π 2 − π 2   Tr   k j=1 exp e iφ 2 tf (vj) 1 j=k exp e −iφ 2 tf (vj)     dµ(φ)   =d 1− π 4 π 2 − π 2 Ev 1 ••• ,v k   Tr   k j=1 exp e iφ 2 tf (vj) 1 j=k exp e −iφ 2 tf (vj)     dµ(φ) ≤d 1− π 4 π 2 − π 2 φ π d exp kt 2 e iφ 2 1 + 8 1 − λ dµ(φ) = φ π d 2− π 4 exp kt 2 1 + 8 1 − λ π 2 − π 2 dµ(φ) = φ π d 2− π 4 exp kt 2 1 + 8 1 − λ (5)</formula><p>where the first step follows Equation <ref type="formula">4</ref>, the second step follows by swapping E and , the third step follows by Lemma 1, the forth step follows by e iφ = 1, and the last step follows by µ is a probability distribution on</p><formula xml:id="formula_56">[− π 2 , π 2 ] so π 2 − π 2 dµ(φ) = 1</formula><p>Finally, putting it all together:</p><formula xml:id="formula_57">P λmax 1 k k j=1 f (vj) ≥ ≤ E Tr exp t k j=1 f (vj) exp (tk ) = E Tr exp π 4 4 π t k j=1 f (vj) exp (tk ) ≤ φ π d 2− π 4 exp k 4 π t 2 1 + 8 1−λ exp (tk ) = φ π d 2− π 4 exp 4 π 2 k 2 (1 − λ) 2 1 36 2 9 1 − λ − k (1 − λ)<label>36</label></formula><formula xml:id="formula_58">≤ φ π d 2 exp (−k 2 (1 − λ)/72).</formula><p>where the first step follows by Equation <ref type="formula" target="#formula_48">3</ref>, the second step follows by Equation <ref type="formula">5</ref>, the third step follows by choosing t = (1 − λ) /36. The only thing to be check is that</p><formula xml:id="formula_59">t = (1 − λ) /36 satisfies t γ 2 + b 2 = t ≤ 1−λ 4λ . Recall that &lt; 1 and λ ≤ 1, we have t = (1−λ) 36 ≤ 1−λ 4 ≤ 1−λ 4λ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Proof of Lemma 1</head><p>Lemma 1 (Analogous to Lemma 4.3 in <ref type="bibr" target="#b9">[10]</ref>). Let P be a regular Markov chain with state space [N ] with spectral expansion λ. Let f be a function f :</p><formula xml:id="formula_60">[N ] → R d×d such that (1) v∈[N ] π v f (v) = 0; (2) f (v) 2 ≤ 1 and f (v) is symmetric, v ∈ [N ]. Let (v 1 , • • • , v k ) denote a k-step random walk on P starting from a distribution φ on [N ]. Then for any t &gt; 0, γ ≥ 0, b &gt; 0 such that t 2 (γ 2 + b 2 ) ≤ 1 and t γ 2 + b 2 ≤ 1−λ 4λ , we have E   Tr   k j=1 exp tf (vj )(γ + ib) 2 1 j=k exp tf (vj )(γ − ib) 2     ≤ φ π d exp kt 2 (γ 2 + b 2 ) 1 + 8 1 − λ . Proof. Note that for A, B ∈ C d×d , (A ⊗ B) vec(I d ), vec(I d ) = Tr AB . By letting A = k j=1 exp tf (vj )(γ+ib) 2 and B = 1 j=k exp tf (vj )(γ−ib) 2 = k j=1 exp tf (vj )(γ−ib) 2</formula><p>. The trace term in LHS of Lemma 1 becomes</p><formula xml:id="formula_61">Tr   k j=1 exp tf (vj)(γ + ib) 2 1 j=k exp tf (vj)(γ − ib) 2   = k j=1 exp tf (vj)(γ + ib) 2 ⊗ k j=1 exp tf (vj)(γ − ib) 2 vec(I d ), vec(I d ) .<label>(6)</label></formula><p>By iteratively applying</p><formula xml:id="formula_62">(A ⊗ B)(C ⊗ D) = (AC) ⊗ (BD), we have k j=1 exp tf (vj)(γ + ib) 2 ⊗ k j=1 exp tf (vj)(γ − ib) 2 = k j=1 exp tf (vj)(γ + ib) 2 ⊗ exp tf (vj)(γ − ib) 2 k j=1 Mv j ,</formula><p>where we define</p><formula xml:id="formula_63">Mv j exp tf (vj)(γ + ib) 2 ⊗ exp tf (vj)(γ − ib) 2 .<label>(7)</label></formula><p>Plug it to the trace term, we have</p><formula xml:id="formula_64">Tr   k j=1 exp tf (vj)(γ + ib) 2 1 j=k exp tf (vj)(γ − ib) 2   = k j=1 Mv j vec(I d ), vec(I d ) .</formula><p>Next, taking expectation on Equation <ref type="formula" target="#formula_61">6</ref>gives</p><formula xml:id="formula_65">Ev 1 ,••• ,v k   Tr   k j=1 exp tf (vj)(γ + ib) 2 1 j=k exp tf (vj)(γ − ib) 2     =Ev 1 ,••• ,v k k j=1 Mv j vec(I d ), vec(I d ) = Ev 1 ,••• ,v k k j=1 Mv j vec(I d ), vec(I d ) .<label>(8)</label></formula><p>We turn to study</p><formula xml:id="formula_66">E v1,••• ,v k k j=1</formula><p>M vj , which is characterized by the following lemma:</p><formula xml:id="formula_67">Lemma 2. Let E diag(M 1 , M 2 , • • • , M N ) ∈ C N d 2 ×N d 2 and P P ⊗ I d 2 ∈ R N d 2 ×N d 2 . For a random walk (v 1 , • • • , v k ) such that v 1 is sampled from an arbitrary probability distribution φ on [N ], E v1,••• ,v k k j=1 M vj = (φ ⊗ I d 2 ) (E P ) k−1 E (1 ⊗ I d 2 )</formula><p>, where 1 is the all-ones vector.</p><p>Proof. (of Lemma 2) We always treat E P as a block matrix, s.t.,</p><formula xml:id="formula_68">E P =    M1 . . . MN       P1,1I d 2 • • • P1,N I d 2 . . . . . . . . . PN,1I d 2 • • • PN,N I d 2    =    P1,1M1 • • • P1,N M1 . . . . . . . . . PN,1MN • • • PN,N MN    .</formula><p>I.e., the (u, v)-th block of E P , denoted by</p><formula xml:id="formula_69">(E P ) u,v , is P u,v M u . Ev 1 ,••• ,v k k j=1 Mv j = v 1 ,••• ,v k φv 1 Pv 1 ,v 2 • • • Pv k−1 ,v k k j=1 Mv j = v 1 φv 1 v 2 (Pv 1 ,v 2 Mv 1 ) • • • v k Pv k−1 ,v k Mv k−1 Mv k = v 1 φv 1 v 2 (E P )v 1 ,v 2 v 3 (E P )v 2 ,v 3 • • • v k (E P E)v k−1 ,v k = v 1 φv 1 v k (E P ) k−1 E v 1 ,v k = (φ ⊗ I d 2 ) (E P ) k−1 E (1 ⊗ I d 2 )</formula><p>Given Lemma 2, Equation 8 becomes:</p><formula xml:id="formula_70">Ev 1 ,••• ,v k   Tr   k j=1 exp tf (vj)(γ + ib) 2 1 j=k exp tf (vj)(γ − ib) 2     = Ev 1 ,••• ,v k k j=1 Mv j vec(I d ), vec(I d ) = (φ ⊗ I d 2 ) (E P ) k−1 E (1 ⊗ I d 2 ) , vec(I d ) = (E P ) k−1 E (1 ⊗ I d 2 ) vec(I d ), (φ ⊗ I d 2 ) vec(I d ) = (E P ) k−1 E (1 ⊗ vec(I d )) , π ⊗ vec(I d )</formula><p>The third equality is due to x, Ay = A * x, y . The forth equality is by setting</p><formula xml:id="formula_71">C = 1 (scalar) in (A ⊗ B)(C ⊗ D) = (AC) ⊗ (BD). Then Ev 1 ,••• ,v k   Tr   k j=1 exp tf (vj)(γ + ib) 2 1 j=k exp tf (vj)(γ − ib) 2     = (E P ) k−1 E (1 ⊗ vec(I d )) , φ ⊗ vec(I d ) =(φ ⊗ vec(I d )) * (E P ) k−1 E (1 ⊗ vec(I d )) =(φ ⊗ vec(I d )) * (E P ) k−1 E P Π −1 π ⊗ (I d 2 I d 2 vec(I d )) =(φ ⊗ vec(I d )) * E P k Π −1 ⊗ I d 2 (π ⊗ vec(I d )) π ⊗ vec(I d ), z k π ,</formula><p>where we define z 0 = φ ⊗ vec(I d ) and</p><formula xml:id="formula_72">z k = z * 0 E P k * = z * k−1 E P * . Moreover, by Remark 2, we have π ⊗ vec(I d ) π = π π vec(I d ) 2 = √ d and z 0 π = φ ⊗ vec(I d ) π = φ π vec(I d ) 2 = φ π √ d Definition 2. Define linear subspace U = π ⊗ w, w ∈ C d 2 . Remark 3. {π ⊗ e i , i ∈ [d 2 ]</formula><p>} is an orthonormal basis of U. This is because π ⊗ e i , π ⊗ e j π = π, π π e i , e j = δ ij by Remark 1, where δ ij is the Kronecker delta.</p><p>Remark 4. Given x = y ⊗ w. The projection of x on to U is x = (1 * y)(π ⊗ w). This is because</p><formula xml:id="formula_73">x = d 2 i=1 y ⊗ w, π ⊗ ei π (π ⊗ ei) = d 2 i=1 y, π π w, ei (π ⊗ ei) = (1 * y)(π ⊗ w).</formula><p>We want to bound</p><formula xml:id="formula_74">π ⊗ vec(I d ), z k π = π ⊗ vec(I d ), z ⊥ k + z k π = π ⊗ vec(I d ), z k π ≤ π ⊗ vec(I d ) π z k π = √ d z k π .</formula><p>As z k can be expressed as recursively applying operator E and P on z 0 , we turn to analyze the effects of E and P operators. Next to show λ(P ) ≥ λ( P ). For ∀x ∈ C N d 2 such that x ⊥ U and x = 0, we can decompose it to be</p><formula xml:id="formula_75">x =     x1 x2 . . . x N d 2     =      x1 x d 2 +1</formula><p>. . .</p><formula xml:id="formula_76">x (N −1)d 2 +1      ⊗ e1 +      x2 x d 2 +2</formula><p>. . .</p><formula xml:id="formula_77">x (N −1)d 2 +2      ⊗ e2 + • • • +     x d 2 x 2d 2 . . . x N d 2     ⊗ e d 2 d 2 i=1 xi ⊗ ei,</formula><p>where we define</p><formula xml:id="formula_78">x i x i • • • x (N −1)d 2 +i for i ∈ [d 2 ]. We can observe that x i ⊥ π, i ∈ [d 2 ], because for ∀j ∈ [d 2 ], we have 0 = x, π⊗ej π = d 2 i=1 xi ⊗ ei, π ⊗ ej π = d 2 i=1 xi ⊗ ei, π ⊗ ej π = d 2 i=1 xi, π π ei, ej = xj, π π , which indicates x j ⊥ π, j ∈ [d 2 ]</formula><p>. Furthermore, we can also observe that x i ⊗ e i , i ∈ [d 2 ] is pairwise orthogonal. This is because for ∀i, j ∈ [d 2 ], x i ⊗ e i , x j ⊗ e j π = x i , x j π e i , e j = δ ij , which suggests us to use Pythagorean theorem such that x</p><formula xml:id="formula_79">2 π = d 2 i=1 x i ⊗ e i 2 π = d 2 i=1 x i π e i 2 2 .</formula><p>We can use similar way to decompose and analyze x * P * :</p><formula xml:id="formula_80">x * P * = P * x = d 2 i=1 (P * ⊗ I d 2 )(xi ⊗ ei) = d 2 i=1 (P * xi) ⊗ ei.</formula><p>where we can observe that (P * x i ) ⊗ e i , i ∈ [d 2 ] is pairwise orthogonal. This is because for ∀i, j ∈ [d 2 ], we have (P * x i ) ⊗ e i , (P * x j ) ⊗ e j π = P * x i , P * x j π e i , e j = δ ij . Again, applying Pythagorean theorem gives:</p><formula xml:id="formula_81">x * P * 2 π = d 2 i=1 (P * xi) ⊗ ei 2 π = d 2 i=1 (x * i P ) * 2 π ei 2 2 ≤ d 2 i=1 λ(P ) 2 xi 2 π ei 2 2 = λ(P ) 2   d 2 i=1 xi 2 π ei 2 2   = λ(P ) 2 x 2 π ,</formula><p>which indicate that for ∀x such that x ⊥ U and x = 0, we have (x * P ) * π x π ≤ λ(P ), or equivalently λ( P ) ≤ λ(P ).</p><p>Overall, we have shown both λ( P ) ≥ λ(P ) and λ( P ) ≤ λ(P ). We conclude λ( P ) = λ(P ). </p><formula xml:id="formula_82">* P Π −1 ⊗ I d 2 (π ⊗ w) = y * (P Π −1 π) ⊗ w = y * (Π −1 π) ⊗ w =y * Π −1 ⊗ I d 2 (π ⊗ w) = π ⊗ w, y π = 0.</formula><p>The third equality is due to P Π  3.</p><formula xml:id="formula_83">z ⊥ * E P * π ≤ α 3 z ⊥ π , where α 3 = exp (t ) − 1. 4. z ⊥ * E P * ⊥ π ≤ α 4 z ⊥ π , where α 4 = λ exp (t ).</formula><p>Proof. (of Lemma 5) We first show that, for z = y ⊗ w,</p><formula xml:id="formula_84">(z * E) * = E * z =    exp(tH * 1 ) . . . exp(tH * N )       y1w . . . yN w    =    y1 exp(tH * 1 )w . . . yN exp(tH * N )w    =    y1 exp(tH * 1 )w . . . 0    + • • • +    0 . . . yN exp(tH * N )w    = N i=1 yi (ei ⊗ (exp(tH * i )w)) .</formula><p>Due to the linearity of projection,</p><formula xml:id="formula_85">(z * E) * = N i=1 yi (ei ⊗ (exp(tH * i )w)) = N i=1 yi(1 * ei) (π ⊗ (exp(tH * i )w)) = π ⊗ N i=1 yi exp(tH * i )w ,<label>(9)</label></formula><p>where the second inequality follows by Remark 4.</p><p>Proof of Lemma 5, Part 1 Firstly We can bound</p><formula xml:id="formula_86">N i=1 π i exp(tH * i ) 2 by N i=1 πi exp(tH * i ) 2 = N i=1 πi exp(tHi) 2 = N i=1 πi +∞ k=0 t j H j i j! 2 = I + N i=1 πi +∞ j=2 t j H j i j! 2 ≤ 1 + N i=1 πi +∞ j=2 t j Hi j 2 j! ≤ 1 + N i=1 πi +∞ j=2 (t ) j j! = exp (t ) − t ,</formula><p>where the first step follows by A 2 = A * 2 , the second step follows by matrix exponential, the third step follows by i∈[N ] π i H i = 0, and the forth step follows by triangle inequality. Given the above bound, for any z which can be written as z = π ⊗ w for some w ∈ C d 2 , we have</p><formula xml:id="formula_87">z * E P * π = z * E * π = π ⊗ N i=1 πi exp(tH * i )w π = π π N i=1 πi exp(tH * i )w 2 ≤ π π N i=1 πi exp(tH * i ) 2 w 2 = N i=1 πi exp(tH * i ) 2 z π ≤ (exp (t ) − t ) z π ,</formula><p>where step one follows by Part 1 of Remark 5 and step two follows by Equation <ref type="formula" target="#formula_85">9</ref>.</p><p>Proof of Lemma 5, Part 2 For ∀z ∈ C N d 2 , we can write it as block matrix such that:</p><formula xml:id="formula_88">z =    z1 . . . zN    =    z1 . . . 0    + • • • +    0 . . . zN    = N i=1 ei ⊗ zi,</formula><p>where each z i ∈ C d 2 . Please note that above decomposition is pairwise orthogonal. Applying Pythagorean theorem gives z</p><formula xml:id="formula_89">2 π = N i=1 e i ⊗ z i 2 π = N i=1 e i 2 π z i 2 2 . Similarly, we can decompose (E * − I N d 2 )z such that (E * − I N d 2 )z =    exp(tH * 1 ) − I d 2 . . . exp(tH * N ) − I d 2       z1 . . . zN    =    (exp(tH * 1 ) − I d 2 )z1 . . . (exp(tH * N ) − I d 2 )zN    =    (exp(tH * 1 ) − I d 2 )z1 . . . 0    + • • • +    0 . . . (exp(tH * N ) − I d 2 )zN    = N i=1 ei ⊗ ((exp(tH * i ) − I d 2 )zi) .<label>(10)</label></formula><p>Note that above decomposition is pairwise orthogonal, too. Applying Pythagorean theorem gives</p><formula xml:id="formula_90">(E * − I N d 2 )z 2 π = N i=1 ei ⊗ ((exp(tH * i ) − I d 2 )zi) 2 π = N i=1 ei 2 π (exp(tH * i ) − I d 2 )zi 2 2 ≤ N i=1 ei 2 π exp(tH * i ) − I d 2 2 2 zi 2 2 ≤ max i∈[N ] exp(tH * i ) − I d 2 2 2 N i=1 ei 2 π zi 2 2 = max i∈[N ] exp(tH * i ) − I d 2 2 2 z 2 π = max i∈[N ] exp(tHi) − I d 2 2 2 z 2 π , which indicates (E * − I N d 2 )z π = max i∈[N ] exp(tHi) − I d 2 2 z π = max i∈[N ] +∞ j=1 t j H j i j! 2 z π ≤ +∞ j=1 t j j j! z π = (exp (t ) − 1) z π .</formula><p>Now we can formally prove Part 2 of Lemma 5 by:</p><formula xml:id="formula_91">z * E P * ⊥ π = E * z ⊥ * P * π ≤ λ E * z ⊥ π = λ E * z − z + z ⊥ π = λ (E * − I N d 2 ) z ⊥ π ≤ λ (E * − I N d 2 ) z π ≤ λ(exp (t ) − 1) z π .</formula><p>The first step follows by Part 2 of Remark 5, the second step follows by Part 1 on Lemma 4 and the forth step is due to z ⊥ = 0.</p><p>Proof of Lemma 5, Part 3 Note that</p><formula xml:id="formula_92">z ⊥ * E P * π = E * z ⊥ π = E * z ⊥ − z ⊥ + z ⊥ π = (E * − I N d 2 )z ⊥ π ≤ (E * − I N d 2 )z ⊥ π ≤ (exp (t ) − 1) z ⊥ π ,</formula><p>where the first step follows by Part 1 of Remark 5, the third step follows by z ⊥ = 0, and the last step follows by Part 2 of Lemma 4.</p><p>Proof of Lemma 5, Part 4 Simiar to Equation <ref type="formula" target="#formula_89">10</ref>, for ∀z ∈ C N d 2 , we can decompose E * z as</p><formula xml:id="formula_93">E * z = N i=1 e i ⊗ (exp(tH * i )z i ).</formula><p>This decomposition is pairwise orthogonal, too. Applying Pythagorean theorem gives</p><formula xml:id="formula_94">E * z 2 π = N i=1 ei ⊗ (exp(tH * i )zi) 2 π = N i=1 ei 2 π exp(tH * i )zi 2 2 ≤ N i=1 ei 2 π exp(tH * i ) 2 2 zi 2 2 ≤ max i∈[N ] exp(tH * i ) 2 2 N i=1 ei 2 π zi 2 2 ≤ max i∈[N ] exp tH * i 2 2 z 2 π ≤ exp (t ) 2 z 2 π</formula><p>which indicates E * z π ≤ exp (t ) z π . Now we can prove Part 4 of Lemma 5: Note that</p><formula xml:id="formula_95">z ⊥ * E P * ⊥ π = E * z ⊥ ⊥ * P * π ≤ λ E * z ⊥ ⊥ π ≤ λ E * z ⊥ π ≤ λ exp (t ) z ⊥ π .</formula><p>Recursive Analysis We now use Lemma 5 to analyze the evolution of z i and</p><formula xml:id="formula_96">z ⊥ i . Let H v f (v)(γ+ib) 2 ⊗ I d 2 + I d 2 ⊗ f (v)(γ−ib) 2</formula><p>in Lemma 5. We can see verify the following three facts: (1) Secondly, we can bound H v 2 by:</p><formula xml:id="formula_97">exp(tH v ) = M v ; (2) H v 2 is bounded (3) v∈[N ] π v H v = 0.</formula><formula xml:id="formula_98">Hv 2 ≤ f (v)(γ + ib) 2 ⊗ I d 2 2 + I d 2 ⊗ f (v)(γ − ib) 2 2 = f (v)(γ + ib) 2 2 I d 2 2 + I d 2 2 f (v)(γ − ib) 2</formula><p>where the first step follows by triangle inequality, the second step follows by the fact that A ⊗ B 2 = A 2 B 2 , the third step follows by I d 2 = 1 and f (v) 2 ≤ 1. We set = γ 2 + b 2 to satisfy the assumption in Lemma 5 that H v 2 ≤ . According to the conditions in Lemma 1, we know that t ≤ 1 and t ≤ 1−λ 4λ . Finally, we show that v∈[N ] π v H v = 0, because </p><formula xml:id="formula_99">z ⊥ i π = z * i−1 E P * ⊥ π ≤ z * i−1 E P * ⊥ π + z ⊥ * i−1 E P * ⊥ π ≤ α2 z i−1 π + α4 z ⊥ i−1 π ≤ (α2 + α2α4 + α2α 2 4 + • • • ) max 0≤j&lt;i z j π ≤ α2 1 − α4 max 0≤j&lt;i z j π</formula><p>Claim 5. z i π ≤ α 1 + α2α3 1−α4 max 0≤j&lt;i z j π .</p><p>Proof. Using Part 1 and Part 3 of Lemma 5 as well as Claim 4, we have</p><formula xml:id="formula_100">z i π = z * i−1 E P * π ≤ z * i−1 E P * π + z ⊥ * i−1 E P * π ≤ α1 z i−1 π + α3 z ⊥ i−1 π ≤ α1 z i−1 π + α3 α2 1 − α4 max 0≤j&lt;i−1 z j π ≤ α1 + α2α3 1 − α4 max 0≤j&lt;i z j π .</formula><p>Combining Claim 4 and Claim 5 gives where the second step is because exp (x) ≤ 1 + 2x, ∀x ∈ [0, 1] and t &lt; 1,</p><formula xml:id="formula_101">α4 = λ exp (t ) ≤ λ(1 + 2t ) ≤ 1 2 + 1 2 λ</formula><p>where the second step is because t &lt; 1, and the third step follows by t ≤ 1−λ 4λ . Overall, we have</p><formula xml:id="formula_102">α1 + α2α3 1 − α4 k ≤ 1 + t 2 (γ 2 + b 2 ) + 4λt 2 (γ 2 + b 2 ) 1 2 − 1 2 λ k ≤ exp kt 2 (γ 2 + b 2 ) 1 + 8 1 − λ .</formula><p>This completes our proof of Lemma 1. Proof. (of Theorem 1) Our strategy is to adopt complexification technique <ref type="bibr" target="#b7">[8]</ref>. For any d × d complex Hermitian matrix X, we may write X = Y + iZ, where Y and iZ are the real and imaginary parts of X, respectively. Moreover, the Hermitian property of X (i.e., X * = X) implies that (1) Y is real and symmetric (i.e., Y = Y ); (2) Z is real and skew symmetric (i.e., Z = −Z ). The eigenvalues of X can be found via a 2d × 2d real symmetric matrix H where the first step follows by the fact that 1 k k j=1 f (v j ) and 1 k k j=1 g(v j ) have the same eigenvalues (with different multiplicity), and the second step follows by Theorem 3. <ref type="foot" target="#foot_5">5</ref> The bound on λ min also follows similarly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1. 1 1 :</head><label>11</label><figDesc>Applications to Co-occurrence Matrices of Markov Chains Algorithm The Co-occurrence Matrix. Input sequence (v1, • • • , vL); window size T ; Output co-occurrence matrix C; C ← 0n×n; ; /* vi ∈ [n], i ∈ [L] */ for i = 1, 2, . . . , L − T do for r = 1, . . . , T do Cv i ,v i+r ← Cv i ,v i+r + 1/T ; Cv i+r ,v i ← Cv i+r ,v i + 1/T ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Claim 3 .</head><label>3</label><figDesc>(Claim 3.1 in Chung et al.<ref type="bibr" target="#b5">[6]</ref>) Let Q be a regular Markov chain with δ-mixing time τ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>AE[C] could be arbitrarily small by increasing the sampled trajectory length L. Specially, if we want the event C − AE[C] 2 ≥ happens with probability smaller than 1/n O(1) , we need L = O (τ (P ) + T ) (log n + log (τ (P ) + T )) / 2 + T . If we assume T = O(1), we can achieve L = O τ (P ) (log n + log τ (P )) / 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The convergence rate of co-occurrence matrices on Barbell graph, winning streak chain, BlogCatalog graph , and random graph (in log-log scale). The x-axis is the trajectory length L and the y-axis is the error C − AE[C] 2 . Each experiment contains 64 trials, and the error bar is presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>H 1 ,B. 2</head><label>12</label><figDesc>• • • H k be k Hermitian matrices, then for some probability distribution µ on [− π 2 , Proof of Theorem 3 Theorem 3 (A Real-Valued Version of Theorem 1). Let P be a regular Markov chain with state space [N ], stationary distribution π and spectral expansion λ. Let</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Definition 3 .</head><label>3</label><figDesc>The spectral expansion of P is defined as λ( P ) max x⊥U ,x =0 (x * P ) * π x π Lemma 3. λ(P ) = λ( P ).Proof. First show λ( P ) ≥ λ(P ). Suppose the maximizer of λ(P ) max y⊥π,y =0 (y * P ) * π y π is y ∈ C n , i.e., (y * P ) * π = λ(P ) y π . Construct x = y ⊗ o for arbitrary non-zero o ∈ C d 2 . Easy to check that x ⊥ U, because x, π ⊗ w π = y, π π o, w = 0, where the last equality is due to y ⊥ π. Then we can bound x * P * π such that x * P * π = P * x π = (P * ⊗ I d 2 )(y ⊗ o) π = (P * y) ⊗ o π = (y * P ) * π o 2 = λ(P ) y π o 2 = λ(P ) x π , which indicate for x = y ⊗o, (x * P ) * π x π = λ(P ). Taking maximum over all x gives λ( P ) ≥ λ(P ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Lemma 4 .</head><label>4</label><figDesc>(The effect of P operator) This lemma is a generalization of lemma 3.3 in [6]. 1. ∀y ∈ U, then y * P * = y. 2. ∀y ⊥ U, then y * P * ⊥ U, and y * P * π ≤ λ y π . Proof. First prove the Part 1 of lemma 4. ∀y = π ⊗ w ∈ U: y * P = (π * ⊗ w * ) (P ⊗ I d 2 ) = (π * P ) ⊗ (w * I d 2 ) = π * ⊗ w * = y * , where third equality is becase π is the stationary distribution. Next to prove Part 2 of lemma 4. Given y ⊥ U, want to show (y * P ) * ⊥ π ⊗ w, for every w ∈ C d 2 . It is true because π ⊗ w, (y * P ) * π =y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Remark 5 ..Lemma 5 .</head><label>55</label><figDesc>−1 π = P 1 = 1 = Π −1 π. Moreover, y * P * π ≤ λ y π is simply a re-statement of definition 3. Lemma 4 implies that ∀y ∈ C nd 2 1. y * P * = y * P * + y ⊥ * P * = y + 0 = y 2. y * P * ⊥ = y * P * ⊥ + y ⊥ * P * ⊥ = 0 + y ⊥ * P * = y ⊥ * P * (The effect of E operator) Given three parameters λ ∈ [0, 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Firstly, easy to 2 ⊗ I d 2 +</head><label>22</label><figDesc>see thatexp (tHv) = exp tf (v)(γ + ib) I d 2 ⊗ tf (v)(γ − ib) 2 = exp tf (v)(γ + ib) 2 ⊗ exp tf (v)(γ − ib) 2 = Mv,where the first step follows by definition of H i and the second step follows by the fact that exp(A ⊗I d + I d ⊗ B) = exp(A) ⊗ exp(B), and the last step follows by Equation7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 ⊗ I d 2 + 2 =</head><label>222</label><figDesc>I d 2 ⊗ f (v)(γ − ib)where the last step follows by v∈[N ] π v f (v) = 0. Claim 4. z ⊥ i π ≤ α2 1−α4 max 0≤j&lt;i z j π .Proof. Using Part 2 and Part 4 of Lemma 5, we have</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>z k π ≤ α1 + α2α3 1 −.Finally, we bound α 1 .</head><label>11</label><figDesc>α4 max 0≤j&lt;k z j π (because α1 + α2α3/(1 − α4) ≥ α1 ≥ 1 ) ≤ α1 + α2α3 1 − α4 k z 0 π = φ π √ d α1 + α2α3 1 − α4 k , which implies π ⊗ vec(I d ), z k π ≤ φ π d α1 + α2α3 1 − α4k The same as<ref type="bibr" target="#b9">[10]</ref>, we can bound α 1 , α 2 α 3 , α 4 by:α1 = exp (t ) − t ≤ 1 + t 2 2 = 1 + t 2 (γ 2 + b 2 ),andα2α3 = λ(exp (t ) − 1) 2 ≤ λ(2t ) 2 = 4λt 2 (γ 2 + b 2 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>B. 4 Theorem 1 (ff</head><label>41</label><figDesc>Proof of Theorem 1 Markov Chain Matrix Chernoff Bound). Let P be a regular Markov chain with state space [N ], stationary distribution π and spectral expansion λ.Let f : [N ] → C d×d be a function such that (1) ∀v ∈ [N ], f (v) is Hermitian and f (v) 2 ≤ 1; (2) v∈[N ] π v f (v) = 0. Let (v 1 , • • • , v k ) denote a k-step random walk on P starting from a distribution φ. Given ∈ (0, 1), (vj) ≥ ≤ 4 φ π d 2 exp −( 2 (1 − λ)k/72) (vj) ≤ − ≤ 4 φ π d 2 exp −( 2 (1 − λ)k/72) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>φ π d 2</head><label>2</label><figDesc>, where the symmetry of H follows by the symmetry of Y and skew-symmetry of Z. Note the fact that, if the eigenvalues (real) ofX are λ 1 , λ 2 , • • • λ d , then those of H are λ 1 , λ 1 , λ 2 , λ 2 , • • • , λ d , λ d . I.e., X and H have the same eigenvalues, but with different multiplicity.Using the above technique, we can formally prove Theorem 1. For any complex matrix function f : [N ] → C d×d in Theorem 1, we can separate its real and imaginary parts byf = f 1 + if 2 . Then we construct a real-valued matrix function g : [N ] → R 2d×2d s.t. ∀v ∈ [N ], g(v) = f1(v) f2(v) −f2(v) f1(v). According to the complexification technique, we know that (1) ∀v ∈[N ], g(v) is real symmetric and g(v) 2 = f (v) 2 ≤ 1; (2) v∈[N ] π v g(v) = 0. Then exp −( 2 (1 − λ)k/72) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>.31 26.99 33.85 39.12 41.28 41.58 41.82 .</figDesc><table><row><cell>Length L of DeepWalk</cell><cell>10 4</cell><cell>10 5</cell><cell>10 6</cell><cell>10 7</cell><cell>10 8</cell><cell>10 9</cell><cell>10 10</cell><cell>+∞</cell></row><row><cell>Micro-F1 (%)</cell><cell cols="2">15.21 18</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>3 Proof of Corollary 1Corollary 1 (Co-occurrence Matrices of HMMs). For a HMM with observable states y t ∈ Y and hidden states x t ∈ X , let P (y t |x t ) be the emission probability and P (x t+1 |x t ) be the hidden state transition probability. Given an L-step trajectory observations from the HMM, (y 1 , • • • , y L ), one needs a trajectory of length L = O(τ (log |Y| + log τ )/ 2 ) to achieve a co-occurrence matrix within error bound with high probability, where τ is the mixing time of the Markov chain on hidden states.</figDesc><table /><note>Proof. A HMM can be model by a Markov chain P on Y × X such that P (y t+1 , x t+1 |y t , x t ) = P (y t+1 |x t+1 )P (x t+1 |x t ). For the co-occurrence matrix of observable states, applying a similar proof like our Theorem 2 shows that one needs a trajectory of length O(τ (P )(log |Y|+log τ (P ))/ 2 ) to achieve error bound with high probability. Moreover, the mixing time τ (P ) is bounded by the mixing time of the Markov chain on the hidden state space (i.e., P (x t+1 |x t )).B Matrix Chernoff Bounds for Markov ChainsB.1 Preliminaries Kronecker Products If A is an M 1 × N 1 matrix and B is a M 2 × N 2 matrix, then the Kronecker product A ⊗ B is the M 2 M 1 × N 1 N 2 block matrix such that</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>], ≥ 0 and t &gt; 0. Let P be a regular Markov chain on state space [N ], with stationary distribution π and spectral expansion λ. Suppose each state i ∈ [N ] is assigned a matrix H i ∈ C d 2 ×d 2 s.t. H i 2 ≤ and i∈[N ] π i H i = 0.</figDesc><table /><note>Let P = P ⊗ I d 2 and E denotes the N d 2 × N d 2 block matrix where the i-th diagonal block is the matrix exp (tH i ), i.e., E = diag(exp (tH 1 ), • • • , exp (tH N )). Then for any ∀z ∈ C N d 2 , we have:1.z * E P * π ≤ α 1 z π , where α 1 = exp (t ) − t .2.z * E P * ⊥ π ≤ α 2 z π , where α 2 = λ(exp (t ) − 1).</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="34" xml:id="foot_0">34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">Please note that regular Markov chains are Markov chains which are aperiodic and irreducible, while an undirected regular graph is an undirected graph where each vertex has the same number of neighbors. In this work, the term "regular" may have different meanings depending on the context.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">The volume of a graph G is defined to be vol (G) i j Aij.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3">Please note that we need the Markov chain to be regular to make the mixing-time well-defined. For an ergodic Markov chain which could be periodic, the mixing time may be ill-defined.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_4">≤ γ 2 + b 2 ,</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5">The additional factor 4 is because the constructed g(v) has shape 2d × 2d.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>We thank Jian Li (IIIS, Tsinghua) and Shengyu Zhang (Tencent Quantum Lab) for motivating this work. Funding in direct support of this work: Jiezhong Qiu and Jie Tang were supported by the National Key R&amp;D Program of China (2018YFB1402600), NSFC for Distinguished Young Scholar (61825602), and NSFC (61836013). Richard Peng was partially supported by NSF grant CCF-1846218. There is no additional revenue related to this work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material of A Matrix Chernoff Bound for Markov Chains and Its Application to Co-occurrence Matrices A Convergence Rate of Co-occurrence Matrices</head><p>A.1 Proof of Claim 1 Claim 1 (Properties of Q). If P is a regular Markov chain, then Q satisfies:</p><p>3. ∀δ &gt; 0, the δ-mixing time of P and Q satisfies τ (Q) &lt; τ (P ) + T ;</p><p>4. ∃P with λ(P ) &lt; 1 s.t. the induced Q has λ(Q) = 1, i.e. Q may have zero spectral gap.</p><p>Proof. We prove the fours parts of this Claim one by one.</p><p>We know P is a regular Markov chain, so there exists N 2 ≥ T s.t., for any</p><p>Since this is true for any n 2 ≥ N 2 , we then claim that any state can be reached from any other state in any number of steps greater than or equal to a number</p><p>) is a random walk on P starting from distribution φ, so the probability we observe</p><p>) , i.e., X 1 is sampled from the distribution ρ. Then we study the transition probability from</p><p>which implies ρ σ = φ π .</p><p>Part 3 For any distribution y on S, define x ∈ R n such that</p><p>Easy to see x is a probability vector, since x is the marginal probability of y. For convenience, we</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Strong converse for identification via quantum channels</title>
		<author>
			<persName><forename type="first">Rudolf</forename><surname>Ahlswede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Item2vec: neural item embedding for collaborative filtering</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Barkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Koenigstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 26th International Workshop on Machine Learning for Signal Processing</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient sampling for gaussian graphical models via spectral sparsification</title>
		<author>
			<persName><forename type="first">Dehua</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT &apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Dehua</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Teng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03496</idno>
		<title level="m">Spectral sparsification of random-walk matrix polynomials</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations</title>
		<author>
			<persName><forename type="first">Herman</forename><surname>Chernoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annals of Mathematical Statistics</title>
				<imprint>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Chernoff-hoeffding bounds for markov chains: Generalized and simplified</title>
		<author>
			<persName><forename type="first">Kai-Min</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STACS&apos; 12</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">metapath2vec: Scalable representation learning for heterogeneous networks</title>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The eigenvalue problem for hermitian matrices with time reversal symmetry</title>
		<author>
			<persName><surname>Jj Dongarra</surname></persName>
		</author>
		<author>
			<persName><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><surname>Koelling</surname></persName>
		</author>
		<author>
			<persName><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra and its Applications</title>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Eigenvalue bounds on convergence to stationarity for nonreversible markov chains, with an application to the exclusion process. The annals of applied probability</title>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fill</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A matrix expander chernoff bound</title>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Tat Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC &apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A chernoff bound for random walks on expander graphs</title>
		<author>
			<persName><forename type="first">David</forename><surname>Gillman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS &apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Randomness-efficient sampling within nc</title>
		<author>
			<persName><forename type="first">D</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><surname>Healy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Complexity</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mixing time estimation in reversible markov chains from a single sample path</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aryeh</forename><surname>Kontorovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Peres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Wolfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Probability</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mixing time estimation in reversible markov chains from a single sample path</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aryeh</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Csaba</forename><surname>Kontorovich</surname></persName>
		</author>
		<author>
			<persName><surname>Szepesvári</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS &apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning hidden markov models from pairwise co-occurrences with application to topic modeling</title>
		<author>
			<persName><forename type="first">Kejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Sidiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The markov chain monte carlo method: an approach to approximate counting and integration. Approximation Algorithms for NP-hard problems</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Jerrum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alistair</forename><surname>Sinclair</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>PWS Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large deviation bounds for markov chains</title>
		<author>
			<persName><forename type="first">Nabil</forename><surname>Kahale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Combinatorics, Probability and Computing</title>
				<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A first course in stochastic processes</title>
		<author>
			<persName><surname>Samuel Karlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Academic press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Umesh Virkumar Vazirani, and Umesh Vazirani. An introduction to computational learning theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Kearns</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR &apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On learning parametric-output hmms</title>
		<author>
			<persName><forename type="first">Aryeh</forename><surname>Kontorovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boaz</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimal hoeffding bounds for discrete reversible markov chains</title>
		<author>
			<persName><forename type="first">François</forename><surname>Carlos A León</surname></persName>
		</author>
		<author>
			<persName><surname>Perron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Probability</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Markov chains and mixing times</title>
		<author>
			<persName><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><surname>Peres</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>American Mathematical Soc</publisher>
			<biblScope unit="volume">107</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural Word Embedding as Implicit Matrix Factorization</title>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS &apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Chernoff-type bound for finite markov chains</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Lezaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Applied Probability</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Factorization meets the item embedding: Regularizing matrix factorization with item co-occurrence</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaan</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In RecSys &apos;16</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Related pins at pinterest: The evolution of a real-world recommender system</title>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>David C Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Shiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">C</forename><surname>Kislyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhigang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast and consistent learning of hidden markov models by incorporating non-consecutive correlations</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mattila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Cristian R Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><surname>Wahlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;20</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Conductance and convergence of markov chains-a combinatorial treatment of expanders</title>
		<author>
			<persName><forename type="first">Milena</forename><surname>Mihail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS &apos;89</title>
				<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop &apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS&apos; 13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName><forename type="first">Tomáš</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL &apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Randomized algorithms</title>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Regret bounds for reinforcement learning via markov chain concentration</title>
		<author>
			<persName><forename type="first">Ronald</forename><surname>Ortner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP &apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM &apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS &apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A sharp tail bound for the expander random sampler</title>
		<author>
			<persName><forename type="first">Shravas</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oded</forename><surname>Regev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10205</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Random vectors in the isotropic position</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Rudelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Analysis</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Random walks on dynamic graphs: Mixing times, hitting times, and return probabilities</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Sauerwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Zanetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICALP 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An mdp-based recommender system</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Shani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><forename type="middle">I</forename><surname>Brafman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR &apos;05</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Multivariate trace inequalities. Communications in Mathematical Physics</title>
		<author>
			<persName><forename type="first">David</forename><surname>Sutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Berta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tomamichel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="page" from="37" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Line: Largescale information network embedding</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;15</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Relational learning via latent social dimensions</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;09</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Online algorithms for the multi-armed bandit problem with markovian rewards</title>
		<author>
			<persName><forename type="first">Cem</forename><surname>Tekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1675" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The natural language of actions</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Tennenholtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shie</forename><surname>Mannor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">An introduction to matrix concentration inequalities</title>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.01571</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Meta-prod2vec: Product embeddings using side-information for recommendation</title>
		<author>
			<persName><forename type="first">Flavian</forename><surname>Vasile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Smirnova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys &apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Tail estimates for sums of variables sampled by a random walk</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorics, Probability and Computing</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A randomness-efficient sampler for matrix-valued functions and applications</title>
		<author>
			<persName><forename type="first">Avi</forename><surname>Wigderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS&apos;05</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Estimating the mixing time of ergodic markov chains</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Wolfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aryeh</forename><surname>Kontorovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT &apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Rates of convergence for empirical processes of stationary mixing sequences. The Annals of Probability</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="94" to="116" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
