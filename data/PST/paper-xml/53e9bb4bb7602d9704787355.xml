<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convergence analysis and improvements of quantum-behaved particle swarm optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-01-11">11 January 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jun</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Advanced Control for Light Industry (Ministry of China)</orgName>
								<address>
									<addrLine>No. 1800, Lihu Avenue</addrLine>
									<postCode>214122</postCode>
									<settlement>Wuxi</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Xiaojun</forename><surname>Wu</surname></persName>
							<email>wu_xiaojun@yahoo.com.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Advanced Control for Light Industry (Ministry of China)</orgName>
								<address>
									<addrLine>No. 1800, Lihu Avenue</addrLine>
									<postCode>214122</postCode>
									<settlement>Wuxi</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vasile</forename><surname>Palade</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<addrLine>Parks Road</addrLine>
									<postCode>OX1 3QD</postCode>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Advanced Control for Light Industry (Ministry of China)</orgName>
								<address>
									<addrLine>No. 1800, Lihu Avenue</addrLine>
									<postCode>214122</postCode>
									<settlement>Wuxi</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Choi-Hong</forename><surname>Lai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing and Mathematical Sciences</orgName>
								<orgName type="institution">University of Greenwich</orgName>
								<address>
									<postCode>SE10 9LS</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenbo</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Advanced Control for Light Industry (Ministry of China)</orgName>
								<address>
									<addrLine>No. 1800, Lihu Avenue</addrLine>
									<postCode>214122</postCode>
									<settlement>Wuxi</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="laboratory">Key Laboratory of Advanced Control for Light Industry (Ministry of China)</orgName>
								<orgName type="institution">Jiangnan University</orgName>
								<address>
									<addrLine>No. 1800, Lihu Avenue</addrLine>
									<postCode>214122</postCode>
									<settlement>Wuxi</settlement>
									<region>Jiangsu</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Convergence analysis and improvements of quantum-behaved particle swarm optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-01-11">11 January 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">AD059B77CAE966E68DC98BDA3B771E60</idno>
					<idno type="DOI">10.1016/j.ins.2012.01.005</idno>
					<note type="submission">Received 14 August 2011 Received in revised form 18 December 2011 Accepted 3 January 2012</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Global Convergence Particle swarm Quantum behavior Time complexity Performance evaluation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Motivated by concepts in quantum mechanics and particle swarm optimization (PSO), quantum-behaved particle swarm optimization (QPSO) was proposed as a variant of PSO with better global search ability. Although it has been shown to perform well in finding optimal solutions for many optimization problems, there has so far been little theoretical analysis on its convergence and performance. This paper presents a convergence analysis and performance evaluation of the QPSO algorithm and it also proposes two variants of the QPSO algorithm. First, we investigate in detail the convergence of the QPSO algorithm on a probabilistic metric space and prove that the QPSO algorithm is a form of contraction mapping and can converge to the global optimum. This is the first time that the theory of probabilistic metric spaces has been employed to analyze a stochastic optimization algorithm. We provided a new definition for the convergence rate of a stochastic algorithm as well as definitions for three types of convergence according to the correlations between the convergence rate and the objective function values. With these definitions, the effectiveness of the QPSO is evaluated by computing and analyzing the time complexity and the convergence rate of the algorithm. Then, the QPSO with random mean best position (QPSO-RM) and the QPSO with ranking operator (QPSO-RO) are proposed as two improvements of the QPSO algorithm. Finally, some empirical studies on popular benchmark functions are performed in order to make a full performance evaluation and comparison between QPSO, QPSO-RM, QPSO-RO and other variants of PSO.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Particle swarm optimization (PSO), motivated by the social behavior of bird flocks or fish schooling, was first introduced by <ref type="bibr">Kennedy and</ref> Eberhart as a population-based optimization technique <ref type="bibr" target="#b30">[31]</ref>. In PSO, the potential solutions, called particles, fly through the problem space by following their own experiences and the current best particle. The PSO algorithm is comparable in performance with the well known Genetic Algorithm (GA) approach <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b49">50]</ref>, and has gained increasing popularity during the last decade due to its effectiveness in performing difficult optimization tasks.</p><p>In order to gain a deep insight into the mechanism of PSO, many theoretical analyses have been done on the algorithm. Most of these works focused on the behaviour of the single particle in PSO, analyzing the particle's trajectory or its stability by using deterministic or stochastic methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b83">84]</ref>. As for the algorithm itself, Van den Bergh <ref type="bibr" target="#b4">[5]</ref> proved that the canonical PSO is not a global search algorithm, even not a local one, according to the convergence criteria provided by Solis and Wets <ref type="bibr" target="#b73">[74]</ref>.</p><p>In addition to the theoretical analyses mentioned above, there has been a considerable amount of work done in developing the original version of PSO, through empirical simulations. Shi and Eberhart <ref type="bibr" target="#b67">[68]</ref> introduced the concept of inertia weight to the original PSO, in order to balance the local and global search during the optimization process. Clerc <ref type="bibr" target="#b9">[10]</ref> proposed an alternative version of PSO incorporating a parameter called constriction factor which should replace the restriction on velocities. Angeline <ref type="bibr" target="#b1">[2]</ref> introduced a tournament selection into PSO based on the particle's current fitness so that the properties that make some solutions superior were transferred directly to some of the less effective particles. This technique improved the performance of the PSO algorithm on some benchmark functions. Suganthan <ref type="bibr" target="#b75">[76]</ref> proposed a variant of the algorithm, with another general form of particle swarm optimization referred to as the local best (LBest) model. It divided the swarm into multiple ''neighborhoods'', where each neighborhood maintained its own local best solution. This approach was less prone to becoming trapped in local minima, but typically had slower convergence. Several researchers investigated other neighborhood topologies or adaptive topologies that may enhance the performance of PSO, in order to improve the exploration ability of the algorithm <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b53">54]</ref>.</p><p>Some researchers have attempted to experiment with various ways to simulate the particle trajectories by directly sampling, using a random number generator with a certain probability distribution <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b78">79]</ref>. For example, Sun et al., inspired by quantum mechanics and the trajectory analysis of PSO <ref type="bibr" target="#b10">[11]</ref>, used a strategy based on a quantum d potential well to sample around the previous best points <ref type="bibr" target="#b77">[78]</ref>, and later introduced the mean best position into the algorithm and proposed a new version of PSO, quantum-behaved particle swarm optimization (QPSO) <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b79">80]</ref>. The QPSO algorithm essentially falls into the family of bare-bones PSO <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, but uses double exponential distribution and an adaptive strategy to sample particle's positions. The iterative equation of QPSO is very different from that of PSO, and leads QPSO to be global convergent, as will be proved mathematically in this paper. Besides, unlike PSO, QPSO needs no velocity vectors for particles, and also has fewer parameters to adjust, making it easier to implement.</p><p>The QPSO algorithm has been shown to successfully solve a wide range of continuous optimization problems and many efficient strategies have been proposed to improve the algorithm <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b88">89]</ref>. While empirical evidence has shown that the algorithm works well, there has thus far been little insight into how it works. In this paper, we investigate the convergence issue of the QPSO and propose two improved versions of the algorithm as well. First, the global convergence of the QPSO is analyzed on the probability metric (PM) space established for the algorithm. We prove that the QPSO is a form of contraction mapping on the PM space and its orbit is probabilistic bounded, and, in turn, that the algorithm converges asymptotically to the global optimum, the unique fixed point. It is the first time that the theory of PM-sapces has been used to analyze a stochastic optimization algorithm. Next, the time complexity and its relationship to the behavior of a single particle are addressed, and a new definition of the convergence rate for a stochastic algorithm is presented, followed by semitheoretically evaluating the time complexity and convergence rate of the QPSO and PSO. Then, we propose two improved versions of QPSO, in order to enhance the search ability of the algorithm. One improved QPSO employs a random mean best position, so that the particle swarm can be diversified during the search and thus its global search ability is enhanced. The other incorporates a ranking operator to select a random particle whose personal best position replaces the global best position in order to guide the particle to escape the local optima. Finally, in order to further evaluate the efficiency of the QPSO algorithms and test the performance of the improved QPSO, we make a performance comparison with other variants of PSO by testing the algorithms on a set of problems from the CEC2005 benchmarks.</p><p>The remainder of the paper is structured as follows. In Section 2, the principles of QPSO are introduced. The global convergence analysis of QPSO is given in Section 3. The efficiency evaluation of the algorithms by time complexity and convergence rate is provided in Section 4. Section 5 presents the two proposed improved QPSO algorithms. Section 6 provides the experimental results on benchmark functions. Some concluding remarks are given in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Quantum-behaved particle swarm optimization</head><p>In the PSO with M individuals, each individual is treated as a volume-less particle in the N-dimensional space, with the current position vector and velocity vector of particle i at the nth iteration represented by X i;n ¼ X 1 i;n ; X 2 i;n ; . . . ; X N i;n and V i;n ¼ V 1 i;n ; V 2 i;n ; . . . ; V N i;n . The particle updates its position and velocity according to the following equations:</p><formula xml:id="formula_0">V j i;nþ1 ¼ V j i;n þ c 1 r j i;n P j i;n À X j i;n þ c 2 R j i;n G j n À X j i;n ;<label>ð1Þ</label></formula><formula xml:id="formula_1">X j i;nþ1 ¼ X j i;n þ V j i;nþ1 ;<label>ð2Þ</label></formula><p>for i = 1, 2, . . . , M; j = 1, 2, . . . , N, where c 1 and c 2 are called acceleration coefficients. Vector P i;n ¼ P </p><formula xml:id="formula_2">s:t: X 2 S # R N ;<label>ð3Þ</label></formula><p>where f(X) is an objective function continuous almost everywhere and S is the feasible space, then P i,n can be updated by</p><formula xml:id="formula_3">P i;n ¼ X i;n if f ðX i;n Þ &lt; f ðP i;nÀ1 Þ P i;nÀ1 if f ðX i;n Þ P f ðP i;nÀ1 Þ &amp; ;<label>ð4Þ</label></formula><p>and accordingly G n can be found by G n = P g,n , where g = argmin 16i6M [f(P i,n )].</p><p>The trajectory analysis in <ref type="bibr" target="#b10">[11]</ref> demonstrated the fact that the convergence of the PSO algorithm may be achieved if each particle converges to its local attractor, p i;n ¼ p 1 i;n ; p 2 i;n ; . . . p N i;n defined at the coordinates</p><formula xml:id="formula_4">p j i;n ¼ c 1 r j i;n P j i;n þ c 2 R j i;n G j n c 1 r j i;n þ c 2 R j i;n ; 1 6 j 6 N;<label>ð5Þ</label></formula><formula xml:id="formula_5">or p j i;n ¼ u j i;n P j i;n þ 1 À u j i;n G j n ;<label>ð6Þ</label></formula><formula xml:id="formula_6">where u j i;n ¼ c 1 r j i;n c 1 r j i;n þ c 2 R j i;n .</formula><p>with regard to the random numbers r j i;n and R j i;n in (1) and ( <ref type="formula" target="#formula_4">5</ref>). In PSO, the acceleration coefficients c 1 and c 2 are generally set to be equal, i.e., c 1 = c 2 , and thus u j i;n is a sequence of uniformly distributed random numbers on (0,1). As a result, Eq. ( <ref type="formula" target="#formula_5">6</ref>) can be restated as</p><formula xml:id="formula_7">p j i;n ¼ u j i;n P j i;n þ 1 À u j i;n G j n ; u j i;n $ Uð0; 1Þ:<label>ð7Þ</label></formula><p>The above equation indicates that p i,n , the stochastic attractor of particle i, lies in the hyper-rectangle with P i,n and G n being the two ends of its diagonal so that it moves following P i,n and G n . In fact, as the particles are converging to their own local attractors, their current position, personal best positions, local attractors and the global best positions are all converging to one point, leading the PSO algorithm to converge. From the point view of Newtonian dynamics, in the process of convergence, the particle moves around and careens toward point p i,n with its kinetic energy (or velocity) declining to zero, like a returning satellite orbiting the earth. As such, the particle in PSO can be considered as the one flying in an attraction potential field centered at point p i,n in Newtonian space. It has to be in a bound state for the sake of avoiding explosion and guaranteeing convergence. If these conditions are generalized to the case that the particle in PSO moves in quantum space, it is also indispensable that the particle should move in a quantum potential field to ensure the bound state. The bound state in quantum space, however, is entirely different from that in Newtonian space, which may lead to a very different form of PSO. This is the motivation of the QPSO algorithm <ref type="bibr" target="#b77">[78]</ref>.</p><p>In QPSO, each single particle is treated as a spin-less one moving in quantum space. Thus the state of the particle is characterized by a wave function w, where jwj 2 is the probability density function of its position. Inspired by the convergence analysis of the particle in PSO, we assume that, at the nth iteration, particle i flies in the N-dimensional quantum space with a d potential well centered at p j i;n on the jth dimension (1 6 j 6 N). Let Y j i;nþ1 ¼ X j i;nþ1 À p j i;n , then we can obtain the normalized wave function at iteration n+1 as;</p><formula xml:id="formula_8">w Y j i;nþ1 ¼ 1 ffiffiffiffiffiffi ffi L j i;n q exp ÀY j i;nþ1 =L j i;n ;<label>ð8Þ</label></formula><p>which satisfies the bound condition that w Y j i;nþ1 ! 0 as Y j i;nþ1 ! 1. L j i;n is the characteristic length of the wave function. By the definition of wave function, the probability density function is given by</p><formula xml:id="formula_9">Q Y j i;nþ1 ¼ w Y j i;nþ1 2 ¼ 1 L j i;n exp À2Y j i;nþ1 =L j i;n ;<label>ð9Þ</label></formula><p>and thus the probability distribution function is</p><formula xml:id="formula_10">F Y j i;nþ1 ¼ 1 À exp À2Y j i;nþ1 =L j i;n :<label>ð10Þ</label></formula><p>Using the Monte Carlo method, we can measure the jth component of position of particle i at the (n + 1)th iteration by</p><formula xml:id="formula_11">X j i;nþ1 ¼ p j i;n AE L j i;n 2 ln 1=u j i;nþ1 ; u j i;nþ1 $ Uð0; 1Þ;<label>ð11Þ</label></formula><p>where u j i;nþ1 is a sequence of random numbers uniformly distributed on (0, 1). Two approaches of determining the value of L j i;n were proposed in <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79]</ref>, respectively:</p><formula xml:id="formula_12">L j i;n ¼ 2a X j i;n À p j i;n ;<label>ð12Þ</label></formula><p>and</p><formula xml:id="formula_13">L j i;n ¼ 2a X j i;n À C j n ;<label>ð13Þ</label></formula><p>where</p><formula xml:id="formula_14">C n ¼ C 1 n ; C 2 n ; . . . ; C N</formula><p>n is called mean best (mbest) position defined by the average of the pbest positions of all particles, i.e., C j n ¼ ð1=MÞ P M i¼1 P j i;n ð1 6 j 6 NÞ. These two strategies result in two versions of the QPSO algorithm. To distinguish them, we denote the QPSO with the former approach as QPSO-Type 1 and the QPSO with the latter one as QPSO-Type 2. Therefore, the position of the particle in either type of QPSO is updated according to the following two equations respectively:</p><formula xml:id="formula_15">X j i;nþ1 ¼ p j i;n AE a X j i;n À p j i;n ln 1=u j i;nþ1 ;<label>ð14Þ</label></formula><formula xml:id="formula_16">or X j i;nþ1 ¼ p j i;n AE a X j i;n À C j n ln 1=u j i;nþ1 :<label>ð15Þ</label></formula><p>The parameter a in Eqs. ( <ref type="formula" target="#formula_13">13</ref>)-( <ref type="formula" target="#formula_16">15</ref>) is known as the contraction-expansion (CE) coefficient, which can be adjusted to balance the local and global search of the algorithm during the optimization process. The search procedure of the algorithm is outlined in Fig. <ref type="figure">1</ref>. Note that randi(Á), i = 1, 2, 3, is used to denote random numbers generated uniformly and distributed on (0, 1).</p><p>Fig. <ref type="figure">1</ref>. The procedure of the QPSO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Convergence of the QPSO algorithm</head><p>In this section, the global convergence of the QPSO is analyzed by establishing a probabilistic metric space (PM-space) for the algorithm, in which we prove that the algorithm is a form of contraction mapping and its orbit is probabilistic bounded. Before the convergence analysis, we give an introduction to the PM-space and some related work, and provide basic concepts of a PM-space and the fixed point theorem on the PM-space that are used in the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">An introduction to PM-spaces and some related work</head><p>The idea of a PM-space was first introduced by Menger as a generalization of ordinary metric spaces <ref type="bibr" target="#b46">[47]</ref>. In this theory, the notion of distance has a probabilistic nature, that is, the distance between two points x and y is represented by a distribution function F x,y , and for any positive number t, the value F x,y (t) is interpreted as the probability that the distance from x to y is less than t. Such a probabilistic generalization is well adapted for the investigation of physical events, and has also important applications in nonlinear analysis <ref type="bibr" target="#b8">[9]</ref>.</p><p>The theory of PM-spaces was brought to its present state by Schweizer and Sklar <ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref><ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref>, Šeerstnev <ref type="bibr" target="#b66">[67]</ref>, Tardiff <ref type="bibr" target="#b81">[82]</ref> and Thorp <ref type="bibr" target="#b82">[83]</ref>. There are also many others studying on PM-spaces <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b65">66]</ref>. For a clear and detailed history, as well as for the motivations behind the introduction of PM-spaces, the reader should refer to the book by Schweizer and Sklar <ref type="bibr" target="#b62">[63]</ref>.</p><p>The convergence theorems for obtaining the stable points, i.e., the fixed point theorems for contraction mappings, have been always an active area of research since 1922, with the celebrated Banach contraction fixed point theorem. Seghal <ref type="bibr" target="#b64">[65]</ref> initiated the study of the fixed point theorems in PM-spaces. Subsequently, some other fixed point theorems for contraction mappings have been proved in PM-spaces <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref>. In <ref type="bibr" target="#b51">[52]</ref>, the authors established global output convergence for a recurrent neural network (RNN) with continuous and monotone non-decreasing activation functions, by using the fixed point theorems in PM-spaces. They provided the sufficient conditions to guarantee the global output convergence of this class of neural networks, which are very useful in the design of RNNs. However, since the output of a RNN is not probabilistic of nature, they practically employed the fixed point theorems in PM-spaces to analyze the convergence of the sequence of non-random variables. That is, they essentially specialized the fixed point theorems in PM-spaces into the ones in ordinary metric spaces.</p><p>In the remaining part of this section, we analyze the convergence of the QPSO algorithm, whose output, i.e. the fitness value of the global best position, is a sequence of random variables. Therefore the theory of PM-spaces is very suitable for the analysis of the algorithm. To our knowledge, it is the first time that the fix point theorem of a stochastic algorithm has ever been proved. Although this section focuses on the QPSO algorithm, the established theoretical framework can be used as a general-purpose analysis tool for the convergence of any stochastic optimization algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Preliminaries</head><p>Definition 1. Denote the set of all real numbers as R, and the set of all non-negative real numbers as R + . The mapping f: R ? R + is a called distribution function if it is non-decreasing, left continuous and inf t2R f(t) = 0, sup t2R f(t) = 1.</p><p>We denote the set of all distribution functions by D, and H(t) is the specific distribution function defined by</p><formula xml:id="formula_17">HðtÞ ¼ 1 t &gt; 0 0 t 6 0 &amp; :<label>ð16Þ</label></formula><p>Definition 2. A probabilistic metric space (briefly, a PM-space) is an ordered pair (E, F), where E is a nonempty set and F is a mapping of E Â E into D. The value of F at (x, y) 2 E Â E is denoted by F x,y , and F x,y (t) represents the value of F x,y at t. The functions F x,y (x,y 2 E) are assumed to satisfy the following conditions:</p><p>(PM-1) F x,y (0) = 0; (PM-2) F x,y (t) = H(t) for all t &gt; 0 if and only if x = y;</p><p>(PM-3) F x,y = F y,x ;</p><p>(PM-4) F x,y (t 1 ) = 1 and F y,z (t 2 ) = 1 imply F x,z (t 1 + t 2 ) = 1, "x, y, z 2 E.</p><p>The value F x,y (t) of F x,y at t 2 R can be interpreted as the probability that the distance between x and y is less than t. It can be easily verified that</p><formula xml:id="formula_18">D 1 (a, b) = max{a + b À 1, 0) is a t-norm.</formula><p>Definition 4. A Menger probabilistic metric space (briefly a Menger space) is a triplet (E, F, D), where (E, F) is a PM-space and t-norm D is such that Menger's triangle inequality (PM-4)' F x,z (t 1 + t 2 ) P D(F x,y (t 1 ),F y,z (t 2 )) holds for all x, y, z 2 E and for all t 1 P 0, t 2 P 0.</p><p>If (E,F,D) is a Menger space with a continuous t-norm, then it is a Hausdoff Space with the topology T introduced by the family {U y (e, k):y 2 E,k &gt; 0}, where U y ðe; kÞ ¼ fx 2 E; F x;y ðeÞ &gt; 1 À k; e &gt; 0; k &gt; 0g ð 17Þ is called an (e, k)-neighborhood of y 2 E. Hence we can introduce the following concepts into (E, F, D).</p><p>Definition 5. Let {x n } a sequence in a Menger space (E, F, D), where D is continuous. The sequence {x n } converges to</p><formula xml:id="formula_19">x ⁄ 2 E in T ðx n ! T x Ã Þ, if</formula><p>for every e &gt; 0 and k &gt; 0, there exists a positive integer K = K(e, k) such that F xn;xÃ ðeÞ &gt; 1 À k, whenever n P K.</p><p>The sequence {x n } is called a T -Cauchy Sequence in E, if for every e &gt; 0 and k &gt; 0, there exists a positive integer</p><formula xml:id="formula_20">K = K(e, k) such that F xn;xm ðeÞ &gt; 1 À k, whenever m, n P K. A Menger space (E, F, D) is called T -Complete if every T -Cauchy</formula><p>Sequence in E converges in T to a point in E. In <ref type="bibr" target="#b62">[63]</ref>, it was proved that every <ref type="bibr">Menger</ref>  . For the contraction mapping in Definition 7, we have the following fixed point theorem.</p><p>Theorem 1. Let a self-mapping T: (E, F, D) ? (E, F, D) be the contraction mapping in Definition 7. If for every x 2 E, O T (x; 0, 1) is probabilistic bounded, then there exists a unique common fixed point x ⁄ in E for T, and for every x 0 2 E, the iterative sequence {T n x 0 } converges to x ⁄ in T (see the proof in Appendix A). Minimize f ðXÞ;</p><formula xml:id="formula_21">s:t: X 2 S # R N ;<label>ð19Þ</label></formula><p>where f is a real-valued function defined over region S and continuous almost everywhere, and S is a compact subset of a Ndimensional Euclidean space R N . Let V represent the range of f over S, and thus</p><formula xml:id="formula_22">V &amp; R. Denote f ⁄ = min X2S {f(X)}.</formula><p>Theorem 2. Consider the ordered pair (V, F), where F is a mapping of V Â V into D. For every x, y 2 V, if the distribution function F x,y is defined by F x,y (t) = P{jx À yj &lt; t}, "t 2 R, then (V, F) is a PM-space (see the proof in Appendix A).</p><p>Theorem 3. The triplet (V, F, D) is a Menger space, where D = D 1 (see the proof in Appendix A). (V, F, D) is a Menger space with continuous t-norm D 1 , and also is a Hausdoff space of the topology T introduced by the family {U y (e, k): y 2 V, k &gt; 0}, where U y (e, k) = {x 2 V, F x,y (e) &gt; 1 À k, e, k &gt; 0}, and consequently is T -Complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">The fixed point theorem of the QPSO algorithm</head><p>We regard the QPSO as a mapping denoted by T, and therefore T is a self-mapping of the Menger space (V, F, D). When n = 0, the global best position G 0 is generated by the initialization of QPSO. Let f 0 = f(G 0 ), and thus f 0 2 V. By a series of iterations of the algorithm, we can obtain a sequence of global best position {G n ,n P 1}, and a sequence of the corresponding non-increasing function values {f n , n P 1}, where f n = f(G n ). We can consider {f n , n P 1} as a sequence of points generated by T in (V, F, D), i.e. f n = T n f 0 and f n 2 V. Denoting the orbit generated by T at f 0 2 V by O T (f 0 ; 0, 1), we have</p><formula xml:id="formula_23">O T ðf 0 ; 0; 1Þ ¼ ff n ¼ T n f 0 g 1 n¼0 .</formula><p>The following theorem proves that T is a contraction mapping of (V, F, D).</p><p>Theorem 4. The mapping T is a contraction mapping of the Menger space (V, F, D) (see the proof in Appendix A).</p><p>Theorem 5. f ⁄ is the unique fixed point in V such that for every f 0 2 V, the iterative sequence {T n f 0 } converges to f ⁄ (see the proof in Appendix A).</p><p>Define the optimality region of problem <ref type="bibr" target="#b2">(3)</ref> by</p><formula xml:id="formula_24">V e = V(e) = {f: f 2 V, f À f ⁄ &lt; e}. For QPSO in(V, F, D), the theorem below</formula><p>shows the equivalence between the convergence in T and the convergence in probability.</p><p>Theorem 6. The sequence of function values {f n , n P 0} generated by the QPSO converges to f ⁄ in probability (see the proof in Appendix A).</p><p>The above convergence analysis on a PM-space can be used to analyze other random optimization algorithms. Essentially, any global convergent algorithm is a contraction mapping defined by Definition 7, whose orbit is probabilistic bounded. The PSO algorithm is not global convergent, since it does not satisfy the contractive condition of Definition 7, even though its orbit is probabilistic bounded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Time complexity and convergence rate of the QPSO algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Measure of time complexity</head><p>Convergence is an important characteristic of a stochastic optimization algorithm. Nevertheless, it is not sufficient to evaluate the efficiency of the algorithm by comparison to others. The most promising and tractable approach is the study of the distribution of the number of steps required to reach the optimality region V(e), more specifically by comparing the expected number of steps and higher moments of this distribution. The number of steps required to reach V(e) is defined by K(e) = inf{njf n 2 V e }. The expected value (time complexity) and the variance of K(e), if they exist, can be computed by</p><formula xml:id="formula_25">E½KðeÞ ¼ X 1 n¼0 na n ;<label>ð20Þ</label></formula><formula xml:id="formula_26">Var½KðeÞ ¼ E½K 2 ðeÞ À fE½KðeÞg 2 ¼ X 1 n¼0 n 2 a n À X 1 n¼0 na n ! 2 ;<label>ð21Þ</label></formula><p>where a n = a n (e) with a n (t) defined by (A13), that is</p><formula xml:id="formula_27">a n ¼ PfKðeÞ ¼ ng ¼ Pff 0 2 V c e ; f 1 2 V c e ; f 2 2 V c e ; . . . ; f nÀ1 2 V c e ; f n 2 V e g ¼ a n ðeÞ:<label>ð22Þ</label></formula><p>Referring to (A14), we can also find that</p><formula xml:id="formula_28">F fn;fÃ ðeÞ ¼ Pff n 2 V e g ¼ X n i¼0 a n :<label>ð23Þ</label></formula><p>Thus, it is required that P 1 i¼0 a n ¼ 1 so that the algorithm can be global convergent. It is evident that the existence of E[K(e)] relies on the convergence of P 1 n¼0 na n . Generally, for most of the stochastic optimization algorithms, particularly population-based random search techniques, it is far more difficult to compute all a n analytically than to prove the global convergence of the algorithm. To evaluate E[K(e)] and Var[K(e)], researchers have either undertaken theoretical analysis relying on specific situations or provided the numerical results on some specific functions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b86">87]</ref>.</p><p>Now we focus our attention on the problem of how the behavior of the individual particle influences the convergence of QPSO, from the perspective of time complexity. It has been shown that for both types of QPSO, setting a 6 e c % 1.781 (where c % 0.577215665 is called Euler constant) can prevent the particle from exploding <ref type="bibr" target="#b80">[81]</ref>. As can be seen, however, the proof of global convergence of QPSO does not involve the behavior of the individual particle. It is true that the algorithm is global convergent even when the particle diverges (i.e. when a &gt; e c ). The global convergence of QPSO only requires that P 1 i¼0 a n ¼ 1 or g n (e) &gt; 0 for all n, according to (A14). When the particle diverges, for every e &gt; 0, although g n (e) declines constantly, F fn;fÃ ðeÞ ¼ P n i¼0 a n ðeÞ ¼ 1 À Q n i¼1 ½1 À g i ðeÞ may also converge to 1 since 0 &lt; g n (e) &lt; 1 for all n &lt; 1. The series P 1 n¼0 na n , however, may diverge in such a case. Therefore, we find that the divergence of the particle may also guarantee the global convergence of the algorithm, but can result in infinite complexity in general. On the other hand, when the particle converges or is bounded, g n (e) does not decline constantly but may even increase during the search. As a result, for certain e &gt; 0, P 1 n¼0 na n can converge, which implies that the algorithm has finite time complexity. Thus, to make QPSO converge globally with finite time complexity, we have to set a 6 e c to ensure the convergence or boundedness of the particle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">The convergence rate</head><p>Another measure used to evaluate the efficiency of the algorithm is its convergence rate. The mathematical complexity of analyzing the convergence rate of a population-based random optimization algorithm, however, is no less significant than that of computing the expected value or variance of K(e). Although some work has been done on the issue of the convergence rate <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b84">85]</ref>, it is apparently an open problem for arbitrary objective functions. In these literatures, the convergence rate of an algorithm is defined as the rate of change of Euclidean distance from the current solution to the optimal point. This definition can indeed measure the convergence speed of the algorithm intuitively and effectively when the optimization problem is unimodal. However, if the problem is multimodal, it may fail to evaluate the efficiency of the algorithm properly when the current solution flies away from the optimal point but its fitness value improves. Particularly, when the objective function has many optimal solutions in the given search domain, such a definition for the convergence rate is unfeasible since we cannot determine which optimal point is used as the reference point, to which the distance from current solution should be computed.</p><p>The definition proposed in this work differs from the above one in that it measures the convergence rate by the rate of change of the difference between the current best fitness value and the optimal value, not by that of the difference between the current best point and the optimal solution. More precisely, the convergence rate at the nth step c n 2 (0, 1) by the conditional expectation of the change rate of the difference between the current best fitness value and the minimum fitness value, that is</p><formula xml:id="formula_29">c n ¼ E jf n À f Ã j jf nÀ1 À f Ã j f nÀ1 ! ¼ E f n À f Ã f nÀ1 À f Ã f nÀ1 ! :<label>ð24Þ</label></formula><p>Thus we have</p><formula xml:id="formula_30">E½ðf n À f Ã Þjf nÀ1 ¼ c n ðf nÀ1 À f Ã Þ:<label>ð25Þ</label></formula><p>The advantage of this kind of definition for the convergence rate lies in that is can be applied to arbitrary objective functions. It can be observed from ( <ref type="formula" target="#formula_29">24</ref>) that with given f n À 1 , smaller c n 2 (0, 1) results from smaller f n or jf n À f ⁄ j, implying rapider decreasing of the f n , i.e. the faster convergence speed of the algorithm. Let e n = E(f n À f ⁄ ) be the expected error at iteration n P 0. If there exists a constant c 2 (0, 1) called expected convergence rate, then e n = c n e 0 for every n P 0, which, by elementary transformation, leads to</p><formula xml:id="formula_31">n ¼ log 10 ðe n =e 0 Þ log 10 ðcÞ ¼ À H log 10 ðcÞ ;<label>ð26Þ</label></formula><p>where H &gt; 0 denotes the orders of magnitude the error is to be decreased. If H is fixed, then the time n that is required to decrease the error by H orders of magnitude decreases as c decreases toward zero. Since the expected error after K(e) iterations is approximately e, we therefore have e K(e) = c K(e) e 0 % e, from which we can evaluate K(e) approximately by</p><formula xml:id="formula_32">KðeÞ % log 10 ðe=e 0 Þ log 10 ðcÞ ¼ log 10 ðe=E½f 0 À f Ã Þ log 10 ðcÞ ¼ log 10 fe=½Eðf 0 Þ À f Ã g logðcÞ ¼ ÀH 0 logðcÞ ;<label>ð27Þ</label></formula><p>where H 0 = log 10 ((E[f 0 ] À f ⁄ )/e) &gt; 0. The following theorem states the relationship between c and c n . Since the sequence {f n À f ⁄ , n &gt; 0} decreases with n, the negatively correlation between {c n ,n &gt; 0} and {f n À f ⁄ , n &gt; 0} implies that c n increases or the convergence velocity decreases as f n decreases. In this case, the convergence of f n is called sub-linear. When {c n , n &gt; 0} and {f n À f ⁄ , n &gt; 0} are positively correlated, c n decreases as f n decreases, which means that the convergence accelerates as f n decreases, and thus we call that f n is of super-linear convergence. When {c n ,n &gt; 0} and {f n À f ⁄ , n &gt; 0} are uncorrelated, c ¼ c for all n &gt; 0, implying that c n = c, and the convergence of f n is known as linear.</p><formula xml:id="formula_33">Theorem 7. Let c ¼ Q n i¼1 c i À Á 1=n , where c i ¼ Eðc i Þ. If {c n ,n &gt; 0} and {f n À f ⁄ , n &gt; 0}</formula><p>Linear convergence may occur in some idealized situations. For Pure Adaptive Search (PAS) <ref type="bibr" target="#b87">[88]</ref>, if the objective function is the Sphere function f(X) = X T Á X, it may achieve linear convergence. Taking a 2-dimensional problem for instance, we have</p><formula xml:id="formula_34">E = [f n À f ⁄ jf n À 1 ] = E[f n jf n À 1 ] = E[kX n k 2 jkX nÀ1 k 2 ]. Denoting r 2 nÀ1 ¼ kX nÀ1 k 2 and considering that X n is distributed uniformly over S n ¼ X : kXk 2 6 r 2 nÀ1 n o , we obtain E ¼ ½f n À f Ã jf nÀ1 ¼ 1 pr 2 nÀ1 Z Z Sn r 2 dX ¼ 1 pr 2 nÀ1 Z 2p 0 dh Z r nÀ1 0 r 2 Á r dr ¼ r 2 nÀ1 2 ¼ kX nÀ1 k 2 2 ¼ f nÀ1 À 0 2 ¼ f nÀ1 À f Ã 2 :</formula><p>Thus it can be find that c n = 0.5 for all n &gt; 0 and c = c n = 0.5, implying that linear convergence is achieved by the PAS.</p><p>Most of practical stochastic algorithms, however, run in sub-linear convergence in general. If we are to evaluate an algorithm in terms of the convergence rate, we can calculate the value of c ¼ Q n i¼1 c i À Á 1=n and compare it with that of other algorithms, and besides, we may also compute the value of j c À cj to measure the ''linearity'' of its convergence. However, for most of the stochastic algorithms including QPSO, analytical calculation of their convergence rates is no less difficult than that of their time complexities. Therefore, in the remainder part of this section we turn our attention to the numerical results of convergence rate and time complexity on some specific problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.3.</head><p>Testing the time complexity and convergence rate of the QSPO algorithm 4.3.1. Evaluation of time complexity Now, as it is hard to compute analytically the time complexity and convergence rate of QPSO. In this subsection, we test these convergence properties of QPSO empirically, using the Sphere function f(X) = X T Á X, which has minimum value at zero. The Sphere function is unimodal and is a special instance from the class of quadratic functions with positive definite Hessian matrix. It has been generally used to test the convergence properties of a random search algorithm <ref type="bibr" target="#b73">[74]</ref>. In our experiment, the initialization scope used by each algorithm for the function is [À10, 10] N , where N is the dimension of the problem.</p><p>For evaluating the convergence of the algorithms, the first thing we require is a fair time measurement. The number of iterations cannot be accepted as a time measure since the algorithms perform different amount of work in their inner loops and also they have different population sizes. We have used the number of fitness function (objective function) evaluations as a measure of time. The advantage of measuring complexity by counting the function evaluations is that there is a strong relationship between this measure and the processor time as the function complexity increases. Therefore, the subscript m is used to denote the number of fitness function values, and the relationship m = (n À 1)M + i holds, where n is the number of iterations, M is the population size and i is the particle's index.</p><p>We performed two sets of experiments to evaluate the time complexity and convergence rate of the QPSO algorithm, respectively. The QPSO-Type 1, QPSO-Type 2 and PSO with constriction factor <ref type="bibr" target="#b9">[10]</ref> were tested for the comparison. To test the time complexity, we set the optimality region as V(e) = V(10 À4 ) = {f: f 2 V, f À f ⁄ &lt; 10 À4 } and recorded K(e), the number of function evaluations when the tested algorithm first reached the region. Each algorithm ran 50 times on the Sphere function with a certain dimension. We figured out some statistical results including the mean number of function evaluations ðKðeÞÞ, the standard deviation of K(e) (r K(e) ), the standard error ðr KðeÞ = ffiffiffiffiffiffi 50 p Þ, the ratio of the standard error and the dimension ðr KðeÞ =ðN ffiffiffiffiffiffi 50 p ÞÞ, and the ratio of KðeÞ and the dimension (KðeÞ/N). Tables 1-3 list, respectively, the results generated by QPSO-Type 1 with a = 1.00, QPSO-Type 2 with a = 0.75 and PSO with constriction factor v = 0.73 and acceleration coefficients c 1 = c 2 = 2.05. Each algorithm used 20 particles. The settings of a for both types of QPSO may lead to good performance in general, which has been demonstrated in our preliminary studies on a set of widely used benchmark functions.</p><p>The numerical results of KðeÞ/N for QPSO-Type 2, listed in the last columns in Table <ref type="table" target="#tab_3">2</ref>, show to have a fairly stable values, with the maximum and minimum values being 154.8450 and 146.0333 respectively. Moreover, the correlation coefficient between KðeÞ and N in Table <ref type="table" target="#tab_3">2</ref> was found to be 0.9997. The fact indicates that there is a strong linear correlation between KðeÞ and the dimension, i.e. KðeÞ ¼ H Á N, for the QPSO-Type 2. The constant H is function of the algorithm used and appears to be near 150 in Table <ref type="table" target="#tab_3">2</ref>. For QPSO-Type 1 and PSO, the correlation coefficients between KðeÞ and N are 0.9967 and 0.9984, meaning that with the given algorithmic parameters, the linear correlations between KðeÞ and N are not so remarkable as that for QPSO-Type 2, but the linearity for PSO is somewhat stronger than that for QPSO-Type 1. For further investigation, we visualize in Figs. <ref type="figure" target="#fig_3">2</ref><ref type="figure" target="#fig_0">3</ref><ref type="figure" target="#fig_1">4</ref>the results of each tested algorithm with other parameter settings. Fig. <ref type="figure" target="#fig_3">2</ref> shows that the value of KðeÞ/N increases slowly as the dimension increases, implying that the time complexity may increase nonlinearly with the dimension. From Figs. <ref type="figure" target="#fig_8">3</ref> and<ref type="figure" target="#fig_1">4</ref>, it can be seen that the time complexities of QPSO-Type 2 and PSO increase fairly linearly when dimension varies in the range of 2-20. However, both the QPSO-Type 1 and QPSO-Type 2 may have lower time complexity than PSO under the given parameter settings.</p><p>To explain the linear correlation we observed, let us consider an idealized random search algorithm with the constant probability q(0 &lt; q 6 1) of improving objective function value. The algorithm is called Somewhat Adaptive Search (SAS),</p><p>as in <ref type="bibr" target="#b87">[88]</ref>. Denote the time complexity of PAS by E[K PAS (e)], and by referring to <ref type="bibr" target="#b2">[3]</ref>, we can obtain that E½K SAS ðeÞ ¼ 1 q E½K PAS ðeÞ ¼ ln vðSÞ vðVeÞ , where v(Á) is the Lebesgue measure. For the testing problem, V e is an N-dimensional super-ball with radius ffiffi ffi e p and its volume is</p><formula xml:id="formula_35">vðV e Þ ¼ p N=2 C N 2 þ 1 À Á Â Ã e N 2 . Considering that ln C N 2 þ 1 À Á ¼ OðNÞ, we obtain E½K SAS ðeÞ ¼ 1 q ln d N vðV e Þ ¼ 1 q ln d N Á C N 2 þ 1 0 ðpeÞ N 2 ! ¼ N q ln d ffiffiffiffiffiffi pe p ! þ ln C N 2 þ 1 ¼ OðNÞ;<label>ð28Þ</label></formula><p>where d is the length of the search scope of each dimension. The above equation implies that the SAS has linear time complexity and the constant H is mainly determined by q if the values of d and e are given.</p><p>For the tested algorithm, the probability q generally varies with the number of function evaluations and dimension of the problem. Under certain parameter settings, the linear correlation between time complexity and dimension showed by QPSO-Type 2 or PSO indicates that q is relatively stable when the number of function evaluation is increasing and the dimension is varying in a certain interval. The value of q of QPSO-Type 1 seems to be less stable when the algorithm is running, leading the  time complexity to increase nonlinearly with the dimension. Nevertheless, since both types of QPSO may have larger q, the values of their H's are smaller than that of PSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Evaluation of the convergence rate</head><p>To test the convergence rate, we also had 50 trial runs for every instance with each run executed for a given maximum number of function evaluations, which were set as m max = 200N. For each algorithm, two groups of experiments were performed, one with population size M = 20, the other with M = 40. To compute the convergence rate, at the (m À 1)th step of the function evaluation, we sampled the particle's position 30 times independently before the next update of the position. For each sample position, we calculated its objective function value denoted by f k m (where k is the number of sampled position), which in turn was compared with that of the global best position f m À 1 . If f k mÀ1 &lt; f mÀ1 , we recorded f k m as it was; otherwise, we replaced it by f mÀ1 . After the 30th sampling, we computed E½f mÀ1 À f Ã jf mÀ1 ¼ 1 30</p><formula xml:id="formula_36">P 30 k¼1 f k m À f Ã À Á</formula><p>and thus could obtain the convergence rate c m . It should be noticed that the sampling procedure did not affect the actual variables such as the particle's current position, its personal best position, the global best position, its velocity (for PSO algorithm) and so forth. After the sampling, the particle updated the position according to these variables.</p><p>For a certain m, the value of c m was obtain by calculating the arithmetic mean of all the c m s of 50 runs. Thus, c was obtained by using c ¼ Q nmax m¼1 c m À Á 1=nmax and the expected convergence rate c was worked out by c ¼ ð f nmax = f 0 Þ 1=nmax . Besides, we also computed the correlation coefficient between c m and f m , and denoted it by h(c m ,f m ).   Tables 4-6 list the results generated by QPSO-Type 1 (a = 1.00), QPSO-Type 2 (a = 0.75) and PSO (v = 0.729, c 1 = c 2 = 2.05). It can be seen from the three tables that for each algorithm on each problem, the value of c is larger than c and the correlation coefficient is negative. The fact indicates that the algorithms ran with sub-linear convergence. It can also be observed that the convergence rates of both types of QPSO (as shown in Tables <ref type="table">4</ref> and<ref type="table" target="#tab_5">5</ref>) are smaller than that of PSO (as shown in Table <ref type="table" target="#tab_6">6</ref>) on each problem with the same population size except when N = 2. This implies that QPSO may converge faster. A closer look at the three tables reveals that h(c m , f m ) increases as the dimension increases. The reason may be that improvement of the function value was relatively harder when the dimension was high, making the convergence rate c m so close to 1 that it changed little as f m decreases. It should also be noted that for a given problem, when M = 40, the convergence rates of all the three algorithms are larger than those when M = 20. However, it cannot be concluded that a larger population size leads to a larger convergence rate, since the convergence rate also depends on other parameters. Smaller population size may result in a faster convergence on the problem with lower dimension, but the algorithm may encounter premature convergence when dimension is higher. On the other hand, although the algorithm with larger population size is not efficient on low-dimensional problems, it has less chance to result in premature convergence on high-dimensional problems. It can be inferred that if other parameters are given, when the dimension increases to a certain number, the convergence rate of the algorithm with smaller population size may exceed that with larger population size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Results for the convergence rate test of QPSO-Type 1.   </p><formula xml:id="formula_37">N n max M = 20 M = 40 f 0 f nmax c c h(c m ,f m ) f 0 f nmax c c h(c m ,f m )<label>2</label></formula><formula xml:id="formula_38">f 0 f nmax c c h(c m ,f m ) f 0 f nmax c c h(c m ,f m ) 2 400</formula><formula xml:id="formula_39">f 0 f nmax c c h(c m ,f m ) f 0 f nmax c c h(c m ,f m )<label>2</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Two improved QPSO algorithms</head><p>Although the QPSO method, particularly the QPSO-Type 2, has been showed to be efficient in solving continuous optimization problem, there is the possibility of improving the algorithm without increasing the complexity of its implementation. Here, we proposed two improved versions of the algorithm based on the QPSO-Type 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">QPSO with random mean best position</head><p>In the first improved QPSO algorithm, the mean best position C in ( <ref type="formula" target="#formula_16">15</ref>) is replaced by the pbest position of a randomly selected particle in the population at each iteration. For convenience, we denoted the randomly selected pbest position by C 0 n . For each particle, the probability for its personal best position to be selected as C 0 n is 1/M. Consequently, the expected value of C 0 n equals to C n , that is,</p><formula xml:id="formula_40">E C 0 n À Á ¼ X M i¼1 1 M P i;n ¼ C n :<label>ð29Þ</label></formula><p>However, since the C 0 n appears to be more changeful than C n , the current position of each particle at each iteration shows to be more volatile than that of the particle in QPSO-Type 2, which diversifies the particle swarm and in turn enhances the global search ability of the algorithm. This improved algorithm is called QPSO with random mean best position (QPSO-RM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">QPSO with ranking operator</head><p>The second improvement involves a ranking operator proposed to enhance the global search ability of the QPSO algorithm. In the original QPSO and QPSO-RM, the neighborhood topology is the global best model so that each particle follows their own pbest position and the gbest position, leading the algorithm to fast convergence. However, the particle may be misguided by the gbestposition if it is located at a local optimal point, particularly at the later stage of the search process. In such a case, the particles are all pulled toward the gbest position and have less opportunity to escape the local optimum even though some particles are located in promising regions where the better solutions or the global optimal solution can be found. As a result, the QPSO using this topology may be prone to encounter premature convergence.</p><p>In the proposed QPSO with ranking operator (QPSO-RO), each particle flies in the search space following its own pbest position and the pbestposition of a randomly selected particle based on a ranking operator, whose fitness value is better than the considered particle. The selection procedure is as follows. Before the position update for particle i at every iteration, the pbest positions of all the particles are ranked in ascending order according to their fitness values, with the rank of the global best particle being M and that of the worst particle being 1. Given that the rank of the considered particle is rank i (1 6 rank i 6 M), each particle whose rank is larger than rank i will be considered as a candidate to be selected but the other particles will not be selected. In other words, the selection probability of particle q(1 6 q 6 M) is given by PS q ¼ 2Ârankq rank i ðrank i À1Þ ; rank q &gt; rank i 0;</p><p>rank q 6 rank i</p><formula xml:id="formula_41">( ;<label>ð30Þ</label></formula><p>where rank i is the rank of particle i. From Eq. ( <ref type="formula" target="#formula_41">30</ref>), it can be seen that the sum of the selection probabilities of all the candidates equals 1. For particle i, if the pbest position of particle q is selected, then the coordinates of the local attractor of particle i is determined by</p><formula xml:id="formula_42">p j i;n ¼ u j i;n P j i;n þ 1 À u j i;n P j q;n ; u j i;n $ Uð0; 1Þ;<label>ð31Þ</label></formula><p>where P j q;n is the jth component of the pbest position of particle q with rank q &gt; rank i . Eq. ( <ref type="formula" target="#formula_42">31</ref>) implies that particle i is attracted by both its own pbest position and the randomly selected P q,n . Although the global best particle is selected with the highest probability, there is a better chance for the other particles to be selected as a part of the local attractor. This helps the particle swarm search other promising region and consequently enhance the global search ability of the algorithm. The procedure of the QPSO-RO algorithm is outlined in Fig. <ref type="figure" target="#fig_7">5</ref>. Also note that randi(Á), i = 1, 2, 3, is used to denote random numbers generated uniformly and distributed on (0, 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments on benchmark functions</head><p>Section 3 has theoretically proven that the QPSO algorithm is global convergent, which, however, is not sufficient to draw a conclusion that the QPSO is effective in real-world applications. Semi-theoretical evaluation of time-complexity and convergence rate of QPSO in Section 4 reveals that it has lower computational complexity and better convergence properties for the Sphere function, which is a unimodal function usually used to test the local search ability of an algorithm. Nevertheless, it is hard to generalize the same evaluation method to an arbitrary problem, particularly when the problem is multimodal, and it is inconclusive with respect to the overall performance of the algorithms using the Sphere function only. Hence, to evaluate the QPSO objectively, it would be better to compare it with other PSO variants using a large test set of optimization functions.</p><p>The goal of this section is thus to determine the overall performance of QPSO by using the first ten functions from the CEC2005 benchmark suite <ref type="bibr" target="#b76">[77]</ref>. Furthermore, the proposed QPSO-RM and QPSO-RO were also experimented on these benchmark functions. A performance comparison was made among the QPSO algorithms (QPSO-Type 1 and QPSO-Type 2), QPSO-RM, QPSO-RO and other forms of PSO, including PSO with inertia weight (PSO-In) <ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref>, PSO with constriction factor (PSO-Co) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, the Standard PSO <ref type="bibr" target="#b3">[4]</ref>, Gaussian PSO <ref type="bibr" target="#b63">[64]</ref>, Gaussian Bare Bones PSO <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>, Exponential PSO (PSO-E) <ref type="bibr" target="#b38">[39]</ref>, Lévy PSO <ref type="bibr" target="#b55">[56]</ref>, comprehensive learning PSO (CLPSO) <ref type="bibr" target="#b42">[43]</ref>, dynamic multiple swarm PSO (DMS-PSO) <ref type="bibr" target="#b41">[42]</ref> and fully-informed particle swarm (FIPS) <ref type="bibr" target="#b45">[46]</ref>. F 1 to F 5 of the CEC 2005 benchmark suite are unimodal, while functions F 6 to F 10 are multi-modal. Each algorithm ran 100 times on each problem using 20 particles to search the global best fitness value. At each run, the particles in the algorithms started in new and randomly-generated positions, which are uniformly distributed within the search bounds. Every run of each algorithm lasted 3000 iterations and the best fitness value (objective function value) for each run was recorded.</p><p>For the QPSO-based algorithms, two methods of controlling a were used. One is the fixed-value method, in which the value of a was fixed at a constant during the search process. The other is time-varying method, in which the value of a decreased linearly in the course of running. For QPSO-Type 1 with the fixed-value method, a was fixed at 1.0, while for QPSO-Type 1 with the time-varying method, a decreased linearly form 1.0 to 0.9. For QPSO-Type 2 with the fixed-value method, the value of a was fixed at 0.75, while for QPSO-Type 2 with the time-varying method, a decreased linearly from 1.0 to 0.5 with regard to the iteration number. For QPSO-RM, a was set to be 0.54 when the fixed-value method was used, and decreased linearly from 0.6 to 0.5 when the time-varying method was used. For QPSO-RO, a was fixed at 0.68 and decreased linearly from 0.9 to 0.5 for the two parameter control methods, respectively. The parameter configurations for the QPSO-based algorithms were recommended according to our preliminary experiments or by the existing publications <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b80">81]</ref>. The other parameters of the remainder PSO variants were configured as recommended by the corresponding publications.</p><p>The mean best fitness values and standard deviations out of 100 runs of each algorithm on F 1 to F 5 are presented in Table <ref type="table" target="#tab_8">7</ref> and those on F 6 to F 10 in Table <ref type="table" target="#tab_9">8</ref>. To investigate if the differences in mean best fitness values between algorithms were significant, the mean values for each problem were analyzed using a multiple comparison procedure, an ANOVA (Analysis Of Variance), with 0.05 as the level of significance. The procedure employed in this work is called the ''stepdown'' procedure, which takes into account that all but one of the comparisons are less different than the range. When doing all pairwise comparisons, this approach is the best available if confidence intervals are not needed and the sample sizes are equal <ref type="bibr" target="#b16">[17]</ref>.</p><p>The algorithms were ranked to determine which algorithm could be reliably said to be the most effective for each problem. The algorithms that were not statistically different to each other were given the same rank; those that were not statistically different to more than one other groups of algorithms were ranked with the best-performing of these groups. For each algorithm, the resulting rank for each problem, the total rank and the average rank are shown in Table <ref type="table">9</ref>.</p><p>For the Shifted Sphere Function (F 1 ), QPSO-RM with either fixed or time-varying a generated better results than other methods. The results for the Shifted Schwefel's Problem 1.2 (F 2 ) show that, QPSO-RM with fixed a yielded the best results, but the performances of PSO-In and QPSO-Type 2 with linearly decreasing a were inferior to those of the other competitors. For Shifted Rotated High Conditioned Elliptic Function (F 3 ), when using fixed a, both the QPSO-RO and QPSO-RM outperformed the other methods in a statistical significance manner. QPSO-RO with fixed a also showed to be the winner among all the tested algorithms for the Shifted Schwefel's Problem 1.2 with Noise in Fitness (F 4 ). F 5 is the Schwefel's Problem 2.6 with Global Optimum on the Bounds, and for this benchmark, QPSO-RO with time-varying a yielded the best results. For benchmark F 6 , the Shifted Rosenbrock Function, the QPSO-based algorithms except QPSO-Type 2 were superior to those of the other algorithms, among which there was no statistically significant difference except PSO-In and DMS-PSO. The results for the Shifted Rotated Griewank's Function without Bounds (F 7 ) suggest that QPSO-RM, either with fixed a or with time-varying a, was able to find the solution for the function with the best quality compared to the other methods. Benchmark F 8 is the Shifted Rotated Ackley's Function with Global Optimum on the Bounds. The QPSO-RM with time-varying a showed the best performance for this problem among the competitors. It can be seen that the performance differences between the QPSO-based algorithms and PSO-In are not statistically significant. The Shifted Rastrigin's Function (F 9 ) is a separable function, which the CLPSO algorithm was good at solving it. However, it can be observed that the QPSO-RO obtained the better performance than the other QPSO-based algorithms. F 10 is the Shifted Rotated Rastrigrin's Function, which appears to be a more difficult problem than F 9 . For this benchmark, the QPSO-Type 2, QPSO-Type 1 with time-varying a and the standard PSO outperformed the other competitors in a statistically significant manner. Table <ref type="table">9</ref> shows that the QPSO-RO obtained a better overall performance than all the other tested algorithms, for the total and average ranks of QPSO-RO with both parameter control methods are smaller than those of the other algorithms. Although the total and average ranks of QPSO-RO with fixed a and QPSO-RO with time-varying a are the same, the former obtained relatively more stable performance than the latter. It can be observed that QPSO-RO with fixed a yielded the best result for four of the tested benchmark problems in a statistically significant manner, with the worst rank being 6 for F 5 and F 10 , and that QPSO-RO with time-varying agenerated the best result for half of all the tested functions, and the worst rank is 10 for F 2 . Compared with the QPSO algorithm, including QPSO-Type 1 and QPSO-Type 2, the QSPO-RO achieved a remarkable improvement of the overall algorithmic performance.</p><p>The second best-performing algorithm was the QPSO-RM algorithm, as indicated by the total and average ranks. Between the two parameter control methods, QPSO-RM with the time-varying a yielded a comparable overall performance with QPSO-RO. It can be seen that the performance of QPSO-RM with time-varying ais more stable than that of QPSO-RM with fixed a, for the worst ranks of the two versions of QPSO-RM are 11 and 17 for F 10 , respectively. It is obvious that QPSO-RM has slightly better overall performance than the two types of the original QPSO.</p><p>The two types of the original QPSO algorithm, as shown by the total ranks, achieved better overall performance than other PSO variants. Besides the evaluation of the convergence rate and time complexity of QPSO, these results further provided stronger evidence that the QPSO is a promising tool for optimization problems. Between QPSO-Type 2 and QPSO-Type 1, the former showed to have a better and more stable overall performance than the latter. Among the other PSO variants, the DMS-PSO and the standard PSO yielded better overall performance than the remainder competitors. It is evident from the ranking list that the standard PSO and PSO-Co were two great improvements over the PSO-In algorithm, which did not show comparable performance with the other competitors. The other four probabilistic algorithms did not work so effectively as the QPSO-based algorithm, DMS-PSO and the standard PSO. What should be noticed is that the CLPSO is very effective in solving separable functions such as F 9 , but has slower convergence speed, as has been indicated in the related publication <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper, we first investigated the convergence of the QPSO algorithm by establishing a Menger space for the algorithm, in which the algorithm is shown to be a contraction mapping, and its orbit is probabilistic bounded. Thus, we proved the fixed point theorem of the QPSO algorithm in the Menger space, showing that the algorithm converges to the global optimum in probability.</p><p>Then, the effectiveness of the algorithm was evaluated by time complexity on the Sphere function. The linear correlation between complexity and the dimension of the problem was observed and analyzed. Besides, we also evaluated the performance of the QPSO algorithm with respect to the convergence rate, which was defined by the ratio of conditional expectation of the distance of objective function value to the global optimum at the next iteration and the distance at the current iteration. It was found that the algorithms ran in sub-linear convergence and the QPSO had smaller convergence rate than the PSO, which means the QPSO can converge faster with given parameters.</p><p>Two improvements of the QPSO, the QPSO-RO and QPSO-RM were proposed next. The QPSO algorithm, along with the two improved versions and other PSO variants were tested on a set of benchmark problems for an overall performance evaluation. The experimental results show that the QPSO is comparable with or even better than other forms of PSO in finding the optimal solutions of the tested benchmark functions, and also show that the two modified QPSO algorithms achieved remarkable improvement over the original QPSO algorithm.</p><p>F xm;x mþi ðtÞ P F T n mÀ1 x mÀ1 ;T n mþiÀ1 þÁÁÁþnm þn mÀ1 x mÀ1 ðtÞ P F x mÀ1 ;T </p><formula xml:id="formula_43">sup u&lt;t=k m inf z2fT s x 0 g 1 s¼0 F x 0 ;z ðuÞ ¼ sup u&gt;0 inf z2fT s x 0 g 1 s¼0 F x 0 ;z ðuÞ; if t &gt; 0; 0; if t ¼ 0; 8 &lt; : ¼ 1; if t &gt; 0; 0; if t ¼ 0; &amp;<label>ðA3Þ</label></formula><p>which means that the sequence fx m g 1 m¼0 is a T -Cauchy Sequence in E. Thus (E,F,D) is T -Complete and there exists a point x ⁄ in E such that x n ! T x Ã .</p><p>(2) Now we prove that x ⁄ is the fixed point of T nÃ , where n ⁄ = n(x ⁄ ). For any positive integer i and "t P 0, according to <ref type="bibr" target="#b17">(18)</ref>, the following inequality holds.</p><formula xml:id="formula_44">F x i ;T nÃ x i ðtÞ P F x iÀ1 ;T nÃ x iÀ1 t k P Á Á Á P F x 0 ;T nÃ x 0 t k i P sup u&lt;t=k i F x 0 ;T nÃ x 0 ðuÞ:<label>ðA4Þ</label></formula><p>Taking the limit as i ? 1 on both sides of the above inequality, we find that lim i!1 </p><formula xml:id="formula_45">F x i ;T nÃ x i ðtÞ P lim i!1 sup u&lt;t=k i F x 0 ;T nÃ x 0 ðuÞ P sup u&gt;0 F x 0 ;T nÃ x 0 ðuÞ; if t &gt; 0 0 i f t ¼ 0 ( ¼ 1 if t &gt; 0; 0 if t ¼ 0: &amp;<label>ðA5Þ</label></formula><p>Taking the limit as n ? 1 on the right side of the above inequality and considering that lim n!1 t k n ¼ 1, we can obtain that</p><formula xml:id="formula_47">F xÃ;y Ã ðtÞ ¼ 1; 8t P 0, implying that x ⁄ = y ⁄ . As such, x ⁄ is the unique fixed point of T nÃ in E. Since Tx Ã ¼ TT nÃ x Ã ¼ T nÃ Tx Ã , Tx ⁄ is also a fixed point of T nÃ . Thus Tx ⁄ = x ⁄ , which means that x ⁄ is a fixed point of T. It is evident that x ⁄ is the unique fixed point of T.</formula><p>(3) Finally we have to prove that for every x 0 2 E, the iterative sequence {T n x 0 } converges to x ⁄ in T . For every positive integer n &gt; n ⁄ and n = mn ⁄ + s where 0 6 s &lt; n ⁄ , from <ref type="bibr" target="#b17">(18)</ref> </p><formula xml:id="formula_48">which implies that T n x 0 ! T x Ã .<label>ðA10Þ</label></formula><p>This completes the proof of the theorem. h Theorem 2. Consider the ordered pair (V, F), where F is a mapping of V Â V into D. For every x, y 2 V, if the distribution function F x,y is defined by F x,y (t) = P{jx À yj &lt; t}, "t 2 R, then (V, F) is a PM-space.</p><p>Proof. To achieve the proof of the theorem, we only need to show that the mapping F satisfies conditions (PM-1) to (PM-4).</p><p>(1) For every x, y 2 V, since jx À yj P 0, F x,y (0) = P{jx À yj &lt; 0} = 0, implying that F satisfies condition (PM-1).</p><p>(2) For every x, y 2 V, if F x,y (t) = H(t) for every t &gt; 0, we have F x,y (t) = P{jx À yj &lt; t} = 1, which implies that for every positive integer m, P jx À yj &lt;</p><formula xml:id="formula_49">1 m È É ¼ 1. Therefore, P T 1 m¼1 jx À yj &lt; 1 m À Á È É ¼ Pfjx À yj ¼ 0g ¼ 1, namely, x = y.</formula><p>Contrarily, if x = y, namely jx À yj = 0, then for every t &gt; 0 F x,y (t) = P{jx À yj &lt; t} = 1; or for every t &lt; 0, F x,y (t) = P{jx À y &lt; t} = 0. Thus F x,y (t) = H(t), that is, F satisfies (PM-2).</p><p>(3) By the definition of F, we find it evident that F satisfies (PM-3). (4) For ever x,y,z 2 V, if F x,y (t 1 ) = 1 and F y,z (t 2 ) = 1, then F x,y (t 1 ) = P{jx À yj &lt; t 1 } = 1 and F y,z (t 2 ) = P{jy À zj &lt; t 2 } = 1. Since jx À zj 6 jx À yj + jy À zj, so</p><formula xml:id="formula_50">F x;z ðt 1 þ t 2 Þ ¼ Pfjx À zj 6 t 1 þ t 2 g P Pfjx À yj þ jy À zj &lt; t 1 þ t 2 g P Pfðjx À yj &lt; t 1 Þ \ ðjy À zj &lt; t 2 Þg ¼ Pfjx À yj &lt; t 1 g þ Pfjy À zj &lt; t 2 g À Pfðjx À yj &lt; t 1 Þ [ ðjy À zj &lt; t 2 Þg ¼ 2 À Pfðjx À yj &lt; t 1 Þ [ ðjy À zj &lt; t 2 Þg P 1: Accordingly, F x,z (t 1 + t 2 ) = P{jx À zj &lt; t 1 + t 2 } = 1, which implies that F satisfies (PM-4).</formula><p>This completes the proof of the theorem. h Proof. To achieve the proof, we only need to prove that (V, F, D) satisfies Menger's triangle inequality (PM-4) 0 . For every x, y, z 2 V and every t 1 P 0, t 2 P 0, since jx À zj 6 jx À yj þ jy À zj;</p><formula xml:id="formula_51">we have fjx À zj &lt; t 1 þ t 2 g ' fjx À yj þ jy À zj &lt; t 1 þ t 2 g ' fjx À yj &lt; t 1 g \ fjy À zj &lt; t 2 g:<label>ðA11Þ</label></formula><p>Hence F x;z ðt 1 þ t 2 Þ ¼ Pfjx À zj &lt; t 1 þ t 2 g P Pfjx À yj þ jy À zj &lt; t 1 þ t 2 g P Pfðjx À yj &lt; t 1 Þ \ ðjy À zj &lt; t 2 Þg ¼ Pfjx À yj &lt; t 1 g þ Pfy À zj &lt; t 2 g À Pfðjx À yj &lt; t 1 Þ [ ðjy À zj &lt; t 2 Þg P Pfjx À yj &lt; t 1 g þ Pfy À zj &lt; t 2 g À 1</p><formula xml:id="formula_52">¼ F x;y ðt 1 Þ þ F y;z ðt 2 Þ À 1 ¼ maxfF x;y ðt 1 Þ þ F y;z ðt 2 Þ À 1; 0g ¼ D 1 ðF x;y ðt 1 Þ; F y;z ðt 2 Þg</formula><p>implying that (V, F, D), where D = D 1 , satisfies Menger's triangle inequality (PM-4) 0 . Therefore, (V, F, D) is a Menger space. This completes the proof of the theorem. h Theorem 4. The mapping T is a contraction mapping of the Menger space (V, F, D).</p><p>Proof. If t = 0, it is evident that T satisfies the contractive condition in Definition 7. In the rest part of the proof, we assume that t &gt; 0. Given f 0 2 V, "f 00 2 V and "t &gt; 0, we suppose that F f 0 ;f 00 ðtÞ ¼ Pfjf 0 À f 00 j &lt; tg</p><formula xml:id="formula_53">¼ 1 À d;<label>ðA12Þ</label></formula><p>where 0 &lt; d &lt; 1. Let V(t) = {f: f 2 V, f À f ⁄ &lt; t}, where f ⁄ is the global minimum of f(X). V(t) is measurable and its Lebesgue measure v[V(t)] &gt; 0. Letting S(t) = {X: f(X) 2 V(t)}, we have that v[S(t)] &gt; 0, due to the almost everywhere continuity of f(X).</p><p>For the start point f 0 , let a 0 (t) = P{f 0 2 V(t)} = g 0 (t). At the precedent iterations, for every random variable f n = T n f 0 , according to the update equation of QPSO, we can let </p><formula xml:id="formula_54">g n ðtÞ ¼ 1 À Y M i¼1</formula><p>Since for every 0 6 n &lt; 1, we have X j i;n &lt; 1, C À X j i;n &lt; 1 or p À X j i;n &lt; 1. According to <ref type="bibr" target="#b13">(14)</ref> or <ref type="bibr" target="#b14">(15)</ref>, we have 0 &lt; L i,j,n &lt; 1, which implies that h i;n ðŷ n ; y i;n ; x i;n Þ is Lebesgue integrable and 0 &lt; g i (t) &lt; 1. We thus immediately have that sup n&gt;0 F fn;fÃ ðtÞ ¼ 1, according to (A14). Hence, for the given d and f 0 , there exists a positive integer n 1 (f 0 ) such that whenever n P n 1 (f 0 ), F T n f 0 ;fÃ ðtÞ ¼ PfjT n f 0 À f Ã j &lt; tg ¼ PfT n f 0 2 VðtÞg &gt; 1 À d 2 ;</p><p>and there also exists a positive integer n 2 (f 0 ) such that whenever n P n 2 (f 0 ), F T n f 00 ;fÃ ðtÞ ¼ PfjT n f 00 À f Ã j &lt; tg ¼ PfT n f 00 2 VðtÞg &gt; 1 À d 2 :</p><p>Let n(f 0 ) P max{n 1 (f 0 ), n 2 (f 0 )}. Thus both of the following two inequalities are satisfied</p><formula xml:id="formula_56">F T nðf 0 Þ f 0 ;fÃ ðtÞ ¼ PfjT nðf 0 Þ f 0 À f Ã j &lt; tg ¼ PfT nðf 0 Þ f 0 2 VðtÞg ¼ PfT nðf 0 Þ f 0 À f Ã &lt; tg &gt; 1 À d 2 ; F T nðf 0 Þ f 00 ;fÃ ðtÞ ¼ PfjT nðf 0 Þ f 00 À f Ã j &lt; tg ¼ PfT nðf 0 Þ f 00 2 VðtÞg ¼ PfT nðf 0 Þ f 00 À f Ã &lt; tg &gt; 1 À d 2 :</formula><p>Since the diameter of V(t) is t, that is, sup x,y2V(t) jx À yj = t. If T nðf 0 Þ f 0 ; T nðf 0 Þ f 00 2 VðtÞ, jT nðf 0 Þ f 0 À T nðf 0 Þ f 00 j &lt; t. As a result, it is satisfied that</p><formula xml:id="formula_57">fjT nðf 0 Þ f 0 À T nðf 0 Þ f 00 j &lt; tg ' fðT nðf 0 Þ f 0 2 VðtÞÞ \ T nðf 0 Þ f 00 2 VðtÞg ¼ fðT nðf 0 Þ f 0 À f Ã &lt; tÞ \ ðT nðf 0 Þ f 00 À f Ã &lt; tÞg:</formula><p>Thus we have that F T nðf 0 Þ f 00 ;T nðf 0 Þ f 00 ðtÞ ¼ PfjT nðf 0 Þ f 0 À T nðf 0 Þ f 00 j &lt; tg P PfðT nðf 0 Þ f 0 À f Ã &lt; tÞ \ ðT</p><formula xml:id="formula_58">nðf 0 Þ f 00 À f Ã &lt; tÞg ¼ PfT nðf 0 Þ f 0 À f Ã &lt; tg þ PfT nðf 0 Þ f 00 À f Ã &lt; tg À PfðT nðf 0 Þ f 0 À f Ã &lt; tÞ [ ðT nðf 0 Þ f 00 À f Ã &lt; tÞg &gt; 1 À d 2 þ 1 À d 2 À PfðT nðf 0 Þ f 0 À f Ã &lt; tÞ [ ðT nðf 0 Þ f 00 À f Ã &lt; tÞg &gt; 2 À d À 1 ¼ 1 À d;</formula><p>and accordingly F T nðf 0 Þ f 0 ;T nðf 0 Þ f 00 ðtÞ &gt; F f 0 ;f 00 ðtÞ: ðA15Þ</p><p>Since F is monotonically increasing with t, there must exist k 2 (0, 1) such that</p><formula xml:id="formula_59">F T nðf i Þ f 0 ;T nðf i Þ f 00 ðtÞ P F f 0 ;f 00 t k :<label>ðA16Þ</label></formula><p>It implies that T satisfies the contractive condition in Definition 7. This completes the proof of the theorem. h Theorem 5. f ⁄ is the unique fixed point in V such that for every f 0 2 V, the iterative sequence {T n f 0 } converges to f ⁄ .</p><p>Proof. For Menger space (V, F, D), where D = D 1 , T is a contraction mapping as shown by Theorem 4. Given f 0 2 V, we have f n = T n f 0 2 [f ⁄ , f 0 ] for every n P 1. This implies that O T ðf 0 ; 0; 1Þ ¼ ff n ¼ T n f 0 g 1 n¼0 &amp; ½f Ã ; f 0 . Thus for every t &gt; f 0 À f ⁄ , inf f 0 ;f 00 2O T ðf 0 ;0;1Þ F f 0 ;f 00 ðtÞ ¼ 1. Accordingly, we have sup t&gt;0 inf f 0 ;f 00 2O T ðf 0 ;0;1Þ F f 0 ;f 00 ðtÞ ¼ 1; ðA17Þ which means that the orbit generated by T at f 0 is probabilistic bounded. By Theorem 1, there exists a unique common fixed point in E for T. Since f ⁄ = Tf ⁄ , f ⁄ is the fixed point. Consequently, for every f 0 2 V, the iterative sequence {T n f 0 } converges to f ⁄ in T . This completes the proof of the theorem. h Theorem 6. The sequence of function values {f n , n P 0} generated by QPSO converges to f ⁄ in probability.</p><p>Proof. Since {f n , n P 0} converges to f ⁄ in T , by Definition 5 and the definition given in Theorem 4, for every e &gt; 0, k &gt; 0, there exists K = K(e, k) such that whenever n P K, F fn;fÃ ðeÞ ¼ Pfjf n À f Ã j &lt; eg ¼ Pff n 2 V e g &gt; 1 À k:</p><p>Due to the arbitrariness of k, (A18) implies that f n ! P f Ã .</p><p>This completes the proof of the theorem. h Proof. According to the properties of conditional expectations, we have</p><formula xml:id="formula_61">E½ðf n À f Ã Þ ¼ E½E½ðf n À f Ã Þjf nÀ1 ;<label>ðA19Þ</label></formula><p>for all n &gt; 0. If {c n , n &gt; 0} and {f n À f ⁄ , n &gt; 0} are negatively correlated, it follows that</p><formula xml:id="formula_62">Covðc n ; f n À f Ã Þ ¼ E½c n ðf n À f Ã Þ À Eðc n ÞEðf n À f Ã Þ &lt; 0; namely E½c n ðf n À f Ã Þ &lt; Eðc n ÞEðf n À f Ã Þ;<label>ðA20Þ</label></formula><p>for all n &gt; 0. By (A19) and (A20), we therefore have</p><formula xml:id="formula_63">e n ¼ Eðf n À f Ã Þ ¼ EfE½ðf n À f Ã Þjf nÀ1 g ¼ E½c n ðf nÀ1 À f Ã Þ &lt; Eðc n ÞEðf nÀ1 À f Ã Þ ¼ c n Eðf nÀ1 À f Ã Þ ¼ c n EfE½ðf nÀ1 À f Ã Þjf nÀ2 g ¼ c n E½c nÀ1 ðf nÀ2 À f Ã Þ &lt; c n c nÀ1 Eðf nÀ2 À f Ã Þ ¼ Á Á Á &lt; c n c nÀ1 c nÀ2 . . . c 1 Eðf 0 À f Ã Þ ¼ Y n i¼1 c i ! Eðf 0 À f Ã Þ ¼ c n e 0 ;<label>ðA21Þ</label></formula><formula xml:id="formula_64">implying that c ¼ ðe n =e 0 Þ 1=n &lt; c.</formula><p>If {c n , n &gt; 0} and {f n À f ⁄ , n &gt; 0} are positively correlated,</p><formula xml:id="formula_65">Covðc n ; f n À f Ã Þ ¼ E½c n ðf n À f Ã Þ À Eðc n ÞEðf n À f Ã Þ &gt; 0:</formula><p>Similarly, we have c &gt; c.</p><p>If {c n , n &gt; 0} and {f n À f ⁄ , n &gt; 0} are uncorrelated,</p><formula xml:id="formula_66">Covðc n ; f n À f Ã Þ ¼ E½c n ðf n À f Ã Þ À Eðc n ÞEðf n À f Ã Þ ¼ 0:</formula><p>Replacing each sign of inequality in (A21) by an equal sign, we find that c ¼ c. This completes the proof of the theorem. h</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 3 .</head><label>3</label><figDesc>A mapping D: [0, 1] Â [0, 1] ? [0, 1] is a triangle norm (briefly t-norm) if it satisfies: for every a, b, c, d 2 [0, 1], (D-1) D(a, 1) = a, D(0, 0) = 0; (D-2) D(a, b) = D(b, a); (D-3) D(c, d) P D(a, b) for c P a, d P b; (D-4) D(D(a, b), c) = D(a, D(b, c)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3. 4 .</head><label>4</label><figDesc>Global convergence of the QPSO algorithm 3.4.1. Construction of the PM-space for QPSOConsider the minimization problem defined by (3), which is rewritten as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>are two negatively correlated (or positively correlated or uncorrelated) sequences of random variables, then c &lt; c (or c &gt; c or c ¼ cÞ (see the proof in Appendix A).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results of time complexity testing for QPSO-Type 1 with different values of a and population sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Results of the time complexity testing for QPSO-Type 2 with different values of a and population sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results of the time complexity testing for QPSO-Type 2 with different values of v and population sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. The procedure of the QPSO-RO algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Theorem 3 .</head><label>3</label><figDesc>Triplet (V, F, D) is a Menger space, where D = D 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Theorem 7 .</head><label>7</label><figDesc>Let c ¼ Q n i¼1 c i À Á 1=n where c i ¼ Eðc i Þ. If {c n , n &gt; 0} and {f n À f ⁄ , n &gt; 0}are two negatively correlated (or positively correlated or uncorrelated) sequences of random variables, then c &lt; c (or c &gt; c or c ¼ cÞ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1Þ. Generally, the value of V j i;n is restricted within the interval [ÀV max , V max ]. Without loss of generality, if we consider the following minimization problem:</figDesc><table><row><cell>Minimize f ðXÞ;</cell></row></table><note><p>1 i;n ; P 2 i;n ; . . . ; P N i;n is the best previous position (the position giving the best objective function value or fitness value) of particle i called personal best (pbest) position, and vector G n ¼ G 1 n ; G 2 n ; . . . ; G N n is the position of the best particle among all the particles in the population and called global best (gbest) position. The parameters r j i;n and R j i;n are sequences of two different random numbers distributed uniformly on (0, 1), that is, r j i;n ; R j i;n $ Uð0;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>space with continuous t-norm is T -Complete. Let (E, F, D) be a Menger space where D is continuous. The self-mapping T that maps E into itself is T -continuous on E, if for every sequence {x n } in E, Tx n ! T Tx Ã whenever x n ! T x Ã 2 E.</figDesc><table><row><cell cols="3">Definition 6. 3.3. The fixed point theorem in PM-space</cell><cell></cell></row><row><cell cols="4">Definition 7. Let T be a self-mapping of a Menger space(E, F, D). T is a contraction mapping, if there exists a constant</cell></row><row><cell cols="3">k 2 (0, 1) and for every x 2 E there exists a positive integer n(x) such that for every y 2 E,</cell><cell></cell></row><row><cell>F T nðxÞ x;T nðxÞ y ðtÞ P F x;y</cell><cell>t k</cell><cell>; 8t P 0:</cell><cell>ð18Þ</cell></row><row><cell cols="4">A set A &amp; (E, F, D) is called probabilistic bounded if sup t&gt;0 inf x,y2A F x,y (t) = 1. Denote the orbit generated by T at x 2 E by</cell></row><row><cell cols="3">O T (x; 0, 1), i.e., O T ðx; 0; 1Þ ¼ fx n ¼ T n xg 1 n¼0</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Statistical results of the time complexity test for QPSO-Type 1.</figDesc><table><row><cell>N</cell><cell>KðeÞ</cell><cell>r K(e)</cell><cell>r KðeÞ = p</cell><cell>ffiffiffiffiffiffi 50</cell><cell>r KðeÞ =ðN</cell><cell>p</cell><cell>ffiffiffiffiffiffi 50 Þ</cell><cell>KðeÞ=N</cell></row><row><cell>2</cell><cell>232.16</cell><cell>49.24713</cell><cell cols="2">6.9646</cell><cell>3.4823</cell><cell></cell><cell></cell><cell>116.0800</cell></row><row><cell>3</cell><cell>382.78</cell><cell>67.11832</cell><cell cols="2">9.4920</cell><cell>3.1640</cell><cell></cell><cell></cell><cell>127.5933</cell></row><row><cell>4</cell><cell>577.92</cell><cell>92.87886</cell><cell cols="2">13.1351</cell><cell>3.2838</cell><cell></cell><cell></cell><cell>144.4800</cell></row><row><cell>5</cell><cell>741.08</cell><cell>104.8719</cell><cell cols="2">14.8311</cell><cell>2.9662</cell><cell></cell><cell></cell><cell>148.2160</cell></row><row><cell>6</cell><cell>921.92</cell><cell>128.5678</cell><cell cols="2">18.1822</cell><cell>3.0304</cell><cell></cell><cell></cell><cell>153.6533</cell></row><row><cell>7</cell><cell>1124.7</cell><cell>115.4569</cell><cell cols="2">16.3281</cell><cell>2.3326</cell><cell></cell><cell></cell><cell>160.6714</cell></row><row><cell>8</cell><cell>1396.2</cell><cell>170.9966</cell><cell cols="2">24.1826</cell><cell>3.0228</cell><cell></cell><cell></cell><cell>174.5250</cell></row><row><cell>9</cell><cell>1586.36</cell><cell>159.0606</cell><cell cols="2">22.4946</cell><cell>2.4994</cell><cell></cell><cell></cell><cell>176.2622</cell></row><row><cell>10</cell><cell>1852.86</cell><cell>185.6496</cell><cell cols="2">26.2548</cell><cell>2.6255</cell><cell></cell><cell></cell><cell>185.2860</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Statistical results of the time complexity test for QPSO-Type 2.</figDesc><table><row><cell>N</cell><cell>KðeÞ</cell><cell>r K(e)</cell><cell>r KðeÞ = p</cell><cell>ffiffiffiffiffiffi 50</cell><cell>r KðeÞ =ðN</cell><cell>p</cell><cell>ffiffiffiffiffiffi 50 Þ</cell><cell>KðeÞ=N</cell></row><row><cell>2</cell><cell>306.26</cell><cell>69.41529</cell><cell cols="2">9.8168</cell><cell>4.9084</cell><cell></cell><cell></cell><cell>153.1300</cell></row><row><cell>3</cell><cell>455.06</cell><cell>71.15301</cell><cell cols="2">10.0626</cell><cell>3.3542</cell><cell></cell><cell></cell><cell>151.6867</cell></row><row><cell>4</cell><cell>619.38</cell><cell>60.03057</cell><cell cols="2">8.4896</cell><cell>2.1224</cell><cell></cell><cell></cell><cell>154.8450</cell></row><row><cell>5</cell><cell>748.92</cell><cell>69.87156</cell><cell cols="2">9.8813</cell><cell>1.9763</cell><cell></cell><cell></cell><cell>149.7840</cell></row><row><cell>6</cell><cell>883.92</cell><cell>94.45458</cell><cell cols="2">13.3579</cell><cell>2.2263</cell><cell></cell><cell></cell><cell>147.3200</cell></row><row><cell>7</cell><cell>1043.26</cell><cell>101.0267</cell><cell cols="2">14.2873</cell><cell>2.0410</cell><cell></cell><cell></cell><cell>149.0371</cell></row><row><cell>8</cell><cell>1171.68</cell><cell>102.8985</cell><cell cols="2">14.5520</cell><cell>1.8190</cell><cell></cell><cell></cell><cell>146.4600</cell></row><row><cell>9</cell><cell>1314.3</cell><cell>117.4271</cell><cell cols="2">16.6067</cell><cell>1.8452</cell><cell></cell><cell></cell><cell>146.0333</cell></row><row><cell>10</cell><cell>1477.2</cell><cell>112.9856</cell><cell cols="2">15.9786</cell><cell>1.5979</cell><cell></cell><cell></cell><cell>147.7200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Statistical results of the time complexity test for PSO.</figDesc><table><row><cell>N</cell><cell>KðeÞ</cell><cell>r K(e)</cell><cell>r KðeÞ = p</cell><cell>ffiffiffiffiffiffi 50</cell><cell>r KðeÞ =ðN</cell><cell>p</cell><cell>ffiffiffiffiffiffi 50 Þ</cell><cell>KðeÞ=N</cell></row><row><cell>2</cell><cell>679.2</cell><cell>126.4995</cell><cell cols="2">96.0534</cell><cell cols="2">48.0267</cell><cell></cell><cell>339.6000</cell></row><row><cell>3</cell><cell>967.8</cell><cell>146.133</cell><cell cols="2">136.8676</cell><cell cols="2">45.6225</cell><cell></cell><cell>322.6000</cell></row><row><cell>4</cell><cell>1235.3</cell><cell>137.2839</cell><cell cols="2">174.6978</cell><cell cols="2">43.6745</cell><cell></cell><cell>308.8250</cell></row><row><cell>5</cell><cell>1417.3</cell><cell>157.8286</cell><cell cols="2">200.4365</cell><cell cols="2">40.0873</cell><cell></cell><cell>283.4600</cell></row><row><cell>6</cell><cell>1686</cell><cell>174.2886</cell><cell cols="2">238.4364</cell><cell cols="2">39.7394</cell><cell></cell><cell>281.0000</cell></row><row><cell>7</cell><cell>1914.5</cell><cell>220.8512</cell><cell cols="2">270.7512</cell><cell cols="2">38.6787</cell><cell></cell><cell>273.5000</cell></row><row><cell>8</cell><cell>2083.3</cell><cell>186.5505</cell><cell cols="2">294.6231</cell><cell cols="2">36.8279</cell><cell></cell><cell>260.4125</cell></row><row><cell>9</cell><cell>2346.5</cell><cell>162.1101</cell><cell cols="2">331.8452</cell><cell cols="2">36.8717</cell><cell></cell><cell>260.7222</cell></row><row><cell>10</cell><cell>2525.2</cell><cell>200.4582</cell><cell cols="2">357.1172</cell><cell cols="2">35.7117</cell><cell></cell><cell>252.5200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Results for the convergence rate test of QPSO-Type 2.</figDesc><table><row><cell></cell><cell>400</cell><cell>6.3710</cell><cell>1.9311eÀ05</cell><cell>0.9772</cell><cell>0.9687</cell><cell>À0.1306</cell><cell>2.8309</cell><cell>4.5267eÀ05</cell><cell>0.9867</cell><cell>0.9728</cell><cell>À0.1513</cell></row><row><cell>3</cell><cell>600</cell><cell>19.1981</cell><cell>4.7244eÀ06</cell><cell>0.9810</cell><cell>0.9750</cell><cell>À0.1089</cell><cell>11.1715</cell><cell>2.8342eÀ04</cell><cell>0.9876</cell><cell>0.9825</cell><cell>À0.1341</cell></row><row><cell>4</cell><cell>800</cell><cell>32.2220</cell><cell>3.5506eÀ06</cell><cell>0.9842</cell><cell>0.9802</cell><cell>À0.0893</cell><cell>23.8846</cell><cell>2.5734eÀ04</cell><cell>0.9900</cell><cell>0.9858</cell><cell>À0.1333</cell></row><row><cell>5</cell><cell>1000</cell><cell>52.0046</cell><cell>6.6324eÀ06</cell><cell>0.9869</cell><cell>0.9843</cell><cell>À0.0734</cell><cell>44.3261</cell><cell>6.8896eÀ04</cell><cell>0.9912</cell><cell>0.9890</cell><cell>À0.1052</cell></row><row><cell>6</cell><cell>1200</cell><cell>74.4027</cell><cell>1.3265eÀ05</cell><cell>0.9887</cell><cell>0.9871</cell><cell>À0.0830</cell><cell>63.5427</cell><cell>6.9010eÀ04</cell><cell>0.9926</cell><cell>0.9905</cell><cell>À0.1120</cell></row><row><cell>7</cell><cell>1400</cell><cell>104.7848</cell><cell>1.3256eÀ05</cell><cell>0.9902</cell><cell>0.9887</cell><cell>À0.0870</cell><cell>82.9243</cell><cell>0.0012</cell><cell>0.9936</cell><cell>0.9921</cell><cell>À0.0999</cell></row><row><cell>8</cell><cell>1600</cell><cell>119.6822</cell><cell>1.7295eÀ05</cell><cell>0.9918</cell><cell>0.9902</cell><cell>À0.0745</cell><cell>103.6366</cell><cell>0.0027</cell><cell>0.9943</cell><cell>0.9934</cell><cell>À0.1009</cell></row><row><cell>9</cell><cell>1800</cell><cell>145.3857</cell><cell>7.2877eÀ05</cell><cell>0.9926</cell><cell>0.9920</cell><cell>À0.0710</cell><cell>127.3277</cell><cell>0.0032</cell><cell>0.9950</cell><cell>0.9941</cell><cell>À0.0924</cell></row><row><cell>10</cell><cell>2000</cell><cell>166.8939</cell><cell>6.9944eÀ05</cell><cell>0.9933</cell><cell>0.9927</cell><cell>À0.0581</cell><cell>139.2103</cell><cell>0.0046</cell><cell>0.9954</cell><cell>0.9949</cell><cell>À0.0848</cell></row><row><cell>N</cell><cell>n max</cell><cell>M = 20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>M = 40</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>Results for the convergence rate test of PSO.</figDesc><table><row><cell></cell><cell></cell><cell>6.2432</cell><cell>2.2060eÀ05</cell><cell>0.9845</cell><cell>0.9691</cell><cell>À0.2165</cell><cell>3.5850</cell><cell>4.2072eÀ04</cell><cell>0.9883</cell><cell>0.9776</cell><cell>À0.2589</cell></row><row><cell>3</cell><cell>600</cell><cell>14.0202</cell><cell>1.2962eÀ05</cell><cell>0.9864</cell><cell>0.9771</cell><cell>À0.2134</cell><cell>12.6022</cell><cell>0.0012</cell><cell>0.9898</cell><cell>0.9847</cell><cell>À0.2304</cell></row><row><cell>4</cell><cell>800</cell><cell>33.3147</cell><cell>1.7636eÀ05</cell><cell>0.9867</cell><cell>0.9821</cell><cell>À0.1644</cell><cell>25.9027</cell><cell>0.0019</cell><cell>0.9920</cell><cell>0.9882</cell><cell>À0.2289</cell></row><row><cell>5</cell><cell>1000</cell><cell>50.7010</cell><cell>7.1771eÀ06</cell><cell>0.9881</cell><cell>0.9844</cell><cell>À0.1579</cell><cell>43.9053</cell><cell>0.0012</cell><cell>0.9927</cell><cell>0.9895</cell><cell>À0.1910</cell></row><row><cell>6</cell><cell>1200</cell><cell>68.6281</cell><cell>4.2896eÀ06</cell><cell>0.9889</cell><cell>0.9863</cell><cell>À0.1405</cell><cell>62.3872</cell><cell>0.0018</cell><cell>0.9933</cell><cell>0.9913</cell><cell>À0.1529</cell></row><row><cell>7</cell><cell>1400</cell><cell>100.3869</cell><cell>2.6875eÀ06</cell><cell>0.9899</cell><cell>0.9876</cell><cell>À0.1410</cell><cell>87.6376</cell><cell>0.0020</cell><cell>0.9939</cell><cell>0.9924</cell><cell>À0.1633</cell></row><row><cell>8</cell><cell>1600</cell><cell>132.1488</cell><cell>2.1607eÀ06</cell><cell>0.9910</cell><cell>0.9889</cell><cell>À0.1244</cell><cell>100.1323</cell><cell>0.0023</cell><cell>0.9945</cell><cell>0.9933</cell><cell>À0.1700</cell></row><row><cell>9</cell><cell>1800</cell><cell>144.2586</cell><cell>1.5950eÀ06</cell><cell>0.9915</cell><cell>0.9899</cell><cell>À0.1090</cell><cell>119.0672</cell><cell>0.0013</cell><cell>0.9951</cell><cell>0.9937</cell><cell>À0.1329</cell></row><row><cell>10</cell><cell>2000</cell><cell>172.0399</cell><cell>1.7459eÀ06</cell><cell>0.9921</cell><cell>0.9908</cell><cell>À0.0782</cell><cell>154.5341</cell><cell>0.0017</cell><cell>0.9951</cell><cell>0.9943</cell><cell>À0.1274</cell></row><row><cell>N</cell><cell>n max</cell><cell>M = 20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>M = 40</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7</head><label>7</label><figDesc>Experimental results of mean best fitness values and standard deviations by algorithms and problems, F 1 to F 5 (best results in bold).</figDesc><table><row><cell>Algorithms</cell><cell>F 1</cell><cell>F 2</cell><cell>F 3</cell><cell>F 4</cell><cell>F 5</cell></row><row><cell>In-PSO (Std. Dev.)</cell><cell>3.8773eÀ013</cell><cell>785.0932</cell><cell>3.9733e+07</cell><cell>1.1249e+04</cell><cell>6.0547e+03</cell></row><row><cell></cell><cell>(1.6083eÀ012)</cell><cell>(661.2154)</cell><cell>(4.6433e+07)</cell><cell>(5.4394e+03)</cell><cell>(2.0346e+03)</cell></row><row><cell>PSO-Co</cell><cell>1.5713eÀ026</cell><cell>0.1267</cell><cell>8.6472e+06</cell><cell>1.3219e+04</cell><cell>7.6892e+03</cell></row><row><cell></cell><cell>(1.4427eÀ025)</cell><cell>(0.3796)</cell><cell>(9.1219e+06)</cell><cell>(6.0874e+03)</cell><cell>(2.3917e+03)</cell></row><row><cell>Standard PSO</cell><cell>8.2929eÀ026</cell><cell>78.2831</cell><cell>6.6185e+06</cell><cell>1.3312e+04</cell><cell>6.2884e+03</cell></row><row><cell></cell><cell>(1.2289eÀ025)</cell><cell>(52.3272)</cell><cell>(3.0124e+06)</cell><cell>(4.1076e+03)</cell><cell>(1.4318e+03)</cell></row><row><cell>Gaussian PSO</cell><cell>7.3661eÀ026</cell><cell>0.0988</cell><cell>1.1669e+07</cell><cell>2.3982e+04</cell><cell>8.0279e+03</cell></row><row><cell></cell><cell>(5.9181eÀ025)</cell><cell>(0.3362)</cell><cell>(2.5153e+07)</cell><cell>(1.2512e+04)</cell><cell>(2.3704e+03)</cell></row><row><cell>Gaussian Bare Bones PSO</cell><cell>1.7869eÀ025</cell><cell>16.8751</cell><cell>7.7940e+06</cell><cell>1.1405e+04</cell><cell>9.5814e+03</cell></row><row><cell></cell><cell>(8.4585eÀ025)</cell><cell>(16.2021)</cell><cell>(4.3240e+06)</cell><cell>(6.7712e+03)</cell><cell>(3.0227e+03)</cell></row><row><cell>PSO-E</cell><cell>5.2531eÀ024</cell><cell>20.2750</cell><cell>6.2852e+06</cell><cell>8.2706e+03</cell><cell>7.2562e+03</cell></row><row><cell></cell><cell>(2.2395eÀ023)</cell><cell>(15.2414)</cell><cell>(2.8036e+06)</cell><cell>(3.6254e+03)</cell><cell>(1.8666e+03)</cell></row><row><cell>Lévy PSO</cell><cell>1.1880eÀ024</cell><cell>36.9986</cell><cell>1.7366e+07</cell><cell>7.4842e+03</cell><cell>8.2543e+03</cell></row><row><cell></cell><cell>(1.1455eÀ023)</cell><cell>(29.1360)</cell><cell>(1.9001e+07)</cell><cell>(6.6588e+03)</cell><cell>(2.2297e+03)</cell></row><row><cell>CLPSO</cell><cell>3.5515eÀ008</cell><cell>5.3394e+03</cell><cell>5.1434e+07</cell><cell>1.6069e+04</cell><cell>5.4958e+003</cell></row><row><cell></cell><cell>(2.2423eÀ008)</cell><cell>(1.2207e+03)</cell><cell>(1.3489e+07)</cell><cell>(3.4776e+03)</cell><cell>(888.9618)</cell></row><row><cell>DMS-PSO</cell><cell>7.2525eÀ006</cell><cell>844.9978</cell><cell>1.2841e+07</cell><cell>2.7125e+003</cell><cell>2.9189e+003</cell></row><row><cell></cell><cell>(2.2114eÀ005)</cell><cell>(350.2620)</cell><cell>(4.9745e+06)</cell><cell>(972.8958)</cell><cell>(811.5164)</cell></row><row><cell>FIPS</cell><cell>3.3157eÀ027</cell><cell>75.4903</cell><cell>1.0409e+07</cell><cell>1.0529e+04</cell><cell>4.3452e+003</cell></row><row><cell></cell><cell>(2.5732eÀ028)</cell><cell>(76.1305)</cell><cell>(4.4786e+06)</cell><cell>(3.8510e+03)</cell><cell>(978.6149)</cell></row><row><cell>QPSO-Type 1 (a = 1.00)</cell><cell>3.5936eÀ028</cell><cell>40.2282</cell><cell>4.8847e+06</cell><cell>6.2397e+03</cell><cell>8.0749e+03</cell></row><row><cell></cell><cell>(1.5180eÀ028)</cell><cell>(23.3222)</cell><cell>(2.1489e+06)</cell><cell>(2.4129e+03)</cell><cell>(1.7099e+03)</cell></row><row><cell>QPSO-Type 1 (a = 1.00 ? 0.90)</cell><cell>5.0866eÀ029</cell><cell>4.5003</cell><cell>3.2820e+06</cell><cell>6.4303e+03</cell><cell>7.8471e+03</cell></row><row><cell></cell><cell>(4.4076eÀ029)</cell><cell>(2.9147)</cell><cell>(1.9953e+06)</cell><cell>(2.9744e+03)</cell><cell>(1.7878e+03)</cell></row><row><cell>QPSO-Type 2 (a = 0.75)</cell><cell>1.9838eÀ027</cell><cell>0.1771</cell><cell>1.6559e+06</cell><cell>3.1321e+03</cell><cell>5.7853e+03</cell></row><row><cell></cell><cell>(5.2716eÀ028)</cell><cell>(0.1137)</cell><cell>(7.1264e+05)</cell><cell>(2.0222e+03)</cell><cell>(1.2483e+03)</cell></row><row><cell>QPSO-Type 2 (a = 1.0 ? 0.5)</cell><cell>1.2672eÀ027</cell><cell>120.6051</cell><cell>4.4257e+06</cell><cell>4.0049e+03</cell><cell>3.3684e+003</cell></row><row><cell></cell><cell>(3.7147eÀ028)</cell><cell>(62.2340)</cell><cell>(2.3302e+06)</cell><cell>(2.7218e+03)</cell><cell>(975.6551)</cell></row><row><cell>QPSO-RM (a = 0.54)</cell><cell>3.1554eÀ036</cell><cell>0.0715</cell><cell>1.8544e+06</cell><cell>3.1443e+03</cell><cell>5.7144e+03</cell></row><row><cell></cell><cell>(2.3913eÀ036)</cell><cell>( 0.0530)</cell><cell>(6.4710e+05)</cell><cell>(3.8785e+03)</cell><cell>(1.4898e+003)</cell></row><row><cell>QPSO-RM (a = 0.6 ? 0.5)</cell><cell>2.6728eÀ035</cell><cell>1.4099</cell><cell>2.1737e+06</cell><cell>2.1835e+003</cell><cell>4.3398e+03</cell></row><row><cell></cell><cell>(6.5932eÀ035)</cell><cell>(7.8582)</cell><cell>(1.0089e+06)</cell><cell>(2.8487e+003)</cell><cell>(1.4313e+03)</cell></row><row><cell>QPSO-RO (a = 0.68)</cell><cell>1.5414eÀ027</cell><cell>0.1784</cell><cell>1.6309e+006</cell><cell>1.9489e+003</cell><cell>5.2202e+003</cell></row><row><cell></cell><cell>(2.9964eÀ028)</cell><cell>(0.1217)</cell><cell>(8.7302e+005)</cell><cell>( 1.6002e+003)</cell><cell>(1.2661e+003)</cell></row><row><cell>QPSO-RO (a = 0.9 ? 0.5)</cell><cell>1.0747eÀ027</cell><cell>50.9939</cell><cell>4.7718e+006</cell><cell>2.1540e+003</cell><cell>2.7469e+003</cell></row><row><cell></cell><cell>(2.3154eÀ028)</cell><cell>(48.6055)</cell><cell>(2.0760e+006)</cell><cell>(1.3635e+003)</cell><cell>(723.4961)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8</head><label>8</label><figDesc>Experimental results of mean best fitness values and standard deviations by algorithms and problems, F 6 to F 10 (best results in bold).</figDesc><table><row><cell>Algorithms</cell><cell></cell><cell>F 6</cell><cell></cell><cell>F 7</cell><cell></cell><cell></cell><cell>F 8</cell><cell></cell><cell></cell><cell>F 9</cell><cell></cell><cell>F 10</cell></row><row><cell>In-PSO (Std. Dev.)</cell><cell></cell><cell cols="2">263.7252</cell><cell cols="2">0.9907</cell><cell></cell><cell cols="2">0.0414</cell><cell></cell><cell cols="2">39.5528</cell><cell>239.5814</cell></row><row><cell></cell><cell></cell><cell cols="2">(437.4145)</cell><cell cols="2">(4.7802)</cell><cell></cell><cell cols="2">(0.2393)</cell><cell></cell><cell cols="2">(16.1654)</cell><cell>(72.2521)</cell></row><row><cell>Co-PSO</cell><cell></cell><cell cols="2">123.0243</cell><cell cols="2">0.0255</cell><cell></cell><cell cols="2">5.1120</cell><cell></cell><cell cols="2">96.7296</cell><cell>171.6488</cell></row><row><cell></cell><cell></cell><cell cols="2">(266.2520)</cell><cell cols="2">(0.0327)</cell><cell></cell><cell cols="2">(4.5667)</cell><cell></cell><cell cols="2">(28.0712)</cell><cell>(58.5713)</cell></row><row><cell>Standard PSO</cell><cell></cell><cell cols="2">153.5178</cell><cell cols="2">0.0218</cell><cell></cell><cell cols="2">0.2744</cell><cell></cell><cell cols="2">79.1219</cell><cell>128.9865</cell></row><row><cell></cell><cell></cell><cell cols="2">(246.1049)</cell><cell cols="2">(0.0165)</cell><cell></cell><cell cols="2">(0.6795)</cell><cell></cell><cell cols="2">(20.2619)</cell><cell>(32.3662)</cell></row><row><cell>Gaussian PSO</cell><cell></cell><cell cols="2">150.7872</cell><cell cols="2">0.0224</cell><cell></cell><cell cols="2">2.7722</cell><cell></cell><cell cols="2">103.6245</cell><cell>184.2657</cell></row><row><cell></cell><cell></cell><cell cols="2">(303.3368)</cell><cell cols="2">(0.0178)</cell><cell></cell><cell cols="2">(1.4603)</cell><cell></cell><cell cols="2">(28.6113)</cell><cell>(57.3675)</cell></row><row><cell>Gaussian Bare Bones PSO</cell><cell></cell><cell cols="2">144.1377</cell><cell cols="2">0.0205</cell><cell></cell><cell cols="2">3.5460</cell><cell></cell><cell cols="2">80.9496</cell><cell>164.2914</cell></row><row><cell></cell><cell></cell><cell cols="2">(165.2616)</cell><cell cols="2">(0.0208)</cell><cell></cell><cell cols="2">(6.1929)</cell><cell></cell><cell cols="2">(22.0621)</cell><cell>(72.8542)</cell></row><row><cell>PSO-E</cell><cell></cell><cell cols="2">189.8292</cell><cell cols="2">0.0493</cell><cell></cell><cell cols="2">3.5881</cell><cell></cell><cell cols="2">66.5112</cell><cell>163.7187</cell></row><row><cell></cell><cell></cell><cell cols="2">(375.8636)</cell><cell cols="2">(0.0538)</cell><cell></cell><cell cols="2">(5.5286)</cell><cell></cell><cell cols="2">(20.9853)</cell><cell>(55.0921)</cell></row><row><cell>Lévy PSO</cell><cell></cell><cell cols="2">133.9526</cell><cell cols="2">0.0446</cell><cell></cell><cell cols="2">2.2168</cell><cell></cell><cell cols="2">74.0446</cell><cell>154.3838</cell></row><row><cell></cell><cell></cell><cell cols="2">(293.8460)</cell><cell cols="2">(0.1182)</cell><cell></cell><cell cols="2">(1.3575)</cell><cell></cell><cell cols="2">(21.6913)</cell><cell>(76.3070)</cell></row><row><cell>CLPSO</cell><cell></cell><cell cols="2">117.3987</cell><cell cols="2">2.4151</cell><cell></cell><cell cols="2">1.1582eÀ04</cell><cell></cell><cell></cell><cell>0.6990</cell><cell>151.2854</cell></row><row><cell></cell><cell></cell><cell cols="2">(54.8846)</cell><cell cols="2">(0.7533)</cell><cell></cell><cell cols="2">(6.7878eÀ05)</cell><cell></cell><cell cols="2">(0.7983)</cell><cell>(23.4628)</cell></row><row><cell>DMS-PSO</cell><cell></cell><cell cols="2">296.0911</cell><cell cols="2">0.3985</cell><cell></cell><cell cols="2">0.1213</cell><cell></cell><cell cols="2">39.9694</cell><cell>112.8426</cell></row><row><cell></cell><cell></cell><cell cols="2">(347.1682)</cell><cell cols="2">(0.2502)</cell><cell></cell><cell cols="2">(0.3716)</cell><cell></cell><cell cols="2">(10.2384)</cell><cell>(71.2957)</cell></row><row><cell>FIPS</cell><cell></cell><cell cols="2">188.8304</cell><cell cols="2">0.0330</cell><cell></cell><cell cols="2">0.3843</cell><cell></cell><cell cols="2">64.6289</cell><cell>198.3699</cell></row><row><cell></cell><cell></cell><cell cols="2">(294.0374)</cell><cell cols="2">(0.0464)</cell><cell></cell><cell cols="2">(0.5713)</cell><cell></cell><cell cols="2">(14.5907)</cell><cell>(21.7958)</cell></row><row><cell>QPSO-Type 1 (a = 1.00)</cell><cell></cell><cell cols="2">138.0746</cell><cell cols="2">0.0218</cell><cell></cell><cell cols="2">0.1217</cell><cell></cell><cell cols="2">56.4232</cell><cell>137.0334</cell></row><row><cell></cell><cell></cell><cell cols="2">(209.1735)</cell><cell cols="2">(0.0204)</cell><cell></cell><cell cols="2">(0.4504)</cell><cell></cell><cell cols="2">(16.7090)</cell><cell>(38.5269)</cell></row><row><cell>QPSO-Type 1 (a = 1.10 ? 0.90)</cell><cell></cell><cell cols="2">139.9815</cell><cell cols="2">0.0209</cell><cell></cell><cell cols="2">0.0916</cell><cell></cell><cell cols="2">54.4278</cell><cell>126.1298</cell></row><row><cell></cell><cell></cell><cell cols="2">(206.8138)</cell><cell cols="2">(0.0203)</cell><cell></cell><cell cols="2">(0.3166)</cell><cell></cell><cell cols="2">(16.6044)</cell><cell>(44.9531)</cell></row><row><cell>QPSO-Type 2 (a = 0.75)</cell><cell></cell><cell cols="2">82.9908</cell><cell cols="2">0.0203</cell><cell></cell><cell cols="2">0.0683</cell><cell></cell><cell cols="2">39.0991</cell><cell>128.5351</cell></row><row><cell></cell><cell></cell><cell cols="2">(119.836)</cell><cell cols="2">(0.0164)</cell><cell></cell><cell cols="2">(0.3080)</cell><cell></cell><cell cols="2">(12.4904)</cell><cell>(57.6255)</cell></row><row><cell>QPSO-Type 2 (a = 1.0 ? 0.5)</cell><cell></cell><cell cols="2">88.0494</cell><cell cols="2">0.0208</cell><cell></cell><cell cols="2">2.0961eÀ014</cell><cell></cell><cell cols="2">29.9218</cell><cell>118.4549</cell></row><row><cell></cell><cell></cell><cell cols="2">(159.7481)</cell><cell cols="2">(0.0130)</cell><cell></cell><cell cols="2">(1.9099eÀ014)</cell><cell></cell><cell cols="2">(10.5736)</cell><cell>(53.0216)</cell></row><row><cell>QPSO-RM (a = 0.54)</cell><cell></cell><cell cols="2">105.7474</cell><cell cols="2">0.0163</cell><cell></cell><cell cols="2">0.0762</cell><cell></cell><cell cols="2">42.4817</cell><cell>185.6351</cell></row><row><cell></cell><cell></cell><cell cols="2">(155.4583)</cell><cell cols="2">(0.0134)</cell><cell></cell><cell cols="2">(0.3075)</cell><cell></cell><cell cols="2">(12.1384)</cell><cell>(46.6356)</cell></row><row><cell>QPSO-RM (a = 0.6 ? 0.5)</cell><cell></cell><cell cols="2">89.6543</cell><cell cols="2">0.0150</cell><cell></cell><cell cols="2">7.5318eÀ015</cell><cell></cell><cell cols="2">43.8327</cell><cell>207.0548</cell></row><row><cell></cell><cell></cell><cell cols="2">(151.6908)</cell><cell cols="2">(0.0119)</cell><cell></cell><cell cols="2">( 1.7046eÀ015)</cell><cell></cell><cell cols="2">(17.881)</cell><cell>(14.4658)</cell></row><row><cell>QPSO-RO (a = 0.68)</cell><cell></cell><cell cols="2">63.9916</cell><cell cols="2">0.0219</cell><cell></cell><cell cols="2">0.0536</cell><cell></cell><cell cols="2">34.5288</cell><cell>159.9417</cell></row><row><cell></cell><cell></cell><cell cols="2">(65.7906)</cell><cell cols="2">(0.0292)</cell><cell></cell><cell cols="2">(0.2653)</cell><cell></cell><cell cols="2">(15.0725)</cell><cell>(36.2107)</cell></row><row><cell>QPSO-RO (a = 0.9 ? 0.5)</cell><cell></cell><cell cols="2">61.0752</cell><cell cols="2">0.0196</cell><cell></cell><cell cols="2">1.9611eÀ014</cell><cell></cell><cell cols="2">23.3014</cell><cell>143.4452</cell></row><row><cell></cell><cell></cell><cell cols="2">(72.2629)</cell><cell cols="2">(0.0152)</cell><cell></cell><cell cols="2">(1.5498eÀ014)</cell><cell></cell><cell cols="2">(7.6051)</cell><cell>(43.9709)</cell></row><row><cell>Table 9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ranking by algorithms and problems.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Algorithms</cell><cell>F 1</cell><cell>F 2</cell><cell>F 3</cell><cell>F 4</cell><cell>F 5</cell><cell>F 6</cell><cell>F 7</cell><cell>F 8</cell><cell>F 9</cell><cell>F 10</cell><cell>Total rank</cell><cell>Average rank</cell></row><row><cell>PSO-In</cell><cell>16</cell><cell>=16</cell><cell>17</cell><cell>=12</cell><cell>=9</cell><cell>=17</cell><cell>17</cell><cell>=1</cell><cell>=5</cell><cell>18</cell><cell>128</cell><cell>12.8</cell></row><row><cell>PSO-Co</cell><cell>=10</cell><cell>=1</cell><cell>=11</cell><cell>=15</cell><cell>=11</cell><cell>=7</cell><cell>=4</cell><cell>18</cell><cell>=17</cell><cell>=11</cell><cell>105</cell><cell>10.5</cell></row><row><cell>Standard PSO</cell><cell>=10</cell><cell>=13</cell><cell>=9</cell><cell>=15</cell><cell>=11</cell><cell>=7</cell><cell>=4</cell><cell>=10</cell><cell>=14</cell><cell>=1</cell><cell>94</cell><cell>9.4</cell></row><row><cell>Gaussian PSO</cell><cell>=10</cell><cell>=1</cell><cell>=11</cell><cell>18</cell><cell>=15</cell><cell>=7</cell><cell>=4</cell><cell>=14</cell><cell>=17</cell><cell>=11</cell><cell>108</cell><cell>10.8</cell></row><row><cell>Gaussian Bare Bones PSO</cell><cell>=13</cell><cell>=8</cell><cell>=11</cell><cell>=12</cell><cell>18</cell><cell>=7</cell><cell>=4</cell><cell>=14</cell><cell>=14</cell><cell>=11</cell><cell>112</cell><cell>11.2</cell></row><row><cell>PSO-E</cell><cell>=13</cell><cell>=8</cell><cell>=9</cell><cell>11</cell><cell>=11</cell><cell>=7</cell><cell>=13</cell><cell>=14</cell><cell>=12</cell><cell>=11</cell><cell>109</cell><cell>10.9</cell></row><row><cell>Lévy PSO</cell><cell>15</cell><cell>=10</cell><cell>16</cell><cell>=8</cell><cell>=15</cell><cell>=7</cell><cell>=13</cell><cell>=14</cell><cell>=14</cell><cell>=6</cell><cell>118</cell><cell>11.8</cell></row><row><cell>CLPSO</cell><cell>17</cell><cell>18</cell><cell>18</cell><cell>17</cell><cell>=6</cell><cell>=7</cell><cell>18</cell><cell>=10</cell><cell>1</cell><cell>=6</cell><cell>118</cell><cell>11.8</cell></row><row><cell>DMS-PSO</cell><cell>18</cell><cell>=16</cell><cell>=11</cell><cell>=4</cell><cell>=1</cell><cell>=17</cell><cell>16</cell><cell>=1</cell><cell>=5</cell><cell>=1</cell><cell>90</cell><cell>9.0</cell></row><row><cell>FIPS</cell><cell>9</cell><cell>=13</cell><cell>=11</cell><cell>=12</cell><cell>=4</cell><cell>=7</cell><cell>=13</cell><cell>13</cell><cell>=12</cell><cell>16</cell><cell>110</cell><cell>11.0</cell></row><row><cell>QPSO-Type 1 (a = 1.00)</cell><cell>4</cell><cell>=10</cell><cell>=6</cell><cell>=8</cell><cell>=15</cell><cell>=7</cell><cell>=4</cell><cell>=10</cell><cell>=10</cell><cell>=6</cell><cell>80</cell><cell>8.0</cell></row><row><cell>QPSO-Type 1 (a = 1.00 ? 0.90)</cell><cell>3</cell><cell>7</cell><cell>5</cell><cell>=8</cell><cell>=11</cell><cell>=7</cell><cell>=4</cell><cell>=1</cell><cell>=10</cell><cell>=1</cell><cell>57</cell><cell>5.7</cell></row><row><cell>QPSO-Type 2 (a = 0.75)</cell><cell>8</cell><cell>=4</cell><cell>=1</cell><cell>=4</cell><cell>=9</cell><cell>=1</cell><cell>=4</cell><cell>=1</cell><cell>=5</cell><cell>=1</cell><cell>38</cell><cell>3.8</cell></row><row><cell>QPSO-Type 2 (a = 1.00 ? 0.5)</cell><cell>6</cell><cell>15</cell><cell>=6</cell><cell>7</cell><cell>3</cell><cell>=1</cell><cell>=4</cell><cell>=1</cell><cell>=3</cell><cell>=1</cell><cell>47</cell><cell>4.7</cell></row><row><cell>QPSO-RM (a = 0.54)</cell><cell>1</cell><cell>=1</cell><cell>=1</cell><cell>=4</cell><cell>=6</cell><cell>=1</cell><cell>=1</cell><cell>=1</cell><cell>=5</cell><cell>17</cell><cell>38</cell><cell>3.8</cell></row><row><cell>QPSO-RM (a = 0.6 ? 0.5)</cell><cell>2</cell><cell>=4</cell><cell>4</cell><cell>=1</cell><cell>=4</cell><cell>=1</cell><cell>=1</cell><cell>=1</cell><cell>=5</cell><cell>=11</cell><cell>34</cell><cell>3.4</cell></row><row><cell>QPSO-RO (a = 0.68)</cell><cell>7</cell><cell>=4</cell><cell>=1</cell><cell>=1</cell><cell>=6</cell><cell>=1</cell><cell>=4</cell><cell>=1</cell><cell>=3</cell><cell>=6</cell><cell>34</cell><cell>3.4</cell></row><row><cell>QPSO-RO (a = 0.9 ? 0.5)</cell><cell>5</cell><cell>=10</cell><cell>=6</cell><cell>=1</cell><cell>=1</cell><cell>=1</cell><cell>=1</cell><cell>=1</cell><cell>2</cell><cell>=6</cell><cell>34</cell><cell>3.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>, we have, F xÃ;T n x 0 ðtÞ ¼ F T nÃ xÃ;T mnÃ þs x 0 ðtÞ P F xÃ;T ðmÀ1ÞnÃ þs x 0</figDesc><table><row><cell></cell><cell></cell><cell>t k</cell><cell>P Á Á Á P F xÃ;T s x 0</cell><cell>t k m</cell><cell>; 8t P 0:</cell></row><row><cell>m!1</cell><cell>F xÃ;T s x 0</cell><cell>t k</cell><cell></cell></row></table><note><p><p>ðA9Þ</p>Let m ? 1 on the rightmost side of (A9). Thus n ? 1 on the leftmost side the inequality, and we obtain lim n!1 F xÃ;T n x 0 ðtÞ P lim m ¼ 1; 8t P 0;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Thus we have a n ðtÞ ¼ Pff n 2 VðtÞ; f k R VðtÞ; k ¼ 1; 2; . . . ; n À 1g ¼ g n ðtÞF fn;fÃ ðtÞ ¼ Pfjf n À f Ã j &lt; tg ¼ Pff n 2 VðtÞg ¼</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Y nÀ1</cell><cell>½1 À g nÀ1 ðtÞ:</cell><cell>ðA13Þ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>i¼0</cell></row><row><cell>Accordingly,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>X n</cell><cell cols="3">a n ðtÞ ¼ 1 À</cell><cell>Y n ½1 À g i ðtÞ:</cell></row><row><cell></cell><cell></cell><cell></cell><cell>i¼0</cell><cell></cell><cell></cell><cell>i¼1</cell></row><row><cell>Z</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1 À</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y N j¼1</cell><cell>Z G j n P j i;n</cell><cell>1 i;n L j</cell><cell cols="2">exp À2jx À pj=L j i;n</cell><cell>dp</cell><cell>:</cell></row></table><note><p>SðtÞ h X i;n ðG nÀ1 ; P i;nÀ1 ; xÞ dx " # ; where h X i;n ðG nÀ1 ; P i;n ; xÞ ¼</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J. Sun et al. / Information Sciences 193 (2012) 81-103</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>J. Sun et al. / Information Sciences 193 (2012) 81-103</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by the National Natural Science Foundation of China (Project Numbers: 61170119, 60973094), by the Natural Science Foundation of Jiangsu Province, China (Project Number: BK2010143), by the Fundamental Research Funds for the Central Universities (Project Numbers: JUSRP21012, JUSRP11023), and by the Foundation of Key Laboratory of Advanced Process Control for Light Industry (Jiangnan University), Ministry of Education, PR China.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A Theorem 1. Let a self-mapping T: (E, F, D) ? (E, F, D) be the contraction mapping in Definition 7. If for every x 2 E, O T (x; 0, 1) is probabilistic bounded, then there exists a unique common fixed point x ⁄ in E for T, and for every x 0 2 E, the iterative sequence {T n x 0 } converges to x ⁄ in T .</p><p>Proof. The proof of the theorem is achieved through the following two steps.</p><p>(1) First, we prove that for every x 0 2 E, the sequence fx m g 1 m¼0 is a T -Cauchy Sequence in E, where fx m g 1 m¼0 ¼ fx 0 ; x 1 ¼ T nðx 0 Þ x 0 ; . . . ; x mþ1 ¼ T nðxmÞ x m ; . . .g: ðA1Þ</p><p>Let n i = n(x i ), where i = 0, 1, 2, . . ., and let m and i are two arbitrary positive integers. From ( <ref type="formula">18</ref>) and (A1), we have</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evolutionary optimization versus particle swarm optimization: philosophy and performance differences. Evolutionary programming VII</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">1447</biblScope>
			<biblScope unit="page" from="601" to="610" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using selection to improve particle swarm optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Angeline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 IEEE International Conference on Evolutionary Computation, ICEC 1998</title>
		<meeting>the 1998 IEEE International Conference on Evolutionary Computation, ICEC 1998<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="84" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards pure adaptive search</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Baritompa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Mlandineo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Zambinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="93" to="110" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Defining a standard for particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bratton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE Swarm Intelligence Symposium</title>
		<meeting>the 2007 IEEE Swarm Intelligence Symposium</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<title level="m">An Analysis of Particle Swarm Optimizers</title>
		<meeting><address><addrLine>Pretoria, South Africa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Univ. Pretoria</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A cooperative approach to particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="225" to="239" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Toward a theory of evolution strategies: on the benefits of sex-the (l/l,k) theory</title>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="81" to="111" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On some fixed point theorems in probabilistic metric space and its applications</title>
		<author>
			<persName><forename type="first">S.-S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Probability Theory and Related Fields</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="463" to="474" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Nonlinear Operator Theory in Probabilistic Metric Spaces</title>
		<author>
			<persName><forename type="first">S.-S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Kang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Nova Science Publishers</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The swarm and the queen: towards a deterministic and adaptive particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Congress on Evolutionary Computation</title>
		<meeting>the 1999 Congress on Evolutionary Computation<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1951" to="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The particle swarm-explosion, stability and convergence in a multidimensional complex space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Particle Swarm Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ISTE Publishing Company</publisher>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A novel Gaussian quantum-behaved particle swarm optimizer applied to electromagnetic design</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="290" to="294" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>IET Science</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Global optimization of electromagnetic devices using an exponential quantum-behaved particle swarm optimizer</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Magenetics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1074" to="1077" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A quantum particle swarm optimizer with chaotic mutation operator</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons &amp; Fractals</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1409" to="1418" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Istratescu</surname></persName>
		</author>
		<title level="m">Elements of Probabilistic Analysis with Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparisons of treatments after an analysis of variance in ecology</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Quinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Monographs</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="433" to="463" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Continuous swarm optimization technique with stability analysis</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Emara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A A</forename><surname>Fattah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 American Control Conference</title>
		<meeting>the 2004 American Control Conference<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="2811" to="2817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parameters estimation on-line for Lorenz system by a novel quantum-behaved particle swarm optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Physics B</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1196" to="1201" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stability analysis of social foraging swarms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Passino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="539" to="557" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A comparison of particle swarm optimization and the genetic algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cohanim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>De Weck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference</title>
		<meeting>the 46th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards an analytic framework for analysing the computation time of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="59" to="97" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Drift analysis and average time complexity of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="57" to="85" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">From an individual to a population: an analysis of the first hitting time of population-based evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="495" to="551" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A fixed point theorem for mappings with a probabilistic contractive iterate</title>
		<author>
			<persName><forename type="first">I</forename><surname>Istratescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Romanian Journal of pure and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="431" to="435" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fixed point theorems for contraction mappings on probabilistic metric spaces</title>
		<author>
			<persName><forename type="first">V</forename><surname>Istratescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sacuiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Romanian Journal of pure and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1375" to="1381" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A hierarchical particle swarm optimizer and its adaptive variant</title>
		<author>
			<persName><forename type="first">S</forename><surname>Janson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1272" to="1282" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Part B: Cybernetics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stochastic convergence analysis and parameter selection of the standard particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Comparison of genetic algorithm and particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 International Conference on Computer System and Technologies</title>
		<meeting>the 2005 International Conference on Computer System and Technologies<address><addrLine>Varna, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="A1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stability analysis of the particle dynamics in particle swarm optimizer</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kadirkamanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Selvarajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="245" to="255" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1995 IEEE International Conference on Neural Networks</title>
		<meeting>the 1995 IEEE International Conference on Neural Networks<address><addrLine>Perth, WA, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The behavior of particles</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Annual Conference on Evolutionary Programming</title>
		<meeting>the 7th Annual Conference on Evolutionary Programming<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="581" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Small worlds and mega-minds: effects of neighborhood topology on particle swarm performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Congress on Evolutionary Computation</title>
		<meeting>the 1999 Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1931" to="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stereotyping: improving particle swarm performance with cluster analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Congress on Computational Intelligence</title>
		<meeting>the 2002 Congress on Computational Intelligence<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1671" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bare bones particle swarms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 IEEE Swarm Intelligence Symposium</title>
		<meeting>the 2003 IEEE Swarm Intelligence Symposium<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probability and dynamics in the particle swarm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Congress on Evolutionary Computation</title>
		<meeting>the 2004 Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="page" from="340" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">In search of the essential particle swarm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE World Congress on Computational Intelligence</title>
		<meeting>the IEEE World Congress on Computational Intelligence</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1694" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Gaussian swarm: a novel particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Krohling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Cybernetics and Intelligent Systems</title>
		<meeting>the IEEE Conference on Cybernetics and Intelligent Systems<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-12">December 2004</date>
			<biblScope unit="page" from="372" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">PSO-E: particle swarm with exponential distribution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Krohling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1428" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Some common fixed point theorems for mappings satisfying a new contraction condition in Menger spaces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Sciences</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="227" to="234" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A new model of simulated evolutionary computation-convergence analysis and specification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="3" to="16" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamic multiswarm particle swarm optimizer (DMS-PSO)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 IEEE Swarm Intelligence Symposium</title>
		<meeting>the 2005 IEEE Swarm Intelligence Symposium<address><addrLine>Pasadena, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Comparative research on particle swarm optimization and genetic algorithm</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">D</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer and Information Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="120" to="127" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A new QPSO based BP neural network for face detection</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R.-G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Q</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy Information and Engineering</title>
		<editor>
			<persName><forename type="first">B.-Y</forename><surname>Cao</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
	<note>Advances in Soft Computing</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Menger</surname></persName>
		</author>
		<title level="m">Statistical metrics, Proceedings of the National Academy of Science USA</title>
		<imprint>
			<date type="published" when="1942">1942</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="535" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Quantum particle swarm optimization for electromagnetics</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mikki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Kishk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Antennas and Propagation</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="2764" to="2775" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Neighborhood re-structuring in particle swarm optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Postoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Australian Joint Conference on Artificial Intelligence</title>
		<meeting>the 18th Australian Joint Conference on Artificial Intelligence<address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="776" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Particle swarm optimization and genetic algorithms</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Onet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Control Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="43" to="46" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Particle swami optimization: surfing the waves</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ozcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 IEEE Congress on Evolutionary Computation, CEC&apos;99</title>
		<meeting>the 1999 IEEE Congress on Evolutionary Computation, CEC&apos;99<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1939" to="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Global output convergence of RNN in Menger probabilistic metric space</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 International MultiConference of Engineers and Computer Scientists</title>
		<meeting>the 2008 International MultiConference of Engineers and Computer Scientists</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="101" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Some common fixed point theorems for commuting mappings in Menger spaces</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural &amp; Physical Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Locating and tracking multiple dynamic optima by a particle swarm model using speciation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Parrott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="440" to="458" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Theoretical analysis of evolutionary algorithms with infinite population size in continuous space. Part I: Basic properties</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Palmeiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="102" to="119" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The Levy particle swarm</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Richer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Congress on Evolutionary Computation</title>
		<meeting>the 2006 Congress on Evolutionary Computation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="808" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Local convergence rates of simple evolutionary algorithms with Cauchy mutations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="249" to="258" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">D-boundedness and D-compactness in finite dimensional probabilistic normed spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Saadati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Indian Academy of Science (Math. Sci.)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="483" to="492" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Statistical metric spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schweizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sklar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="313" to="334" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The metrization of statistical metric spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schweizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sklar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Thorp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="673" to="675" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Statistical metric spaces arising from sets of random variables in n-Euclidean spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schweizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sklar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Probability and its Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="447" to="456" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Triangle inequalities in a class of statistical metric spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schweizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sklar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the London Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="401" to="406" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Probabilistic Metric Spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schweizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sklar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Visualizing particle swarm optimization-Gaussian particle swarm optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Secrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lamont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003IEEE Swarm Intelligence Symposium, SIS&apos;03</title>
		<meeting>the 2003IEEE Swarm Intelligence Symposium, SIS&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="198" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Sehgal</surname></persName>
		</author>
		<title level="m">Some Fixed Point Theorems in Functional Analysis and Probability</title>
		<imprint>
			<date type="published" when="1966">1966</date>
		</imprint>
		<respStmt>
			<orgName>Wayne State University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Probabilistic metric spaces</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sempi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopaedia of General Topology</title>
		<editor>
			<persName><forename type="first">K P</forename><surname>Hart</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="288" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">On a probabilistic generalization of metric spaces</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Šerstnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kazanskogo Gosudarstvennogo Universiteta Uchenye Zapiski</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="3" to="11" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 IEEE International Conference on Evolutionary Computation, ICEC&apos;98</title>
		<meeting>the 1998 IEEE International Conference on Evolutionary Computation, ICEC&apos;98<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference on Evolutionary Programming, EP&apos;98</title>
		<meeting>the 7th Conference on Evolutionary Programming, EP&apos;98</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Empirical study of particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Congress on Evolutionary Computation, CEC &apos;99</title>
		<meeting>the 1999 Congress on Evolutionary Computation, CEC &apos;99</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1945" to="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Common fixed point theorems for commuting mappings in probabilistic metric spaces</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Honam Mathematical Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="139" to="150" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Common fixed point theorems in probabilistic metric spaces and extension to uniform spaces</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Honam Mathematical Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">General fixed point theorems in probabilistic metric and uniform space</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Indian Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="9" to="21" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Solis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J-B</forename><surname>Wets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Minimization by random search techniques</title>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Rate of convergence in evolutionary computation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Spall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 American Control Conferences</title>
		<meeting>the 2003 American Control Conferences</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1932" to="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Particle swarm optimizer with neighborhood operator</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Congress on Evolutionary Computation, CEC&apos;99</title>
		<meeting>the 1999 Congress on Evolutionary Computation, CEC&apos;99<address><addrLine>Wasington, DC, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1958" to="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Problem Definitions and Evaluation Criteria for the CEC 2005 Special Session on Real-parameter Optimization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tiwari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-05">May 2005. 2005005</date>
			<pubPlace>Singapore; IIT Kanpur, India</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with particles having quantum behavior</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Congress on Evolutionary Computation, CEC&apos;04</title>
		<meeting>the 2004 Congress on Evolutionary Computation, CEC&apos;04<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="326" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A global search strategy of quantum-behaved particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 IEEE conference on Cybernetics and Intelligent Systems</title>
		<meeting>the 2004 IEEE conference on Cybernetics and Intelligent Systems<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="111" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">AddTaptive parameter control for quantum-behaved particle swarm optimization on individual level</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 IEEE International Conference on Systems, Man and Cybernetics</title>
		<meeting>the 2005 IEEE International Conference on Systems, Man and Cybernetics<address><addrLine>Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="3049" to="3054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Quantum-behaved particle swarm optimization: analysis of the individual particle&apos;s behavior and parameter selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Palade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1162/EVCO_a_00049</idno>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Topologies for probabilistic metric spaces</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Tardiff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="233" to="251" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Generalized topologies for statistical metric spaces</title>
		<author>
			<persName><forename type="first">E</forename><surname>Thorp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundamenta Mathematicae</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="9" to="21" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">The particle swarm optimization algorithm: convergence analysis and parameter selection</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Trelea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="317" to="325" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Logarithmic convergence of random heuristic search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="395" to="404" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Quantum-behaved particle swarm optimization with generalized local search operator for global optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 International Conference on Intelligent Computing</title>
		<meeting>the 2007 International Conference on Intelligent Computing</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="344" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A new approach to estimating the expected first hitting time of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="1809" to="1832" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Pure adaptive search in global optimization</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Zabinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="323" to="338" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Multilevel minimum cross entropy threshold selection based on quantum particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing</title>
		<meeting>the Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="65" to="69" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
