<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Philipos</forename><forename type="middle">C</forename><surname>Loizou</surname></persName>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2724F3D8F60556CAB8284C8BE588022F</idno>
					<idno type="DOI">10.1109/TSA.2005.851929</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech Enhancement Based on Perceptually</head><p>Motivated Bayesian Estimators of the Magnitude Spectrum Philipos C. Loizou, Senior Member, IEEE Abstract-The traditional minimum mean-square error (MMSE) estimator of the short-time spectral amplitude is based on the minimization of the Bayesian squared-error cost function. The squared-error cost function, however, is not subjectively meaningful in that it does not necessarily produce estimators that emphasize spectral peak (formants) information or estimators which take into account auditory masking effects. To overcome the shortcomings of the MMSE estimator, we propose in this paper Bayesian estimators of the short-time spectral magnitude of speech based on perceptually motivated cost functions. In particular, we use variants of speech distortion measures, such as the Itakura-Saito and weighted likelihood-ratio distortion measures, which have been used successfully in speech recognition. Three classes of Bayesian estimators of the speech magnitude spectrum are derived. The first class of estimators emphasizes spectral peak information, the second class uses a weighted-Euclidean cost function that implicitly takes into account auditory masking effects, and the third class of estimators is designed to penalize spectral attenuation. Of the three classes of Bayesian estimators, the estimators that implicitly take into account auditory masking effect performed the best in terms of having less residual noise and better speech quality.</p><p>Index Terms-Minimum mean-square error (MMSE) estimators, perceptually-motivated speech enhancement, speech distortion measures, speech enhancement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>S INGLE-CHANNEL speech enhancement algorithms based on minimum mean-square error (MMSE) estimation of the short-time spectral magnitude have received a lot of attention in the past two decades <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref>, and are often compared against new algorithms. The MMSE estimators have been very popular, partly because they have been shown to be successful in eliminating musical noise <ref type="bibr" target="#b6">[7]</ref>.</p><p>It is known from estimation theory, that the MMSE estimator minimizes the Bayes risk based on a squared-error cost function <ref type="bibr" target="#b7">[8]</ref>. The squared-error cost function is most commonly used because it is mathematically tractable and easy to evaluate. It might not be subjectively meaningful, however, in that small and large squared estimation errors might not necessarily correspond to good and poor speech quality respectively. Also, the squared Manuscript received June 24, 2004; revised <ref type="bibr">July 17, 2004</ref>. This work was supported by NIDCD/NIH. The Associate Editor coordinating the review of this manuscript and approving it for publication was Prof. Bayya Yegnanarayana.</p><p>The author is with the Department of Electrical Engineering, University of Texas-Dallas, Richardson, TX 75083-0688 USA (e-mail: loizou@utdallas.edu).</p><p>Digital Object Identifier 10.1109/TSA.2005.851929 error criterion might not necessarily produce estimators that preserve spectral peak (formant) information or estimators that take into account auditory masking effects. Lastly, the squared error cost function treats positive and negative estimation errors the same way. But the perceptual effect of positive error (i.e., the estimated magnitude is smaller than the true magnitude) and negative error (i.e., the estimated magnitude is larger than the true magnitude) is not the same in speech enhancement applications. Hence, the positive and negative errors need not be weighted equally.</p><p>To overcome the above problems and shortcomings of the squared-error cost function, we propose in this paper Bayesian estimators of the short-time spectral magnitude of speech based on perceptually motivated distortion measures. In particular, we use variants of speech distortion measures, such as the Itakura-Saito and weighted likelihood-ratio distortion measures, which have been applied successfully in speech recognition applications <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>. These distortion measures have been shown to be subjectively more meaningful than the squared error measure and have been applied to speech recognition tasks <ref type="bibr" target="#b11">[12]</ref>.</p><p>Three classes of Bayesian estimators are derived in this paper based on these distortion measures. In the first class, Bayesian estimators are derived that place more emphasis on spectral peaks (formants) than on spectral valleys. In the second class, Bayesian estimators are derived that take into account auditory masking effects. Lastly, in the third class, a Bayesian estimator is derived which preserves weak (low-energy) segments of speech, such as fricatives and stop consonants. This was done by using a distortion measure which penalizes positive estimation errors more than negative errors. MMSE estimators do not typically do well with such low-energy speech segments because of the low segmental SNR associated with such segments.</p><p>This paper is organized as follows. Section II provides an overview of general Bayesian estimators, Section III derives the perceptually motivated Bayesian estimators, Section IV presents the experimental results, and Section V presents the conclusions. , where is the frame length in samples. The above equation can also be expressed in polar form as <ref type="bibr" target="#b1">(2)</ref> where denote the magnitudes and denote the phases at frequency bin of the noisy speech, clean speech and noise respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. GENERAL BAYESIAN ESTIMATORS: BACKGROUND</head><p>In this paper, we are interested in estimating the magnitude spectrum, from the noisy complex speech spectrum, . Let denote the error in estimating the magnitude at frequency bin , and let denote a nonnegative function of . The average cost, i.e., , is known as the Bayes risk , and is given by</p><formula xml:id="formula_0">(3)</formula><p>Minimizing the Bayes risk with respect to for a given cost function results in a variety of estimators. If we use the squared-error cost function in (3), and we minimize the inner integral with respect to , while holding fixed, then we get the traditional MMSE estimator <ref type="bibr" target="#b0">[1]</ref>. If we use the "hit-or-miss" function for , then we get the MAP estimator <ref type="bibr" target="#b7">[8]</ref>. If we use the following cost function: <ref type="bibr" target="#b3">(4)</ref> then we get the log-MMSE estimator <ref type="bibr" target="#b1">[2]</ref>. Non-linear cost functions that incorporated psychoacoustic constraints were proposed in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. However, due to the nonlinearity of the constraints, no closed form solution was derived for the Bayesian estimators <ref type="bibr" target="#b3">[4]</ref>.</p><p>In summary, different Bayesian estimators of can be derived depending on the choice of the cost function. Aside from the cost functions used in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, and the log square-error cost function used in <ref type="bibr" target="#b1">[2]</ref> (since loudness is often modeled by a log function), the squared-error type cost functions used in <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b5">[6]</ref> were not necessarily subjectively meaningful. Next, we derive Bayesian estimators of based on perceptually motivated cost functions in place of the squared-error cost function. We refer to these cost functions as "distortion measures," as they do not necessarily satisfy the metric requirements of symmetry and triangle inequality <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PERCEPTUALLY MOTIVATED BAYESIAN ESTIMATORS OF THE SPEECH MAGNITUDE SPECTRUM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Psychoacoustically Motivated Distortion Measure</head><p>The proposed distortion measure is motivated by the perceptual weighting technique used in low-rate analysis-by-synthesis speech coders <ref type="bibr" target="#b12">[13]</ref>. In most low-rate speech coders (e.g., CELP), the excitation used for LPC synthesis is selected in a closed-loop fashion using a perceptually weighted error criterion <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. This error criterion exploits the masking properties of the auditory system. More specifically, it is based on the fact that the auditory system has a limited ability in detecting quantization noise near the high-energy regions of the spectrum (e.g., near the formant peaks). Quantization noise near the formant peaks is masked by the formant peaks, and is therefore not audible. Auditory masking can be exploited by shaping the frequency spectrum of the error (estimation error in our case) so that less emphasis is placed near the formant peaks and more emphasis is placed on the spectral valleys, where any amount of noise present will be audible. We are referring here to simultaneous masking and not temporal masking (forward or backward masking) which extends in time outside the period the masker is present. Non-stationary masking effects such as forward and backward masking are not modeled in this work.</p><p>In speech coding, the perceptually-weighted error criterion is implemented by weighting the error spectrum with a filter which has the shape of the inverse spectrum of the original signal. That way, spectral peaks are not emphasized as much as spectral valleys. As a crude approximation to this perceptual weighting filter, we considered weighting the estimation error by . We therefore considered the following cost function: <ref type="bibr" target="#b4">(5)</ref> It is clear that the above distortion measure penalizes the estimation error more heavily when is small (spectral valley) than when is large (spectral peak). The following Bayesian risk (corresponding to the inner integral in (3), and denoted henceforth as ) was then minimized <ref type="bibr" target="#b5">(6)</ref> Taking the derivative of with respect to and setting it equal to zero, we get <ref type="bibr" target="#b6">(7)</ref> Solving for we get <ref type="bibr" target="#b7">(8)</ref> Using the Gaussian statistical model, it can be shown (see Appendix A) that evaluates to <ref type="bibr" target="#b8">(9)</ref> where denotes the confluent hypergeometric function [16, eq. 9.210.1],</p><p>denotes the gamma function and . It is easy to show that can also be written as <ref type="bibr" target="#b9">(10)</ref> Fig. <ref type="figure">1</ref>. Plot of the magnitude spectrum, X , of a 30-ms segment of the vowel /iy/ taken from the word "heed" (F1 = 344 Hz, F2 = 2450 Hz). Plots of the spectra X , 1=X and 1=X are superimposed for comparison. The latter spectra are shifted relative to X for better visual clarity.</p><p>where , , , and . Using <ref type="bibr" target="#b9">(10)</ref>, we can also express ( <ref type="formula">9</ref>) as <ref type="bibr" target="#b10">(11)</ref> where</p><p>. The above confluent hypergeometric function can also be written in terms of a Bessel function [17, eq. A1.31b], thereby simplifying the above estimator to <ref type="bibr" target="#b11">(12)</ref> where denotes the modified Bessel function of order zero. It is worthwhile noting that the above estimator becomes the Wiener estimator when . To prove that, after substituting in <ref type="bibr" target="#b11">(12)</ref> the approximation of the Bessel function, (for ), we get <ref type="bibr" target="#b12">(13)</ref> which is the Wiener estimator. Next, we considered generalizing the cost function given in (5) to weigh the estimation error by , i.e., <ref type="bibr" target="#b13">(14)</ref> Note that the above distortion measure emphasizes spectral peaks when , but emphasizes spectral valleys when . This is illustrated in Fig. <ref type="figure">1</ref>. For , the above distortion measure is similar to the model distortion measure proposed by Itakura <ref type="bibr" target="#b10">[11]</ref> for comparing two autoregressive speech models. The cost function used in ( <ref type="formula">5</ref>) is obtained by setting . We refer to the above distortion measure as the weighted Euclidean distortion measure, since it can be written as</p><p>, where is a diagonal matrix, having as the th diagonal element, . Using ( <ref type="formula">14</ref>), the following risk is then minimized:</p><formula xml:id="formula_1">(15)</formula><p>Taking the derivative of with respect to and setting it equal to zero, we get ( <ref type="formula">16</ref>) Solving for we get <ref type="bibr" target="#b16">(17)</ref> Note that the above Bayesian estimator is the ratio of the ( ) moment of the posterior pdf and the th moment of , i.e., it can be written as: . In our case, is not restricted to be an integer, however. Note also that when , we get the traditional MMSE estimator derived in <ref type="bibr" target="#b0">[1]</ref>.</p><p>Using the Gaussian statistical model <ref type="bibr" target="#b0">[1]</ref>, we can show (see Appendix A) that evaluates to (18) The above equation allows us to express in terms of a nonlinear gain function which is a function of both the a priori SNR and posteriori SNR , much like the gain function of the MMSE estimator <ref type="bibr" target="#b0">[1]</ref>. Fig. <ref type="figure" target="#fig_1">2</ref> plots the gain function as a function of the instantaneous SNR (</p><p>) for a fixed value of ( in top panel and in bottom panel ) for several values of the power exponent . For comparative purposes, the gain functions of the MMSE <ref type="bibr" target="#b0">[1]</ref> and log-MMSE <ref type="bibr" target="#b1">[2]</ref> estimators are superimposed. As can be seen, the shape of the gain function is similar to that of the MMSE and log-MMSE gain functions. The amount of attenuation seems to be dependent on the value of the power exponent . Large and positive values of provide small attenuation, while large and negative values of provide heavier attenuation.</p><p>Note that for large values of the gain function converges to the MMSE gain function. In fact, converges to the Wiener gain function for and consequently for . This can be proven by substituting in ( <ref type="formula">18</ref>) the following asymptotic approximation of the confluent hypergeometric function [17, eq. A1.16b]: <ref type="bibr" target="#b18">(19)</ref> In doing so, we get <ref type="bibr" target="#b19">(20)</ref> which is the Wiener estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Itakura-Saito Measure</head><p>The Itakura-Saito measure <ref type="bibr" target="#b17">[18]</ref> has been used successfully in speech recognition for comparing a reference power spectrum against a test spectrum according to (21) Due to its asymmetric nature, the IS measure is known to provide more emphasis on spectral peaks than spectral valleys.</p><p>In this paper, we consider the IS distortion measure between the estimated and true short-time power spectra at the th frequency bin (rather than over the whole spectrum) <ref type="bibr" target="#b21">(22)</ref> Note that , since . It is easy to show that minimization of the following Bayesian risk: <ref type="bibr" target="#b22">(23)</ref> yields the following magnitude-squared estimator <ref type="bibr">(24)</ref> which is also the MMSE estimator of the short-time power spectrum. So, the Bayesian estimator resulting from minimization of the IS distortion measure is the same as the MMSE estimator resulting from minimization of the following distortion measure:</p><p>It is worthwhile noting that minimization of the IS measure based on the magnitude spectra (i.e., ) of the signal, i.e., minimization of the following Bayesian risk:</p><p>(25) results in the MMSE estimator:</p><p>. To verify this, after taking the derivative of given in (25) with respect to , and setting it equal to zero, we get (26)</p><p>After solving for , we get , which is the MMSE estimator of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Measure</head><p>As mentioned earlier, the IS measure is asymmetric since . A symmetric distortion measure was derived in <ref type="bibr" target="#b8">[9]</ref> by combining the two forms of the IS measure to get a new distortion measure, termed measure. The measure considered here is given by (27) The measure was shown in <ref type="bibr" target="#b8">[9]</ref> to be nearly identical to the log spectral distortion ((4)) for small estimation errors but to differ markedly for large errors. This is illustrated in Fig. <ref type="figure" target="#fig_2">3</ref> which plots the measure against the log spectral distortion measure, given in (4). We can therefore conclude that compared to the log spectral difference measure [(4)], the measure penalizes large estimation errors more heavily, but penalizes small estimation errors equally.</p><p>After minimizing the risk (28) with respect to we get the following magnitude-squared estimator:</p><p>(29) Note that the numerator is the traditional MMSE estimator <ref type="bibr" target="#b0">[1]</ref>, and the denominator is the estimator derived in <ref type="bibr" target="#b7">(8)</ref>. Substituting <ref type="bibr" target="#b8">(9)</ref> for the denominator and the MMSE estimator <ref type="bibr" target="#b0">[1]</ref> for the numerator, we get (30) ) for several values of and for . For comparative purposes we also superimpose the gain function of the log-MMSE estimator. The power exponent clearly influences attenuation with negative values providing more attenuation than positive values. When , we get the "unweighted"</p><p>estimator given in (30). Note that the estimator given in (30) provides slightly more attenuation than the log-MMSE estimator. Only the parametric gain curves for were plotted in Fig. <ref type="figure" target="#fig_3">4</ref>. The shape of the gain functions obtained for other values of is similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Weighted Likelihood Ratio</head><p>As mentioned earlier, the IS measure places more emphasis on spectral peaks than spectral valleys. To further increase the sensitivity of distortion measure to the spectral peaks, Shikano and Sugiyama <ref type="bibr" target="#b18">[19]</ref> proposed the weighted likelihood ratio (WLR) distortion measure which has the following form:</p><formula xml:id="formula_2">(35)</formula><p>The WLR measure can be considered to be a variant of the log spectral difference measure given in (4). The weighting function used in is the linear spectral difference ( ) which weights log spectral peaks more than spectral valleys. In contrast, the measure implicitly uses the log spectral difference, (</p><p>), as the weighting function, thereby weighting spectral peaks and valleys equally.</p><p>After differentiating the Bayesian risk and is the MMSE estimator <ref type="bibr" target="#b0">[1]</ref>. The term above was derived in <ref type="bibr" target="#b1">[2]</ref>. It is easy to show that the function in (37) is monotonically increasing in (0, ) with (given that ) and , and therefore has a single zero. That is, the solution of the nonlinear equation in (37) yields a unique estimator. Numerical techniques <ref type="bibr" target="#b19">[20]</ref> can be used to find the single zero of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Modified Itakura-Saito Distortion Measure</head><p>With the exception of the asymmetric IS measure, the other distortion measures discussed so far were symmetric. The symmetry property is certainly desirable in pattern recognition applications, where we would like the distortion measure to yield the same value regardless of whether we compare the reference spectrum (or parametric model) against the test spectrum or the test spectrum against the reference spectrum. In speech enhancement applications, however, the distortion measure need not be symmetric, as we may want to penalize positive errors more than negative errors or vice versa. A positive estimation error (</p><p>) would suggest that the estimated spectral amplitude is attenuated since , while a negative error ( ) would suggest that the estimated amplitude is amplified, since . The perceptual effects of these two types of error, however, are not equivalent and therefore the positive and negative errors need not be weighted equally. Wanting to prevent attenuation of the weak speech segments (e.g., stops, fricatives), we chose a distortion measure that penalizes the positive errors more heavily than the negative errors.</p><p>The following distortion measure was therefore considered:</p><p>(39) which is referred to as the modified IS (MIS) measure. Note that the original IS measure had the form where , whereas in our case, . Fig. <ref type="figure" target="#fig_4">5</ref> plots the above measure as a function of . As can be seen, the above distortion measure is indeed nonsymmetric in that it penalizes the positive errors ( or equivalently,</p><p>) more than the negative errors. After minimizing the Bayesian risk (40) with respect to , we get the following estimator:</p><p>(41)</p><p>The integral in the above equation evaluates to (see derivation in Appendix B) (42) where denotes the Gaussian hypergeometric function [16, eq. 9.100]. In our implementation, we truncated the above infinite series to the first terms as follows:</p><p>(43) Good performance was obtained using in the range of 30 to 40. Due to highly nonlinear nature of the resulting estimator, we are unable to plot its gain function. We can easily prove, however, that the above estimator always provides less attenuation than the MMSE estimator. Acknowledging the fact that the integral in (41) is , and after using Jensen's inequality, we have (44)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head><p>The proposed estimators were evaluated using both objective measures and subjective listening tests. Twenty sentences from the TIMIT database were used for the objective evaluation of the proposed estimators, ten produced by female speakers and ten produced by male speakers. The TIMIT sentences were downsampled to 8 kHz. Speech-shaped noise constructed from the long-term spectrum of the TIMIT sentences was added to the clean speech files at 0, 5, and 10 dB SNR. An estimate of the noise spectrum was obtained from the initial 100-ms segment of each sentence. The noise spectrum estimate was not updated in subsequent frames.</p><p>The proposed estimators were applied to 20-ms duration frames of speech using a Hamming window, with 50% overlap between frames. The "decision-directed" approach <ref type="bibr" target="#b0">[1]</ref> was used in all proposed Bayesian estimators to compute the a priori SNR , with . The enhanced signal was combined using the overlap and add approach. For comparative purposes, we evaluated the performance of the MMSE and log-MMSE estimators. MATLAB implementations of the proposed estimators are available upon request from the author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Objective Evaluations</head><p>Objective measures, in terms of the segmental SNR, were used to evaluate the performance of the proposed Bayesian estimators of the speech magnitude spectrum. We first compared the performance obtained with the weighted Euclidean Bayesian estimator [( <ref type="formula">18</ref>)] against the performance obtained with the MMSE estimator <ref type="bibr" target="#b0">[1]</ref>. For the implementation of the function in <ref type="bibr" target="#b17">(18)</ref>, we used the first 100 terms of the confluent hypergeometric series. The results are shown in Fig. <ref type="figure" target="#fig_5">6</ref> in terms of segmental SNR improvement (over the noisy speech) for different values of and for three input SNRs (0, 5, 10 dB). Clearly, better performance is obtained with negative values of . Listening tests indicated that the residual noise is reduced significantly when . Speech distortion is introduced however when takes on large negative values, particularly when gets close to . Hence, the value of controls the tradeoff between speech distortion and residual noise. A good compromise was found with (see next section). Fig. <ref type="figure">7</ref> compares the performance obtained with the and weighted-estimators, against the performance obtained with the log-MMSE estimator <ref type="bibr" target="#b1">[2]</ref>. The estimator based on the weighted-measure performs a little better than the log-MMSE estimator for , and performs equally well for higher SNR levels. Listening tests (see next section) indicated that the residual noise is reduced significantly by the weighted-Bayesian estimators when . Speech distortion is introduced however when gets close to . A good compromise between residual noise and speech distortion was found with . Table <ref type="table" target="#tab_0">I</ref> compares the performance obtained with the weighted-likelihood Bayesian estimator against the performance obtained with the log-MMSE estimator. Brent's algorithm <ref type="bibr" target="#b19">[20]</ref> was used to solve for the WLR estimator satisfying (37). In addition to the segmental SNR measure, we also evaluated the performance of the two estimators using the Itakura-Saito distortion measure. This was done to assess the spectral-peak matching ability of the WLR estimator. Large improvement in IS values was indeed observed for with the WLR estimator.</p><p>Table <ref type="table" target="#tab_1">II</ref> compares the performance obtained with the MMSE estimator against the performance obtained with the MIS estimator [(43)] using . For the implementation of the function in (43), we used the first 40 terms of the Gaussian hypergeometric series. Overall, the MMSE estimator performs better, however, closer examination of some of the enhanced signals revealed that the MIS Bayesian estimator does a better job in preserving weak (low-energy) speech segments such as stops and fricatives. This is illustrated in Fig. <ref type="figure" target="#fig_6">8</ref> which compares the enhanced signals obtained with the two estimators. Note that the fricative /s/ at , 1.4 and 2.4 secs is hardly present in the signal enhanced by the MMSE estimator, but is quite evident in the signal enhanced by the MIS estimator. The MMSE estimator, however, does a better job in enhancing the voiced segments of speech and preserving the consonant-to-vowel amplitude ratio. Informal listening tests indicated that the quality of speech produced by the MIS estimator was sensitive to the number of terms, , used to truncate the infinite series in (43). We found that in the range of 30 to 40 gives modest performance, but the MIS estimator becomes very aggressive with "musical"-type of noise if a smaller number of terms is used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Subjective Evaluations</head><p>Ten TIMIT sentences (subset of the sentences used for the objective evaluations) produced by five male and five male speakers were used in the listening tests. Five normal-hearing listeners, age 20-25 yrs, participated in the listening tests [all listeners were paid for their participation]. Listeners were presented randomly with 30 pairs ( ) of sentences processed by the MMSE estimator and the weighted-Euclidean based Bayesian estimators using and . In a different listening session, listeners were presented with 30 pairs of sentences processed by the log-MMSE estimator and the weighted-based Bayesian estimators using and . Subjects were asked to (1) choose the sentence they prefer in terms of being more natural and having less distortion, and (2) indicate which sentence had more residual noise.</p><p>The results, scored in terms of preference percentage, are given in Table <ref type="table" target="#tab_1">III</ref>. Results indicated that the value of clearly influenced the amount of distortion perceived, with large negative value of producing more distortion than small negative values of . Small values of produce speech with little distortion, but with more residual noise. Subjects preferred the quality of speech produced by the MMSE estimator over speech enhanced by the weighted-Euclidean estimator for large negative values of , i.e., when . Subjects also preferred the quality of ) over speech enhanced by the MMSE estimator. Quality of speech by the log-MMSE estimator and the weighted-estimator ( ) was found to be comparable (</p><p>), but with substantially lower residual noise reported for the weighted-estimator. Listeners overwhelmingly reported that speech produced by the proposed estimators had less residual noise than either the MMSE or log-MMSE estimators. (p = 01:5) and weighted-cosh estimator (p = 00:9). Note that the residual noise is significantly reduced by the proposed estimators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SUMMARY AND CONCLUSIONS</head><p>The present study focused on the derivation of perceptually-motivated Bayesian estimators of the magnitude spectrum. Several other perceptually-motivated methods were proposed in <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref> but used a different approach for incorporating psychoacoustic constraints.</p><p>Six different Bayesian estimators of the spectral magnitude were derived in this paper. Unlike the previous MMSE estimators derived in <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, the proposed Bayesian estimators are based on perceptually motivated distortion measures. Based on the evaluation of the proposed estimators, we can draw the following conclusions. 1) Bayesian estimators which over-emphasize spectral peak information performed the worst. These include the traditional MMSE estimator <ref type="bibr" target="#b0">[1]</ref>, the WLR estimator [(37)] and the estimators given in ( <ref type="formula">18</ref>) and (34) with . The enhanced speech signal produced by these estimators (including the traditional MMSE estimator) had a significant amount of residual noise which was audible (see Fig. <ref type="figure" target="#fig_7">9</ref>). This was confirmed by listening tests. We believe that this is due to the fact that the estimation error produced by these estimators is small near the spectral peaks (where it is masked anyway) and large in the spectral valleys, where the residual noise is audible <ref type="bibr" target="#b14">[15]</ref>.</p><p>2) Bayesian estimators that emphasize spectral valleys more than the spectral peaks performed the best in terms of having less residual noise and better speech quality (see Fig. <ref type="figure" target="#fig_7">9</ref>). These include the estimator given in <ref type="bibr" target="#b17">(18)</ref> with and the estimator given in (34) with . Listening tests confirmed that the weighted-Euclidean estimator ( ) performed significantly better than the MMSE estimator. The weighted-estimator ( ) performed comparably with the log-MMSE estimator, but with substantially reduced residual noise. This class of estimators exploits implicitly auditory masking effects by taking into account the fact that estimation errors near the spectral peaks are masked.</p><p>3) The derived Bayesian estimators based on the Itakura-Saito measure of the magnitude and power spectrum were identical to the MMSE estimator of the magnitude and power-spectrum, respectively. 4) The Bayesian estimator based on the asymmetric MIS measure seems to perform well in preserving weak speech segments (e.g., fricatives) but not in enhancing voiced segments. This was based on visual inspection of spectrograms and waveforms of the enhanced signals.</p><p>This estimator was designed to penalize positive errors more than negative errors, thereby avoiding spectral for their useful comments that helped improved the present manuscript.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Let be the sampled noisy speech signal consisting of the clean signal and the noise signal . Taking the short-time Fourier transform of , we get (1) 1063-6676/$20.00 Â© 2005 IEEE for and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Gain functions of the weighted-Euclidean distance estimator [(18)] as a function of the instantaneous SNR ( 0 1) and for several values of the power exponent p. Top panel plots the gain functions for = 05 dB and bottom panel plots the gain function for = 5 dB. The gain functions of the MMSE and log-MMSE estimators are also plotted for comparison.</figDesc><graphic coords="5,131.04,65.42,328.00,571.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Plot of the cosh distortion measure d (V ) = cosh(V ) 0 1, where V = log X 0 log X . The log spectral distortion measure [(4)] is also plotted (dashed line) for comparison.</figDesc><graphic coords="6,119.58,65.26,354.00,284.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Gain function of the weighted-cosh estimator [(34)] as a function of the instantaneous SNR ( 01) and for several values of the power exponent p. The a priori SNR is fixed at = 05 dB. The gain function of the log-MMSE estimator is also plotted for comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Plot of the modified Itakura-Saito distortion measure d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Performance, in terms of segmental SNR improvement (dB), of the weighted Euclidean estimator [(18)] for different values of p and for different input SNR levels. The performance of the MMSE estimator is also shown for comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. Top panel shows the waveform of the TIMIT sentence "She was so beautiful, so valiant, so pitiable." produced by a male speaker. Second panel from the top shows the noisy waveform at 0 dB SNR. The bottom two panels show the enhanced signals by the MMSE and MIS Bayesian estimators. Note that the fricative /s/ at t 0:4, 1.4 and 2.4 secs is hardly present in the signal enhanced by the MMSE estimator, but is quite evident in the signal enhanced by the MIS estimator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Top panel shows the waveform of the TIMIT sentence "The angry boy answered, but didn't look up." produced by a female speaker. Second panel from the top shows the noisy waveform at 5 dB SNR. The remaining panels show the enhanced signals produced by the MMSE, log-MMSE, weighted-Euclidean estimator</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,115.50,66.18,359.00,285.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COMPARISON</head><label>I</label><figDesc>BETWEEN THE LOG-MMSE [2] AND WLR BAYESIAN ESTIMATORS [(37)] IN TERMS OF SEGMENTAL SNR IMPROVEMENT (DB) AND IN TERMS OF THE IS MEASURE</figDesc><table /><note><p>Fig. 7. Performance, in terms of segmental SNR improvement (dB), of the weighted cosh estimator [(34)] for different values of p and for different input SNR levels. The performance of the log-MMSE estimator is also shown for comparison.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II COMPARISON</head><label>II</label><figDesc>BETWEEN THE MMSE [1] AND MIS BAYESIAN ESTIMATORS [(43) WITH Q = 40] IN TERMS OF SEGMENTAL SNR IMPROVEMENT (DB)</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>S'90-M'91-SM'04) received the B.S., M.S., and Ph.D. degrees, all in electrical engineering, from Arizona State University, Tempe, in 1989, 1991, and 1995, respectively. From 1995 to 1996, he was a Postdoctoral Fellow in the Department of Speech and Hearing Science, Arizona State University, working on research related to cochlear implants. He was an Assistant Professor at the University of Arkansas at Little Rock from 1996 to 1999. He is now a Professor in the Department of Electrical Engineering at the University of Texas at Dallas. His research interests are in the areas of signal processing, speech processing, and cochlear implants. Dr. Loizou was an Associate Editor of the IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING (1999-2002) and is currently a member of the Industrial Technology Track Technical Committee of the IEEE Signal Processing Society.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>attenuation. Although the performance of the MIS Bayesian estimator was not consistently or equally well for all voiced and unvoiced speech segments, conceivably, a hybrid estimator can be implemented which uses the MIS estimator for unvoiced segments and a different estimator (e.g., <ref type="bibr" target="#b17">(18)</ref> with ) for voiced segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A</head><p>In this Appendix, we derive the estimators given in ( <ref type="formula">8</ref>), ( <ref type="formula">18</ref>), (29) and (33). Assuming the Gaussian statistical model <ref type="bibr" target="#b0">[1]</ref>, we know that <ref type="bibr" target="#b1">[2]</ref> (45) Using <ref type="bibr">[16, eq. 6.631.1, 8.406.3, 9.212.1]</ref> it is easy to show that <ref type="bibr" target="#b1">[2]</ref> (46) By setting in the above equation, we can evaluate the integral in <ref type="bibr" target="#b7">(8)</ref> to get <ref type="bibr" target="#b8">(9)</ref>.</p><p>The above equation is similarly used in <ref type="bibr" target="#b16">(17)</ref> to evaluate the estimator given in <ref type="bibr" target="#b17">(18)</ref>. The restriction on the value of to be larger than comes from the evaluation of the integral in the numerator of (45). From [16, eq. 6.631.1], the power exponent of the term has to be larger than , which leads to the condition that . The estimator in (29) and the weighted-estimator in (33) are derived in a similar way using (46).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B</head><p>In this Appendix, we evaluate the MIS Bayesian estimator given in (41). Using Bayes' rule, we can write (47) After using the Gaussian statistical model, and after integrating over , we get <ref type="bibr">(48)</ref> where indicates the modified Bessel function of order zero. After using the following identity for the exponential term [17, eq. A.1.47c]:</p><p>(49) in (48), we get (50)</p><p>The above integrals can be evaluated using <ref type="bibr">[16, eq. 6.633</ref> The Gaussian hypergeometric infinite series is known to converge if or equivalently if . Simulation results indicated that this condition was rarely violated even at extremely low SNR conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>Many thanks go to S. Rangachari for all his help with the listening tests. The author would also like to thank the reviewers</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Speech enhancement using a minimum mean-square error short-time spectral amplitude estimator</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ephraim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Malah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1109" to="1121" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Speech enhancement using a minimum mean-square error logspectral amplitude estimator</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust. , Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="443" to="445" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Speech enhancement using MMSE short time spectral estimation with Gamma distributed speech priors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Speech, Acoustics, Signal Processing</title>
		<meeting>Int. Conf. Speech, Acoustics, Signal essing</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="253" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toward a perceptually optimal spectral amplitude estimator for audio signal enhancement</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Godsill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal essing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="821" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A perceptually balanced loss function for short-time spectral amplitude estimation</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust. , Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoust. , Speech, Signal essing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="425" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive b-order MMSE estimation for speech enhancement</title>
		<author>
			<persName><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahardja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust. , Speech, Signal Processing</title>
		<meeting>IEEE Int. Conf. Acoust. , Speech, Signal essing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="900" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Elimination of the musical noise phenomenon with the Ephraim and Malah noise suppressor</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cappe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="346" to="349" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Kay</surname></persName>
		</author>
		<title level="m">Fundamentals of Statistical Signal Processing: Estimation Theory</title>
		<meeting><address><addrLine>Upper Saddle River, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distance measures for speech processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Markel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="380" to="391" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distortion measures for speech processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="367" to="376" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Minimum prediction residual principle applied to speech recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Itakura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="67" to="72" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparative study of several distortion measures for speech recognition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nocerino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predictive coding of speech using analysis-bysynthesis techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kroon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Speech Signal Processing</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Furui</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sondhi</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Marcel-Dekker</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="141" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predictive coding of speech and subjective error criteria</title>
		<author>
			<persName><forename type="first">B</forename><surname>Atal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="247" to="254" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing digital speech coders by exploiting masking properties of the human ear</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Atal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="1647" to="1652" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Gradshteyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ryzhik</surname></persName>
		</author>
		<title level="m">Table of Integrals, Series and Products</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>6 ed</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">An Introduction to Statistical Communication Theory</title>
		<author>
			<persName><forename type="first">D</forename><surname>Middleton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An analysis-synthesis telephony based on maximum likelihood method</title>
		<author>
			<persName><forename type="first">F</forename><surname>Itakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Acoustics</title>
		<meeting>6th Int. Conf. Acoustics</meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluation of LPC spectral matching measures for spoken word recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. IECE</title>
		<imprint>
			<biblScope unit="volume">565</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="535" to="541" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Algorithms for Minimization without Derivatives</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Speech enhancement based on audible noise suppression</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Tsoukalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Mourjopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kokkinakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="497" to="514" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Incorporating a psychoacoustical model in frequency domain speech enhancement</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Loizou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Lett</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="270" to="273" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Single channel speech enhancement based on masking properties of the human auditory system</title>
		<author>
			<persName><forename type="first">N</forename><surname>Virag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="126" to="137" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
