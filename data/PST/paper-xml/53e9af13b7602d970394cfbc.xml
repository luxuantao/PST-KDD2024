<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Discriminative Projections for Compact Binary Descriptors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tomasz</forename><surname>Trzcinski</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CVLab</orgName>
								<orgName type="institution">EPFL</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CVLab</orgName>
								<orgName type="institution">EPFL</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Discriminative Projections for Compact Binary Descriptors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A08673A41293BEB5790E2A8C8CDC3C8A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Binary descriptors of image patches are increasingly popular given that they require less storage and enable faster processing. This, however, comes at a price of lower recognition performances. To boost these performances, we project the image patches to a more discriminative subspace, and threshold their coordinates to build our binary descriptor. However, applying complex projections to the patches is slow, which negates some of the advantages of binary descriptors. Hence, our key idea is to learn the discriminative projections so that they can be decomposed into a small number of simple filters for which the responses can be computed fast. We show that with as few as 32 bits per descriptor we outperform the state-of-the-art binary descriptors in terms of both accuracy and efficiency.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Local image feature descriptors have been vastly used in many computer vision applications such as image retrieval, pose estimation and 3D reconstruction. Their main goal is to represent a salient image region while remaining invariant to various illumination and viewpoint changes. In practice, however, obtaining such a robust representation becomes a challenging task, especially for mobile devices with limited resources.</p><p>Numerous methods have been proposed in the literature to tackle this problem <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, but very recently, several binary descriptors computed directly on image patches-BRIEF <ref type="bibr" target="#b2">[3]</ref>, ORB <ref type="bibr" target="#b3">[4]</ref>, and BRISK <ref type="bibr" target="#b4">[5]</ref>-have appeared. They are both fast to compute and to match, with a very small memory footprint, and their quick success clearly shows a need for such descriptors in real applications, especially for low-end handheld devices.</p><p>However, these new descriptors tend to be less robust than slower approaches. In this work, we aim to bridge this performance gap without increasing the computational cost. In order to boost the recognition performances, we adopt a discriminative approach as in <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>: We use training data to learn linear projections that map image patches to a more discriminative subspace, and to obtain a binary descriptor, we threshold the projected patches. This way we avoid the intermediate step of computing complex floating-point descriptors, which is common for many binary descriptors <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref> but exceeds the capabilities of many mobile platforms. To compute our binary descriptor, we learn from a training set of corresponding image patches several discriminative linear projections that can be computed from a linear combination of a few simple filters. For the example of this figure, we used rectangular filters that can be computed efficiently with integral images, but we also consider box and Gaussian filters which are also efficient to compute. This approach enables us to build our binary descriptor fast while leveraging on training data.</p><p>Nevertheless, projecting image patches is computationally expensive and negates the efficiency of binary descriptors, especially when they have to be computed in real time. Thus, in our approach, and this is our main contribution, we train the projections not only to be discriminative but also to be computed as a linear combination of a small number of simple filters from a given dictionary, as shown in Fig. <ref type="figure">1</ref>. We design the dictionaries in such a way that the filter responses can be computed fast, with box or Gaussian filtering or using integral images.</p><p>Our key idea is that this can be done by imposing sparsity constraints and using efficient optimization techniques.</p><p>To summarize, we build our binary descriptor, which we refer to as D-Brief for Discriminative BRIEF <ref type="foot" target="#foot_0">1</ref> , by first projecting image patches to a more discriminant subspace and then concatenating the results of a thresholding operation applied on the projected coordinates. When we use box or Gaussian filters to construct the projections, we can speed up the computation of projected patches by first convolving the entire image with a given filter and then combining only a few values read from the convolved image. With rectangular filters, we use integral images to compute the responses fast. As a result, D-Brief provides better recognition performances than its direct competitors <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, while being significantly shorter-only 32 bits to be compared with several hundreds-and less time consuming. D-Brief can also be seen as a much more efficient binary alternative to the short floating-point descriptors of <ref type="bibr" target="#b5">[6]</ref>, which require more time to be computed, and hence target different applications than binary descriptors.</p><p>The rest of this paper is organized as follows. In Section 2, we discuss the related work. In Section 3, we introduce our method to construct a binary descriptor from a set of discriminant projections learnt from a training dataset. We explain in details how we optimize on the projections so that they can be computed using small number of simple filter banks which enables efficient computation of projected patches. Finally, we compare the performances of our D-Brief binary descriptor with the state of the art and we show an example of a real-time application based on D-Brief.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Due to the increasing interest of the research community in real-time applications and the implementation of Computer Vision algorithms on mobile devices, many efficient feature descriptors have been proposed in the literature.</p><p>The widely used SURF descriptor <ref type="bibr" target="#b1">[2]</ref> is created by summing responses of Haar wavelets, which can be done very fast using integral images. We also rely on integral images for one of our dictionaries of filters, but to speed up the computation of learnt discriminative projections, not to compute handcrafted filters. Our descriptor is also significantly shorter and faster to compute.</p><p>Few recent methods propose to construct efficient low bit-rate descriptors using compression or quantization techniques <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. These approaches, however, were mainly designed for visual search, which is an application of much lower speed requirements than our descriptor aims at. Thus, even though the resulting descriptors are compact, they require complex image gradient computations which often remain prohibitive for mobile devices.</p><p>Much research has been recently focused on designing binary descriptors, since they require much less storage than the real-valued ones. They also enable faster matching as there are efficient indexing schemes for binary vectors <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> and Hamming distances can be computed fast on many architectures, including mobile devices. Thanks to all these properties, binary descriptors are perfect candidates for real-time applications. Both unsupervised and supervised approaches have been proposed. Unsupervised approaches seek for a transformation that preserves the similarity as evaluated in the original space, typically using the Euclidean distance <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. Our method belongs to the category of supervised approaches: These approaches aim to outperform unsupervised ones by exploiting labeled data to produce similar binary representations for data with the same class labels <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Our work is closely related to LDAHash <ref type="bibr" target="#b6">[7]</ref>, which also computes a binary descriptor using discriminative projections but applied to SIFT descriptors instead of image patches. Linear Discriminative Analysis was also applied to image patches and other descriptors in <ref type="bibr" target="#b5">[6]</ref>. However, the descriptors in <ref type="bibr" target="#b5">[6]</ref> are not binary and much more time-consuming to compute and match than ours. Our main contribution, on the other hand, is to show that the linear projections can be optimized for very fast computation using recent optimization theory, and is therefore not limited to LDA.</p><p>Most of the binarization methods mentioned above are applied to a sophisticated descriptor, such as SIFT or Gist, and thus exceed the capabilities of modern mobile devices. To address this problem, we consider here simple intensity image patches. This is motivated by very recent binary feature descriptors <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>, which are computed by applying simple tests directly to the image. These tests compare the image intensities at two pixel locations. For noise removal, the image is pre-smoothed with a box filter or a Gaussian filter. BRIEF <ref type="bibr" target="#b2">[3]</ref> uses random pre-determined locations, whereas BRISK <ref type="bibr" target="#b4">[5]</ref> uses an exhaustive set of comparisons of close locations. ORB <ref type="bibr" target="#b3">[4]</ref> relies on optimization like we do and aims at improving the recognition rates by choosing the locations that decorrelate the tests.</p><p>However, the approach in ORB is limited to a very specific type of tests and relies on a greedy optimization, while we can deal with tests of general form and incorporate the computational cost as a penalty in our cost function. Finally, our formulation encompasses the computation of these descriptors, as they are built by computing a linear combination of two box or Gaussian filter responses and thresholding the resulting values at zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning Framework</head><p>Our binary descriptor is computed by applying a set of projections to a realvalued vector made of the intensities of an image patch and then thresholding the results:</p><formula xml:id="formula_0">∀ i∈1,...,N b i = sign(w i x + τ i ) , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where the b i are the N bits of our descriptor, the w i the projections, the τ i the thresholds, and x the image patch in vector form. We show in Section 3.1 how to optimize over the {w i , τ i } to obtain our efficient and discriminative descriptor, and in Section 3.2 we explain how it can be computed fast. Finally, we evaluate how our descriptor is influenced by its parameters in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Approach</head><p>In principal, our approach seeks to minimize the expected Hamming distance between binary descriptors that describe similar keypoints while maximizing it for the descriptors that describe different keypoints. To that end, we learn a set of discriminative orthogonal linear projections and the corresponding thresholds from a set P of pairs of corresponding image patches and another set N of pairs of different patches. Nevertheless, applying general projections directly on the image patches is computationally expensive. Hence, our key idea is to train the projections w i to be a linear combination of a few elements from a predefined set or dictionary D, which is designed to contain elements for which the responses can be computed fast, for example using box filters. More formally, we express the projections as w i = Ds i , where the dictionary D is defined as a matrix with its columns being the elements of the dictionary. We want most of the coefficients of the s i vectors to be equal to zero, that is, the s i should be sparse. Our goal can then be formalized as solving the following minimization problem: min</p><formula xml:id="formula_2">{(si,τi)} i∈1,...,N (x,x )∈N sign((Ds i ) x + τ i ) sign((Ds i ) x + τ i ) - (x,x )∈P sign((Ds i ) x + τ i ) sign((Ds i ) x + τ i ) + λ|s i | 1 subject to (Ds i ) (Ds j ) = δ ij , (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where the last term encourages sparsity of the s i with λ determining its sparsity level, and |.| 1 denotes the 1 norm. The constraint, with δ ij = 1 if i = j and 0 otherwise, makes sure that the projections are orthogonal.</p><p>Unfortunately, direct minimization of this objective function is difficult as it involves the non-differentiable sign function. In our case, typical solutions of this problem, such as smooth approximation with the hinge function <ref type="bibr" target="#b17">[18]</ref>, would lead to a quadratic non-convex problem which is challenging to solve, as it involves thousands of unknowns.</p><p>Thus, we drop the sign function and minimize the related objective function as it is done in <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_4">min {si} i (x,x )∈P ((Ds i ) (x -x )) 2 (x,x )∈N ((Ds i ) (x -x )) 2 + λ|s i | 1 (3) subject to (Ds i ) (Ds j ) = δ ij</formula><p>The above objective is independent of the thresholds τ i . Hence, after finding the projections w i = Ds i , the optimal thresholds are obtained by minimizing the original objective of Eq. ( <ref type="formula" target="#formula_2">2</ref>) using the training sets P and N . With the projections w i being fixed, this requires simple one-dimensional search, as explained in <ref type="bibr" target="#b6">[7]</ref>.</p><p>A possible method to solve the minimization problem of Eq. ( <ref type="formula">3</ref>) is by using Stochastic Gradient Descent, with soft-thresholding as the proximal operator of the 1 norm <ref type="bibr" target="#b18">[19]</ref>. However, even after dropping the sign function, Eq. ( <ref type="formula">3</ref>) remains non-convex and the optimization is likely to get stuck in a local minimum. Therefore, it becomes essential to initialize the optimization properly, because random initialization may not give satisfactory results, as we show below.</p><p>We propose to set the initialization point of the optimization using the following approach: We start by minimizing the first term of Eq. ( <ref type="formula">3</ref>) and we obtain an initial set of discriminant projections {w 0 i } using Linear Discriminant Embedding (LDE) <ref type="bibr" target="#b5">[6]</ref>:</p><formula xml:id="formula_5">{w 0 i } = arg min {wi} i (x,x )∈P (w i (x -x )) 2 (x,x )∈N (w i (x -x )) 2 .</formula><p>(</p><formula xml:id="formula_6">)<label>4</label></formula><p>As one can see, the LDE includes the orthogonality constraint from Eq. ( <ref type="formula">3</ref>), as the resulting projections are based on the orthogonal eigenvectors. We then address the sparsity constraint of Eq. ( <ref type="formula">3</ref>) and approximate each w 0 i projection with a sparse linear combination of elements from dictionary D by minimizing the following objective:</p><formula xml:id="formula_7">{s 0 i } = arg min si w 0 i -Ds i 2 2 + λ|s i | 1 , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where the first term corresponds to the quality of approximation, and the second one to the sparsity of the filter representation. To simplify our optimization, we do not constrain our approximated projections to be orthogonal, although this could certainly lead to an interesting extension of our approach. The advantage of the stepwise approach discussed above is that Eq. ( <ref type="formula" target="#formula_6">4</ref>) can be solved in closed-form as shown in <ref type="bibr" target="#b5">[6]</ref>, while Eq. ( <ref type="formula" target="#formula_7">5</ref>) is convex and can be solved with efficient recent techniques <ref type="bibr" target="#b18">[19]</ref>. In practice, we use the MATLAB lasso function which implements <ref type="bibr" target="#b19">[20]</ref> and lets the user define |s| max 0 , the maximal number of non-zero coefficients in the representation, which is a more convenient way of controlling the sparsity of the approximation compared to tuning λ.</p><p>To evaluate the quality of our approach, we performed the following experiments. We took two sets of projections: Random ones {w R i } and those obtained using our stepwise approach {w S i = Ds 0 i }. We then minimized Eq. ( <ref type="formula">3</ref>) with Stochastic Gradient Descent using first {w R i } and then {w S i } as initializers. As a result we obtained two optimized sets of projections, {w R-Opt i } and {w S-Opt i } respectively. To make the comparison fair, we set the number of projections to 32 and tuned the parameters so that each projection was a linear combination of 64 columns of D. We then found the corresponding optimal thresholds and evaluated the resulting descriptors on all the test sets, using the setup of Section 3.3. We present here two representative ROC curves.</p><p>As Fig. <ref type="figure">2</ref> shows, optimizing over the random projections significantly improves the results. Nevertheless, the projections obtained using the stepwise initialization scheme we propose perform better even without optimization. Moreover, our extensive evaluation shows that applying a global optimization on the {w S i } does not lead to any significant improvement and, hence, in the remainder of this paper we use our stepwise approach without further optimizing it. </p><formula xml:id="formula_9">{w R i } {w S i } {w R-Opt i } {w S-Opt i } Fig. 2.</formula><p>Results obtained using Stochastic Gradient Descent applied to Eq. ( <ref type="formula">3</ref>) and initialized with random projections or projections found with our stepwise approach. We used 32 projections and tuned the parameters so that each projection is a linear combination of 64 columns of BOX dictionary. We then found the corresponding optimal thresholds. Initializing gradient descent with the stepwise approach instead of random projections boosts the results significantly. Interestingly, optimization improves the quality of the projections only slightly while requiring additional processing time. Thus, to build D-Brief we use projections computed with the stepwise approach without further optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dictionaries</head><p>After finding a set of projections {w i = Ds i }, they can be applied on an image patch x as:</p><formula xml:id="formula_10">w i x = (Ds i ) x = j such that sij =0 s ij D j x , (<label>6</label></formula><formula xml:id="formula_11">)</formula><p>where the D j are the columns of matrix D and contain the dictionary elements.</p><p>The dictionary in D is designed so that the dot product D j x can be computed efficiently. In our experiments we use three different dictionaries that contain:   <ref type="formula" target="#formula_6">4</ref>) and used for dimensionality reduction before and after applying the thresholds (the 95% error rate is the percent of incorrect matches obtained when 95% of the true matches are found). Without binarization, the error rates do not change significantly for different dimensionalities. After binarization, however, the dimensionality has much greater influence, likely because the projections are ranked by decreasing discriminative power, while the binarization gives them equal importance. The minimum of the plotted curve corresponding to the best performance is obtained for 32 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiments</head><p>To train our projections, we use three publicly available dataset: Liberty, Notre Dame and Yosemite <ref type="bibr" target="#b5">[6]</ref>. Each of them contains over 400k scale-and rotationnormalized 64 × 64 patches. These patches are sampled around interest points detected using Difference of Gaussians and the correspondences between patches are found using a multi-view stereo algorithm. The datasets created this way exhibit substantial perspective distortion and various lighting conditions. Sample patches from the Liberty dataset are shown in Fig. <ref type="figure" target="#fig_2">3</ref>(a). The ground truth available for each of those datasets describes 100k, 200k and 500k pairs of patches, where 50% correspond to match pairs, and 50% to non-match pairs. To avoid overfitting when training the LDE projections we apply a regularization method proposed in <ref type="bibr" target="#b5">[6]</ref> with clipping parameter α = 0.01. We tried different combinations of training and testing datasets, but as in <ref type="bibr" target="#b5">[6]</ref>, we found that choosing a specific combination does not have a strong influence on the final results.</p><p>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>(b) the best performances are obtained when using the first 32 projections. When a larger number of projections is used, the performances start deteriorating. This performance peak can be explained by the fact that the binarization step gives equal importance to all the projections, while the projections with LDE are ranked by decreasing discriminative power. Moreover, using the least ranked projections, which correspond to the dimensions of lower energy, introduces classification noise and deteriorates performance. We therefore keep the top 32 projections in the rest of the paper, and our descriptor is made of 32 bits.</p><p>We performed a set of experiments to qualitatively and quantitatively assess the influence of different parameters on Eq. ( <ref type="formula" target="#formula_7">5</ref>). Fig. <ref type="figure" target="#fig_3">4</ref> shows how the dictionary type and the number of elements used influences the results on two sample LDE projections.  <ref type="formula" target="#formula_7">5</ref>), from two LDE projections obtained with Eq. ( <ref type="formula" target="#formula_6">4</ref>). We varied the dictionaries and the maximal numbers of dictionary elements per projection. The columns on the right show the first 8 elements of the sparse representation s which are best viewed on a monitor.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref> shows the recognition rates for projections obtained by optimizing Eq. ( <ref type="formula" target="#formula_7">5</ref>), from the top 32 LDE projections obtained with Eq. ( <ref type="formula" target="#formula_6">4</ref>) with different dictionaries and various numbers of dictionary elements used. Before binarization, the RECT dictionary provides the best results, followed by the GAUSS and BOX dictionaries. While optimizing the projections with Eq. ( <ref type="formula" target="#formula_7">5</ref>) hurts the recognition performances before binarization, it is not true anymore after binarization. There is actually a minor improvement, which may come from the fact that the LDE projections are typically noisy and the optimization introduces some regularization which makes the thresholds generalize better. Surprisingly, the GAUSS dictionary performs better than the others after binarization for small numbers of elements, but then gets outperformed again by the RECT dictionary large numbers of elements.   <ref type="formula" target="#formula_7">5</ref>), from the top 32 LDE projections obtained with Eq. ( <ref type="formula" target="#formula_6">4</ref>). We varied the dictionaries and the maximal numbers of dictionary elements per projection. We also give the results for the projections directly obtained with Eq. ( <ref type="formula" target="#formula_6">4</ref>), referred to as LDE. In parentheses: Number of floating point (f) or binary (b) coordinates, and number of elements. Before binarization, the RECT dictionary provides the best approximation, followed by the GAUSS and BOX dictionary. While the approximation hurts the recognition performances before binarization, it is not true anymore after binarization. The minor improvement can be explained by the smoothing effect of the approximation applied on typically noisy LDE projections which makes the thresholds generalize better.</p><p>As explained in Section 3.1, to build the descriptors efficiently at run-time we first preprocess the image patch either by convolving it with a box or Gaussian filter or by computing the integral image. Then, the D j x values of Eq. ( <ref type="formula" target="#formula_10">6</ref>) are obtained by reading either one or four values from the output of this preprocessing stage. Convolution with a box filter is faster than convolution with a Gaussian filter, and when using the RECT dictionary, we need to read four values for each D j x instead of only one as with the BOX and GAUSS dictionaries. The computation times are therefore different for each dictionary and Table <ref type="table">2</ref> presents the times required for computing our descriptors using different dictionaries. With our approach, we can speed up the description time with respect to regular projections by over an order of magnitude.</p><p>Moreover, there is a trade-off between the accuracy and efficiency of the dictionaries: The slower one yields the best recognition performance, and vice versa. In practice, this means that we can adapt our method to the need of the final application.</p><p>In the remainder of this paper, we use projections learnt on the Notre Dame dataset, unless stated otherwise, and the RECT dictionary with 64 elements to approximate the projections, since its performance is superior while the processing time still enables real-time applications, as shown in the next section.</p><p>As reported in <ref type="bibr" target="#b5">[6]</ref>, pre-normalizing the patches by subtracting the intensity mean value and dividing by the standard deviation and post-normalizing the descriptor to unit length improves the performance, in case of a real-valued descriptor. Inspired by these findings, we tried normalizing our patches and descriptors as in <ref type="bibr" target="#b5">[6]</ref>. Fig. <ref type="figure" target="#fig_5">6</ref> confirms the observed performance improvement for real-valued coordinates. However, these steps do not have much influence on the results after binarization. This is because we train the thresholds to be discriminative after applying the projections and, hence, they adapt well to the light variations. Hence, we skip the normalization, as it entails additional computational overhead. coordinates. Normalization improves the performance only for the real-valued coordinates. The thresholds applied in the binarization step adapt to the discriminative subspace and, we can hence skip the normalization steps with no loss of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, we first compare the performance of our approach to other descriptors including recent binary descriptors. We then confirm the generalization of our approach by providing an example of a real-time object detection application based on the compact binary descriptor we learnt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Descriptor Comparison</head><p>We compare here the performance of our D-Brief descriptor against the state-ofthe-art descriptors on the Yosemite, Notre Dame, and Liberty datasets from <ref type="bibr" target="#b5">[6]</ref> and report the results in terms of ROC curves and 95% error rate as in <ref type="bibr" target="#b5">[6]</ref>. We focus on fast binary descriptors, and consider the very recent BRIEF, BRISK, and ORB as they are the direct competitors to our approach. For reference, we also provide results obtained with SIFT, and a real-valued descriptor computed by applying LDE projections on bias-gain normalized patches. For this descriptor, which we refer to as LDE, we use the optimal number of projections found in <ref type="bibr" target="#b5">[6]</ref>. We compute BRIEF and ORB using OpenCV implementations. For SIFT, we use the publicly available implementation of A. Vedaldi<ref type="foot" target="#foot_1">2</ref> . For BRISK and SURF, we use the implementations available on the websites of the authors, and for LDE, our own implementation. All the experiments were performed on a Macbook Pro with an Intel i7 2.66 GHz CPU. Table <ref type="table">1</ref> clearly shows that D-Brief provides up to 32% improvement over BRISK and up to 11% improvement over BRIEF in terms of 95% error rate, while requiring only 4 bytes instead of 64 for BRISK and 32 for BRIEF. It also shows that D-Brief remains competitive to the much longer and much more computationally expensive floating-point SURF.</p><p>Table <ref type="table">1</ref>. 95% error rates for different training and testing configurations and the corresponding results for BRIEF, BRISK and SURF (the results for ORB were identical to those of BRIEF, despite the fact that ORB optimizes its tests). As a baseline, we give the results for SIFT which is over 3 orders of magnitude slower to compute than our descriptor. For each configuration, we learnt the first 32 projections, approximated them using a dictionary of rectangular filters and learnt the thresholds. Below the descriptor names we write the number of bytes used to encode them. D-Brief outperforms its binary competitors, while requiring significantly less memory. Table 2 also recalls the advantages of binary descriptors directly computed from the image. The description times for BRIEF and for D-Brief are over two orders of magnitude shorter than for SURF and LDE. The matching time for D-Brief is also much shorter than for SURF and LDE thanks to its binary nature.</p><p>Overall, we can build and match our descriptor over three times faster than BRIEF (when working on a CPU on which the POPCOUNT instruction is not available<ref type="foot" target="#foot_2">3</ref> ) and almost two times faster when the POPCOUNT instruction is enabled.</p><p>Moreover, while we could not test it on mobile devices, it is reasonable to expect that D-Brief presents a few more advantages on such platforms. The ARM processors, which they typically use, are 32-bit processors, and since our descriptor is made of 32 bits, it fits into a single register. This is very advantageous as many operations could be performed in one cycle.</p><p>Finally, Fig. <ref type="figure" target="#fig_6">7</ref> provides the ROC curves for two combinations of training and test sets. D-Brief performs better than its binary competitors at all error rates. D-Brief remains competitive to SURF, especially for the higher false positive rates, even though it has a much shorter representation. The results of D-Brief are comparable to those obtained with LDE. However, our descriptor is binary which enables further speed-up when computing the similarities, and can be computed much faster, as shown above. SIFT performs the best of all tested descriptors, though its complexity is prohibitive for real-time application. BRISK performs better than ORB and BRIEF at low True Positive rates and joins our descriptor at such rates, but it is much longer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Real-Time Application</head><p>To demonstrate the real-time performance of D-Brief we implemented a simple real-time application for planar object detection. The user can select the object of interest by drawing a rectangle around it in a reference view. The application then extracts feature points using FAST <ref type="bibr" target="#b20">[21]</ref> and builds a database of D-Brief descriptors for these feature points in 18 rotated views at 3 scales, totaling up to 54 views. This is a simple way to make our descriptor invariant to scale and rotation changes, and was used for BRIEF in <ref type="bibr" target="#b2">[3]</ref>. Alternatively, one could estimate the scale and orientation of the feature points, and compute the descriptors on the rectified patches as was done in ORB for example.</p><p>At run-time, for each input image, the application simply extracts feature points, computes their D-Brief descriptors, matches them against all the descriptors of the database, and finally computes the homography between the reference view and the input image using RANSAC. Some screenshots are shown in Fig. <ref type="figure" target="#fig_7">8</ref>. One shall note that the projection matrix and thresholds of D-Brief are learnt on images from Notre Dame dataset, whose quality differs significantly  and BRISK, while remaining competitive to SURF for higher false positive rates. It is also much shorter than all the other descriptors. The results obtained with LDE <ref type="bibr" target="#b5">[6]</ref> applied to normalized patches are similar to those of D-Brief, but it is much more computationally expensive to compute and match (see Table <ref type="table">2</ref>). from the quality of webcam images. Despite of that, the matching results are very consistent and the correct homography is easily found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a new method to learn discriminative projections which can be computed efficiently as a linear combination of a few simple filters from a given dictionary. This approach enables us to learn a compact and discriminative binary descriptor we call D-Brief. With only 32 bits per descriptor, D-Brief outperforms its binary state-of-the-art competitors in terms of accuracy and efficiency, while significantly reducing the memory footprint.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1.To compute our binary descriptor, we learn from a training set of corresponding image patches several discriminative linear projections that can be computed from a linear combination of a few simple filters. For the example of this figure, we used rectangular filters that can be computed efficiently with integral images, but we also consider box and Gaussian filters which are also efficient to compute. This approach enables us to build our binary descriptor fast while leveraging on training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>a)</head><label></label><figDesc>Box filters (BOX):To create this dictionary we generate a set of box filters of size 5 × 5 that are centered at each coordinate of the image patch. Since our subsampled patches are of size 32 × 32, there are 1,024 elements in this dictionary. b) Gaussian filters (GAUSS): Similarly, we generate a set of Gaussian filters with σ = 3 centered at each coordinate of the image patch. The size of this dictionary is also 1,024. c) Rectangular filters (RECT): We create this dictionary by generating a set of rectangular filters of different sizes centered at each coordinate. We subsample the space of all possible rectangular filters by considering those whose horizontal or vertical edge is equal to 1, 4, 7, 10, . . . . The resulting dictionary size is 34,596.At run-time, to compute the D j x values, we first convolve the image patch with a box filter or a Gaussian filter, or compute the integral image for the patch. All these operations can be done very efficiently. Then, the D j x can be obtained by reading a single value in the result of the convolution, or four values in the integral image in the case of the RECT dictionary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Some images patches from the Liberty dataset [6] used to train the discriminative projections. (b) 95% error rates for different numbers of LDE projections obtained from Eq. (4) and used for dimensionality reduction before and after applying the thresholds (the 95% error rate is the percent of incorrect matches obtained when 95% of the true matches are found). Without binarization, the error rates do not change significantly for different dimensionalities. After binarization, however, the dimensionality has much greater influence, likely because the projections are ranked by decreasing discriminative power, while the binarization gives them equal importance. The minimum of the plotted curve corresponding to the best performance is obtained for 32 dimensions.</figDesc><graphic coords="7,64.26,340.83,121.00,121.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Projections obtained by optimizing Eq. (5), from two LDE projections obtained with Eq. (4). We varied the dictionaries and the maximal numbers of dictionary elements per projection. The columns on the right show the first 8 elements of the sparse representation s which are best viewed on a monitor.</figDesc><graphic coords="8,48.39,404.43,168.01,150.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Performances of the projections obtained by optimizing Eq. (5), from the top 32 LDE projections obtained with Eq. (4). We varied the dictionaries and the maximal numbers of dictionary elements per projection. We also give the results for the projections directly obtained with Eq. (4), referred to as LDE. In parentheses: Number of floating point (f) or binary (b) coordinates, and number of elements. Before binarization, the RECT dictionary provides the best approximation, followed by the GAUSS and BOX dictionary. While the approximation hurts the recognition performances before binarization, it is not true anymore after binarization. The minor improvement can be explained by the smoothing effect of the approximation applied on typically noisy LDE projections which makes the thresholds generalize better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Influence of normalization applied on the D-Brief descriptors before (left) and after (right) binarization. In parentheses: Number of floating point (f) or binary (b) coordinates. Normalization improves the performance only for the real-valued coordinates. The thresholds applied in the binarization step adapt to the discriminative subspace and, we can hence skip the normalization steps with no loss of accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7.Recognition rates for the floating point and binary descriptors for different training and testing datasets. In parentheses: The number of floating point (f) or binary (b) coordinates, and the 95% error rate. Our D-Brief descriptor outperforms all the other binary descriptors based on the intensity tests, namely BRIEF, ORB, and BRISK, while remaining competitive to SURF for higher false positive rates. It is also much shorter than all the other descriptors. The results obtained with LDE<ref type="bibr" target="#b5">[6]</ref> applied to normalized patches are similar to those of D-Brief, but it is much more computationally expensive to compute and match (see Table2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Screenshots of the object detection application. The user first draws a rectangle around the target. The invariance to large scale changes and rotation is obtained by computing the feature point descriptors under different scales and orientations. This is performed on-the-fly and detecting the target runs in real-time with 27 frames per second.</figDesc><graphic coords="14,51.78,50.88,165.91,62.23" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The reference implementation of D-Brief will be made publicly available.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>www.vlfeat.org/ ~vedaldi/code/siftpp.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The POPCOUNT instruction computes the number of bits set to 1, and can be used after a bitwise XOR operation to compute the Hamming distance very efficiently.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SURF: Speeded Up Robust Features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2006</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pinz</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3951</biblScope>
			<biblScope unit="page" from="404" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BRIEF: Computing a Local Binary Descriptor Very Fast</title>
		<author>
			<persName><forename type="first">M</forename><surname>Calonder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ozuysal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Trzcinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strecha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ORB: an efficient alternative to SIFT or SURF</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BRISK: Binary Robust Invariant Scalable Keypoints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Discriminative Learning of Local Image Descriptors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="43" to="57" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LDAHash: Improved Matching with Smaller Descriptors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Strecha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="66" to="78" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning Linear Discriminant Projections for Dimensionality Reduction of Image Descriptors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="338" to="352" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Small Codes and Large Databases for Recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">CHoG: Compressed histogram of gradients A low bit-rate feature descriptor</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Takacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Girod</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Similarity Search in High Dimensions via Hashing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Very Large Databases</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Spectral Hashing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Iterative Quantization: A Procrustean Approach to Learning Binary Codes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning Task-Specific Similarity</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-Supervised Hashing for Scalable Image Retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.: S.-F</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Picodes: Learning a compact code for novel-category recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bergamo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimization with Sparsity-Inducing Penalties</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Obozienski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="106" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Regression Shrinkage and Selection via the Lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Faster and Better: A Machine Learning Approach to Corner Detection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rosten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="105" to="119" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
