<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evolutionary Population Dynamics and Grasshopper Optimization Approaches for Feature Selection Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Majdi</forename><surname>Mafarja</surname></persName>
							<email>mmafarja@birzeit.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Birzeit University</orgName>
								<address>
									<settlement>Birzeit</settlement>
									<country key="PS">Palestine</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ibrahim</forename><surname>Aljarah</surname></persName>
							<email>i.aljarah@ju.edu.jo</email>
							<affiliation key="aff2">
								<orgName type="department">King Abdullah II School for Information Technology</orgName>
								<orgName type="institution">The University of Jordan</orgName>
								<address>
									<settlement>Amman</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><forename type="middle">Asghar</forename><surname>Heidari</surname></persName>
							<email>as_heidari@ut.ac.ir</email>
							<affiliation key="aff3">
								<orgName type="department">School of Surveying and Geospatial Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abdelaziz</forename><forename type="middle">I</forename><surname>Hammouri</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Information Systems</orgName>
								<orgName type="institution">Al-Balqa Applied University</orgName>
								<address>
									<settlement>Al-Salt</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hossam</forename><surname>Faris</surname></persName>
							<email>hossam.faris@ju.edu.jo</email>
							<affiliation key="aff2">
								<orgName type="department">King Abdullah II School for Information Technology</orgName>
								<orgName type="institution">The University of Jordan</orgName>
								<address>
									<settlement>Amman</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Ala'</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Seyedali</forename><surname>Al-Zoubi</surname></persName>
						</author>
						<author>
							<persName><surname>Mirjalili</surname></persName>
						</author>
						<author>
							<persName><surname>Al-Zoubi</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">King Abdullah II School for Information Technology</orgName>
								<orgName type="institution">The University of Jordan</orgName>
								<address>
									<settlement>Amman</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seyedali</forename><surname>Mirjalili</surname></persName>
							<email>seyedali.mirjalili@griffithuni.edu.au</email>
							<affiliation key="aff5">
								<orgName type="department">School of Information and Communication Technology</orgName>
								<orgName type="institution">Griffith University</orgName>
								<address>
									<postCode>4111</postCode>
									<settlement>Nathan, Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Evolutionary Population Dynamics and Grasshopper Optimization Approaches for Feature Selection Problems</orgName>
								<orgName type="institution">Hossam Faris</orgName>
								<address>
									<addrLine>Ala&apos;M. Al-Zoubi, Seyedali Mirjalili</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evolutionary Population Dynamics and Grasshopper Optimization Approaches for Feature Selection Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">452DFDCD59078BC123B0398E7ABB7589</idno>
					<idno type="DOI">10.1016/j.knosys.2017.12.037</idno>
					<note type="submission">Received date: 25 September 2017 Revised date: 4 December 2017 Accepted date: 30 December 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Knowledge-Based Systems Grasshopper Optimization Algorithm</term>
					<term>GOA</term>
					<term>Feature Selection</term>
					<term>Classification</term>
					<term>Metaheuristics</term>
					<term>Evolutionary Population Dynamics</term>
					<term>Binary</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Searching for the optimal subset of features is known as a challenging problem in feature selection process. To deal with the difficulties involved in this problem, a robust and reliable optimization algorithm is required. In this paper, grasshopper optimization algorithm (GOA) is employed as a search strategy to design a wrapper-based feature selection method. The GOA is a recent population-based metaheuristic that mimics the swarming behaviors of grasshoppers. In this work, an efficient optimizer based on the simultaneous use of the GOA, selection operators, and Evolutionary Population Dynamics (EPD) is proposed in the form of four different strategies to mitigate the immature convergence and stagnation drawbacks of the conventional GOA. In the first two approaches, one of the top three agents and a randomly generated one are selected to reposition a solution from the worst half of the population. In the third and fourth approaches, to give a chance to the low fitness solutions in reforming the population, Roulette Wheel Selection (RWS) and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The existence of thousands of applications of information systems complicated the role of extracting useful information from the collected data <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Data mining plays the main role in extracting the useful knowledge from the collected datasets <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. The collected datasets may contain irrelevant and redundant data. Feature selection (FS) is one of the major preprocessing phases that aims to exclude the irrelevant/redundant data from the dataset being processed <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>FS methods can be broadly categorized into three main classes: supervised <ref type="bibr" target="#b6">[7]</ref>, unsupervised <ref type="bibr" target="#b7">[8]</ref>, and semi-supervised methods <ref type="bibr" target="#b8">[9]</ref>. Supervised FS requires the availability of the class labels to select proper features and used for classification problems. While in unsupervised FS, the class labels are not required, and used for clustering tasks. On the other hand, semi-supervised methods applied when part of the data is labeled.</p><p>There are several supervised, semi supervised, and unsupervised FS algorithms in literature. To name a few, the correlation-based feature selection (CFS) <ref type="bibr" target="#b6">[7]</ref>, fast correlation-based filter (FCBF) <ref type="bibr" target="#b9">[10]</ref>, and wavelet power spectrum (Spectrum) <ref type="bibr" target="#b10">[11]</ref> are examples on supervised techniques. While non-negative spectral learning and sparse regression-based dual-graph regularized (NSSRD) feature selection is one of the latest unsupervised techniques proposed by <ref type="bibr">Shang et al. in 2017 [8]</ref>  <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. On the other hand, feature selection via spectral analysis, and forward feature selection <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref> are examples on semi-supervised FS.</p><p>FS process can be accomplished in four major steps <ref type="bibr" target="#b14">[15]</ref>: subset generation, subset assessment, ending criterion, and validation. From the evaluation perspectives, FS methods can be divided to two groups based on selection strategy: wrapper-based and filter-based. In filter-based methods, the selection of a subset is performed independently from the learning algorithm (e.g., classification). The merits of a feature or a subset of them is estimated with regard to specific characteristics of the info <ref type="bibr" target="#b15">[16]</ref>. Examples of filter models include Chi-Square <ref type="bibr" target="#b16">[17]</ref>, Information Gain (IG) <ref type="bibr" target="#b17">[18]</ref>, Gain Ratio <ref type="bibr" target="#b18">[19]</ref>, and ReliefF <ref type="bibr" target="#b19">[20]</ref>. In the wrapper-based methods, the goodness of a subset is evaluated based on a learning algorithm <ref type="bibr" target="#b20">[21]</ref>. Examples of wrapper models include the LVW algorithm <ref type="bibr" target="#b21">[22]</ref> and a neural network-based method <ref type="bibr" target="#b22">[23]</ref>.</p><p>Subset generation is considered as a search process to select a subset of items from the initial set using complete, heuristic search, or a random search <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. The complete search generates all possible subsets to select the best one. If the dataset includes n features, then 2 n subsets will be generated and assessed, which is computationally expensive for the larger size datasets. Random search is another possible policy to select the attributes. It searches for the next feature subset randomly <ref type="bibr" target="#b25">[26]</ref>. The main drawback of the random search strategy is that it may perform as a complete search in the worst case <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>An alternative strategy to the previous two strategies is the heuristic search. Heuristic search can be clarified as a 'depth first' search managed by heuristics. According to Talbi <ref type="bibr" target="#b26">[27]</ref>, metaheuristic search methods can be defined as "upper level general methodologies (templates) that can be used as guiding strategies in designing underlying heuristics to solve specific optimization problems" <ref type="bibr" target="#b26">[27]</ref>. Various metaheuristics such as Grey wolf optimizer (GWO) <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, Whale Optimization Algorithm (WOA) <ref type="bibr" target="#b29">[30]</ref>, Ant Lion Optimization (ALO) <ref type="bibr" target="#b30">[31]</ref>, Firefly Algorithm (FA) <ref type="bibr" target="#b31">[32]</ref>, Particle Swarm Optimization (PSO) <ref type="bibr" target="#b32">[33]</ref>, and Ant Colony Optimization (ACO) <ref type="bibr" target="#b33">[34]</ref> may demonstrate superior efficiencies in tackling feature selection problems when compared to the exact methods <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>. Metaheuristic algorithms have shown improved results and efficiencies in dealing with many real-life applications such as path planning <ref type="bibr" target="#b36">[37]</ref>, clustering <ref type="bibr" target="#b37">[38]</ref>, and power dispatch <ref type="bibr" target="#b38">[39]</ref>. For example, E.S. Ali et al. applied the ALO to find the best location and sizing of renewable distributed generations <ref type="bibr" target="#b39">[40]</ref>. <ref type="bibr">Wu</ref>  planning of solar-powered UAV <ref type="bibr" target="#b36">[37]</ref>. Faris et al. also reviewed the recent variants and applications of the GWO <ref type="bibr" target="#b40">[41]</ref>.The history of metaheuristics is presented in <ref type="bibr" target="#b41">[42]</ref>.</p><p>The GOA is a new efficient nature-inspired population-based metaheuristic algorithm <ref type="bibr" target="#b42">[43]</ref> proposed by <ref type="bibr">Saremi et al.</ref> in 2017 to inspire the idealized swarming behaviors of grasshopper insects in nature. This algorithm can disclose improved results and efficiencies on global unconstrained/constrained optimization and various real-life tasks. The basic GOA has been applied to realize the best parameters of proton exchange membrane fuel cells (PEM-FCs) stack and the results exposed the viability of the GOA-based algorithm in dealing with the steady-state and dynamic models <ref type="bibr" target="#b43">[44]</ref>. In 2017, Wu et al. <ref type="bibr" target="#b44">[45]</ref> proposed a dynamic GOA for optimizing the distributed trajectory of UAVs in urban environments. They proved that this algorithm can attain enhanced results and satisfactory trajectories. Tharwat et al. <ref type="bibr" target="#b45">[46]</ref> developed a modified multi-objective GOA (MOGOA) with external archive for constrained and unconstrained problems. Mirjalili et al. <ref type="bibr" target="#b46">[47]</ref> also developed the basic multi-objective GOA and revealed that the proposed algorithm can tackle several benchmark problem, effectively and with better performance in terms of accuracy of Pareto optimal solutions and the related distribution.</p><p>Although the metaheuristic algorithms do not guarantee finding the best solution in all runs, they can find relatively accurate solutions in a reasonable time <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b47">48]</ref>. Metaheuristics can be classified into two main families; single-solution and population-based algorithms <ref type="bibr" target="#b26">[27]</ref>. In the former class (e.g., Simulated Annealing), one solution is manipulated and transformed during the search process, while a set of solutions is evolved in the former class (e.g., PSO). Single-solution-based algorithms show more exploitative behaviour; which means digging the space around a possible solution whereas the population-based class are more explorative or a mix of both behavior; which means exploring different regions of the space <ref type="bibr" target="#b26">[27]</ref>. When designing a metaheuristic algorithm, these two criteria should be taken into account. High exploration decreases the quality of results and causes an unpromising convergence. This results in a failure to find the target global optimum. However, high exploitation may cause the optimizer to be trapped in Local Optima (LO).</p><p>Evolutionary algorithms (EA) are deep-rooted metaheuristics inspired by natural processes <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>. Genetic algorithms (GA), by J. H. Holland <ref type="bibr" target="#b50">[51]</ref>; and evolutionary programming by L. Fogel et.al <ref type="bibr" target="#b51">[52]</ref> are two different kind of EA. In recent years, many EA are proposed to tackle the optimization</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>problems especially in the field of feature selection <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>. Ant Colony (AntRSAR) and Genetic Algorithm (GenRSAR) are two EAs that have been proposed by Jensen and Shen <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref> and applied to FS problems. For instance, a chaos-based genetic FS method (CGFSO) has been proposed in <ref type="bibr" target="#b57">[58]</ref>. Two hybrid approaches have been proposed in <ref type="bibr" target="#b58">[59]</ref> between the GA and Simulated Annealing (SA) and in <ref type="bibr" target="#b59">[60]</ref> between the GA and Record to Record algorithm. A Scatter Search-based approach (SSAR) proposed by Jue et al. <ref type="bibr" target="#b60">[61]</ref> is another EA-based FS method. Ant Lion Optimizer (ALO), a recent well-regarded metaheuristic, proposed by S. Mirjalili in <ref type="bibr" target="#b61">[62]</ref>, was utilized as a searching mechanism in a wrapper FS method in <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b63">64]</ref>. A chaotic ALO approach was proposed for FS in <ref type="bibr" target="#b64">[65]</ref>. The GWO, as another recent population-based optimizer <ref type="bibr" target="#b28">[29]</ref>, has been successfully employed to tackle several applications like the tuning of fuzzy control systems <ref type="bibr" target="#b65">[66]</ref>. It has been applied to FS problems <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b67">68]</ref> as well. Recently, a new wrapper-based FS algorithm that uses a hybrid Whale Optimization algorithm (WOA) with SA algorithm as a search method was proposed in <ref type="bibr" target="#b68">[69]</ref>.</p><p>EAs are modeled to mimic the evolution of individuals from their initial states to become better adapted to some objectives imposed upon them. These revolutionary paradigms apply some evolutionary operators (mutation and recombination in GA or pheromone updating rules of ACO) to some selected individuals (based on some selection mechanisms; random, tournament, and roulette wheel selection) in the population to generate an offspring. However, these operators affect and manipulate individuals rather that the whole population. Evolutionary Population Dynamics (EPD) is another evolutionary operator that manipulates the whole population rather than manipulating individuals <ref type="bibr" target="#b69">[70]</ref>. Using this operator with EAs will omit the worst individuals from the population rather than improving the best individuals in the population (e.g., recombination in GA). Extremal optimization (EO) <ref type="bibr" target="#b70">[71]</ref> is a metaheuristic algorithm that works based on the idea of EPD. The EO algorithm has been used in many research fields with much success <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74]</ref>. The EPD operator is the main feature that enhanced the performance of this algorithm <ref type="bibr" target="#b27">[28]</ref>.</p><p>This paper presents an efficient GOA-based optimizer with EPD and selection operators are proposed to improve the efficacy of the basic GOA in dealing with FS tasks. In this work, we have made the following key contributions:</p><p>• The significant merits of the EPD operator motivated our attempts to</p><formula xml:id="formula_1">A C C E P T E D M A N U S C R I P T</formula><p>apply it to the recently proposed Grasshopper Optimization Algorithm (GOA) and investigate its effectiveness on FS problems.</p><p>• Four variants of GOA with EPD operator are proposed. In the first two approaches, one of the top three solutions and a randomly generated solution are selected to reposition a solution from the worst half of the population. In the third and fourth approaches, to give a chance to the low fitness solutions to reformulate the population, two different selection mechanisms (namely Roulette Wheel Selection (RWS) and Tournament Selection (TS) are utilized to select the guiding solution from the first half.</p><p>• The proposed approaches have been tested on 22 real benchmarks datasets to show its efficiency for feature selection tasks.</p><p>• The hybrid GOA and EPD operator is proposed for the first time to solve the feature selection tasks.</p><p>• The proposed GOA based approaches have been tested on real datasets with different settings and characteristics to demonstrate its effectiveness and quality of solutions.</p><p>The rest of this paper is organized as follows: Section 2 presents a background about EPD operator. The basics of the GOA algorithm and the hybridization with EPD operator is given in Section 2 as well. Section 3 presents the details of the proposed approaches. In Section 4, the experimental results are presented and results are analysed. Finally, in Section 5, conclusions and future work are given. Table <ref type="table" target="#tab_0">1</ref> describes all the abbreviations used in this paper. EAs are known as stochastic search methods in which a set of solutions (population) is initialized and then gradually improved to become better adapted to the objectives imposed upon them. Some EAs utilize mutation mechanisms to alter the selected solutions, while others employ the crossover operators. These operators aim to evolve the top selected solutions that are mostly the best solutions. The EPD is the process of eliminating the worst solutions in a population by repositioning them around the best ones. The EPD is basically based on the theory of self-organized criticality (SOC) <ref type="bibr" target="#b74">[75]</ref> which</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><formula xml:id="formula_2">A C C E P T E D M A N U S C R I P T</formula><p>indicates that a local change in the population may affect the whole population and provide delicate balances without external organising force <ref type="bibr" target="#b69">[70]</ref>. In the GA, the best solutions are combined using the evolutionary operators (crossover and mutation). In contrast, in the EPD, the worst solutions should be omitted from the current population. Evolutionary programming using self-organizing criticality (EPSCO) <ref type="bibr" target="#b75">[76]</ref> and Extremal optimization (EO) <ref type="bibr" target="#b70">[71]</ref> are two metaheuristics methods that were proposed based on the SCO concept. The EPD is a simple and effective mechanism that can be embedded in different optimizers. It starts by removing the worst solutions from the swarm and then repositioning the removed solutions around the best search agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Grasshopper Optimization Algorithm (GOA)</head><p>The GOA is a recent swarm-based nature-inspired algorithm <ref type="bibr" target="#b42">[43]</ref> proposed by Saremi et al. It mimics the idealized swarming behavior of grasshopper insects in nature. Similarly other population-based algorithms <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b77">78]</ref>, in GOA, a set of candidate solutions (each individual represents a grasshopper) are randomly generated to construct the initial artificial swarm. Next, all candidate agents are evaluated with regard to the fitness values and the best search agent in the current swarm in considered as the target or leader. The target grasshopper starts attracting the other individuals around its location, and all grasshoppers start moving towards the target grasshopper.</p><p>The movement of the i-th grasshopper towards the target grasshopper is denoted as X i and is formulated as in Eq. (1).</p><formula xml:id="formula_3">X i = S i + G i + A i<label>(1)</label></formula><p>where S i is the social interaction, G i is the gravity force on i-th grasshopper, and A i shows the wind advection.The social interaction S i acts as the main component during the grasshopper movement process. It can be calculated as Eq. ( <ref type="formula" target="#formula_4">2</ref>):</p><formula xml:id="formula_4">S i = N j=1, j =i s (d ij ) d ij<label>(2)</label></formula><p>where d ij is the Euclidian distance of the i-th with the j-th grasshopper, and it is calculated as</p><formula xml:id="formula_5">d ij = |x j -x i |. While, d ij = x j -x i</formula><p>d ij is a unit vector from the i-th grasshopper to the j-th grasshopper. The s function is defined as the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T strength of social forces, which can be calculated as follows:</p><formula xml:id="formula_6">s (r) = f e -d l -e -d (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>where f is the intensity of attraction and l is the attractive length scale. Fig. <ref type="figure" target="#fig_3">1</ref> illustrates the impact of s-function on the attraction and repulsion (i.e., social interaction) of the grasshoppers. In this figure, the distance d has been considered in the interval of <ref type="bibr">[0,</ref><ref type="bibr" target="#b14">15]</ref>. The repulsion force between grasshoppers occurs when the distance between them is between 0 and 2.079 units. In the case that the distance between a grasshopper and other agents is 2.079, it enters to the comfort zone, where neither attraction nor repulsion occurs there, while the attraction starts increasing after 2.079 till 4 and then starts decreasing.  Fig. <ref type="figure" target="#fig_3">1</ref> shows that while the distance between grasshoppers becomes larger, s-function returns values close to 0. Thus, for large distances between grasshoppers, s-function is not capable of applying strong forces to them. To overcome this drawback, the distance between agents are mapped between 1 and 4. The shape of the s-function in the interval <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> is shown in Fig. <ref type="figure" target="#fig_3">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(right).</head><p>Different social behaviors can be obtained for the artificial grasshoppers by changing the parameters l and f of s-function in Eq. (3) as shown in Fig. <ref type="figure">2</ref>.</p><p>The conceptual model of the comfort zone and the attraction and repulsion forces between the grasshoppers is also shown in Fig. <ref type="figure">3</ref>.</p><p>The gravity force G i (second component in Eq. ( <ref type="formula" target="#formula_8">4</ref>)) is calculated as follows:</p><formula xml:id="formula_8">G i = -g × e g<label>(4)</label></formula><p>A   where g denotes the gravitational constant and e g is a unity vector in the vertical direction of the surface.</p><formula xml:id="formula_9">(c) f in [0,1], l in [1,2]</formula><p>The wind advection A i (third component in Eq. ( <ref type="formula" target="#formula_10">5</ref>)) is calculated as follows:</p><formula xml:id="formula_10">A i = u × e w<label>(5)</label></formula><p>where u represents a constant drift and e w denotes a unity vector in accordance with the wind.</p><p>In stochastic optimisation, a metaheuristic optimizer must make a fine balance between the exploration and exploitation when conducting the search to find a accurate approximation of the global optimum. Therefore, the mathematical formulation of the GOA, which was presented in Eq. (1),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>should be equipped with special parameters to achieve to this purpose. The mathematical model proposed by Saremi et al. in this regard is as follows:</p><formula xml:id="formula_11">X d i = c N j=1, j =i c ub d -lb d 2 s |x d j -x d i | x j -x i d ij + T d<label>(6)</label></formula><p>where ub d and lb d are respectively the upper bound and lower bounds in the D th dimension, T d is the value of the D th dimension of the target grasshopper. Parameter c is a decreasing coefficient to shrink the comfort zone, attraction, and repulsion regions. Note that S is similar to the s function in Eq. ( <ref type="formula" target="#formula_4">2</ref>). In Eq. ( <ref type="formula" target="#formula_11">6</ref>), gravity force has been considered equal to Zero (no G component), and the wind force (A component) is always towards the target grasshopper</p><formula xml:id="formula_12">T d .</formula><p>The adaptive parameter c is considered as decreasing coefficient, it has been used twice to simulate the deceleration of grasshoppers approaching the source of food and eventually consuming it. The outer c (first c from the left) has been used to reduce the search coverage toward the target grasshopper as the iteration count increases, while the inner c has been used to reduce the effect of the attraction and repulsion forces between grasshoppers with regard to the number of iterations to shrink the comfort, repulsion, and attraction areas.</p><p>The parameter c is updated with the following relation, it should be inversely proportional to the number of executed iterations. This mechanism increases the degree of exploitation as the iteration count increases. It also reduces the comfort zone proportional to the number of iterations.</p><formula xml:id="formula_13">c = cM ax -l cM ax -cM in L<label>(7)</label></formula><p>where cM ax and cM in are respectively the maximum and minimum values of parameter c, l is iteration, and L is the maximum bound of iterations. In <ref type="bibr" target="#b75">[76]</ref>, the authors used 0.00001 and 1 for cM in and cM ax, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Binary GOA (BGOA) for feature selection</head><p>Finding a minimal feature set has been described as a NP-hard problem <ref type="bibr" target="#b78">[79]</ref>. Searching the best combination of features is a challenging problem especially in the wrapper-based methods. Hence, an intelligent optimization method is required to reduce the number of evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>As reported in the literature <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b46">47]</ref>, the GOA algorithm can reveal a superior efficacy in tackling various optimization cases. The merits of GOA motivated us to propose a binary version of the GOA optimizer and use it as the core search engine in this paper when solving FS problems <ref type="bibr" target="#b78">[79]</ref>. Based on the NP-hard nature of FS problems, where the search space can be represented by binary values, some operators of the GOA algorithm need to be modified. In the continuous GOA, each individual updates its position based on its current position, the position of the best grasshopper found so far (target), and the position of all other grasshoppers as in Eq. ( <ref type="formula" target="#formula_11">6</ref>). This behavior of the GOA is similar to other swarm-based techniques (e.g., PSO). In the GOA, the first term of Eq. ( <ref type="formula" target="#formula_11">6</ref>) is analogous to the velocity vector (step) in the PSO. According to the claims provided by Mirjalili and Lewis <ref type="bibr" target="#b79">[80]</ref>, one of the easiest ways to convert an algorithm from continuous to binary version without modifying its structure is to utilize transfer functions. In the proposed approach, the transfer function (see Fig. <ref type="figure" target="#fig_7">4</ref>) use the first term in Eq. ( <ref type="formula" target="#formula_11">6</ref>), that is re-defined ∆X in Eq. ( <ref type="formula" target="#formula_14">8</ref>) as the probability for changing of the position elements. Sigmoidal function is a common transfer function proposed by Kennedy and Eberhart <ref type="bibr" target="#b80">[81]</ref> as Eq. ( <ref type="formula" target="#formula_15">9</ref>):</p><formula xml:id="formula_14">∆X = c N j=1, j =i c ub d -lb d 2 s |x d j -x d i | x j -x i d ij<label>(8)</label></formula><formula xml:id="formula_15">T (∆X t ) = 1 1 + e -∆Xt<label>(9)</label></formula><p>where ∆X represents the step vector of a search agent at a specific iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The position of the current grasshopper will be updated as expressed in Eq. ( <ref type="formula" target="#formula_16">10</ref>) based on the probability value T (∆X t ) obtained from Eq. ( <ref type="formula" target="#formula_15">9</ref>).</p><formula xml:id="formula_16">X k t+1 (t + 1) = 1 If rand &lt; T (∆X t+1 ) 0 If rand ≥ T (∆X t+1 )<label>(10)</label></formula><p>Algorithm 1 Pseudo code of the BGOA algorithm Initialize the GOA parameters cM ax, cM in, and maximum iterations L Initialize a set of random solutions X i (i = 1, 2, . . . , n) as initial population Calculate the fitness of all agents Remark the best solution as the Target Set T as the best solution while t &lt; L do Update c using Eq. ( <ref type="formula" target="#formula_13">7</ref>) for each individual in the population do Normalize the distances between grasshoppers into <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> Update the step vectors (∆X) using Eq. ( <ref type="formula" target="#formula_14">8</ref>) Update position vectors using Eq. ( <ref type="formula" target="#formula_16">10</ref>) Update Target if there is a better solution in population t = t + 1 return T</p><p>In the wrapper FS, a learning algorithm should be involved in the evaluation of the selected feature subset. In this work, the k-Nearest Neighbor (k-NN) classifier <ref type="bibr" target="#b81">[82]</ref> is utilized to attain the classification accuracy of the solution. The higher classification accuracies show that the relevant solution is better. Moreover, since the aim of FS is to eliminate the number of selected features, the smaller the number of features in the solution, the better the solution is. These are two contradictory objectives that should be taken into consideration when designing an objective function for FS algorithms. In this work, the fitness function in Eq. ( <ref type="formula" target="#formula_17">11</ref>) that can balance among the selected features in each agent (minimum) and the accuracy of classification (maximum) is used to evaluate the selected subsets in all approaches.</p><formula xml:id="formula_17">F itness = αγ R (D) + β |R| |N |<label>(11)</label></formula><p>where γ R (D) is the classification error rate of the known classier, |R| is the</p><formula xml:id="formula_18">A C C E P T E D M A N U S C R I P T</formula><p>number of selected features and |N | is the number of features, α and β are two parameters to reflect the role of classification rate and length of subset, α ∈ [0, 1] and β = (1α) adopted from <ref type="bibr" target="#b62">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Applying the EPD strategy to BGOA</head><p>As discussed earlier, the EPD eliminates the worst solutions from the population and replaces them by generating neighbor solutions around the good ones. The EPD mechanism is a simple but effective operator for populationbased techniques <ref type="bibr" target="#b69">[70]</ref>, therefore, it is applied to the conventional GOA here since it is also a stochastic population-based optimizer. To equip the GOA algorithm with the EPD technique, the swarm of grasshoppers is divided into two parts after sorting it based on the fitness values. The half of the worst grasshoppers is eliminated and reinitialized based on four different strategies depending on the good half of the population.</p><p>In this paper, four different strategies are utilized to combine the EPD scheme with the binary BGOA. These versions can be categorized into two main classes based on the implemented selection operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">BGOA_EPD with random selection operator</head><p>The first model for hybridizing is to us random selection operator. For this purpose, one solution among the best three grasshoppers from the population is selected in addition to a random grasshopper. Then, the leader of 'poor' solution will be selected randomly. To implement this idea, two different approaches are designed that work based on the random selection technique:</p><p>1. BGOA_EPD: it is the simplest hybrid form of the EPD and BGOA algorithms. In this approach, the random selection mechanism is employed to select the solutions. This method also uses a simple mutation operator.</p><p>In the first approach, the top three individuals are selected and a fourth solution is generated randomly. Each solution in the worst half is repositioned around any of these four solutions depending on a random number. The process is straightforward; a random number is generated X r in each iteration and then one of the following four choices will be applied for repositioning of the poor solution: when X r ∈ [0, 0.25], then the best solution is used, when X r ∈ [0.25, 0.5], then the second best solution is used, when X r ∈ [0.5, 0.75], then the third best solution is employed, and when X r ∈ [0.75, 1], a random solution is used.</p><formula xml:id="formula_19">A C C E P T E D M A N U S C R I P T ... ... N N-1 1+N/2 N/2</formula><p>List of worst grasshoppers</p><formula xml:id="formula_20">N-2 2 1 3 X r</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random agent</head><p>List of three best solutions and a random one</p><formula xml:id="formula_21">... N N-1 1+N/2 N-2</formula><p>New repositioned list List of best grasshoppers The selected solution will be used as a starting point to reposition the poor solution. Repositioning the poor solutions around the best solutions aims to heighten the median of the swarm in each step. However, this process may cause a premature convergence of the algorithm. As a remedy, a randomly generated solution is used in the first rule to promote exploration and prevent trapping in local optima.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BGOA_EPD_CM: this version is similar to the BGOA_EPD and the</head><p>only difference is that it also uses a crossover and a mutation operator.</p><p>In the second approach, a random number is generated and one solution is selected similar to the first strategy, then the selected solution is mutated to improve the exploration tendency of the algorithm. The mutated solution is then crossover with the poor solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">BGOA_EPD with special selection operator</head><p>According to the findings of Talbi <ref type="bibr" target="#b26">[27]</ref>, "it does not mean that using better solutions as initial solutions will always lead to better local optima" <ref type="bibr" target="#b26">[27]</ref>. The best individuals may bias the searching process and this may cause a premature convergence and a loss of diversity. For this reason, instead of selecting one of the three best solutions like the previous versions, two well-regarded selection mechanism are applied to select a solution from the first half of the population. For each solution in the second half of the population, select a solution from the first half using the selection mechanism; mutate and then crossover it with the poor solution. In this regard, the alternative method for hybridizing the EPD with the BGOA in the BGOA-EPD algorithm is to also employ a special selection mechanism. There are two well-known selection techniques: Roulette wheel selection (RWS) <ref type="bibr" target="#b82">[83]</ref> and the TS <ref type="bibr" target="#b83">[84]</ref>. These methods are utilized in this work. Therefore, another</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>two different strategies that can be developed for the BGOA_EPD are:</p><p>1. BGOA_EPD_Tour: in this version, a solution from the first half of the swarm is selected using the TS operator, then the same crossover and mutation operators utilized in the BGOA_EPD version are applied on the obtained solution.</p><p>The TS is the most popular selection mechanism used with GA due to its efficiency and simple implementation. In TS, a set of n individuals are randomly selected from the whole population, then the best individual among the selected individuals will be selected to reposition the poor solution. The number of selected individuals called tournament size T s. The advantage of T S is that it gives a chance to all individuals to guide the poor solutions, which preserve the diversity of the BGOA_EPD_Tour algorithm. An example of the TS mechanism for the BGOA_EPD_Tour is illustrated in Fig. <ref type="figure" target="#fig_9">6</ref>, where three individuals are selected (T s = 3) and the best solution among them is picked out. After applying the TS operator,the mutation operator with suitable mutation rate is applied the selected grasshopper hoping to find a better solution in the neighbor of the selected solution and to avoid the BGOA_EPD_Tour algorithm from the premature convergence. After that, the poor solution is repositioned around the resulting solution by applying a crossover operator. In the BGOA_EPD_Tour, a solution is selected using the TS to give a chance to the lower fitness solution in the first half of the population to be selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BGOA_EPD_RWS: This version is similar to the BGOA_EPD_Tour</head><p>version and the only difference is that it uses the RWS operator instead of the TS operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>In the BGOA_EPD_RWS, in each iteration of the BGOA process, for each solution in the worst half of the population, a solution from the first half is selected using the RWS operator. In RWS, individuals are selected with a probability based on their fitness values. In this selection strategy, a roulette wheel is formulated with a circumference equals the sum of all fitness values of the individuals (see <ref type="bibr">Fig 7)</ref>.  Each individual will have a segment with a size proportional to its fitness. The probability to select an individual can be seen as spinning a roulette wheel, and the segment where the pointer stops is taken and the corresponding individual will be selected. Obviously, the individuals with the largest fitness (i.e. largest segment sizes) have higher probability of being selected than those who have lower probability (i.e. smallest segment sizes). The advantage of RWS that it does not ignore any individual in the population, therefore, it preserves the diversity of the population. After selecting a solution using the RWS operator, it is mutated to explore more regions of the feature space, then; the resulted solution from the mutation operator is used to reposition a solution from the second half by applying a crossover operator.</p><p>The mutation rate r for all related approaches is shown in Eq. <ref type="bibr" target="#b11">(12)</ref>. The parameter r is decremented from 0.9 to 0,linearly, according to the iteration number i.</p><formula xml:id="formula_22">r = 0.9(1 + (1 -i) L -1 )<label>(12)</label></formula><p>where L was the maximum number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>The main difference between these versions is that they use different selection operators. In addition, the BGOA_EPD_CM uses the best solutions in the population while BGOA_EPD_RWS and BGOA_EPD_Tour variants do not use this policy. They use other solutions from the first half of the population.</p><p>The overall pseudo code of the BGOA_EPD algorithm is described in Algorithm 2. Flowchart of the BGOA_EPD is also demonstrated in Fig. <ref type="figure" target="#fig_12">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Pseudo code of the BGOA_EPD approaches</head><p>Initialize GOA parameters (cM ax, cM in, and L) Initialize a set of random solutions X i (i = 1, 2, . . . , n) as initial population Obtain the fitness of all agents Remark the best solution as Target while t &lt; L do Update c using Eq. ( <ref type="formula" target="#formula_13">7</ref>) for each individual in the population do Normalize the distances between grasshoppers into <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> Update the step vectors (∆X) using Eq. ( <ref type="formula" target="#formula_14">8</ref>) Update position vectors using Eq. ( <ref type="formula" target="#formula_16">10</ref>) Update Target if there is a better solution in the population Sort the population based on the fitness for i = (n/2) + 1 to n do Update the position of ith grasshopper using EPD approach Note that the computational complexity of the proposed BGOA_EPD is not significantly different from the GOA. The computational complexity of GOA is of O(t × d × n 2 ) where t indicates the number of iterations, d is the number of variables, and n shows the number of solutions. The proposed binary operators do not change the computational complexity since they have been applied to the position updating mechanism of the original GOA. To re-initialize 50% of solutions, however, the additional complexity of O(n/2) is required, so the overall computational complexity of the proposed BGOA_EPD is O(t × d × n 2 + n/2). Note that due to the need to re-evaluate the objective value of half of the solutions, the number of function evaluations in BGOA_EPD is n/2 units more that of GOA.</p><formula xml:id="formula_23">t = t + 1 return Target A C C E P T E D M A N U S C R I P T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results and discussions</head><p>In this section, the efficacy of the proposed hybrid EPD_BGOA versions in dealing with 22 well-regarded datasets including Exactly, Breastcancer, Zoo, IonosphereEW, Vote, WaveformEW, WineEW, HeartEW, Colon, Clean1, M-of-n, Tic-tac-toe, KrvskpEW, Leukemia, and SonarEW is investigated.</p><p>Table <ref type="table" target="#tab_1">2</ref> reports the brief description of the 22 datasets utilized. For more details, interested readers are referred to the UCI source. These benchmark cases have been studied in several well-established works. The utilized test set cover different traits and the instances of small to high dimensional datasets and can examine the searching competencies of EA and metaheuristics in tackling the FS problems. Different variants of BGOA algorithm were employed to search for the best reduct with the minimum error rate based on KNN classifier (where K = 5 <ref type="bibr" target="#b84">[85]</ref>) with the Euclidean distance metric. For evaluation purposes, each datasets is divided into training and testing sets where 80% of the instances in the datasets were used for training purposes and the rest of them is utilized for testing tasks <ref type="bibr" target="#b85">[86]</ref>.</p><p>All the fair tests and the computed results in this research are conducted and prepared on a PC with Intel Core(TM) i5-5200U 2.2GHz CPU and 4.0GB RAM. The maximum iterations (L) is set to 100 and the number of search agents (N ) is 10. Additionally, all statistical results are recorded over 30 independent runs. The dimension of cases is equal to the number of features in each experimented dataset. The α and β parameters in the fitness equation are set to 0.99 and 0.01, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation of proposed methods</head><p>In this part, the efficiency, convergence and the quality of the results of four developed hybrid approaches are deeply measured and compared to each other's to distinguish the preeminent variant for more advanced investigations. The four techniques utilizing different operators and the random, TS and RWS mechanisms are substantiated and compared to judge and discover the influence of the crossover and mutation strategies and using a specific selection scheme in preference to the random selection policy on either the results or efficacy of the proposed variants. The performance of the proposed optimizers is evaluated and compared in terms of the average classification accuracy (Acc), selection size, and fitness values, computational times, and convergence rates over all runs of each technique. The Acc is measured via the nominated features on the used dataset. The standard deviation (Std-Dev) of all proposed versions is also provided for all metrics, datasets and algorithms.</p><p>Table <ref type="table" target="#tab_2">3</ref> exposes the attained Acc and related StdDev results for the BGOA_S algorithm versus other designed versions. Tables 4-6 also reflect the average selected attributes, fitness, and CPU time values along with the related StdDev for the proposed techniques.</p><p>From Table <ref type="table" target="#tab_2">3</ref>, it can be detected that the hybrid BGOA_EPD_Tour can Regarding the Acc rates, the BGOA_EPD_Tour can outperform the BGOA_S over 19 problems and there is a marked shift in the rates for the BGOA_EPD_Tour and improvement varies from 1% to 12.5%.A comparable</p><formula xml:id="formula_24">A C C E P T E D M A N U S C R I P T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>pattern can be detected from the results of BGOA_EPD_RWS, it outperform the BGOA_S technique on 17 datasets, whereas the BGOA_EPD_CM and BGOA_EPD outperform the basic optimizer on 15 problems.</p><p>According to the selected attributes (Atts) in Table <ref type="table" target="#tab_3">4</ref>, it is seen that the simple BGOA_S is better than the BGOA_EPD_Tour on 19 datasets. It also is superior to the BGOA_EPD_RWS and BGOA_EPD_CM in dealing with 17 problems. Inspecting the fitness measures (Fitness) in Table <ref type="table" target="#tab_4">5</ref>, the best optimizer is the BGOA_EPD_Tour. It shows the lowest values for the objective function in tackling the 10 datasets: Breastcancer, Exactly, Exactly2, KrvskpEW, M-of-n, PenglungEW, Tic-tac-toe, Vote, Colon, and Leukemia. The BGOA_EPD_RWS has shown a relatively good performance in dealing with 4 test cases: BreastEW, CongressEW, SonarEW, and Zoo. The BGOA_EPD_CM has provided a lower fitness for IonosphereEW, SpectEW, WaveformEW, Clean1, and Semeion datasets.</p><p>From Table <ref type="table" target="#tab_5">6</ref>, it can be observed that the BGOA_S is the fastest approach in a same computational environment with other optimizers. When comparing the algorithms with the TS-based and RWS-based selection operators, it is seen that for 19 datasets, BGOA_EPD_RWS outperforms the BGOA_EPD_Tour. For only BreastEW, Exactly, and Tic-tac-toe, the BGOA_EPD_Tour has a slightly better run speed. The average ranking of the proposed binary and hybrid versions in terms of Acc, Att, and fitness metrics is presented in Table <ref type="table" target="#tab_7">8</ref>. In Table <ref type="table" target="#tab_7">8</ref>, the rank of each method on a dataset is calculated, then, the sum of the ranks based on each metric is obtained. The total sum shows the sum of the ranks of each optimizer based on all metrics. The final rank shows the final average place of each algorithm in handling all 22 datasets. The utilized ranking system gives a lower place to those items that have better value according to a specific metric. The overall and final ranks are inside <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref> interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Table <ref type="table" target="#tab_7">8</ref> divulges that the BGOA_EPD_RWS and BGOA_EPD_Tour has achieved to the best places.</p><p>Regarding the Acc metric, the BGOA_EPD_Tour won the competition and BGOA_EPD_RWS was the second winner, while the BGOA_EPD_CM and BGOA_EPD were both the third front-runners and BGOA_S gained the last stage. Based on the orders for the Fit measure, the best solvers can be spotted as the BGOA_EPD_Tour, BGOA_EPD_RWS, BGOA_EPD_CM, BGOA_EPD, and BGOA_S, respectively. Regarding the Att measure, the best is the BGOA_S, while the BGOA_EPD_Tour and BGOA_EPD_RWS have acquired the second and third places.</p><p>Based on the final ranks, the best two algorithms (BGOA_EPD_RWS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>and BGOA_EPD_Tour) have demonstrated very competitive performances and the ranks are 172 and 176, respectively. There is a notable gap between the ranks of top winners having the RWS and TS selection schemes and the third front-runner, the BGOA_EPD_CM that runs the mutation and crossover to relocate the feeble grasshoppers based on top front-runners of the population. The reason might be that the BGOA_EPD_CM and BGOA_EPD have utilized the best grasshoppers of the population, and this can bias the exploration phase, which has instigated premature convergence and a loss of diversity in the population. This effect of best solutions has decreased the quality of the outcomes, and consequently, the grades of the BGOA_EPD_CM and BGOA_EPD in the ranking system have dropped compared to the BGOA_EPD_Tour and BGOA_EPD_RWS. From the other side, BGOA_EPD_Tour inherits the advantage of TS, which can preserve the diversity of grasshoppers and consequently, the BGOA_EPD_Tour has an advanced potential to retain and recover a stable balance between the exploration and exploitation inclinations. In addition, BGOA_EPD_Tour applies the mutation scheme to the selected grasshopper hoping to find a better solution in the neighbor of the selected solution and to avoid the LO. For these reasons, the BGOA_EPD_Tour can outperform all based on Acc and fitness measures.</p><p>Based on final ranks, the best version is the BGOA_EPD_RWS. The reason is that this version does not ignore any grasshopper in the population, so it is capable of preserving the diversity of the agents, which can help the BGOA_EPD_RWS to perform deeper exploration levels. This fact has enabled the BGOA_EPD_RWS to avoid LO and discover better results. In addition, after selecting an agent with the RWS operator, it is mutated to explore more areas of the feature space, then; the resulted solution is used again to reposition a solution from the second half by applying the crossover operator. these operators also improve the efficacy of the BGOA_EPD_RWS in balancing the exploration and exploitation as compared to other developed versions.</p><p>The convergence trends for the all proposed variants according to the fitness measure on all 22 datasets are also compared and demonstrated in Figs. <ref type="figure" target="#fig_14">9</ref> and<ref type="figure" target="#fig_15">10</ref>.</p><p>From Fig. <ref type="figure" target="#fig_14">9</ref>, it can be observed that the BGOA_EPD_RWS has exposed the best curves compared to other versions in tackling the BreastEW, Con-gressEW, Lymphography, and SonarEW problems. The BGOA_EPD_Tour   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>can reveal a quicker tendency than others in treating the Breastcancer, Ex-actly2, HeartEW, KrvskpEW, M-of-n, and penglungEW datasets, while the BGOA_EPD has stagnated to LO in early steps of the exploration phase, for example when solving the Breastcancer, CongressEW, Exactly, HeartEW, IonosphereEW, KrvskpEW, Lymphography, and penglungEW tasks. From the curves on Fig. <ref type="figure" target="#fig_14">9</ref>, it can be inferred that the approaches utilizing the TS and RWS schemes have a head-to-head convergence proclivity.</p><p>It seems that the TS and RWS-embedded variants perform better than versions employing random selection and top solutions for rearranging of the worst grasshoppers. This reveals that enhancing the median of all population using only top solutions and a random grasshopper may increase the chance of BGOA_EPD to be easily captivated in LO when penetrating the fruitless regions of the feature space. The trends of the BGOA_EPD_CM also support that the crossover and mutation schemes has heightened the inclusive leaning of the BGOA_EPD in balancing the exploration and exploitation traits. Therefore, it is seen that the BGOA_EPD_CM can converge faster to better results than the BGOA_EPD in basically all cases. And yet, the BGOA_EPD_CM cannot surpass both BGOA_EPD_Tour and BGOA_EPD_RWS in terms of convergence results, except in solving the IonosphereEW. Therefore, it is seen that using selection mechanisms has alleviated the unripe convergence shortcoming of the BGOA_EPD. In RWS-based version, the door is open for the weak solution in the first half of the population to be selected but the better solutions have more chance. In this regard, the BGOA_EPD_Tour attains better results than BGOA_EPD_RWS.</p><p>According to Fig. <ref type="figure" target="#fig_15">10</ref>, the convergence shortcomings of the BGOA_EPD can still be detected. However, it converged to improved results for the Clean1. The BGOA_S can be better than the BGOA_EPD regarding the convergence and it shows competitive trends for all cases.</p><p>The BGOA_EPD_CM has revealed enriched tendencies compared to the BGOA_EPD and BGOA_S, mainly on SpectEW, WaveformEW, WineEW, and Semeion problems, which has slightly outperformed other methods. It shows that the extra operators assist the BGOA_EPD in fleeing from the LO. When the TS-based selection theme has met the BGOA_EPD, it has shown best curves on the Tic-tac-toe, Vote, Colon, and Leukemia, whereas the BGOA_EPD_RWS has not exposed the excellent curves, except on the Zoo. The reason is that the TS can enhance and preserve the diversity of the solutions, which can encourage more stable balance between the local</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>and global search trends. Then, it helps the BGOA_EPD_Tour to uncover superior trends on harder cases like the Leukemia with 7129 and Colon with 2000 features. It is seen that the tendencies of BGOA_EPD_Tour and BGOA_EPD_RWS are very competitive on the WineEW and Wave-formEW.</p><p>Considering all results, convergence curves and final rankings of algorithms, it can be recognized that two best versions are the BGOA_EPD_RWS and BGOA_EPD_Tour algorithms. In the next section, the BGOA_EPD_Tour, which is the best hybrid variant of BGOA_EPD ,is considered to be further compared to other well-established optimizers with regard to the efficacy, performance on different metrics and convergence behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with other metaheuristics</head><p>In this section, the efficacy and qualitative results of the BGOA_EPD_Tour techniques is compared to the several well-regarded and related optimizers in the FS field from different aspects. The binary versions of the GWO (bGWO) <ref type="bibr" target="#b66">[67]</ref>, GSA (BGSA) <ref type="bibr" target="#b86">[87]</ref>, and BA (BBA) <ref type="bibr" target="#b87">[88]</ref> are utilized here to deeply investigate the comparative efficiency of these well-established methods against the developed BGOA-based version.</p><p>All trials have completed during a same condition and all conditions were similar to the described info in preceding section. The parameters of optimizers are sensibly selected using many trial and error processes to comprehend the finest feasible settings. Table <ref type="table" target="#tab_8">9</ref> shows the the used parameters. Table <ref type="table" target="#tab_9">10</ref> exposes the attained Acc and related StdDev results for the proposed algorithms versus other metaheuristics. Tables 11-13 also reflect the average selected attributes, fitness, and CPU time values along with the related StdDev for the compared techniques. Table <ref type="table" target="#tab_3">14</ref> shows the results of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Wilcoxon sum rank statistical test for the accuracy results in Table <ref type="table" target="#tab_9">10</ref>. For the used test, the best technique for each dataset is considered as the base method to be compared with other peers, independently. From Table <ref type="table" target="#tab_9">10</ref>, it is seen that the hybrid BGOA_EPD_Tour can evidently outperform all contestants on 20 datasets. The bGWO also outperform others on 2 problems: BreastEW and clean1. In comparison with the BGSA, the BGOA_EPD_Tour can provide better rates on a11 problems. In dealing with 21 datasets, the classification accuracies of the BGOA_EPD_Tour have improved in the interval of 0.5% (Semeion) to 30% (Exactly) in comparison with the BGSA. It can also outperform the BBA on all 22 datasets.</p><p>The best and worst average Acc that the bGWO have reached is 97.45% and 66.13% on Zoo and Colon datasets, respectively. For M-of-n case, the BGOA_EPD_Tour have reached to 100% accuracy, while bGWO has</p><formula xml:id="formula_25">A C C E P T E D M A N U S C R I P T</formula><p>the accuracy of 89.41%, which shows the superior efficacy of the proposed EPD-based optimizer. Based on the overall ranks, the BGOA_EPD_Tour has achieved to the first place and bGWO, BGSA, and BBA are the next choices, respectively. several substantial improvements in the StdDev index can also be detected. The main reason for improved efficacy of the BGOA_EPD_Tour is that the poor solutions are repositioned around the better ones in the BGOA_EPD_Tour using the EPD, and during this process, the selection mechanisms has assisted the proposed approach to maintain the diversity of swarm, and then, recover a fine balance between the exploration and exploitation. Therefore, in the case of stagnation to LO, they can escape from them using the random nature behind the utilized operators.</p><p>From the results reflected in Table <ref type="table" target="#tab_10">11</ref>, it is evident that the BBA algorithm is better than other algorithms on 19 datasets. The BGOA_EPD_Tour and BGSA algorithms have attained the next ranks. For CongressEW and Vote, is observed that the BGOA_EPD_Tour can show the best results. </p><formula xml:id="formula_26">A C C E P T E D M A N U S C R I P T</formula><p>Inspecting the results in Table <ref type="table" target="#tab_11">12</ref>, it is observed that the proposed BGOA_EPD_Tour is capable of outperforming all algorithms and revealing the best costs in realizing 20 datasets.</p><p>The BGOA_EPD_Tour shows superior costs compared to the BBA, BGSA, and bGWO algorithms on 90.9%, 95.45%, and 90.9% of the datasets, respectively. The reason is that the TS-based selection operator assists the algorithm to maintain the diversity of grasshoppers. It also utilizes top solutions to guide the poor ones and this strategy improves the exploitative behavior of algorithm. Hence, the BGOA_EPD_Tour an enriched potential to retain and recover a stable balance between the exploration and exploitation phases in dealing with difficult feature spaces. The effect of selection operators are seen in the background of the improved results.</p><p>The proposed BGOA_EPD_Tour has also attained an acceptable Std-Dev values. Regarding the fitness, the bGWO show a good efficacy on 2 datasets. The penglungEW, Colon, Tic-tac-toe, krvskpEW cases can be considered as relatively large datasets and the fitness values of the developed EPD-based version is relatively less than other optimizers.</p><p>Based on Table <ref type="table" target="#tab_12">13</ref>, the BGSA is the fastest approach and the binary BBA is placed at the next rank.</p><p>Table <ref type="table" target="#tab_3">14</ref> shows all datasets that the proposed method provides the best results (20 cases), the improvements are meaningful and accuracy of classification results has significantly increased compared to the other competitors.</p><p>The convergence curves for the compared algorithms on all datasets are demonstrated in Figs. <ref type="figure" target="#fig_16">11</ref> and<ref type="figure" target="#fig_17">12</ref>. It can be seen that the BGOA_EPD_Tour has an accelerated behavior on all 22 problems. Based on the last found solutions, which can be seen from the ending points of the curves, it can outperform all techniques in tackling 20 problems except the BreastEW and Clean1 datasets, which no stagnation behavior occurs but the concluding marks are not better than the bGWO algorithm. Premature convergence behaviors can be detected in the curves of the bGWO, BBA and BGSA in dealing with several cases including the Exactly, Vote, Tic-tac-toe, SpectEW, and Zoo cases. For 20 datasets, the curves BGOA_EPD_Tour are superior to those of other competitors. Based on the aforementioned remarks, it can be recognized that the novel EPD-based operators have strengthened the overall tradeoff between the exploratory and exploitative steps. Consequently, it alleviates the immature convergence drawbacks of the BGOA in dealing with FS problems.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T on all 18 available datasets and it can provide better than the bGWO2 on 17 datasets. These results also affirm that the proposed EPD-based and selection operators in the BGOA_EPD_Tour not only enriched its exploitation and exploitation capabilities and alleviated its stagnation problems but also enhanced the quality of the attained solutions for 22 datasets with various dimensions and characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison with filter-based techniques</head><p>In this subsection, the classification of the EPD-embedded BGOA optimizer is compared to five well-known filter-based techniques <ref type="bibr" target="#b90">[91]</ref>: correlationbased feature selection (CFS) <ref type="bibr" target="#b6">[7]</ref>, fast correlation-based filter (FCBF) <ref type="bibr" target="#b9">[10]</ref>, fisher score (F-score) <ref type="bibr" target="#b91">[92]</ref>, IG <ref type="bibr" target="#b92">[93]</ref>, and wavelet power spectrum (Spectrum) <ref type="bibr" target="#b10">[11]</ref>. These filter-based techniques have carefully selected from two main classes: univariate and multivariate approaches. The IG, Spectrum, and F-Score are from the univariate strategies, which do not reflect the dependencies of the features in the assessment measure. In addition, CFS and FCBF are from the other category, which can employ the dependencies of the features. These approaches are investigated here because they have different mechanisms for utilizing the class labels of the training info to realize the relevance of analyzed features. The supervised approaches such as CFS, FCBF, F-Score and IG can utilize class labels whereas the unsupervised techniques such as Spectrum cannot handle labels for assessing the features. The results for the filter-based techniques after 20 runs are compared with the rates of the BGOA_EPD_Tour in Table <ref type="table" target="#tab_13">16</ref>. Inspecting the comparative results in Table <ref type="table" target="#tab_13">16</ref>, it is seen that the TSbased optimizer can outperform other algorithms on 17 datasets, while the IG and F-Score methods have obtained the best results for 2 datasets. It surpassed the supervised univariate approaches such as F-Score and IG, and the supervised multivariate types such as CFS and FCBF, and the unsupervised Spectrum technique. Furthermore, the results indicate that the wrapper-based FS procedures can provide superior rates in comparison with the filter-based versions since they can utilize both labels and dependencies during the selection of associated subsets. It can be concluded that the proposed algorithm has merits among other well-regarded optimizers and outperforms some well-known filter-based approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>Taken together, the results and discussions showed that the binary operators integrated into the BGOA algorithm were beneficial. The proposed operators slightly change the solutions that accelerates local search and convergence of the proposed algorithm. The EPD operator randomly changes the worst solutions, which promotes diversity and global search of the proposed algorithm. In feature selection problems, the shape of search space changes for every new dataset. Feature selection is normally considered for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>problems with medium or large number of features as well. To handle these difficulties, therefore, we need an efficient optimization algorithm that shows less local optima stagnation and high accuracy. Both operators proposed in the method assist BGOA_EPD in handling these difficulties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and future directions</head><p>In this study, an efficient GOA-based optimizer with EPD and selection operators was proposed to improve the efficacy of the basic GOA in dealing with FS tasks. The proposed GOA_EPD approaches were utilized extensively to tackle 22 benchmark datasets. The overall classification accuracy, selected features, fitness, consumed CPU time, and convergence behaviors of all hybrid versions were compared in detail to select the best version of the BGOA_EPD. The BGOA_EPD_Tour and BGOA_EPD_RWS has obtained the best place among four developed hybrid variants. The BGOA_EPD_Tour technique was utilized and compared in detail to various well-known metaheuristic-based and filter-based FS methods. The comprehensive comparative results and analysis revealed the improved efficacy of the proposed algorithm for solving different FS tasks.</p><p>Future studies can focus on the application of the EPD strategy to other population-based optimizers. The efficacy of the proposed binary GOA and EPD-based algorithms can also be employed to tackle other data mining problems. For future works, we intended to compare the proposed GOA-EPD with different classes of FS methods in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>. The subspace learning-based graph regularized (SGFS) technique and self-representation based dual-graph regularized feature selection clustering (DFSC) are also well-established FS A C C E P T E D M A N U S C R I P T techniques proposed by Shang et al. in 2016</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>et al. utilized the WOA for path A C C E P T E D M A N U S C R I P T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>When d is inside[0,<ref type="bibr" target="#b3">4]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Function s when l = 1.5 and f = 0.5 and closer window when d changes in [0,4].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>f =0.5 and l in<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: behavior of the function s based on l and f .LOCATION OF TARGET</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Sigmoidal Transfer function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The sorted population and related agents that should be repositioned around the best solutions and a random one</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The mechanism of TS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Selection strategy with roulette wheel mechanism</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The overall steps for proposed BGOA_EPD approach</figDesc><graphic coords="20,128.85,152.88,311.73,306.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Convergence curves of the proposed approaches for Breastcancer, BreastEW, Exactly, Exactly2, HeartEW, Lymphography, M-of-n, penglungEW, and SonarEW, SpectEW, CongressEW, and IonosphereEW datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Convergence curves of the proposed approaches for KrvskpEW, Tic-tac-toe, Vote, WaveformEW, WineEW, Zoo, Clean1, Semeion, Colon, and Leukemia datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Convergence curves for BGOA_EPD_Tour and other state-of-art methods for Breastcancer, BreastEW, Exactly, Exactly2, HeartEW, Lymphography, M-of-n, penglungEW, and SonarEW, SpectEW, CongressEW, and IonosphereEW datasets..</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Convergence curves for BGOA_EPD_Tour and other state-of-art methods for KrvskpEW, Tic-tac-toe, Vote, WaveformEW, WineEW, Zoo, Clean1, Semeion, Colon, and Leukemia datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>List of abbreviations</figDesc><table><row><cell cols="2">Abbreviations Expansions</cell></row><row><cell>Acc ACO ALO Atts BGOA BGWO CFS CGFSO CM DFSC EA EO EPD EPSCO FA FCBF FS F-score GOA GWO GA IG k-NN LO NSSRD PSO RWS SA SGFS SOC SSAR StdDev TS Ts WOA</cell><cell>Accuracy Ant Colony Optimization Ant Lion Optimizer Attributes Binary GOA Binary GWO Correlation-based Feature Selection Chaos-based Genetic FS Method Crossover and Mutation Self-representation Based Dual-graph Regularized Clustering Evolutionary Algorithms Extremal Optimization Evolutionary Population Dynamics Evolutionary Programming using Self-Organizing Criticality Firefly Algorithm Fast Correlation-based Filter Feature Selection Fisher Score Grasshopper Optimization Algorithm Grey Wolf Optimizer Genetic Algorithms Information Gain k-Nearest Neighbor Local Optima Non-negative Spectral Learning and Sparse Regression-based Dual-graph Regularized Particle Swarm Optimization Roulette Wheel Selection Simulated Annealing Subspace Learning-based Graph Regularized Self-Organized Criticality Scatter Search-based Approach Standard Deviation Tournament Selection Tournament Size Whale Optimization Algorithm</cell></row></table><note><p><p>2. EPD for The GOA</p>2.1. Evolutionary Population Dynamics (EPD)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>List of used datasets</figDesc><table><row><cell>No. Dataset</cell><cell cols="2">No. of Features No. of instances</cell></row><row><cell>1. 2. 3. 4. 5. 6. 7. 8. 9. 10. SpectEW Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography M-of-n PenglungEW SonarEW 11. CongressEW 12. IonosphereEW 13. KrvskpEW 14. Tic-tac-toe 15. Vote 16. WaveformEW 17. WineEW 18. Zoo 19. Clean1 20. Semeion 21. Colon 22. Leukemia</cell><cell>9 30 13 13 13 18 13 325 60 22 16 34 36 9 16 40 13 16 166 265 2000 7129</cell><cell>699 596 1000 1000 270 148 1000 73 208 267 435 351 3196 958 300 5000 178 101 476 1593 62 72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of the BGOA_S with four hybrid versions using Acc and StdDev metrics StdDev using only 6.47 attributes. From Table3, it is observed that the BGOA_EPD_RWS can provide superior Acc rates compared to other varieties in tackling the BreastEW, CongressEW, SonarEW, and Zoo datasets. The BGOA_EPD_RWS has attained the Acc of 100% in solving the Zoo test case. The BGOA_EPD_CM outperform others in terms of Acc in dealing with the 6 datasets: IonosphereEW, SpectEW, WaveformEW, Clean1, Semeion, and Leukemia problems. The BGOA_EPD has outperformed competitors in realizing the HeartEW, Lymphography, and WineEW. In tackling the CongressEW, both BGOA_EPD and BGOA_EPD_RWS have reached to a same Acc rate 98.3%, while based on selected attributes in Table4, the BGOA_EPD_RWS with 5.5 selected attributes has outperformed the BGOA_EPD.</figDesc><table><row><cell>Dataset</cell><cell cols="6">BGOA_S Acc StdDev Acc StdDev Acc BGOA_EPD BGOA_EPD_CM BGOA_EPD_RWS BGOA_EPD_Tour StdDev Acc StdDev Acc StdDev</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 0.815 0.012 0.895 0.013 0.969 0.000 0.966 0.000 0.960 0.005 0.962 0.002 0.946 0.036 0.997 0.006 0.760 0.000 0.734 0.005 0.826 0.010 0.842 0.006 M-of-n 0.979 0.030 0.997 0.007 PenglungEW 0.861 0.015 0.868 0.008 SonarEW 0.895 0.011 0.921 0.007 SpectEW 0.851 0.011 0.850 0.007 0.882 0.969 0.963 0.993 0.744 0.841 0.844 0.999 0.839 0.883 CongressEW 0.953 0.004 0.983 0.003 0.974 IonosphereEW 0.883 0.007 0.907 0.004 0.922 KrvskpEW 0.956 0.008 0.960 0.006 0.959 Tic-tac-toe 0.803 0.007 0.797 0.001 0.789 Vote 0.951 0.004 0.948 0.006 0.953 WaveformEW 0.729 0.009 0.739 0.006 0.743 WineEW 0.979 0.004 0.994 0.006 0.993 Zoo 0.990 0.010 0.976 0.008 0.960 Clean1 0.883 0.008 0.885 0.005 0.893 Semeion 0.975 0.002 0.979 0.001 0.986 Colon 0.745 0.010 0.812 0.012 0.712 Leukemia 0.928 0.014 0.889 0.000 0.931</cell><cell>0.000 0.003 0.009 0.013 0.012 0.012 0.004 0.021 0.006 0.006 0.004 0.007 0.006 0.000 0.004 0.004 0.005 0.004 0.005 0.001 0.008 0.014</cell><cell>0.977 0.964 0.999 0.762 0.815 0.878 0.999 0.750 0.922 0.852 0.983 0.911 0.963 0.785 0.960 0.740 0.988 1.000 0.885 0.974 0.810 0.855</cell><cell>0.000 0.003 0.008 0.000 0.008 0.009 0.004 0.012 0.008 0.007 0.004 0.005 0.004 0.000 0.003 0.004 0.003 0.000 0.006 0.001 0.010 0.012</cell><cell>0.980 0.947 0.999 0.780 0.833 0.868 1.000 0.927 0.912 0.826 0.964 0.899 0.968 0.808 0.966 0.737 0.989 0.993 0.863 0.976 0.870 0.931</cell><cell>0.001 0.005 0.005 0.000 0.004 0.011 0.000 0.013 0.009 0.010 0.005 0.007 0.003 0.000 0.003 0.003 0.000 0.009 0.004 0.002 0.006 0.014</cell></row></table><note><p>relatively outperform other competitors in terms of Acc and StdDev metrics in dealing with 10 and 11 datasets, respectively. The simple binary BGOA_S cannot reveal higher accuracies than any hybrid variant over all 22 datasets. For the M-of-n dataset, the BGOA_EPD_Tour has classified with 100% Acc and 0</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Average selected attributes using the developed algorithms</figDesc><table><row><cell>Dataset</cell><cell>BGOA_S Atts StdDev</cell><cell>BGOA_EPD Atts StdDev</cell><cell cols="3">BGOA_EPD_CM BGOA_EPD_RWS BGOA_EPD_Tour Atts StdDev Atts StdDev Atts StdDev</cell></row><row><cell>Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography M-of-n PenglungEW SonarEW SpectEW CongressEW IonosphereEW KrvskpEW Tic-tac-toe Vote WaveformEW WineEW Zoo clean1 Semeion Colon Leukemia</cell><cell cols="3">4.00 15.37 7.63 1.27 6.77 7.47 7.53 150.13 28.57 9.93 4.33 13.43 19.90 6.83 5.27 21.20 6.33 8.13 82.93 134.90 967.87 3495.23 48.699 4138.27 373.767 4366.87 288.129 3896.63 0.000 5.13 0.346 4.17 0.379 4.73 2.697 20.00 2.729 17.50 1.889 17.20 0.809 6.60 0.498 6.57 0.504 6.43 0.450 7.97 0.809 5.67 3.565 1.50 1.524 6.67 0.922 5.77 0.817 6.13 2.080 10.60 1.003 10.60 1.522 11.60 0.973 6.53 0.629 6.57 0.504 6.57 8.509 166.53 15.937 198.90 8.707 174.77 3.191 36.37 3.157 36.03 3.489 35.73 1.856 14.13 1.995 12.83 2.437 11.93 1.322 7.67 1.729 6.53 2.145 5.50 3.115 18.93 3.269 17.93 2.420 17.77 3.010 22.33 3.010 22.10 2.551 22.43 0.379 5.03 0.183 6.00 0.000 6.10 2.083 6.73 1.015 6.57 1.995 6.07 2.952 25.53 3.082 25.80 3.295 24.93 1.348 7.27 0.944 7.23 0.817 6.83 1.167 7.97 1.426 7.93 1.230 7.77 5.948 103.80 6.880 105.20 6.206 96.00 7.662 169.63 11.137 171.50 7.361 159.87 23.882 1194.33 89.430 1198.33 97.070 1050.83</cell><cell>0.980 2.747 0.568 0.509 1.548 1.476 0.568 15.460 2.778 2.463 1.592 3.785 2.417 0.305 1.617 2.876 1.147 0.774 9.127 9.885 70.247 292.866</cell><cell>5.00 17.33 6.53 1.53 8.40 10.63 6.47 178.33 36.77 11.10 5.77 16.40 21.67 5.00 5.43 26.23 8.80 9.17 92.60 157.03 1063.67 3768.80</cell><cell>0.000 2.440 0.571 0.507 1.037 1.217 0.507 15.486 4.240 3.044 2.012 3.701 2.496 0.000 1.223 3.451 1.472 1.967 7.802 11.485 64.618 224.842</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Average fitness values for proposed versions</figDesc><table><row><cell>Dataset</cell><cell cols="10">BGOA_S Fitness StdDev Fitness StdDev Fitness StdDev Fitness BGOA_EPD BGOA_EPD_CM BGOA_EPD_RWS BGOA_EPD_Tour StdDev Fitness StdDev</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 0.187 0.036 0.045 0.059 0.239 0.178 M-of-n 0.027 PenglungEW 0.142 SonarEW 0.109 SpectEW 0.152 Tic-tac-toe 0.203 CongressEW 0.049 IonosphereEW 0.120 KrvskpEW 0.049 Vote 0.052 WaveformEW 0.274 WineEW 0.025 Zoo 0.015 Clean1 0.121 Semeion 0.030 Colon 0.257 Leukemia 0.076</cell><cell>0.000 0.005 0.036 0.000 0.009 0.012 0.030 0.015 0.010 0.011 0.007 0.004 0.008 0.008 0.004 0.009 0.004 0.010 0.008 0.002 0.010 0.014</cell><cell>0.040 0.044 0.008 0.269 0.161 0.110 0.008 0.136 0.084 0.155 0.206 0.022 0.098 0.046 0.055 0.265 0.012 0.028 0.120 0.027 0.192 0.116</cell><cell>0.000 0.002 0.006 0.005 0.006 0.013 0.007 0.008 0.007 0.007 0.001 0.003 0.004 0.006 0.006 0.006 0.005 0.007 0.004 0.001 0.012 0.001</cell><cell>0.036 0.043 0.012 0.257 0.162 0.161 0.006 0.166 0.122 0.123 0.215 0.030 0.082 0.047 0.050 0.261 0.013 0.044 0.112 0.020 0.291 0.074</cell><cell>0.000 0.003 0.010 0.015 0.012 0.012 0.004 0.020 0.006 0.006 0.000 0.004 0.007 0.006 0.005 0.004 0.005 0.004 0.005 0.001 0.008 0.014</cell><cell>0.028 0.041 0.006 0.237 0.188 0.127 0.006 0.253 0.083 0.152 0.220 0.020 0.094 0.043 0.044 0.263 0.017 0.005 0.120 0.031 0.194 0.149</cell><cell>0.001 0.003 0.008 0.000 0.008 0.009 0.004 0.012 0.008 0.006 0.000 0.005 0.005 0.004 0.003 0.005 0.003 0.000 0.006 0.001 0.010 0.012</cell><cell>0.026 0.058 0.006 0.219 0.171 0.137 0.005 0.078 0.094 0.177 0.196 0.039 0.105 0.038 0.037 0.267 0.018 0.012 0.141 0.030 0.134 0.073</cell><cell>0.001 0.004 0.006 0.000 0.004 0.011 0.000 0.012 0.008 0.010 0.000 0.005 0.007 0.003 0.003 0.003 0.001 0.008 0.004 0.001 0.006 0.014</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Average CPU time (seconds) of proposed techniques</figDesc><table><row><cell>Dataset</cell><cell cols="6">BGOA_S Time StdDev Time StdDev Time BGOA_EPD BGOA_EPD_CM BGOA_EPD_RWS BGOA_EPD_Tour StdDev Time StdDev Time StdDev</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography M-of-n penglungEW SonarEW SpectEW Tic-tac-toe CongressEW IonosphereEW KrvskpEW Vote WaveformEW 123.546 4.381 152.292 4.186 157.271 3.537 0.248 4.053 0.232 4.370 3.780 0.199 5.256 0.221 5.761 4.874 0.238 6.166 0.301 6.881 5.223 0.344 6.204 0.285 6.882 2.803 0.164 3.276 0.183 3.667 2.540 0.148 3.145 0.144 3.547 4.792 0.234 5.641 0.220 6.406 2.836 0.164 18.597 0.784 21.038 2.713 0.160 5.469 0.263 6.113 2.705 0.154 3.465 0.147 3.916 4.226 0.210 4.961 0.210 5.227 3.248 0.160 3.835 0.186 4.273 2.899 0.152 4.441 0.205 4.988 49.520 1.668 58.357 1.773 62.814 2.799 0.158 3.364 0.164 3.491 WineEW 2.492 0.151 3.054 0.152 3.176 Zoo 2.485 0.145 3.076 0.137 3.182 clean1 7.204 0.225 16.423 0.542 16.988 Semeion 88.934 1.514 129.229 2.182 130.251 Colon 4.964 0.338 100.832 3.628 106.310 Leukemia 15.322 0.884 383.067 19.075 379.074</cell><cell>0.222 0.237 0.313 0.351 0.165 0.169 0.288 0.920 0.262 0.189 0.255 0.207 0.207 3.055 0.154 5.641 0.152 0.156 0.566 2.154 4.461 15.501</cell><cell>4.131 5.427 6.155 5.934 3.484 3.413 5.812 19.494 5.774 3.746 5.214 4.093 4.717 56.831 3.618 145.890 3.281 3.371 16.904 120.308 107.901 381.100</cell><cell>0.214 0.249 0.262 0.265 0.190 0.161 0.279 0.756 0.240 0.183 0.250 0.211 0.201 1.871 0.187 4.420 0.176 0.186 0.600 2.480 4.333 15.244</cell><cell>4.146 5.404 6.014 5.942 3.505 3.427 6.173 19.560 5.801 3.775 5.097 4.109 4.735 57.043 3.640 152.167 3.766 3.614 17.220 123.254 112.236 394.688</cell><cell>0.191 0.241 0.277 0.257 0.178 0.162 0.271 0.822 0.245 0.164 0.222 0.205 0.199 1.743 0.179 4.812 0.301 0.240 0.608 2.147 4.364 15.418</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>P-values of the Wilcoxon test the classification accuracy results of the proposed approaches (p ≥ 0.05 are underlined, and N/A means not applicable).</figDesc><table><row><cell>BGOA_S BGOA_EPD BGOA_EPD-CM BGOA_EPD_RWS BGOA_EPD_Tour 2.71E-14 2.71E-14 2.71E-14 1.22E-12 N/A 1.42E-04 1.32E-02 2.25E-01 N/A 1.88E-11 2.04E-10 9.53E-06 1.21E-04 1.00E+00 N/A 1.69E-14 1.01E-12 5.37E-13 1.69E-14 N/A 7.62E-09 N/A 2.15E-01 1.29E-11 7.19E-08 Lymphography 1.98E-11 Breast Cancer BreastEW Exactly Exactly2 HeartEW N/A 1.79E-11 6.41E-06 1.89E-11 M-of-n 8.60E-07 4.19E-02 8.15E-02 3.34E-01 N/A penglungEW 3.75E-12 8.38E-13 5.90E-12 2.63E-12 N/A SonarEW 4.77E-11 7.19E-01 7.57E-12 N/A 2.11E-05 SpectEW 2.46E-11 1.56E-11 N/A 1.29E-11 1.79E-11 CongressEW 1.35E-11 6.58E-01 3.87E-09 N/A 1.54E-11 IonosphereEW 1.82E-11 2.68E-10 N/A 2.95E-08 5.21E-11 KrvskpEW 3.14E-09 4.23E-06 1.48E-08 3.29E-06 N/A Tic-tac-toe 1.19E-13 2.71E-14 2.71E-14 1.69E-14 N/A Vote 9.06E-12 7.00E-12 1.64E-11 2.11E-08 N/A WaveformEW 3.04E-08 3.16E-03 N/A 3.13E-02 3.73E-07 WineEW 1.07E-10 N/A 4.35E-01 2.50E-05 5.59E-05 Zoo 3.80E-06 1.55E-13 2.71E-14 N/A 6.18E-04 Clean1 1.09E-06 4.81E-07 N/A 2.15E-06 1.94E-11 semeion 1.77E-11 1.80E-11 N/A 1.83E-11 1.96E-11 Colon 9.45E-14 2.39E-13 6.50E-14 1.13E-13 N/A Leukemia 3.09E-01 4.63E-13 N/A 3.31E-12 N/A</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Overall ranking results</figDesc><table><row><cell>Algorithm</cell><cell>BGOA_S</cell><cell cols="6">BGOA_EPD BGOA_EPD_CM BGOA_EPD_RWS BGOA_EPD_Tour</cell></row><row><cell>Metric</cell><cell cols="2">Acc Att Fit Acc Att Fit Acc Att</cell><cell>Fit</cell><cell>Acc Att</cell><cell>Fit</cell><cell>Acc Att</cell><cell>Fit</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>The parameter settings</figDesc><table><row><cell cols="2">Algorithm Parameter</cell><cell>Value</cell></row><row><cell>GSA BA GWO</cell><cell cols="2">G 0 α Q min Frequency minimum 0 100 20 Q max Frequency maximum 2 A Loudness 0.5 r Pulse rate 0.5 a [2 0]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Classification accuracy results of the BGOA_EPD_Tour compared to other metaheuristics</figDesc><table><row><cell>Dataset</cell><cell cols="2">BGOA_EPD_Tour Acc StdDev</cell><cell>bGWO Acc StdDev Acc StdDev Acc StdDev BGSA BBA</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 0.868 0.980 0.947 0.999 0.780 0.833 M-of-n 1.000 penglungEW 0.927 SonarEW 0.912 SpectEW 0.826 CongressEW 0.964 IonosphereEW 0.899 KrvskpEW 0.968 Tic-tac-toe 0.808 Vote 0.966 WaveformEW 0.737 WineEW 0.989 Zoo 0.993 clean1 0.863 semeion 0.976 Colon 0.870 Leukemia 0.931</cell><cell>0.001 0.005 0.005 0.000 0.004 0.011 0.000 0.013 0.009 0.010 0.005 0.007 0.003 0.000 0.003 0.003 0.000 0.009 0.004 0.002 0.006 0.014</cell><cell>0.968 0.954 0.007 0.942 0.006 0.931 0.014 0.002 0.957 0.004 0.937 0.031 0.809 0.076 0.697 0.060 0.610 0.065 0.743 0.017 0.706 0.023 0.628 0.057 0.792 0.017 0.777 0.022 0.754 0.033 0.813 0.028 0.781 0.022 0.701 0.069 0.894 0.041 0.835 0.063 0.722 0.080 0.850 0.014 0.919 0.000 0.795 0.029 0.836 0.016 0.888 0.015 0.844 0.036 0.810 0.014 0.783 0.024 0.800 0.027 0.948 0.011 0.951 0.008 0.872 0.075 0.885 0.009 0.881 0.010 0.877 0.019 0.934 0.015 0.908 0.048 0.816 0.081 0.754 0.032 0.753 0.024 0.665 0.063 0.944 0.010 0.931 0.011 0.851 0.096 0.723 0.007 0.695 0.014 0.669 0.033 0.960 0.012 0.951 0.015 0.919 0.052 0.975 0.009 0.939 0.008 0.874 0.095 0.908 0.006 0.898 0.011 0.826 0.021 0.972 0.003 0.971 0.002 0.962 0.006 0.661 0.022 0.766 0.015 0.682 0.038 0.884 0.016 0.844 0.014 0.877 0.029</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 :</head><label>11</label><figDesc>Average number of selected attributes results of the BGOA_EPD_Tour and BGOA_EPD_RWS compared to other metaheuristics</figDesc><table><row><cell>Dataset</cell><cell>BGOA_EPD_Tour Att StdDev</cell><cell>bGWO Att StdDev</cell><cell>BGSA Att StdDev</cell><cell>Att</cell><cell>BBA StdDev</cell></row><row><cell cols="6">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 10.633 5.000 17.333 6.533 1.533 8.400 M-of-n 6.467 penglungEW 178.333 SonarEW 36.767 SpectEW 11.100 CongressEW 5.767 IonosphereEW 16.400 KrvskpEW 21.667 Tic-tac-toe 5.000 Vote 5.433 WaveformEW 26.233 WineEW 8.800 Zoo 9.167 clean1 92.600 semeion 157.033 Colon 1063.667 Leukemia 3768.800 224.842 3663.767 294.872 3555.133 39.713 2860.000 247.642 0.000 7.100 1.447 6.067 1.143 3.667 1.373 2.440 19.000 4.307 16.567 2.979 12.400 2.762 0.571 10.233 1.654 8.733 1.048 5.733 1.893 0.507 7.333 4.155 5.100 2.107 6.067 2.333 1.037 8.167 2.001 6.833 1.315 5.900 1.647 1.217 11.100 1.971 9.167 1.895 7.800 2.203 0.507 9.633 0.964 8.467 1.432 6.167 2.086 15.486 166.333 28.232 157.167 7.729 126.167 15.601 4.240 36.233 8.613 30.033 3.700 24.700 5.377 3.044 12.633 2.442 9.533 2.300 7.967 2.282 2.012 7.300 2.136 6.767 2.402 6.233 2.063 3.701 19.233 5.015 15.400 2.513 13.400 2.594 2.496 27.367 3.388 19.967 2.125 15.000 2.853 0.000 6.700 1.343 5.867 1.137 4.700 1.489 1.223 7.400 2.222 8.167 1.821 6.133 2.177 3.451 31.967 4.612 19.900 2.917 16.667 3.304 1.472 8.600 1.754 7.367 1.098 6.067 1.741 1.967 10.367 2.484 8.167 1.177 6.567 2.501 7.802 121.267 20.691 83.700 5.421 64.767 10.016 11.485 200.100 31.022 133.533 7.422 107.033 10.947 64.618 1042.100 126.721 995.833 20.021 827.500 55.371</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 12 :</head><label>12</label><figDesc>Average fitness results of the BGOA_EPD_Tour and BGOA_EPD_RWS compared to other metaheuristics</figDesc><table><row><cell>Dataset</cell><cell cols="2">BGOA_EPD_Tour Fitness StdDev</cell><cell cols="6">bGWO Fitness StdDev Fitness StdDev Fitness StdDev BGSA BBA</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 0.137 0.026 0.058 0.006 0.219 0.171 M-of-n 0.005 penglungEW 0.078 SonarEW 0.094 SpectEW 0.177 CongressEW 0.039 IonosphereEW 0.105 KrvskpEW 0.038 Tic-tac-toe 0.196 Vote 0.037 WaveformEW 0.267 WineEW 0.018 Zoo 0.012 clean1 0.141 semeion 0.030 Colon 0.134 Leukemia 0.073</cell><cell>0.001 0.004 0.006 0.000 0.004 0.011 0.000 0.012 0.008 0.010 0.005 0.007 0.003 0.000 0.003 0.003 0.001 0.008 0.004 0.001 0.006 0.014</cell><cell>0.039 0.051 0.197 0.260 0.213 0.191 0.112 0.154 0.169 0.194 0.056 0.120 0.073 0.251 0.060 0.283 0.047 0.032 0.099 0.036 0.341 0.120</cell><cell>0.003 0.007 0.077 0.019 0.017 0.028 0.041 0.013 0.016 0.014 0.011 0.009 0.015 0.032 0.010 0.007 0.012 0.009 0.006 0.003 0.022 0.016</cell><cell>0.049 0.063 0.307 0.295 0.226 0.222 0.170 0.085 0.116 0.220 0.053 0.122 0.097 0.251 0.073 0.307 0.054 0.065 0.106 0.034 0.237 0.160</cell><cell>0.003 0.006 0.059 0.024 0.021 0.022 0.063 0.000 0.015 0.024 0.008 0.010 0.047 0.024 0.011 0.014 0.015 0.008 0.010 0.002 0.014 0.013</cell><cell>0.044 0.056 0.323 0.326 0.208 0.226 0.171 0.168 0.110 0.172 0.064 0.108 0.117 0.257 0.071 0.304 0.036 0.042 0.156 0.033 0.279 0.085</cell><cell>0.005 0.006 0.074 0.017 0.015 0.024 0.056 0.017 0.021 0.012 0.015 0.012 0.047 0.024 0.013 0.014 0.013 0.015 0.013 0.003 0.035 0.023</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 13 :</head><label>13</label><figDesc>Average CPU time (seconds) results of the BGOA_EPD_Tour and BGOA_EPD_RWS compared to other metaheuristics</figDesc><table><row><cell>Dataset</cell><cell cols="2">BGOA_EPD_Tour Time StdDev</cell><cell>bGWO Time StdDev Time StdDev BGSA</cell><cell>BBA Time StdDev</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 3.427 4.146 5.404 6.014 5.942 3.505 M-of-n 6.173 penglungEW 19.560 SonarEW 5.801 SpectEW 3.775 CongressEW 4.109 IonosphereEW 4.735 KrvskpEW 57.043 Tic-tac-toe 5.097 Vote 3.640 WaveformEW 152.167 WineEW 3.766 Zoo 3.614 clean1 17.220 semeion 123.254 Colon 112.236 Leukemia 394.688</cell><cell>0.191 0.241 0.277 0.257 0.178 0.162 0.271 0.822 0.245 0.164 0.205 4.735 1.743 0.222 0.179 4.812 0.301 0.240 0.608 2.147 4.364 15.418</cell><cell cols="2">3.879 4.602 6.154 6.050 2.739 2.602 6.157 7.717 3.677 2.869 3.309 3.564 78.113 6.208 2.851 213.955 13.607 125.804 6.770 119.990 8.169 0.236 3.461 0.194 3.456 0.184 0.234 3.748 0.173 3.862 0.196 0.275 4.876 0.311 4.956 0.272 0.380 5.033 0.374 5.224 0.394 0.174 2.812 0.182 2.767 0.201 0.161 2.589 0.150 2.634 0.145 0.241 5.138 0.293 4.892 0.361 0.432 3.060 0.171 4.166 0.238 0.193 2.703 0.146 2.850 0.191 0.176 2.723 0.162 2.809 0.161 0.172 3.217 0.188 3.244 0.158 0.184 2.921 0.145 3.018 0.148 4.606 49.534 2.527 47.923 2.576 0.622 4.344 0.278 4.237 0.278 0.154 2.824 0.152 2.834 0.178 2.628 0.173 2.585 0.171 2.624 0.141 2.623 0.136 2.547 0.158 2.777 0.192 13.683 0.647 7.397 0.288 7.589 0.467 169.538 9.191 90.601 2.212 82.776 5.579 36.694 1.998 5.154 0.242 12.176 0.774 130.878 6.366 16.441 0.683 39.379 2.418</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 16 :</head><label>16</label><figDesc>Classification accuracy results of all filter-based methods versus the BGOA_EPD_Tour algorithm</figDesc><table><row><cell>Dataset</cell><cell cols="2">CFS FCBF F-Score</cell><cell>IG</cell><cell>Spectrum BGOA_EPD_Tour</cell></row><row><cell cols="2">Breastcancer BreastEW Exactly Exactly2 HeartEW Lymphography 0.500 0.567 0.957 0.986 0.825 0.798 0.670 0.440 0.705 0.545 0.648 0.648 M-of-n 0.785 0.815 PenglungEW 0.600 0.667 SonarEW 0.310 0.214 SpectEW 0.736 0.774 CongressEW 0.793 0.793 IonosphereEW 0.857 0.857 KrvskpEW 0.768 0.934 Tic-tac-toe 0.000 0.000 Vote 0.950 0.950 WaveformEW 0.620 0.710 WineEW 0.778 0.889 Zoo 0.800 0.900 clean1 0.716 0.642 semeion 0.875 0.875 Colon 0.750 0.667 Leukemia 0.929 0.857</cell><cell cols="2">0.979 0.930 0.600 0.680 0.759 0.667 0.815 0.800 0.048 0.793 0.908 0.729 0.959 0.010 0.933 0.662 0.861 0.650 0.632 0.875 0.667 0.980 0.980 0.957 0.930 0.615 0.620 0.759 0.667 0.815 0.667 0.191 0.793 0.828 0.800 0.934 0.010 0.967 0.662 0.889 0.850 0.547 0.868 0.667</cell><cell>0.957 0.772 0.575 0.660 0.796 0.767 0.580 0.400 0.048 0.736 0.828 0.829 0.377 0.167 0.850 0.292 0.889 0.600 0.611 0.875 0.500 0.357</cell><cell>0.980 0.947 0.999 0.780 0.833 0.868 1.000 0.927 0.912 0.826 0.964 0.899 0.968 0.808 0.966 0.737 0.989 0.993 0.863 0.976 0.870 0.931</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Preprint submitted to Knowledge-Based SystemsDecember 30, 2017   </p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T </p><p>Comparison with other meta-heuristics in the literature In this part, the classification rates of the proposed EPD-based approach are compared to some reported results from the past literature. Table <ref type="table">15</ref> compares the average classification results of the BGOA_EPD_Tour with other algorithms obtained from the previous specialized works. The BGOA_EPD_Tour is compared to the reported classification results of GA and PSO from <ref type="bibr" target="#b88">[89]</ref> and results of the bGWO1, bGWO2, GA, and PSO from <ref type="bibr" target="#b89">[90]</ref>. Note that the first versions of GA and PSO were executed with exact settings in the implementation of the authors in <ref type="bibr" target="#b88">[89]</ref>. While the results of other four approaches (bGWO1, bGWO2, GA, and PSO) in the table were obtained by the authors with the same datasets in <ref type="bibr" target="#b89">[90]</ref>. From the results in Table <ref type="table">15</ref>, it is evident that the attained classification rates by the developed EPD-based approach in this work are higher than other optimizers on 21 datasets and have a substantial superiority compared to those of GWO, GA, and PSO algorithms. The rates of the BGOA_EPD_Tour are better than the results of GA and PSO in <ref type="bibr" target="#b88">[89]</ref> for all 22 datasets. In comparison with the revealed results in <ref type="bibr" target="#b89">[90]</ref>, the BGOA-based algorithm provides better classification rates than the PSO, GA, and bGWO1 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dynamic variable precision rough set approach for probabilistic set-valued information systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Horng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="131" to="147" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast semi-supervised clustering with enhanced spectral embedding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="4358" to="4369" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m">Data mining: concepts and techniques</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An overview on the roles of fuzzy set techniques in big data processing: Trends, challenges and opportunities</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="15" to="30" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Feature Selection for Knowledge Discovery and Data Mining</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Binary pso with mutation operator for feature selection using decision tree applied to spam detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="22" to="31" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Feature selection for machine learning: Comparing a correlation-based filter approach to the wrapper., in: FLAIRS conference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">1999</biblScope>
			<biblScope unit="page" from="235" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Non-negative spectral learning and sparse regression-based dual-graph regularized feature selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stolkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A semi-supervised feature ranking method with ensemble learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bellal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elghazel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aussem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1426" to="1433" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Feature selection for high-dimensional data: A fast correlation-based filter solution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on machine learning (ICML-03)</title>
		<meeting>the 20th international conference on machine learning (ICML-03)</meeting>
		<imprint>
			<biblScope unit="page" from="856" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spectral feature selection for supervised and unsupervised learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="1151" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Subspace learning-based graph regularized feature selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stolkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="152" to="165" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-representation based dual-graph regularized feature selection clustering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="1242" to="1253" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Forward semi-supervised feature selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia conference on knowledge discovery and data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="970" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Feature selection for classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligent data analysis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="131" to="156" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recent advances and emerging challenges of feature selection in the context of big data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bolón-Canedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sánchez-Maroño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alonso-Betanzos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="33" to="45" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Feature selection and discretization of numeric attributes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Setiono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Induction of decision trees</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="81" to="106" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">C4. 5: programs for machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quinlan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Theoretical and empirical analysis of relieff and rrelieff</title>
		<author>
			<persName><forename type="first">M</forename><surname>Robnik-Øě Ikonja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kononenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="23" to="69" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accelerating wrapperbased feature selection with k-nearest-neighbor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alterovitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="81" to="91" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Feature selection and classification-a probabilistic wrapper approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Setiono</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural-network feature selector, Neural Networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Setiono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="654" to="662" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On automatic feature selection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Siedlecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sklansky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="197" to="220" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Selection of relevant features in machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random subspace method for multivariate feature selection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Reinders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wessels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1067" to="1076" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Talbi</surname></persName>
		</author>
		<title level="m">Metaheuristics From design to implementation</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evolutionary population dynamics and grey wolf optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1257" to="1263" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The whale optimization algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The ant lion optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="80" to="98" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Firefly Algorithms for Multimodal Optimization</title>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="169" to="178" />
			<pubPlace>Berlin Heidelberg, Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory, in: Micro Machine and Human Science, 1995. MHS &apos;95</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Symposium on</title>
		<meeting>the Sixth International Symposium on</meeting>
		<imprint>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ant colony optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stutzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computational intelligence magazine</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="28" to="39" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An introduction to variable and feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hybrid approach of differential evolution and artificial bee colony for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zorarpacøďâś</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Øčâăşzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="91" to="103" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Path planning for solar-powered uav in urban environment</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Synchronization clustering based on central force optimization and its extension for large-scale datasets</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="31" to="44" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Gooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Imura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wind-thermal power system dispatch using mlsad model and gsoiclw algorithm</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="94" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Ant lion optimization algorithm for optimal location and sizing of renewable distributed generations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Elazim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdelaziz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Renewable Energy</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1311" to="1324" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Grey wolf optimizer: a review of recent variants and applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al-Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Neural Computing and Applications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sevaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00853</idno>
		<title level="m">A history of metaheuristics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Grasshopper optimisation algorithm: Theory and application</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="30" to="47" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Electrical characterisation of proton exchange membrane fuel cells stack using grasshopper optimiser</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>El-Fergany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Renewable Power Generation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Distributed trajectory optimization for multiple solar-powered uavs target tracking in urban environment by adaptive grasshopper optimization algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerospace Science and Technology</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="497" to="510" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mogoa algorithm for constrained and unconstrained multi-objective optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tharwat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Houssein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Grasshopper optimization algorithm for multi-objective optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aljarah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sca: a sine cosine algorithm for solving optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="120" to="133" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Handbook of evolutionary computation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bøčâďck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Release</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Performance comparison of generational and steady-state asynchronous multi-objective evolutionary algorithms A</title>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Zăvoianu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lughofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Koppelstätter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weidenholzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Amrhein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Klement ; C C E P T E D M A N U S C R I P T For</surname></persName>
		</author>
		<author>
			<persName><surname>Computationally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="47" to="60" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>intensive problems</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<title level="m">Adaptation in natural and artificial systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence through simulated evolution</title>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Genetic algorithms in feature and instance selection</title>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Eberle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="240" to="247" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Integration of graph clustering with ant colony optimization for feature selection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rostami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="144" to="161" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A discrete bacterial algorithm for feature selection in classification of microarray gene expression cancer data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="8" to="19" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Finding rough set reducts with ant colony optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 UK workshop on computational intelligence</title>
		<meeting>the 2003 UK workshop on computational intelligence</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Semantics-preserving dimensionality reduction: Rough and fuzzy-rough-based approaches</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Knowl. and Data Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1457" to="1471" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">A heuristic feature selection approach for text categorization by using chaos optimization and genetic algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Mathematical problems in Engineering 2013</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Investigating memetic algorithm in solving rough set attribute reduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications in Technology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fuzzy population-based metaheuristic approaches for attribute reduction in rough set theory, World Academy of Science, Engineering and Technology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Majdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Jaddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer, Electrical, Automation, Control and Information Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2289" to="2297" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Scatter search for rough set attribute reduction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-R</forename><surname>Hedar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bio-Inspired Computing: Theories and Applications, 2007. BIC-TA 2007. Second International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="236" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The ant lion optimizer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="80" to="98" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Binary antlion approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Feature selection based on antlion optimization algorithm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Feature selection via chaotic antlion optimization</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grosan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">150652</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Grey wolf optimizer algorithmbased tuning of fuzzy control systems with reduced parametric sensitivity</title>
		<author>
			<persName><forename type="first">R.-E</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R.-C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Petriu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="527" to="534" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Binary grey wolf optimization approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="371" to="381" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Feature subset selection approach by gray-wolf optimization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grosan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassenian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Afro-European Conference for Industrial Advancement</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Hybrid whale optimization algorithm with simulated annealing for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mafarja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Evolutionary population dynamics and multi-objective optimisation problems, Multi-Objective Optimization in Computational Intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mostaghim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Practice</title>
		<imprint>
			<biblScope unit="page" from="185" to="206" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Extremal optimization: Methods derived from co-evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boettcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Percus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 1st Annual Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="825" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Extremal optimisation for assignment type problems, Biologically-Inspired Optimisation Methods: Parallel Algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Randall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hendtlass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems and Applications</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page" from="139" to="164" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The computing of the optimal power consumption for semi-track air-cushion vehicle using hybrid generalized extremal optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematical Modelling</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2831" to="2844" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Distributed modified extremal optimization using island model for reducing crossovers in reconciliation graph</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kitakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nakada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Letters</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Self-organized criticality: An explanation of the 1/f noise</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wiesenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">381</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">An evolutionary programming algorithm for automatic engineering design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Abramson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peachey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Processing and Applied Mathematics</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="586" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">An efficient modified grey wolf optimizer with lévy flight for optimization tasks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pahlavani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="115" to="134" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">An efficient chaotic water cycle algorithm for optimization tasks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Abbaspour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Jordehi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="57" to="85" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Rough-fuzzy hybridization: A new trend in decision making</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Skowron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer-Verlag New York, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">S-shaped versus v-shaped transfer functions for binary particle swarm optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm and Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A discrete binary version of the particle swarm algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Systems, Man, and Cybernetics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997">1997. 1997</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4104" to="4108" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">An introduction to kernel and nearest-neighbor nonparametric regression</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Evolutionary algorithms in theory and practice: evolution strategies, evolutionary programming, genetic algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Genetic algorithms, tournament selection, and the effects of noise</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="193" to="212" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Binary ant lion approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="54" to="65" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">The elements of statistical learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Springer series in statistics New York</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Bgsa: binary gravitational search algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rashedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nezamabadi-Pour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saryazdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="727" to="745" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Binary bat algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="663" to="681" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Nezamabadi-pour, An advanced aco algorithm for feature subset selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kashef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="271" to="279" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Binary grey wolf optimization approaches for feature selection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Emary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Zawbaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="371" to="381" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">A review of feature selection techniques in bioinformatics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Saeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Inza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Larrañaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2507" to="2517" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<title level="m">Pattern classification</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of information theory</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
