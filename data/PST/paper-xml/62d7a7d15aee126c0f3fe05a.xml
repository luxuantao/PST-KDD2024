<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">täkō: A Polymorphic Cache Hierarchy for General-Purpose Optimization of Data Movement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Brian</forename><forename type="middle">C</forename><surname>Schwedock</surname></persName>
							<email>bschwedo@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Piratach</forename><surname>Yoovidhya</surname></persName>
							<email>piratacy@andrew.cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jennifer</forename><surname>Seibert</surname></persName>
							<email>jseiber1@binghamton.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Binghamton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
							<email>beckmann@cs.cmu.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">täkō: A Polymorphic Cache Hierarchy for General-Purpose Optimization of Data Movement</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3470496.3527379</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cache hierarchy</term>
					<term>data movement</term>
					<term>data-centric computing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Current systems hide data movement from software behind the load-store interface. Software's inability to observe and respond to data movement is the root cause of many inefficiencies, including the growing fraction of execution time and energy devoted to data movement itself. Recent specialized memory-hierarchy designs prove that large data-movement savings are possible. However, these designs require custom hardware, raising a large barrier to their practical adoption.</p><p>This paper argues that the hardware-software interface is the problem, and custom hardware is often unnecessary with an expanded interface. The täkō architecture lets software observe data movement and interpose when desired. Specifically, caches in täkō can trigger software callbacks in response to misses, evictions, and writebacks. Callbacks run on reconfigurable dataflow engines placed near caches. Five case studies show that this interface covers a wide range of data-movement features and optimizations. Microarchitecturally, täkō is similar to recent near-data computing designs, adding ≈5% area to a baseline multicore. täkō improves performance by 1.4×-4.2×, similar to prior custom hardware designs, and comes within 1.8% of an idealized implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Computer systems organization → Processors and memory architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cache</head><p>optimize data movement. But mainstream instruction set architectures were designed at a time when data movement was inexpensive and do not emphasize it. In current systems, software reads and writes data, and hardware decides when and where to move it.</p><p>Lacking visibility and control over data movement, software cannot implement many attractive features or optimizations, and instead resorts to overly conservative and wasteful solutions. Recognizing this, there has been a wave of proposals for specialized memory hierarchies <ref type="bibr">[2, 6-9, 23, 34, 36, 40, 50, 54, 58, 67, 75, 85, 90, 92, 95, 106-108, 118, 127, 131, 135, 136, 146, 149-154]</ref>. These designs are highly effective, often reporting speedups of 2× or more, so there is clearly potential to massively reduce data movement.</p><p>However, the elephant in the room is that adding custom logic to a general-purpose CPU memory hierarchy is very expensive. Taken literally, prior work suggests that memory hierarchies should contain an ever-growing number of custom accelerators. But this is unrealistic because each change to the hardware-software interface requires large, up-front investment in both hardware and software to be effective. Most accelerators benefit too few applications to justify such investment, creating innovation deadlock where large potential speedups cannot be realized in practice. Thus, optimizations are mostly limited to those that preserve the load-store interface, such as cache replacement policies or prefetchers.</p><p>We argue that the solution to this deadlock is to find a single, general-purpose architecture that supports a wide variety of datamovement features and optimizations. Only with wide applicability can the necessary hardware and software investment be justified. Additionally, we observe that the key to many prior optimizations is the ability to perform simple computations in response to data movement. Hence, the thesis of this paper is that: Architectures should expose more data movement to software, so that software can observe and optimize data movement itself. In other words, the hardware-software interface is the problem, and often specialized hardware is not needed with a richer interface. The missing ingredient is feedback from hardware to software when data moves. We call this idea a polymorphic cache hierarchy, and we propose the täkō<ref type="foot" target="#foot_0">1</ref> architecture to realize it.</p><p>Software control of data movement offers enormous advantages over a hardware-only approach. Solutions can be better tailored to individual applications, and development cycles go from years to days. Although the upfront costs of a new hardware-software interface are formidable, these costs are paid only once, after which the marginal cost is reduced by orders of magnitude.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates täkō in action. Software (e.g., an application, domain-specific framework, or library) registers a phantom address range with täkō, whose data only lives in-cache and is not backed by off-chip memory <ref type="bibr" target="#b22">[23]</ref>. Instead of fetching data from memory, misses to this address range are served by software callbacks. Evictions and writebacks are handled similarly. These callbacks thus define the semantics of loads and stores in this address range, letting software re-purpose the caches as desired.</p><p>Like recent near-data computing architectures <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b104">105,</ref><ref type="bibr" target="#b141">142,</ref><ref type="bibr" target="#b149">150]</ref>, täkō adds programmable engines near caches to execute callbacks efficiently. In täkō, engines contain scheduling logic and a spatial dataflow fabric to run callbacks <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b131">132,</ref><ref type="bibr" target="#b137">138,</ref><ref type="bibr" target="#b142">143]</ref>. With this microarchitectural support, täkō gets close to the performance of fully specialized hardware -software programmability adds little overhead because data movement costs dominate and callbacks are short. The critical difference from prior work is that whereas cores invoke tasks in prior near-data architectures, caches invoke callbacks in täkō. This difference is the crux of the architecture: täkō closes the loop between hardware and software, letting software finally observe and optimize data movement.</p><p>This paper explores the programming interface and system architecture of a polymorphic cache hierarchy. täkō's goal is to enable optimizations that otherwise require custom hardware, and as such it currently provides a low-level interface for expert programmers. This paper focuses on (i) an initial set of callbacks that covers many, but not all, data-movement features and optimizations; and (ii) an architecture that implements these callbacks correctly and efficiently.</p><p>Contributions. This paper contributes the following:</p><p>• Problem. We identify the need for an improved hardwaresoftware interface to unlock the performance and efficiency gains demonstrated by recent specialized cache hierarchies. • Programming Interface. We propose a simple, flexible, and effective programming interface to give software visibility and control over data movement. • Architecture. We discuss the architectural constraints and features needed to implement a polymorphic cache hierarchy correctly and with good performance, with similar hardware overhead to prior near-data computing architectures.</p><p>Summary of results. We present five case studies for täkō, demonstrating that a general-purpose, programmable data-movement architecture can enable new functionality while approaching the performance of custom hardware.</p><p>• In-cache data transformation: täkō enables software-defined transformations (e.g., decompression) when data moves. With good locality, täkō eliminates redundant work to get 2.2× speedup and 61% energy savings. • Commutative scatter-updates: täkō implements PHI <ref type="bibr" target="#b94">[95]</ref>, transforming the caches to use push-based semantics to accelerate commutative scatter-updates in graphs. täkō gets 4.2× speedup, similar to <ref type="bibr" target="#b94">[95]</ref>. • Decoupled graph traversals: täkō implements HATS <ref type="bibr" target="#b91">[92]</ref> as a representative decoupled streaming application. täkō accelerates graph traversals and gets a 43% speedup and 17% energy savings. • Transactions on non-volatile memory: täkō's improved visibility over data movement eliminates wasteful work in NVM transactions. If no data is evicted before commit <ref type="bibr" target="#b90">[91]</ref>, täkō eliminates journaling overhead and achieves up to 2.1× speedup and 47% energy savings. • Detecting cache side-channel attacks: täkō exposes data movement to software, letting applications detect and prevent cache side-channel attacks <ref type="bibr" target="#b80">[81]</ref>. Unlike prior work that requires custom hardware for each feature and optimization, täkō implements these applications on a single, general-purpose hardware design. täkō adds just ≈5% area overhead, similar to prior near-data systems. Further, we show that täkō's hardware achieves performance within 1.8% of an idealized design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TÄK Ō OVERVIEW</head><p>täkō consists of software and hardware components. In software, täkō's programming interface gives software visibility and control over data movement via cache-triggered callbacks. In hardware, täkō adds architectural support for scheduling and executing callbacks efficiently near data.</p><p>Design rationale. Caches exist to shield systems from expensive operations. Traditionally, these are reads and writes to larger memories lower in the cache hierarchy, but in principle they could be anything. täkō opens up the cache hierarchy by letting software define what happens on a cache miss and, similarly, what to do with evictions.</p><p>Opening up the cache hierarchy yields two distinct benefits: (a) Software can leverage existing cache hardware to memoize expensive computations or buffer updates; and (b) Software can observe data movement as it happens and interpose as necessary. Both of these benefits are essential to implementing many data movement features and optimizations. For example, PHI <ref type="bibr" target="#b94">[95]</ref> (a) buffers graph updates in-cache, and (b) decides on eviction whether to apply updates in-place or log them (Sec. 8.1).</p><p>Interface. Table <ref type="table" target="#tab_0">1</ref> summarizes täkō's interface. Callbacks are registered only on selected addresses, and täkō does not affect loads and stores to other addresses. onMiss is invoked on cache misses, letting software fill in the requested cache line. Values are then cached normally; i.e., cores can read and write them, with hits handled like any other data. onEviction and onWriteback handle evictions for clean and dirty data, respectfully.</p><p>Architecture. Fig. <ref type="figure">2</ref> shows a high-level view of a täkō system. On top of a baseline, cache-coherent multicore, each tile is augmented with an engine that contains hardware scheduling logic and a programmable dataflow fabric to execute callbacks. täkō tracks which lines have callbacks registered and adds no latency or energy to traditional loads and stores.</p><p>The engine microarchitecture is guided by constraints and characteristics of täkō callbacks. To compete with specialized hardware, callbacks must exploit memory-level parallelism but should not add much area. Callbacks tend to be short, re-execute repeatedly, and perform the same operation across entire cache lines. These considerations led us to a dataflow fabric (to avoid re-fetching the same instructions) with SIMD functional units (for repeated operations).</p><p>Summary. täkō hardware enables visibility and control over data movement in software via its general-purpose programming interface. The architecture changes only once, up front, rather than for each individual data-movement feature or optimization. täkō thus massively reduces the barrier for optimizing data movement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>Memory hierarchies currently suffer from innovation deadlock: though specialization offers large benefits, it also requires prohibitively large, up-front investments in both hardware and software. Without strong demand from software, hardware vendors are reluctant to design, verify, and support new features; but without hardware support, software vendors will not rewrite applications. As a result, architects are limited to optimizations that preserve the load-store interface but leave significant gains on the table. The goal of täkō is to break this deadlock by providing a general-purpose architecture that frees software to optimize data movement itself.</p><p>To motivate täkō, we begin with an example of how polymorphic cache hierarchies enable data-movement optimization in software. The purpose of this example is to introduce the basic components of a polymorphic cache hierarchy. Later case studies will show the full power of polymorphic cache hierarchies to transform cache behavior.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Example program: Lossy compression.</head><p>Prior work has studied many optimizations that transform data as it moves through the cache, e.g., to compress <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b105">106,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr" target="#b117">118,</ref><ref type="bibr" target="#b135">136,</ref><ref type="bibr" target="#b145">146]</ref>, decrypt <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b114">115]</ref>, prefetch <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b130">131,</ref><ref type="bibr" target="#b148">149]</ref>, change layout <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>, memoize <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b152">153,</ref><ref type="bibr" target="#b153">154]</ref>, or serialize/de-serialize <ref type="bibr" target="#b107">[108]</ref> data. We motivate täkō by observing how its onMiss callback enables arbitrary data transformations while improving performance, saving energy, and reducing overall work. Fig. <ref type="figure" target="#fig_1">3</ref> shows our example program, which computes the average value of a data set that is stored in an approximate, compressed format in memory as a base plus offset value, similar to <ref type="bibr" target="#b106">[107]</ref>. Unlike standard compressed caches, this lossy compression cannot be implemented in hardware without application knowledge <ref type="bibr" target="#b88">[89]</ref>, motivating the need for software in the loop. (The details of the compression algorithm are immaterial; the point is that software can transform data however it likes.) This program has two major problems. Cores are inefficient at data transformations, wasting time and energy <ref type="bibr" target="#b107">[108,</ref><ref type="bibr" target="#b145">146]</ref>. And if data are re-used, then the program re-executes the same transformation many times. However, there is currently no good alternative in software, as alternative implementations waste memory, add data movement, or perform even more work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">täkō to the rescue!</head><p>Fig. <ref type="figure">4</ref> illustrates how täkō solves these problems. Rather than operate on the raw compressed data, the program allocates a new "phantom" address range for decompressed data. These addresses only live in the caches and are not backed by physical memory. The program defines an onMiss callback that decompresses data whenever a new cache line in the phantom range is requested.</p><p>The callbacks are grouped in a Morph object that collects the data and methods for this polymorphic cache hierarchy -in this example, a data pointer to the phantom address range and pointers to the bases and deltas arrays. The onMiss callback takes the phantom address that triggered the miss and decompresses the requested data. All operations execute in parallel across the full cache line, shown in data-parallel pseudocode for brevity.</p><p>The modified program first registers the Morph at the private L2 cache, allocating a phantom address range for it. It then simply reads the decompressed data and computes the average, now using even simpler code. Fig. <ref type="figure">5</ref> illustrates its execution. The first time the program reads a phantom address X, there is an L2 miss, which triggers onMiss on the spatial dataflow engine to decompress the full cache line. The decompressed line is then cached so that any  subsequent read of the same line (due to spatial or temporal locality) is a cache hit, eliminating redundant work from decompressing the same data many times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results and comparison to prior work.</head><p>The täkō version of this program improves performance, saves energy, and reduces redundant work. Fig. <ref type="figure">6</ref> shows results with 32 K indices for the baseline software implementation, a software version that pre-computes the decompressed data in a separate array, a near-data computing (NDC) implementation, and the täkō ( ) implementation. The pre-compute version uses vector instructions to decompress a full cache line (eight values) at a time. The NDC version is similar to <ref type="bibr" target="#b82">[83]</ref>, where the core offloads decompressions to execute at an L2 engine. Indices are randomly generated following a Zipfian distribution <ref type="bibr" target="#b20">[21]</ref> over 16 K values. (Full experimental methodology is in Sec. 7.) täkō reduces execution time by 55% vs. the software baseline and by 50% vs. software pre-computation, and it reduces energy by 61% and 52%, respectively. Moreover, täkō comes within 1.1% performance and 1.3% energy of an idealized engine with unlimited, instantaneous, and energy-free compute. täkō achieves these gains by memoizing decompressions of frequently accessed data (Fig. <ref type="figure" target="#fig_3">7</ref>), greatly reducing the number of total decompressions. Although the pre-compute version avoids decompressing the same value multiple times, it decompresses values which are never accessed and also allocates memory for the entire decompressed array, incurring significant memory overheads. With täkō, decompression runs on in-cache engines, in parallel with software threads, similar to prior near-data computing (NDC) architectures. However, unlike NDC, täkō triggers computation by data movement, not from cores: instead of decompressing data every time it is requested, täkō decompresses data only on a miss and caches it thereafter, exploiting locality to eliminate redundant work <ref type="bibr" target="#b152">[153,</ref><ref type="bibr" target="#b153">154]</ref>.</p><p>This optimization is not possible in prior NDC systems, which move computation closer to data but do not improve software's visibility over data movement. Fig. <ref type="figure">6</ref> shows that NDC actually hurts performance and energy efficiency on this decompression example. This is because decompressing at the L2 fails to exploit locality in the L1s; in other words, offloading computation near-data is not always an optimization <ref type="bibr" target="#b82">[83]</ref>. In contrast, täkō's cache-triggered computation gets the best of all worlds by executing computations near-data, eliminating wasteful work, and preserving locality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discussion.</head><p>Decompression is representative of many prior optimizations that transform data as it moves through the cache hierarchy. Such transformations are easily implemented by writing onMiss, onEviction, and onWriteback callbacks. These callbacks are written in software and execute on täkō's general-purpose hardware. Compared to adding custom hardware, täkō reduces the innovation barrier by orders of magnitude.</p><p>It bears emphasizing that a polymorphic cache hierarchy is not purely microarchitectural. This is by design: the entire point is to give software visibility and control over data movement. Callbacks should be thought of as part of the application code, which execute as hardware-scheduled threads in parallel with conventional software threads. A well-structured application splits functionality appropriately between the two. Finally, while this example showed how täkō can leverage caches to eliminate redundant work, täkō is capable of more radical transformations of cache behavior. These will be explored in Sec. 8.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TÄK Ō PROGRAMMING INTERFACE</head><p>täkō's programming interface is designed to let software optimize data movement in ways that would otherwise require custom hardware. Our goal is to massively reduce implementation effort vs. the custom hardware required by prior specialized cache hierarchies. This section describes the interface and restrictions that make it easier to reason about program behavior. Though täkō is available to application programmers, it currently targets experts; we envision täkō code being shipped as part of domain-specific frameworks or libraries.</p><p>Overview. täkō breaks the address space into different address ranges, each with their own semantics. Software can register callbacks that execute in response to specific cache events -misses, evictions, and writebacks. By default, addresses retain load-store semantics and have no callbacks registered.</p><p>Software defines the behavior of a polymorphic cache hierarchy by providing a Morph data type and registering it with a specific address range. Often, the Morph allocates a new "phantom" address range that is not backed by physical off-chip memory <ref type="bibr" target="#b22">[23]</ref>, but Morphs can also be registered on "real" addresses. Phantom callbacks define the results of loads and stores to the address range, since there is no backing memory to load or store. Fig. <ref type="figure" target="#fig_4">8</ref> gives pseudocode for täkō's basic interface, discussed in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">register/unregister.</head><p>Registering the Morph associates callbacks with an address range. Software provides a morph type (a child class of täkō::Morph), the location in the cache hierarchy to register the Morph, and the address range. The location can be PRIVATE (at the L2) or SHARED (at the L3). Currently, täkō does not support Morphs at the L1 because L1s are very tightly integrated with cores; nor does it support Morphs at memory because memory controllers are below the cache coherence protocol, complicating consistency in callbacks.</p><p>Phantom address ranges are requested only by their size, and registerPhantom allocates and assigns the address range. To support Morphs on existing data, registerReal accepts an arbitrary base and bound and attempts to register the Morph on this range. täkō only allows one Morph to be registered on an address at a time. This restriction simplifies translation hardware (see below), but it is not fundamental.</p><p>The Morph remains in effect until unregistered. When a Morph is registered or unregistered, its address range is flushed from the cache. unregister de-allocates phantom address ranges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Morph objects.</head><p>A Morph object represents an instance of a particular polymorphic cache hierarchy. Multiple instances of a Morph type, or of different types, can be registered at the same time, each operating on their own distinct address ranges (e.g., see Sec. 8.3). register returns a Morph object, letting software threads control it (e.g., by unregistering it).</p><p>Callbacks execute on engines, not cores, and each engine also has its own view (i.e., copy) of the Morph object. This is important because each view may have local state, similar to conventional thread-local state, but shared by all threads running on that engine. Local state is allocated in memory, and engines access it via coherent loads and stores. PRIVATE Morphs have a single view (at the L2), but SHARED Morphs have one view per L3 bank. The views are gathered in the views array to, e.g., allow initialization of local state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Callbacks.</head><p>Cache-triggered callbacks are the heart of täkō's design. By defining callbacks in the Morph, software transforms the semantics of that address range. Callbacks are flexible to maximize täkō's applicability, but they must obey certain restrictions for correctness and performance.</p><p>Semantics. täkō callbacks allow software to modify cache behavior, as summarized in Table <ref type="table" target="#tab_0">1</ref>. For phantom address ranges, onMiss and onWriteback directly define the results of loads and stores. When there is a miss to a phantom address, the cache controller allocates a line, zeroes it, and then invokes onMiss. When evicting a phantom cache line, the cache controller invokes onEviction (if clean) or onWriteback (if dirty) and then discards the line. Intervening memory operations (i.e., cache hits) simply read and write the data normally, without invoking callbacks.</p><p>Callbacks on real address ranges operate similarly, except that the cache controller reads and writes the backing memory, maintaining load-store semantics by default. onMiss begins executing in parallel with reading addr. onWriteback executes before writing back addr to let the callback interpose.</p><p>onMiss is on the critical path of software threads, but onEviction and onWriteback are not. This difference is important for performance: it is best to keep onMiss short, and push work into the other callbacks (e.g., see Sec. 8.1).</p><p>Execution model. Callbacks are short threads that are created and scheduled entirely by hardware and run in parallel with conventional software threads (Fig. <ref type="figure">9</ref>). Because callbacks are triggered by cache hardware, they can occur spontaneously from the perspective of a software thread. This spontaneity can be unintuitive: cache misses can be triggered by speculative loads or prefetches, so an onMiss may not correspond to any committed instruction in a program. Similarly, data can be evicted from caches at any time, triggering onWriteback even when no corresponding software thread is active.</p><p>Restrictions. Given these considerations, it is best practice to write callbacks that behave similarly to conventional reads, evictions, and writebacks. Ignoring side effects, callbacks can reference nearly any memory address. The remaining exception is that callbacks cannot access data with a Morph registered at the same or higher level of the cache hierarchy (Fig. <ref type="figure">9</ref>). Without this restriction, deadlock is possible as callbacks trigger further callbacks, quickly exhausting the engine's hardware scheduler. A SHARED callback is not allowed to trigger a PRIVATE callback because the PRIVATE callback could trigger onMiss in the shared cache. But a PRIVATE callback can trigger a SHARED callback, since there is no cyclic dependence. This constraint was not problematic in any of our case studies.</p><p>Callback code. täkō is designed for short callbacks, which we find to be natural in our case studies. Callback code executes in SIMD fashion across entire cache lines. For long code paths or error conditions, callbacks can raise a user-space interrupt to preempt a software thread (e.g., see Sec. 8.4). For simulation convenience, callback code is currently written in C++, and instructions are mapped onto the dataflow fabric when they first execute; in practice, one could compile code statically <ref type="bibr" target="#b129">[130,</ref><ref type="bibr" target="#b142">143]</ref>.</p><p>Coherence and consistency. täkō leverages the cache-coherence protocol in the baseline multicore to provide a consistent view of memory. A callback is just another thread in the system, from a consistency perspective. Engines have coherent L1d caches, implemented using clustered coherence within each tile to avoid increasing directory state <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b87">88]</ref>. In brief, the L2 and engine L1d snoop on coherence traffic within each tile so that the directory behaves exactly as if the engine L1d is part of the L2 cache on that tile.</p><p>Callbacks thus enjoy the same coherence and consistency as any other thread in the system. Additionally, the address that triggered the callback is locked for the duration of callback execution; i.e., no other thread (or callback) can access the data until the callback completes. Locking is strictly enforced by the cache controller, which serializes operations on each address. Callbacks therefore do not need to worry about racing accesses to addr, but races to other addresses are possible, so callbacks should be data-race free <ref type="bibr" target="#b0">[1]</ref> to maintain consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">flushData.</head><p>flushData enables synchronization between callbacks and conventional threads without completely unregistering a Morph. By flushing all of a Morph's data from the cache, programs are guaranteed that there will be no further racing writes from callbacks. flushData signals cache controllers at the appropriate level of the hierarchy to walk their tag arrays and flush any lines belonging to the Morph's address range, triggering onWriteback or onEviction. flushData blocks the software thread until all callbacks complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discussion and roads not taken.</head><p>We found the above callbacks to be a logical starting point for a polymorphic cache hierarchy that covers a wide range of use cases. As discussed in Sec. 2, the basic intuition is to generalize caches by letting software provide an onMiss handler <ref type="bibr" target="#b55">[56]</ref>, and the rest of the interface and its restrictions follow naturally. We arrived at this interface early in the design, and it proved useful, self-contained, and consistent. Although the semantics are not trivial, writing täkō software has been fairly straightforward in our experience. For most applications, there is a clear separation of concerns across misses and clean or dirty evictions (Sec. 8).</p><p>That said, more callbacks are certainly possible. onReplacement would allow software to optimize the eviction policy for particular workloads <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b144">145]</ref>. onHit would allow customization of the cache coherence protocol, among other applications. We did not pursue onHit because programmable cache coherence has been explored extensively <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b112">113,</ref><ref type="bibr" target="#b122">123,</ref><ref type="bibr" target="#b150">151,</ref><ref type="bibr" target="#b151">152]</ref> and because it seemed that onHit would often be needed in the L1, requiring disruptive core changes. Finally, one could make cache indexing programmable, letting software re-purpose the tag array <ref type="bibr" target="#b110">[111,</ref><ref type="bibr" target="#b111">112,</ref><ref type="bibr" target="#b115">116,</ref><ref type="bibr" target="#b120">121,</ref><ref type="bibr" target="#b121">122,</ref><ref type="bibr" target="#b153">154]</ref>. We did not explore this direction to avoid adding any latency to conventional loads and stores -täkō has no performance impact on legacy applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">TÄK Ō ARCHITECTURE</head><p>Similar to recent near-data-computing architectures <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b104">105,</ref><ref type="bibr" target="#b141">142,</ref><ref type="bibr" target="#b149">150]</ref>, täkō extends a baseline multicore with near-cache engines to run callbacks efficiently (Fig. <ref type="figure">2</ref>). Engines are placed on each tile of the multicore, near the L2 and L3 caches. The engines consist of (i) a hardware scheduler that buffers callbacks and runs them when they are ready, and (ii) a spatial dataflow fabric that executes callbacks efficiently. Fig. <ref type="figure" target="#fig_6">10</ref> shows onMiss and onWriteback callbacks, which are referenced throughout the text below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Core modifications for täkō.</head><p>Tracking Morphs. täkō tracks which addresses have a registered Morph via the TLB. TLBs are augmented with two bits indicating whether a Morph is registered and, if so, whether it is registered at PRIVATE or SHARED. When a load or store misses, the core augments the GET request with these bits, giving the Morph's location 1 . Alternatively, täkō could keep a separate table of registered Morphs, but this would limit the number of Morphs that could be registered concurrently.  ISA. täkō adds one new cache flush instruction, corresponding to the flushData API, that flushes a particular address range in the PRIVATE or SHARED cache.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cache modifications for täkō.</head><p>State. Tags are extended with one bit to track whether a Morph is registered for the line at that cache level 2 . This bit is set on insertion using the two registration bits in the GET request.</p><p>Triggering a callback. Engines are tightly integrated with the cache controller. When serving a cache miss, eviction, or writeback, the controller checks whether a Morph is registered and, if so, sends a request to the local engine along with the addr and operation type. The engine's scheduler enqueues a request in its callback buffer 3 8a , which starts executing it as soon as the fabric is available and the callback configuration is loaded 4 9 . (Usually, the fabric is ready immediately.) For onEviction and onWriteback, the registered line occupies an entry in the cache's writeback buffer until a callback buffer entry is available. When the callback completes, the cache controller responds to the original request 5 . Other cache operations (i.e., all hits and any operation with no Morph registered) work normally and do not go through the engines at all.</p><p>Avoiding deadlock. Without additional mechanisms, deadlock can occur in the engine scheduler: e.g., suppose the engine's callback buffer is full, an executing callback suffers a cache miss, and every line in the set is waiting to grab a callback buffer spot (e.g., to execute onMiss). Nothing can be evicted because the callback buffer is full, so the callback buffer cannot drain.</p><p>Luckily, it is easy to avoid this deadlock by ensuring that there is always a cache line in every set with no Morph registered at this cache or any child cache. This constraint guarantees forward progress, as there will always be a line that can be evicted without triggering a callback. täkō enforces this constraint by modifying its eviction policy, trrîp (see below). For similar reasons, täkō enforces that there is always at least one MSHR and writeback buffer entry not waiting on a callback.</p><p>Avoiding cache pollution from callbacks. Callbacks often translate a phantom address to some real address that is accessed during the callback, but is not accessed afterwards (e.g., deltas[idx] in Fig. <ref type="figure">4</ref>). To avoid cache pollution, täkō modifies its RRIP-based <ref type="bibr" target="#b61">[62]</ref> Processing Element replacement policy, trrîp, to insert accesses from engines at lower priority (i.e., closer to eviction). This optimization can significantly improve cache utilization; e.g., in a simple Morph that maps arrayof-structs to struct-of-arrays, we have observed speedup of &gt; 4×.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ALUs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Engine microarchitecture.</head><p>täkō adds one engine to each tile of the CMP. The engine runs all callbacks for the L2 and L3 bank on that tile. It has its own cachecoherent L1 data cache, a small TLB and reverse TLB for address translation, and a spatial dataflow engine to execute callbacks.</p><p>Scheduling callbacks in hardware. The scheduler consists of simple logic in hardware and a buffer of pending requests. Upon receiving a callback request, the engine enqueues it in its callback buffer, assigns the callback a unique id, and loads the callback bitstream into the fabric (if necessary). The engine maintains a small bitstream cache, which maps Morphs' registered address ranges to their callbacks' bitstreams and tracks which callbacks are loaded on the fabric. Callbacks begin executing once the fabric is ready and all earlier callbacks on the same addr have finished.</p><p>Dataflow fabric. Callbacks execute on a small dataflow fabric; see Fig. <ref type="figure" target="#fig_7">11</ref>. The fabric is an array of simple processing elements (PEs) connected by an on-chip network. Each PE contains an instruction memory that holds a small number (e.g., <ref type="bibr" target="#b15">16</ref>) of static instructions, a token store that holds intermediate values, and ALUs. PEs issue operations using asynchronous dataflow firing, supporting concurrently executing callbacks via dynamic tag matching <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b137">138,</ref><ref type="bibr" target="#b142">143]</ref> on callback ids. Operations work in SIMD fashion across entire cache lines at a time.</p><p>Our workloads require only a small fabric (e.g., 5 × 5) with simple integer operations and few (e.g., 8) concurrent callbacks (see Sec. 9). Our largest Morph, for HATS (Sec. 8.2), contains 94 instructions across all its callbacks, less than one-quarter of fabric resources. Our next-largest application contains only 46 instructions. Moreover, across all applications, there are no more than 19 average live tokens when an engine is active (summing across concurrent callbacks). There is thus plenty of room for co-running applications to share engines, even without mechanisms to limit contention (see Sec. 6).</p><p>We chose dataflow fabrics for täkō engines because (i) callbacks are typically short, (ii) callbacks are frequently executed in parallel, and (iii) callbacks are executed repeatedly. Short callbacks map easily onto a small, dynamic dataflow fabric, letting täkō run callbacks near-data with low area overhead. A dataflow fabric can easily run callbacks in parallel by assigning each a unique tag. Alternatively, täkō could execute callbacks on reserved SMT threads <ref type="bibr" target="#b140">[141,</ref><ref type="bibr" target="#b150">151]</ref>, but this would either sequentialize callbacks or require multiple, heavy-weight thread contexts. Moreover, constantly re-fetching and decoding the same instructions would be wasteful. Preliminary exploration of SMT threads showed severe performance penalties, and Sec. 9 finds that in-order cores, as proposed in prior work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b82">83]</ref>. perform very poorly in täkō.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Putting it all together.</head><p>täkō's hardware support adds little area to the baseline multicore system (Table <ref type="table" target="#tab_5">2</ref>). With 512 KB L3 banks and 64 B lines, the L3 tags need 1 KB to track Morph registration. The engines have 8 KB L1d caches, 2 KB TLB and rTLBs (see below), and a 5 × 5 dataflow fabric with integer functional units. Conservatively overprovisioning the token and instruction memory yields state overhead of 5.3% over an L3 bank. This is comparable to recent fabrics <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b113">114,</ref><ref type="bibr" target="#b142">143]</ref>, which add roughly 5% area overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SYSTEM INTEGRATION</head><p>By opening up the cache hierarchy to software, täkō touches many aspects of the system stack. This paper does not solve every issue, but here we discuss some of the major implications of polymorphic cache hierarchies.</p><p>Address translation. Caches use physical addresses, but täkō callbacks need virtual addresses. The engines maintain a reverse TLB (rTLB) for this purpose. The rTLB is eagerly filled when an onMiss is scheduled 3 ; however, we found that this optimization makes little difference in our workloads because rTLB hit ratios are so high. When a callback is scheduled, the engine recovers the virtual addr using the rTLB and the physical address from the cache tags 8b . Synonyms (i.e., ambiguity in reverse translation) are not an issue because only one Morph can be registered on an address at a time. The engine also keeps a conventional L1 TLB for other data accessed by callbacks, sharing the L2 TLB with the main core.</p><p>täkō has several nice features with respect to address translation. Phantom addresses are not backed by physical memory, making huge pages easier to use because fragmentation is less of a concern than in conventional memory allocators <ref type="bibr" target="#b73">[74]</ref>. Moreover, the engines' rTLB only needs to cover data currently in the cache, since onEviction and onWriteback can only be triggered on cached data. Both of these observations mean that the engine rTLB can be small (Sec. 9). We assume that engine TLBs are kept coherent using shootdowns when translations change (e.g., when a Morph is registered or unregistered). OS support. täkō requires operating system support to manage Morph registration. The operating system needs to track which address ranges currently have a Morph registered along with a pointer to the callback code. Phantom address ranges may require an independent data structure from the page tables, since they use physical addresses that do not correspond to physical memory. Morphs also complicate thread scheduling because eviction callbacks can still run even if a process is de-scheduled from cores. In many cases, this is not problematic. But if a process must be fully de-scheduled for some reason, then it is necessary to also flush its Morphs' data (i.e., using the flushData API). Doing this is feasible but takes time and energy, especially for Morphs at the SHARED cache.</p><p>Multi-tenancy, virtualization, and security. In heavily shared systems with many active Morphs, further potential problems arise with thrashing in engines, possible security issues between concurrent callbacks, and virtualizing shared resources. These issues are outside the scope of this paper, but we think partitioning application data across L3 banks is a promising solution <ref type="bibr" target="#b99">[100,</ref><ref type="bibr" target="#b119">120]</ref>. That is, the operating system can prevent unwanted contention or interaction between callbacks by preventing them from sharing cache space in the first place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTAL METHODOLOGY</head><p>Simulation framework. We evaluate täkō in execution-driven microarchitectural simulation. Our simulator shares infrastructure with SwarmSim <ref type="bibr" target="#b62">[63]</ref>, but supports cycle-level timing throughout the memory hierarchy and models täkō's interface and engines.</p><p>System parameters. Except where specified otherwise, our system parameters are given in Table <ref type="table" target="#tab_6">3</ref>. We model a tiled multicore system with 16 cores connected in a mesh on-chip network. Each tile contains a conventional out-of-order core (modeled after Intel Goldmont), one bank of the shared LLC, and a täkō engine. Sec. 9 varies these parameters and shows that täkō is effective across a variety of system configurations.</p><p>We assume the out-of-order cores support atomic exchange operations (e.g., LL/SC) along with other relaxed atomics. Except where noted, we evaluate engines with a 5 × 5 dataflow fabric (15 integer PEs and 10 memory PEs) with 1-cycle PE latency. We also evaluate an idealized engine with unlimited, 0-cycle latency PEs; i.e., callback latency is only affected by memory latency and data dependencies.</p><p>Metrics. We present results for speedup and dynamic execution energy (energy parameters from <ref type="bibr" target="#b113">[114,</ref><ref type="bibr" target="#b132">133]</ref>). We focus on dynamic energy because täkō has negligible impact on static power and to clearly distinguish täkō's impact on data movement energy from its overall performance benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EVALUATION -CASE STUDIES ON TÄK Ō</head><p>täkō's flexible programming interface enables a wide variety of optimizations on the same, general-purpose hardware. We evaluate a sample of four applications that can benefit from täkō to demonstrate:</p><p>• täkō supports prior specialized cache hierarchies. We implement two prior designs that accelerate graphs in very different ways <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b94">95]</ref>. • täkō enables features in software that are impossible without fine-grain visibility over data movement. Specifically, täkō lets the system eliminate unnecessary writes in direct-access NVM and detect suspicious activity. • täkō's performance is fairly insensitive to its microarchitectural parameters (Sec. 9) and close to an idealized design.</p><p>Our case studies depend on being able to observe and interpose on data movement, and are thus not implementable on prior near-data computing (NDC) architectures. täkō provides the missing interface and mechanisms to implement these data-movement optimizations in software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Accelerating commutative scatter-updates.</head><p>We begin with an example of how täkō can redefine cache semantics to accelerate data movement. This study implements PHI <ref type="bibr" target="#b94">[95]</ref>, a push-based hierarchy for commutative scatter-updates, e.g., in graph applications. PHI turns the cache into a large write-combining buffer for commutative operations (e.g., addition). In PHI, the cache contains updates (e.g., deltas), not raw data. When a cache line is evicted, PHI either immediately applies the update in-place or logs the update to be applied later <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b69">70]</ref>. PHI minimizes memory bandwidth by choosing between these two policies, using the number of updates in the line to decide which is best.</p><p>Description. Fig. <ref type="figure" target="#fig_0">12</ref> illustrates how täkō implements PHI. The application starts by allocating a phantom address range the same size as the graph's vertex data. In the first phase, updates are pushed to the phantom region using remote memory operations (RMO) (i.e., relaxed atomic add <ref type="bibr" target="#b125">[126]</ref>). If updates 1 miss in the cache, they trigger onMiss 2 to initialize the lines with an identity element (e.g., zero for addition), without making any requests down the cache hierarchy. The application then pushes commutative updates to the cache (i.e., write hits). When a line is evicted from the cache, onWriteback either directly applies the updates to backing memory 3a or appends them to a "bin" 3b , depending on the number of non-identity values in the line. After completing the edge phase, the main thread calls flushData and then streams through the bins to apply deferred updates (not shown).</p><p>Why täkō? PHI's design fits very well with täkō's interface. Its implementation requires application-and data-dependent operations on cache lines as they are allocated and evicted. This is exactly the type of data-movement control that täkō enables in software. Moreover, PHI is a prime example of the limitations of prior NDC: PHI requires the ability to intercept misses and writebacks and modify their behavior, which is not possible in traditional NDC.</p><p>Figure <ref type="figure" target="#fig_0">12</ref>: täkō lets software repurpose the cache to accelerate applications. PHI accelerates scatter-updates by buffering updates in-cache and applying them when evicted. Writebacks either apply updates in-place or log updates to be applied later. These optimizations are naturally implemented in täkō via onMiss and onWriteback.  otherwise, log updates for application in "binning" phase. Evaluation. Fig. <ref type="figure" target="#fig_9">13</ref> shows results for PageRank with 16 pushing updates to a single Morph registered at SHARED, 3 comparing täkō to a baseline software implementation, a software implementation of update batching (UB) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b69">70]</ref>, and an ideal dataflow engine. We see similar results as the PHI paper <ref type="bibr" target="#b94">[95]</ref>: UB in software gets 3.2× speedup, but täkō gets 4.2× speedup. täkō also reduces energy by 36%, compared to 27% for UB. täkō achieves its benefits by (i) writing to phantom data, which does not incur a memory access on miss; (ii) binning updates off the critical path of the main threads on writeback; and (iii) reducing memory accesses and core computation compared to UB (by 29% each) by buffering updates in the cache and sometimes applying them in-place. Fig. <ref type="figure" target="#fig_10">14</ref> breaks down memory accesses for each implementation between the edge, bin, and vertex phases of PageRank. UB reduces total accesses by 43% by improving spatial locality via binning. täkō reduces total accesses by 60% by buffering updates in-cache and only binning when 3 Due to simulator limitations, we can currently only run PHI at a single level. But täkō's design allows hierarchical PHI as described in <ref type="bibr" target="#b94">[95]</ref>, which would show even better results.</p><p>there is poor spatial locality, lowering accesses in both edge and bin phases. Further, täkō incurs negligible overheads compared to an ideal engine because onWriteback is short (35 cycles and 21 instructions on average), off the critical-path, and most of the latency comes from memory accesses (0.17 accesses per onWriteback on average).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Accelerating graph traversals via streams.</head><p>This second study takes a much different view of accelerating graph applications by using täkō to implement a programmable, decoupled stream. Architectures have long had special support for streaming access patterns <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b98">99,</ref><ref type="bibr" target="#b138">139,</ref><ref type="bibr" target="#b139">140,</ref><ref type="bibr" target="#b141">142]</ref>, many of which use dedicated engines to stream data to the main cores. We demonstrate täkō's support for programmable streams by implementing HATS (hardware-accelerated traversal scheduling) <ref type="bibr" target="#b91">[92]</ref>, which computes an efficient graph traversal to improve data locality in graph applications.</p><p>Description. HATS observed that, without expensive pre-processing, it is inefficient to process edges in the order they are laid out in memory. Many graphs exhibit strong community structure <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b77">78]</ref>, so it is much better to process graphs one community at a time. A bounded, depth-first search (BDFS) is a simple traversal order that significantly improves locality. The challenge is that BDFS is a poor fit for cores due to unpredictable control flow, so HATS adds a dedicated hardware engine.</p><p>Fig. <ref type="figure" target="#fig_11">15</ref> illustrates the täkō implementation of HATS. The application initially allocates a phantom address range large enough to hold every edge of the graph (recall that no physical memory is allocated). This phantom address range acts as a stream, where the core reads edges sequentially and the engine supplies edges when requested by onMiss. HATS's onMiss keeps a small stack and walks the graph in BDFS order, as described in the original paper <ref type="bibr" target="#b91">[92]</ref>. Our current implementation of HATS sequentializes all onMisses to simplify contention on the shared stack. While the core processes one part of the stream, the prefetcher triggers onMiss for subsequent edges. Note that onMiss is not guaranteed to be called in strictly sequential order, but this is fine in HATS because minor re-orderings have minimal impact on locality.</p><p>However, a more serious concern is that phantom lines can be evicted before the core has processed them. Although this occurs exceedingly rarely, the application cannot tolerate any lost edges. täkō solves this problem by logging unprocessed edges to memory in onWriteback and onEviction. To know which edges have been processed, the core assigns an INVALID value to processed edges using an atomic exchange (e.g., LL/SC). Any unprocessed edges are logged during onWriteback and onEviction, and the core processes the logged edges at the end of the iteration.</p><p>Why täkō? HATS is a good example of a streaming computation that runs inefficiently on cores, motivating the need for separate streaming hardware <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b141">142,</ref><ref type="bibr" target="#b149">150]</ref>. This case study shows how täkō can support this important class of workloads. For performance, HATS relies on decoupling between graph traversal (on engines) and edge processing (on cores); this is awkward if not impossible to implement in NDC. Moreover, implementing HATS in täkō software    lets it support a wide range of graph data formats or traversal heuristics <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b93">94]</ref>, unlike fixed-function hardware.</p><p>Evaluation. Fig. <ref type="figure" target="#fig_12">16</ref> presents speedup and energy results for a single thread of PageRank with the baseline "vertex-ordered" traversal, a baseline software BDFS implementation, täkō, and an ideal engine. Baseline BDFS provides minimal benefits due to extra instructions with complex control flow. In contrast, täkō provides substantial speedup of 43%, approaching the 46% speedup of an ideal engine. täkō also reduces energy by 17%, compared to 22% for ideal.</p><p>This speedup is due to (i) better cache locality; (ii) regularizing control flow on the core; and (iii) decoupling edge traversal from the core. Fig. <ref type="figure" target="#fig_13">17</ref> quantifies these points. All versions incur the same number of accesses during the vertex phase, but the BDFS traversal (also used by täkō) reduces misses to vertex data during the edge täkō achieves significant speedups on HATS, but somewhat lower than reported in <ref type="bibr" target="#b91">[92]</ref>. This is because we sequentialize the calls to onMiss, whereas <ref type="bibr" target="#b91">[92]</ref> re-orders the trace to exploit locality by traversing multiple neighbors in parallel and processing whichever data returns first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">System support: Transactions in</head><p>direct-access NVM.</p><p>We next show how better visibility over data movement enables new features and optimizations. There are many applications where it would be useful to know when data moves in or out of caches: e.g., for immutable data structures <ref type="bibr" target="#b18">[19]</ref>, intermittent computing <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b86">87]</ref>, checking data integrity <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b143">144,</ref><ref type="bibr" target="#b155">156]</ref>, debugging and logging <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b90">91]</ref>, etc. This study considers a filesystem on non-volatile memory (NVM) with battery-backed caches, like Intel eADR <ref type="bibr" target="#b59">[60]</ref>. The major challenge is to avoid inconsistent states on failure. For this purpose, NVM filesystems employ transactions using journaling, logging, or shadow paging <ref type="bibr" target="#b143">[144,</ref><ref type="bibr" target="#b155">156]</ref>.</p><p>Description. Fig. <ref type="figure" target="#fig_4">18</ref> illustrates efficient journal-based transactions in täkō. Like prior transactional memory designs <ref type="bibr" target="#b90">[91]</ref>, the idea is that if a transaction's writes complete before any have been evicted from cache, then it is safe to push the updates directly to NVM without journaling. (In a sense, the cache is the journal.) The application writes all updates to a phantom address range 1 . To commit a transaction, the thread simply flushes the Morph's phantom data from the cache 2 . onWriteback either writes directly to NVM (if the transaction has committed) or journals the writes (if not) ∞ . In the common case where no data is evicted, täkō adds minimal overhead 3 . But if data is evicted before commit, then the application must apply the journaled writes to commit the transaction 4 . This design permits one in-flight transaction per Morph instance, but an application can register many instances. We register at PRIVATE because each transaction needs to flush all the phantom data, which is more efficient in the L2.</p><p>Why täkō? Current NVM filesystems must implement transactions conservatively because they cannot observe when data enters or leaves caches. Journaling avoids writing directly to data, but adds instructions and NVM writes. täkō lets filesystems only resort  Evaluation. Fig. <ref type="figure" target="#fig_0">19</ref> shows results for a workload of appendonly transactions of different sizes, from 1 KB to 128 KB. As long as transactions fit in the L2, täkō provides up to 2.1× speedup by eliminating unnecessary journaling. täkō executes ≈50% fewer core instructions and ≈36% fewer total instructions (Fig. <ref type="figure" target="#fig_15">20</ref>), yielding large speedup and up to 47% energy savings. täkō achieves the same gains as the ideal engine because the engine mainly performs very simple data copies. When the transaction size exceeds the cache size (i.e., 128 KB), onWriteback falls back to journaling and performs closer to the baseline. However, täkō still outperforms the baseline by filling the journal in onWriteback, off the critical-path of the core.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Detecting side-channel attacks.</head><p>Finally, we demonstrate täkō's security benefits by showing how it can defend against prime+probe attacks <ref type="bibr" target="#b80">[81]</ref> at the shared cache. This study emphasizes the additional functionality enabled by better visibility over data movement. Specifically, we demonstrate that täkō enables fine-grain monitoring of data for side-channel attacks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b124">125,</ref><ref type="bibr" target="#b146">147]</ref>.</p><p>Threat model. We consider a scenario with attacker and victim threads running on separate cores in a CMP with shared last-level cache. The attacker detects when the victim accesses a vulnerable data structure (e.g., AES tables) to reverse engineer secure data (e.g., AES keys). We consider a prime+probe attack, but prior work has used similar techniques to defend flush+reload, evict+time, and cache+collision <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>Description. The prime+probe attack <ref type="bibr" target="#b80">[81]</ref> leaks information about a victim process simply by detecting which cache sets the victim     <ref type="figure" target="#fig_18">21a</ref>. The attacker starts by priming a target cache set with its own data. After the victim has accessed its secure data, the attacker then monitors how long it takes to probe its own data. Long latency (due to cache misses) reveals to the attacker which sets the victim has accessed, and thus leaks the victim's access pattern. This prime+probe attack has been shown to leak entire AES keys <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b78">79]</ref>.</p><p>täkō gives the victim visibility over movement of their secure data. Specifically, to detect a prime+probe attack, the victim needs to know when data is evicted. The application registers a "real data" Morph for the address range of its secure data (e.g., AES tables). The Morph only implements one callback, onEviction, which simply interrupts the main thread whenever any cache line containing the AES tables is evicted. This interrupt lets the victim defend itself from attack <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b101">102,</ref><ref type="bibr" target="#b124">125]</ref>. Fig. <ref type="figure" target="#fig_18">21b</ref> shows a cache-eviction trace of an attack that is successful without täkō (left) and unsuccessful with täkō (right). täkō interrupts the victim during the probe phase of the attack before any information is leaked.</p><p>Why täkō? täkō exposes software to previously invisible data movement. Although active attackers can time cache accesses to expose microarchitectural state, passive victims might never even know they were attacked. täkō provides victim applications the tools to monitor data movement for cache attacks. This allows victims to take control over their data and defend themselves proactively. Like transactions above, visibility over data movement is the key to this defense, and prior NDC systems offer no solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">EVALUATION -SENSITIVITY STUDIES</head><p>Engine microarchitecture. We study täkō's sensitivity to engine microarchitecture on HATS. HATS is most sensitive to the fabric because its onMiss is the longest callback among our benchmarks. Fig. <ref type="figure">22</ref> evaluates different dataflow-fabric sizes, as well as an inorder core and ideal. Dataflow vastly outperforms in-order, but performance plateaus with small fabrics. We use a 5 × 5 fabric, which is within 1.8% of ideal.   5 fabric, varying arithmetic PE execution latency. We use singlecycle latency, but even at eight cycles speedup only decreases 30% from 43%. This is because memory-level parallelism, not arithmetic throughput, is what matters most for täkō (Sec. 5.3).</p><p>Core microarchitecture. Fig. <ref type="figure" target="#fig_20">24</ref> evaluates PageRank on PHI with different core microarchitectures. Speedup is unchanged because PageRank is memory-bound. Beefier cores improve performance in absolute terms on decompression and HATS, but täkō's speedup is affected little. Scalability. Fig. <ref type="figure" target="#fig_21">25</ref> evaluates PageRank on PHI across different system and data sizes. (Memory bandwidth scales proportionally with cores.) täkō consistently outperforms update batching and improves with data size. täkō outperforms update batching by ≈34%, 32%, and 21% at 8, 16, and 36 cores, respectively. Hierarchical PHI would improve PHI's speedup further at larger core counts by reducing cross-chip coherence traffic.</p><p>Callback-buffer size. The NVM journaling benchmark invokes many concurrent onWritebacks when flushing data, stressing the callback buffer. Varying the callback buffer from 1 to 64 entries, performance plateaus at 4 entries. Accordingly, we use 8 entries as a practical but sufficient size in our evaluation. rTLB size. Finally, we swept rTLB size from 256 to 1024 entries with both 4 KB and 2 MB pages, and found that performance varied by at most 2.1%. We use 256 entries with 2 MB pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">RELATED WORK</head><p>The cost of data movement. Data movement is more expensive than compute and only growing more so <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b75">76]</ref>. Even with inefficient out-of-order cores, data movement often consumes the majority of execution time and energy. Architectural specialization is no panacea: specialization makes data movement relatively more expensive <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38]</ref>, and a significant fraction of programs will always run on general-purpose cores <ref type="bibr" target="#b118">[119]</ref>. Architectures simply must become more efficient at data movement. Specialized cache hierarchies. These trends have been widely recognized, and there are many proposals to accelerate data movement, e.g., in machine learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b49">50]</ref>, graph analytics <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b149">150]</ref>, data structures <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b153">154]</ref>, memoization <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b152">153,</ref><ref type="bibr" target="#b153">154]</ref>, compression <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b105">106,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr" target="#b117">118,</ref><ref type="bibr" target="#b135">136,</ref><ref type="bibr" target="#b145">146]</ref>, data layout <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b154">155]</ref>, prefetching <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b130">131,</ref><ref type="bibr" target="#b148">149]</ref>, coherence and synchronization <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b150">151,</ref><ref type="bibr" target="#b151">152]</ref>, memory management <ref type="bibr" target="#b84">[85,</ref><ref type="bibr" target="#b134">135]</ref>, and system software <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b107">108,</ref><ref type="bibr" target="#b126">127]</ref>. While highly effective, they share the drawback of requiring custom hardware.</p><p>Software control of data movement. There has been some work that attempts to give software more control over the cache through better hardware partitioning mechanisms <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b109">110,</ref><ref type="bibr" target="#b116">117,</ref><ref type="bibr" target="#b132">133]</ref>, software policies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b119">120]</ref>, or a richer interface <ref type="bibr" target="#b92">[93,</ref><ref type="bibr" target="#b136">137]</ref>. These works are complementary to täkō: they control data movement behind the load-store interface, whereas täkō expands that interface.</p><p>Near-data computing. Rather than move data to compute, some architectures move compute to data. Many of these designs are discrete "processing in-memory" co-processors that integrate logic in memory <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b97">98,</ref><ref type="bibr" target="#b100">101,</ref><ref type="bibr" target="#b103">104,</ref><ref type="bibr" target="#b123">124,</ref><ref type="bibr" target="#b127">128]</ref> or near high-bandwidth memory <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b108">109,</ref><ref type="bibr" target="#b147">148,</ref><ref type="bibr" target="#b156">157]</ref>. Coprocessor designs make sense on streaming applications, but they are ill-suited to applications with significant data reuse or fine-grain communication <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b133">134,</ref><ref type="bibr" target="#b147">148]</ref>. Other architectures enable neardata computing within a CPU's memory hierarchy, letting cores offload work to memory <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b50">51]</ref> or caches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b104">105,</ref><ref type="bibr" target="#b128">129,</ref><ref type="bibr" target="#b141">142]</ref>. However, there is no mechanism to trigger software when data moves, which we have shown is essential to many data-movement optimizations. täkō provides this missing mechanism.</p><p>Programmable memory hierarchies. Finally, the most related work is prior programmable memory hierarchies. The first programmable memory hierarchies were explored in the '90s and focused on distributed cache coherence <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b112">113,</ref><ref type="bibr" target="#b122">123]</ref>. More recently, designs have added some programmability to the memory hierarchy for specific purposes: e.g., prefetching <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b130">131]</ref> or compression <ref type="bibr" target="#b145">[146]</ref>. By contrast, täkō targets a much wider set of features and optimizations by providing a general-purpose interface and architecture to increase software's visibility and control over data movement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">CONCLUSION AND FUTURE WORK</head><p>Many inefficiencies in current systems are the result of an outdated hardware-software interface that gives software too little visibility and control over data movement. Polymorphic cache hierarchies expand the hardware-software interface to expose more data movement to software. täkō is an efficient, general-purpose implementation of a polymorphic cache hierarchy that massively reduces the innovation barrier for data movement features and optimizations. We demonstrated the wide applicability of täkō in five case studies.</p><p>Polymorphic cache hierarchies open up several exciting directions for further research. The current programming interface is low-level and intended for experts as an alternative to custom hardware. Language and compiler support would make polymorphic cache hierarchies more approachable for programmers. The large design space for the engine microarchitecture remains unexplored, and there is potential for new callbacks to unlock more applications. täkō provides the first step towards a polymorphic cache hierarchy, and we plan to explore each component further in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: täkō in action: An application registers an address range whose semantics are defined by software callbacks. These callbacks run in-cache on programmable engines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example program written in traditional software.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>5 Figure 6 :</head><label>56</label><figDesc>Figure 6: Results for the example program. täkō improves performance by 2.2× and reduces energy by 61%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Num. decompressions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: täkō's interface for a polymorphic cache hierarchy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Example callback execution in täkō on a phantom address. Engines schedule and execute callbacks in hardware. TLBs and cache tags track where Morphs are registered. The accompanying text walks through the steps of callback execution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Figure11: Sketch of engine dataflow fabric microarchitecture. A fabric of simple processing elements (PE) are connected by an onchip network. Each PE holds a small number of instructions, which are issued to the ALU when input operands (with matching thread id) are available. A small number of PEs also connect to memory through the engine's L1 data cache.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: PHI results for PageRank on a 16M vertex, 160M edge synthetic graph. täkō improves performance by 4.2×.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: DRAM accs. per phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 :</head><label>15</label><figDesc>Figure15: täkō's stream implementation supports complex decoupled pipelines. HATS improves locality in graphs by traversing the graph in bounded depth-first order so that communities are visited together. onMiss provides a simple, datamovement triggered approach to filling a stream.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 16 :</head><label>16</label><figDesc>Figure16: HATS results for one iteration of PageRank on uk-2002 graph<ref type="bibr" target="#b32">[33]</ref>. täkō improves performance by 43% and reduces energy by 17% vs. the software baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: HATS performance breakdown. Left: DRAM accesses split by PageRank phase. Mid: core branch mispredictions per graph edge processed. Right: cumulative core load latency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 18 : 4 onWriteback</head><label>184</label><figDesc>Figure 18: täkō increases software's visibility over data movement, making some operations dramatically more efficient. When caches are persistent, täkō lets transactions avoid journaling if there are no writebacks before commit. Better visibility thus greatly reduces transaction overheads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Instructions executed for each 8B written in application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Attack succeeds in baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Attack detected in täkō.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Prime+probe attack on AES encryption tables at the L3. Without täkō, the attack succeeds with the victim unaware. täkō detects the attack immediately.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 22 :Figure 23 :</head><label>2223</label><figDesc>Figure 22: Sensitivity to engine fabric with HATS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 24 :</head><label>24</label><figDesc>Figure 24: PHI results for PageRank on a 160M-edge synthetic graph. täkō performs similarly with all core microarchitectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 25 :</head><label>25</label><figDesc>Figure 25: PHI results for PageRank across different numbers of cores/threads and different graph sizes (shown as num. edges). täkō performs well across all configurations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>täkō callback semantics. * ✗ -can only write local state and/or the affected cache line; see Sec. 4.3.Figure 2: täkō adds programmable engines to each tile of a CMP.Engines schedule callbacks in response to cache events and execute them in parallel with conventional threads.</figDesc><table><row><cell>Callback</cell><cell>Semantics</cell><cell></cell><cell cols="3">Side effects?  *</cell></row><row><cell>onMiss</cell><cell cols="2">Generates data for requested address.</cell><cell></cell><cell></cell><cell>✗</cell></row><row><cell>onEviction</cell><cell cols="2">Handles eviction of unmodified data.</cell><cell></cell><cell></cell></row><row><cell>Tile</cell><cell></cell><cell>Core</cell><cell>Callback</cell><cell>Buffer</cell><cell>Scheduler Hardware</cell></row><row><cell></cell><cell>L1d</cell><cell>L1i</cell><cell></cell><cell></cell></row><row><cell></cell><cell>L2</cell><cell>Engine</cell><cell cols="2">L1d</cell><cell>TLB</cell><cell>rTLB</cell></row><row><cell></cell><cell cols="2">L3 Cache Bank</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Tag Array</cell><cell>Data Array</cell><cell cols="3">Dataflow Fabric</cell></row></table><note>✗onWriteback Handles eviction of modified data. ✓</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>That is, onMiss and onEviction should Figure 9: Callbacks are scheduled by hardware in response to cache misses, evictions, and writebacks, and run on the engine closest to the data. Only writebacks should have side effects.be free of side effects, 2 since they can be triggered at any time, whereas onWriteback can have side effects, since modified data must correspond to a committed store in some software thread. These restrictions make it easier to reason about callback behavior, but täkō does not strictly enforce them because misses/evictions are sometimes part of correctness (e.g., for security; see Sec. 8.4).</figDesc><table><row><cell>GET</cell><cell>GET</cell><cell></cell></row><row><cell>Tile</cell><cell></cell><cell cols="2">Core</cell><cell>onMiss()</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Initializes data</cell></row><row><cell></cell><cell></cell><cell></cell><cell>No side-effects</cell></row><row><cell></cell><cell cols="2">PRIVATE L2</cell><cell>Engine</cell></row><row><cell></cell><cell>Morph</cell><cell></cell></row><row><cell></cell><cell>L3</cell><cell>✘</cell><cell>onEviction() onWriteback()</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Evicts data</cell></row><row><cell></cell><cell cols="3">SHARED Morph</cell><cell>Side effects only</cell></row><row><cell></cell><cell cols="3">Cannot access Morphs</cell><cell>for writebacks</cell></row><row><cell></cell><cell cols="3">at/above cache level</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Hardware overhead (state per L3 bank).</figDesc><table><row><cell>L3 tags 8K lines × 1 bit = 1 KB</cell></row><row><cell>Engine L1d, TLB, rTLB 8 KB + 2 KB + 2 KB = 12 KB</cell></row><row><cell>Callback buffer 8 lines × 64 B = 0.5 KB</cell></row><row><cell>Token store 25 PEs × 8 tokens / PE × 64 B = 12 KB</cell></row><row><cell>Instruction Memory 25 PEs × 16 instr / PE × ≈4 B = 1.6 KB</cell></row><row><cell>Total per L3 bank 27.1 KB / 512 KB = 5.3%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>System parameters in our experimental evaluation.Cores 16 cores, x86-64 ISA, 2.4 GHz, OOO Goldmont uarch<ref type="bibr" target="#b3">[4]</ref> Engines 16 engines, 15 int FUs (1-cycle latency), 10 mem FUs, 256-entry rTLB L1 32 KB, 8-way set-assoc, split data and instruction caches</figDesc><table><row><cell>L2</cell><cell>128 KB, 8-way set-assoc, 2-cycle tag, 4-cycle data array, trrîp repl., strided prefetcher</cell></row><row><cell>LLC</cell><cell>8 MB (512 KB per tile), 16-way set-assoc, 3-cycle tag, 5-cycle data array, inclusive, trrîp repl.</cell></row><row><cell cols="2">NoC mesh, 128-bit flits and links, 2/1-cycle router/link delay</cell></row><row><cell cols="2">Memory 4 controllers, 100-cycle latency, 11.8 GB/s per controller</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>täkō callbacks for PHI.</figDesc><table><row><cell>Callback</cell><cell>Semantics</cell></row><row><cell>onMiss</cell><cell>Sets line to identity element (e.g., zero).</cell></row><row><cell>onEviction</cell><cell>-</cell></row><row><cell cols="2">onWriteback If # updates &gt; threshold, apply updates immediately;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>täkō callbacks for HATS.</figDesc><table><row><cell>Callback</cell><cell>Semantics</cell></row><row><cell>onMiss</cell><cell>Fills line with edges in BDFS order.</cell></row><row><cell>onEviction</cell><cell>Logs unprocessed edges.</cell></row><row><cell cols="2">onWriteback Logs unprocessed edges.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>täkō callbacks for NVM support.</figDesc><table><row><cell>Callback</cell><cell>Semantics</cell></row><row><cell>onMiss</cell><cell>Sets line with INVALID value.</cell></row><row><cell>onEviction</cell><cell>-</cell></row><row><cell cols="2">onWriteback If transaction committed, apply writes immediately;</cell></row><row><cell></cell><cell>otherwise, journal writes.</cell></row><row><cell cols="2">Figure 19: Results for NVM journaling microbenchmark at different</cell></row><row><cell cols="2">transaction sizes. täkō improves performance by up to 2.1× and</cell></row><row><cell cols="2">reduces energy by up to 47%.</cell></row><row><cell cols="2">to journaling if data falls out of the cache. Prior NDC systems do</cell></row><row><cell cols="2">not improve visibility over data movement and hence do not enable</cell></row><row><cell>this feature.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>täkō callbacks for detecting side-channel attacks.</figDesc><table><row><cell>Callback</cell><cell>Semantics</cell></row><row><cell>onMiss</cell><cell>-</cell></row><row><cell>onEviction</cell><cell>Interrupt main thread.</cell></row><row><cell cols="2">onWriteback -</cell></row><row><cell>accesses, as shown in Fig.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">täkō is Japanese for octopus, an animal famous for its intelligence and mimicry. täkō is also a delicious Mexican-Asian fusion restaurant in Pittsburgh.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">We define a side effect as a modification to non-local state, i.e., a store to any location except the engine's local Morph object or the addr itself.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers, Nikhil Agarwal, Souradip Ghosh, Graham Gobieski, Brandon Lucia, Sara McAllister, and Nathan Serafin for their feedback. Brian Schwedock is supported by an NSF Graduate Research Fellowship and the Ann and Martin McGuinn Graduate Fellowship. Jennifer Seibert was supported by an NSF REU grant in the REUSE program at CMU's Institute for Software Research. This work was supported by NSF grant CCF-1845986.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Shared memory consistency models: A tutorial</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sarita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><surname>Gharachorloo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Compute caches</title>
		<author>
			<persName><forename type="first">Shaizeen</forename><surname>Aga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Supreet</forename><surname>Jeloka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Subramaniyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satish</forename><surname>Narayanasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Blaauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reetuparna</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23rd IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-23)</title>
				<meeting>of the 23rd IEEE intl. symp. on High Performance Computer Architecture (. HPCA-23)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The MIT Alewife machine: architecture and performance</title>
		<author>
			<persName><forename type="first">Anant</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Bianchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Chaiken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirk</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Kubiatowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beng-Hong</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd annual Intl. Symp. on Computer Architecture</title>
				<meeting>of the 22nd annual Intl. Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Agner</forename><surname>Fog</surname></persName>
		</author>
		<ptr target="https://www.agner.org/optimize/microarchitecture.pdf" />
		<title level="m">The microarchitecture of Intel, AMD and VIA CPUs</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">PIM-enabled instructions: a low-overhead, locality-aware processing-in-memory architecture</title>
		<author>
			<persName><forename type="first">Junwhan</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungjoo</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiyoung</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 42nd annual Intl. Symp. on Computer Architecture (Proc. ISCA-42)</title>
				<meeting>of the 42nd annual Intl. Symp. on Computer Architecture (. ISCA-42)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An Event-Triggered Programmable Prefetcher for Irregular Workloads</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ainsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23rd intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXIII)</title>
				<meeting>of the 23rd intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXIII)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Data reorganization in memory using 3D-stacked DRAM</title>
		<author>
			<persName><forename type="first">Berkin</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><surname>Franchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Hoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 42nd annual Intl. Symp. on Computer Architecture (Proc. ISCA-42)</title>
				<meeting>of the 42nd annual Intl. Symp. on Computer Architecture (. ISCA-42)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">AMNESIAC: Amnesic Automatic Computer</title>
		<author>
			<persName><forename type="first">Ismail</forename><surname>Akturk</surname></persName>
		</author>
		<author>
			<persName><surname>Ulya R Karpuzcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive cache compression for high-performance processors</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Alaa R Alameldeen</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 31st annual Intl. Symp. on Computer Architecture (Proc. ISCA-31)</title>
				<meeting>of the 31st annual Intl. Symp. on Computer Architecture (. ISCA-31)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">P-OPT: Practical Optimal Cache Replacement for Graph Analytics</title>
		<author>
			<persName><forename type="first">Vignesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><surname>Crago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aamer</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-27)</title>
				<meeting>of the 27th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-27)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Near-data processing: Insights from a MICRO-46 workshop</title>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Troy</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><forename type="middle">H</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="36" to="42" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive caches as a defense mechanism against cache side-channel attacks</title>
		<author>
			<persName><forename type="first">Sahan</forename><surname>Bandara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><forename type="middle">A</forename><surname>Kinsy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cryptographic Engineering</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Locality exists in graph processing: Workload characterization on an Ivy Bridge server</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Intl. Symp. on Workload Characterization (Proc. IISWC)</title>
				<meeting>of the IEEE Intl. Symp. on Workload Characterization (. IISWC)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reducing PageRank communication via propagation blocking</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 31st IEEE Intl. Parallel and Distributed Processing Symp. (Proc. IPDPS)</title>
				<meeting>of the 31st IEEE Intl. Parallel and Distributed essing Symp. (. IPDPS)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Jigsaw: Scalable Software-Defined Caches</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd intl. conf. on Parallel Architectures and Compilation Techniques</title>
				<meeting>of the 22nd intl. conf. on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Talus: A Simple Way to Remove Cliffs in Cache Performance</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-21)</title>
				<meeting>of the 21st IEEE intl. symp. on High Performance Computer Architecture (. HPCA-21)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scaling distributed cache hierarchies through computation and data co-scheduling</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-21)</title>
				<meeting>of the 21st IEEE intl. symp. on High Performance Computer Architecture (. HPCA-21)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Die Stacking is Happening!</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-46 Keynote</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The parallel persistent memory model</title>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Guy E Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcguffey</surname></persName>
		</author>
		<author>
			<persName><surname>Shun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 30th ACM Symp. on Parallelism in Algorithms and Architectures (Proc. SPAA)</title>
				<meeting>of the 30th ACM Symp. on Parallelism in Algorithms and Architectures (. SPAA)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks</title>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Boroumand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saugata</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngsok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachata</forename><surname>Ausavarungnirun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daehyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aki</forename><surname>Kuusela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Knies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23rd intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXIII)</title>
				<meeting>of the 23rd intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXIII)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Web caching and Zipf-like distributions: Evidence and implications</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Breslau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<idno>IEEE INFO- COM. 126-134</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the representation and multiplication of hypersparse matrices</title>
		<author>
			<persName><forename type="first">Aydin</forename><surname>Buluç</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd IEEE Intl. Parallel and Distributed Processing Symp. (Proc. IPDPS)</title>
				<meeting>of the 22nd IEEE Intl. Parallel and Distributed essing Symp. (. IPDPS)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Impulse: Building a smarter memory controller</title>
		<author>
			<persName><forename type="first">John</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilson</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leigh</forename><surname>Stoller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Brunvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Chi</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravindra</forename><surname>Kuramkote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lambert</forename><surname>Schaelicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Tateyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-5)</title>
				<meeting>of the 5th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-5)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">PARTIES: QoS-Aware Resource Partitioning for Multiple Interactive Services</title>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Delimitrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><forename type="middle">F</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXIV)</title>
				<meeting>of the 24th intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXIV)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Flexible hardware acceleration for instructiongrain program monitoring</title>
		<author>
			<persName><forename type="first">Shimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodoros</forename><surname>Strigkos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijaya</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olatunji</forename><surname>Ruwase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 35th annual Intl. Symp. on Computer Architecture (Proc. ISCA-35)</title>
				<meeting>of the 35th annual Intl. Symp. on Computer Architecture (. ISCA-35)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Leveraging Hardware Transactional Memory for Cache Side-Channel Defenses</title>
		<author>
			<persName><forename type="first">Sanchuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyu</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinqian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 on Asia Conference on Computer and Communications Security</title>
				<meeting>the 2018 on Asia Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory</title>
		<author>
			<persName><forename type="first">Ping</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuangchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jishen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongpan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd annual Intl. Symp. on Computer Architecture (Proc. ISCA-43)</title>
				<meeting>of the 43rd annual Intl. Symp. on Computer Architecture (. ISCA-43)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Chain: Tasks and Channels for Reliable Intermittent Programs</title>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Colin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGPLAN Conf. on Object-Oriented Programming, Systems, Languages, and Applications (Proc. OOPSLA)</title>
				<meeting>of the ACM SIGPLAN Conf. on Object-Oriented Programming, Systems, Languages, and Applications (. OOPSLA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving Real-Time Performance by Using Cache Allocation Technology</title>
	</analytic>
	<monogr>
		<title level="j">Intel Whitepaper</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>Intel corporation</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<title level="m">GPU Computing: To Exascale and Beyond</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Supercomputing &apos;10. Plenary Talk</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Merrimac: Supercomputing with streams</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Labonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>-H Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jayasena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">J</forename><surname>Kapasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gummaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Buck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM/IEEE conf. on Supercomputing (Proc. SC03)</title>
				<meeting>of the ACM/IEEE conf. on Supercomputing (. SC03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Domain-Specific Hardware Accelerators</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatish</forename><surname>Turakhia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1145/3361682</idno>
		<ptr target="https://doi.org/10.1145/3361682" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<date type="published" when="2020-06">2020. June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The University of Florida sparse matrix collection</title>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOMS</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Understanding and Optimizing Asynchronous Low-Precision Stochastic Gradient Descent</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>De Sa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunle</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 44th annual Intl. Symp. on Computer Architecture (Proc. ISCA-44)</title>
				<meeting>of the 44th annual Intl. Symp. on Computer Architecture (. ISCA-44)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unlimited Vector Extension with Data Streaming Support</title>
		<author>
			<persName><forename type="first">Joao</forename><surname>Mario Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuno</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Tomás</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual Intl. Symp. on Computer Architecture (Proc. ISCA-48)</title>
				<meeting>of the 48th annual Intl. Symp. on Computer Architecture (. ISCA-48)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A robust main-memory compression scheme</title>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per</forename><surname>Stenstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 32nd annual Intl. Symp. on Computer Architecture (Proc. ISCA-32</title>
				<meeting>of the 32nd annual Intl. Symp. on Computer Architecture (. ISCA-32</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">KPart: A Hybrid Cache Partitioning-Sharing Technique for Commodity Multicores</title>
		<author>
			<persName><forename type="first">Nosayba</forename><surname>El-Sayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Mukkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshad</forename><surname>Kasture</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaosong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-24)</title>
				<meeting>of the 24th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-24)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dark Silicon and The End of Multicore Scaling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Blem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>St Amant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 38th annual Intl. Symp. on Computer Architecture (Proc. ISCA-38)</title>
				<meeting>of the 38th annual Intl. Symp. on Computer Architecture (. ISCA-38)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Coherence domain restriction on large scale systems</title>
		<author>
			<persName><forename type="first">Yaosheng</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wentzlaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-48)</title>
				<meeting>of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-48)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Scaling Datacenter Accelerators With Compute-Reuse Architectures</title>
		<author>
			<persName><forename type="first">Adi</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wentzlaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th annual Intl. Symp. on Computer Architecture (Proc. ISCA-45)</title>
				<meeting>of the 45th annual Intl. Symp. on Computer Architecture (. ISCA-45)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Practical near-data processing for in-memory analytics frameworks</title>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th Intl. Conf. on Parallel Architectures and Compilation Techniques (Proc. PACT-24)</title>
				<meeting>of the 24th Intl. Conf. on Parallel Architectures and Compilation Techniques (. PACT-24)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">HRL: Efficient and flexible reconfigurable logic for near-data processing</title>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-22)</title>
				<meeting>of the 22nd IEEE intl. symp. on High Performance Computer Architecture (. HPCA-22)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Snafu: An Ultra-Low-Power, Energy-Minimal CGRA-Generation Framework and Architecture</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Gobieski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Oguz Atli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual Intl. Symp. on Computer Architecture (Proc. ISCA-48)</title>
				<meeting>of the 48th annual Intl. Symp. on Computer Architecture (. ISCA-48)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Processing in memory: The Terasys massively parallel PIM array</title>
		<author>
			<persName><forename type="first">Maya</forename><surname>Gokhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Iobst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1995">1995. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">PipeRench: A coprocessor for streaming multimedia acceleration</title>
		<author>
			<persName><forename type="first">Herman</forename><surname>Seth Copen Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Schmit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srihari</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reed</forename><surname>Cadambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><surname>Laufer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th annual Intl. Symp. on Computer Architecture (Proc. ISCA-26)</title>
				<meeting>of the 26th annual Intl. Symp. on Computer Architecture (. ISCA-26)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Strong and Efficient Cache Side-Channel Protection Using Hardware Transactional Memory</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Lettner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Ohrimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Istvan</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th USENIX Conference on Security Symposium</title>
				<meeting>the 26th USENIX Conference on Security Symposium</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A Memory Encryption Engine Suitable for General Purpose Processors</title>
		<author>
			<persName><forename type="first">Shay</forename><surname>Gueron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IACR Cryptol. ePrint Arch</title>
		<imprint>
			<biblScope unit="page">204</biblScope>
			<date type="published" when="2016">2016. 2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cache games-Bringing access-based cache attacks on AES to practice</title>
		<author>
			<persName><forename type="first">David</forename><surname>Gullasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Endre</forename><surname>Bangerter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Krenn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Symposium on Security and Privacy</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Reducing memory and traffic requirements for scalable directory-based cache coherence schemes</title>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolf-Dietrich</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scalable shared memory multiprocessors</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="167" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">EIE: Efficient Inference Engine on Compressed Deep Neural Network</title>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huizi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ardavan</forename><surname>Pdream</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd annual Intl. Symp. on Computer Architecture (Proc. ISCA-43)</title>
				<meeting>of the 43rd annual Intl. Symp. on Computer Architecture (. ISCA-43)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Accelerating dependent cache misses with an enhanced memory controller</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eiman</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd annual Intl. Symp. on Computer Architecture (Proc. ISCA-43)</title>
				<meeting>of the 43rd annual Intl. Symp. on Computer Architecture (. ISCA-43)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">How secure is your cache against sidechannel attacks?</title>
		<author>
			<persName><forename type="first">Zecheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-50)</title>
				<meeting>of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-50)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A New Golden Age for Computer Architecture: Domain-Specific Hardware/Software Co-Design, Enhanced Security, Open Instruction Sets, and Agile Chip Development</title>
		<author>
			<persName><forename type="first">John</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Turing Award Lecture</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Accelerating linked-list traversal through near-data processing</title>
		<author>
			<persName><forename type="first">Byungchul</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gwangsun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongkee</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th Intl. Conf. on Parallel Architectures and Compilation Techniques (Proc. PACT-25)</title>
				<meeting>of the 25th Intl. Conf. on Parallel Architectures and Compilation Techniques (. PACT-25)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Computing&apos;s energy problem (and what we can do about it)</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ISSCC</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Informing memory operations: Providing memory performance feedback in modern processors</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Transparent Offloading and Mapping (TOM): Enabling Programmer-Transparent Near-Data Processing in GPU Systems</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eiman</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gwangsun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niladrish</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Mike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nandita</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Vijaykumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">W</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><surname>Keckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd annual Intl. Symp. on Computer Architecture (Proc. ISCA-43)</title>
				<meeting>of the 43rd annual Intl. Symp. on Computer Architecture (. ISCA-43)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Accelerating pointer chasing in 3D-stacked memory: Challenges, mechanisms, evaluation</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nandita</forename><surname>Vijaykumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Boroumand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saugata</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 34th Intl. Conf. on Computer Design (Proc. ICCD)</title>
				<meeting>of the 34th Intl. Conf. on Computer Design (. ICCD)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Elastic cgras</title>
		<author>
			<persName><forename type="first">Yuanjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Ienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Temam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyong</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/SIGDA international symposium on Field programmable gate arrays (FPGA)</title>
				<meeting>the ACM/SIGDA international symposium on Field programmable gate arrays (FPGA)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title/>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intel Optane Persistent Memory</title>
		<imprint>
			<date type="published" when="0200">2020. 200</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">S$A: A shared cache attack that works across cores and defies VM sandboxing-and its application to AES</title>
		<author>
			<persName><forename type="first">Gorka</forename><surname>Irazoqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Eisenbarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berk</forename><surname>Sunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Symposium on Security and Privacy</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)</title>
		<author>
			<persName><forename type="first">Aamer</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">C</forename><surname>Steely</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 37th annual Intl. Symp. on Computer Architecture</title>
				<meeting>of the 37th annual Intl. Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A scalable architecture for ordered parallelism</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvinay</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-48)</title>
				<meeting>of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-48)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">FlexRAM: Towards an intelligent memory system</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seung-Moon</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Keen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenzhou</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinh</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratap</forename><surname>Pattnaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 17th Intl. Conf. on Computer Design (Proc. ICCD)</title>
				<meeting>of the 17th Intl. Conf. on Computer Design (. ICCD)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">AMD Memory Encryption</title>
		<author>
			<persName><forename type="first">David</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Woller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>AMD</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Ubik: Efficient Cache Sharing with Strict QoS for Latency-Critical Workloads</title>
		<author>
			<persName><forename type="first">Harshad</forename><surname>Kasture</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 19th intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XIX)</title>
				<meeting>of the 19th intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XIX)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Tvarak: softwaremanaged hardware offload for redundancy in direct-access NVM storage</title>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Kateja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 47th annual Intl. Symp. on Computer Architecture (Proc. ISCA-47)</title>
				<meeting>of the 47th annual Intl. Symp. on Computer Architecture (. ISCA-47)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A highresolution side-channel attack on last-level cache</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kayaalp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ponomarev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Abu-Ghazaleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<idno type="DOI">10.1145/2897937.2897962</idno>
		<ptr target="https://doi.org/10.1145/2897937.2897962" />
	</analytic>
	<monogr>
		<title level="m">53nd ACM/EDAC/IEEE Design Automation Conference (DAC)</title>
				<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Imagine: media processing with streams</title>
		<author>
			<persName><forename type="first">B</forename><surname>Khailany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">J</forename><surname>Kapasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mattson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Towles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rixner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Optimizing indirect memory references with milk</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Kiriansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th Intl. Conf. on Parallel Architectures and Compilation Techniques (Proc. PACT-25)</title>
				<meeting>of the 25th Intl. Conf. on Parallel Architectures and Compilation Techniques (. PACT-25)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">EXECUBE-A new architecture for scaleable MPPs</title>
		<author>
			<persName><surname>Peter M Kogge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the intl conf. on Parallel Processing (ICPP)</title>
				<meeting>of the intl conf. on Parallel essing (ICPP)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Scalable processors in the billion-transistor era</title>
		<author>
			<persName><forename type="first">Stylianos</forename><surname>Christoforos E Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Perissakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Cardwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Golbus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><surname>Gribstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randi</forename><surname>Keeton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Treuhaft</surname></persName>
		</author>
		<author>
			<persName><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRAM. Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The Stanford FLASH multiprocessor</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Kuskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ofelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Heinlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Simoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Chapin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Nakahira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Baxter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mendel</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st annual Intl. Symp. on Computer Architecture (Proc. ISCA-21)</title>
				<meeting>of the 21st annual Intl. Symp. on Computer Architecture (. ISCA-21)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Coordinated and Efficient Huge Page Management with Ingens</title>
		<author>
			<persName><forename type="first">Youngjin</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hangchen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmett</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th USENIX symp. on Operating Systems Design and Implementation (Proc. OSDI-12)</title>
				<meeting>of the 12th USENIX symp. on Operating Systems Design and Implementation (. OSDI-12)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">BSSync: Processing near memory for machine learning workloads with bounded staleness consistency models</title>
		<author>
			<persName><forename type="first">Jaewoong</forename><surname>Joo Hwan Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyesoon</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th Intl. Conf. on Parallel Architectures and Compilation Techniques (Proc. PACT-24)</title>
				<meeting>of the 24th Intl. Conf. on Parallel Architectures and Compilation Techniques (. PACT-24)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">There&apos;s plenty of room at the Top: What will drive computer performance after Moore&apos;s law?</title>
		<author>
			<persName><surname>Charles E Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Neil C Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><forename type="middle">C</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Butler W Lampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><forename type="middle">B</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><surname>Schardl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">368</biblScope>
			<biblScope unit="page">6495</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">The directory-based cache coherence protocol for the DASH multiprocessor</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lenoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Laudon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hennessy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Statistical properties of community structure in large social and information networks</title>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirban</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the intl</title>
				<meeting>of the intl</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>World Wide Web conf. (WWW-17</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Cache Attack on AES for Android Smartphone</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Cryptography, Security and Privacy</title>
				<meeting>the 2nd International Conference on Cryptography, Security and Privacy</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Pinatubo: A processing-in-memory architecture for bulk bitwise operations in emerging non-volatile memories</title>
		<author>
			<persName><forename type="first">Shuangchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaosha</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jishen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Design Automation Conference</title>
				<meeting>the 53rd Annual Design Automation Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">173</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Lastlevel cache side-channel attacks are practical</title>
		<author>
			<persName><forename type="first">Fangfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gernot</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Symposium on Security and Privacy</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Heracles: improving resource efficiency at scale</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rama</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 42nd annual Intl. Symp. on Computer Architecture (Proc. ISCA-42)</title>
				<meeting>of the 42nd annual Intl. Symp. on Computer Architecture (. ISCA-42)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Livia: Data-centric computing throughout the memory hierarchy</title>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Lockerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Axel</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandru</forename><surname>Stanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashwat</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXV)</title>
				<meeting>of the 25th intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXV)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A Simpler, Safer Programming and Execution Model for Intermittent Systems</title>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Ransford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGPLAN Conf. on Programming Language Design and Implementation (Proc. PLDI)</title>
				<meeting>of the ACM SIGPLAN Conf. on Programming Language Design and Implementation (. PLDI)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A Hardware Accelerator for Tracing Garbage Collection</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krste</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Kubiatowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th annual Intl. Symp. on Computer Architecture (Proc. ISCA-45)</title>
				<meeting>of the 45th annual Intl. Symp. on Computer Architecture (. ISCA-45)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Alpaca: Intermittent Execution without Checkpoints</title>
		<author>
			<persName><forename type="first">Kiwan</forename><surname>Maeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Colin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGPLAN Conf. on Object-Oriented Programming, Systems, Languages, and Applications (Proc. OOPSLA)</title>
				<meeting>of the ACM SIGPLAN Conf. on Object-Oriented Programming, Systems, Languages, and Applications (. OOPSLA)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Adaptive Dynamic Checkpointing for Safe Efficient Intermittent Computing</title>
		<author>
			<persName><forename type="first">Kiwan</forename><surname>Maeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3291168.3291178" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the 12th USENIX Conference on Operating Systems Design and Implementation (OSDI&apos;18)</title>
				<meeting>of the 12th USENIX Conference on Operating Systems Design and Implementation (OSDI&apos;18)<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Why on-chip cache coherence is here to stay</title>
		<author>
			<persName><forename type="first">Milo</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Sorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">DoppelgäNger: A Cache for Approximate Computing</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>San</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Albericio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><forename type="middle">Enright</forename><surname>Jerger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-48)</title>
				<meeting>of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-48)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">The anytime automaton</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>San</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><forename type="middle">Enright</forename><surname>Jerger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd annual Intl. Symp. on Computer Architecture (Proc. ISCA-43)</title>
				<meeting>of the 43rd annual Intl. Symp. on Computer Architecture (. ISCA-43)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">LogTM: log-based transactional memory</title>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayaram</forename><surname>Bobba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelle</forename><forename type="middle">J</forename><surname>Moravan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HPCA</title>
				<meeting>HPCA</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Exploiting Locality in Graph Analytics through Hardware-Accelerated Traversal Scheduling</title>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Mukkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maleen</forename><surname>Abeydeera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaosong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-51)</title>
				<meeting>of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-51)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Whirlpool: Improving dynamic cache management with static data classification</title>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Mukkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXI)</title>
				<meeting>of the 21st intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXI)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Cache-Guided Scheduling: Exploiting Caches to Maximize Locality in Graph Processing</title>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Mukkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st International Workshop on Architectures for Graph Processing</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>held in conjuntion with ISCA-44</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">PHI: Architectural Support for Synchronization-and Bandwidth-Efficient Commutative Scatter Updates</title>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Mukkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 52nd annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-52)</title>
				<meeting>of the 52nd annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-52)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Run-time detection of prime+ probe side-channel attack on AES encryption algorithm</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Mushtaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayaz</forename><surname>Akram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><forename type="middle">Khurram</forename><surname>Bhatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Global Information Infrastructure and Networking Symposium</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<publisher>GIIS</publisher>
		</imprint>
	</monogr>
	<note>Rao Naveed Bin Rais, Vianney Lapotre, and Guy Gogniat</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Fifer: Practical Acceleration of Irregular Applications on Reconfigurable Architectures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 54th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-54)</title>
				<meeting>of the 54th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-54)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">The Jmachine multicomputer: an architectural evaluation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Noakes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 20th annual Intl. Symp. on Computer Architecture</title>
				<meeting>of the 20th annual Intl. Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Stream-dataflow acceleration</title>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinay</forename><surname>Gangadhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newsha</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Sankaralingam</surname></persName>
		</author>
		<idno>ISCA 44</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">IRONHIDE:A Secure Multicore that Efficiently Mitigates Microarchitecture State Attacks for Interactive Applications</title>
		<author>
			<persName><forename type="first">Hamza</forename><surname>Omar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-26)</title>
				<meeting>of the 26th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-26)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Active Pages: A Model of Computation for Intelligent Memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Oskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th annual Intl. Symp. on Computer Architecture (Proc. ISCA-25)</title>
				<meeting>of the 25th annual Intl. Symp. on Computer Architecture (. ISCA-25)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Cache attacks and countermeasures: the case of AES</title>
		<author>
			<persName><forename type="first">Arne</forename><surname>Dag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adi</forename><surname>Osvik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><surname>Tromer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cryptographers&apos; Track at the RSA Conference</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Triggered instructions: A control paradigm for spatially-programmed architectures</title>
		<author>
			<persName><forename type="first">Angshuman</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bushra</forename><surname>Ahsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><surname>Crago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Gambhir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aamer</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randy</forename><surname>Allmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachid</forename><surname>Rayess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Maresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 40th annual Intl. Symp. on Computer Architecture (Proc. ISCA-40)</title>
				<meeting>of the 40th annual Intl. Symp. on Computer Architecture (. ISCA-40)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A case for intelligent RAM</title>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><surname>Cardwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><surname>Keeton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoforos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randi</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE micro</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="34" to="44" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Opportunistic computing in gpu architectures</title>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Pattnaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xulong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Kayiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adwait</forename><surname>Jog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asit</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Mahmut T Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chita R</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th annual Intl. Symp. on Computer Architecture (Proc. ISCA-46)</title>
				<meeting>of the 46th annual Intl. Symp. on Computer Architecture (. ISCA-46)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Linearly compressed pages: a low-complexity, low-latency main memory compression framework</title>
		<author>
			<persName><forename type="first">Gennady</forename><surname>Pekhimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoongu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-46)</title>
				<meeting>of the 46th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-46)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Base-delta-immediate compression: Practical data compression for on-chip caches</title>
		<author>
			<persName><forename type="first">Gennady</forename><surname>Pekhimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st Intl. Conf. on Parallel Architectures and Compilation Techniques (Proc. PACT-21)</title>
				<meeting>of the 21st Intl. Conf. on Parallel Architectures and Compilation Techniques (. PACT-21)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Optimus prime: Accelerating data transformation in servers</title>
		<author>
			<persName><forename type="first">Arash</forename><surname>Pourhabibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hussein</forename><surname>Kassir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zilu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><forename type="middle">Paulo</forename><surname>Drumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXV)</title>
				<meeting>of the 25th intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXV)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">NDC: Analyzing the Impact of 3D-Stacked Memory + Logic Devices on MapReduce Workloads</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Seth H Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huihui</forename><surname>Jestes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijayalakshmi</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Intl. Symp. on Performance Analysis of Systems and Software (ISPASS)</title>
				<meeting>of the IEEE Intl. Symp. on Performance Analysis of Systems and Software (ISPASS)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Utility-based cache partitioning: A lowoverhead, high-performance, runtime mechanism to partition shared caches</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 39th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-39)</title>
				<meeting>of the 39th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-39)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">CEASER: Mitigating conflict-based cache attacks via encrypted-address and remapping</title>
		<author>
			<persName><forename type="first">K</forename><surname>Moinuddin</surname></persName>
		</author>
		<author>
			<persName><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-51)</title>
				<meeting>of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-51)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">New attacks and defense for encrypted-address cache</title>
		<author>
			<persName><forename type="first">K</forename><surname>Moinuddin</surname></persName>
		</author>
		<author>
			<persName><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th annual Intl. Symp. on Computer Architecture (Proc. ISCA-46)</title>
				<meeting>of the 46th annual Intl. Symp. on Computer Architecture (. ISCA-46)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Tempest and Typhoon: User-level shared memory</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Steven K Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st annual Intl. Symp. on Computer Architecture (Proc. ISCA-21)</title>
				<meeting>of the 21st annual Intl. Symp. on Computer Architecture (. ISCA-21)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Pipelining a triggered processing element</title>
		<author>
			<persName><surname>Thomas J Repetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><forename type="middle">A</forename><surname>João P Cerqueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Seok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-50)</title>
				<meeting>of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-50)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Morphable counters: Enabling compact integrity trees for low-overhead secure memories</title>
		<author>
			<persName><forename type="first">Gururaj</forename><surname>Saileshwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Prashant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakash</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Ramrakhyani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">A</forename><surname>Elsasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moinuddin K</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-51)</title>
				<meeting>of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-51)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">The ZCache: Decoupling Ways and Associativity</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 43rd intl. symp. on Microarchitecture</title>
				<meeting>of the 43rd intl. symp. on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Vantage: Scalable and Efficient Fine-Grain Cache Partitioning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 38th annual Intl. Symp. on Computer Architecture</title>
				<meeting>of the 38th annual Intl. Symp. on Computer Architecture</meeting>
		<imprint>
			<publisher>Proc</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Decoupled compressed cache: exploiting spatial locality for energy-optimized compressed caching</title>
		<author>
			<persName><forename type="first">Somayeh</forename><surname>Sardashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-46)</title>
				<meeting>of the 46th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-46)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">The Role of Edge Offload for Hardware-Accelerated Mobile Devices</title>
		<author>
			<persName><forename type="first">Mahadev</forename><surname>Satyanarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Lucia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HotMobile</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Jumanji: The Case for Dynamic NUCA in the Datacenter</title>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">C</forename><surname>Schwedock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 53rd annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-53)</title>
				<meeting>of the 53rd annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-53)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A case for two-way skewed-associative caches</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 20th annual Intl. Symp. on Computer Architecture</title>
				<meeting>of the 20th annual Intl. Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Decoupled sectored caches: conciliating low tag implementation cost</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st annual Intl. Symp. on Computer Architecture (Proc. ISCA-21)</title>
				<meeting>of the 21st annual Intl. Symp. on Computer Architecture (. ISCA-21)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Smart memories polymorphic chip multiprocessor</title>
		<author>
			<persName><forename type="first">Ofer</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zain</forename><surname>Asgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Firoozshahian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rehan</forename><surname>Hameed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wajahat</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Solomatnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Wachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th Design Automation Conf. (Proc. DAC-46)</title>
				<meeting>of the 46th Design Automation Conf. (. DAC-46)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Shafiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirban</forename><surname>Nag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Muralimanohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Paul Strachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanley</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Micro-architectural cache side-channel attacks and countermeasures</title>
		<author>
			<persName><forename type="first">Chaoqun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congcong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC)</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Chasing away rats: Semantics and evaluation for relaxed atomics on heterogeneous systems</title>
		<author>
			<persName><forename type="first">Johnathan</forename><surname>Matthew D Sinclair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarita</forename><forename type="middle">V</forename><surname>Alsop</surname></persName>
		</author>
		<author>
			<persName><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 44th annual Intl. Symp. on Computer Architecture (Proc. ISCA-44)</title>
				<meeting>of the 44th annual Intl. Symp. on Computer Architecture (. ISCA-44)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Pageforge: a near-memory content-aware page-merging architecture</title>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Skarlatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename><forename type="middle">Sung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-50)</title>
				<meeting>of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-50)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">GraphR: Accelerating graph processing using ReRAM</title>
		<author>
			<persName><forename type="first">Linghao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youwei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-24)</title>
				<meeting>of the 24th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-24)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Cache automaton</title>
		<author>
			<persName><forename type="first">Arun</forename><surname>Subramaniyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingcheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ezhil Rm Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Blaauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reetuparna</forename><surname>Sylvester</surname></persName>
		</author>
		<author>
			<persName><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-50)</title>
				<meeting>of the 50th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-50)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Andrew Schwerin, and Mark Oskin. 2003. WaveScalar</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Michelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 36th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-36)</title>
				<meeting>of the 36th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-36)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Prodigy: Improving the Memory Latency of Data-Indirect Irregular Workloads Using Hardware-Software Co-Design</title>
		<author>
			<persName><forename type="first">Nishil</forename><surname>Talati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Behroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuba</forename><surname>Kaszyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Vasiladiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarunesh</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawen</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-27)</title>
				<meeting>of the 27th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-27)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Ultra-Elastic CGRAs for Irregular Loop Specialization</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Torng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peitian</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghui</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Batten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-27)</title>
				<meeting>of the 27th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-27)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Jenga: Software-Defined Cache Hierarchies</title>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 44th annual Intl. Symp. on Computer Architecture (Proc. ISCA-44)</title>
				<meeting>of the 44th annual Intl. Symp. on Computer Architecture (. ISCA-44)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Adaptive Scheduling for Systems with Asymmetric Memory Hierarchies</title>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changping</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-51)</title>
				<meeting>of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-51)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Rethinking the Memory Hierarchy for Modern Languages</title>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Ling</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-51)</title>
				<meeting>of the 51st annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-51)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Compress objects, not cache lines: An object-based compressed memory hierarchy</title>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXIV)</title>
				<meeting>of the 24th intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXIV)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">A case for richer cross-layer abstractions: Bridging the semantic gap with expressive memory</title>
		<author>
			<persName><forename type="first">Nandita</forename><surname>Vijaykumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhilasha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diptesh</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gennady</forename><surname>Pekhimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eiman</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nastaran</forename><surname>Hajinazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th annual Intl. Symp. on Computer Architecture (Proc. ISCA-45)</title>
				<meeting>of the 45th annual Intl. Symp. on Computer Architecture (. ISCA-45)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Single-graph multiple flows: Energy efficient design alternative for GPGPUs</title>
		<author>
			<persName><forename type="first">Dani</forename><surname>Voitsechov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Etsion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Baring it all to software: Raw machines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Waingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srikrishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Babb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Stream-based memory access specialization for general purpose processors</title>
		<author>
			<persName><forename type="first">Zhengrong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 46th annual Intl. Symp. on Computer Architecture (Proc. ISCA-46)</title>
				<meeting>of the 46th annual Intl. Symp. on Computer Architecture (. ISCA-46)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Near-Stream Computing: General and Transparent Near-Cache Acceleration</title>
		<author>
			<persName><forename type="first">Zhengrong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Stream Floating: Enabling Proactive and Decentralized Cache Optimizations</title>
		<author>
			<persName><forename type="first">Zhengrong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Lowe-Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayesh</forename><surname>Gaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-27)</title>
				<meeting>of the 27th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-27)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">A hybrid systolic-dataflow architecture for inductive matrix algorithms</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sihao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengrong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vidushi</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Nowatzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-26)</title>
				<meeting>of the 26th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-26)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File System</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirsaman</forename><surname>Memaripour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshatha</forename><surname>Gangadharaiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Borase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamires</forename><surname>Brito Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><surname>Rudoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th Symp. on Operating System Principles (Proc. SOSP-26)</title>
				<meeting>of the 26th Symp. on Operating System Principles (. SOSP-26)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Secure hierarchy-aware cache replacement policy (SHARP): Defending against cache-based side channel attacks</title>
		<author>
			<persName><forename type="first">Mengjia</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhargava</forename><surname>Gopireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Shull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 44th annual Intl. Symp. on Computer Architecture (Proc. ISCA-44)</title>
				<meeting>of the 44th annual Intl. Symp. on Computer Architecture (. ISCA-44)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">SpZip: Architectural Support for Effective Data Compression In Irregular Applications</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual Intl. Symp. on Computer Architecture (Proc. ISCA-48)</title>
				<meeting>of the 48th annual Intl. Symp. on Computer Architecture (. ISCA-48)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Preventing and Detecting Cache Side-Channel Attacks in Cloud Computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Younis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Younis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abir</forename><surname>Kifayat</surname></persName>
		</author>
		<author>
			<persName><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing</title>
				<meeting>the Second International Conference on Internet of Things, Data and Cloud Computing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">TOP-PIM: Throughputoriented Programmable Processing in Memory</title>
		<author>
			<persName><forename type="first">Dongping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuwan</forename><surname>Jayasena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lyashevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Greathouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ignatowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HPDC</title>
				<meeting>HPDC</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Worklist-directed Prefetching</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Minnow: Lightweight Offload Engines for Worklist Management and Worklist-Directed Prefetching</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 23rd intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXIII)</title>
				<meeting>of the 23rd intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXIII)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Exploiting Semantic Commutativity in Hardware Speculation</title>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 49th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-49)</title>
				<meeting>of the 49th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-49)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Exploiting commutativity to reduce the cost of updates to shared data in cache-coherent systems</title>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Webb</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (Proc. MICRO-48)</title>
				<meeting>of the 48th annual IEEE/ACM intl. symp. on Microarchitecture (. MICRO-48)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Leveraging Hardware Caches for Memoization</title>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Architecture Letters (CAL)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Leveraging caches to accelerate hash tables and memoization</title>
		<author>
			<persName><forename type="first">Guowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="440" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Software-Defined Address Mapping: A Case on 3D Memory</title>
		<author>
			<persName><forename type="first">Jialiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing (jane)</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 27th intl. conf. on Architectural Support for Programming Languages and Operating Systems (Proc. ASPLOS-XXVII)</title>
				<meeting>of the 27th intl. conf. on Architectural Support for Programming Languages and Operating Systems (. ASPLOS-XXVII)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Pangolin: A Fault-Tolerant Persistent Memory Programming Library</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the USENIX Annual Technical Conf. (Proc. USENIX ATC)</title>
				<meeting>of the USENIX Annual Technical Conf. (. USENIX ATC)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">GraphP: Reducing communication for PIM-based graph processing with efficient data partition</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youwei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th IEEE intl. symp. on High Performance Computer Architecture (Proc. HPCA-24)</title>
				<meeting>of the 24th IEEE intl. symp. on High Performance Computer Architecture (. HPCA-24)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
