<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Survey of Compiler Testing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
							<email>junjiechen@tju.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Jibesh</forename><surname>Patra</surname></persName>
							<email>jibesh.patra@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Pradel</surname></persName>
							<email>michael@binaervarianz.de</email>
						</author>
						<author>
							<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
							<email>xiongyf@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
							<email>hongyu.zhang@newcastle.edu.au.</email>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
							<email>haodan@pku.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Lu</forename><forename type="middle">U</forename><surname>Zhang</surname></persName>
							<email>zhanglucs@pku.edu.cn</email>
						</author>
						<author>
							<persName><surname>De-</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Intelligence and Computing</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Key Laboratory of High Confidence Software Technologies (Peking University)</orgName>
								<address>
									<settlement>MoE</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Electrical Engineering and Computing</orgName>
								<orgName type="institution">University of Newcastle</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">Key Laboratory of High Confidence Software Technologies (Peking University)</orgName>
								<address>
									<settlement>MoE</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">College of Intelligence and Computing</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300350</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<postCode>70569</postCode>
									<settlement>Stuttgart</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="department">partment of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">School of Electrical Engineering and Computing</orgName>
								<orgName type="institution" key="instit1">University of Newcastle</orgName>
								<orgName type="institution" key="instit2">NSW</orgName>
								<address>
									<postCode>2308</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Survey of Compiler Testing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">31E01BB38E346E67F02EE8B7D958CCA3</idno>
					<idno type="DOI">10.1145/3363562</idno>
					<note type="submission">Received August 2018; revised May 2019; accepted September 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Compiler testing</term>
					<term>test program generation</term>
					<term>test oracle</term>
					<term>test optimization</term>
					<term>compiler debugging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Virtually any software running on a computer has been processed by a compiler or a compiler-like tool.</p><p>Because compilers are such a crucial piece of infrastructure for building software, their correctness is of paramount importance. To validate and increase the correctness of compilers, significant research efforts have been devoted to testing compilers. This survey article provides a comprehensive summary of the current state-of-the-art of research on compiler testing. The survey covers different aspects of the compiler testing problem, including how to construct test programs, what test oracles to use for determining whether a compiler behaves correctly, how to execute compiler tests efficiently, and how to help compiler developers take action on bugs discovered by compiler testing. Moreover, we survey work that empirically studies the strengths and weaknesses of current compiler testing research and practice. Based on the discussion of existing work, we outline several open challenges that remain to be addressed in future work.</p><p>CCS Concepts: • Software and its engineering → Compilers; Software testing and debugging; Maintaining software;</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Compilers are important tools, because they are a central piece of infrastructure for building other software. Virtually every program that runs on a computer, ranging from operating systems over web browsers to small scripts written by end-users, has been processed by a compiler or a compilerlike tool. Because compilers are such a central piece of infrastructure, they are very widely distributed. For example, popular compilers of widespread programming languages, such as GCC for C/C++, are run by millions of users. Beyond these direct users of compilers, typically developers, much more people indirectly rely on compilers when executing compiled programs.</p><p>Even though considerable efforts have been made to improve the quality of compilers, similar to all other software, compilers still contain bugs <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b122">123]</ref>. A compiler bug can cause incorrect binary code to be generated from correct source code. Also, a single bug in a production compiler can propagate to any application built upon it and cause surprising and possibly harmful misbehavior. For example, a miscompilation bug in the Java 7 implementation caused several popular Apache projects to crash. <ref type="foot" target="#foot_0">1</ref> Sometimes, compiler bugs may even be injected on purpose to compromise the security of compiled applications. For example, a malicious variant of Apple's Xcode development environment contained a compiler "bug" that introduces a backdoor into every compiled application. <ref type="foot" target="#foot_1">2</ref> Such compiler backdoors can also exploit accidentally introduced bugs, as evidenced by work on compromising the Unix sudo tool via a publicly known bug in LLVM <ref type="bibr" target="#b104">[105]</ref>.</p><p>Compiler bugs not only cause unintended behavior with possibly severe consequences, but also make software debugging more difficult. The reason is that developers can hardly determine whether a software failure is caused by the program they are developing or the compilers they are using <ref type="bibr" target="#b25">[26]</ref>. For example, when a buggy compiler optimizes a correct program into an executable that has incorrect runtime behavior, it is unclear to the developer of the program what causes the unexpected behavior. Since application developers usually assume the misbehavior tends to be caused by bugs introduced by themselves, they may spend a long time to eventually realize that a compiler bug is the root cause.</p><p>Given the importance of compilers, there is a huge interest in implementing them correctly. However, reaching this goal is non-trivial, since compilers are complex pieces of software. A typical compiler consists of a pipeline of interacting components that address, e.g., the lexical analysis of the source language, parsing the source language into an intermediate representation, applying semantic checks, optimizing the code, and generating code in the target language. Currently, the optimization phase and implementation of parallelism and object-oriented features make it more complex. Because of this complexity, traditional computer science curricula typically dedicate at least one entire course to the art of constructing compilers. In contrast to other complex software, the domain that compilers deal with is particularly rich. Both the input and the output of compilers usually are programs written in Turing-complete languages. Moreover, both the inputs and output domains are infinitely large, since programs can be arbitrarily long. As a result, reasoning about the behavior of a compiler is all but trivial.</p><p>The difficulties of correctly implementing a compiler lead to several challenges for testing the implementation. One challenge is the lack of a formal specification of what exactly a compiler is supposed to do. While the high-level specification is implicitly known-compilers translate a source program into a target program in a semantics-preserving way-the lower level details are usually unspecified. For instance, when to apply what optimizations is rarely specified, making it difficult to check whether a compiler applies all desired optimizations. As an example, the LLVM A Survey of Compiler Testing 4:3 compiler has 58 optimizing transformation passes, <ref type="foot" target="#foot_2">3</ref> which can be combined in various ways, but no specification exists when to apply which of these passes.</p><p>Another challenge for testing is the semantic richness of the input and output languages that compilers deal with. Because source code can express a wide range of computations, including many computations that cause the program to crash early, automatically creating source code with non-trivial behavior is difficult. However, such non-trivial programs are often required to reach deep into the pipelined workflow of a compiler and to test hard-to-reach code. For example, an input program must pass all sanity checks and type checks in the lexer and parser before it can test optimizations performed by the compiler. However, a non-compiler program often does not have such complex checks. A related challenge is that small changes in the input can cause huge differences in the expected behavior. For example, changing a single character in an input program may cause the compiler to take a completely different path and to expose completely different behaviors.</p><p>A third important challenge is that compilers have various options and features. For example, most compilers offer different optimization levels, support several variants of the source language, and consider multiple target platforms. This multitude of configurations creates a large space that is difficult to explore exhaustively and orthogonal to the regular input space.</p><p>In addition to these challenges, compilers fortunately also have some properties that simplify the problem of validating their correctness. One such property is that the inputs to compilers are written in a programming language, i.e., the space of possible inputs is clearly defined by the language grammar. In contrast, general-purpose fuzzing tools, such as AFL, <ref type="foot" target="#foot_3">4</ref> may not have a grammar to help control the generation of syntactically valid inputs. Another property that eases compiler testing is that the semantics of the source language are usually specified, either informally in a language specification or formally, e.g., for a core of the programming language. As a result, the expected behavior of (most) programs and thereby also of the compiler output, is known when running the program. Finally, compiler testing benefits from the fact that for most popular programming languages, there are multiple supposedly equivalent implementations, which compiler testing can exploit as an oracle for differential testing <ref type="bibr" target="#b80">[81]</ref> (discussed in detail in <ref type="bibr">Section 4)</ref>.</p><p>Motivated both by the importance of compilers and by the interesting challenges involved in improving their reliability and correctness, the area has received significant attention from researchers and practitioners. A particularly successful line of work is compiler testing, which has made tremendous advances in recent years. Several widely adopted tools and approaches have been developed in the past decade, some of which found hundreds of bugs in production compilers of popular languages <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b122">123]</ref>.</p><p>The impressive progress made in compiler testing is good news for developers and users of compilers. However, the huge amount of existing work makes it difficult for interested non-experts to understand the state-of-the-art and how to improve upon it. This article summarizes existing work and provides a retrospection of the compiler testing field after years of development. The readers can thus have an in-depth understanding of the advantages and limitations of the existing approaches. Our findings can help researchers and practitioners understand more about the implications of the existing compiler testing approaches and help prompt their adoption in practice. Based on our analysis, we also point out the current challenges and suggest possible future directions for compiler testing research.</p><p>We present the work on compiler testing from the following six perspectives, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>: • Constructing test programs: Section 3 presents approaches to creating programs that serve as inputs for testing compilers. • Test oracles: Section 4 describes approaches to determine whether the behavior or output of a compiler is correct or not. • Optimizing the test process: Section 5 discusses how to make compiler testing more efficient.</p><p>• Post-processing of test results: Section 6 presents approaches that help developers prioritize and understand bugs detected through compiler testing.</p><p>• Empirical studies: Section 7 discusses empirical studies performed to better understand compiler bugs and the process of compiler testing. • Outlook and challenges for future work: Section 8 presents open challenges that remain to be addressed by future work.</p><p>Orthogonal to the efforts on compiler testing discussed in this article, formally verifying compilers is another attempt towards more reliable compilers. Work on compilers verification <ref type="bibr" target="#b35">[36]</ref> checks whether the implementation of a compiler complies with a formal specification of some correctness properties, such as, to not crash during compilation or to preserve the semantics of the input program in the produced machine code. A particularly noticeable example is the CompCert compiler <ref type="bibr" target="#b75">[76]</ref>, which targets a subset of the C language and which has been formally verified. For this article, we focus on compiler testing and do not cover work on compiler verification in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SURVEY METHODOLOGY</head><p>For this survey, we carefully collect 85 papers from relevant international journals and conferences. To collect these papers, we systematically search the DBLP publication database<ref type="foot" target="#foot_5">5</ref> using the following keywords: "compiler test," "compiler validation," "compiler defect," "compiler bug," "compiler vulnerabilit(y/ies)," "compiler fault," "compiler error," "compiler issue," and "compiler debug." Then, we manually filter the results by removing irrelevant papers. Finally, we retrieve additional papers by following references in the already found papers.</p><p>A Survey of Compiler Testing 4:5  Figure <ref type="figure" target="#fig_1">2</ref> shows the collected papers from 1970 to 2018. We can see that the number of relevant papers has increased significantly since 2011, indicating that the problem of compiler testing has received significant attention since then. We further analyze the reason behind this phenomenon. One possible reason is that some easy-to-use and effective tools such as Csmith <ref type="bibr" target="#b122">[123]</ref> and C-Reduce <ref type="bibr" target="#b96">[97]</ref> were developed and released around 2011, since nearly 50% papers from 2011 to 2018 are based on these tools. Actually, this is as expected. For example, constructing test programs is one of the most important challenges in compiler testing and is the initial step of the testing process. Csmith makes this step convenient, and thus promotes compiler testing research.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the distribution of papers on each research perspective, including constructing test programs, test oracles, optimizing the test process, post-processing of test results, and empirical studies. If a paper addresses more than one research perspective, then we categorize it based on its most important contribution. Figure <ref type="figure" target="#fig_2">3</ref> shows that, like general software testing, most papers on compiler testing also focus on constructing test programs and test oracles. In particular, constructing test programs attracts most of the attention. This is as expected, because it is the initial step of the testing process (only after test programs are constructed can the testing process be started).</p><p>Furthermore, we are aware of four existing surveys on compiler testing, all of which were published before 2005. Burgess <ref type="bibr" target="#b14">[15]</ref> summarizes the main automatic compiler testing approaches before 1994. Boujarwah and Saleh <ref type="bibr" target="#b12">[13]</ref> assess and compare various compiler test-program construction approaches before 1997. Tonndorf <ref type="bibr" target="#b116">[117]</ref> presents tool-based Ada compiler validations before 1998. <ref type="bibr">Kossatchev and Posypkin [68]</ref> present compiler testing approaches based on formal specifications of the programming language syntax and semantics before 2005. These existing survey Purdom <ref type="bibr" target="#b95">[96]</ref>, Hanford <ref type="bibr" target="#b51">[52]</ref>, Houssais <ref type="bibr" target="#b60">[61]</ref>, Duncan and Hutchison <ref type="bibr" target="#b44">[45]</ref>, Burgess <ref type="bibr" target="#b33">[34]</ref>, Burgess and Saidi <ref type="bibr" target="#b15">[16]</ref>, Bird and Munoz <ref type="bibr" target="#b11">[12]</ref>, Amodio et al. <ref type="bibr" target="#b3">[4]</ref>, Bazzichi and Spadafora <ref type="bibr" target="#b8">[9]</ref>, Zelenov et al. <ref type="bibr" target="#b126">[127]</ref>, Zelenov and Zelenova <ref type="bibr" target="#b125">[126]</ref>, Lindig <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79]</ref> Grammar-aided Approaches (Section 3. papers mainly focus on constructing test programs and do not address other research challenges. Meanwhile, these survey papers were completed 10-20 years ago, which may have limited aids for current research on compiler testing. Therefore, we believe it is necessary to conduct a new survey of the field of compiler testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CONSTRUCTING TEST PROGRAMS</head><p>Testing of any kind of software requires test cases. In the realm of compiler testing, programs form part of the test cases. In this article, we call such programs test programs. Constructing test programs for testing compilers is not trivial. We describe the challenges faced when constructing test programs in Section 3.1.</p><p>Approaches to constructing test programs can be broadly classified into three categories. Table <ref type="table" target="#tab_0">1</ref> gives an overview of the broad classification and also shows how each category can be further divided. Test programs are either manually written or constructed automatically. We explain the manual approaches in Section 3.2. The automated approaches either generate program fragments and concatenate them into test programs, or mutate existing programs. Section 3.3 gives details  <ref type="table" target="#tab_2">2</ref> gives an overview of the programming languages targeted by the various approaches discussed in this section. Overall, the approaches cover a wide range of languages, with C/C++ being the most popular language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Challenges for Constructing Test Programs</head><p>Constructing test programs for testing compilers is challenging. In particular, it is difficult to construct test programs that are valid, diverse, and meet certain requirements for testing.</p><p>Validity of test programs. It is non-trivial to construct valid programs, because of the restrictions some languages have on using certain language constructs only in a certain way or in a certain context. Constructing invalid programs is of limited usefulness for testing compilers, since a program goes through multiple phases of processing by the compiler; if a compiler is presented with an invalid input program, then the program tends to get discarded in the initial stages of the processing. For example, if a constructed JavaScript program contains a return statement that is not inside a function, then the program is considered syntactically invalid. Such a program does not reach the code generation or the optimization phases of a JavaScript engine. In C, for example, generating a program with undefined behavior cannot be considered as a valid test program, since the result is invariably correct. Similarly, for many languages, an identifier must be declared before being used in the program. Constructing a program while maintaining such restrictions is not always straightforward. For typed languages in particular, maintaining type constraints during test program construction is not easy, which often leads to the construction of invalid test programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversity of test programs.</head><p>As with all test inputs, constructed test programs should be diverse. A syntactically diverse set of test programs will exercise different parts of the compiler and potentially increase code coverage of the compiler under test. This can potentially aid in uncovering bugs. In the realm of testing compilers, diversity metrics such as distance between test programs <ref type="bibr" target="#b29">[30]</ref> have been proposed. Although desirable, it is difficult to construct a diverse set of test programs, since an increase in the number of syntactic language constructs can adversely affect the validity of the generated programs. For example, it might be desirable that a set of constructed C test programs contain variables and their corresponding operations using all available types. Unfortunately, it is not very straightforward for a test program constructor to do so. With the use of more features, the constructed test program becomes more prone to be generated as invalid. This is probably the reason many test program generators that we discuss later in Section 3.3 only generate programs using a subset of all available language features. Specific requirements imposed by a testing method. The construction of test programs also becomes difficult when certain testing methods impose restrictions. For example, a common testing method is to compile a program with two compilers and compare the execution results. In such a case, the input program should be free of undefined behavior. However, if we just test for compiler crashes, the input program does not necessarily have to be free of undefined behavior. Constructing test programs that follow these restrictions or conformance in addition to the validity and diversity requirements can be challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Manually Constructing Test Programs</head><p>Manually constructed test programs have been used since the early days of compiler testing. Such test programs can be effective in uncovering bugs, since the programs can be tuned to a particular need and they are often written to test newly implemented features.</p><p>Popular compilers, such as GCC <ref type="bibr" target="#b37">[38]</ref>, compiler infrastructures, such as LLVM <ref type="bibr" target="#b38">[39]</ref>, implementations of the Java platform, such as OpenJDK <ref type="bibr" target="#b39">[40]</ref>, and browsers, such as Chromium <ref type="bibr" target="#b36">[37]</ref>, use extensive manually written test suites to test their implementations. For example, GCC comes with several test suites for both the runtime libraries and the language front-ends. The documentation of OpenJDK,<ref type="foot" target="#foot_7">6</ref> GCC, <ref type="foot" target="#foot_8">7</ref> and Chromium<ref type="foot" target="#foot_9">8</ref> all have guides for developers on how a test case should be written. In addition, there are independently developed conformance test suites, such as the Plum Hall Validation Suite <ref type="bibr" target="#b61">[62]</ref> for C and C++ and Test262 for ECMAScript <ref type="bibr" target="#b45">[46]</ref>.</p><p>Although popular in practice, there has been very limited academic work on manually constructing test programs for testing compilers. One exception is by Callahan et al. <ref type="bibr" target="#b16">[17]</ref>, who describe the manual construction of 100 Fortran loops for testing a vectorizing compiler. Such compilers should be able to determine if a loop can be expressed using hardware-supported vector operations, i.e., if a loop can be vectorized. The primary goal of the test programs manually constructed by Callahan et al. is to check whether the compiler vectorizes vectorizable loops rather than to test the correctness of the generated code. To this end, each of the manually written loop contains some code that can be vectorized by the compiler. When passing these loops to compilers, Callahan et al. find that some compilers miss vectorizable loop statements.</p><p>Another description of manually constructing test programs is by Dongarra et al. <ref type="bibr" target="#b43">[44]</ref>, who collect subroutines and loops that contain parallelism opportunities written by other developers. Additionally, they themselves also manually write programs containing parallelism opportunities. The end goal is to measure if Fortran compilers automatically parallelize the loops.</p><p>Wolf et al. <ref type="bibr" target="#b119">[120]</ref> describe their experience of manually constructing test programs based on a natural language specification of the programming language. Their approach is to study the specification sentence-by-sentence, and to create a test program for every testable requirement given in the specification. Their work targets the Arden language, a domain-specific programming language to describe medical knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Test Program Generation</head><p>Although effective, writing test programs manually needs significant effort. As a result, there have been constant efforts towards designing automatic test program generators for testing compilers. These efforts can be broadly classified into three categories: grammar-directed, grammar-aided, and other approaches. We explain these approaches in the following: 3.3.1 Grammar-directed Approaches. Grammar-directed approaches for test program generation take a language grammar as their input and generate programs based on this grammar. Grammar-directed approaches are the first approaches proposed for automatic test program generation to test compilers. Given the context-free grammar of a language, it is natural to walk over its productions to generate strings of the language. To this end, Purdom <ref type="bibr" target="#b95">[96]</ref> presents an approach to testing the correctness of parsers and grammars based on context-free grammars. The primary focus is to validate parsers that are automatically generated from context-free grammars and to find non-reduced grammars (where the grammar contains symbols that cannot be used for a sentence derivation). The generation starts from a unique start symbol and proceeds by applying left-right rewriting rules from the grammar. The approach uses some heuristics to generate short sentences by recursively going over the grammar. For testing parsers, it is desirable that the generated programs cover different states and transitions of the parser. Purdom evaluates his approach on automatically generated LALR(1) parsers and shows that in many cases, the generated test programs are able to cover multiple states and transitions of the parser.</p><p>Purdom's <ref type="bibr" target="#b95">[96]</ref> test program generation based on context-free grammar faces shortcomings when the objective is to test all parts of a compiler. By only using a context-free grammar, it is difficult to express context-sensitive features of a language. Since the end goal of Purdom is to test parsers that do not expect semantically correct programs, this shortcoming does not affect the approach.</p><p>Approaches that focus on testing harder-to-reach parts of the compiler, instead of only the parser, use different ways to address context sensitivity during test program generation. The initial attempts at generating compilable programs based on language grammars tend to extend the context-free productions with context-sensitive features. The extended grammars form a family of grammars known as two-level grammars and are introduced by Adriaan van Wijngaarden to specify ALGOL 68 <ref type="bibr" target="#b117">[118]</ref>. Generation of test programs for the goal of testing compilers use three particular two-level grammars: W-grammars, attribute grammars, and affix grammars. The following gives a brief introduction of these three variants of two-level grammars and also explains the approaches that use each of them. For a comprehensive description about these three types of grammars, readers are referred to a tutorial by Koster <ref type="bibr" target="#b68">[69]</ref>.</p><p>Affix grammar. Originally invented for linguistic applications <ref type="bibr" target="#b81">[82]</ref>, affix grammars present a way of extending context-free grammars with context-sensitive notions using affixes to the grammar productions. In principle, affix grammars and attribute grammars that we present later only differ in terms of their formal notation <ref type="bibr" target="#b68">[69]</ref>. Both extend the context-free grammar using parameters.</p><p>Inspired by affix grammars, Hanford <ref type="bibr" target="#b51">[52]</ref> proposes an approach that uses an extended contextfree grammar. The extended grammar has rules that have other rules known syntax generators attached to them. A syntax generator effectively acts as a working store. Consider the following simplified example from Reference <ref type="bibr" target="#b51">[52]</ref>:</p><formula xml:id="formula_0">&lt;label declaration&gt; → &lt;declaration identifier&gt;, &lt;label&gt; → &lt;&lt;lambda&gt;&gt;.</formula><p>The first line above is the grammar rule,while the second line is the syntax generator. Informally, these rules mean that whenever an identifier (say, a) is declared, then the syntax generator gets activated and a rule called &lt;label&gt; → a gets added to the context-free grammar. Such addition of rules to the context-free grammar effectively allows programs to be generated with some contextsensitive features, e.g., "use after declaration." For each non-terminal in the grammar, a pseudorandom decision is made to select another non-terminal or a terminal. Hanford implements the approach as a program called syntax machine, which generates syntactically valid test programs for a subset of PL/I. Another approach using affix grammars is presented by Houssais <ref type="bibr" target="#b60">[61]</ref>, who uses these grammars to generate programs that test an ALGOL 68 implementation. This approach restricts the domain of the affixes to integers. The program generator creates fragments of the language and their necessary context by enumerating over each of the productions separately and then the resulting fragments together into the final test programs. Additionally, the approach also has some code appended to the grammar that aids in the generation of syntactically correct programs.</p><p>Attribute grammar. The work by Hanford <ref type="bibr" target="#b51">[52]</ref> presented above provides the basic idea that an extended grammar may be used to generate test programs for testing compilers. Later, Duncan and Hutchison <ref type="bibr" target="#b44">[45]</ref> demonstrate a test program generator using an attributed test grammar.</p><p>Attribute grammars are another way of extending context-free grammars by adding attributes to the grammar rules. Attribute grammars are introduced by Knuth <ref type="bibr" target="#b66">[67]</ref>, who extends context-free grammars to express semantics by appending additional information (attributes) to some of the productions. Knuth's formulation has two types of attributes: synthesized attributes and inherited attributes. When the grammar rules are expressed as parse trees, the values of the synthesized attributes depend on the attribute values of the children, whereas the attribute values of inherited attributes depend on the attribute values of the parents.</p><p>Duncan and Hutchison <ref type="bibr" target="#b44">[45]</ref> present a general test grammar, which serves as a guideline of how and where attributes are to be added to a concrete context-free grammar of a language. As an example, they apply their test grammar to a subset of a context-free grammar for Ada and add attributes to the grammar productions. The attributes are non-negative integers, and they guide the generation of test programs in the sense that the values of the attributes determine which grammar productions will be used during generation. They show that their approach can be useful in testing the optimizer of the Ada compiler.</p><p>Burgess <ref type="bibr" target="#b33">[34]</ref> presents an approach to testing Pascal compilers also based on attribute grammar. Later, Burgess and Saidi <ref type="bibr" target="#b15">[16]</ref> extend it to check for optimization errors in two Fortran compilers. Similar to the previous work <ref type="bibr" target="#b33">[34]</ref>, they extend a grammar by adding attributes with the additional possibility of assigning weights to grammar productions and generate so-called self-checking test programs. The basic idea of self-checking test programs is to generate assertions along with the test programs, an idea inspired by a work of Bird and Munoz <ref type="bibr" target="#b11">[12]</ref>. The approach uses many heuristics to generate test programs to test known optimizations applied by compilers. A tester may control the applications of such heuristics and may specify weights to the grammar productions.</p><p>An approach by Amodio et al. <ref type="bibr" target="#b3">[4]</ref> trains a recurrent neural network to generate test programs. The model is trained to generate data that conform to a given grammar and also respect additional well-formed properties of the language, such as defining a variable before using it. Such well-formed properties as specified use the formalism of attribute grammars. To enable the neural network to learn such properties, the approach computes a context vector for each program element, which encodes, e.g., the set of variables that has already been defined. W-grammar. Developed by Adriaan van Wijngaarden to specify ALGOL 68 <ref type="bibr" target="#b117">[118]</ref>, W-grammars have been the first kind of two-level grammars. A W-grammar consists of two context-free grammars. One of these context-free grammars is a meta grammar that is used to generate terminal symbols for the second grammar. The meta grammar can be thought of as a way to generalize the context-free grammar. Using techniques such as consistent substitution, where all occurrences of a nonterminal are replaced with the same expansion symbol, W-grammars are able to enforce context sensitivity.</p><p>Bazzichi and Spadafora <ref type="bibr" target="#b8">[9]</ref> use a context-free grammar extended with a parameter, which effectively is a W-grammar. They call the new grammar a context-free parametric grammar. The extension augments a parameter to some of the nonterminal grammar productions. For this particular case, the parameter itself is a grammar that generates variables. Their objective is to generate both valid and invalid programs to test compilers. Similar to the work by Purdom <ref type="bibr" target="#b95">[96]</ref>, the generation algorithms are skewed towards short derivations to a terminal and towards using all productions of the grammar at least once. Bazzichi and Spadafora implement their approach for testing PLZ/SYS and Pascal compilers.</p><p>The previous grammar-directed approaches for generating test programs are either based on a complete language grammar or on a subset of the complete grammar. Zelenov et al. <ref type="bibr" target="#b126">[127]</ref> propose an alternate approach to generating test programs based on a model of a grammar. Given a language grammar, they introduce grammar transformations to generate a restricted model of a language grammar. This model contains the minimal set of productions required to generate wellformed sentences of the target language. This generator contains an iterator, which generates such model representations, and a mapper, which maps those representations to valid language sentences. Based on the same generation approach, but specifically aimed at testing optimizations, Zelenov and Zelenova <ref type="bibr" target="#b125">[126]</ref> build a model of the compiler's optimizer and generate optimizationtargeted tests. The basic idea is to build models of optimizations performed by a compiler and then to generate tests that contain optimization opportunities.</p><p>Lindig <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79]</ref> presents another approach that directly iterates over the grammar productions. His approach, called Quest, uses custom grammar-like productions to generate random test programs for testing C compilers. The goal of the generation is to test if the parameters passed to a function is received unaltered. The generation is driven by a BNF-style production system that serves as a generator. Each generator can either generate a type or a value for a type or take other generators as inputs. Since the goal is to test if values passed to a function is carried forward unaltered, the test programs contain global variables, functions, and calls to the functions using the global variables. The functions contain assertions that check if the received parameters have the expected values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Grammar-aided Approaches.</head><p>Grammar-aided approaches take a grammar as an input and in addition use some heuristics to address context sensitivity. These approaches start with a template-like, fixed code fragment that acts as a placeholder and then utilize the grammar to generate the rest of the program. In addition, to guide the overall generation, some approaches also take a test driver file as an input, while others augment it into grammar productions. Sirer et al. <ref type="bibr" target="#b107">[108]</ref> propose one such grammar-aided approach to testing the Java virtual machine (JVM) by probabilistically iterating over the grammar productions. Given a grammar and a skeletal program called seed, the approach outputs self-checking test programs, i.e., programs with assertions to validate the correctness of the JVM. The input grammar specification contains the productions that need to be augmented with other information, e.g., a limit on the number of times a particular production can be used, and guard conditions that describe the context in which a production is applicable. The skeletal program contains annotations about the probability of each production, along with holes to be filled with code fragments generated by the expansions of the productions.</p><p>Yang et al. <ref type="bibr" target="#b122">[123]</ref> propose a grammar-aided tool, called Csmith, that creates C test programs. The tool is based on Randprog <ref type="bibr" target="#b46">[47]</ref> (discussed in Section 3.3.3). In addition to functions, global and local variables, const and volatile variables, all of which exist in Randprog, Csmith generates programs that contain control flow statements, structs, arrays, and most kinds of C expressions. The approach uses complex heuristics to avoid generating C programs that have undefined behavior as well as that depend on unspecified behavior. The generation starts by creating a main function and a set of struct type declarations, each of which contains a random number of member variables of randomly decided types. Using the main function as the starting point, the rest of the C code is generated based on a subset of the C grammar. Depending upon the current state of the generation, Csmith chooses an allowable production based on a probability table and a filter function. The filter function enforces context sensitivity. During generation, Csmith performs certain safety checks and creates a code fragment only if all safety checks pass.</p><p>Several variants of the Csmith test program generator have been proposed. Morisset et al. <ref type="bibr" target="#b84">[85]</ref> modify Csmith to generate programs that test C/C++ concurrency bugs. Their altered version adds support for mutexes and atomic variables, as well as system calls to lock and unlock the mutex variables. Also, Lidbury et al. <ref type="bibr" target="#b76">[77]</ref> build a test program generator for OpenCL compilers based on Csmith, which is called CLsmith. CLsmith has six modes in total, and it generates different types of OpenCL kernels (i.e., test programs) under different modes. For example, in the VECTOR mode, CLsmith extends Csmith by introducing the capability to generate variables and expressions with vector types and exercising the rich set of vector operations available in OpenCL <ref type="bibr" target="#b76">[77]</ref>.</p><p>Instead of extending Csmith with additional language features, swarm testing <ref type="bibr" target="#b50">[51]</ref> restricts the set of language features available for generating a specific program. For example, swarm testing may configure Csmith to not use any arrays for some test programs and not use any pointers for some other programs. The intuition of this approach is that some bugs are more likely to be covered by intensively using a subset of all language features instead of equally distributing the testing effort across all features. Later, Alipour et al. <ref type="bibr" target="#b2">[3]</ref> further propose directed swarm testing, which aims to generate test programs focusing on only part of a compiler through tuning the set of available language features. More specifically, by analyzing statistical data on past testing results, directed swarm testing configures Csmith on a set of C language features to generate test programs with higher probability to cover a specific part of a compiler.</p><p>Furthermore, Chen et al. <ref type="bibr" target="#b26">[27]</ref> propose an approach, called HiCOND, to finding a set of test configurations (which can control the language features of the generated test programs) for test-program generators (e.g., Csmith) to generate bug-revealing and diverse test programs. More specifically, HiCOND first infers the range of each configuration option where the bug-revealing test programs are more likely to be generated based on historical data and then identifies a set of test configurations that can generate diverse test programs via a search method (i.e., particle swarm optimization).</p><p>Instead of generating or hard coding the placeholder code as in the previous approaches, Holler et al. <ref type="bibr" target="#b57">[58]</ref> use real-world programs as placeholders. They take these programs from a corpus and replace some parts of the program with randomly generated code fragments. Code fragments get generated by iterating over the grammar productions and by taking a random decision whenever multiple choices are available for a particular production. After a maximum number of iterations, the remaining nonterminals are always replaced by terminals. These replacement terminals are again taken from a large code corpus. Additionally, the approach uses some heuristics, such as renaming of identifiers, to fit the generated code fragments into the target or placeholder program. The overall approach is a combination of both generation and mutation, and we explain it further in Section 3.4.</p><p>All previous grammar-aided approaches start with a given placeholder input. In contrast, Boujarwah et al. <ref type="bibr" target="#b13">[14]</ref> first generate a test program and then generate additional code to obtain a semantically correct test program. According to a context-free grammar, their approach tests certain semantic features of Java compilers. They first decide upon which semantic features of the language they want to test and then use the context-free grammar, together with a test driver file, to guide the generation. The test driver file contains information about the language construct to generate, i.e., how many occurrences of each such language construct to generate, and the order in which they will get generated. For example, if during generation, Bourjarwah et al. decide to generate test programs for testing loops, then the test driver may contain which kinds of loops (for, while, do-while) should get generated and the number of them. Once a language construct has been generated, the approach generates the required context for the generated code. For example, they generate the required type declarations or add necessary imports. The iteration over the context-free grammar is based on Purdom's algorithm <ref type="bibr" target="#b95">[96]</ref> discussed earlier (Section 3.3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Other</head><p>Approaches. Not all approaches for automatic test program generation are built on a grammar of the targeted programming language. The following discusses a set of approaches that do not use a grammar directly as an input. Many of them generate test programs based on pre-defined code templates that specify a skeleton for test programs, which is then filled with additional code snippets.</p><p>Berry <ref type="bibr" target="#b10">[11]</ref> proposes test program generation for compilers based on the frequency of language features used by real programmers. To this end, they collect statistics of how language features are used and then design test programs based on frequently used features. The insight behind the approach is that features with higher usage frequency are more likely to be used by a compiler during its practical usage, and hence also more likely to trigger a bug. The approach generates different hard-coded language snippets based on the collected statistics.</p><p>Mandl <ref type="bibr" target="#b79">[80]</ref> is an approach to avoiding the generation of duplicated elements in programs. It uses a unique approach called orthogonal latin squares to generating test programs for validating an Ada compiler. A latin square is a square matrix where each row and column contains an element exactly once, i.e., all elements of the matrix are unique. Two matrices are orthogonal latin squares if combining them creates another latin square. Mandl represents test templates as orthogonal latin squares and generates test programs by replacing elements of a row from the template matrix with allowable values. Using this latin square representation helps the approach to creating a test template with different configurations. Each configuration can generate multiple unique test programs. As an example, suppose the goal is to generate arithmetic expressions. Given the operands of the expression, the test template matrix could contain the operators of arithmetic expressions. Going through each row of the template matrix while using the operands, the approach generates unique arithmetic expressions.</p><p>The Csmith approach explained in Section 3.3.2 is an extension of a non-grammar-based approach called Randprog, which is introduced by Eide and Regehr <ref type="bibr" target="#b46">[47]</ref>. As suggested by the name, Randprog generates random C programs to find miscompilations of C's volatile qualifier. Each program generated by Randprog is hard-coded to first contain a number of randomly initialized global variables that are either const or volatile. The program then contains functions that declare local variables and that contain expressions using global and local variables. Finally, to make the programs executable, each program contains a main function.</p><p>An approach similar to Randprog is proposed by Nagai et al. <ref type="bibr" target="#b86">[87]</ref>. They test code optimization for arithmetic expressions in C compilers. Each generated test program contains initialized global and local variables along with arithmetic expressions that use random operators and variables. The generation uses heuristics to avoid generating undefined behavior. During generation, the approach precomputes the result of each expression and inserts a runtime check that compares the precomputed result with the actual result. In a follow-up work, Nagai et al. <ref type="bibr" target="#b87">[88]</ref> improve upon their work by mutating arithmetic expression, which we explain in Section 3.4.</p><p>Randprog <ref type="bibr" target="#b46">[47]</ref> and the approach by Nagai et al. <ref type="bibr" target="#b87">[88]</ref> start by generating fixed language constructs and then randomly generate the rest of the program. In contrast, Palka et al. <ref type="bibr" target="#b91">[92]</ref>, similar to some grammar-aided approaches (Section 3.3.2), start with a placeholder and expand the placeholder with random Haskell terms. In addition to the placeholder, they take type rules written in judgment proposition notation as inputs and generate well-typed Haskell terms. Each type rule has an associated environment that contains a list of identifiers and their corresponding types. For each type rule, the approach first recursively generates the terms present in the premise and then generates the terms in the consequence. Instead of directly using the type rules, Dewey et al. <ref type="bibr" target="#b40">[41]</ref> present a fuzzing technique using constraint logic programming (CLP). The type judgments are written in CLP specifications and used as an input to CLP engine for generation. They extend swarm testing ideas to find defects in the Rust type checker; i.e., instead of creating one generator that encompasses all of Rust, they create different generators that focus on different parts of the Rust type system.</p><p>The approach of Palka et al. <ref type="bibr" target="#b91">[92]</ref> (presented in the previous paragraph) is later refined by Midtgaard et al. <ref type="bibr" target="#b82">[83]</ref>. They observe that, in some languages, the evaluation of expressions depends on an unspecified evaluation order. For example, if the evaluation order is not specified, the outcome of the left-to-right evaluation of an expression can be different from the right-to-left evaluation. Since it is difficult to judge the correct outcome of an evaluation order-dependent expression, their approach tries to avoid creating such expressions. To this end, they refine the approach of Palka et al. <ref type="bibr" target="#b91">[92]</ref> by introducing type and effect rules. During generation, the approach avoids the generation of programs that depend on the evaluation order using some predefined rules.</p><p>Instead of hard-coding the features of the generated test programs in the generator, some approaches use configuration or template files that a user can control. Austin et al. <ref type="bibr" target="#b5">[6]</ref> present such a program generator for testing Ada compilers. The approach generates complex Ada expressions in a recursive descent manner by taking random decisions for alternative syntactic decisions. The generator is configurable in the sense that a tester can specify, e.g., the size of the integers produced or the seed used for random decision.</p><p>Yoshikawa et al. <ref type="bibr" target="#b124">[125]</ref> present a similar configuration-driven generation approach with the knowledge of syntax and the application of heuristics. The generation starts by generating a random number of Java classes having acyclic parenthood relationships. This is followed by the generation of fields for each class followed by generation of methods. The methods are then filled with control flow information. For example, method invocations are added randomly into each method body. These additions are made with some constraints to avoid certain behaviors such as infinite method calls.</p><p>Zhao et al. <ref type="bibr" target="#b131">[132]</ref> present another configuration-driven approach of test program generation that targets at testing compiler optimization. The approach takes a test configuration file as an input, which specifies, e.g., which variable type should be generated, what operators need to be generated, and how many branches and loops are used in the test programs. Moreover, a user can configure which optimization to be tested. The optimizations to be tested are specified as temporal logic formulas, which in turn are converted into graph structures. The graphs are then converted to templates whose expansion leads to the generated programs.</p><p>Similar to Berry <ref type="bibr" target="#b10">[11]</ref> (presented in the beginning of Section 3.3.3), Ching and Katz <ref type="bibr" target="#b31">[32]</ref> propose an approach to testing an APL compiler using programs collected from real-world applications. Additionally, Ching and Katz <ref type="bibr" target="#b31">[32]</ref> also propose generation of unit tests from templates. A template here represents a test with special symbols denoting functions and data types. During generation, these symbols are replaced with concrete values and the particular function being tested. The functions here are built-in functions of APL.</p><p>In addition to a template, an approach by Kalinov et al. <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b64">65]</ref> also takes an input expression for test program generation that they use to find bugs in mpC, a parallel language compiler. The template contains a set of mpC operators, while the expression is a valid expression called seed expression provided by the testers. Starting from this seed expression, the approach generates multiple variant expressions by using the operands from the seed expression and operators from the template. The mpC language is specified as a visual formalism called Montages <ref type="bibr" target="#b69">[70]</ref> that can express the syntax as well as the execution behavior. Kalinov et al. <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b64">65]</ref> use this specification to filter out positive and negative examples during test program generation.</p><p>Zhang et al. <ref type="bibr" target="#b130">[131]</ref> propose skeletal program enumeration. Given a program skeleton, i.e., source code with holes to be filled with variable names, the approach exhaustively enumerates all possible variable usage patterns. Because different assignments of holes to variable names may be equivalent, the approach enumerates only one program out of a set of equivalent programs under alpha renaming, i.e., under a consistent renaming of variables names.</p><p>Following the recent trend of using machine learning on software artifacts, e.g., source code, several approaches for learning-based generation of test programs have been proposed. They all share the basic idea of learning a model from a corpus of code examples and to then use this model to generate additional test programs. The approaches differ in the kinds of models they use and in the kinds of program properties they are targeting, as explained in the following. We have already introduced one such approach by Amodio et al. <ref type="bibr" target="#b3">[4]</ref> in Section 3.3.1, who train a recurrent neural network to generate test programs. Another learning-based approach called TreeFuzz <ref type="bibr" target="#b92">[93]</ref> learns a set of probabilistic generative models of tree-shaped data, such as programs represented by an AST. The models address both syntactic and semantic properties of programs, e.g., by learning what children nodes a particular node typically has or by learning definition-use-like relationships between occurrences of the same variable. The approach has been used for testing JavaScript engines.</p><p>Bastani et al. <ref type="bibr" target="#b7">[8]</ref> propose to learn a grammar based on examples of data accepted by the grammar and on black-box access to a parser for the grammar. The approach iteratively constructs a grammar that accepts an increasingly general language, starting by synthesizing regular expressions and by then generalizing the regular expressions into a context-free grammar. Once the grammar is learned, it can be used to sample new test programs. The approach has been used for a variety of data formats, including test programs in Python, Ruby, and JavaScript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Program Mutation</head><p>Instead of generating complete programs from scratch, the main idea of program mutation is to modify parts of an existing test program. However, it is possible that the existing program itself is generated using approaches presented in Section 3.3. It is interesting to note that most program mutation-based approaches for testing compilers are a result of very recent research efforts in the past decade. These research efforts are driven by the success of Csmith <ref type="bibr" target="#b122">[123]</ref> and in many cases either mutate Csmith-generated programs or build upon the shortcomings of Csmith. Furthermore, it is also interesting to note that a large portion of the mutation approaches find bugs in the optimization phase of the compiler. The reason for this is that, by code mutations and by complicating control flow, the approaches provoke the optimizer. Overall, the mutation approaches to constructing test programs can be classified into two categories. One category is based on semantics-preserving mutation (Section 3.4.1), and the second category is based on mutations that do not try to preserve the semantics of a program (Section 3.4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Semantics-preserving Mutation.</head><p>The main idea of semantics-preserving mutation is to mutate without changing the behavior of the program. Almost all semantics-preserving mutations are based on the general idea of equivalence modulo inputs (EMI) <ref type="bibr" target="#b71">[72]</ref>. Informally, two test programs written in the same programming language are equivalent to each other under a set of inputs, if for each input of the set their behaviors are the same. Actually, EMI makes greater contribution to test oracles in compiler testing, and thus more details about it are presented in Section 4.2. Mutation approaches leverage the general idea of EMI by mutating programs to their semantic equivalences, and these semantic-preserving mutants can also be regarded as a type of test program.</p><p>Based on the general idea of EMI, Le et al. <ref type="bibr" target="#b71">[72]</ref> propose Orion to validate C compilers by randomly mutating non-executed parts of code to create test programs. The premise of Orion is mutating non-executed part of the code should not alter the behavior of the program, and a diverging behavior can potentially be due to a bug. Later, Le et al. <ref type="bibr" target="#b72">[73]</ref> extend Orion, called Athena, and instead of blind random mutations in Orion adopt a guided mutation strategy. Given a program, they mutate the non-executed parts of the program with the objective to generate a mutated program having a large distance with the original program. The distance is calculated based on controlflow graph (CFG) nodes, the distance between the CFG edges, and the program sizes. To guide the mutation, Athena uses Markov Chain Monte Carlo (MCMC) sampling that selects mutated programs with large distances. In contrast to Orion, where the only mutation operation was to delete non-executed code, they additionally insert code into the non-executed parts of the program. Both of these approaches use Csmith as the source program generator on which the mutations are performed.</p><p>Lidbury et al. <ref type="bibr" target="#b76">[77]</ref> present fuzzing of OpenCL compilers also using the basic idea of EMI. They modify Csmith to generate programs suitable for OpenCL compilers and perform semanticspreserving code mutations. The mutation operation is the insertion of code known to be deadby-construction at random locations of the original program.</p><p>The code mutation strategies adopted by Le et al. <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b72">73]</ref> and Lidbury et al. <ref type="bibr" target="#b76">[77]</ref> either delete or insert dead code. In comparison, Sun et al. <ref type="bibr" target="#b110">[111]</ref> present Hermes, including some novel EMIbased mutation strategies. In addition to dead code, Hermes mutates live code or the code that gets executed. The mutation strategies adopted by Hermes involve insertion of code blocks where the conditional predicate always evaluate to false, wrapping an always true code block around live code and insertion of side-effects-free self-constructed live code. A similar mutation approach has also been proposed by Donaldson et al. <ref type="bibr" target="#b41">[42]</ref>, who apply semantic-preserving transformations to test graphics shader compilers. Some of the code transformations applied by them are similar to the mutation operations of Sun et al. <ref type="bibr" target="#b110">[111]</ref>. In addition, they also apply code transformations such as mutation of numeric and Boolean expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Non-semantics-preserving Mutation.</head><p>In addition to semantics-preserving mutations, there exist approaches that mutate programs without keeping the same semantics. The main motivation of mutation for such approaches is to make a program suitable for testing compilers, e.g., by avoiding undefined behaviors or by creating more diverse test programs.</p><p>To this end, Nagai et al. <ref type="bibr" target="#b87">[88]</ref> extend their previous work of generating random arithmetic expressions <ref type="bibr" target="#b86">[87]</ref> (Section 3.3) using non-semantics-preserving mutation of the generated expressions. In their previous work <ref type="bibr" target="#b86">[87]</ref>, Nagai et al. avoid generating long arithmetic expression with the assumption that longer expressions are more susceptible to induce undefined behaviors. They improve upon this and avoid undefined behaviors in long expressions by mutating the undefinedbehavior-producing expression with some heuristics and apply it for testing C compilers. The heuristics are, for example, flipping an operation or by inserting an operation. As a result, they are able to generate larger arithmetic expressions and are able to find errors in C compilers.</p><p>The main idea of Chen et al. <ref type="bibr" target="#b30">[31]</ref> for testing JVM implementations, is similar to that of Le et al. <ref type="bibr" target="#b72">[73]</ref> (Section 3.4.1), i.e., instead of blind mutations, performing MCMC (Markov Chain Monte Carlo) sampling. The objective is to select mutations that have larger possibilities to trigger compiler bugs. More specifically, to test JVM implementations, Chen et al. <ref type="bibr" target="#b30">[31]</ref> mutate class files with a wide range of mutation operations. They have implemented many mutation operations, such as inserting/deleting methods into/from class.</p><p>Holler et al. <ref type="bibr" target="#b57">[58]</ref> present a mutation-based approach called LanдFuzz that finds bugs in the JavaScript interpreter of Mozilla Firefox. LanдFuzz contains two phases: learning and mutation. In the first phase, it learns a large pool of code fragments by processing a set of sample input files using a parser. These are actually non-terminal expansions of the grammar. In the next phase, they parse a target program and replace some randomly chosen non-terminals with the expansions of the same type from the learned pool. For some cases, instead of choosing the replacement from the pool, they generate the replacement using a grammar. It is possible that the replacement fragments do not fit into the target program and they use some heuristics to fix this. For example, if the replacement fragment contains identifiers that are not declared in the target program, the target program might crash. To mitigate such situations, they rename all identifiers occurring in the replacement code fragment with some identifiers occurring somewhere in the target program.</p><p>Certain mutation approaches take a complete test suite as input and mutate with varying goals in mind. To this end, Garoche et al. <ref type="bibr" target="#b47">[48]</ref> present a mutation approach with the goal of producing more failure-inducing programs using existing test suites. The mutation approach does not alter the control flow or the overall semantic structure, albeit changing the semantics of entire programs. The mutation operations are, for example, replacement of arithmetic or Boolean operations and replacement of constants with others. However, Groce et al. <ref type="bibr" target="#b48">[49]</ref> mutate test programs with the goal of still maintaining certain properties. As an example goal, they successfully reduce the test suite of Spidermonkey while retaining the statement coverage. The overall mutation operation is a generalization of delta debugging <ref type="bibr" target="#b127">[128]</ref> introduced by Zeller. Groce et al. call their reduction approach cause reduction and in addition to maintaining coverage, can also be used to keep other properties, such as maintaining the same failure-inducing test programs in the test suite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TEST ORACLES</head><p>As any testing activity, compiler testing must address the test-oracle problem, i.e., to determine whether a given test program exposes any undesired behavior. To address this challenge, several approaches have already been proposed in the literature. We categorize these approaches into two groups: differential testing <ref type="bibr" target="#b80">[81]</ref> (presented in Section 4.1) and metamorphic testing <ref type="bibr" target="#b28">[29]</ref> (presented in Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Differential Testing for Compilers</head><p>To solve the test-oracle problem for complex software such as compilers, McKeeman et al. <ref type="bibr" target="#b80">[81]</ref> propose the concept of differential testing. In general, differential testing for compilers needs at least two compilers that are designed and implemented based on the same specification, and then X X Chen et al. <ref type="bibr" target="#b30">[31]</ref> X X Sun et al. <ref type="bibr" target="#b109">[110]</ref> X X X compares the results from these comparable compilers to determine whether compiler bugs are detected. To select the implementations to compare, there are several variants of differential testing for compilers. In particular, Table <ref type="table" target="#tab_3">3</ref> summarizes the usage of three widely used differential-testing strategies in compiler testing.</p><p>• Cross-compiler strategy: Detect compiler bugs by comparing results produced by different compilers. This strategy is the most general concept in differential testing for compilers. • Cross-optimization strategy: Detect compiler bugs by comparing results produced using different optimizations implemented in a single compiler. This strategy is the most widely used strategy in the existing compiler-testing research. • Cross-version strategy: Detect compiler bugs by comparing results produced by different versions of a single compiler.</p><p>Sheridan <ref type="bibr" target="#b106">[107]</ref> uses the cross-compiler strategy to test a C99 compiler, the PalmSource Cobalt ARM C/C++ embedded cross-compiler. In this work, Sheridan compares the output of the compiler under test and that of the preexisting tools to detect compiler bugs. In particular, they use the GNU C Compiler in C99 mode and the ARM ADS assembler as the preexisting tools. The insight as to why they utilize this strategy includes three points: First, different compilers for the same programming language are expected to produce the same output for the same input. Second, if the input can trigger a bug, different compilers seldom expose the same bug and produce the same buggy output under the same input due to the differences between their implementations. Third, if two compilers produce different outputs under the same input, one of them must contain a bug.</p><p>Ofenbeck et al. <ref type="bibr" target="#b89">[90]</ref> propose to detect compiler bugs by taking random instances of an IR (intermediate representation) as inputs through differential testing, which is called RandIR. They target at vanilla Scala code in their study. When using RandIR, the users should give the grammar of the code that is represented by the IR <ref type="bibr" target="#b89">[90]</ref>. Actually, the grammar is a collection of typed functions/operations. More specifically, RandIR first randomly constitutes the operations provided by users and records the information in a typed dependency graph. Then, it translates the constituted operations to regular Scala functions. To conduct differential testing, it still requires another regular Scala program. Here, the program can be produced based on the typed dependency graph or another compiler pipeline that transforms IRs to Scala functions. That is, they use the crosscompiler strategy for differential testing.</p><p>Sassa and Sudosa <ref type="bibr" target="#b103">[104]</ref> use the cross-optimization strategy to test optimizers of a compiler. In particular, their approach detects compiler bugs by comparing traces of important values before and after optimizing the given test program. If the traces are different, then it means that a bug in the optimizer is detected. To conduct such a comparison, the first step is to determine which values of variables should be compared. The second step is to determine when during the program execution the comparison should be conducted. The final step is to conduct the comparison. In particular, the comparison on values of variables is based on the traces of variable information, including basic block number, instruction number in the basic block, variable name, and the value of variables.</p><p>Morisset et al. <ref type="bibr" target="#b84">[85]</ref> use the cross-optimization strategy to detect concurrent bugs in C11/C++11 compilers. Since concurrent test programs are not deterministic and compiler optimizations can compile away non-determinism, it is essential to ensure that all the behaviors of an executable produced by a compiler are allowed by the source-program semantics. To conduct differential testing for concurrent compiler bugs, they must assume that the sequential code that is optimized by C11/C++11 compilers can be run in any concurrent context. In particular, there is one constraint, which is that the test program is well-defined and can only apply sound optimizations for the concurrency model. More specifically, this work presents the correctness of the criteria for sound optimizations in the C11/C++11 model. Based on the theory of sound optimizations, they develop a tool, called cmmtest, to conduct differential testing of concurrent compiler bugs. The tool compiles the same test program using the compiler with optimizations under test and the compiler without turning on any optimization, and then records their memory traces (i.e., all memory accesses to global variables and synchronizations). Finally, it compares the recorded traces to determine whether a compiler bug is detected. In particular, it checks whether the trace from the compiler with optimizations under test can be transformed from the trace of the reference compiler by conducting some transformation rules, including the valid elimination rule, the reordering rule, and the introduction rule.</p><p>Le et al. <ref type="bibr" target="#b73">[74]</ref> use the cross-optimization strategy to test link-time optimization (LTO) of compilers and develop a tool called Proteus. More specifically, Proteus compiles a test program in three different ways. The first way is that, the test program is directly compiled by the compiler under test without turning on LTO. The second way is that the test program is compiled by the compiler under test with turning on LTO and various other optimizations. The last way is that the test program is first split into a set of compilation units, and then the set of compilation units are separately compiled by the compiler under test under various optimizations and linked with turning on LTO. The results produced in the above three different ways should be the same. Otherwise, there is a compiler bug that is detected.</p><p>Béra et al. <ref type="bibr" target="#b9">[10]</ref> use a variant of the cross-optimization strategy to test dynamic deoptimization of bytecode-to-bytecode JIT compilers. They compare the abstract stack of deoptimization and that of non-optimization to detect bugs. In particular, they apply symbolic execution on the bytecode produced by the compilation with optimizations and that produced by the compilation without optimizations. During the process of symbolic execution, when coming across a point where the dynamic deoptimization can be applied, they stop symbolic execution and then compare the stack of abstract values of deoptimization and that of non-optimization to guarantee the correctness of deoptimization for each value. Some work uses multiple test oracle strategies at the same time. Hawblitzel et al. <ref type="bibr" target="#b53">[54]</ref> propose to detect compiler bugs by comparing assembly language outputs of (1) multiple versions of a compiler (cross-version strategy) and (2) a compiler with different optimization levels (crossoptimizations strategy). Besides, this work also uses other strategies, including cross-architecture strategy, in which compiler bugs are detected by comparing results produced on different architectures for a compiler (i.e., ARM and x86); and cross-scenario strategy, in which compiler bugs are detected by comparing results produced in different compilation scenarios of a compiler (i.e., Just-In-Time and Machine Dependent Intermediate Language). During comparison, their proposed tool proves the equivalence between assembly language programs using the symbolic differencing tool SymDiff, the program verifier Boogie, and the automated theorem prover Z3. Since an assembly language program consists of a collection of compiled methods, their tool first converts each of these methods into a procedure in the Boogie language. Then, it uses SymDiff to integrate converted methods into a single block of Boogie code. Next, it uses the Boogie program verifier to convert the assertions into verification conditions. Finally, it uses Z3 to prove whether these verification conditions are valid. To reduce false alarms, their tool automatically produces counterexample traces that show values causing different behaviors in the two assembly language programs.</p><p>Chen et al. <ref type="bibr" target="#b30">[31]</ref> propose to test JVM implementations via differential testing, focusing on the startup processes of JVMs. A JVM startup process includes four steps, i.e., loading, linking, initializing, and invoking classes. During the process of differential testing, their approach uses crosscompiler strategy and cross-version strategy to detect JVM discrepancies. More specifically, they propose a coverage-directed fuzzing approach, called classfuzz, to generate representative classfiles (referring to those that are likely to be distinct) for differential testing.</p><p>Sun et al. <ref type="bibr" target="#b109">[110]</ref> propose to detect incorrect compiler warnings via differential testing. They use all the three strategies for differential testing, i.e., cross-compiler strategy, cross-version strategy, and cross-optimization strategy. Their approach first randomly generates test programs to make compilers emit various compiler warnings. Their program generation approach is based on two observations from historical warning bugs. First, most historical bugs are irrelevant to the bodies in conditional statements. Second, most historical bugs do not occur at the regions of obviously dead code. Then, since the warnings emitted by different compilers, different versions of one compiler, and different optimizations of one compiler version are described differently using the natural language, their approach conducts the alignment for these warnings. In particular, their approach extracts the warning elements that can be recognized by computers from warning descriptions for alignment. Finally, their approach identifies inconsistencies as potential warning bugs.</p><p>Besides, Kitaura and Ishiura <ref type="bibr" target="#b65">[66]</ref> propose to detect performance bugs via differential testing. They use both cross-compiler strategy and cross-version strategy. Their approach is based on mixed static and dynamic code comparison. In the static step, it first compares the assembly codes produced from a given test program under two different compilers/versions to detect a code difference, and then reduces the test program to isolate the difference. In the dynamic step, it executes the codes produced from the reduced test program under two different compilers/versions to compare their actual execution time. For the performance of compilers, there is also some research on finding missed compiler optimizations (i.e., optimizations performed by one compiler but missed by another compiler) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b85">86]</ref>. For example, Barany <ref type="bibr" target="#b6">[7]</ref> uses differential testing (i.e., cross-compiler strategy) to find missed optimizations in C compilers. In particular, they develop a tool to statically compare the binary codes produced from a test program under two compilers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Metamorphic Testing for Compilers</head><p>Metamorphic testing <ref type="bibr" target="#b28">[29]</ref> is another popular approach for addressing the test-oracle problem. The core idea of metamorphic testing is to construct metamorphic relations, which specify how particular changes to the input of the project under test would change the output. For example, when testing the sine function, it is difficult to determine the expected output of sin <ref type="bibr" target="#b0">(1)</ref>. However, the mathematical property of the sine function, i.e., sin(x ) = sin(πx ), can help test sin(x ). In other words, we can test whether sin(1) = sin(π -1) to facilitate the testing of the sine function.</p><p>To apply metamorphic testing to compilers, several metamorphic relations have been proposed, as summarized in Table <ref type="table" target="#tab_5">4</ref>. In particular, the most widely adopted metamorphic relations are the equivalence relations that establish that two programs are equivalent under some assumptions. The following discusses the approaches summarized in  Tao et al. <ref type="bibr" target="#b113">[114]</ref> develop a testing tool, called Mettoc, to test compilers via metamorphic testing, where they consider the equivalence-preservation relation as the metamorphic relation. Mettoc generates at least two equivalent test programs and then uses the compiler under test to compile them to produce executables. After running these executables, producing different results means that a bug is detected. Here, Mettoc generates equivalent test programs by constructing equivalent expressions, assignment blocks, and submodules. Here, "assignment block" refers to a compounded statement consisting of a sequence of assignments, and "submodule" refers to a compounded statement that may contain conditional structures. More specifically, Mettoc first constructs a general control flow graph, and each block node of the graph represents a submodule. Then, Mettoc uses those equivalent statements or expressions to fill in each block node. Finally, it traverses the filled graph to generate the equivalent test programs.</p><p>Le et al. <ref type="bibr" target="#b71">[72]</ref> introduce the concept of Equivalence Modulo Inputs (EMI) to test compilers. Different from the used metamorphic relations in Tao et al. <ref type="bibr" target="#b113">[114]</ref>, this work adopts the equivalence relation under a given set of test inputs as the metamorphic relation. Given a test program and a set of test inputs of the test program, EMI first generates a series of equivalent variants with the original one under the given test inputs. Taking the original program and its equivalent variants as the inputs of a compiler, the compiler produces executables accordingly. Then, these executables should produce the same results when executing under the given test inputs. Otherwise, there is a compiler bug that is detected.</p><p>In particular, EMI is a general idea and has three instantiations, called Orion <ref type="bibr" target="#b71">[72]</ref>, Athena <ref type="bibr" target="#b72">[73]</ref>, and Hermes <ref type="bibr" target="#b110">[111]</ref>. The difference among them is mainly the way of generating equivalent variants with a given test program under a set of test inputs. Orion generates equivalent variants by randomly deleting non-executed statements under the given test inputs <ref type="bibr" target="#b71">[72]</ref>. Athena utilizes the MCMC (Markov Chain Monte Carlo) algorithm to guide the generation process by introducing insertion operations in the non-executed regions besides deletion operations <ref type="bibr" target="#b72">[73]</ref>. Hermes further introduces mutations in both live and dead regions by synthesizing valid semantic-preserving code snippets under the set of test inputs <ref type="bibr" target="#b110">[111]</ref>. More details about the way of generating equivalent variants have been presented in Section 3.4.1.</p><p>Similar to the idea of EMI <ref type="bibr" target="#b71">[72]</ref>, Donaldson and Lascu <ref type="bibr" target="#b42">[43]</ref> utilize metamorphic testing to test OpenGL compilers. This work proposes to inject dead code into existing test programs to construct equivalent program variants. The original test program and its equivalent program variants should produce the same results. Otherwise, a compiler bug is detected. Furthermore, Nakamura and Ishiura <ref type="bibr" target="#b88">[89]</ref> propose to construct equivalent programs to test C compilers by designing a set of equivalent transformation rules on existing test programs.</p><p>Later, Donaldson et al. <ref type="bibr" target="#b41">[42]</ref> propose to test graphics shader compilers via metamorphic testing. More specifically, they leverage existing graphics shaders of high value to create sets of semantically equivalent transformed shaders by applying a set of (essentially) semantics-preserving transformations. Here, a semantics-preserving transformation means that the transformation will have no impact on computation. The exception is the floating-point computation in which it is possible to induce slight changes at the transformation point. That is, it is different from the deterministic equivalence used in the existing work <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b113">114]</ref>.</p><p>Different from the metamorphic relations whose inputs are equivalent source programs, Samet <ref type="bibr" target="#b98">[99]</ref><ref type="bibr" target="#b99">[100]</ref><ref type="bibr" target="#b100">[101]</ref> tests compilers based on the metamorphic relations whose inputs are a source program and the object program produced by a compiler under test. Their approach utilizes the intermediate representation (IR) to evaluate the equivalence between a source program and the object program produced by a compiler to detect compiler bugs. It first converts a source program into an IR, then converts the object program to the IR, and finally checks the equivalence between the two IRs. In particular, the IR of the object program is obtained by the process of symbolic interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">OPTIMIZING THE TEST PROCESS</head><p>Typically, compilers are well tested and are widely used, and thus it is difficult to detect latent bugs in compilers. In fact, compiler testing approaches tend to take a long period of testing time to find a relatively small number of compiler bugs through running a lot of test programs <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b122">123]</ref>. To address this efficiency problem, some optimization approaches for test-program execution have been proposed in the literature <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b121">122]</ref>. These optimization approaches can be divided into two types: test-program prioritization (presented in Section 5.1) and test-suite reduction (presented in Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Test-program Prioritization</head><p>In compiler testing, among all available test programs, only a small number can trigger bugs. Therefore, if we run these programs earlier, the efficiency of compiler testing can be improved. Test-program prioritization is a way to optimize the test-program execution order such that the programs with larger possibilities to trigger compiler bugs can be executed as early as possible <ref type="bibr" target="#b123">[124]</ref>.</p><p>Traditional test prioritization approaches <ref type="bibr" target="#b123">[124]</ref> are infeasible for compiler testing, and the reasons are presented below. First, most traditional test prioritization approaches rely on code coverage (e.g., statement coverage). The coverage information can be collected in the regression testing scenario <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b129">130]</ref>. However, the test programs for compiler testing tend to be randomly generated on the fly via automated program generators (e.g., Csmith <ref type="bibr" target="#b122">[123]</ref>). Therefore, their coverage information is not available before testing. That is, coverage-based test prioritization is not a good match for accelerating compiler testing. Second, there are also some other test prioritization approaches based on only test-input information <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b114">115]</ref>. Unfortunately, an existing study <ref type="bibr" target="#b21">[22]</ref> has evaluated the effectiveness of the state-of-the-art test-input-based test prioritization approach on accelerating compiler testing <ref type="bibr" target="#b62">[63]</ref>, and their results demonstrate that it cannot accelerate compiler testing, since the time required for prioritization is very long. The limited applicability of traditional test prioritization approaches motivates new work on test-program prioritization for compiler testing.</p><p>Chen et al. <ref type="bibr" target="#b22">[23]</ref> propose a test-program prioritization approach by transforming each test program to a text-vector. Here, this approach considers three categories of bug-relevant tokens, i.e., statements, types and modifiers, and operators, for the transformation. Based on these text vectors, this approach then uses three strategies to prioritize these test programs: (1) The first one is to schedule test programs following the descending order of distances between text vectors and the origin vector (0,0, . . . ,0), which is called the greedy strategy. <ref type="bibr" target="#b1">(2)</ref> The second one is to schedule test programs by borrowing the strategy of adaptive random testing. More specifically, it selects the next test program, minimizing the distance to the already selected test programs. (3) The third one is to schedule test programs using a local beam search strategy.</p><p>Later, Chen et al. <ref type="bibr" target="#b21">[22]</ref> propose the idea of "learning to test." Based on this idea, they implement an approach (called LET) to prioritizing test programs. The key insight of LET is that, if a test program contains certain features, then it can be hard to compile or optimize, and thus it has a larger possibility to trigger compiler bugs. LET first extracts two categories of features that are helpful to reveal compiler bugs to some degree. The first one is existence features, reflecting whether some types of elements are in the target test program. The second one is usage features, reflecting how these elements in the target test program are used. Based on the two categories of features, LET builds a capability model and a time model. The former aims to predict the bug-revealing probabilities for new test programs, while the latter aims to predict the execution time for new test programs. Based on both models, LET computes the bug-revealing probability per unit time for each new test program. Finally, LET schedules these new test programs according to the computed values.</p><p>Since the above proposed test-program prioritization approaches ignore the case in which different test programs may have the same test capabilities (i.e., testing the same functionalities of a compiler, even detecting the same bugs), such neglect may discount their acceleration effectiveness. To relieve this problem, Chen et al. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b27">28]</ref> propose an approach to distinguishing test programs with different test capabilities based on test coverage information. As discussed before, test-program coverage information in compiler testing is not available in advance, and thus he proposes to predict coverage statically based on test-program features, without test execution. Then, according to the statically predicted test coverage, this approach clusters test programs into different groups, each of which tends to have the similar test capability. Finally, this approach ranks test programs by iteratively enumerating each group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Test-suite Reduction</head><p>Test-suite reduction is also a way to reduce testing costs <ref type="bibr" target="#b23">[24]</ref>. It improves the efficiency of compiler testing by excluding redundant test programs. There are at least three approaches aimed at testsuite reduction for compilers. Two of them focus on retargeted compilers for embedded processors, which are developed by adapting existing compilers <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b121">122]</ref>.</p><p>Woo et al. <ref type="bibr" target="#b121">[122]</ref> propose an approach to removing redundant test programs for retargeted compilers according to the IR-level coverage information. They work at this for three reasons: (1) different test programs at the source-code level are able to be mapped to the same program at the IR level; (2) the machine code produced by compilers has the direct dependency on the IR;</p><p>(3) the modifications of retargeted compilers extensively occur at the compiler back-ends during retargeting. This approach aims to acquire a test suite that has a smaller size but does not reduce the grammar coverage of the intermediate language <ref type="bibr" target="#b70">[71]</ref>. More specifically, it assures that every preserved test program in the test suite should be able to cover at least one new grammar rule.</p><p>Chae et al. <ref type="bibr" target="#b18">[19]</ref> further extend the above test-suite reduction approach <ref type="bibr" target="#b121">[122]</ref>. First, they investigate a new kind of grammar coverage in their approach to test compilers such as n-state path coverage <ref type="bibr" target="#b63">[64]</ref>, making this approach more general. Second, they develop a fully automatic tool to reduce a test suite, which first generates a test suite according to the used coverage criteria and then reduces this test suite using the proposed reduction approach.</p><p>In addition to excluding redundant test programs from a test suite, Groce et al. <ref type="bibr" target="#b48">[49]</ref> propose to reduce a test suite of a compiler by simplifying each test program but retaining all test programs. This approach is called cause reduction. Cause reduction is actually a generalization of delta debugging <ref type="bibr" target="#b127">[128]</ref>. It simplifies each test program by maintaining test coverage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">POST-PROCESSING OF TEST RESULTS</head><p>Once compiler testing has found test programs that trigger a compiler bug, the next step is to understand and fix these bugs. To facilitate this task, several research efforts focus on post-processing of test results. We discuss these efforts in three groups: test program reduction (presented in Section 6.1), duplicated bug identification (presented in Section 6.2), and compiler bug debugging (presented in Section 6.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Test Program Reduction</head><p>Test programs tend to be large and complex. Therefore, an important step before reporting a compiler bug to a compiler developer is to produce a small test program that still triggers the compiler bug, i.e., test program reduction. This is because small test programs can facilitate the debugging of compiler bugs for developers. This post processing is also encouraged by compiler developers. For example, in the documentation of LLVM, there is the following declaration: "...to narrow down the bug so that the person who fixes it will be able to find the problem more easily...."</p><p>Delta debugging is an approach to determining the minimal set of failure-inducing changes in a faulty program in general <ref type="bibr" target="#b127">[128]</ref>. Also, Zeller and Hildebrandt <ref type="bibr" target="#b128">[129]</ref> apply delta debugging to simplify tests and utilize delta debugging to isolate the difference between passing tests and failing tests. Furthermore, there are various delta debugging algorithms proposed in the literature <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b83">84]</ref>. However, they cannot effectively reduce test programs of compilers well, since they tend to get stuck in the local optima that are still too large. Besides, for some compilers such as C/C++ compilers, they often generate test programs with undefined behaviors, which are useless for those compilers.</p><p>To solve these problems, Regehr et al. <ref type="bibr" target="#b96">[97]</ref> leverage domain-specific knowledge to solve the local optimal problem and avoid undefined behaviors directly during reduction. More specifically, they design and implement three reducers for test programs of C compilers as follows: Pflanzer et al. <ref type="bibr" target="#b93">[94]</ref> further extend the C-Reduce test program reducer to OpenCL. That is, they provide an automated approach to reducing OpenCL test inputs triggering bugs. The key challenge is to detect undefined behaviors in an OpenCL kernel. To address this challenge, they build a new plugin (called ShadowKeeper) for Oclgrind <ref type="bibr" target="#b94">[95]</ref>, which is able to precisely detect accesses to data without initialization. In particular, the internal mechanics of the ShadowKeeper plugin borrow the ideas of the Memcheck plugin in Valgrind <ref type="bibr" target="#b105">[106]</ref> and MemorySanitizer in Clang <ref type="bibr" target="#b108">[109]</ref>.</p><p>The above-introduced reducers are specific to some single kind of test inputs (e.g., C programs or OpenCL kernels). Herfert et al. <ref type="bibr" target="#b55">[56]</ref> propose the generalized tree reduction algorithm, called GTR, to reduce any test inputs that are tree-structured, such as Python and JavaScript. This approach is independent of programming languages. Its input is a tree that has a property (e.g., to trigger a specific compiler bug) that should be preserved during reduction. Its output is a tree that has been reduced but still has the property. During the reduction process, GTR minimizes the whole tree by considering all nodes at a level, and then continues to the next level for further reduction. More specifically, GTR designs tree transformation rules and utilizes the delta debugging algorithm and a greedy algorithm for backtracking. The designed tree transformation rules are the key part of GTR, which performs reduction for a tree and then produces a new but smaller tree. In particular, GTR provides two transformation rules: (1) removing a node and all its children; (2) replacing a node with one of its children. Actually, GTR is easy to extend with additional transformation rules. Furthermore, their experimental study also demonstrates that GTR significantly outperforms the existing improved delta debugging algorithms <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b83">84]</ref> for reducing tree-structured test inputs.</p><p>Sun et al. <ref type="bibr" target="#b112">[113]</ref> propose another general framework, called Perses, for test program reduction. Besides the above-mentioned tree-structured test inputs, it can be used to reduce other structured test inputs, e.g., reducing structured text formats in the security domain. The key insight of Perses is to take the formal syntax of a programming language as a guide for reduction. It ensures to consider only smaller and syntactically valid program variants in each step of reduction so the syntactically invalid program variants can be avoided and the corresponding efforts can be saved.</p><p>Holmes et al. <ref type="bibr" target="#b59">[60]</ref> define the problem of slippage in test input reduction (including test program reduction), which means that the bug triggered by a test input is different from that by the test input after reduction. Slippage may be harmful or beneficial, since the bug triggered by the reduced test input may be an already-known one or a new one. To avoid harmful slippage and induce beneficial slippage, they propose to produce a set of reduced test inputs for a given bug-triggering test input, instead of producing only one reduced test input. More specifically, they propose two approaches, comb-block and multi-ddmin, based on the delta debugging algorithm ddmin <ref type="bibr" target="#b127">[128,</ref><ref type="bibr" target="#b128">129]</ref>. The former blocks some components during delta debugging, while the latter randomizes the checking order for smaller test inputs during delta debugging to produce a set of different reduced test inputs.</p><p>Christi et al. <ref type="bibr" target="#b32">[33]</ref> investigate the impact of delta debugging for test input reduction (including test program reduction) on spectrum-based bug localization that localizes bugs based on statistics of coverage status of each program element during failing and passing executions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b120">121]</ref>. The experimental results show the advantage of using reduced failing test inputs on spectrum-based bug localization compared with using original failing test inputs, indicating that it is necessary to use delta debugging to reduce failing test inputs before spectrum-based bug localization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Duplicated Bug Identification</head><p>Since random testing, or fuzzing, is one of the most important approaches to detecting compiler bugs, those fuzzers suffer from a serious problem: A fuzzer may produce a large number of bugtriggering test programs during the testing time of one night, and many of those test programs actually trigger the same compiler bug. Such redundant bug-triggering test programs enhance the debugging difficulty for developers, since compiler developers are expensive and limited in numbers. In particular, the existing work <ref type="bibr" target="#b29">[30]</ref> reports that some industrial compiler developers stop using Csmith due to this problem. Therefore, it is necessary to identify such duplication before reporting compiler bugs.</p><p>Chen et al. <ref type="bibr" target="#b29">[30]</ref> formulate this problem as the fuzzer taming problem, which is that, given a large number of bug-triggering test programs, it is essential to rank these test programs so the test programs triggering distinct bugs are ranked at the early positions in the list. Moreover, there is also an additional condition: If a test program triggering compiler bugs is marked as an undesirable one previously, the test program should be ranked at the late position in the list. To tame compiler fuzzers, Chen et al. <ref type="bibr" target="#b29">[30]</ref> propose to distinguish test programs that trigger distinct compiler bugs through defining a set of distance functions to measure the similarity between test programs (based on a set of identified static and dynamic characteristics of test programs). It then ranks these test programs based on the furthest point first algorithm, which iteratively selects the next test program that has the maximum distance with the nearest one among all the existing selected test programs.</p><p>The key insight of this approach is that, if two test programs have a farther distance, then they have a larger possibility to trigger two distinct bugs.</p><p>Holmes and Groce <ref type="bibr" target="#b58">[59]</ref> further solve the fuzzer taming problem by proposing a mutation-based metric to measure the similarity between two bug-triggering test programs. The key insight is that, if two bug-triggering test programs become passing due to the same mutant of the compiler under test, then they are more likely to trigger the same compiler bug. More specifically, they first collect a set of mutants of the compiler under test and record which mutants make the test program passing for each bug-triggering test program. Then, they calculate the Jaccard distance between bug-triggering test programs based on the recorded information. Finally, they rank bug-triggering test programs based on the furthest point first algorithm like Chen et al. <ref type="bibr" target="#b29">[30]</ref> so the test programs that are more likely to trigger different compiler bugs are ranked higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Compiler Bug Debugging</head><p>After receiving compiler bug reports, debugging these bugs is the next step, which is also important and challenging <ref type="bibr" target="#b101">[102]</ref>.</p><p>Some work focuses on finding the bug-triggering part of a test program and the bug-triggering condition to facilitate the debugging of compiler bugs. For example, Caron and Darnell <ref type="bibr" target="#b17">[18]</ref> develop a tool called Bugfind to debug compiler bugs, which can isolate modules (i.e., files) that are not optimized correctly when multi-module projects are used as test programs. In particular, this tool targets at optimizing compilers, which have one or more levels of optimization. Compared to previously existing approaches, e.g., binary search by hand and semi-automated shell scripts, the Bugfind tool is automated and requires minimal human intervention. Moreover, it finds the failing modules in a minimal amount of time. To be specific, Bugfind first divides a failing multimodule test program into small files that can be compiled separately, and then turns up or down the optimization level for each file to find the files causing incorrect optimizations.</p><p>Whalley <ref type="bibr" target="#b118">[119]</ref> proposes a tool, called upoiso, to automatically identify the first transformation within a function that causes incorrect results. In particular, this tool targets both optimization bugs and non-optimization bugs in the upo compiler system. For optimization bugs, it utilizes the binary search to identify the first transformation causing incorrect results by limiting the number of transformations applied to a specified function. For non-optimization bugs, it utilizes the binary search to identify the first function containing incorrect instructions by modifying the labels in the native assembly files generated by a native compiler.</p><p>Besides, some work focuses on providing more sufficient execution information to facilitate the debugging of compiler bugs. Sloane <ref type="bibr" target="#b101">[102]</ref> proposes Noosa to debug the compilers that are generated using the Eli generation system. Noosa conducts the visualization for the compiler execution when processing test programs. The aim of Noosa is to make the debugging process conduct at the specification level. That is, it makes the implementation details of compilers be hidden, and thus the compiler execution can be understood even if there is no knowledge about it.</p><p>Hemmert et al. <ref type="bibr" target="#b54">[55]</ref> propose to debug the SC (short for Sea Cucumber) synthesizing compiler at the source-code level. The synthesizing compilers make the debugging and verification of the operation of the hardware applications harder. The proposed debugger conducts the mapping between the executing circuit state and the source code. Such an approach not only utilizes the high efficiency of hardware, but also displays the messages of debugging at the original source code, which is helpful for users to conduct fast debugging of the circuit.</p><p>Ogata et al. <ref type="bibr" target="#b90">[91]</ref> propose to debug a Just-In-Time (JIT) compiler by replaying the compilation based on two compilers. The approach is named replay JIT compilation. In particular, the first compiler used in the approach is the state-saving compiler, which is responsible to record all the runtime information in a normal compilation. The second compiler is the replaying compiler, which is responsible to replay the compilation in the debugging mode to output diagnostic information.</p><p>Chang et al. <ref type="bibr" target="#b19">[20]</ref> propose to facilitate the debugging of native-code compilers in addition to bytecode compilers by conducting the assembly-language level type checking. More specifically, the assembly-language level checking is extended from the intermediate-language level checking. The extension additionally maintains a lattice of dependent types, which actually enhances the complexity of the approach. Even so, it provides the opportunity to debug native-code compilers through the checking technique.</p><p>Furthermore, Holmes and Groce <ref type="bibr" target="#b58">[59]</ref> propose to utilize the mutation-based metric presented in Section 6.2 to help localize compiler bugs. The localization technique is called Repair. For a bugtriggering test program, Repair calculates a score for each mutant that makes the test program passing, and then ranks these mutants so the statements changed by the mutants ranked higher are more likely to be suspicious. The key insight is that, if a mutant can only make the bugtriggering test programs-which are similar to the given bug-triggering test program based on the mutation-based metric, passing-the mutant should be ranked higher. More specifically, the score of a mutant is calculated based on the maximum distance between the given bug-triggering test program and other bug-triggering test programs that the mutant makes passing.</p><p>Recently, Chen et al. <ref type="bibr" target="#b24">[25]</ref> propose an approach, called DiWi, to localizing compiler bugs by transforming the problem of compiler bug localization into a search problem, i.e., searching for a set of effective witness test programs that are able to eliminate innocent compiler files from suspects (the compiler files involved when compiling the failing test program). More specifically, DiWi designs a set of witnessing mutation rules and proposes a heuristic-based search strategy to generate such a set of effective witness test programs based on a given failing test program. Then, DiWi isolates compiler bugs by comparing the coverage between the set of witness test programs and the given failing test program following the practice of spectrum-based fault localization <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EMPIRICAL STUDIES ON COMPILER TESTING</head><p>In addition to developing new approaches that address technical challenges, the compiler testing research field is benefiting from several empirical studies. These studies systematically explore compiler bugs and compiler testing approaches, providing insights on compiler testing.</p><p>Chen et al. <ref type="bibr" target="#b25">[26]</ref> conduct a comparison study on three mainstream compiler testing approaches, including randomized differential testing (abbreviated as RDT), different optimization levels (abbreviated as DOL), and equivalence modulo inputs (abbreviated as EMI) <ref type="bibr" target="#b71">[72]</ref>. Here, RDT refers to the approach testing compiler using the cross-compiler strategy, whereas DOL refers to that using cross-optimization strategy. To compare them precisely, they propose Correcting Commits, a novel measurement that searches for the commits correcting the detected bugs and uses such commit number to estimate the bug number. They prepare a fixed sequence of test programs generated by Csmith and apply them to GCC and LLVM, respectively, recording compiler bugs (measured by Correcting Commits) revealed by each approach during 90 hours. Following this experimental methodology, this study gets some findings. For example, DOL performs the most effective on the bugs related to compiler optimizations, RDT performs the most effective on the bugs not related to optimizations, and EMI complements them due to its effectiveness on detecting unique bugs. Moreover, the study investigates the factors impacting a compiler testing approach, including its efficiency, its used test oracle, and kind of test programs. They find each of the factors significantly impacts a compiler testing approach. In particular, the efficiency of the approach has the most impact, while the impact of the kind of test programs is the least. Besides, this study also discusses the combination of these approaches and suggests their usage order to be DOL, RDT, and EMI.</p><p>Lidbury et al. <ref type="bibr" target="#b76">[77]</ref> perform an experimental study to investigate the effectiveness of RDT and EMI on a new application, i.e., OpenCL compilers. To apply RDT to OpenCL compilers, they build a tool called CLsmith using Csmith <ref type="bibr" target="#b122">[123]</ref> to randomly generate test programs (i.e., OpenCL kernels) for OpenCL compilers. In particular, CLsmith provides several strategies for the random generation. Moreover, to apply EMI to OpenCL compilers, they propose to first inject dead code into OpenCL kernels and then apply the EMI technique (i.e., Orion <ref type="bibr" target="#b71">[72]</ref>) to generate equivalent variants. Based on the two testing approaches, they apply inputs randomly generated by CLsmith to four versions of OpenCL in its 21 configurations (differ in devices and drivers), recording bugs revealed in a specified time-out. According to the empirical study, more than 50 OpenCL compiler bugs are identified and reported, most of which are in commercial implementations.</p><p>Sun et al. <ref type="bibr" target="#b111">[112]</ref> conduct an empirical study to investigate the characteristics of compiler bugs, aiming to facilitate the understanding of compiler bugs. In particular, they study GCC revisions from August 1999 to October 2015 and LLVM revisions from October 2003 to October 2015 and choose the revision that is a fix to a bug based on its commit message. Through this process, this work collects 39,890 GCC bugs and 12,842 LLVM bugs. Based on the two bug repositories, this study investigates four important aspects of compiler bugs, including where the bugs occur, which characteristics the test programs triggering bugs and bug fixes have, how long the bugs can be detected and fixed, and what the cases of bug priorities are. Based on their results of the four aspects, they get some findings. First, the component processing C++ programs is the most buggy one, which should attract more research attention. Second, the test programs triggering bugs usually have a small size, indicating that we should produce small but complex test programs for compiler testing. Third, the fixes of bugs tend to involve only one file, and the size of these fixes tend to be small, indicating that we can conduct testing for a specific component. Finally, debugging the bugs usually takes a few months due to the complexity of compilers.</p><p>Groce et al. <ref type="bibr" target="#b49">[50]</ref> conduct an empirical study to investigate the relationships between what a test program contains and what the compiler does in testing. They first define "triggers" and "suppressors," where the former means that certain test-program features can make a test program more likely to explore some compiler behaviors (such as bugs and coverage entities) in testing, while the latter means that certain test-program features can make a test program less likely to explore some compiler behaviors. In particular, this study focuses on investigating how test-program features can suppress a compiler behavior, including the frequency and degree of "suppressors" in compiler testing. The study demonstrates that suppressors are quite common, and many features of test programs act as suppressors for some compiler behaviors in testing. They further discuss the causes and impacts of "suppressors." For example, some test-program features acting as suppressors have to be omitted in test programs to increase the probability of triggering some bugs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">OUTLOOK AND CHALLENGES FOR FUTURE WORK</head><p>Although significant progress has been made in the area of compiler testing, the problem is far from being solved. In this section, we highlight some challenges that future work may address.</p><p>Efficiency of Compiler Testing. Though some efforts have been made to enhance the efficiency of compiler testing, compiler testing is still a time-consuming task. Further efforts are still needed to enhance the efficiency of compiler testing.</p><p>One efficiency bottleneck is that a bug is often discovered multiple times by different test programs in compiler testing. This causes not only an efficiency problem but also a large amount of extra work for developers to review and classify the duplicated test programs. It would be desirable to have an approach that generates test programs triggering only new bugs, possibly by using the feedback from known bugs-inducing test programs. Chen et al. <ref type="bibr" target="#b22">[23]</ref> have shown that by extracting feature vectors from existing test programs, better prioritization of test programs can be achieved. Such approaches may be integrated into the generation process to enhance test efficiency. Similarly, Chen et al. <ref type="bibr" target="#b21">[22]</ref> have shown that learning from existing bug-inducing test programs could help us to recognize future bug-inducing test programs for test program prioritization. Such approaches may also be integrated into test generation to directly generate programs that have larger possibilities to trigger bugs.</p><p>Compiler Verification. Compiler verification is another family of attempts to eliminate bugs in compilers <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b75">76]</ref>. However, due to the high cost of developing formal specifications and proofs, verification techniques usually can be applied only to a small part of compilers and guarantee a selection of properties. How testing can complement verification may be another research direction, where the focus could be the parts of a compiler that have not been verified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalizability of Approaches.</head><p>Though tremendous progress has been made in automating compiler testing, most of these efforts are specific to one particular programming language. In particular, many existing approaches are specific to C. For example, one of the most widely used tools for test program generation, Csmith <ref type="bibr" target="#b122">[123]</ref>, is designed only for generating C programs. Migrating such tools to other programming languages is not easy. Csmith has been carefully designed so no program triggering undefined behaviors will be generated, and a bunch of static analysis has been integrated into the generation process to prevent such programs. To migrate such tools to other languages, we need to carefully understand the rules for valid programs in other programming languages and design static analyses to best approximate such rules at generation time. These tasks require expert knowledge in program analysis and semantics and are not easy to perform. Therefore, future research could focus on providing approaches that can be generalized to different compilers: For example, by allowing easy specification of valid programs or by deriving specifications automatically from compilers, and deducing generation procedures from the specifications.</p><p>Recent work on learning-based test program generation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b92">93]</ref>, which can be easily applied to different programming languages, is the first step in that direction.</p><p>Another related problem is whether the current approaches can generalize to other software systems that also take programs as inputs, such as refactoring tools <ref type="bibr" target="#b34">[35]</ref>, debuggers <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b115">116]</ref>, static bug detectors, code search engines, and so on. More research is required to understand the difference between these tools and compilers and what approaches could be generalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coverage of Bugs.</head><p>Current automatic approaches for constructing test programs and test oracles can only cover a subset of all possible test programs and oracles, therefore covering only a subset of bugs among all compiler bugs. In test program generation, to generate only valid programs without undefined behaviors, tools like Csmith <ref type="bibr" target="#b122">[123]</ref> rely on static analysis to approximate the boundary of a valid program, and thus cannot generate all valid programs. Also, some bugs may require invalid programs to trigger them. Similarly, the automatic oracles mainly rely on equivalence relations between programs/compilers, and thus cannot be used to discover bugs that require oracles beyond equivalence relations.</p><p>Therefore, future studies are needed to understand test programs and test oracles beyond the current spaces. While generating invalid programs is easy, understanding which invalid programs are likely to trigger bugs may not be easy. Programs with undefined behaviors or non-deterministic behaviors could also be taken into account. In the space of test oracles, we may consider relations that are not equivalence relations. For example, when optimizing the program size, the program size should become smaller than that before optimization.</p><p>Handling the Discovered Bugs. While a lot of research efforts have been put into discovering bugs, the processing of test results has received relatively little attention. Here, we highlight some challenges in bug handling.</p><p>One of the open challenges is which test programs should be brought to compiler developers. As mentioned before, existing research <ref type="bibr" target="#b29">[30]</ref> has studied how to identify test programs that trigger the same compiler bug. However, even with these approaches, redundant test programs still exist and more studies are needed to understand whether they can be further reduced. A similar problem is the prioritization of bug reports. In early development stages of a compiler, a testing process may produce many bugs-how to prioritize the bugs and report to developers remain open problems.</p><p>Another challenge is the readability of test programs. While several attempts <ref type="bibr" target="#b96">[97]</ref> have been made to reduce test programs, smaller programs do not necessarily mean better readability. How to model readability and how to achieve better readability are problems left to be solved.</p><p>Due to the complexity of compilers, fixing compiler bugs is not easy. Recently, significant progress has been made in automatic program repair. Can compiler bugs be repaired automatically? Can existing repair approaches be applied to compilers? Additional research is needed here to answer these questions.</p><p>Benchmarks. Currently, there is no established benchmark of compiler bugs for evaluating the effectiveness of compiler testing. Existing studies often spend huge efforts to discover bugs in existing compilers during their evaluation <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26]</ref>. Agreeing on a common benchmark could further promote the development of compiler testing research. A benchmark makes it much easier to measure the effectiveness of a newly proposed compiler testing approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>This article provides a survey of approaches for testing compilers. Given the importance of compilers as a basic part of every developer's tool chain and the disastrous consequences of compiler bugs, testing compilers is an extremely important topic. Recent years have seen significant improvements and activities in the field of compiler testing. Our article enables interested outsiders</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of topics covered in this article.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Compiler testing papers from 1970 to 2018.</figDesc><graphic coords="5,94.95,249.46,295.69,124.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Paper distribution on each research perspective.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Overview of Approaches for Constructing Test Programs</figDesc><table><row><cell cols="2">Constructing Test Programs (Section 3)</cell><cell>Approach</cell></row><row><cell cols="2">Manually Constructing Test Programs (Section 3.2)</cell><cell>Callahan et al. [17], Dongarra et al.</cell></row><row><cell></cell><cell></cell><cell>[44], Wolf et al. [120]</cell></row><row><cell>Test Program</cell><cell>Grammar-directed Approaches</cell></row><row><cell>Generation</cell><cell>(Section 3.3.1)</cell></row><row><cell>(Section 3.3)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Summary of the Programming Languages Targeted by Different Test-program Construction Approaches</figDesc><table><row><cell>Language</cell><cell>Approach</cell></row><row><cell>C/C++</cell><cell>Eide and Regehr [47], Yang et al. [123], Nagai et al. [87], Nagai et al. [88], Lindig</cell></row><row><cell></cell><cell>[78, 79], Groce et al. [51], Le et al. [72], Le et al. [73], Morisset et al. [85], Zhang</cell></row><row><cell></cell><cell>et al. [131], Sun et al. [111], Amodio et al. [4], Alipour et al. [3]</cell></row><row><cell cols="2">JavaScript Holler et al. [58], Groce et al. [49], Patra and Pradel [93], Bastani et al. [8]</cell></row><row><cell>PL/I</cell><cell>Hanford [52]</cell></row><row><cell>Ada</cell><cell>Duncan and Hutchison [45], Austin et al. [6], Mandl [80]</cell></row><row><cell>Fortran</cell><cell>Callahan et al. [17], Dongarra et al. [44], Burgess and Saidi [16]</cell></row><row><cell>Java</cell><cell>Sirer et al. [108], Boujarwah et al. [14], Yoshikawa [125], Chen et al. [31]</cell></row><row><cell>Algol</cell><cell>Houssais [61]</cell></row><row><cell>APL</cell><cell>Ching and Katz [32]</cell></row><row><cell>Arden</cell><cell>Wolf et al. [120]</cell></row><row><cell>Haskell</cell><cell>Palka et al. [92]</cell></row><row><cell>Lusture</cell><cell>Garoche et al. [48]</cell></row><row><cell>mpC</cell><cell>Kalinov et al. [64, 65]</cell></row><row><cell>OCaml</cell><cell>Midtgaard et al. [83]</cell></row><row><cell>Pascal</cell><cell>Burgess [34], Bazzichi and Spadafora [9]</cell></row><row><cell>PLZ/SYS</cell><cell>Bazzichi and Spadafora [9]</cell></row><row><cell>Python</cell><cell>Bastani et al. [8]</cell></row><row><cell>Ruby</cell><cell>Bastani et al. [8]</cell></row><row><cell>Rust</cell><cell>Dewey et al. [41]</cell></row><row><cell>Scala</cell><cell>Zhang et al. [131]</cell></row><row><cell>GLSL</cell><cell>Donaldson et al. [42]</cell></row></table><note><p>on automated test program generation, and Section 3.4 discusses mutation-based test program construction approaches. Because automated approaches for test program construction can create a large number of test programs with little effort, they are widely used in compiler testing. Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Usage of the Three Differential-testing Strategies in Compiler Testing</figDesc><table><row><cell>Paper</cell><cell>Cross-compiler Cross-optimization Cross-version</cell></row><row><cell>Sheridan [107]</cell><cell>X</cell></row><row><cell>Ofenbeck et al. [90]</cell><cell>X</cell></row><row><cell>Sassa and Sudosa [104]</cell><cell>X</cell></row><row><cell>Morisset et al. [85]</cell><cell>X</cell></row><row><cell>Le et al. [74]</cell><cell>X</cell></row><row><cell>Béra et al. [10]</cell><cell>X</cell></row><row><cell>Hawblitzel et al. [54]</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table 4 in more detail.</figDesc><table><row><cell>A Survey of Compiler Testing</cell><cell>4:21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Metamorphic Relations Used in Compiler Testing</figDesc><table><row><cell>Paper</cell><cell>Metamorphic</cell><cell>How to construct metamorphic relations</cell></row><row><cell></cell><cell>relation</cell><cell></cell></row><row><cell>Tao et al. [114]</cell><cell cols="2">Equivalence relation Constructing equivalent expressions, assignment</cell></row><row><cell></cell><cell></cell><cell>blocks, and submodules</cell></row><row><cell>Le et al. [72]</cell><cell>Equivalence relation</cell><cell>Deleting code in the dead regions under the set of</cell></row><row><cell></cell><cell>under a given set of</cell><cell>test inputs</cell></row><row><cell></cell><cell>test inputs</cell><cell></cell></row><row><cell>Le et al. [73]</cell><cell>Equivalence relation</cell><cell>Deleting and inserting code in the dead regions</cell></row><row><cell></cell><cell>under a given set of</cell><cell>under the set of test inputs</cell></row><row><cell></cell><cell>test inputs</cell><cell></cell></row><row><cell>Sun et al. [111]</cell><cell>Equivalence relation</cell><cell>Inserting code in both the live and dead regions</cell></row><row><cell></cell><cell>under a given set of</cell><cell>by synthesizing valid semantic-preserving code</cell></row><row><cell></cell><cell>test inputs</cell><cell>snippets under the set of test inputs</cell></row><row><cell>Donaldson and</cell><cell cols="2">Equivalence relation Injecting dead code into test programs</cell></row><row><cell>Lascu [43]</cell><cell></cell><cell></cell></row><row><cell>Nakamura and</cell><cell cols="2">Equivalence relation Applying a set of equivalent transformation rules</cell></row><row><cell>Ishiura [89]</cell><cell></cell><cell>on test programs</cell></row><row><cell>Donaldson et al.</cell><cell cols="2">Equivalence relation Applying a set of (essentially)</cell></row><row><cell>[42]</cell><cell></cell><cell>semantics-preserving transformations on</cell></row><row><cell></cell><cell></cell><cell>high-value graphics shaders</cell></row><row><cell>Samet [99-101]</cell><cell cols="2">Equivalence relation Converting a source program and the object</cell></row><row><cell></cell><cell></cell><cell>program into an intermediate representation,</cell></row><row><cell></cell><cell></cell><cell>respectively</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>•</head><label></label><figDesc>The first one is called Seq-Reduce test-program reducer, which only works for test programs generated by Csmith. Since test programs generated by Csmith are determined by a sequence of integers produced by a pseudo-random number generator, the Seq-Reduce testprogram reducer iteratively generates the variant that still triggers the bug but is smaller than the smallest variant produced previously, by randomly modifying the sequence. • The second one is called Fast-Reduce test-program reducer, which also only works for test programs generated by Csmith. It supports a series of transformation rules such as deadcode elimination and exploiting path divergence. These rules are based on the information of both the static structures of the generated test program and its runtime behaviors. • The third one is called C-Reduce, which works for any test program for C compilers. The C-Reduce test program reducer applies a set of pluggable transformations performing operations for reduction to a test program, until the test program cannot be reduced anymore (i.e., reaching a global fixpoint). It is the most effective one among the three reducers for reducing test programs triggering C compiler bugs. In particular, their experimental results demonstrate that the reduced test programs produced by C-Reduce are smaller than those produced by their other two reducers (i.e., Seq-Reduce and Fast-Reduce) over 25× on average.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://blog.thetaphi.de/2011/07/real-story-behind-java-7-ga-bugs.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://arstechnica.com/information-technology/2015/09/apple-scrambles-after-40-malicious-xcodeghost-apps-hauntapp-store/. ACM Computing Surveys, Vol. 53, No. 1, Article 4. Publication date: February 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://llvm.org/docs/Passes.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://lcamtuf.coredump.cx/afl/. ACM Computing Surveys, Vol.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>53, No. 1, Article 4. Publication date: February 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>https://dblp.uni-trier.de. ACM Computing Surveys, Vol. 53, No. 1, Article 4. Publication date: February 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>ACM Computing Surveys, Vol. 53, No. 1, Article 4. Publication date: February 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_7"><p>http://openjdk.java.net/jtreg/writetests.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_8"><p>https://gcc.gnu.org/wiki/HowToPrepareATestcase.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_9"><p>https://www.chromium.org/chromium-os/testing/test-suites. ACM Computing Surveys, Vol. 53, No. 1, Article 4. Publication date: February 2020.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the National Key Research and Development Program of China under Grant No.2017YFB1001803 and the National Natural Science Foundation of China under Grant Nos. 61672047, 61861130363, 61872008, and 61828201. This work was also supported by BMWF/Hessen within CRISP and by the German Research Foundation within the ConcSys and Perf4JS projects. Yingfei Xiong and Dan Hao are the corresponding authors. This work was mainly done when Junjie Chen was at Peking University.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>to obtain an overview of this thriving field and may enable experts to fill any gaps in their knowledge of the state-of-the-art. Based on our discussion of existing work, we conclude compiler testing has evolved into a mature field that has already made significant impacts on real-world compiler development.</p><p>Despite all the advances on compiler testing, there remain several interesting challenges to be addressed in the future, including how to generalize existing approaches and how to further improve both their effectiveness and efficiency. We hope that our survey allows researchers to make progress towards these goals.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spectrum-based multiple fault localization</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Zoeteweij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjan</forename><forename type="middle">J C</forename><surname>Van Gemund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Automated Software Engineering</title>
		<meeting>the International Conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="88" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the accuracy of spectrum-based fault localization</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Zoeteweij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjan</forename><forename type="middle">J C</forename><surname>Van Gemund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION</title>
		<meeting>the Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generating focused random tests using directed swarm testing</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arpit</forename><surname>Christi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Symposium on Software Testing and Analysis</title>
		<meeting>the 25th International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="70" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Neural attribute machines for program generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Amodio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
		<idno>arxiv:cs.AI/1705.09231</idno>
		<imprint>
			<date type="published" when="2017-05">2017. May 2017</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Iterative delta debugging</title>
		<author>
			<persName><forename type="first">Cyrille</forename><surname>Artho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Softw. Tools Technol. Transf</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="223" to="246" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An Ada program test generator</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Wilkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on TRI-Ada &apos;91: Today&apos;s Accomplishments; Tomorrow&apos;s Expectations (TRI-Ada&apos;91</title>
		<meeting>the Conference on TRI-Ada &apos;91: Today&apos;s Accomplishments; Tomorrow&apos;s Expectations (TRI-Ada&apos;91</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="320" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding missed compiler optimizations by differential testing</title>
		<author>
			<persName><forename type="first">Gergö</forename><surname>Barany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Compiler Construction</title>
		<meeting>the 27th International Conference on Compiler Construction</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Synthesizing program input grammars</title>
		<author>
			<persName><forename type="first">Osbert</forename><surname>Bastani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Aiken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Conference on Programming Language Design and Implementation</title>
		<meeting>the 38th Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="95" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An automatic generator for compiler testing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bazzichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Spadafora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="343" to="353" />
			<date type="published" when="1982">1982. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Practical validation of bytecode to bytecode JIT compiler dynamic deoptimization</title>
		<author>
			<persName><forename type="first">Clément</forename><surname>Béra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliot</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Ducasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Obj. Technol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A new methodology for generating test cases for a programming language compiler</title>
		<author>
			<persName><forename type="first">M</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="46" to="56" />
			<date type="published" when="1983">1983. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic generation of random self-checking test cases</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">U</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Syst. J</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="229" to="245" />
			<date type="published" when="1983">1983. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Compiler test case generation methods: A survey and assessment</title>
		<author>
			<persName><forename type="first">Abdulazeez</forename><forename type="middle">S</forename><surname>Boujarwah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kassem</forename><surname>Saleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Softw. Technol</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="617" to="625" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Testing syntax and semantic coverage of Java language compilers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abdulazeez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kassem</forename><surname>Boujarwah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jehad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><surname>Al-Dallal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Softw. Technol</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="15" to="28" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The automated generation of test cases for compilers</title>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">J</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Test. Verif. Rel</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="81" to="99" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The automatic generation of test cases for optimizing Fortran compilers</title>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">J</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Softw. Technol</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="111" to="119" />
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Vectorizing compilers: A test suite and results</title>
		<author>
			<persName><forename type="first">D</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE Conference on Supercomputing</title>
		<meeting>the ACM/IEEE Conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bugfind: A tool for debugging optimizing compilers</title>
		<author>
			<persName><forename type="first">Jacqueline</forename><forename type="middle">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Darnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="17" to="22" />
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An automated approach to reducing test suites for testing retargeted C compilers for embedded systems</title>
		<author>
			<persName><forename type="first">Heung</forename><surname>Seok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chae</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Gyun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeon</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Won</forename><surname>Ho Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Syst. Softw</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="2053" to="2064" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Type-based verification of assembly language for compiler debugging</title>
		<author>
			<persName><forename type="first">Bor-Yuh Evan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Chlipala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">C</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">R</forename><surname>Schneck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN International Workshop on Types in Languages Design and Implementation</title>
		<meeting>the ACM SIGPLAN International Workshop on Types in Languages Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="91" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to accelerate compiler testing</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Software Engineering</title>
		<meeting>the 40th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="472" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to prioritize test programs for compiler testing</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanwei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Software Engineering</title>
		<meeting>the 39th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="700" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Test case prioritization for compilers: A text-vector based approach</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanwei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Software Testing, Verification and Validation</title>
		<meeting>the IEEE International Conference on Software Testing, Verification and Validation</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">How do assertions impact coverage-based test-suite reduction?</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanwei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Software Testing, Verification and Validation</title>
		<meeting>the IEEE International Conference on Software Testing, Verification and Validation</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="418" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Compiler bug isolation via effective witness test program generation</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</title>
		<meeting>the 27th Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="223" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An empirical comparison of compiler testing techniques</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering</title>
		<meeting>the 38th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="180" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">History-guided configuration diversification for compiler test-program generation</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guancheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Automated Software Engineering</title>
		<meeting>the 34th International Conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coverage prediction for accelerating compiler testing</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guancheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Softw. Eng</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Metamorphic Testing: A New Approach for Generating Next Test Cases</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsong</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shing</surname></persName>
		</author>
		<author>
			<persName><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><surname>Yiu</surname></persName>
		</author>
		<idno>HKUST-CS98-01</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Hong Kong</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Hong Kong University of Science and Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Taming compiler fuzzers</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weng-Keen</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoli</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="197" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Coverage-directed differential testing of JVM implementations</title>
		<author>
			<persName><forename type="first">Yuting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianjun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="85" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The testing of an APL compiler</title>
		<author>
			<persName><forename type="first">Wai-Mee</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on APL</title>
		<meeting>the International Conference on APL</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reduce before you localize: Delta-debugging and spectrum-based fault localization</title>
		<author>
			<persName><forename type="first">Arpit</forename><surname>Christi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">Lyle</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Software Reliability Engineering Workshops</title>
		<meeting>the International Symposium on Software Reliability Engineering Workshops</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="184" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards the automatic generation of executable programs to test a Pascal compiler</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Burgess</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automated testing of refactoring engines</title>
		<author>
			<persName><forename type="first">Brett</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Dig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kely</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darko</forename><surname>Marinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering</title>
		<meeting>the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="185" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Compiler verification: A bibliography</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maulik</surname></persName>
		</author>
		<author>
			<persName><surname>Dave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGSOFT Softw. Eng. Notes</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2" to="2" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Chromium developers</title>
		<ptr target="https://www.chromium.org/chromium-os/testing/test-suites" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<ptr target="https://gcc.gnu.org/onlinedocs/gccint/Testsuites.html#Testsuites" />
		<title level="m">GCC developers</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>GCC Testsuites</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<ptr target="https://llvm.org/docs/TestingGuide.html" />
		<title level="m">LLVM Testing Infrastructure Guide</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>LLVM developers</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">OpenJDK developers</title>
		<ptr target="http://openjdk.java.net/jtreg" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fuzzing the Rust typechecker using CLP (T)</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Dewey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Roesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Hardekopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Automated Software Engineering</title>
		<meeting>the 30th International Conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="482" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automated testing of graphics shader compilers</title>
		<author>
			<persName><forename type="first">Alastair</forename><forename type="middle">F</forename><surname>Donaldson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugues</forename><surname>Evrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Lascu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Thomson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Proceedings of the ACM on Programming Languages</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>OOPSLA</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Metamorphic testing for (graphics) compilers</title>
		<author>
			<persName><forename type="first">Alastair</forename><forename type="middle">F</forename><surname>Donaldson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Lascu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on Metamorphic Testing</title>
		<meeting>the 1st International Workshop on Metamorphic Testing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="44" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Parallel loops-A test suite for parallelizing compilers: Description and example results</title>
		<author>
			<persName><forename type="first">Jack</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Furtney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1247" to="1255" />
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Using attributed grammars to test designs and implementations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hutchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Software Engineering</title>
		<meeting>the 5th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="170" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<author>
			<persName><surname>Ecmascript</surname></persName>
		</author>
		<ptr target="https://github.com/tc39/test262" />
	</analytic>
	<monogr>
		<title level="m">ECMAScript Test Suite</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">262</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Volatiles are miscompiled, and what to do about it</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM International Conference on Embedded Software (EMSOFT&apos;08)</title>
		<meeting>the 8th ACM International Conference on Embedded Software (EMSOFT&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Testing-based compiler validation for synchronous languages</title>
		<author>
			<persName><forename type="first">Pierre-Loïc</forename><surname>Garoche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Falk</forename><surname>Howar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Temesghen</forename><surname>Kahsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Thirioux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NASA Formal Methods Symposium</title>
		<meeting>the NASA Formal Methods Symposium</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="246" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cause reduction: Delta debugging, even without bugs</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Test. Verif. Rel</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="40" to="68" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Help, help, I&apos;m being suppressed! The significance of suppressors in software testing</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Software Reliability Engineering</title>
		<meeting>the International Symposium on Software Reliability Engineering</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="390" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Swarm testing</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Software Testing and Analysis</title>
		<meeting>the International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="78" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Automatic generation of test cases</title>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">V</forename><surname>Hanford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Syst. J</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="242" to="257" />
			<date type="published" when="1970">1970. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Detecting arithmetic optimization opportunities for C compilers by randomly generated equivalent programs</title>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nagisa</forename><surname>Ishiura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPSJ Trans. Syst. LSI Des. Methodol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="21" to="29" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Will you still compile me tomorrow? Static cross-version compiler validation</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hawblitzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shuvendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kshama</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hammad</forename><surname>Pawar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sedar</forename><surname>Hashmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lakshan</forename><surname>Gokbulut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Detlefs</surname></persName>
		</author>
		<author>
			<persName><surname>Wadsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 9th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="191" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Source level debugger for the sea cucumber synthesizing compiler</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Scott</forename><surname>Hemmert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><forename type="middle">L</forename><surname>Tripp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><forename type="middle">L</forename><surname>Hutchings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preston</forename><forename type="middle">A</forename><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE Symposium on Field-programmable Custom Computing Machines</title>
		<meeting>the 11th IEEE Symposium on Field-programmable Custom Computing Machines</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="228" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Automatically reducing tree-structured test inputs</title>
		<author>
			<persName><forename type="first">Satia</forename><surname>Herfert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jibesh</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pradel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the 32nd IEEE/ACM International Conference on Automated Software Engineering</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Modernizing hierarchical delta debugging</title>
		<author>
			<persName><forename type="first">Renáta</forename><surname>Hodován</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ákos</forename><surname>Kiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation (A-TEST&apos;16</title>
		<meeting>the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation (A-TEST&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="31" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Fuzzing with code fragments</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Holler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st USENIX Conference on Security Symposium</title>
		<meeting>the 21st USENIX Conference on Security Symposium</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="445" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Causal distance-metric-based assistance for debugging after compiler fuzzing</title>
		<author>
			<persName><forename type="first">Josie</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Symposium on Software Reliability Engineering</title>
		<meeting>the 29th International Symposium on Software Reliability Engineering</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="166" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Mitigating (and exploiting) test reduction slippage</title>
		<author>
			<persName><forename type="first">Josie</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Groce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alipour</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation</title>
		<meeting>the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="66" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Verification of an Algol 68 implementation</title>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Houssais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Strathclyde ALGOL 68 Conference</title>
		<meeting>the Strathclyde ALGOL 68 Conference</meeting>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The Plum Hall Validation Suite</title>
		<ptr target="http://www.plumhall.com/stec1.html" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Plum Hall Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Input-based adaptive randomized test case prioritization: A local beam search approach</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Syst. Softw</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="91" to="106" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>C</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Coverage-driven automated compiler test suite generation</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kalinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kossatchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Petrenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Posypkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Shishkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Notes Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="500" to="514" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Using ASM specifications for compiler testing</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kalinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Kossatchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Petrenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Posypkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Shishkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Abstract State Machines 10th International Conference on Advances in Theory and Practice</title>
		<meeting>the Abstract State Machines 10th International Conference on Advances in Theory and Practice</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="415" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Random testing of compilers&apos; performance based on mixed static and dynamic code comparison</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Automating TEST Case Design, Selection, and Evaluation</title>
		<meeting>the 9th International Workshop on Automating TEST Case Design, Selection, and Evaluation</meeting>
		<imprint>
			<publisher>Kota Kitaura and Nagisa Ishiura</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="38" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Semantics of context-free languages</title>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Knuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Syst. Theor</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="127" to="145" />
			<date type="published" when="1968">1968. 1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Survey of compiler testing methods</title>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Kossatchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Posypkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Comput. Softw</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="10" to="19" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Affix grammars for programming languages</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Summer School on Attribute Grammars, Applications and Systems</title>
		<meeting>the International Summer School on Attribute Grammars, Applications and Systems</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="358" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Montages specifications of realistic programming languages</title>
		<author>
			<persName><forename type="first">Philipp</forename><forename type="middle">W</forename><surname>Kutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfonso</forename><surname>Pierantonio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Univ. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="416" to="442" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Grammar testing</title>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Lämmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Fundamental Approaches to Software Engineering</title>
		<meeting>the 4th International Conference on Fundamental Approaches to Software Engineering</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="201" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Compiler validation via equivalence modulo inputs</title>
		<author>
			<persName><forename type="first">Mehrdad</forename><surname>Vu Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Afshari</surname></persName>
		</author>
		<author>
			<persName><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="216" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Finding deep compiler bugs via guided stochastic program mutation</title>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Vu Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Object-Oriented Programming, Systems, Languages, and Applications</title>
		<meeting>the International Conference on Object-Oriented Programming, Systems, Languages, and Applications</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="386" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Randomized stress-testing of link-time optimizers</title>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Vu Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Software Testing and Analysis</title>
		<meeting>the International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="327" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Feedback-directed differential testing of interactive debuggers</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pradel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</title>
		<meeting>the 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="610" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Formal verification of a realistic compiler</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Leroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="107" to="115" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Many-core compiler fuzzing</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Lidbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Lascu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alastair</forename><forename type="middle">F</forename><surname>Donaldson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Conference on Programming Language Design and Implementation</title>
		<meeting>the 36th Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="65" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Find a compiler bug in 5 minutes</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Lindig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Symposium on Automated Analysis-Driven Debugging</title>
		<meeting>the ACM International Symposium on Automated Analysis-Driven Debugging</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Random testing of C calling conventions</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Lindig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Symposium on Automated Analysis-driven Debugging (AADEBUG&apos;05)</title>
		<meeting>the 6th International Symposium on Automated Analysis-driven Debugging (AADEBUG&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Orthogonal Latin squares: An application of experiment design to compiler testing</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1054" to="1058" />
			<date type="published" when="1985">1985. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<author>
			<persName><surname>William M Mckeeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Differential testing for software</title>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Basic English, a generative grammar for a part of English</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G L T</forename><surname>Meertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H A</forename><surname>Koster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<pubPlace>Talen, Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Effectdriven QuickChecking of compilers</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Midtgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Nygaard Justesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Kasting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flemming</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanne Riis</forename><surname>Nielson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Prog. Lang</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">HDD: Hierarchical delta debugging</title>
		<author>
			<persName><forename type="first">Ghassan</forename><surname>Misherghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Software Engineering</title>
		<meeting>the 28th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Compiler testing via a theory of sound optimisations in the C11/C++11 memory model</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Morisset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pankaj</forename><surname>Pawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><forename type="middle">Zappa</forename><surname>Nardelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">OptiScope: Performance accountability for optimizing compilers</title>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Peri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Symposium on Code Generation and Optimization</title>
		<meeting>the 7th International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="254" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Random testing of C compilers targeting arithmetic optimization</title>
		<author>
			<persName><forename type="first">Eriko</forename><surname>Nagai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hironobu</forename><surname>Awazu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Synthesis And System Integration of Mixed Information Technologies</title>
		<meeting>the Workshop on Synthesis And System Integration of Mixed Information Technologies</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
	<note>Nagisa Ishiura, and Naoya Takeda</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Reinforcing random testing of arithmetic optimization of C compilers by scaling up size and number of expressions</title>
		<author>
			<persName><forename type="first">Eriko</forename><surname>Nagai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nagisa</forename><surname>Ishiura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPSJ Trans. Syst. LSI Des. Methodol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Random testing of C compilers based on test program generation by equivalence transformation</title>
		<author>
			<persName><forename type="first">Kazuhiro</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nagisa</forename><surname>Ishiura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Asia Pacific Conference on Circuits and Systems (APCCAS&apos;16</title>
		<meeting>the IEEE Asia Pacific Conference on Circuits and Systems (APCCAS&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="676" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">RandIR: Differential testing for embedded compilers</title>
		<author>
			<persName><forename type="first">Georg</forename><surname>Ofenbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiark</forename><surname>Rompf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Püschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM SIGPLAN Symposium on Scala</title>
		<meeting>the 7th ACM SIGPLAN Symposium on Scala</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Replay compilation: Improving debuggability of a just-in-time compiler</title>
		<author>
			<persName><forename type="first">Kazunori</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamiya</forename><surname>Onodera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiyokuni</forename><surname>Kawachiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideaki</forename><surname>Komatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshio</forename><surname>Nakatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="241" to="252" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Testing an optimising compiler by generating random lambda terms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Michał</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koen</forename><surname>Pałka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Claessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Automation of Software Test</title>
		<meeting>the 6th International Workshop on Automation of Software Test</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="91" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Learning to Fuzz: Application-Independent Fuzz Testing with Probabilistic, Generative Models of Input Data</title>
		<author>
			<persName><forename type="first">Jibesh</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pradel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>TU Darmstadt, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Automatic test case reduction for OpenCL</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Pflanzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alastair</forename><forename type="middle">F</forename><surname>Donaldson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Lascu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on OpenCL</title>
		<meeting>the 4th International Workshop on OpenCL</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Oclgrind: An extensible OpenCL device simulator</title>
		<author>
			<persName><forename type="first">James</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Mcintosh-Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Workshop on OpenCL</title>
		<meeting>the 3rd International Workshop on OpenCL</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">A sentence generator for testing parsers</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Purdom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BIT Numer. Math</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="366" to="375" />
			<date type="published" when="1972">1972. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Test-case reduction for C compiler bugs</title>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Cuoq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chucky</forename><surname>Ellison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuejun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Conference on Programming Language Design and Implementation</title>
		<meeting>the 33rd Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="335" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Test case prioritization: An empirical study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rothermel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Untch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Harrold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Software Maintenance</title>
		<meeting>the International Conference on Software Maintenance</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Compiler testing via symbolic interpretation</title>
		<author>
			<persName><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1976 Annual Conference (ACM&apos;76)</title>
		<meeting>the 1976 Annual Conference (ACM&apos;76)</meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
			<biblScope unit="page" from="492" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">A machine description facility for compiler testing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="343" to="351" />
			<date type="published" when="1977">1977. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A normal form for compiler testing</title>
		<author>
			<persName><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGART Bull</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="155" to="162" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Toward automatic debugging of compilers</title>
		<author>
			<persName><forename type="first">Hanan</forename><surname>Samet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 5th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1977">1977</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="379" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A note on the detection of an Ada compiler bug while debugging an Anna program</title>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Sankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="1989">1989. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Experience in testing compiler optimizers using comparison checking</title>
		<author>
			<persName><forename type="first">Masataka</forename><surname>Sassa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daijiro</forename><surname>Sudosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering Research and Practice</title>
		<imprint>
			<publisher>CSREA Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="837" to="843" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Deniable backdoors using compiler bugs</title>
		<author>
			<persName><forename type="first">Scotty</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Cuoq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. PoC||GTFO</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">08</biblScope>
			<biblScope unit="page" from="7" to="9" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Using Valgrind to detect undefined value errors with bit-precision</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Seward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Nethercote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Annual Technical Conference</title>
		<meeting>the USENIX Annual Technical Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="17" to="30" />
		</imprint>
	</monogr>
	<note>General Track</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Practical testing of a C99 compiler using output comparison</title>
		<author>
			<persName><forename type="first">Flash</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw.: Pract. Exper</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1475" to="1488" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Using production grammars in software testing</title>
		<author>
			<persName><forename type="first">Gün</forename><surname>Emin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">N</forename><surname>Sirer</surname></persName>
		</author>
		<author>
			<persName><surname>Bershad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on Domain-specific Languages</title>
		<meeting>the 2nd Conference on Domain-specific Languages</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">MemorySanitizer: Fast detector of uninitialized memory use in C++</title>
		<author>
			<persName><forename type="first">Evgeniy</forename><surname>Stepanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Serebryany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Symposium on Code Generation and Optimization</title>
		<meeting>the 13th International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Finding and analyzing compiler warning defects</title>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/ACM 38th International Conference on Software Engineering</title>
		<meeting>the IEEE/ACM 38th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="203" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Finding compiler bugs via live code mutation</title>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Object-oriented Programming, Systems, Languages, and Applications</title>
		<meeting>the International Conference on Object-oriented Programming, Systems, Languages, and Applications</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="849" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Toward understanding compiler bugs in GCC and LLVM</title>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vu</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qirun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGSOFT International Symposium on Software Testing and Analysis</title>
		<meeting>the 25th ACM SIGSOFT International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Perses: Syntax-guided program reduction</title>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qirun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianxiao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Software Engineering</title>
		<meeting>the 40th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="361" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">An automatic testing approach for compiler based on metamorphic testing technique</title>
		<author>
			<persName><forename type="first">Qiuming</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wuwei</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asia Pacific Software Engineering Conference</title>
		<meeting>the Asia Pacific Software Engineering Conference</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="270" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Static test case prioritization using topic models</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">W</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hadi</forename><surname>Hemmati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorothea</forename><surname>Blostein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emp. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="182" to="212" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Interactive metamorphic testing of debuggers</title>
		<author>
			<persName><forename type="first">Sandro</forename><surname>Tolksdorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pradel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Symposium on Software Testing and Analysis</title>
		<meeting>the 28th International Symposium on Software Testing and Analysis</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="273" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Ten years of tool-based Ada compiler validations an experience report</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tonndorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Reliable Software Technologies</title>
		<meeting>the International Conference on Reliable Software Technologies</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Orthogonal Design and Description of a Formal Language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Wijngaarden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Stichting Mathematisch Centrum</title>
		<imprint>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Automatic isolation of compiler errors</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">B</forename><surname>Whalley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Prog. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1648" to="1659" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">A conformance test suite for Arden syntax compilers and interpreters</title>
		<author>
			<persName><forename type="first">Klaus-Hendrik</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Klimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud. Health Technol. Inf</title>
		<imprint>
			<biblScope unit="volume">228</biblScope>
			<biblScope unit="page" from="379" to="383" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A survey on software fault localization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Eric</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruizhi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><surname>Wotawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="707" to="740" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">An intermediate representation approach to reducing test suites for retargeted compilers</title>
		<author>
			<persName><forename type="first">Gyun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heung</forename><surname>Seok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chae</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Hanil</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ada-Europe International Conference on Reliable Software Technologies</title>
		<meeting>the Ada-Europe International Conference on Reliable Software Technologies</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="100" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Finding and understanding bugs in C compilers</title>
		<author>
			<persName><forename type="first">Xuejun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Regehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="283" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Regression testing minimization, selection, and prioritization: A survey</title>
		<author>
			<persName><forename type="first">Shin</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Softw. Test. Verif. Rel</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="67" to="120" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Random program generator for Java JIT compiler test system</title>
		<author>
			<persName><forename type="first">Takahide</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kouya</forename><surname>Shimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshihiro</forename><surname>Ozawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Quality Software</title>
		<meeting>the 3rd International Conference on Quality Software</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="20" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Model-based testing of optimizing compilers</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Zelenov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Zelenova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Formal Approaches to Software Testing and International Conference on Testing of Communicating Systems</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the International Workshop on Formal Approaches to Software Testing and International Conference on Testing of Communicating Systems</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="volume">4581</biblScope>
			<biblScope unit="page" from="365" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Test generation for compilers and other formal text processors</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Zelenov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Zelenova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Kossatchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Petrenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Comput. Softw</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="104" to="111" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Yesterday, my program worked. Today, it does not. Why?</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th European Software Engineering Conference Held Jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<title level="s">ESEC/FSE-7</title>
		<meeting>the 7th European Software Engineering Conference Held Jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="253" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Simplifying and isolating failure-inducing input</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Hildebrandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="183" to="200" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Bridging the gap between the total and additional test-case prioritization strategies</title>
		<author>
			<persName><forename type="first">Lingming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregg</forename><surname>Rothermel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Software Engineering</title>
		<meeting>the International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="192" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Skeletal program enumeration for rigorous compiler testing</title>
		<author>
			<persName><forename type="first">Qirun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Conference on Programming Language Design and Implementation</title>
		<meeting>the 38th Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="347" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Automated test program generation for an industrial optimizing compiler</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhi</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuming</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICSE Workshop on Automation of Software Test</title>
		<meeting>the ICSE Workshop on Automation of Software Test</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
