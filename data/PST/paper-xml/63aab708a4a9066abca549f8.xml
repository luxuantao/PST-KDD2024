<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MTDiag: An Effective Multi-Task Framework for Automatic Diagnosis</title>
				<funder ref="#_KV35Rch">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_ABx35nU">
					<orgName type="full">National Science Foundation for Distinguished Young Scholars</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziding</forename><surname>Liu</surname></persName>
							<email>liuziding@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongxue</forename><surname>Wu</surname></persName>
							<email>wudongxue03@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Baoyan</forename><surname>Wang</surname></persName>
							<email>wangbaoyan@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuanhe</forename><surname>Li</surname></persName>
							<email>lixuanhe@meituan.com</email>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Hong</surname></persName>
							<email>honglei@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MTDiag: An Effective Multi-Task Framework for Automatic Diagnosis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>runny nose: true expectoration: true Implicit Symptoms: fever: false</term>
					<term>cough: true sneeze: true</term>
					<term>sore throat: true Disease: rhinitis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic diagnosis systems aim to probe for symptoms (i.e., symptom checking) and diagnose disease through multi-turn conversations with patients. Most previous works formulate it as a sequential decision process and use reinforcement learning (RL) to decide whether to inquire about symptoms or make a diagnosis. However, these RL-based methods heavily rely on the elaborate reward function and usually suffer from an unstable training process and low data efficiency. In this work, we propose an effective multi-task framework for automatic diagnosis called MTDiag. We first reformulate symptom checking as a multi-label classification task by direct supervision. Each medical dialogue is equivalently converted into multiple samples for classification, which can also help alleviate data scarcity problem. Furthermore, we design a multi-task learning strategy to guide the symptom checking procedure with disease information and further utilize contrastive learning to better distinguish symptoms between diseases. Extensive experimental results show that our method achieves state-of-the-art performance on four public datasets with 1.7%? 3.1% improvement in disease diagnosis, demonstrating the superiority of the proposed method. Additionally, our model is now deployed in an online medical consultant system as an assistant tool for real-life doctors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Artificial intelligence is revolutionizing our life in various aspects and has the potential to bring new vitality to the healthcare and medical domain. Automatic diagnosis <ref type="bibr" target="#b8">(Li et al. 2017;</ref><ref type="bibr" target="#b17">Wei et al. 2018;</ref><ref type="bibr" target="#b18">Xu et al. 2019)</ref>, which aims to provide convenient medical care and assist diagnosis, is one of the most promising applications. The rapidly growing and aging population brings an increasingly heavy workload for read-life doctors, especially in countries and areas with high-density populations. And in the Internet era, people are also seeking more convenient ways to find medical services during the COVID-19 pandemic. Thus automatic diagnosis arises at this moment and is gaining increasing attention in contemporary research. Currently, the main focus has been on making more effective diagnostic decisions or building a diagnostic dialogue system <ref type="bibr" target="#b12">(Shivade et al. 2014;</ref><ref type="bibr" target="#b18">Xia et al. 2020;</ref><ref type="bibr" target="#b1">Chen et al. 2022)</ref>.</p><p>Figure <ref type="figure">1</ref>: A medical dialogue can be converted to a standard user goal for automatic diagnosis, including a disease tag, explicit symptoms, and implicit symptoms.</p><p>Specifically, the automatic diagnosis task usually relies on interactions between an agent and a patient, where the agent collects necessary symptoms for the diagnosis. This is consistent with the real-world diagnostic procedure. As the example in Figure <ref type="figure">1</ref> shows, the patient first states a self-report. Then the doctor checks several related symptoms and finally gives a diagnostic suggestion to the patient. The medical dialogue can be simplified and converted to a corresponding diagnosis sample (or user goal), consisting of explicit symptoms obtained from the user's self-report, additional implicit symptoms from inquiries, and a disease tag to be predicted. Hence, the problem can be viewed as a multi-step reasoning task <ref type="bibr" target="#b1">(Chen et al. 2022)</ref> and targets inquiring about the implicit symptoms step by step based on explicit symptoms and then making the final disease diagnosis. Note that in automatic diagnosis, the agent only asks about symptoms, and the patient answers with Yes/No/Not sure, which is quite different from the natural language used in traditional taskoriented dialogue systems.</p><p>Previous works <ref type="bibr" target="#b17">(Wei et al. 2018;</ref><ref type="bibr" target="#b18">Xu et al. 2019;</ref><ref type="bibr" target="#b9">Liao et al. 2020)</ref> for automatic diagnosis typically regard the problem as a Markov Decision Process (MDP) <ref type="bibr" target="#b19">(Young et al. 2013)</ref> and address it via reinforcement learning (RL) <ref type="bibr" target="#b3">(Cuay?huitl, Keizer, and Lemon 2015;</ref><ref type="bibr" target="#b20">Yu et al. 2021)</ref>. For example,</p><p>The Thirty-Seventh AAAI Conference on Artificial Intelligence  the dialogue policy can be parameterized with a deep Qnetwork <ref type="bibr" target="#b10">(Mnih et al. 2015;</ref><ref type="bibr" target="#b5">Hessel et al. 2018</ref>). However, RL-based methods suffer from potential drawbacks, especially in the medical domain. On the one hand, RL needs explicit learning objectives and elaborate rewards, making it hard to balance symptom checking and disease diagnosis. Learning the action merely from the final reward is not only less data-efficient but also inconsistent with the actual diagnostic procedure, where doctors would adjust inquiries based on instant response. In addition, RL is datahungry and usually requires a considerable amount of data to achieve satisfactory results. Unfortunately, the data is always sparse and insufficient in the medical domain. Recent effort <ref type="bibr" target="#b1">(Chen et al. 2022</ref>) considers automatic diagnosis as a sequence generation task and generates implicit symptoms in an auto-regressive style. Nevertheless, as the symptoms are intrinsically unordered, it is necessary to preserve this inductive bias in the algorithm design.</p><p>In this work, we propose an effective multi-task framework, MTDiag, to address these challenges. We first reformulate the symptom checking as a multi-label classification task to keep the unordered setting. A multi-turn dialogue can be transformed into a set of (input, label) samples, where the inputs represent the known symptoms, and the labels are the symptoms to be inquired. To be specific, a dialogue consisting of k implicit symptoms can be decomposed into k i=0 k i samples. Based on this decomposition, we can transfer the sequential decision process within one multiturn dialogue into multiple independent training samples of the multi-label classification task. Secondly, we propose an effective multi-task learning strategy to better capture the relationship between disease and symptom. The intuition is that in real diagnosis, when checking possible symptoms, doctors use a combination of their prior experiences of cooccurring symptoms and their professional knowledge of what disease might cause the symptoms. To leverage this prior knowledge, we employ two task-specific attentional pooling heads for predicting target symptoms and disease based on a Transformer <ref type="bibr" target="#b15">(Vaswani et al. 2017)</ref> encoder. As contrastive learning can push samples to form better clusters, we also use contrastive learning to differentiate symptoms of different diseases. Our model has been deployed online, serving hundreds of thousands of people every day.</p><p>Our main contributions are summarized in the following:</p><p>? We reformulate symptom checking as a multi-label classification task while keeping the unordered nature of automatic diagnosis. Our approach could alleviate data scarcity in the medical field and speed up training.</p><p>? We design a multi-task learning framework to interweave the learning of symptom and disease prediction. Specially, we employ contrastive learning to better distinguish symptoms among different diseases.</p><p>? Extensive experimental results show that the proposed method achieves state-of-the-art performance on four public medical diagnosis datasets, demonstrating the effectiveness of our approach.</p><p>input label</p><formula xml:id="formula_0">es 1 , es 2 [-, -, 1, 1, 0, 0] es 1 , es 2 , is 1 [-, -, -, 1, 0, 0] es 1 , es 2 , is 2 [-, -, 1, -, 0, 0] es 1 , es 2 , is 1 , is 2 [-, -, -, -, 0, 0]</formula><p>Table 1: A simple example of decomposing a user goal "E = (es 1 , es 2 ) = (s 1 , s 2 ), I = (is 1 , is 2 ) = (s 3 , s 4 )" of multiturn dialogue into multi-label classification, assuming there are only 6 symptoms in total. The 4 pieces could cover all the information contained in the user goal. The "-" in the label represents masked symptoms appearing in the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MTDiag Framework</head><p>In this section, we first introduce how to reformulate symptom checking into a multi-label classification task. Then we propose a simple and effective attention-based model and a multi-task learning strategy to tackle the problem of both symptom checking and disease diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem Reformulation</head><p>Formally, a sample of automatic diagnosis data contains explicit symptoms S ex = {es 1 , ..., es n }, implicit symptoms S im = {is 1 , ..., is m }, and a disease tag Dis. Only the explicit symptoms are accessible at the beginning. The target of symptom checking is to obtain as many implicit symptoms as possible via limited turns of inquiries since more implicit symptoms would contribute to a more precise diagnosis. For each symptom inquiry, the simulator will output True or False as an answer for a positive/negative symptom and not sure for symptom not in the user goal S ex ?S im . The objective equals maximizing the likelihood P (S im |S ex ). We denote the symptoms obtained via inquires as S add ? S im , and the missed ones as Sadd = S im -S add . Since symptoms are naturally orderless, the learning objective can be formulated as follows:</p><formula xml:id="formula_1">S add ?Sim P ( Sadd |S ex ? S add )<label>(1)</label></formula><p>We model the symptom checking as a multi-label rather than multi-class classification task to avoid the potential problem of sequential generation. Afterward, the disease is predicted based on known symptoms, whose learning objective is to maximize P (Dis|S ex ? S add ).</p><p>Training. In this part, we show how to apply supervised learning to tackle the problem of multi-step reasoning. Traditional supervised learning hypothesizes that data samples are independent. We aim to decompose a multi-turn diagnostic dialogue into several independent one-step multilabel classification data samples while covering all possible cases and information in the dialogue. According to Equation 1, to maximize p(S im |S ex ), we could maximize each P ( Sadd |S ex ?S add ) independently, which corresponds to an intermediate state before an inquiry of a dialogue: given explicit symptoms S ex and observed implicit ones S add as input, the objective is to predict the remaining implicit symptoms Sadd . In such a case, the problem can be converted to a multi-label classification task:</p><formula xml:id="formula_2">Input(S ex ? S add ) predict ----? Label( Sadd )</formula><p>If we enumerate all possible S add of each dialogue, that is, all subsets of S im , any intermediate state would be covered during training, and we transfer the sequential decision problem into a multi-label classification task under the setting of supervised learning. Table <ref type="table">1</ref> shows a simple example of the decomposition of a user goal containing two explicit and two implicit symptoms. Symptoms in the input should not appear in the label in order to prevent label leakage and false negatives. In our implementation, we mask the input symptoms label during training.</p><p>This decomposition also has advantages. A dialogue with k implicit items can be transformed into Inference. In the inference, we still follow the multi-turn setting to imitate the actual medical dialogue scenario. In each turn, the model accepts S ex ? S add as inputs, and the symptom of the highest probability in the prediction is selected as the subsequent inquiry. If the patient answers True or False, the symptom will be marked and added to the known set. Otherwise, the next highest probability symptom will be the subsequent inquiry until finding the implicit one or stopping. To make the model aware of when to stop, we set a stop threshold ? ? (0, 1) as the minimum probability boundary. If the probability of all remaining symptoms in the prediction is all below ?, the model will stop. Then the explicit symptoms and those obtained via inquiries will be used for disease diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>In this part, we introduce our proposed attention-based model and a multi-task learning strategy to resolve symptom checking and disease diagnosis. The architecture is illustrated in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Model Architecture. In each step, our model maps an input set of known symptoms (s 1 , ..., s n ) to a set of continuous representations and then aggregates them together to make the prediction. All symptoms are converted to d dimension token embeddings, denoted as x i ? R d for symptom s i . Explicit and implicit symptoms share the same token embeddings. We add symptom condition embedding c i ? R d to indicate it is positive (True) or negative (False), which works similarly to the positional encoding in Transformer <ref type="bibr" target="#b15">(Vaswani et al. 2017)</ref>.</p><p>We first stack multiple Transformer blocks to capture the interaction between symptoms, as various works have demonstrated that transformer is powerful in tackling sequences of varying lengths. To be concrete, after adding the condition embeddings, we feed the symptom embeddings to the transformer encoder to get hidden representations:</p><p>[h 1 , .., Previous studies <ref type="bibr" target="#b12">(Reimers and Gurevych 2019)</ref> show that inserting a special [CLS] token in the sequence often achieves good performance for sentence-level classification.</p><formula xml:id="formula_3">h n ] = MH-Attn(f Q ( X), f K ( X), f V ( X)),</formula><p>In our experiments, we find that aggregating symptoms' representation works better in symptom checking. In this work, we design a simple and effective attentional pooling to obtain the sequence representation for the final prediction.</p><p>We first construct a virtual signal using a shared learnable vector q ? R d to represent the target disease/symptom. The signal is employed to calculate the attention scores for aggregation. This works similarly to the self-attention used in Graph Attention Networks <ref type="bibr" target="#b16">(Veli?kovi? et al. 2018)</ref>, and the main difference is that our query is a learnable vector rather than any input representation.</p><formula xml:id="formula_4">a i = exp(?(q ? h i /?)) j?N exp(?(q ? h j )/?) , (<label>2</label></formula><formula xml:id="formula_5">)</formula><p>where N is the set of symptoms in the input set, ?(x) is the LeakyReLU activation and, ? ? R + is the temperature. We obtain the prediction by computing the linear combination of symptom embeddings and also utilize multi-head attention to improve the expressiveness:</p><formula xml:id="formula_6">z = W 2 ( K || k=1 ?( i?N a (l) i h i )).<label>(3)</label></formula><p>Multi-task Design. From the above description, we aim to predict the implicit symptoms based on explicit ones. The multi-label training objective tends to guide the model to learn the concurrence of symptoms. Despite the fact that we always predict diseases based on symptoms in our daily life, it is the disease itself that causes symptoms to appear. Thus this inspires us to provide auxiliary information about the disease to support symptom checking. As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, we design a multi-task learning strategy to achieve this goal. In symptom checking, we employ two different attentional pooling heads for symptom and disease prediction respectively. A transformer serves as a shared bottom encoder of the two heads to capture information of two tasks.</p><p>For clarity, we denote the output of the symptom prediction head as z (s) ? R C and the disease head z (d) ? R d , where C is the number of symptoms.</p><p>For symptom prediction, binary cross entropy (BCE) is a traditional solution to multi-label classification for training. <ref type="bibr" target="#b11">Peng et al. (2020)</ref> point out that BCE declines the suppression between categories and behaves poorly in imbalanced multi-label distribution. In automatic diagnosis, there could be hundreds of symptoms in total, but each user goal usually involves only less than ten symptoms. To tackle the issue, we use the concurrent softmax proposed in <ref type="bibr" target="#b11">(Peng et al. 2020)</ref>:</p><formula xml:id="formula_7">L sym = - C i=1 y i log exp(z (s) i ) C j=1 (1 -y j ) exp(z (s) j ) + exp(z (s) i )</formula><p>For the auxiliary disease prediction, we resort to the idea of contrastive learning <ref type="bibr">(He et al. 2020)</ref>. Contrastive learning implicitly pulls clusters of points belonging to the same class together while pushing apart samples from different classes. In our scenario, it agrees with the aim of symptom checking to pull the combination of symptoms belonging to the same disease together and separate irrelevant ones. Supervised contrastive learning <ref type="bibr" target="#b7">(Khosla et al. 2020</ref>) generalizes self-supervised contrastive learning to an arbitrary number of positive samples. Samples belonging to the same disease are all viewed as positive:</p><formula xml:id="formula_8">L aux = -1 |P (i)| p?P (i) log exp(z (d) ? z (d) p /? ) a?N (i) exp(z (d) ? z (d) a /? ) .</formula><p>Here, P (i) includes all positive samples of z (d) , N (i) is the set of negative samples, and ? ? R + is a temperature hyperparameter. As demonstrated in <ref type="bibr" target="#b2">(Chen et al. 2020;</ref><ref type="bibr">He et al. 2020)</ref>, contrastive learning benefits from larger batch size and more negative samples. However, automatic diagnosis suffers from insufficient training data and a small batch size.</p><p>To alleviate this issue, we adopt a dynamic queue, which stores representations of previous samples to serve as positives/negatives. As the training continues, we progressively update the queue by adding the latest samples and removing the oldest ones. This enables us to use large negative samples with limited batch size. Note that in our method, S ex ? S add is used for symptom prediction while S ex ? S im for disease prediction. We find that predicting the disease with only partial symptoms would potentially bring extra noise and harm the diagnosis performance.</p><p>Finally, we add the two losses together for the training of symptom checking with a coefficient ?:</p><formula xml:id="formula_9">L = L sym + ? ? L aux .</formula><p>Then the attention head for disease prediction can be directly used for disease prediction. In our experiments, we find that training a new attentional head without transformer encoders from scratch achieves better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In this section, we conduct extensive experiments on public datasets of automatic diagnosis to evaluate our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup</head><p>Datasets. We evaluate our method on four commonly used public datasets. The MDD dataset is from ICLR 2021 Workshop MLPCP Track 2 Medical Dialogue System for Automatic Diagnosis<ref type="foot" target="#foot_0">1</ref> . It contains 2,374 user goals and 118 symptoms, covering 12 disease types. All the dialogues in MDD are derived from real-world patients in offline hospitals, thus closer to the real clinical diagnosis scenario. Since the test set of the MDD dataset is not available, we only report the metric in the validation (dev) set. The MZ dataset <ref type="bibr" target="#b17">(Wei et al. 2018</ref>) is collected from the pediatric department in a Chinese online healthcare community (Baidu Muzhi). It contains 710 user goals and 66 symptoms, covering 4 types of diseases. The DXY dataset (Xu et al. <ref type="formula">2019</ref>) is collected from a Chinese online healthcare community (dxy.com) where users ask doctors for medical diagnoses or professional medical advice. The dataset contains 527 user goals and 41 symptoms, covering 5 types of diseases. The Synthetic dataset <ref type="bibr" target="#b9">(Liao et al. 2020</ref>) is constructed from a symptom-disease database called SymCat<ref type="foot" target="#foot_1">2</ref> . It contains 30,000 user goals with 90 diseases.</p><p>Baselines. We compare our model with several baselines, including traditional methods and state-of-the-art methods. SVM (Chang and Lin 2011) is a commonly used traditional classifier. "SVM-ex&amp;im" can be viewed as a strong baseline as it uses all explicit and implicit symptoms. RL-based methods formulate the medical dialogue as a Markov decision process with reinforcement learning. The Basic DQN is from <ref type="bibr" target="#b17">(Wei et al. 2018</ref>) and the PPO baseline is provided by <ref type="bibr" target="#b14">(Teixeira, Maran, and Dragoni 2021)</ref>. HRL <ref type="bibr" target="#b9">(Liao et al. 2020)</ref> integrates a two-level hierarchical policy learning strategy. KR-DS (Xu et al. <ref type="formula">2019</ref>) is an extension of Basic-DQN and integrates relation encoding to help symptom checking and a knowledge-routed graph branch for action decision-making. It also makes use of the self-report of patients before the dialogue. GAMP <ref type="bibr" target="#b18">(Xia et al. 2020)</ref> integrates the Generative Adversarial Network into the reinforcement learning model with policy gradient and uses mutual information to further enhance the reward function. Diaformer <ref type="bibr" target="#b1">(Chen et al. 2022)</ref>   Evaluation Metrics. Following the setting of the previous works <ref type="bibr" target="#b17">(Wei et al. 2018;</ref><ref type="bibr" target="#b18">Xu et al. 2019;</ref><ref type="bibr" target="#b1">Chen et al. 2022)</ref>, we evaluate our method by three metrics: accuracy for disease diagnosis, recall of implicit symptoms, and average inquiry turns for symptom checking. The accuracy is the key metric for automatic diagnosis. The recall and average turn could evaluate the efficiency of the inquiry.</p><p>Implementation Details. We implement our model by Py-Torch and train the model on NVIDIA 2080Ti (11G). We repeat the experiments five times with random initialization and report the mean results. For symptom checking, the maximum number of turns is set to 20. In addition, in training the diagnosis classifier, explicit symptoms with implicit symptoms in the input and the ones from symptom checking are viewed as different training samples. This could be viewed as a data augmentation technique to help enrich the training data and relieve the problem of data scarcity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Results</head><p>Overall Performance. We report results of baselines from previous works if available. For those results that are not previously reported, we run the official code if it is publicly available. All experimental results are shown in Table ??.</p><p>Overall speaking, we observe that our approach achieves state-of-the-art or competitive results on both symptom checking and disease diagnosis in the four datasets. MTDiag significantly outperforms reinforcement learning (RL) based methods, especially in DXY and Synthetic datasets where the absolute improvement is at least 10.8% and 13.9% in diagnosis accuracy. For the non-RL-based method Diaformer, our method also has an advantage with an average improvement of 1.9% in the four datasets. For symptom checking, MTDiag tends to request more inquiry runs to achieve a higher recall of symptoms. This is practical and reasonable in real scenarios because more symptoms would help the doctor make a more accurate diagnosis. Compared with Diaformer, MTDiag achieves higher recall and diagnosis accuracy while consuming fewer turns in MDD and DXY. This indicates that our method has more potential to provide valid and informative inquiries of symptoms for diagnosis. Overall, these results demonstrate the effectiveness of the proposed learning framework.</p><p>Effect of maximum limited turns. As shown in Table ??, our method, together with Diaformer, tends to request more inquiry turns than RL-based methods to achieve a higher recall of symptoms. We conduct experiments with 5/10/15 maximum turns to test the performance within fewer turns. Due to the limitation that KR-DS, GAMP, and PPO have not released their code, we compare with two RL baselines (DQN and HRL) and one sequence-generation-based model Diaformer. The results are in Table ??. It is observed that in most cases, MTDiag can outperform baselines in terms of diagnostic accuracy and recall of implicit symptoms. Specifically, in the setting of 5 limited turns, our method still has a distinct advantage over two RL-based methods with at least 5% improvement in accuracy and 6% in recall on average. MTDiag shows an edge over Diaformer, especially when limited turns are set to 10/15. These results manifest that the proposed approach can achieve satisfactory performance within limited turns.</p><p>Effect of stop threshold ?. In the inference of symptom checking, we employ a threshold ? to control when to stop inquiring. In addition to limiting the maximum turns, adjusting the stop threshold is another way to control the inquiry turns. We explore the effect of ? in the MDD dataset, and the results are illustrated in Figure <ref type="figure" target="#fig_2">3</ref>. We observe that as the stop threshold ? increases, the recall of implicit symptoms and diagnosis accuracy decrease. This is in line with our intuition that higher ? would cause the inquiry to end earlier, and more implicit symptoms would be overlooked. Besides, it indicates that higher recall can lead to a more accurate diagnosis. Note that the recall drop is more significant than diagnosis accuracy, which may imply that our method can inquire about key implicit symptoms in early steps. Overall speaking, this provides another way to balance the average turn and effectiveness of diagnosis. Ablation Study. We conduct a series of ablation studies to verify the effect of each component in our approach. In this work, we introduce a multi-task learning strategy to assist the symptom checking with extra disease information. Table ?? indicates that this strategy generally boosts the performance of symptom checking as both the recall of implicit symptoms and diagnosis accuracy increase in MDD, MZ, and DXY with almost equal average turns. The Synthetic dataset is an exception in which the performance almost keeps. One possible assumption is that as its scale is much larger than the others, the model is capable of learning well only based on the concurrence of symptoms. We also conduct experiments using binary-cross-entropy (BCE) as the loss function, which is widely used in multi-label classification tasks. The results in  ing) are found in Turns 2 and 3. When the conditions of two key symptoms are recognized, our model gives the right disease prediction, Pediatric Dyspepsia. Finally, our model retains the correct diagnosis after inquiring about two relevant but unknown symptoms. Although some implicit symptoms are not found within five inquiries, our method still gives the right prediction as the final diagnosis.</p><p>Online Deployment. Our method is now deployed as an Table <ref type="table">5</ref>: Case study of an example chosen from the MZ dataset with 5-turn inquiries. We report the symptom, its condition, and the disease prediction in each turn, where UNK means the condition of the symptom is unknown. After the symptom checking, our model makes the correct diagnosis, Pediatric Dyspepsia.</p><p>important component of an online medical consultant system as an assistant tool for the real-life doctor, serving hundreds of thousands of users every day. Practically, for each dialogue, we first extract initial symptoms from the user's self-report by named entity recognition and linking tools from the user's self-report. Then our model is activated to perform the multi-turn dialogue to collect implicit symptoms. In each turn, our model predicts the top-k most probable symptoms, which are present as a multiple-selection checkbox. The user could select several symptoms he/she has, and our method will generate subsequent symptoms. Some hand-crafted rules are combined with our method to collect basic information like age and duration of symptoms and avoid any possible offensive inquiries. After a few interactions, all collected symptoms and the diagnostic suggestion of the disease are provided to the doctor for reference.</p><p>And the doctor could adopt the model's suggestion or inquire for more details to help make the final diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Previous works mostly view automatic diagnosis as a sequential decision problem.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and Future Work</head><p>In this paper, we propose MTDiag, an effective multi-task framework for automatic medical diagnosis. We reformulate the symptom checking under a multi-label classification setting and further design a multi-task strategy to guide the training with disease information. MTDiag achieves stateof-the-art performance on four public datasets, demonstrating the effectiveness of our method. As for future work, we identify the importance of high-quality datasets, since they play a significant role in advancing a research field. But current datasets of automatic medical diagnosis are either too small or not fully open-source. This greatly hinders the development of automatic diagnosis. In the future, we will try to build a better benchmark to achieve a more reliable evaluation of existing methods.</p><p>Ethical Statement. Artificial intelligence can assist people in a variety of patient care and intelligent health systems. Automatic diagnosis is an important application that helps patients with self-diagnosis or doctors as auxiliary tools. Although our approach achieves promising results, the predicting errors caused by the inadequate data may bring potential harm to users when directly applying the method as a diagnostic system. Under the ethical considerations, our model is deployed as an auxiliary tool to offer suggestions and help doctors check symptoms and make the diagnosis in online medical consultation, rather than serve the patient directly and independently.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>at most, which significantly increases the scale of training data and helps alleviate the problem of data scarcity. This technique makes more sense in the medical domain because it is difficult and costly to collect real data. Beyond this, mini-batch training under a supervised setting runs and converges much faster than reinforcement learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The multi-task learning framework. Our model first employs a transformer to encode input symptoms and their conditions. Then we predict the next possible symptom and disease representation using distinct attentional pooling heads, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Sensitivity of the stop threshold ? in symptom checking in MDD and DXY datasets. With the increase of ?, symptom recall drops significantly, and diagnosis accuracy decreases slightly due to the fewer symptoms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Disease tag: Pediatric Dyspepsia Explicit symptoms: {green stool: True, diarrhea: True} Implicit symptoms:{loose stool: True, vomiting: True,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The deployed online medical consultation service.Our method is used to check symptoms of patients before they communicate with the doctor.</figDesc><graphic url="image-5.png" coords="7,389.73,54.28,161.45,112.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>We report results from previous works if available. Otherwise, if code is provided and could be run successfully, we implement them based on the official code and report the results.</figDesc><table><row><cell></cell><cell></cell><cell>MDD</cell><cell></cell><cell></cell><cell>MZ</cell><cell></cell><cell></cell><cell>DXY</cell><cell></cell><cell></cell><cell>Synthetic</cell><cell></cell></row><row><cell></cell><cell cols="12">Acc Recall ATurn Acc Recall ATurn Acc Recall ATurn Acc Recall ATurn</cell></row><row><cell>SVM-ex</cell><cell>70.3</cell><cell>-</cell><cell>-</cell><cell>59.0</cell><cell>-</cell><cell>-</cell><cell>64.4</cell><cell>-</cell><cell>-</cell><cell>34.1</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">SVM-ex&amp;im 84.5</cell><cell>-</cell><cell>-</cell><cell>71.0</cell><cell>-</cell><cell>-</cell><cell>77.9</cell><cell>-</cell><cell>-</cell><cell>73.2</cell><cell>-</cell><cell>-</cell></row><row><cell>Basic DQN</cell><cell>46.4</cell><cell>-</cell><cell>-</cell><cell>65.0</cell><cell>30.1</cell><cell>3.1</cell><cell>73.1</cell><cell>32.2</cell><cell>2.9</cell><cell>35.6</cell><cell>2.0</cell><cell>2.0</cell></row><row><cell>HRL</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>69.4</cell><cell>27.6</cell><cell>3.5</cell><cell>69.5</cell><cell>16.1</cell><cell>2.4</cell><cell>49.6</cell><cell>33.8</cell><cell>8.4</cell></row><row><cell>KR-DS</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>73.0</cell><cell>-</cell><cell>3.4</cell><cell>74.0</cell><cell>-</cell><cell>3.4</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>GAMP</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>73.0</cell><cell>-</cell><cell>6.3</cell><cell>76.9</cell><cell>-</cell><cell>3.3</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PPO</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>73.2</cell><cell>-</cell><cell>6.3</cell><cell>74.6</cell><cell>-</cell><cell>3.3</cell><cell>61.8</cell><cell>-</cell><cell>12.6</cell></row><row><cell>Diaformer</cell><cell>86.0</cell><cell>87.4</cell><cell>18.9</cell><cell>74.2</cell><cell>75.2</cell><cell>15.3</cell><cell>82.9</cell><cell>82.7</cell><cell>13.1</cell><cell>73.3</cell><cell>90.6</cell><cell>13.7</cell></row><row><cell>MTDiag</cell><cell>89.1</cell><cell>89.2</cell><cell>13.8</cell><cell>75.9</cell><cell>79.4</cell><cell>17.9</cell><cell>85.4</cell><cell>91.3</cell><cell>12.5</cell><cell>75.4</cell><cell>90.7</cell><cell>15.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">formulates the dialogue-based</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">diagnosis system as a sequence generation task and designs</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">a transformer-based framework for automatic diagnosis.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Experimental results of four datasets in disease diagnosis. "Acc" is the accuracy of diagnosis. "Recall" is the recall of implicit symptom for symptom checking, and "ATurn" is average turn of inquiry.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results with smaller different limited turns.</figDesc><table><row><cell>Turn</cell><cell>Model</cell><cell cols="10">MDD Acc Recall ATurn Acc Recall ATurn Acc Recall ATurn Acc Recall ATurn MZ DXY Synthetic</cell></row><row><cell></cell><cell>Basic DQN</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>64.1 29.2</cell><cell>2.9</cell><cell>64.7 31.1</cell><cell>2.5</cell><cell>35.6</cell><cell>2.0</cell><cell>2.0</cell></row><row><cell>5</cell><cell cols="3">HRL Diaformer 85.3 58.3 --</cell><cell>-4.9</cell><cell>67.6 26.5 72.2 47.2</cell><cell>2.8 5.0</cell><cell>70.2 15.2 76.6 54.5</cell><cell>1.9 4.8</cell><cell cols="2">44.3 49.4 46.1 2.4</cell><cell>4.3 4.9</cell></row><row><cell></cell><cell>MTDiag</cell><cell cols="2">82.8 59.5</cell><cell>5.0</cell><cell>72.6 45.3</cell><cell>5.0</cell><cell>76.1 58.1</cell><cell>5.0</cell><cell cols="2">51.1 44.1</cell><cell>5.0</cell></row><row><cell>10</cell><cell>Basic DQN HRL</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>68.3 29.6 69.7 26.6</cell><cell>3.0 3.3</cell><cell>71.5 32.2 71.8 15.9</cell><cell>2.7 2.3</cell><cell cols="2">35.6 48.8 30.7 2.0</cell><cell>2.0 7.4</cell></row><row><cell></cell><cell cols="3">Diaformer 84.9 75.6</cell><cell>9.0</cell><cell>73.1 65.5</cell><cell>9.8</cell><cell>80.6 77.8</cell><cell>9.6</cell><cell cols="2">63.2 73.6</cell><cell>9.6</cell></row><row><cell></cell><cell>MTDiag</cell><cell cols="2">85.9 80.1</cell><cell>9.6</cell><cell>74.6 63.2</cell><cell cols="2">10.0 81.9 82.7</cell><cell>9.6</cell><cell cols="2">63.6 72.5</cell><cell>10.0</cell></row><row><cell>15</cell><cell>Basic DQN HRL</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>68.3 29.7 70.2 27.2</cell><cell>3.0 3.4</cell><cell>71.2 32.0 71.8 15.9</cell><cell>2.7 2.3</cell><cell cols="2">35.6 49.9 32.2 2.0</cell><cell>2.0 8.3</cell></row><row><cell></cell><cell cols="3">Diaformer 85.7 81.8</cell><cell cols="2">12.3 74.2 73.1</cell><cell cols="2">13.8 82.8 82.6</cell><cell cols="3">12.4 71.1 86.6</cell><cell>12.6</cell></row><row><cell></cell><cell>MTDiag</cell><cell cols="2">87.5 87.2</cell><cell cols="2">12.9 74.6 73.5</cell><cell cols="2">15.0 85.4 89.8</cell><cell cols="3">11.9 73.3 87.9</cell><cell>14.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>MDD</cell><cell></cell><cell>MZ</cell><cell></cell><cell>DXY</cell><cell></cell><cell></cell><cell>Synthetic</cell></row><row><cell></cell><cell></cell><cell cols="10">Acc Recall ATurn Acc Recall ATurn Acc Recall ATurn Acc Recall ATurn</cell></row><row><cell></cell><cell>MTDiag</cell><cell cols="2">89.1 89.2</cell><cell cols="2">14.4 75.9 79.4</cell><cell cols="2">17.9 85.4 91.3</cell><cell cols="3">12.5 75.4 90.7</cell><cell>15.1</cell></row><row><cell cols="2">w/o SupCon</cell><cell cols="2">88.1 87.3</cell><cell cols="2">12.8 74.2 80.0</cell><cell cols="2">18.0 84.0 88.9</cell><cell cols="3">12.6 75.6 91.3</cell><cell>15.1</cell></row><row><cell cols="2">w/ BCE only</cell><cell cols="2">88.2 87.9</cell><cell cols="2">13.4 73.8 62.6</cell><cell cols="2">18.0 84.1 87.7</cell><cell cols="3">12.1 74.0 89.5</cell><cell>14.0</cell></row><row><cell cols="4">w/ BCE+SupCon 88.7 87.6</cell><cell cols="2">15.9 74.2 62.8</cell><cell cols="2">17.1 84.8 90.3</cell><cell cols="3">12.5 74.1 89.2</cell><cell>14.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Ablation study of different training variants. "w/o SupCon" represents training with symptom prediction loss only. "w/ BCE" means replacing concurrent-softmax based loss with binary cross entropy (BCE) loss.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table ?</head><label>?</label><figDesc>We give an actual example from the MZ dataset to demonstrate how symptom checking helps the final diagnosis, as illustrated in Table??. Our model first gives an initial but wrong prediction (i.e., Pediatric Diarrhea) based on explicit symptoms before the checking and then inquires about five symptoms step by step. During the 5-turn inquiries, two implicit symptoms (i.e., loose stool and vomit-</figDesc><table><row><cell>? show that both concur-</cell></row><row><cell>rent softmax (CCE) and BCE perform equally well without</cell></row><row><cell>disease information. Under the multi-task learning setting,</cell></row><row><cell>CCE has a slight edge over BCE. These results indicate that</cell></row><row><cell>the multi-task learning strategy help to improve the perfor-</cell></row><row><cell>mance of automatic diagnosis.</cell></row><row><cell>Case Study.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://competitions.codalab.org/competitions/29706</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>www.symcat.com   </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported by The <rs type="funder">National Key Research and Development Program of China</rs> (<rs type="grantNumber">2021YFF1201300</rs>), <rs type="funder">National Science Foundation for Distinguished Young Scholars</rs> (No. <rs type="grantNumber">61825602</rs>), and Meituan.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KV35Rch">
					<idno type="grant-number">2021YFF1201300</idno>
				</org>
				<org type="funding" xml:id="_ABx35nU">
					<idno type="grant-number">61825602</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIST</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diaformer: Automatic Diagnosis via Symptoms Sequence Generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Cuay?huitl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lemon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08099</idno>
		<title level="m">Strategic dialogue management via deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rainbow: Combining improvements in deep reinforcement learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Modayil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Horgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
		<idno>AAAI&apos;18</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">End-to-end task-completion neural dialogue systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01008</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14254</idno>
		<title level="m">Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Human-level control through deep reinforcement learning. nature</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="529" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large-scale object detection in the wild from imbalanced multi-labels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9709" to="9718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A review of approaches to identifying patient phenotype cohorts using electronic health records</title>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shivade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fosler-Lussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Embi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2019. 2014</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="221" to="230" />
		</imprint>
	</monogr>
	<note>Sentence-bert: Sentence embeddings using siamese bert-networks</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inquire and diagnose: Neural symptom checking ensemble using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop on Deep Reinforcement Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The interplay of a conversational ontology and AI planning for health dialogue management</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Maran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dragoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual ACM symposium on applied computing</title>
		<meeting>the 36th annual ACM symposium on applied computing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="611" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Task-oriented dialogue system for automatic diagnosis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL&apos;18</title>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generative adversarial regularized mutual information policy gradient framework for automatic diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;20</title>
		<imprint>
			<date type="published" when="2019">2020. 2019</date>
		</imprint>
	</monogr>
	<note>AAAI&apos;19</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pomdp-based statistical spoken dialog systems: A review</title>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reinforcement learning in healthcare: A survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
