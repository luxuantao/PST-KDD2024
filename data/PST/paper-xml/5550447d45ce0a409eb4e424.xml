<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotions Mediated Through Mid-Air Haptics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marianna</forename><surname>Obrist</surname></persName>
							<email>m.obrist@sussex.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering and Informatics</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sriram</forename><surname>Subramanian</surname></persName>
							<email>sriram@cs.bris.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elia</forename><surname>Gatti</surname></persName>
							<email>gattie@adf.bham.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">CNCR</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Long</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Ultrahaptics Limited</orgName>
								<address>
									<settlement>Bristol</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Carter</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Ultrahaptics Limited</orgName>
								<address>
									<settlement>Bristol</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Emotions Mediated Through Mid-Air Haptics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1E887E86F598F21ACFC1BD875EA040C2</idno>
					<idno type="DOI">10.1145/2702123.2702361</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Emotions</term>
					<term>Touch</term>
					<term>Mid-Air</term>
					<term>Emotional Tactile Experiences</term>
					<term>UltraHaptics</term>
					<term>Emotion-Haptics-Mapping H.5.m. Information interfaces and presentation (e.g., HCI)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Touch is a powerful vehicle for communication between humans. The way we touch (how) embraces and mediates certain emotions such as anger, joy, fear, or love. While this phenomenon is well explored for human interaction, HCI research is only starting to uncover the fine granularity of sensory stimulation and responses in relation to certain emotions. Within this paper we present the findings from a study exploring the communication of emotions through a haptic system that uses tactile stimulation in mid-air. Here, haptic descriptions for specific emotions (e.g., happy, sad, excited, afraid) were created by one group of users to then be reviewed and validated by two other groups of users. We demonstrate the non-arbitrary mapping between emotions and haptic descriptions across three groups. This points to the huge potential for mediating emotions through mid-air haptics. We discuss specific design implications based on the spatial, directional, and haptic parameters of the created haptic descriptions and illustrate their design potential for HCI based on two design ideas.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Affect and emotions are important areas of research for human-computer-interaction. There is a growing trend to design interactive systems that elicit and support emotions beyond facial and vocal channels <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b6">7]</ref>. In particular, communicating and mediating emotions through touch is an area of research that opens up new design opportunities for emotion-related communication <ref type="bibr" target="#b7">[8]</ref>. This is evidenced in recent work on the integration of touch during phone conversations for enhancing the emotional expressiveness in long-distance relationships <ref type="bibr" target="#b12">[13]</ref>, the design of a wearable system that allows different types of social touch <ref type="bibr" target="#b8">[9]</ref>, and the increased number of studies on understanding the rich expressiveness of tactile sensations linked to the increasing availability of haptic systems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Park et al. <ref type="bibr" target="#b12">[13]</ref>, for instance, showed that sharing a tactile vocabulary enabled couples to express and understand emotions over distance. For positive emotions participants used weak touches, while negative emotions were often expressed through hard, fast, and continuous touches. Huisman and Frederiks <ref type="bibr" target="#b8">[9]</ref> specifically focused their design on six emotions, expressed through a tactile sleeve mounted on the forearm and equipped with different vibration motors. They identified different types of touch for each emotion (e.g., stroking for love, squeezing for fear), but also reported participants' difficulty in differentiating the intensity of the expressions on the worn sleeve. These results suggest the potential for communicating emotions through touch but do not inform sufficiently which or how specific emotions can be mediated through haptic feedback.</p><p>In this paper we bridge this knowledge gap by using a novel methodology that was adopted from the crowdsourcing community <ref type="bibr" target="#b0">[1]</ref>. Their Find-Fix-Verify approach splits complex crowd intelligence tasks into a series of generate and review stages to produce more reliable results. Instead of relying on a single crowd worker to complete a complex task, different sets of workers are recruited to complete parts of the complex task. Thus, this process prevents single errant crowd workers from contributing too much, too little, or introducing errors into the data collected. We conducted a user study by applying this principle in a lab-based environment to "Generate, Select and Verify" the mapping between specific emotions and haptic stimuli. We used the UltraHaptics system <ref type="bibr" target="#b3">[4]</ref> that conveys haptics using acoustic radiation forces through mid-air.</p><p>In our study, a first group of participants created their own haptic descriptions for standardized emotional stimuli taken from the International Affective Picture System database <ref type="bibr" target="#b9">[10]</ref>. These descriptions were reviewed and ranked by a second group (eliminating half of them) and the remaining descriptions were played back to and rated by an independent third group. Through this process, we showed that the mapping between emotions and haptics is not random and that self-expressiveness can be successfully combined with objective tactile parameters. The main contributions of this paper are (a) the demonstration of a non-arbitrary mapping of emotions through haptic stimuli sensed through a mid-air haptic system, (b) identification of mappings of freely expressed haptic descriptions derived from participants interpretation of the emotional state to the controlled emotional stimuli from the standardized IAPS datasets, and (c) derivation of design opportunities for mediating emotions through mid-air haptics based on three main characteristics: spatial (i.e., location), directional (i.e., movement), and haptic (i.e., frequency, intensity, duration) parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Touch is extensively and richly used in everyday life. While it is often assumed that the use of touch in communicating is primarily relevant for the blind and deaf, it is just as relevant for us all. In particular, the way we touch embraces specific meanings and mediates certain emotions, which are well explored and understood in social sciences <ref type="bibr" target="#b4">[5]</ref>, but not within HCI and the design of user interfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Manipulate, map and influence emotions through touch</head><p>Communicating emotions (and in general abstract concepts) through haptic feedback has become an exciting challenge. Psychologists and designers have investigated the relationship between haptics and emotions by following three main approaches: (i) manipulating haptic stimuli to express emotions, (ii) mapping stimuli to emotional terms, and (iii) influencing emotions through haptic stimuli. The results highlight how it is possible to connect haptic stimuli with users' emotional reactions.</p><p>Bailenson <ref type="bibr" target="#b0">[1]</ref> for example has shown the manipulation of haptic stimuli to express emotions. His findings show that people are able to express and recognize emotions by using a force feedback device that simulated a handshake. Smith and MacLean <ref type="bibr" target="#b16">[17]</ref> confirmed strangers' ability to express and recognize each others' specific emotions using a purely haptic link. Salmien et al. <ref type="bibr" target="#b14">[15]</ref>, in contrast, studied the mapping of haptic stimuli to emotional stimuli and showed how a simple haptic stimulus (the rotation of a cylinder at different speed and at different frequency intervals) could be interpreted as having emotional ratings stable across participants specifically asked to rate it on the dimensions of pleasantness, approachability, dominance, and arousal. Despite the fact that these stimuli are highly controlled, and the emotional rating relatively easy to understand, from a sensorial point of view this kind of study has the drawback of limiting the stimuli to be related with the participants' emotions, with a consequent loss of flexibility. <ref type="bibr">Gatti et al. [6]</ref> also tried to influence the emotional states of participants through haptic stimuli. Their findings suggest that haptic interaction has an effect on the interpretation of emotional stimuli at a secondary emotion's stage, that is at a stage where users merge their primary physiological emotional reaction with the information from the context, giving rise to complex interpreted emotional states. In their experiments, two different groups of users were asked to evaluate emotional pictures while interacting with a Phantom haptic device. Each group experienced a different degree of friction while moving the robotic arm of the device. There was no effect of the haptic interaction on the physiological recording, but there was an effect on the participants' evaluation of the pictures (in particular on their arousal dimension) suggesting that haptic stimulation, despite not providing an emotional activation by itself (therefore eliciting physiological parameters underpinning primary emotions), can play a role when the user is explicitly asked to focus on his/her own emotional state.</p><p>In terms of HCI research this result suggests that interaction designers might work with haptic stimulation in order to communicate emotions between two or more users, or even to mediate the emotional response, rather than use it to elicit an emotional reaction per se.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Use of emotion-related haptic interaction in HCI</head><p>Hertenstein et al. <ref type="bibr" target="#b7">[8]</ref> showed that even strangers can communicate distinct emotions when communicating solely through touch. One person touched a stranger's forearm, trying to convey one of 12 emotions, which then had to be recognized by the other person (the two people did not see each other, interacting only through touch). Their data suggests that anger, fear, disgust, love, gratitude, and sympathy were decoded at greater than chance level, and they discuss the findings for emotion-related communication. Huisman and Frederiks <ref type="bibr" target="#b8">[9]</ref> built on this by exploiting these findings from human-human interaction for computer-mediated communication. They developed TaSST, a tactile sleeve for social touch, focusing on the forearm by integrating different vibration motors. Based on an initial study with 16 participants they identified different types of touch for each emotion (e.g., stroking for love, squeezing for fear) and demonstrate how technology could be designed for emotional expressiveness through touch.</p><p>As introduced before, Park et al. <ref type="bibr" target="#b12">[13]</ref> explored the role of touch during phone conversations for long-distance relationships. They developed POKE, a device that enables the callers to share touches during the conversation. Touch was sent and received through a device's inflatable surface and a skin-like touch input button over a conventional phone. Their findings from a one-month study show that sharing a tactile vocabulary over distance was useful for expressing and understanding emotions. For positive emotions weak touches were delivered, while negative emotions were often expressed through hard, fast, and continuous touches. The findings also show that the voice, the sound of the voice, in this particular use case played an important role to understand the tactile stimulation.</p><p>Overall, these examples highlight the rich potential of touch for communicating emotions. Most recently Nummenmaa et al. <ref type="bibr" target="#b10">[11]</ref> presented maps of bodily sensations associated with different emotions. They demonstrate the validity of emotion specific activation maps across west European and East Asian samples in five experiments and conclude "emotions are represented in the somatosensory system as culturally universal categorical somatotopic maps" ( <ref type="bibr" target="#b10">[11]</ref>, p. 646). With respect to our research, the question is to what extent can these emotions be mapped towards technological features that create tactile sensations through mid-air.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotions mediated through mid-air haptics</head><p>Haptic feedback has recently received a boost through the increased attention on ultransonic haptic feedback, which is a promising means of creating tactile sensations in mid-air without encumbering the user with an actuator <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b3">4]</ref>. Haptic systems such as UltraHaptics ( <ref type="bibr" target="#b3">[4]</ref>, see Figure <ref type="figure" target="#fig_0">1</ref>) is an example using this new technique of focusing air pressure waves on the human hand from an array of ultrasound transducers. One or more focal points on the hand can be stimulated and each stimulus can be modulated by changing its frequency, duration and intensity.</p><p>While Obrist et al. <ref type="bibr" target="#b11">[12]</ref> explored the variety of tactile experiences created through such a haptic system, Wilson at al. <ref type="bibr" target="#b17">[18]</ref> studied the perception, in particular the localization and motion across the hand, for UltraHaptics. There is however no study yet done that investigates the communication potential of touch in mid-air to mediate specific emotions. Hashimoto and Kajimoto <ref type="bibr" target="#b6">[7]</ref> conducted an initial study projecting emotional information through tactile sensations on the palm using air pressure. Through changing the frequency of the vibration they demonstrated the perception of 'soft' feelings and living things in participants' hands. With a low frequency range (1 to 30Hz) participants perceived small living creatures such as a small bird or hamster, while with a medium frequency (3 to 30Hz) they imagined a dog or cat. With a high frequency range (30 to 300Hz) participants reported sensations similar to vibrating motors or solenoids. Although they show that rich tactile sensations could stimulate participants' imagination their link to emotions per se was still weak.</p><p>Considering the increased attention on haptic stimuli in relation to emotions, it is vital to systematically investigate this design opportunity for use in HCI. We help to address this challenge by devising the first controlled study of its kind using the UltraHaptics system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE STUDY</head><p>The purpose of this study is twofold. (1) As the main objective, we assess the non-arbitrary communication of emotions through haptic stimuli delivered by UltraHaptics, a haptic system that uses mid-air stimulation for creating tactile sensations. Insights from this work will help to further understand haptic communication and proving the efficacy of the UltraHaptics device in conveying emotional meanings. (2) As a secondary objective, we propose to investigate the connection between haptic stimuli and emotions by associating freely expressed haptic descriptions to controlled emotional stimulation from standardized emotional stimuli. In this way, participants will be able to represent their emotions using a vast range of emotional stimuli. However, the ambiguity of what they are actually representing will be limited by the use of welldefined affective pictures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study design and procedure</head><p>We applied the "Find-Fix-Verify" pattern, introduced by Bernstein <ref type="bibr" target="#b0">[1]</ref>, which splits complex tasks into a series of generate and review stages to produce reliable results. Although Bernstein and colleagues introduced this approach to handle complex tasks through crowdsourcing, we considered it a very good fit for our study. Considering the complexity of emotions and expressiveness through touch the collection of independent descriptions and their subsequent judgement is beneficial to produce valid results.</p><p>Three groups of participants took part in the experiment. Each group consisted of ten participants (n=30). Five emotional pictures representing valence (pleasure) and arousal extracted from the International Affective Picture System (IAPS) and with reference to the IAPS manual <ref type="bibr" target="#b9">[10]</ref> were used in our study. Positive valence and low arousal was represented by a scene from nature, calm scenery with trees [picture #7211], while positive valence and high arousal was represented through adventure sport, a scene from water rafting [picture #8370]. Negative valence and low arousal was represented through grief, a graveyard scene [picture #9001], while negative valence with high arousal was illustrated by human threat showing a car on fire [picture #8485]. As a neutral picture we selected a simple wall clock [picture #7211]). The choice of this set of pictures was carefully considered based on the picture classification established by Bradley and Lang <ref type="bibr" target="#b2">[3]</ref> (see Figure <ref type="figure" target="#fig_1">2</ref>, integrating our selection of pictures). Please note that the terms of use of the IAPS dataset do not allow one to publish the images in an article, thus we refer to the pictures through their numbers (#) through which they can be identified in the IAPS database.</p><p>Each participant in the first group was presented with 2 out of the 5 emotional pictures and asked to create a haptic description by modulating the frequency, intensity, and duration of the ultrasound stimulation. The pictures were pseudo-randomly assigned to participants, so that we could obtain four haptic descriptions for each of the five selected emotional pictures. The meaning of the haptic description was explained to the participants by the experimenter at the beginning of the study as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"Abstract artists express their emotions through colours and shapes, while musicians express them through music. You will be shown two pictures, which might elicit emotions in you. Please try to describe those emotions by varying the parameters of the tactile stimulation from the device: the frequency, intensity, duration, and the position on your palm. Ideally, another person experiencing the tactile stimulation you create will think "this is anger!" or "this is communicating happiness!" depending on the emotion you want to express. Please remember that the haptic description should represent the emotions that the picture is eliciting in you, rather than being a description of the picture itself."</head><p>After the explanation, participants were introduced to the system by playing a test stimulus consisting of 4 focal points and a diagonal pattern precisely focused on the participant's palm. This was used to make sure the position of the participant's hand was correctly placed above the array of transducers. Then participants familiarized themselves with the device for some minutes, interacting with a graphical interface for controlling the device and its properties (see Figure <ref type="figure" target="#fig_2">3</ref>, bottom left). When ready, they were asked to create the haptic description of the emotion each picture elicited in them. Participants created the haptic descriptions by leaning the non-dominant hand (left hand) on a structure posed over the haptic device (see Figure <ref type="figure" target="#fig_0">1</ref>), to allow a comfortable and steady position of the hand for the stimulation by UltraHaptics. The focal point of the device in the z dimension (height) was fixed, so that the participants only had to experience the haptic stimuli on the palm along the x and y dimensions (4x4 areas on the palm).</p><p>The choice of using the non-dominant hand was made in order to allow participants to set up the haptic description with ease using their dominant hand. Prior work has shown no differences between dominant and non-dominant hand from a perceptual point of view <ref type="bibr" target="#b17">[18]</ref>. Participants wore noise-cancelling headphones, playing pink noise, to mask any sound from the device and to remove any audio cues. The participants specified the characteristics of the haptic description using the graphical interface that is presented in more detail in the next subsection (see Figure <ref type="figure" target="#fig_2">3</ref>).</p><p>The haptic description for each picture was designed as a haptic stimulus along six pre-defined fields that could be filled and extended with more fields if wished, but not more than 12 in total. The haptic stimulation for each field could be varied with the parameters of location on the palm (12 areas), intensity (from low, medium, high), and frequency (with five options from 16Hz to 265Hz). Each individual pre-defined field had a set duration of 200ms, which could be modified by participants as well.</p><p>The second group of 10 participants' task was to confirm the appropriateness of the haptic descriptions created by the first group by ranking the four haptic descriptions for each of the five emotional pictures. From these rankings the overall best and second best haptic description (i.e., haptic stimuli: Stim1 and Stim2) for each picture were chosen. In order to do so, participants rested the non-dominant hand on the support structure as for the first group. Before starting with the task, they were also able to familiarise themselves with the haptic system following the same procedure as participants from group one. Following the ranking, the first two descriptions in terms of appropriateness for each picture were selected, achieving a total of 10 haptic descriptions to be taken further into the next review stage.</p><p>A third group of participants were then presented with the five emotional pictures in a randomized order along with the 10 haptic descriptions from group two. Participants in this group also followed the same hand positioning and went through the same device familiarization procedure as the earlier two groups. When presented with each picture, the participants of this third group experienced one after another all the 10 selected haptic descriptions, also in a randomized order. After each haptic description, the participant was asked to rate on a Likert scale from 1 to 7 (7 was the maximum level of appropriateness) the fit of the haptic description with the emotion elicited by the picture.</p><p>At the end of each test session, each participant in all three groups were presented with a short questionnaire, in which they were asked for each picture to name one to three emotions that could describe the feeling they had while looking at the pictures, and to complete the Self-Assessment Manikin <ref type="bibr" target="#b2">[3]</ref> for the emotional assessment of each picture. Participants from the third group were additionally asked how difficult it was for them to map the haptic stimuli and the emotions elicited through the pictures, as well as how confident they were with their final ratings. Presented with all 10 haptic descriptions their rating provided the final verification of the initial creations and selections from the previous groups. All participants also shared some final thoughts on their experience with the system and the mapping between touch and emotions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The interface to design the haptic description</head><p>Participants were allowed to design their haptic descriptions of the emotional pictures by interacting with a graphical user interface (see Figure <ref type="figure" target="#fig_2">3</ref>, bottom row). The interface was programmed so that the participants were able to decide about the position of the stimulus they wanted to deliver on the hand (palm) by clicking on one of the 16 areas (4x4) in the position grid. By using sliders they were subsequently able to adjust the frequency and the intensity range of the stimulus presented on the selected location. Participants could then decide to change the duration of the stimulation (in milliseconds). The default was set at 200ms. By clicking on the button "Play stimulus" participants were able to experience the stimulus they had just designed.</p><p>It is important to note that the whole haptic description of the emotional pictures could be composed of a sequence of up to six stimuli, rather than by just one stimulus in a single location. In order to create a train of stimulations in different locations, participants clicked into each of the predefined fields and they could also add more fields through a right click "Add stimulus". Participants were told that they had no obligation to fill all the six pre-defined fields. By clicking on the play button in the timeline participants were able to experience the whole haptic description they had created.</p><p>Once the position, frequency, intensity and duration for each field were decided, the haptic description was saved and all values were reset to zero to continue with the next picture following the same procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>A total of 30 participants took part in the study, 10 for each group with no participant belonging to more than one group. In each group 5 female and 5 male participants were recruited to ensure gender balance. The average age of participants was 33 years (± 9.46). Participants were recruited through University mailing lists and social media so as to have a broad variety of participants. None of the participants had ever used or interacted with a haptic system conveying tactile stimuli in mid-air. Therefore, they were all newly introduced to this interaction concept in this study. They received a small monetary compensation for their participation in the 30-minute session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis</head><p>We analyzed all the data collected for each group individually summarizing the ratings from the Likert scales and the qualitative feedback on the performed tasks.</p><p>Additionally we examined the detailed characteristics of the created haptic descriptions identifying the main parameters used in relation to the stimulated emotion (valence and arousal). By doing so we were able to extract insights into the spatial, directional, and haptic features of the created haptic descriptions. However, the main data analysis focused on the ratings obtained by the third group of participants, in order to verify the validity of the mid-air tactile stimulation in conveying emotional meaning. We tested whether participants of the third group scored the haptic descriptions selected by participants of the second group as the most appropriate in describing the picture they were created for. Moreover, we further explored correlations among 'appropriateness' ratings in order to gather more insights about the human ability in communicating emotions through tactile feedbacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>The average ratings of the pictures based on the selfassessment Manikin showed a clear match between the emotions intended by the picture from the IAPS database across all three groups. Thus we can be sure that the mapping is based on a solid foundation. In the following we present the main findings and the analysis performed from each stage of the user study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group 1: creating the haptic descriptions</head><p>Participants in the first group were each tasked to create haptic descriptions for two emotional pictures. Overall, the task was perceived as very challenging reflected in the average difficulty rating of 3.7 (± 1.95) on a scale from 1 to 7 (were 1 is very difficult to 7 not difficult at all). It took on average 10 minutes for the participants to create one haptic description, and the session lasted about 30 minutes in total.</p><p>All 10 participants perceived the positional control on the palm as the most useful parameter to create the haptic description. Thus the usefulness of the position was rated with 6 and 7 on a scale from 1 to 7 (1 is not useful at all, 7 is very useful). The usefulness of the intensity was also rated high with 7 by eight participants, one participant gave intensity a 5 and one only a 2 arguing that "the intensity wouldn't affect the emotion" [P10] (it is worth noting that P10's creation were not chosen by group two as appropriate to represent the elicited emotions). Finally the frequency range was perceived as the least useful parameter for the creation of the haptic descriptions. Half of the participants still rated it with a 7, one with 6, two participants with 5, one 4, and one with 3 out of a scale from 1 to 7. With respect to the position on the palm, and the combination with intensity and frequency, we noticed a distinction between the inner and outer part of the palm as well as the low and high intensity and frequency ranges in relation to arousal elicited through the emotional pictures.</p><p>When participants explained their final haptic description at the end of the study, they also talked about the direction and movement of their creations. One participant explained the creations for picture #8485 and picture #8370; both with high arousal, but different valence, the first a negative [car on fire] and the second [water rafting] a positive emotion. "I used a not predictable pattern for the fire picture, spreading around the palm. That is not a pattern to be easily comfortable with. In contrast to that, the pattern for the other picture with the water rafting is predictable and anticipation is possible" [P7]. The participant further explained that the predictable pattern was expressing the excitement (positive emotion), rather than the panic and fear inherent in the other picture.</p><p>Another participant confirmed this strategy in creating the haptic description for picture #8485 as well "I was creating a random pattern to express the panic. Here the order is not important but the pattern" [P9]. In contrast to that, when creating the haptic description for picture #9001</p><p>[graveyard] the rationale was: "the pattern is slow and gently progressing, there are not many changes of the position, apart from the last position, which is different and far away from the progression and has a high frequency in contrast in order to express the unexpectedness at a graveyard" [P9]. One participant specifically mentioned that the "frequency and intensity ranges are only useful at the extreme, I couldn't be bothered with the middle ranges, only 16Hz and 256Hz are needed, and high and low intensity" [P8]. This comment becomes relevant looking at the final results from group three at the verification of emotional pictures in the high and low valence ratings.</p><p>Overall, 20 haptic descriptions (four for each of the five emotional pictures) were created by group one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group 2: ranking the haptic descriptions</head><p>Participants in the second group were presented with all five emotional pictures (one after another, randomized) along with the four haptic descriptions for each picture. They could play through the different stimuli as often as they wanted until they were certain which one fitted best and second best the emotion elicited by the picture shown.</p><p>At the end of this review and selection stage 10 out of the 20 haptic descriptions were selected and ranked best (Stim1) and second best (Stim2) for each picture.</p><p>Participants rated the difficulty of this task on average with 3.75 (± 1.98) on a scale from 1 to 7, which is similar to the average rating by group one. Participants initially expressed difficulty in finding the mapping between emotions and haptics, but realized along the way that it was actually not so difficult overall. Two participant expressed it as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"To begin with it is an alien thing, you don't do it normally, think about your hand and emotions" [P6]; "I don't have an existing mental model of my palm and emotions" [P3].</head><p>Based on participants' feedback we could identify similarities between group one and two in the rationales of their choices. One participant said, that "the chaotic patterns felt more unpleasant to me" [P1], which fits the intention described above about the unpredictable pattern for expressing panic, to convey negative emotions. Another participant made the following metaphor: "the middle part of my palm is more sensitive ("accepting things" -it is like the belly, that you can only touch if you know each other well, very intimate) versus the edges of the palm which is more casual like a touch on a shoulder" [P3]. This links back to the discussion in group one on the inner and outer part of the palm conveying more or less sensitive emotions.</p><p>Participants found it easier to find a mapping of haptic descriptions and emotional stimuli for high arousal pictures than for those with low arousal. The neutral stimulus represented through a wall clock was the most difficult as it had two possible interpretations, either it was perceived as positive (time to go home) or negative (time pressure). Although participants were instructed to focus on the emotions, one participant expressed the challenge of suppressing the visual influence "I tried to focus on the haptic stimulus but the visual was overpowering" [P3].</p><p>Overall, participants perceived the location on the palm and the combinations of the areas as the most useful parameter to select the haptic stimulus for an emotion, followed by intensity as parameter and least useful the frequency that couldn't really be distinguished when playing the stimuli. One participant summarized it as such: "the palm areas were the most useful feature, followed by the intensity on which I could pick up on quickly" [P5].</p><p>At the end of this stage, we found that six participants from group one were the creators for the 10 selected stimuli, out of which both creations from four participants were chosen [P2, P5, P6, P7], plus one each from P4 and P9. These selected 10 stimuli were further presented to group three.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group 3: rating the selected haptic descriptions</head><p>Participants in the final group were presented with the final 10 haptic descriptions, which they had to rate against the five emotional pictures on a scale from 1 to 7 (1 is not appropriate at all, 7 is very appropriate -'appropriateness' ratings). In particular participants were presented with each one of the five pictures in a randomized order (one at time). While being presented with each picture participants experienced on their hand sequentially the 10 selected haptic stimuli. They were instructed to rate from 1 to 7 "How appropriate the presented haptic description is for the emotion elicited by the picture on the screen?"</p><p>Similarly to the previous two groups the difficulty level of the task received an average rating of 3.5 (± 1.17). The confidence level of participants' ratings was however quite high with an average rating of 5.8 (± 1.13) on a scale from 1 to 7 (1 is not confident at all, 7 very confident). Further we used the R software for the data analysis and statistics. As a first step in analyzing the data, we ensured that there was no difference between "appropriateness" ratings between haptic descriptions meant to describe the same emotional stimulus. To this aim, a paired t-test was performed. Ratings for the "best" describing haptic description did not differ from ratings for the "second best" haptic description. No difference was found between the two groups (t = -0.85, p-value = 0.39).</p><p>As a second step, a multiple factors repeated measure ANOVA was performed in order to assess the factors influencing the appropriateness ratings from the subject of the third group. A normality test was performed allowing us to assume a normal distribution of the data (p&gt;.05). Ratings were tested depending on: the emotional pictures. This factor had five levels, one for each of the pictures used, and the haptic stimuli: The type of haptic description, that is, whether the haptic description was intended to describe picture one, two, three, four or five. Please note that this level encompassed the ratings from both the best and the second best selected haptic descriptions, since no difference between them was shown by the previous t-test. This choice was made to allow us to have more data points per cell, therefore increasing the statistical power of the analysis (power for an effect size of 0.75 at a level of significance of 0.01 was estimated as 0.67 for the unmerged data, and as 0.99 for pooled in data). It is important to point out, however, that this analysis is considered only as a preliminary step in connecting tactile stimuli and emotional interpretation. Pooling together data only allowed us to draw a clear picture of the results. Further experiments (i.e., acquiring data from more participants) will allow us to consider best and second best descriptions separately.</p><p>Results of the ANOVA showed no main effects of the displayed picture, nor a main effect of the haptic stimulus. However, the main reason for the ANOVA was to assess the interaction between our two independent variables, given that we were interested in assessing if haptic descriptions were rated differently depending on the emotional stimuli they were presented with. The ANOVA showed an effect of the interaction between displayed picture and haptic stimulus, indicating that participants rated each haptic description differently depending on the picture displayed on the screen (F= 7.0219 , p&lt;0.001).</p><p>Simple effect analysis was used to better understand the nature of the interaction. In particular, a series of paired ttest (Bonferroni corrected) were performed. Results from these comparisons are summarised in the bar plot in Figure <ref type="figure" target="#fig_3">4a</ref>, that shows the differences between the haptic descriptions for each picture. Haptic descriptions intended to represent picture #8370 are marked as "the outer left grey bar", followed by the ones intended to represent picture #9001 and so on marked with decreasing grey scales.</p><p>In general, participants tended to assign significantly higher 'appropriateness' ratings to the descriptions when they were presented together with the picture the haptic description were intended for, therefore proving that communication of emotional meanings by means of mid-air stimulation was effective. However, participants' ratings for the haptic description for picture #8485 were always similar to the ones for picture #8370. Also ratings for haptic descriptions for pictures #9001, #7211, #5201 showed high correlations among them (see correlation plot in Figure <ref type="figure" target="#fig_3">4b</ref>, the numbers 1 to 5 refer to the five pictures and the five haptic descriptions respectively to the order shown in Figure <ref type="figure" target="#fig_3">4a</ref>).</p><p>One possible explanation for that is that participants were relatively good at interpreting the arousal conveyed by the haptic descriptions (which was, for example, similar for pictures #8370 and #8485), but not so good when it came to interpreting the valence of the emotion inspiring the haptic description (opposite for picture #8370 and #8485).</p><p>To better investigate the relations between the ratings related to each class of haptic descriptions (that is: haptic descriptions intended to describe each specific emotional picture), a metric multidimensional scaling (MDS) on two dimensions was applied (pooled together from each participant).</p><p>The correlation plot from Figure <ref type="figure" target="#fig_3">4b</ref> was transformed into a similarity matrix representing the distance among the different haptic descriptions in a two dimensional space. The number of spatial dimensions was set at two based on a scree-plot evaluation; a scree-plot displays the proportion of the total variation in a dataset that is explained by each of the components from the principal component analysis. The results from the MDS (Figure <ref type="figure" target="#fig_3">4c</ref>) show that two dimensions were enough to represent the data. Interestingly, the representation of the 'appropriateness' ratings of the haptic descriptions strongly resembled the one achieved by Bradley and Lang <ref type="bibr" target="#b2">[3]</ref> for the ratings concerning the actual emotional pictures (shown in Figure <ref type="figure" target="#fig_1">2</ref>). This further attests that it is possible to convey emotional meanings by means of mid-air tactile stimulation.</p><p>Overall, our findings suggest that the haptic descriptions match well the intended emotions (arousal and valance) elicited through the standardized pictures. Our findings however also show that people find it easier to recognize emotional arousal and harder to deal with emotional valence when going through the mapping between the haptic descriptions and their appropriateness for the elicited emotion. These specific insights provide an initial basis for exploring the emotional design space for haptics in mid-air.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DESIGN IMPLICATIONS</head><p>In this section we discuss how our findings can guide the design for emotions through mid-air haptics. To do so, we discuss the specific 'spatial', 'directional', and 'haptic' parameters represented in the selected haptic descriptions. 'Spatial' refers to the particular location on the palm, while 'directional' refers to the direction of the movement of the haptic description. The 'haptic' parameters refer to the frequency, intensity range, and the duration of the haptic stimulation. We further linked them to valence and arousal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial parameters</head><p>Our findings suggest that for a positive emotion through haptic stimulation one might want to stimulate the area around the thumb, the index finger and the middle part of the palm. These are areas selected most by participants in group one to create descriptions for the two positive pictures (#8370 and #5201). If one wants to elicit negative emotions (represented by picture #9001, #8485) the area around the little finger (pinky) and the outer parts of the palm become a relevant design space. Finally, to design for a neutral emotional stimulus, e.g., to regulate a previous extreme emotion, the haptic stimulation could target the upper end of the palm (junction between palm and fingers), which was the area dominating the two haptic descriptions of the neutral stimulus (Stim1 and Stim2 for picture #7211).</p><p>While our final dataset contains only ten haptic descriptions (two for each picture), we are confident that there is some strength in this spatial distinction as it was shown across all three groups. The meaning of the different areas on the palm is further supported by participants' feedback. Areas perceived as pleasant and associated with positive feelings are located in the middle of the palm and near the thumb. . This mapping of positive and negative emotions on the hand can be further explored based on the direction of the haptic stimulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Directional parameters</head><p>In our haptic descriptions we can also identify implications for how to direct a haptic stimulus. If you want to design for positive emotions a vertical movement of the stimulus towards the person is suggested [found in all four haptic descriptions for positive emotions; Stim1 and Stim2 for picture #8370, and Stim1 and Stim2 for picture #5201]. Such stimulation could start at the area around the thumb and move on towards the middle of the palm, or the wrist. In contrast, to design the movement of a negative haptic stimulation our findings suggest directing the stimulus away from the palm towards the fingers [found in Stim1 and Stim2 for picture #8485, Stim1 for picture #9001]. With regard to a neutral stimulation the directional parameter in both haptic stimuli were moving horizontally along the top end of the palm (junction to the fingers). We observed both directions of movement (LR &amp; RL).</p><p>The interesting design opportunity here is not only the clear change from a vertical to a horizontal stimulation pattern for neutral images but also the selected starting position. While all participants rated the picture as neutral in the selfassessment manikin questionnaire, which confirms that it elicits the intended emotion (being neutral), two of the four participants in group one interpreted the elicited emotion as more positive, while the other two interpreted it as leaning towards negative. The visual stimulus used for this emotion was a simple wall clock. P6 described the emotion elicited by the picture as "Walk home: calm, happy" (Stim1 for #7211), while P2 described the elicited emotion as "Time: pressure, tasks, work" (Stim1 for #7211). The implication is twofold: first it confirms the positive / negative mapping on the palm (described in the spatial parameters), and second it highlights the cross-sensory influence of the visual stimulus on the emotion and consequently on the haptic stimulus, which demands more attention around multi-and cross-sensory system design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Haptic parameters</head><p>Here we provide guidance on haptic parameters that elicit specific emotions. For high positive arousal one might select high frequency ranges (128 and 256Hz) combined with a high intensity (found in Stim1 for picture #8370). Stim2 for the same picture had more variety in the use of haptic parameters and explored a broader range of combinations (between 16 to 128Hz frequency range) with a variation from low, medium, and high intensities. In the end, Stim1 received higher ratings on appropriateness by group three, which suggests the use of higher frequency and intensity ranges for positive emotions with high arousal.</p><p>Looking at pictures with negative arousal, we see a similar pattern for high frequency and intensity (Stim2 for #8485 was created with only 256Hz frequency, while Stim1 for the same picture used only 16Hz; both however used high intensity). The Stim2 for picture #8485 was created by P5 in group one and the choice for a low frequency was explained as such: "I chose low for unpleasant and high for pleasant, as lower frequencies are for more energetic emotions, like a base in music" [G1, P5]. This difference in the interpretation of the use of the frequency range is a powerful design element to allow expressiveness. In the end, Stim2 was rated higher in the appropriateness for the emotion by group three, which shows the preference for high frequency ranges for negative emotions with high arousal. The design challenge in the high arousal range [#8370 and #8485] is to carefully combine the haptic parameters with the spatial and directional parameters to make a distinction between positive and negative arousal.</p><p>The design implications for the emotional stimuli with low arousal and the neutral stimuli are less clear as they represent a larger variety of design possibilities around frequency and intensity range. While all frequency ranges are possible, for the selection of the intensity our haptic descriptions provide some guidance. For positive emotions with low arousal [picture #5201] a low intensity is useful as it provides a calm and comforting sensation (e.g., [G1,P6; G1,P4; G2,P4; G2,P7; G3,P5; G3,P10]). However for a negative emotion with low arousal, the intensity is moving more towards medium intensity [Stim1 #9001] to better express the presence of negativity but not as alarming as in high arousal. Finally a neutral emotion is either to be stimulated with low or medium intensity depending on the interpretation of the elicited emotion.</p><p>Finally, the duration of the haptic stimulation suggest that for pictures with high arousal, short and quick stimuli are useful (there were no changes in any of the four haptic descriptions for #8370 and #8485, both used 200ms). For emotions with low arousal and neutral stimuli a longer stimulation time is recommended (as seen for Stim1 for picture #7211, Stim2 for picture #7211, and Stim2 for picture #5201) while for a neutral emotional stimulation, one could design breaks in the haptic stimulation as we saw in both haptic descriptions for picture #7211.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DESIGN OPPORTUNTIES</head><p>By showing the efficacy of mid-air haptics in conveying emotional meanings, a new design spectrum is opened up for emotional design. Below we describe two design ideas (use cases) combining the insights gained from our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-to-many communication</head><p>This is an idea inspired by Kaoss Pads' products and interfaces that allow performers to change parameters in an effect setting (e.g., Korg.com), such as sound effects in a musical performance (e.g., <ref type="bibr" target="#b13">[14]</ref>). Creating an emotional tactile stimulation, for instance when clubbing, and in combination with music is a possible design idea for mediating emotions through mid-air. The UltraHaptics system can render multiple focal points at distance of up to 2m while still maintaining the receiver's distinct sensation. Scenario: Imagine a high-pitched summer song in a room full of people dancing. Now they raise their hands into the air as DJ Hapster offers them some emotional stimulation in mid-air: it starts at the upper end of the palm, runs along the palm, then into the middle of the palm and back to the upper edges creating a predictable loop and a positive feeling of excitement and stability. The DJ is using high frequencies (128 to 256Hz) with high intensity to create emotional arousal. The DJ is creating the haptic stimulus by moving along the thumb and middle part of palm. If one doesn't like the stimulus, hands can be put down.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-to-one communication</head><p>This is an idea inspired by the increased interest in wearable technology within HCI, and in particular enhancing objects near our body (e.g., jewellery, cuffs, cloths, and other objects) with technology <ref type="bibr" target="#b15">[16]</ref>. Creating an emotional tactile stimulation for an individual or connecting two individuals (e.g., couples in <ref type="bibr" target="#b12">[13]</ref>) is a design idea for mediating emotions through mid-air. In contrast to the previous use case, this one is more discrete in its design and customizable for one-to-one communication. Scenario: Imagine a couple that just had a fight in the morning before going to work. She is sitting in a meeting wearing her bracelet that transmits haptic emotional messages from her partner. When she receives a new stimulus, she pulls out the string from her bracelet and connects it to her ring finger (as she is still angry, and does not want him to get near her index finger). Her partner created a haptic stimulus using a combination of 16 and 32Hz frequencies with low intensity, so that she realises he is not angry anymore. She moves the string to her index finger, receives the comforting stimulus along her right part of the hand into the middle of the palm. These are two simplified scenarios illustrating the potential of mediating emotions through mid-air haptics. We can further expand the scope of this research by exploring tactile emotional stimulation beyond the hand, inspired by promising recent work on the emotion-body map <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>Our findings show that communicating through mid-air haptics is not arbitrary and that participants were able to express and recognize tactile stimulation to convey emotional meanings. Haptic emotional descriptions were created by one set of users and validated by a different set of users, showing evidence for successful emotional communication between people through haptics. These insights open up new opportunities for interaction design in different contexts. We discussed various design directions and two design scenarios in particular showing the added value for one-to-many and one-to-one communications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The UltraHaptics system used in our study, where participants positioned their left hand above the array (20cm distance) on a soft structure to keep the hand position steady.</figDesc><graphic coords="3,322.87,61.20,128.07,90.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Selected emotional pictures from the IAPS identified by their # and allocated based on the classification [3] in low and high arousal, low and high pleasure (emotional valence).</figDesc><graphic coords="4,73.86,61.20,212.34,200.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Top Row: The study design involving 3 groups (10 participants in each group) for creating, ranking, rating the haptic descriptions. Bottom Row: the interfaces used for the 3 groups, the black boxes indicate the position of the emotional pictures.</figDesc><graphic coords="5,106.38,61.20,408.30,276.90" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) Shows the differences in interaction between each picture and the haptic descriptions. (b) Correlation plot for the ratings for the haptic descriptions for each picture; the strength and direction of the correlation is represented by the color of the ellipses. (c) MDS representation for the haptic descriptions meant to describe the emotional pictures (see details of Figure in text).</figDesc><graphic coords="8,73.50,61.20,473.16,182.10" type="vector_box" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Feeling &amp; Communicating EmotionsCHI 2015, Crossings, Seoul, Korea</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work is supported by the EC within the 7th framework programme through the European Research Council (Starting Grant Agreement 278576).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Virtual interpersonal touch: Expressing and recognizing emotions through haptic devices</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Bailenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Merget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koslow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HCI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="325" to="353" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Soylent: a word processor with a crowd inside</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Crowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Panovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;10</title>
		<meeting>UIST &apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="313" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring emotion: The self-assessment manikin and the semantic differential</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In J. Beh. Ther and Exp. Psych</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="59" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">UltraHaptics: multi-point mid-air haptic feedback for touch surfaces</title>
		<author>
			<persName><forename type="first">T</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Drinkwater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pro. UIST&apos;13, ACM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="505" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The book of touch</title>
		<author>
			<persName><forename type="first">C</forename><surname>Classen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Berg Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Can the feel of the haptic interaction modify a user&apos;s emotional state?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Caruso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bordegoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Spence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In World Haptics</title>
		<imprint>
			<biblScope unit="page" from="247" to="252" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A novel interface to present emotional tactile sensation to a palm using air pressure</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kajimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;08 ACM</title>
		<meeting>CHI &apos;08 ACM</meeting>
		<imprint>
			<biblScope unit="page" from="2703" to="2708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The communication of emotion via touch</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hertenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mccullough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keltner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Emotion</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="566" to="573" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards tactile expressions of emotion through mediated touch</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Frederiks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;13</title>
		<meeting>CHI &apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="1575" to="1580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">International Affective Picture System (IAPS): Affective ratings of pictures and instruction manual</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Cuthbert</surname></persName>
		</author>
		<idno>A-6</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Univ. of Florida</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bodily maps of emotions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nummenmaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Glerean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hietanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="646" to="651" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Talking about tactile experiences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Obrist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;13</title>
		<meeting>CHI&apos;13</meeting>
		<imprint>
			<biblScope unit="page" from="1659" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The roles of touch during phone conversations: long-distance couples&apos; use of POKE in their homes</title>
		<author>
			<persName><forename type="first">Y-W</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-M</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nam</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T-J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;13. ACM</title>
		<meeting>CHI &apos;13. ACM</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1679" to="1688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Audiopad: a tag-based interface for musical performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Patten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIME&apos;02</title>
		<meeting>NIME&apos;02<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Emotional and behavioral responses to haptic stimulation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Salminen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Surakka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lylykangas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Raisamo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raisamo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rantala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Evreinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;08, ACM</title>
		<meeting>CHI&apos;08, ACM</meeting>
		<imprint>
			<biblScope unit="page" from="1555" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fashionable Technology: The Intersection of Design, Fashion, Science, and Technology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Seymour</surname></persName>
		</author>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Communicating emotion through a haptic link: Design space and methodology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maclean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJHCS</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="376" to="387" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Brewster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;14</title>
		<meeting>CHI &apos;14</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1133" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
