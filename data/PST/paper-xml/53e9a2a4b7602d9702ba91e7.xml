<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">First Stereo Audio Source Separation Evaluation Campaign: Data, Algorithms and Results</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Emmanuel</forename><surname>Vincent</surname></persName>
							<email>emmanuel.vincent@irisa.fr</email>
							<affiliation key="aff0">
								<orgName type="department">IRISA-INRIA</orgName>
								<orgName type="laboratory">METISS Group</orgName>
								<address>
									<addrLine>Campus de Beaulieu</addrLine>
									<postCode>35042</postCode>
									<settlement>Rennes Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hiroshi</forename><surname>Sawada</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Signal Processing Research Group</orgName>
								<orgName type="institution">NTT Communication Science</orgName>
								<address>
									<addrLine>Labs 2-4, Seika-cho, Soraku-gun</addrLine>
									<postCode>619-0237</postCode>
									<settlement>Hikaridai, Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pau</forename><surname>Bofill</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Departament d&apos;Arquitectura de Computadors</orgName>
								<address>
									<addrLine>Universitat Politècnica de Catalunya Campus Nord Mòdul D6, Jordi Girona 1-3</addrLine>
									<postCode>08034</postCode>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shoji</forename><surname>Makino</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Signal Processing Research Group</orgName>
								<orgName type="institution">NTT Communication Science</orgName>
								<address>
									<addrLine>Labs 2-4, Seika-cho, Soraku-gun</addrLine>
									<postCode>619-0237</postCode>
									<settlement>Hikaridai, Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Justinian</forename><forename type="middle">P</forename><surname>Rosca</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Siemens Corporate Research</orgName>
								<address>
									<addrLine>755 College Road East</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">First Stereo Audio Source Separation Evaluation Campaign: Data, Algorithms and Results</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F7E7EAD3D3E55DB3FB7DB0BC39BA3C3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article provides an overview of the first stereo audio source separation evaluation campaign, organized by the authors. Fifteen underdetermined stereo source separation algorithms have been applied to various audio data, including instantaneous, convolutive and real mixtures of speech or music sources. The data and the algorithms are presented and the estimated source signals are compared to reference signals using several objective performance criteria.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large-scale evaluations facilitate progress in a field by revealing the effects of different choices in algorithm design, promoting common test data and evaluation criteria and attracting the interest of funding bodies. Several evaluations of audio source separation algorithms have been conducted recently, focusing on singlechannel speech mixtures 1 or multichannel over-determined speech mixtures 2,3,4 . This article provides an overview of the complementary evaluation campaign for stereo underdetermined audio mixtures organized by the authors. Detailed results of the campaign are available at http://sassec.gforge.inria.fr/.</p><p>We define the source separation task and describe test data and evaluation criteria in Section 2. Then we present the algorithms submitted by the participants in Section 3 and summarize their results in Section 4. We conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Evaluation Criteria</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Stereo Underdetermined Source Separation Task</head><p>Common audio signals, e.g. radio, television, music CDs and MP3s, are typically available in stereo (two-channel) format and consist of a mixture of more than two sound sources. Denoting by J &gt; 2 the number of sources, each channel x i (t) (1 ≤ i ≤ 2) of the mixture signal can be expressed as <ref type="bibr" target="#b0">[1]</ref> x</p><formula xml:id="formula_0">i (t) = J j=1 s img ij (t)<label>( 1 )</label></formula><p>where s img ij (t) is the spatial image of source j (1 ≤ j ≤ J) on channel i, that is the contribution of this source to the observed mixture in this channel.</p><p>Different types of mixtures can be distinguished. Instantaneous mixtures are generated via (1) using a mixing desk or dedicated software by constraining the spatial images of each source j to s img ij (t) = a ij s j (t), where s j (t) is a singlechannel source signal and a ij are positive mixing gains. Synthetic convolutive mixtures are obtained similarly via s img ij (t) = τ a ij (τ )s j (tτ ), where a ij (τ ) are mixing filters. Live recordings are acquired by recording all the sources simultaneously in a room using a pair of microphones. These recordings may also be obtained by recording the sources one at a time in the same room and adding the resulting source images together within each channel <ref type="bibr" target="#b1">[2]</ref>.</p><p>We define the source separation task as that of estimating the spatial images s img ij (t) of all sources j on all channels i from the two channels x i (t) of a mixture. This definition has two advantages: it is valid for all types of mixtures, even with spatially extended sources that cannot be represented as single-channel signals, and potential gain or filtering indeterminacies about the estimated single-channel source signals s j (t) disappear when considering their spatial images instead <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Development and Test Data</head><p>The development and test data used for the evaluation campaign involved four classes of signals: male speech, female speech, non-percussive music and music including drums. Music mixtures involved three sources taken from synchronized multitrack recordings, while speech mixtures involved four independent sources. All the source signals were sampled at 16 kHz and had a duration of 10 s. The development data consisted of one instantaneous mixture, two synthetic convolutive mixtures and two live recordings per class. Instantaneous mixtures were generated by scaling the source signals by positive gains. Live recordings were acquired by playing the source signals through loudspeakers in a room at NTT with RT 60 = 250 ms reverberation time and recording them using two pairs of omnidirectional microphones with spacings of 5 cm and 1 m. Figure <ref type="figure" target="#fig_0">1</ref> depicts the arrangement of loudspeakers and microphones. Synthetic convolutive mixtures were obtained by filtering the sources with simulated room impulse responses computed for the same arrangement using Roomsim 5 . Ground truth data, i.e. the source signals, their spatial images and the mixing filters or gains, were distributed with the mixture signals at http://sassec.gforge.inria.fr/. The same number of test data was obtained similarly to the development data, using different source signals and positions for each mixture. The distances of the sources from the center of the microphone pairs were drawn randomly between 80 cm and 1.2 m and their angles of arrival between -60 • and +60 • with a minimal spacing of 15 • . The mixture signals were made available, but ground truth data, including the exact source positions, was kept hidden<ref type="foot" target="#foot_1">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loudspeakers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Objective Performance Criteria</head><p>The participants were asked to provide estimates ŝimg ij (t) of the spatial images of all sources j for some test mixtures. The quality of these estimates was then evaluated by comparison with the true source images s img ij (t) using four objective performance criteria, inspired from criteria previously designed for singlechannel source estimates <ref type="bibr" target="#b2">[3]</ref>. By contrast with other existing measures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, the proposed criteria can be computed for all types of separation algorithms and do not necessitate knowledge of the separating filters or masks.</p><p>The criteria derive from the decomposition of an estimated source image as</p><formula xml:id="formula_1">ŝimg ij (t) = s img ij (t) + e spat ij (t) + e interf ij (t) + e artif ij (t)<label>( 2 )</label></formula><p>where s img ij (t) is the true source image and e spat ij (t), e interf ij (t) and e artif ij (t) are distinct error components representing spatial (or filtering) distortion, interference and artifacts. This decomposition is motivated by the auditory distinction between sounds from the target source, sounds from other sources and "gurgling" noise, corresponding to the signals s img ij (t) + e spat ij (t), e interf ij (t) and e artif ij (t) respectively. The computational modeling of this auditory segregation process is an open issue so far. For simplicity, we chose to express spatial distortion and interference components as filtered versions of the true source images, computed by least-squares projection of the estimated source image onto the corresponding signal subspaces <ref type="bibr" target="#b2">[3]</ref> </p><formula xml:id="formula_2">e spat ij (t) = P L j (ŝ img ij )(t) -s img ij (t)<label>( 3 )</label></formula><formula xml:id="formula_3">e interf ij (t) = P L all (ŝ img ij )(t) -P L j (ŝ img ij )(t)<label>( 4 )</label></formula><formula xml:id="formula_4">e artif ij (t) = ŝimg ij (t) -P L all (ŝ img ij )(t)<label>( 5 )</label></formula><p>where P L j is the least-squares projector onto the subspace spanned by s img kj (t-τ ), 1 ≤ k ≤ I, 0 ≤ τ ≤ L-1, and P L all is the least-squares projector onto the subspace spanned by</p><formula xml:id="formula_5">s img kl (t -τ ), 1 ≤ k ≤ I, 1 ≤ l ≤ J, 0 ≤ τ ≤ L -1.</formula><p>The filter length L was set to 512 (32 ms), which was the maximal tractable length.</p><p>The relative amounts of spatial distortion, interference and artifacts were then measured using three energy ratio criteria expressed in decibels (dB): the source Image to Spatial distortion Ratio (ISR), the Source to Interference Ratio (SIR) and the Sources to Artifacts Ratio (SAR), defined by ISR j = 10 log 10</p><formula xml:id="formula_6">I i=1 t s img ij (t) 2 I i=1 t e spat ij (t) 2<label>(6)</label></formula><p>SIR j = 10 log 10</p><formula xml:id="formula_7">I i=1 t (s img ij (t) + e spat ij (t)) 2 I i=1 t e interf ij (t) 2<label>(7)</label></formula><p>SAR j = 10 log 10</p><formula xml:id="formula_8">I i=1 t (s img ij (t) + e spat ij (t) + e interf ij (t)) 2 I i=1 t e artif ij (t) 2 . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>The total error was also measured by the Signal to Distortion Ratio (SDR) SDR j = 10 log 10</p><formula xml:id="formula_10">I i=1 t s img ij (t) 2 I i=1 t (e spat ij (t) + e interf ij (t) + e artif ij (t)) 2<label>(9)</label></formula><p>We emphasize that this measure is arbitrary, in the sense that it weights the three error components equally. In practice, each component should be given a different weight depending on the application. For instance, spatial distortion is of little importance for most applications, except for karaoke where it can result in imperfect source cancellation, even in the absence of interference or artifacts. Similarly, artifacts are crucial for hearing aid applications, for which "gurgling" noise should be avoided at the cost of increased interference. These criteria were implemented in Matlab and distributed at http://sassec.gforge.inria.fr/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithms</head><p>The campaign involved thirteen participants, who submitted the results of fifteen source separation algorithms. The underlying approaches are summarized in  <ref type="bibr" target="#b11">[11]</ref> with STFT bins selected as in <ref type="bibr" target="#b12">[12]</ref> Online FFT-domain minimumvariance beamforming <ref type="bibr" target="#b14">[13]</ref> 6 N. Mitianoudis Soft IID clustering given the number of sources <ref type="bibr" target="#b15">[14]</ref> Binwise MDCT projection onto the nearest IID subspace <ref type="bibr">[</ref> Extension of <ref type="bibr" target="#b17">[16]</ref> with more active sources in some time frames</p><p>Algorithms for instantaneous and/or convolutive mixtures 11 S. Araki Soft (IID,ITD) clustering given the number of sources <ref type="bibr" target="#b18">[17]</ref> Maximum SNR beamforming <ref type="bibr" target="#b20">[18]</ref> and soft STFT masking <ref type="bibr" target="#b21">[19]</ref> 12 Y. Izumi Soft clustering of the mixture STFT bins based on (IID,IPD) given the number of sources <ref type="bibr" target="#b22">[20]</ref> Soft STFT masking by cluster probabilities <ref type="bibr" target="#b22">[20]</ref> 13 T. Kim FFT-domain independent component analysis <ref type="bibr" target="#b23">[21]</ref> and soft masking (two sources only) 14 R. Weiss &amp; M. Mandel Soft (IID,IPD) clustering given the number of sources <ref type="bibr" target="#b24">[22]</ref> Soft STFT masking by cluster probabilities <ref type="bibr" target="#b24">[22]</ref> 15 H. Sawada</p><p>Frequency-wise (IID,IPD) clustering given the number of sources as in <ref type="bibr" target="#b18">[17]</ref> and sorting <ref type="bibr" target="#b25">[23]</ref> Binary STFT masking Table <ref type="table" target="#tab_0">1</ref>. All algorithms except n • 13 could be broken into (possibly iterated) source localization and source signal estimation steps. These two steps were conducted in the time-frequency domain via a Short-Time Fourier Transform (STFT) or a </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The performance of each algorithm was assessed by sorting the estimated source image signals so as to maximize the average SIR and successively averaging the measured SDR, ISR, SIR and SAR over the sources and over the mixtures. The resulting figures are given in Tables <ref type="table" target="#tab_2">2</ref> and<ref type="table" target="#tab_3">3</ref> for instantaneous and convolutive mixtures respectively, along with platform-specific computation times. The large negative SDR and ISR figures for algorithms n • 5, 6, 12 and 13 are due to incorrect scaling of the submitted source images. Detailed results and sound files are available at http://sassec.gforge.inria.fr/.</p><p>In the instantaneous case, most algorithms provided similar SIR and SAR values clustered around 13 dB and 6 dB respectively, denoting high interference rejection but clear artifacts. Algorithms n • 2 and 8 resulted in fewer artifacts, while algorithms n • 10 and 14 provided more interference. Note that blind algorithms n • 9 and 10 achieved similar source localization accuracy as non-blind algorithms n • 3, 7 and 8, as shown by large ISR values.</p><p>In the convolutive case, most algorithms provided again similar SIR and SAR values but around 4 dB and 6 dB respectively, indicating both strong interference and artifacts. Algorithms n • 11 and 15 resulted in slightly less interference, while algorithm n • 14 provided much more interference but less artifacts. Interestingly, performance did not vary much between synthetic convolutive mixtures and live recordings or with different microphone spacings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this article, we described the test data and objective performance criteria used in the context of the first stereo audio source separation evaluation campaign and summarized the approaches behind the fifteen submitted algorithms and their results. We are currently planning to complement objective performance figures by listening tests and present detailed results on the campaign website. We hope that this campaign fosters interest for evaluation in the source separation community and that larger-scale regular campaigns will take place in the future. The creation of a collaborative organization framework appears crucial to this aim, since it would allow sharing between the participants of time-consuming tasks such as the collection of test data under appropriate licenses and the recording of live mixtures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>ig. 1 .</head><label>1</label><figDesc>Recording arrangement used for development data. Only three of the four loudspeakers were used for music mixtures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Submitted source separation algorithms</figDesc><table><row><cell>N • Submitter</cell><cell>Source localization</cell><cell>Source signal estimation</cell></row><row><cell>Name</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Algorithms for instantaneous mixtures only</cell></row><row><cell>1 D. Barry</cell><cell>Manual IID clustering from a</cell><cell>Source magnitude estimation in</cell></row><row><cell>ADRess</cell><cell>magnitude-weighted histogram</cell><cell>the STFT bins associated with</cell></row><row><cell></cell><cell>with auditory feedback [6]</cell><cell>each IID cluster [6]</cell></row><row><cell>2 P. Bofill</cell><cell>Peak picking on a smoothed IID</cell><cell>Minimization of the l1 norm of</cell></row><row><cell></cell><cell>histogram [7] with STFT bins</cell><cell>the real and imaginary parts of</cell></row><row><cell></cell><cell>selected as in [8]</cell><cell>the source STFTs [9]</cell></row><row><cell>3 A. Ehmann</cell><cell>Manual peak picking on an IID</cell><cell>Binary STFT masking with dif-</cell></row><row><cell></cell><cell>histogram</cell><cell>ferent resolutions at high/low</cell></row><row><cell></cell><cell></cell><cell>frequencies</cell></row><row><cell cols="2">4 V. Gowreesunker Peak picking on a thresholded</cell><cell>Binwise MDCT projection onto</cell></row><row><cell></cell><cell>IID histogram [10]</cell><cell>the nearest IID subspace [10]</cell></row><row><cell>5 M. Kleffner</cell><cell>Peak picking on a thresholded</cell><cell></cell></row><row><cell></cell><cell>IID histogram</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Results for instantaneous mixtures</figDesc><table><row><cell cols="2">Algorithm 1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5 7</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>14</cell></row><row><cell cols="2">SDR (dB) 4.0</cell><cell>4.2</cell><cell>6.8</cell><cell cols="6">3.5 -23.4 -16.0 7.2 10.3 5.8</cell><cell cols="2">2.7 -2.4</cell></row><row><cell cols="2">ISR (dB) 7.5</cell><cell cols="10">8.2 13.9 6.2 -21.8 -12.8 14.6 19.2 15.9 20.0 4.1</cell></row><row><cell cols="12">SIR (dB) 13.2 12.9 15.5 14.4 12.8 13.2 15.9 16.0 10.7 6.8 -3.0</cell></row><row><cell cols="4">SAR (dB) 5.3 10.8 7.8</cell><cell>5.5</cell><cell>5.9</cell><cell>5.3</cell><cell cols="3">8.1 12.2 5.8</cell><cell>8.7</cell><cell>4.2</cell></row><row><cell>Time (s)</cell><cell>1</cell><cell>300</cell><cell>5</cell><cell>10</cell><cell cols="2">600 200</cell><cell>9</cell><cell>5</cell><cell>2</cell><cell>2</cell><cell>1000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Results for synthetic convolutive mixtures and live recordings with two dif-Modified Discrete Cosine Transform (MDCT), except for algorithms n • 9 and 10 where source estimation was directly performed in the time domain. The directions of the sources were modeled by the Interchannel Intensity Difference (IID) or variants thereof in the instantaneous case. The Interchannel Time Difference (ITD) or the Interchannel Phase Difference (IPD) were additionally used in the convolutive case. Algorithms n • 2, 4, 5, 9 and 10 were fully blind, while others required manual input of the number of sources or the source directions.</figDesc><table><row><cell cols="3">ferent microphone spacings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Mixtures</cell><cell cols="4">Synth 5 cm Synth 1 m</cell><cell></cell><cell></cell><cell cols="2">Live 5 cm</cell><cell>Live 1 m</cell></row><row><cell cols="3">Algorithm 11 7 14 15</cell><cell>14</cell><cell cols="5">15 11 7 12 7 13 8 14</cell><cell>15 13 8 14</cell><cell>15</cell></row><row><cell cols="9">SDR (dB) 2.5 0.9 0.2 0.7 0.6 2.6 -23.2 -20.3 1.2 1.8 -19.0 2.1 3.6</cell></row><row><cell>ISR (dB)</cell><cell cols="8">6.0 2.8 4.6 2.8 4.4 5.9 -19.2 -17.0 4.0 7.0 -15.5 4.9 8.4</cell></row><row><cell>SIR (dB)</cell><cell cols="8">5.8 -2.7 4.4 -0.4 4.2 4.6 1.3 2.9 -1.9 4.2 2.9 0.8 6.9</cell></row><row><cell cols="9">SAR (dB) 4.9 14.1 7.5 10.7 7.5 5.4 6.2 6.2 13.0 6.8 5.8 8.0 6.8</cell></row><row><cell cols="2">Time (min) 1</cell><cell cols="3">20 0.6 20 0.6</cell><cell>1</cell><cell>1</cell><cell>4</cell><cell>20 0.6</cell><cell>4</cell><cell>20 0.6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0"><p>http://media.paisley.ac.uk/˜campbell/Roomsim/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1"><p>Only the first two authors of this article had potentially access to these data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2"><p>Average performance for speech mixtures only.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3"><p>Average performance over the two estimated sources for speech mixtures only.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multidimensional independent component analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>IEEE Int. Conf. on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1941" to="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluation of blind signal separation methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schobben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Torkkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Independent Component Analysis and Blind Source Separation (ICA)</title>
		<meeting>Int. Conf. on Independent Component Analysis and Blind Source Separation (ICA)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="261" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Performance measurement in blind audio source separation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1462" to="1469" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey of the performance indexes of ICA algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ohnishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IASTED Int. Conf. on Modelling, Identification and Control (MIC)</title>
		<meeting>IASTED Int. Conf. on Modelling, Identification and Control (MIC)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="660" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Blind separation of speech mixtures via time-frequency masking</title>
		<author>
			<persName><forename type="first">O</forename><surname>Yılmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Rickard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1830" to="1847" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-time sound source separation using azimuth discrimination and resynthesis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Coyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lawlor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 117th AES Convention</title>
		<meeting>117th AES Convention</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>preprint 6258</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Underdetermined blind source separation using sparse representations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bofill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="2353" to="2362" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A novel approach for underdetermined blind source separation in the frequency domain</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISNN 2005</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X.-F</forename><surname>Liao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3498</biblScope>
			<biblScope unit="page" from="484" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Underdetermined convoluted source reconstruction using LP and SOCP, and a neural approximator of the optimizer</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bofill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Monte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICA 2006</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Rosca</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Erdogmus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Príncipe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3889</biblScope>
			<biblScope unit="page" from="569" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Two improved sparse decomposition methods for blind source separation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Gowreesunker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Tewfik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Independent Component Analysis and Blind Source Separation</title>
		<meeting>Int. Conf. on Independent Component Analysis and Blind Source Separation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Localization of nonstationary sources using a coherence test</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop on Statistical Signal Processing</title>
		<meeting>IEEE Workshop on Statistical Signal essing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="470" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A robust method to count and locate audio sources in a stereophonic linear instantaneous mixture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arberet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bimbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICA 2006</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Rosca</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Erdogmus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Príncipe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3889</biblScope>
			<biblScope unit="page" from="536" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Performance of time-and frequency-domain binaural beamformers based on recorded signals from real rooms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Lockwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bilger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Lansing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>O'brien</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="379" to="391" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Underdetermined source separation using mixtures of warped Laplacians</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mitianoudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stathaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Independent Component Analysis and Blind Source Separation</title>
		<meeting>Int. Conf. on Independent Component Analysis and Blind Source Separation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Complex nonconvex lp norm minimization for underdetermined source separation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Independent Component Analysis and Blind Source Separation</title>
		<meeting>Int. Conf. on Independent Component Analysis and Blind Source Separation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A statistically sparse decomposition principle for underdetermined blind source separation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. on Intelligent Signal Processing and Communication Systems (ISPACS)</title>
		<meeting>Int. Symp. on Intelligent Signal essing and Communication Systems (ISPACS)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="165" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Soft-LOST: EM on a mixture of oriented lines</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>O'grady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICA 2004</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Puntonet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Prieto</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3195</biblScope>
			<biblScope unit="page" from="428" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Blind speech separation in a meeting situation with maximum SNR beamformers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>IEEE Int. Conf. on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Blind source separation based on beamformer array and time-frequency binary masking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cermak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>IEEE Int. Conf. on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="145" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sparseness-based 2ch BSS using the EM algorithm in reverberant environment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Izumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Submitted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</title>
		<imprint>
			<publisher>WASPAA</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Blind source separation exploiting higher-order frequency dependencies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Attias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="70" to="79" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An EM algorithm for localizing multiple sound sources in reverberant environments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P W</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS 19</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Measuring dependence of bin-wise separated signals for permutation alignment in frequency-domain BSS</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. on Circuits and Systems (ISCAS)</title>
		<meeting>IEEE Int. Symp. on Circuits and Systems (ISCAS)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3247" to="3250" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
