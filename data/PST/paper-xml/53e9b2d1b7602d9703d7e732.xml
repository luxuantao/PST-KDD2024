<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Differentially Private Frequent Itemset Mining *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chen</forename><surname>Zeng</surname></persName>
							<email>zeng@cs.wisc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jeffrey</forename><forename type="middle">F</forename><surname>Naughton</surname></persName>
							<email>naughton@cs.wisc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jin-Yi</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">The 39th International Conference on Very Large Data Bases</orgName>
								<address>
									<addrLine>Riva del Garda</addrLine>
									<postCode>26th -30th 2013</postCode>
									<settlement>August, Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Differentially Private Frequent Itemset Mining *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9B09378C4FDF840CAA6A0C70789FD8C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider differentially private frequent itemset mining. We begin by exploring the theoretical difficulty of simultaneously providing good utility and good privacy in this task. While our analysis proves that in general this is very difficult, it leaves a glimmer of hope in that our proof of difficulty relies on the existence of long transactions (that is, transactions containing many items). Accordingly, we investigate an approach that begins by truncating long transactions, trading off errors introduced by the truncation with those introduced by the noise added to guarantee privacy. Experimental results over standard benchmark databases show that truncating is indeed effective. Our algorithm solves the "classical" frequent itemset mining problem, in which the goal is to find all itemsets whose support exceeds a threshold. Related work has proposed differentially private algorithms for the top-k itemset mining problem ("find the k most frequent itemsets".) An experimental comparison with those algorithms show that our algorithm achieves better F -score unless k is small.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Recently, concomitant with the increasing ability to collect personal data, privacy has become a major concern. In this paper, we focus on privacy issues that arise in the context of finding frequent itemsets in "transactional" data. Frequent itemset mining is widely used in many applications, perhaps the best known of which is market basket analysis. The goal of frequent itemset mining in market basket analysis is to find sets of items that are frequently bought together, which is helpful in applications ranging from product placement to marketing and beyond. Developing efficient algorithms for frequent itemset mining has been widely studied by our community <ref type="bibr" target="#b13">[15]</ref>. However, with the exception of the recent work in <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b14">16]</ref>, a differentially private approach to frequent itemset mining has received little attention.</p><p>A frequent itemset mining algorithm takes as input a dataset consisting of the transactions by a group of individuals, and produces as output the frequent itemsets. This immediately creates a privacy concern -how can we be confident that publishing the frequent itemsets in the dataset does not reveal private information about the individuals whose data is being studied? This problem is compounded by the fact that we may not even know what data the individuals would like to protect nor what background information might be possessed by an adversary. These compounding factors are exactly the ones addressed by differential privacy <ref type="bibr" target="#b7">[9]</ref>, which intuitively guarantees that the presence of an individual's data in a dataset does not reveal much about that individual. Accordingly, in this paper we explore the possibility of developing differentially private frequent itemset mining algorithms. Our goal is to guarantee differential privacy without obliterating the utility of the algorithm.</p><p>We quantify the utility of a differentially private frequent itemset mining algorithm by its likelihood to produce a complete and sound result. Intuitively speaking, "completeness" requires an algorithm to include all the sufficiently "frequent" itemsets, and "soundness" requires an algorithm to exclude all the sufficiently "infrequent" ones. We start by a theoretical investigation of the tradeoff between privacy and utility in frequent itemset mining. Our result unfortunately indicates that the problem is very hard -that is, in general, one cannot simultaneously guarantee high utility and a high degree of privacy.</p><p>However, a closer investigation of this negative result reveals that it relies on the possibility of very long transactions (that is, transactions with many items). This raises the possibility of improving the utility-privacy tradeoff by limiting transactions' cardinality. Of course, one cannot in general impose such a limit -so instead, we explore enforcing the limit by truncating transactions. That is, if a transaction has more than a specified number of items, we delete items until the transaction is under the limit. Of course, this deletion must be done in a differentially private way; perhaps equally important, while it reduces the error due to the noise required to enforce privacy, it introduces a new source of error by discarding items from transactions. Exploring the impact of this tradeoff is one of the contributions of our work. Our experimental results with four datasets indicate that truncating has a large positive impact on quality.</p><p>For ease of exposition, we go from this observation to a differentially private frequent itemset mining algorithm by a series of steps. First, we explore how to find frequent 1-itemsets (itemsets with only one item). Next, we generalize this to find frequent β-itemsets (itemsets with β items). Finally, we generalize this to solve the full problem: in a differentially private way, find all the itemsets whose support exceeds a given threshold. We found that each of these steps was non-trivial and had to be done with care to ensure privacy without destroying utility.</p><p>Finally, we compare our work with interesting recent work on differentially private top-k frequent itemset mining <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b14">16]</ref>. This problem is somewhat different from the one we address ("find all itemsets whose support exceeds a threshold") but it is similar enough to allow a comparison. For example, one can use our algorithm with a sufficiently low threshold to guarantee that k itemsets will be found to solve the top-k problem; or one can use a top-k algorithm with k set large enough to find all the itemsets whose support exceeds a threshold. Our experimental study with four benchmark datasets shows that our algorithm produces a result with a higher F -score than either of the top-k algorithms unless k is very small (e.g., k ∼ 10).</p><p>The rest of the paper is organized as follows: Section 2 briefly describes the problem of frequent itemset mining, and the notion of differential privacy. Section 3 explores the trade-off between utility and privacy in frequent itemset mining. Section 4 proposes our differentially private frequent 1-itemset mining algorithm. Section 5 generalizes the idea of truncating transactions to frequent β-itemset mining. Section 6 extends our β-itemset mining algorithm to frequent itemset mining. Section 7 evaluates our algorithm on benchmark datasets. Section 8 discusses related work, and Section 9 concludes our work. Most of the proofs and the pseudocode of some algorithms can be found in the long version of our paper available at [1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PRELIMINARIES</head><p>In this section, we review the problem of frequent itemset mining <ref type="bibr" target="#b0">[2]</ref>, and the notion of differential privacy <ref type="bibr" target="#b7">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Frequent Itemset Mining</head><p>We model a database τ as a vector in D m , where each entry represents the information contributed by an individual from the domain D. In our context, the database in frequent itemset mining is called a transaction database.</p><p>Definition 1. (Transaction database): A transaction database is a vector of transactions τ = t1, . . ., tm where each transaction ti is a subset of the alphabet I = {1, . . . , n}.</p><p>The domain of a single transaction is thus the power set of the alphabet I. In this paper, we use "database" as a shorthand for "transaction database." Each subset of the alphabet I is called an itemset. If the number of transactions containing an itemset exceeds a predefined threshold, then that itemset is called a frequent itemset. Definition 2. (Frequent itemset): For any itemset X, the support of X in a database is the number of transactions containing X. If that number exceeds a predefined threshold λ, then X is called a frequent itemset with respect to the threshold λ.</p><p>In the rest of this paper, we assume the threshold λ is given, and use the term "frequent itemsets" as a shorthand for "frequent itemsets with respect to the threshold" when the threshold is clear from the context. For ease of presentation, we denote "the itemsets of cardinality (number of elements) β" by "β-itemsets", and the query that computes the support of a β-itemset by a "β-itemset query." A βitemset query is a count query which computes the number of transactions containing the given itemset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Differential Privacy</head><p>Intuitively, differential privacy guarantees that the presence or absence of an individual's information has little effect on the output of an algorithm, and thus, an adversary can learn limited information about any individual. In our context, the information contributed by an individual is her transaction. More precisely, for any database τ ∈ D m , let nbrs(τ ) denote the set of neighboring databases of τ , each of which differs from τ by at most one transaction. Differential privacy requires that the probabilities of an algorithm to output the same result on any pair of neighboring databases are bounded by a constant ratio. Definition 3. (ǫ-differential privacy <ref type="bibr" target="#b7">[9]</ref>): For any input database τ , a randomized algorithm f is ǫ-differentially private iff for any S ⊆ Range(f ), and any database τ ′ ∈ nbrs(τ ),</p><formula xml:id="formula_0">Pr(f (τ ) ∈ S) ≤ e ǫ × Pr(f (τ ′ ) ∈ S)</formula><p>where Pr is the probability taken over the coin tosses of the algorithm f . One way to guarantee differential privacy for a count query is to perturb the correct result. In particular, Ghosh et al. <ref type="bibr" target="#b10">[12]</ref> propose the geometric mechanism to guarantee ǫdifferential privacy for a single count query. The geometric mechanism adds noise ∆ drawn from the two-sided geometric distribution G(ǫ) with the following probability distribution: for any integer σ,</p><formula xml:id="formula_1">Pr(∆ = σ) ∼ e -ǫ|σ|<label>(1)</label></formula><p>The geometric mechanism is a discrete variant of the wellstudied Laplacian mechanism <ref type="bibr" target="#b8">[10]</ref>, which adds random noise drawn from the Laplacian distribution. To ensure differential privacy for multiple count queries, we first compute the sensitivity of those queries, which is the largest difference between the output of those queries on any pair of neighboring databases. Definition 4. (Sensitivity): Given d count queries, q = q1, . . . , q d , the sensitivity of q is:</p><formula xml:id="formula_2">Sq = max ∀τ,τ ′ ∈nbrs(τ ) |q(τ ) -q(τ ′ )|1</formula><p>Notice that the output of q is a vector of dimension d, and we use |x -y|p to denote the Lp distance between two vectors x and y. The following theorem is a straightforward extension of the Laplacian mechanism to the geometric mechanism.</p><p>Theorem 1. Given d count queries q = q1, . . . , q d , for any database τ , the database access mechanism: Aq(τ ) = q(τ ) + ∆1, . . . , ∆ d where ∆i is drawn i.i.d from the geometric distribution G(ǫ/Sq) (1), guarantees ǫ-differential privacy for q.</p><p>As proved in <ref type="bibr" target="#b8">[10]</ref>, a sequence of differentially private computations also ensures differential privacy. This is called the composition property of differential privacy as shown in Theorem 2.</p><p>Theorem 2. <ref type="bibr" target="#b8">[10]</ref> Given a sequence of computations, denoted as f = f1,. . .,f d , if each computation fi guarantees ǫi-differential privacy, then f is ( i=d i=1 ǫi)-differentially private.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A TRADE-OFF BETWEEN PRIVACY AND UTILITY</head><p>In this section, we present a theoretical study on the tradeoff between utility and privacy in differentially private frequent itemset mining. First, we formally define the utility of a frequent itemset mining algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Our Utility Model</head><p>Our definition of utility follows that proposed in <ref type="bibr" target="#b3">[5]</ref>. Intuitively, if the support of an itemset is much larger than the threshold, then the result should include that itemset; on the other hand, if the support of an itemset is much smaller than the threshold, then that itemset should be excluded from the output. We specify two criteria to capture that intuition in Definition 5.</p><p>Definition 5. (δ-approximation): Given a database τ and a threshold λ, let S be the output of a frequent itemset mining algorithm on the database τ . We say S is δapproximate iff the following two properties are satisfied:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">(Completeness) Every itemset with support exceeding</head><p>(1 + δ)λ is in S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">(Soundness)</head><p>No itemset with support less than (1-δ)λ is in S.</p><p>We quantify the utility of a frequent itemset mining algorithm by its likelihood to produce a good approximate result as shown in Definition 6. Definition 6. ((δ, η)usef ulness): A frequent itemset mining algorithm f is (δ, η)-useful iff for any database τ , with probability at least 1η, the output of f on τ is δapproximate.</p><p>Both δ and η are within the range (0, 1) by definition. Next, we quantify the trade-off between privacy and utility for frequent itemset mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A Lower Bound on the Privacy Parameter</head><p>Let us first consider a constrained frequent itemset mining problem in which we are only interested in frequent 1itemsets. We call that problem frequent 1-itemset mining. Lemma 1 shows the lower bound on the privacy parameter ǫ if a frequent 1-itemset mining algorithm must be both (δ, η)-useful and ǫ-differentially private.</p><p>Lemma 1. For any frequent 1-itemset mining algorithm that is both ǫ-differentially private and (δ, η)-useful,</p><formula xml:id="formula_3">ǫ ≥ ln[(2 n -1)η ′ ] 2δλ + 2</formula><p>where η ′ = (1η)/η.</p><p>Note that a (δ, η)-useful frequent itemset mining algorithm is also a (δ, η)-useful frequent 1-itemset mining algorithm. Thus, Lemma 1 implies Theorem 3. Theorem 3. For any frequent itemset mining algorithm that is both ǫ-differentially private and (δ, η)-useful,</p><formula xml:id="formula_4">ǫ ≥ ln[(2 n -1)η ′ ] 2δλ + 2</formula><p>where η ′ = (1η)/η.</p><p>In a typical transaction database like BMS-WebView-2 shown in <ref type="bibr" target="#b20">[22]</ref>, n = 3340. Therefore, if we set λ = 310, which is 0.4% of the total number of transactions, δ = 0.2 and η = 0.5, then ǫ ≥ 18.4. That lower bound shows that no matter how sophisticated a differentially private frequent itemset mining algorithm is, in order to guarantee (0.2, 0.5)usefulness, the privacy parameter ǫ must exceed 18.4, which suggests a huge risk of privacy breach. This is a discouraging result. However, the proof of Lemma 1 requires the existence of very long transactions. This observation motivated us to study the approach of eliminating the possibility of these long transactions by truncating them. In the next few sections we use this observation to develop a differentially private algorithm that works on a truncated database, then explore its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FREQUENT 1-ITEMSET MINING</head><p>In this section, as the first step in the development of our frequent itemset mining algorithm, we consider the simpler problem of frequent 1-itemset mining. We will show that by truncating transactions, we can significantly promote the utility of frequent 1-itemset mining while still guaranteeing differential privacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Intuition for Truncating Transactions</head><p>By fixing the threshold λ, and setting the utility parameters δ, η to constants, Lemma 1 suggests that we cannot set the privacy parameter for frequent 1-itemset mining to any value that is not Ω n . An intuition for this is that the addition of a "long" transaction can drastically change the result of the mining algorithm. However, we will show, by limiting the maximal cardinality of transactions, there exists a frequent 1-itemset mining algorithm that is both (δ, η)-useful and ǫ-differentially private provided ǫ ≥ Ω log n . We construct that algorithm by utilizing the geometric mechanism.</p><p>We can formulate the problem of frequent 1-itemset mining by first computing n 1-itemset queries q = q1, . . . , qn , where each qi computes the support of the 1-itemset {i}, and then selecting those 1-itemsets whose support exceeds the threshold. We observe that as long as we compute q in a differentially private way, the frequent 1-itemset mining algorithm will be differentially private. Theorem 4 shows that the sensitivity of computing q is equal to the maximal cardinality of transactions.</p><p>Theorem 4. Let ℓ be the maximal cardinality of transactions. The sensitivity of computing n different 1-itemset queries is ℓ.</p><p>For ease of presentation, we refer to the frequent 1-itemset mining algorithm, which first adds geometric noise to the support, and then checks the threshold, as the "geometric Theorem 5. Given the maximal cardinality ℓ, where ℓ = O 1 , then the geometric noise algorithm is both (δ, η)-useful and ǫ-differentially private provided ǫ ≥ Ω log n .</p><p>We can also prove that the geometric noise algorithm is optimal as shown in Theorem 6. Theorem 6. For any frequent 1-itemset mining algorithm that is both (δ, η)-useful and ǫ-differentially private, ǫ must be Ω log n provided the maximal cardinality ℓ = O 1 .</p><p>Both Theorem 5 and Theorem 6 suggest that the constraint on the maximal cardinality of transactions has a significant impact on the utility of a differentially private frequent 1-itemset mining algorithm. This suggests that we can improve the utility/privacy tradeoff by enforcing a maximal cardinality on transactions. We do so by truncating transactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Rationale in Truncating Transactions</head><p>Our idea of limiting the maximal cardinality of transactions is simple -we truncate a transaction whose cardinality violates that constraint by only keeping a subset of that transaction. Of course, that truncating approach incurs certain information loss. However, if the cardinality of transactions in a dataset follows a distribution in which most are "short" and a few are "long", then these few "long" transactions, while having little impact on which itemsets are frequent, have a major effect on the sensitivity. If this is the case, perhaps we can reduce the sensitivity while still finding a relatively accurate set of frequent 1-itemset by truncating the long transactions. The three benchmark datasets <ref type="bibr" target="#b20">[22]</ref> do follow such a distribution. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the correlation between frequency and the cardinality of transactions in one of those datasets, BMS-WebView-2. As we can see, the short transactions, which contain fewer than 10 items, dominate the datasets. The other two datasets, BMS-WebView-1 and BMS-POS, also have a similar distribution. Therefore, we hope that the reduction in the magnitude of noise can offset the information loss incurred by truncating, and thus, we can get accurate results for frequent 1-itemsets.</p><p>However, the truncating approach raises a privacy concern: does it violate differential privacy? We will show that as long as that transformation is local, by which we mean that the output only depends on the input transaction, then applying any ǫ-differentially private algorithm to the truncated database also guarantees ǫ-differential privacy for the original database. The notion of local transformation is formulated in Definition 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 7. (Local Transformation</head><formula xml:id="formula_5">): A local transfor- mation is a probabilistic function r: 2 I → 2 I such that for any t ⊆ I t ′ ⊆I Pr(r(t) = t ′ ) = 1</formula><p>In the rest of this paper we use "transformation" as a shorthand for "local transformation", and r(τ ) to denote the computation that applies the transformation r to every transaction in the database τ . Theorem 7 proves that applying any differentially private algorithm to a transformed database also guarantees differential privacy.</p><p>Theorem 7. Let r be an arbitrary local transformation, and f be an ǫ-differentially private algorithm. Then for any pair of neighboring databases τ and τ ′ , and any S ⊆ Range(f ),</p><formula xml:id="formula_6">Pr(f (r(τ )) ∈ S) ≤ e ǫ Pr(f (r(τ ′ )) ∈ S)</formula><p>Next, we will present our differentially private frequent 1-itemset mining algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Our Algorithm</head><p>Algorithm 1 TruncateDatabase Input: input database τ ; privacy parameter ǫ Output: truncated database 1: z1, . . . , zn = EstimateDistribution(τ, ǫ) 2: ℓ ← the smallest integer such that ℓ i=1 zi ≥ 0.85 3: τ ′ = ∅ 4: for each transaction t ∈ τ do 5:</p><p>add t ′ = Truncate(ℓ, t) to τ ′ 6: end for 7: return τ ′ 8: function EstimateDistribution(τ, ǫ) 9:</p><p>Let z = z1, . . . , zn where zi is the # of transactions with cardinality i in τ 10: We determine the maximal cardinality ℓ in a heuristic way in which we set ℓ to the value such that the percentage of the transactions with cardinality no greater than ℓ is at least 85%. That heuristic approach requires us to compute the percentage of transactions for each cardinality, which also has privacy implications, and thus, we add geometric noise to that computation. More precisely, let z = z1, . . . , zn , where zi is the number of transactions with cardinality i. It is not hard to show that the sensitivity of computing z is 1 since the addition or deletion of a single transaction can at most increase or decrease a single zi by 1. By Theorem 1, adding geometric noise G(ǫ) in computing z gurantees ǫdifferential privacy. Since that information is differentially private, it is safe to utilize that information. This is shown in the function "EstimateDistribution" in Algorithm 1.</p><formula xml:id="formula_7">z ′ = z + ∆1, . . . ,</formula><p>We impose the cardinality constraint by randomly truncating transactions: if the cardinality of a transaction violates that constraint, then only a subset of its items is picked at random without replacement to generate a new transaction whose cardinality is equal to the enforced maximal cardinality. This is shown in the function "Truncate" in Algorithm 1.</p><p>Algorithm 2 F1M(τ , ǫ, λ) Input: input database τ ; privacy parameter ǫ; threshold λ Output: frequent 1-itemsets 1: ǫ ′ = min{0.05, ǫ/10} 2: τ ′ = TruncateDatabase(τ, ǫ ′ ) 3: ℓ = the maximal cardinality of transactions in τ ′ 4: R = ∅ 5: for all 1-itemset X in the alphabet I do 6:</p><formula xml:id="formula_8">X.supp ′ = i's support in τ ′ + G((ǫ -ǫ ′ )/ℓ) 7: if X.supp ′ ≥ λ then 8: Add X to R 9:</formula><p>end if 10: end for 11: return R Our differentially private f requent 1 -itemset mining algorithm F1M is shown in Algorithm 2. Line 1 in Algorithm 2, which sets ǫ ′ = min{0.05, ǫ/10}, is a configurable parameter that we set by trial and error for our datasets. We prove that F1M guarantees ǫ-differential privacy in Theorem 8.</p><p>Theorem 8. F1M is ǫ-differentially private.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">FROM 1-ITEMSETS TO β-ITEMSETS</head><p>In this section, as the next step toward our complete algorithm, we generalize the 1-itemset mining algorithm to consider frequent β-itemset mining, in which we are interested in frequent itemsets with cardinality not exceeding β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Challenges</head><p>There are two main challenges in frequent β-itemset mining that were not present in frequent 1-itemset mining:</p><p>1. Complexity: It is inefficient to compute the support of all itemsets as there are many.</p><p>2. Privacy: It is hard to precisely quantify the relationship between the maximal cardinality of transactions and the sensitivity of multiple i-itemset (i = 2, . . . β) queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Complexity</head><p>Recall our frequent 1-itemset mining algorithm in which we first compute the support of all 1-itemsets, and then perturb their support by adding geometric noise. That algorithm is efficient since the maximal number of 1-itemsets is n -the size of the alphabet. However, it is not practical to extend that idea directly to frequent β-itemset mining since the number of itemsets grows combinatorially. More precisely, it is not hard to show that the number of all the itemsets is β i=1 n i . In particular, n = 1657 in the dataset BMS-POS, and thus, when β = 5, the total number of all the itemsets is approximately 10 15 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>!</head><p>In this paper, we attack the complexity problem by utilizing the well-known a priori property proposed in <ref type="bibr" target="#b0">[2]</ref>. The a priori property states that a β-itemset is frequent only if all its subsets of cardinality β -1 are frequent. For ease of presentation, we denote the "subset of cardinality β -1" by "(β -1)-subset." Our frequent β-itemset mining algorithm utilizes the a priori property by iteratively finding frequent itemsets in order of increasing cardinality. For the mining of frequent i-itemsets, we will only compute the support of the i-itemsets whose every (i -1)-subset is frequent. In accordance with <ref type="bibr" target="#b0">[2]</ref>, we denote those i-itemsets by candidate i-itemsets. The order of computation is well-defined since we have already presented our frequent 1-itemset mining algorithm in Algorithm 2. The generation of candidate i-itemsets is also safe since it relies on the noisy results of (i -1)-itemsets, which are already differentially private.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Privacy</head><p>By the a priori property, we only need to compute the support of the candidate i-itemsets (i = 2, . . . , β). Similar to frequent 1-itemset mining, we can model that computation by d i-itemset queries q = q1, . . . , q d where qj computes the support of the candidate i-itemset Cj. To utilize the geometric mechanism, we need to compute the sensitivity of q. However, we will show that given the maximal cardinality ℓ (2 ≤ ℓ ≤ n), the precise computation of q's sensitivity is NP-hard. First, we formulate the problem of computing the sensitivity of multiple i-itemset queries in Problem 1.</p><p>Problem 1. (i, ℓ)-sensitivity: Given a set of itemsets C, each element of which is a subset of the alphabet I, and is of the same cardinality i, find a set T ⊆ I such that |T | ≤ ℓ, and the number of itemsets in C contained by T is maximized.</p><p>The number of itemsets in C contained in T is the sensitivity of q. As indicated by Theorem 4, when i = 1, (1, ℓ)sensitivity can be trivially solved in polynomial time. However, this is not true for i &gt; 1, as is shown in Theorem 9.</p><p>Theorem 9. When i ≥ 2, (i, ℓ)-sensitivity is NP-hard. In view of the hardness result for (i, ℓ)-sensitivity, in this paper we employ a safe approximate method by computing the upper bound of multiple i-itemset queries' sensitivity, and use that upper bound to perturb the support of the i-itemsets. The upper bound is shown in Theorem 10. Theorem 10. Given d i-itemset queries q = q1, . . . , q d , let ℓ be the maximal cardinality of transactions. Then the sensitivity of q is no greater than min( ℓ i , d). We want to emphasize that Theorem 10 only computes the upper bound of multiple i-itemset queries instead of the exact sensitivity. To show that, suppose the itemsets are {2,3}, {4,5}, and {6,7}, and ℓ = 3. The sensitivity of those three 2-itemset queries is one instead of three since the addition or deletion of any transaction of cardinality three can only increase or decrease the support of one itemset by one. We use Theorem 10 to perturb the support of the candidate i-itemsets. Although our approach is not optimal with respect to the utility -we add more noise than required to guarantee differential privacy -our approach is safe because we use an upper bound on the sensitivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">A Naïve Algorithm</head><p>By utilizing the a priori property and Theorem 10, we can extend our idea of truncating transactions to frequent β-itemset mining: we set the truncated database produced for frequent 1-itemset mining as the input database, and then by the a priori property, iteratively compute frequent 2, 3, . . . , β-itemsets. The pseudocode of the naïve algorithm is shown in the long version of our paper <ref type="bibr">[1]</ref>. However, we find that the performance of this naïve algorithm is poor for two reasons:</p><p>Random Truncating: Random truncating does not distinguish between frequent subsets and rare subsets of a transaction to be truncated. Yet frequent subsets are more likely to contribute to frequent item sets than rare ones.</p><p>Propagated Errors: If a frequent itemset is mistakenly labeled as infrequent, then any of its supersets is regarded infrequent without even computing its support.</p><p>To ameliorate these two problems, we propose two heuristic methods: smart truncating, and double standards. We discuss those two methods next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Smart Truncating</head><p>Ideally, when truncating a transaction, we only need to keep the subsets that are frequent items since infrequent subsets will not contribute to frequent itemsets. However, our goal is to find those frequent itemsets in a differentially private way. We do so by providing a heuristic method to predict whether or not a candidate itemset is frequent. We observe that in practice, if all the subsets of a candidate itemset are "sufficiently" frequent, then that itemset is very likely to be frequent. To quantify that observation, we assign each candidate i-itemset (i ≥ 2) a frequency score which is the summation over all its (i -1)-subsets' noisy support. Definition 8. (Frequency Score): Given a set of (i -1)-itemsets Y = {Y1, . . . , Y d }, the frequency score of an iitemset X is:</p><formula xml:id="formula_9">f s(X) = Y j ⊂X∧Y j ∈Y Yj.supp ′<label>(2)</label></formula><p>where Yj.supp ′ is the noisy support of the itemset Yj.</p><p>When truncating transactions, we will keep the itemsets with high frequency scores. This is formulated in Problem 2. Problem 2. Optimal (i, ℓ)-truncating: Given a set of iitemsets X = {X1, . . . , X d }, the cover score of a set t ′ is defined as:</p><formula xml:id="formula_10">cs(t ′ ) = X j ⊆t ′ ∧X j ∈X f s(Xj )</formula><p>where f s is the frequency score defined in <ref type="bibr" target="#b0">(2)</ref>. Given a transaction t, find an ℓ-subset of t such that the cover score of that subset is maximized Unfortunately, we can prove that there is no efficient algorithm to solve the optimal (i, ℓ)-truncating problem as shown in Theorem 11. Theorem 11. Optimal (i, ℓ)-truncating is NP-hard.</p><p>In view of the hardness result, we use a greedy algorithm to solve Problem 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Our Greedy Algorithm</head><p>The idea of our greedy algorithm is simple: for each transaction, we construct the truncated transaction by iteratively adding items in the candidate itemset that are both contained by the input transaction and have the highest frequency score until the truncated transaction's cardinality exceeds the maximal cardinality. However, an intuitive observation is that the frequency score of an itemset should not be static: it is possible that some items in an itemset have been added to the truncated transaction, and thus, the number of extra items to include that itemset is less than other itemsets. Therefore, the frequency score of an itemset should be updated with the addition of items to the truncated transaction. To avoid confusion with the static frequency score in Definition 8, we refer the "dynamic frequency score" by "weight."</p><p>Our greedy algorithm "SmartTruncating" accepts three input parameters: the original transaction t, the maximal cardinality ℓ, and the set of candidate i-itemsets C = {C1, . . . , C d }. For each candidate itemset Cj , its weight Cj.weight is initialized by Cj 's frequency score f s(Cj) defined in (2). The algorithm "SmartTruncating" works as follows: we find the candidate i-itemsets contained by the input transaction t, and denote the set of those itemsets by C ′ . Then, starting from an empty transaction t ′ , we first pick the itemset Cj in C ′ with the highest weight, add the items in Cj to t ′ , and delete Cj from C ′ . Next, we update the weight of the remaining itemsets in C ′ : for each remaining itemset C h , we compute the average weight of a single item in C h by α h = f s(C h )/i. Suppose the number of items in C h that has already been added to the truncated transaction t ′ is β h . Then the weight of C h is updated by C h .weight = C h .weight+α h * β h . After updating the weight for every remaining itemset, we repeat those steps until the cardinality of t ′ exceeds ℓ. The pseudocode of SmartTruncating is shown in the long version of our paper. We show a running example of our greedy algorithm in Example 1.</p><p>Example 1. Given a transaction t = {1,2,3,4,5}, and three 2-itemsets {1,2}, {2,3} and {4,5} with weight 10, 8, and 9, respectively. Suppose the maximal cardinality of transactions is 3. The truncated transaction t ′ is initialized to be empty. First, we pick the itemset {1,2} which has the largest weight, and then t ′ is updated to {1,2}. Next, we update the weight of the remaining itemsets as follows: since the single item "2" has been added to t', the new weight of the itemset {2,3} is 8 + 1*8/2 = 12, and that for {4,5} remains the same. Hence, we add the itemset {2,3} to t ′ , which is then updated to {1,2,3}. Since the cardinality of t ′ meets the constraint, the algorithm " SmartTruncating" stops, and the truncated transaction is t ′ = {1,2,3}.</p><p>It is not hard to see that our smart truncating method is a local transformation which only relies on the noisy support, and so it is differentially private.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Double Standards</head><p>As discussed in Section 5.2, by the a priori property, if a frequent itemset is mistakenly labeled as infrequent, then any of its supersets is regarded infrequent without even computing its support. To alleviate this problem, we observe that a frequent itemset indeed serves two different rolesas a result of frequent itemset mining and as a "seed" to generate candidate itemsets. The errors are propagated due to the second role. Therefore, instead of setting the same threshold for both roles for every itemset, we customize the thresholds for each itemset by setting a threshold to determine whether that itemset is frequent or not, and a possibly different one to decide whether or not to use that itemset to generate candidate itemsets. Speaking intuitively, the previous threshold is computed by measuring the "average" information loss in truncating while the latter one by the "maximal" information loss. By that approach, it is possible that some itemsets are labeled infrequent but are used to generate candidate itemsets, which helps to reduce the propagated errors by the a priori property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Quantifying Information Loss in Truncating</head><p>So far, we have only considered the benefit of truncating transactions. Truncating also causes information loss, because the support of some itemsets decreases. For example, given a transaction {1,2,3}, by truncating that transaction to be {2,3}, the support of the itemset {1,2} changes from 1 to 0. To quantify this information loss, we formulate our problem as follows: given the noisy support θ ′ of an iitemset X in the truncated database, estimate the support θ of X in the original database in a differentially private way. The major difficulty in solving this problem comes from the privacy requirement that whenever we need to utilize some information from the database, we need to do so in a differentially private way. Therefore, we must guarantee that our algorithm is either differentially private or only depends on differentially private information. In this paper, we take the latter approach, and our algorithm has two steps:</p><p>1. Given the noisy support of an itemset X, compute its support in the truncated database in a differentially private way.</p><p>2. Given the support of the itemset X in the truncated database, estimate its support in the original database in a differentially private way.</p><p>In the rest of this section, for ease of presentation, we use "original support" as a shorthand for "the support in the original database", and "truncated support" for "the support in the truncated database." Unless otherwise specified, we assume the i-itemset X is given, and use θ, θ and θ ′ to denote X's original support, truncated support and noisy truncated support, respectively.</p><p>The first step is relatively straightforward where we use the Bayesian rule to compute the probability distribution of the truncated support as shown in Theorem 12 Theorem 12.</p><formula xml:id="formula_11">Pr( θ|θ ′ ) ∼ e -ǫ|θ ′ -θ|<label>(3)</label></formula><p>The second step quantifies the information loss in truncating. To give an intuition for our result, we start from an inverse problem: given the original support θ, what is the truncated support θ? We address that problem by using the analysis in random truncating to approximate the itemset X's truncated support. We want to emphasize that our smart truncating method is by no means equivalent to random truncating, and we only utilize the analysis in random truncating as a heuristic method to approximately quantify the information loss by our smart truncating method. We will discuss the rationale of that approximation at the end of this section.</p><p>We assume a uniform distribution among transactions with different cardinality containing the itemset X. More precisely, let zj be the relative frequency of the transactions with cardinality j in the original database. Given an i-itemset X, we assume that the number of transactions with cardinality j containing X is θ * zj/ n h=i z h . 1 Recall that we have already computed zj (j = 1 . . . n) in Algorithm 2 for frequent 1-itemset mining in a differentially private way, and thus, it is safe to utilize that information. For each transaction t, let t ′ be the truncated transaction of t. We observe that if a transaction does not contain X, then the truncated transaction does not contain X either. Thus, it suffices to only consider the transactions containing X to compute X's truncated support. We define a binary random variable Mt to quantify the effect of truncating a transaction on the support of the itemset X:</p><formula xml:id="formula_12">Mt = 1 if X ⊆ t ′ 0 otherwise. (<label>4</label></formula><formula xml:id="formula_13">)</formula><p>(5) quantifies the probability that X remains in the truncated transaction.</p><formula xml:id="formula_14">Pr(Mt = 1) = |t|-i ℓ-i |t| ℓ<label>(5)</label></formula><p>We also observe that the random variable Mt is identical for transactions of the same cardinality, and thus, we denote Mt by M h , where h = |t|. Let f h be the number of transactions with cardinality j containing the itemset X, and by our uniform assumption, f h = θ * z h / n j=i zj. Thus, the truncated support of X is also a random variable M where:</p><formula xml:id="formula_15">M = n h=i f h j=1 M h (6)</formula><p>The expectation of M is:</p><formula xml:id="formula_16">E(M ) = n h=i fi Pr(M h = 1) = θ( n h=i z h n j=i zj h-i ℓ-i h ℓ )<label>(7)</label></formula><p>which quantifies the "average" truncated support of the itemset X. Next, we will compute the minimal truncated support, which quantifies the maximal information loss. It is not hard to see that a trivial lower bound for M is 0. However, by using 0 as the lower bound, it hardly provides us a way to estimate the original support given the truncated support. Therefore, we quantify that lower bound in a probabilistic way such that the truncated support is very unlikely to be smaller than that lower bound. Definition 9 formalizes this idea.</p><p>Definition 9. (ρ-lower bound): An integer σ is called a ρ-lower bound for the truncated support iff:</p><formula xml:id="formula_17">Pr(M ≤ σ) ≤ ρ</formula><p>where M is the random variable defined in (6).</p><p>1 Strictly speaking, it must be rounded to an integer.</p><p>We compute the ρ-lower bound by using the Chernoff bound <ref type="bibr" target="#b1">[3]</ref>. Let µ = E(M ), and for any γ ≥ 0, by the multiplicative form of Chernoff bound,</p><formula xml:id="formula_18">Pr(M ≤ (1 -γ)µ) ≤ exp( -γ 2 µ 2 )</formula><p>Therefore, it suffices to solve the inequality exp(-γ 2 µ/2) ≤ ρ, and the resulting ⌊(1γ)µ⌋ serves as the ρ-lower bound. Thus, given the truncated support θ, let</p><formula xml:id="formula_19">exp ratio(i) = n h=i z h n j=i zj h-i ℓ-i h ℓ</formula><p>By <ref type="bibr" target="#b5">(7)</ref>, the average original support is computed by:</p><formula xml:id="formula_20">avg os( θ) = θ exp ratio(i)<label>(8)</label></formula><p>Let µ be the expectation of the truncated support given the maximal original support. We compute µ by treating the truncated support θ as the ρ-lower bound, which leads to solving the following two inequalities:</p><formula xml:id="formula_21">(1 -γ)µ ≤ θ ≤ µ, exp(- γ 2 µ 2 ) = ρ It is not hard to show that µ ≤ µ * = θ -ln ρ + ln 2 ρ -2 θ ln ρ (9)</formula><p>provided ln ρ ≤ 2 θ. Thus, the maximal original support is computed by</p><formula xml:id="formula_22">max os( θ) = µ * exp ratio(i)<label>(10)</label></formula><p>where µ * is defined in <ref type="bibr" target="#b7">(9)</ref>, and if ln ρ &gt; 2 θ, then we will set max os( θ) to be avg os( θ). By combining our result of the first step, which estimates the truncated support given the noisy support, and our second step, which infers the original support given the truncated support, given θ ′ , the noisy truncated support of the itemset X, we can compute the average original support by:</p><formula xml:id="formula_23">avg supp(θ ′ ) = n j=0</formula><p>Pr(j|θ ′ )avg os(j) <ref type="bibr" target="#b9">(11)</ref> and the maximal original support by:</p><formula xml:id="formula_24">max supp(θ ′ ) = n j=0</formula><p>Pr(j|θ ′ )max os(j) <ref type="bibr" target="#b10">(12)</ref> where Pr(j|θ ′ ), avg os(i) and max os(i) are defined in ( <ref type="formula" target="#formula_11">3</ref>), ( <ref type="formula" target="#formula_20">8</ref>) and <ref type="bibr" target="#b8">(10)</ref>, respectively. We use the average original support of an itemset to check whether or not it is frequent, and the maximal original support to determine whether or not to use it to generate candidate itemsets. Equivalently, given the noisy truncated support θ ′ , we have changed the threshold to determine whether or not X is frequent from λ to λavg supp(θ ′ ) + θ ′ , and that for whether or not to use X to generate itemsets to λmax supp(θ ′ ) + θ ′ . In that way, we have actually relaxed both thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Discussion</head><p>We want to emphasize that our approach of estimating the original support of an itemset is solely a heuristic method. As discussed, the major difficulty of estimating an itemset's original support comes from the privacy requirement, and Algorithm 3 Frequent β itemset Mining Input: input database τ ; itemsets' cardinality β; privacy parameter ǫ; threshold λ Output: frequent itemsets of cardinality not exceeding β 1: ǫ ′ = ǫ/β 2: ǫ ′′ = min{0.05, ǫ ′ /10} 3: τ ′ = TruncateDatabase(τ, ǫ ′′ ) 4: ℓ = the maximal cardinality of transactions in τ ′ 5:</p><formula xml:id="formula_25">S1 = i itemset Mining(τ ′ , ℓ, ǫ ′ -ǫ ′′ , λ,∅) 6: for i = 2 to β do 7: ℓ = ψ(λ, i) 8:</formula><p>Si = i itemset Mining(τ , ℓ, ǫ ′ , λ, Si-1) 9: end for 10: R = ∅ 11: for all itemset Xj in ∪ β i=1 S do 12:</p><p>if avg supp(Xj.supp ′ ) ≥ λ then 13:</p><p>Add Xj to R 14:</p><p>end if 15: end for 16: return R thus, we must be quite careful of utilizing any information from the database. The reason why we use random truncating to approximate the information loss of smart truncating is because it relies on little information from the database. The exploration of other approaches to quantify the information loss by smart truncating is an interesting direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Our Algorithm</head><p>Our algorithm for frequent β-itemset mining improves over the naïve algorithm by using smart truncating to truncate transactions, and setting different thresholds for and itemset being frequent and for it generating candidate itemsets. This is shown in Algorithm 3. In particular, Algorithm 3 differs from the naïve algorithm in two places. First, instead of randomly truncating the transactions only once, we apply the method "SmartTruncating" to the original database for the mining of i-itemsets (i = 2, . . . , β) by utilizing the results of the noisy (i -1)-itemsets as shown in line 10 in Algorithm 4. We initialize a candidate itemset's weight by its frequency score as shown in the code from line 7 to line 9 in Algorithm 4. Second, an itemset is used to generate candidate itemsets iff its estimated maximal original support exceeds the threshold. This is shown in line 18 in Algorithm 4. However, whether an itemset is frequent or not is determined by its estimated average original support. This is shown in line 12 in Algorithm 3.</p><p>The output of ψ in line 7 of Algorithm 3 is tunable given the maximal cardinality of transactions, the threshold and the current candidate itemsets' cardinality. The idea of tuning certain parameters in a differentially private algorithm by the data curator was first proposed by <ref type="bibr" target="#b6">[8]</ref>. We consider how to automatically determine the maximal cardinality of transactions as an interesting direction for future work. We prove Algorithm 3 is differentially private in Theorem 13. Theorem 13. Algorithm 3 is ǫ-differentially private.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">FREQUENT ITEMSET MINING</head><p>We are finally ready to present our complete algorithm. We first observe that Algorithm 3 is also a differentially pri-Algorithm 4 i itemset Mining Input: database τ ; maximal cardinality ℓ; privacy parameter ǫ; threshold λ; noisy (i -1)-itemsets S Output: the i-itemsets whose estimated maximal original support exceeds the threshold 1: if i is 1 then 2:</p><formula xml:id="formula_26">C = I 3: else 4: C = Generate candidate i-itemsets from S 5: end if 6: if i is not 1 then 7:</formula><p>for all itemset Cj ∈ C do 8:</p><p>Cj .weight = f s(Cj) 9:</p><p>end for 10:</p><p>τ ′ ← apply SmartTruncating to τ 's transactions 11: else 12:</p><p>τ ′ = τ 13: end if 14: κ = min{ ℓ i , |C|} 15: R = ∅ 16: for all itemset Cj in C do 17:</p><formula xml:id="formula_27">Cj.supp ′ = Cj's support in τ ′ + G(ǫ/κ) 18:</formula><p>if max supp(Cj.supp ′ ) ≥ λ then 19:</p><p>Add Cj to R 20:</p><p>end if 21: end for 22: return R vate frequent itemset mining algorithm if β is at least maximal cardinality of any frequent itemset. However, this maximal cardinality is a property of the database so we cannot use it directly without privacy implications. Accordingly, we have the following problem: Problem 3. Let y = y1, . . . , yn where yi is the maximal support of the i-itemsets. Given a threshold λ, find the index i * such that yi * is the smallest integer that exceeds λ in a differentially private way.</p><p>A naïve idea to solve Problem 3 is to first add geometric noise to each yi, and then find the index i * . It is not hard to show that the sensitivity of computing y is exactly n, and thus, in order to guarantee ǫ-differential privacy for Problem 3, we need to add the geometric noise G(ǫ/n) to each yi.</p><p>In fact, we observe that y is non-increasing by the a priori property, and thus, we can reduce the required noise to G(ǫ/⌈log n⌉) by using the same idea of binary search. Due to space limitations, we defer the details of this algorithm in the long version of our paper <ref type="bibr">[1]</ref>.</p><p>In practice, it is not practical to precisely compute y. Therefore, we approximate y by setting the threshold to be λ/20, and run the original Apriori algorithm <ref type="bibr" target="#b0">[2]</ref> to compute frequent itemsets. Suppose the maximal cardinality of the resulting frequent itemsets is j. Then for i from 1 to j, we can precisely compute the maximal support of i-itemsets yi. For any i from j + 1 to n, we set yi = yj . Our approxiamtion is safe in that the sensitivity of computing each yi is still 1. We run our frequent itemset mining algorithm by first estimating the maximal cardinality of frequent itemsets, and then using that maximal cardinality as the input for Algorithm 3 to discover frequent itemsets. By the composition property of differential privacy, we conclude that our algorithm is differentially private.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">EXPERIMENTS</head><p>In this section, we experimentally evaluate our techniques on the benchmark datasets described in <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b4">6]</ref>. A summary of those datasets is given in Table <ref type="table" target="#tab_1">1</ref>. For our experiments, instead of using the (δ, η)-usefulness, we employ a more intuitive metric F -score as shown in Definition 10. We implemented our algorithms in C++, and ran the experiments on an Intel Core 2 Duo 2.33GHZ machine with 1 GB RAM running Linux. Since our algorithms involve randomization, we ran each algorithm ten times to obtain its average performance. We use relative thresholds (percentage of transactions) in our experiments. Absolute thresholds can be easily derived by multiplying the relative threshold by the number of transactions in a database. In practice, we find that the overhead of our algorithm is less than 10% compared to the original Apriori algorithm <ref type="bibr" target="#b0">[2]</ref> <ref type="foot" target="#foot_0">2</ref> , and thus, we do not present the running time of our algorithm. We compare our algorithm with the "PrivBasis" algorithm proposed in <ref type="bibr" target="#b14">[16]</ref>, which discovers top-k frequent itemsets, and the "TopK" frequent i-itemsets mining algorithm proposed in <ref type="bibr" target="#b3">[5]</ref>, which mines top-k frequent itemsets of the same cardinality i. We set the privacy parameter to be 1.0 for every algorithm in every set of experiments, and ρ to be 0.01 in We begin by noting that we do not present results for our algorithm without truncating because its performance was uniformly poor, at least an order of magnitude worse than the algorithm with truncating. Hence in our first experiment we move on to compare our algorithm with the topk frequent itemset mining algorithm "PrivBasis" proposed in <ref type="bibr" target="#b14">[16]</ref>. We adapt the "PrivBasis" algorithm to frequent itemset mining by setting k to be the number of frequent itemsets given a threshold. We want to emphasize that setting might have privacy implications. However, even with that relaxation in privacy, Figure <ref type="figure" target="#fig_1">2</ref> shows for the threshold frequent itemset computation, our algorithm outperforms the "PrivBasis" algorithm on two datasets WV1 and WV2. We were unable to compare the results on the dataset POS since the "PrivBasis" algorithm does not scale to handle larger k. In particular, when the threshold is 0.004, the total number of frequent itemsets in POS is more than 6000, and the "PrivBasis" algorithm can not efficiently discover the top-6000 frequent itemsets.</p><p>We are also interested in extending our algorithm to discover the top-k frequent itemsets. We can modify our algorithm to do so by setting the threshold to be the frequency of the k th frequent itemsets. Of course, that computation of that frequency creates privacy concern. However, it is not hard to show that the sensitivity of that computation is one, and thus, we can add geometric noise to that computation. With that modification of our algorithm, we also compare our algorithm with the "PrivBasis" algorithm for top-k frequent itemset mining. Figure <ref type="figure">3</ref> shows that the quality of top-k frequent itemsets produced by our algorithm is better than that by the "PrivBasis" algorithm except the case when k is small (in our experiments, this means k ∼ 10). We also evaluate our techniques on the dataset "PUMSB" in which "long" transactions dominate the datasets. Figure <ref type="figure">3c</ref> shows that our algorithm is still superior. We also observe an interesting phenomena that the F -score of the "PrivBasis" algorithm drops to 0.6 when k = 50. One reason for that phenomena is because there is a 1-itemset whose frequency is very close to the frequency of the 50 th frequent itemset. In that way, the "PrivBasis" algorithm is very likely to label that 1-itemset as frequent, which also has side-effect on the result of 2-itemsets. As a result, it incurs a penalty on F -score since k is small.</p><p>Next, we compare our algorithm with the differentially private set-valued data publishing algorithm <ref type="bibr" target="#b6">[8]</ref> on which we run the original Apriori algorithm over the anonymized data. Note that this is a generic approach -first anonymize the data, then run the (non-private) algorithm. We find that our algorithm outperforms the Apriori algorithm on the publishing anonymized data on all three datasets as shown in Figure <ref type="figure" target="#fig_2">4</ref>. In particular, our algorithm increases the F -score   <ref type="figure">6</ref>: Frequent 2-itemsets in POS of frequent itemsets by an order of magnitude in both POS and WV2 as shown in Figure <ref type="figure" target="#fig_2">4a</ref> and Figure <ref type="figure" target="#fig_2">4c</ref>, respectively. The reason why the data publishing algorithm fails to generate accurate frequent itemsets is because the total number of transactions is greatly reduced after anonymization: for the dataset WV2, the average number of transactions after anonymizing is 6734.5, which is less than 10% of the original transactions. Thus, the anonymization incurs significant information loss.</p><p>We also want to know how our two heuristics -smart truncating and double standards -affect the performance of our algorithm. We show the results in Figure <ref type="figure" target="#fig_3">5</ref>. The most significant improvement is the double standards approach. Although the smart truncating method improves the quality of frequent itemsets over random truncating in both POS and WV1, we find it does not work for WV2. This indicates that whether or not the frequency score is a good indicator of an itemset's frequency depends on the dataset. Whether there exists a truncating approach that outperforms the random truncating approach on any dataset is an interesting direction for future research.</p><p>To better understand why our heuristics work well on the dataset "POS", we show the results of 2-itemsets in Figure <ref type="figure">6</ref>. We observe that the double standards approach significantly improves the recall of frequent 2-itemsets while it decreases the precision a little as shown in Figure <ref type="figure">6c</ref> and Figure <ref type="figure">6b</ref>, respectively. Furthermore, we also observe that by utilizing the a priori property and truncating transactions, our algorithm increases the F -score of frequent 2-itemsets by orders of magnitude comparing to the top-k frequent i-itemset mining algorithm proposed in <ref type="bibr" target="#b3">[5]</ref> as shown in Figure <ref type="figure">6a</ref>.</p><p>As discussed in Section 4, the success of our algorithm relies on the fact the information loss in truncating transactions is offset by the benefit of reducing noise. To show that, we set the threshold to be 0.004. We compare the Fscore of frequent 1-itemsets by changing the constraint on transactions' maximal cardinality. Figure <ref type="figure" target="#fig_4">7</ref> shows the result. As we can see, when the maximal cardinality is very small, the information loss exceeds the benefit of reducing noise. On the other hand, when the maximal cardinality is large, the increase of the noise offsets the benefit of retaining the information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">RELATED WORK</head><p>In this section we discuss related work not explicitly mentioned elsewhere in our paper.</p><p>The notion of differential privacy was proposed by Dwork et al. in <ref type="bibr" target="#b7">[9]</ref>. The same authors also propose the addition of Laplacian noise to guarantee differential privacy <ref type="bibr" target="#b8">[10]</ref>, and <ref type="bibr" target="#b10">[12]</ref> propose adding geometric noise to achieve the same goal. The problem of frequent itemset mining has been ex-tensively studied in literature <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b11">13]</ref>. The data mining community has focused on hiding sensitive rules generated from transactional databases <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b18">20]</ref>. In <ref type="bibr" target="#b2">[4]</ref>, the authors address this problem by altering the database to hide a given set of sensitive rules. However, how to define sensitive rules is unclear, and their approach does not satisfy differential privacy.</p><p>Although <ref type="bibr">Evfimievski et al.</ref> have developed a privacy preserving frequent itemset mining algorithm in <ref type="bibr" target="#b9">[11]</ref>, their approach does not guarantee differential privacy. In <ref type="bibr" target="#b15">[17]</ref>, the authors propose a noisy a priori algorithm which is quite similar to our random truncating approach but they do not explicitly consider the problem of frequent itemset mining as we do.</p><p>Another way to develop a differentially private frequent itemsets mining is to use a basic, non-anonymizing frequent itemset mining algorithm, but to apply it to an anonymized version of the transactional data. This is an intriguing approach and it warrants exploration. Early work appears on anonymizing other types of data sets <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b16">18]</ref> has shown a great success in this direction. In other related work, <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b5">7]</ref> propose ad hoc privacy criteria to resist certain kinds of attacks on publishing transaction databases. However, those ad hoc privacy criteria do not guarantee differential privacy. The latest effort to anonymize transactional data in a differentially private way is proposed by <ref type="bibr" target="#b6">[8]</ref>. However, they only consider the workload of top-k frequent itemsets, and our experimental results indicate that our algorithm improves the F -score of frequent itemsets over <ref type="bibr" target="#b6">[8]</ref> by an order of magnitude on two benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSION</head><p>In this paper, we have proposed a differentially private frequent itemset mining algorithm. We have precisely quantified the trade-off between privacy and utility in frequent itemset mining, and our results indicate that in order to satisfy a non-trivial utility requirement, a frequent itemset mining algorithm incurs a huge risk of privacy breach. However, we find that we can greatly promote the utility of a differentially private frequent itemset mining algorithm by limiting the maximal cardinality of transactions.</p><p>Motivated by that observation, we have proposed a new differentially private frequent itemset mining algorithm. Our results on benchmark datasets indicate that in comparison to the latest algorithm on publishing transactional data in a differentially private way <ref type="bibr" target="#b6">[8]</ref>, our algorithm improves the Fscore of frequent itemsets by more than 200% in one dataset, and by an order of magnitude on the other two datasets. Our results also show that our algorithm significantly improves the quality of top-k frequent itemsets comparing to the differentially private top-k frequent itemset mining algorithm proposed in <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b3">5]</ref> except when k is small.</p><p>There are many potential opportunities for future work. One such direction would be to explore other more sophisticated truncating algorithms. Another direction would be to explore alternative methods to limit the information loss due to truncating. Finally, the success of our algorithm relies on the assumption that the "short" transactions dominate the datasets. How to deal with datasets dominated by long transactions is an open problem, although with no constraints on the database our theoretical results on privacy/utility tradeoffs suggest that algorithms that simultaneously achieve good privacy and utility may prove elusive.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Frequencies of Transactions by Cardinality noise algorithm." We will prove that by assuming the maximal cardinality ℓ = O 1 , the geometric noise algorithm guarantees both ǫ-differential privacy and (δ, η)-usefulness provided ǫ ≥ Ω log n . This is shown in Theorem 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Frequent Itemset Mining</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>F-score of frequent itemsets the double standards method. Definition 10. (F -score): Let Up be the set of frequent itemsets generated by a differentially private frequent itemset mining algorithm, and Uc be the set of correct frequent itemsets, then precision = |Up ∩ Uc| |Up| , recall = |Up ∩ Uc| |Uc| and the F -score is the harmonic mean of precision and recall: F -score = 2 * precision * recall precision + recall</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Improvements of our heuristics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Frequent 1-itemsets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset characteristics</figDesc><table><row><cell cols="2">dataset</cell><cell></cell><cell></cell><cell>m</cell><cell>|I|</cell><cell>max |t|</cell><cell>avg |t|</cell></row><row><cell cols="3">BMS-POS (POS)</cell><cell></cell><cell>515,597</cell><cell>1,657</cell><cell>164</cell><cell>6.5</cell></row><row><cell cols="4">BMS-WebView-1 (WV1)</cell><cell>59,602</cell><cell>497</cell><cell>267</cell><cell>2.5</cell></row><row><cell cols="4">BMS-WebView-2 (WV2)</cell><cell>77,512</cell><cell>3,340</cell><cell>161</cell><cell>5.0</cell></row><row><cell cols="3">pumsb-star (PUMSB)</cell><cell></cell><cell>49,046</cell><cell>2,088</cell><cell>50.0</cell><cell>63</cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>F-score</cell><cell>0.4 0.5 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell cols="2">PrivBasis Our Algorithm</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.004</cell><cell>0.006</cell><cell>0.008</cell><cell>0.01</cell><cell>0.012</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Threshold</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We do not consider the overhead of computing frequent itemsets' maximal cardinality since we can pre-compute that value for each data set for a fixed threshold.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work was supported by National Science Foundation grants IIS-0524671, CCF-0914969 and NIGMS grant R01LM011028-02.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast algorithms for mining association rules</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast probabilistic algorithms for hamiltonian circuits and matchings</title>
		<author>
			<persName><forename type="first">D</forename><surname>Angluin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Anonymity preserving pattern discovery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Atzori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Discovering frequent patterns in sensitive data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laxman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thakurta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Mafia: A performance study of mining maximal frequent itemsets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burdick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Calimlim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Flannick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yiu</surname></persName>
		</author>
		<editor>FIMI</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ρ-uncertainty: Inference proof transaction anonymization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Publishing set-valued data via differential privacy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C M</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>VLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<title level="m">Differential privacy. In ICALP</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TCS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Privacy preserving mining of association rules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Evfimievski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Universally utility-maximizing privacy mechanisms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mining frequent patterns without candidate generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Anonymization of set-valued data via top-down, local generalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Naughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithms for association rule mining: a general survey and comparison</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Güntzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nakhaeizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Privbasis: Frequent itemsets mining with differential privacy</title>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qardaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Differentially-private network trace analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Rev</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differentially private aggregation of distributed time-series with transformation and encryption</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Privacy-preserving anonymization of set-valued data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Terrovitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mamoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kalnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Verykios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Elmagarmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Saygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dasseni</surname></persName>
		</author>
		<title level="m">Association rule hiding</title>
		<imprint>
			<publisher>TKDE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Differential privacy via wavelet transforms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Real world performance of association rule algorithms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;01</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
