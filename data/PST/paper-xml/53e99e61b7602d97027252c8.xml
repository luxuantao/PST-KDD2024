<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Virtual Program Counter (VPC) Prediction: Very Low Cost Indirect Branch Prediction Using Conditional Branch Prediction Hardware</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Hyesoon</forename><surname>Kim</surname></persName>
							<email>hyesoon@cc.gatech.edu..</email>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Jose</forename><forename type="middle">´a</forename><surname>Joao</surname></persName>
							<email>joao@ece.utexas.edu</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Chang</forename><surname>Joo Lee</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
							<email>patt@ece.utexas.edu</email>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
							<email>robert.s.cohn@intel.com</email>
						</author>
						<author>
							<persName><forename type="middle">O</forename><surname>Mutlu</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">R</forename><surname>Cohn</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Computing</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<addrLine>266 Ferst Drive</addrLine>
									<postCode>30332-0765</postCode>
									<settlement>Atlanta</settlement>
									<region>GA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University Station C0803</orgName>
								<address>
									<postCode>78712-0240</postCode>
									<settlement>Austin</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213-3890</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<addrLine>77 Reed Road</addrLine>
									<postCode>HD2-300, 01749</postCode>
									<settlement>Hudson</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Virtual Program Counter (VPC) Prediction: Very Low Cost Indirect Branch Prediction Using Conditional Branch Prediction Hardware</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TC.2008.227</idno>
					<note type="submission">received 3 Oct. 2007; revised 2 June 2008; accepted 18 Sept. 2008;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Indirect branch prediction</term>
					<term>virtual functions</term>
					<term>devirtualization</term>
					<term>object-oriented languages</term>
					<term>Java</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Indirect branches have become increasingly common in modular programs written in modern object-oriented languages and virtual-machine-based runtime systems. Unfortunately, the prediction accuracy of indirect branches has not improved as much as that of conditional branches. Furthermore, previously proposed indirect branch predictors usually require a significant amount of extra hardware storage and complexity, which makes them less attractive to implement. This paper proposes a new technique for handling indirect branches, called Virtual Program Counter (VPC) prediction. The key idea of VPC prediction is to use the existing conditional branch prediction hardware to predict indirect branch targets, avoiding the need for a separate storage structure. Our comprehensive evaluation shows that VPC prediction improves average performance by 26.7 percent and reduces average energy consumption by 19 percent compared to a commonly used branch target buffer based predictor on 12 indirect branch intensive C/Cþþ applications. Moreover, VPC prediction improves the average performance of the full set of object-oriented Java DaCapo applications by 21.9 percent, while reducing their average energy consumption by 22 percent. We show that VPC prediction can be used with any existing conditional branch prediction mechanism and that the accuracy of VPC prediction improves when a more accurate conditional branch predictor is used.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>O BJECT-ORIENTED programs are becoming more common as more programs are written in modern high-level languages such as Java, Cþþ, and C#. These languages support polymorphism <ref type="bibr" target="#b7">[8]</ref>, which significantly eases the development and maintenance of large modular software projects. To support polymorphism, modern languages include dynamically dispatched function calls (i.e., virtual functions) whose targets are not known until runtime because they depend on the dynamic type of the object on which the function is called. Virtual function calls are usually implemented using indirect branch/call instructions in the instruction set architecture. Previous research has shown that modern object-oriented languages result in significantly more indirect branches than traditional C and Fortran languages <ref type="bibr" target="#b6">[7]</ref>. Unfortunately, an indirect branch instruction is more costly on processor performance because predicting an indirect branch is more difficult than predicting a conditional branch as it requires the prediction of the target address instead of the prediction of the branch direction. Direction prediction is inherently simpler because it is a binary decision as the branch direction can take only two values (taken or not-taken), whereas indirect target prediction is an N-ary decision where N is the number of possible target addresses. Hence, with the increased use of object-oriented languages, indirect branch target mispredictions have become an important performance limiter in high-performance processors. 1 Moreover, the lack of efficient architectural support to accurately predict indirect branches has resulted in an increased performance difference between programs written in object-oriented languages and programs written in traditional languages, thereby rendering the benefits of object-oriented languages unusable by many software developers who are primarily concerned with the performance of their code <ref type="bibr" target="#b50">[50]</ref>.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> shows the number and fraction of indirect branch mispredictions per 1000 retired instructions (MPKI) in different Windows applications run on an Intel Core Duo T2500 processor <ref type="bibr" target="#b26">[26]</ref> which includes a specialized indirect branch predictor <ref type="bibr" target="#b19">[20]</ref>. The data are collected with hardware performance counters using VTune <ref type="bibr" target="#b27">[27]</ref>. In the examined Windows applications, on average 28 percent of the branch mispredictions are due to indirect branches. In two programs, Virtutech Simics <ref type="bibr" target="#b39">[39]</ref> and Microsoft Excel 2003, almost half of the branch mispredictions are caused by indirect branches. These results show that indirect branches cause a considerable fraction of all mispredictions even in today's relatively small-scale desktop applications.</p><p>Previously proposed indirect branch prediction techniques <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b33">[33]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b47">[47]</ref> require large hardware resources to store the target addresses of indirect branches. For example, a 1,024-entry gshare conditional branch predictor <ref type="bibr" target="#b41">[41]</ref> requires only 2,048 bits but a 1,024-entry gsharelike indirect branch predictor (tagged target cache <ref type="bibr" target="#b9">[10]</ref>) needs at least 2,048 bytes along with additional tag storage even if the processor stores only the least significant 16 bits of an indirect branch target address in each entry. 2 As such a large hardware storage comes with an expensive increase in power/energy consumption and complexity, most current high-performance processors do not dedicate separate hardware but instead use the branch target buffer (BTB) to predict indirect branches <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b34">[34]</ref>. The BTB implicitly-and usually inaccurately-assumes that the indirect branch will jump to the same target address it jumped to in its previous execution <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b33">[33]</ref>. 3 To our knowledge, only Intel Pentium M and AMD Barcelona implement specialized hardware to help the prediction of indirect branches <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b1">[2]</ref>, demonstrating that hardware designers are increasingly concerned with the performance impact of indirect branches. However, as we showed in Fig. <ref type="figure" target="#fig_0">1</ref>, even on a processor based on the Pentium M, indirect branch mispredictions are still relatively frequent.</p><p>In order to efficiently support polymorphism in objectoriented languages without significantly increasing complexity in the processor front-end, a simple and low-cost-yet effective-indirect branch predictor is necessary. A current high-performance processor already employs a large and accurate conditional branch predictor. Our goal is to use this existing conditional branch prediction hardware to also predict indirect branches instead of building separate, costly indirect branch prediction structures.</p><p>We propose a new indirect branch prediction algorithm: Virtual Program Counter (VPC) prediction. A VPC predictor treats a single indirect branch as if it were multiple conditional branches for prediction purposes only. That is, the code has the single indirect branch. But the hardware branch predictor treats it in the hardware for prediction purposes only as a sequence of conditional branch instructions. These conditional branch instructions do not exist in software. They are part of the hardware branch prediction mechanism. Ergo, we call them virtual branches.</p><p>Conceptually, each virtual branch has its own unique target address, and the target address is stored in the BTB with a unique "fake" PC, which we call the virtual PC. The processor uses the outcome of the existing conditional branch predictor to predict each virtual branch. The processor accesses the conditional branch predictor and the BTB with the virtual PC of the virtual branch. If the predictor returns "taken," the target address provided by the BTB is predicted as the target of the indirect branch. If the predictor returns "not-taken," the processor moves on to the next virtual branch in the sequence. 4  The processor repeats this process until the conditional branch predictor predicts a virtual branch as taken. VPC prediction stops if none of the virtual branches is predicted as taken after a limited number of virtual branch predictions. After VPC prediction stops, the processor can stall the front-end until the target address of the indirect branch is resolved. Our results in Section 5.2 show that the number of iterations needed to generate a correct target prediction is actually small: 45 percent of the correct predictions occur in the first virtual branch and 81 percent of the correct predictions occur within the first three virtual branches.</p><p>The VPC prediction algorithm is inspired by a compiler optimization, called receiver class prediction optimization (RCPO) <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[24]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b5">[6]</ref> or devirtualization <ref type="bibr" target="#b28">[28]</ref>. This optimization statically converts an indirect branch to 2. With a 64-bit address space, a conventional indirect branch predictor likely requires even more hardware resources to store the target addresses <ref type="bibr" target="#b33">[33]</ref>.</p><p>3. Previous research has shown that the prediction accuracy of a BTBbased indirect branch predictor, which is essentially a last-target predictor, is low (about 50 percent) because the target addresses of many indirect branches alternate rather than stay stable for long periods of time <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b33">[33]</ref>.</p><p>4. Since we are using the outcomes of the existing conditional branch predictor to predict indirect branches, we refer to the two outcomes of the predictor as "taken" and "not-taken." However, what we mean by "nottaken" when we are processing indirect branches is not "take the fall through path in the actual code" as is the case for real conditional branches. What we mean is "process the next virtual branch in our sequence of virtual branches that collectively represent the indirect branch." In other words, update the branch history, and make another pass at the conditional branch predictor. multiple direct conditional branches (in other words, it "devirtualizes" a virtual function call). Unfortunately, devirtualization requires extensive static program analysis or accurate profiling, and it is applicable to only a subset of indirect branches with a limited number of targets that can be determined statically <ref type="bibr" target="#b28">[28]</ref>. Our proposed VPC prediction mechanism provides the benefit of using conditional branch predictors for indirect branches without requiring static analysis or profiling by the compiler. In other words, VPC prediction dynamically devirtualizes an indirect branch without compiler support. Unlike compiler-based devirtualization, VPC prediction can be applied to any indirect branch regardless of the number and locations of its targets.</p><p>Contributions. The contributions of this paper are as follows:</p><p>1. To our knowledge, VPC prediction is the first mechanism that uses the existing conditional branch prediction hardware to predict the targets of indirect branches, without requiring any program transformation or compiler support. 2. VPC prediction can be applied using any current as well as future conditional branch prediction algorithm without requiring changes to the conditional branch prediction algorithm. Since VPC prediction transforms the problem of indirect branch prediction into the prediction of multiple virtual conditional branches, future improvements in conditional branch prediction accuracy can implicitly result in improving the accuracy of indirect branch prediction. 3. Unlike previously proposed indirect branch prediction schemes, VPC prediction does not require extra storage structures to maintain the targets of indirect branches. Therefore, VPC prediction provides a lowcost indirect branch prediction scheme that does not significantly complicate the front-end of the processor while providing the same performance as more complicated indirect branch predictors that require significant amounts of storage. 4. We comprehensively evaluate the performance and energy consumption of VPC prediction on both traditional C/C++ and modern object-oriented Java applications. Our results show that VPC prediction provides significant performance and energy improvements, increasing average performance by 26.7 percent/21.9 percent and decreasing energy consumption by 19 percent/22 percent, respectively, for 12 C/C++ and 11 Java applications. We find that the effectiveness of VPC prediction improves as the baseline BTB size and conditional branch prediction accuracy increase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>We first provide a brief background on how indirect branch predictors work to motivate the similarity between indirect and conditional branch prediction. There are two types of indirect branch predictors: history based and precomputation based <ref type="bibr" target="#b46">[46]</ref>. The technique we introduce in this paper utilizes history information, so we focus on history-based indirect branch predictors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Why Does History-Based Indirect Branch Prediction Work?</head><p>History-based indirect branch predictors exploit information about the control flow followed by the executing program to differentiate between the targets of an indirect branch. The insight is that the control-flow path leading to an indirect branch is strongly correlated with the target of the indirect branch <ref type="bibr" target="#b9">[10]</ref>. This is very similar to modern conditional branch predictors, which operate on the observation that the control-flow path leading to a branch is correlated with the direction of the branch <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">A Source Code Example</head><p>The example in Fig. <ref type="figure" target="#fig_1">2</ref> shows an indirect branch from the GAP program <ref type="bibr" target="#b16">[17]</ref> to provide insight into why historybased prediction of indirect branch targets works. GAP implements and interprets a language that performs mathematical operations. One data structure in the GAP language is a list. When a mathematical function is applied to a list element, the program first evaluates the value of the index of the element in the list (line 13 in Fig. <ref type="figure" target="#fig_1">2</ref>).  in the input index expressions and the code structure allows the target address to be predictable using branch history information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Previous Work on Indirect Branch Prediction</head><p>The indirect branch predictor described by Lee and Smith <ref type="bibr" target="#b37">[37]</ref> used the BTB to predict indirect branches. This scheme predicts that the target of the current instance of the branch will be the same as the target taken in the last execution of the branch. This scheme does not work well for indirect branches that frequently switch between different target addresses. Such indirect branches are commonly used to implement virtual function calls that act on objects of different classes and switch statements with many "case" targets that are exercised at runtime. Therefore, the BTBbased predictor has low (about 50 percent) prediction accuracy <ref type="bibr" target="#b37">[37]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b33">[33]</ref>.</p><p>Chang et al. <ref type="bibr" target="#b9">[10]</ref> first proposed to use branch history information to distinguish between different target addresses accessed by the same indirect branch. They proposed the "target cache," which is similar to a two-level gshare <ref type="bibr" target="#b41">[41]</ref> conditional branch predictor. The target cache is indexed using the XOR of the indirect branch PC and the branch history register. Each cache entry contains a target address. Each entry can be tagged, which reduces interference between different indirect branches. The tagged target cache significantly improves indirect branch prediction accuracy compared to a BTB-based predictor. However, it also requires separate structures for predicting indirect branches, increasing complexity in the processor front end.</p><p>Later work on indirect branch prediction by Driesen and Ho ¨lzle focused on improving the prediction accuracy by enhancing the indexing functions of two-level predictors <ref type="bibr" target="#b11">[12]</ref> and by combining multiple indirect branch predictors using a cascaded predictor <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. The cascaded predictor is a hybrid of two or more target predictors. A relatively simple first-stage predictor is used to predict easy-to-predict (single-target) indirect branches, whereas a complex second-stage predictor is used to predict hard-topredict indirect branches. Driesen and Ho ¨lzle <ref type="bibr" target="#b13">[14]</ref> concluded that a three-stage cascaded predictor performed the best for a particular set of C and Cþþ benchmarks.</p><p>Kalamatianos and Kaeli <ref type="bibr" target="#b33">[33]</ref> proposed predicting indirect branches via data compression. Their predictor uses prediction by partial matching (PPM) with a set of Markov predictors of decreasing size indexed by the result of hashing a decreasing number of bits from previous targets. The Markov predictor is a large set of tables where each table entry contains a single target address and bookkeeping bits. Similarly to a cascaded predictor, the prediction comes from the highest order table that can predict. The PPM predictor requires significant additional hardware complexity in the indexing functions, Markov tables, and additional muxes used to select the predicted target address.</p><p>In a recent work, Seznec and Michaud <ref type="bibr" target="#b47">[47]</ref> proposed extending their TAGE conditional branch predictor to also predict indirect branches. Their mechanism (ITTAGE) uses a tagless base predictor and a number of tagged tables (four or seven in the paper) indexed by an increasingly long history. The predicted target comes from the component with longer history that has a hit. This mechanism is conceptually similar to a multistage cascaded predictor with geometric history lengths, and therefore, it also requires significant additional storage space for indirect target addresses and significant complexity to handle indirect branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Our Motivation</head><p>All previously proposed indirect branch predictors (except the BTB-based predictor) require separate hardware structures to store target addresses in addition to the conditional branch prediction hardware. This not only requires significant die area (which translates into extra energy/power consumption), but also increases the design complexity of the processor front-end, which is already a complex and cycle-critical part of the design. 5 Moreover, many of the previously proposed indirect branch predictors are themselves complicated <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b33">[33]</ref>, <ref type="bibr" target="#b47">[47]</ref>, which further increases the overall complexity and development time of the design. For these reasons, most current processors do not implement separate structures to predict indirect branch targets.</p><p>Our goal in this paper is to design a low-cost technique that accurately predicts indirect branch targets (by utilizing branch history information to distinguish between the different target addresses of a branch) without requiring separate complex structures for indirect branch prediction. To this end, we propose Virtual Program Counter (VPC) prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VIRTUAL PROGRAM COUNTER (VPC) PREDICTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>A VPC predictor treats an indirect branch as a sequence of multiple conditional branches, called virtual branches. A "virtual branch" is conceptually a conditional branch that is visible only to the processor's branch prediction structures.</p><p>As such, it is different from a "real" conditional branch; it does not affect program behavior, it is not part of the program binary, and it is only used by the VPC predictor. Each virtual branch is predicted in sequence using the existing conditional branch prediction hardware, which consists of the direction predictor and the BTB (Fig. <ref type="figure" target="#fig_2">3</ref>). If the direction predictor predicts the virtual branch as not-taken, the VPC predictor moves on to predict the next virtual branch in the sequence. If the direction predictor predicts the virtual branch as taken, VPC prediction uses the target associated with the virtual branch in the BTB as the next fetch address, completing the prediction of the indirect branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prediction Algorithm</head><p>The detailed VPC prediction algorithm is shown in Algorithm 1. The key implementation issue in VPC prediction is how to distinguish between different virtual branches. Each virtual branch should access a different location in the direction 5. Using a separate predictor for indirect branch targets adds one more input to the mux that determines the predicted next fetch address. Increasing the delay of this mux can result in increased cycle time, adversely affecting the clock frequency.</p><p>predictor and the BTB (so that a separate direction and target prediction can be made for each branch). To accomplish this, the VPC predictor accesses the conditional branch prediction structures with a different virtual PC address (VPCA) and a virtual global history register value (VGHR) for each virtual branch. VPCA values are distinct for different virtual branches. VGHR values provide the context (branch history) information associated with each virtual branch.</p><p>VPC prediction is an iterative prediction process, where each iteration takes one cycle. In the first iteration (i.e., for the first virtual branch), VPCA is the same as the original PC address of the indirect branch and VGHR is the same as the GHR value when the indirect branch is fetched. If the virtual branch is predicted not-taken, the prediction algorithm moves to the next iteration (i.e., the next virtual branch) by updating the VPCA and VGHR. The VPCA value for an iteration (other than the first iteration) is computed by hashing the original PC value with a randomized constant value that is specific to the iteration. In other words, V PCA ¼ P C È HASHV AL½iter, where HASHVAL is a hard-coded hardware table of randomized numbers that are different from one another. The VGHR is simply leftshifted by one bit at the end of each iteration to indicate that the last virtual branch was predicted not-taken. 6 Note that in the first iteration, the processor does not even know that the fetched instruction is an indirect branch. This is determined only after the BTB access. If the BTB access is a hit, the BTB entry provides the type of the branch. VPC prediction algorithm continues iterating only if all of the following three conditions are satisfied: 1) the first iteration hits in the BTB, 2) the branch type indicated by the BTB entry is an indirect branch, and 3) the prediction outcome of the first iteration is not-taken. The iterative prediction process stops when a virtual branch is predicted to be taken. Otherwise, the prediction process iterates until either the number of iterations is greater than MAX_ITER or there is a BTB miss (!pred target in Algorithm 1 means there is a BTB miss). 7 If the prediction process stops without predicting a target, the processor stalls until the indirect branch is resolved. Our results in Section 5.2 show that 81 percent of the correct predictions happen in the first three iterations.</p><p>Note that the value of MAX_ITER determines how many attempts will be made to predict an indirect branch. It also dictates how many different target addresses can be stored for an indirect branch at a given time in the BTB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Prediction Example</head><p>Figs. <ref type="figure" target="#fig_4">4a and 4b</ref> show an example virtual function call and the corresponding simplified assembly code with an indirect branch. Fig. <ref type="figure" target="#fig_4">4c</ref> shows the virtual conditional branches corresponding to the indirect branch. Even though the static assembly code has only one indirect branch, the VPC predictor treats the indirect branch as multiple conditional branches that have different targets and VPCAs. Note that the hardware does not actually generate multiple conditional branches. The instructions in Fig. <ref type="figure" target="#fig_4">4c</ref> are shown to demonstrate VPC prediction conceptually. We assume, for this example, that MAX_ITER is 3, so there are only three virtual conditional branches.</p><formula xml:id="formula_0">Algorithm 1. VPC prediction algorithm iter 1 V P CA P C V GHR GHR done F ALSE while (!done) do pred target access_BTB(V P CA) pred dir access_conditional_BP(V P CA, V GHR) if (pred target andðpred dir ¼ T AKENÞ) then next P C pred target done T RUE else if (!pred target orðiter ! MAX IT ERÞ) then ST ALL T RUE done T RUE end if V P CA Hash(P C, iter) V GHR Left-Shift(V GHR) iter++ end while</formula><p>Table <ref type="table" target="#tab_1">1</ref> demonstrates five possible cases when the indirect branch in Fig. <ref type="figure" target="#fig_4">4</ref> is predicted using VPC prediction, by showing the inputs and outputs of the VPC predictor in each iteration. We assume that the GHR is 1111 when the indirect branch is fetched. Cases 1, 2, and 3 correspond to cases where, respectively, the first, second, or third virtual branch is predicted taken by the conditional branch direction predictor (BP). As VPC prediction iterates, VPCA and VGHR values are updated as shown in the table. Case 4 corresponds to the case where all three of the virtual branches are predicted not-taken, and therefore, 6. Note that VPC addresses (VPCAs) can conflict with real PC addresses in the program, thereby increasing aliasing and contention in the BTB and the direction prediction structures. The processor does not require any special action when aliasing happens. To reduce such aliasing, the processor designer should: 1) provide a good randomizing hashing function and values to generate VPCAs and 2) codesign the VPC prediction scheme and the conditional branch prediction structures carefully to minimize the effects of aliasing. Conventional techniques proposed to reduce aliasing in conditional branch predictors <ref type="bibr" target="#b41">[41]</ref>, <ref type="bibr" target="#b8">[9]</ref> can also be used to reduce aliasing due to VPC prediction. However, our experimental results in [35, Section 5.5] and in Section 7.5 show that the negative effect of VPC prediction on the BTB miss rate and conditional branch misprediction rate is tolerable. 7. The VPC predictor can continue iterating the prediction process even if there is a BTB miss. However, we found that continuing in this case does not improve the prediction accuracy. Hence, to simplify the prediction process, our VPC predictor design stops the prediction process when there is a BTB miss in any iteration. the outcome of the VPC predictor is a stall. Case 5 corresponds to a BTB miss for the second virtual branch and thus also results in a stall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training Algorithm</head><p>The VPC predictor is trained when an indirect branch is 1. to update the direction predictor as not-taken for the virtual branches that have the wrong target (because the targets of those branches were not taken) and to update it as taken for the virtual branch, if any, that has the correct target; 2. to update the replacement policy bits of the correct target in the BTB (if the correct target exists in the BTB); 3. to insert the correct target address into the BTB (if the correct target does not exist in the BTB). Like prediction, training is also an iterative process. To facilitate training on a correct prediction, an indirect branch carries with it through the pipeline the number of iterations performed to predict the branch (predicted iter). VPCA and VGHR values for each training iteration are recalculated exactly the same way as in the prediction algorithm. Note that only one virtual branch trains the prediction structures in a given cycle. 8   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Training on a Correct Prediction</head><p>If the predicted target for an indirect branch was correct, all virtual branches except for the last one (i.e., the one that has the correct target) train the direction predictor as not-taken (as shown in Algorithm 2). The last virtual branch trains the conditional branch predictor as taken and updates the replacement policy bits in the BTB entry corresponding to the correctly predicted target address. Note that Algorithm 2 is a special case of Algorithm 3 in that it is optimized to eliminate unnecessary BTB accesses when the target prediction is correct.</p><p>Algorithm 2. VPC training algorithm when the branch target is correctly predicted. Inputs: predicted_iter, PC, GHR iter</p><formula xml:id="formula_1">1 V P CA P C V GHR GHR while (iter &lt; predicted iter) do if (iter = predicted iter) then update_conditional_BP(V P CA, V GHR, TAKEN) update_replacement_BTB(V P CA) else update_conditional_BP(V P CA, V GHR, NOT-TAKEN) end if V PCA Hash(PC, iter) V GHR</formula><p>Left-Shift(V GHR) iter++ end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Training on a Wrong Prediction</head><p>If the predicted target for an indirect branch was wrong, there are two misprediction cases: 1) Wrong-target: One of the virtual branches has the correct target stored in the BTB but the direction predictor predicted that branch as not-taken; 2) No-target: none of the virtual branches has the correct target stored in the BTB, so the VPC predictor could not have predicted the correct target. In the no-target case, the correct target address needs to be inserted into the BTB.  </p><formula xml:id="formula_2">F ALSE)) do pred target access_BTB(V P CA) if (pred target = CORRECT_TARGET) then update_conditional_BP(V PCA, V GHR, TAKEN) update_replacement_BTB(V PCA) found correct target T RUE else if (pred target) then update_conditional_BP(V P CA, V GHR, NOT-TAKEN) end if V P CA Hash(PC, iter) V GHR Left-Shift(V GHR) iter++ end while /* no-target case */ if (found correct target ¼ F ALSE) then V P CA</formula><p>VPCA corresponding to the virtual branch with a BTB-Miss or Least-frequently-used target among all virtual branches V GHR VGHR corresponding to the virtual branch with a BTB-Miss or Least-frequently-used target among all virtual branches insert_BTB(V P CA, CORRECT_TARGET) update_conditional_BP(V P CA, V GHR, TAKEN) end if</p><p>To distinguish between wrong-target and no-target cases, the training logic accesses the BTB for each virtual branch (as shown in Algorithm 3). 9 If the target address stored in the BTB for a virtual branch is the same as the correct target address of the indirect branch (wrong-target case), the direction predictor is trained as taken and the replacement policy bits in the BTB entry corresponding to the target address are updated. Otherwise, the direction predictor is trained as not-taken. Similarly to the VPC prediction algorithm, when the training logic finds a virtual branch with the correct target address, it stops training.</p><p>If none of the iterations (i.e., virtual branches) has the correct target address stored in the BTB, the training logic inserts the correct target address into the BTB. One design question is what VPCA/VGHR values should be used for the newly inserted target address. Conceptually, the choice of VPCA value determines the order of the newly inserted virtual branch among all virtual branches. To insert the new target in the BTB, our current implementation of the training algorithm uses the VPCA/VGHR values corresponding to the virtual branch that missed in the BTB. If none of the virtual branches missed in the BTB, our implementation uses the VPCA/VGHR values corresponding to the virtual branch whose BTB entry has the smallest least frequently used (LFU) value. Note that the virtual branch that missed in the BTB or that has the smallest LFU value in its BTB entry can be determined easily while the training algorithm iterates over virtual branches. (However, we do not show this computation in Algorithm 3 to keep the algorithm more readable.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Supporting Multiple Iterations per Cycle</head><p>The iterative prediction process can take multiple cycles. The number of cycles needed to make an indirect branch prediction with a VPC predictor can be reduced if the processor already supports the prediction of multiple conditional branches in parallel <ref type="bibr" target="#b51">[51]</ref>. The prediction logic can perform the calculation of VPCA values for multiple iterations in parallel since VPCA values do not depend on previous iterations. VGHR values for multiple iterations can also be calculated in parallel, assuming that previous iterations were "not-taken" since the prediction process stops when an iteration results in a "taken" prediction. We found that the performance benefit of supporting multiple predictions per cycle is not significant (see <ref type="bibr" target="#b35">[35,</ref><ref type="bibr">Section 5.4]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Pipelining the VPC Predictor</head><p>So far, our discussion assumed that conditional branch prediction structures (the BTB and the direction predictor) can be accessed in a single-processor clock cycle. However, in some modern processors, access of the conditional branch prediction structures takes multiple cycles. To accommodate this, the VPC prediction process needs to be pipelined. We briefly show that our mechanism can be trivially adjusted to accommodate pipelining.</p><p>In a pipelined implementation of VPC prediction, the next iteration of VPC prediction is started in the next cycle without knowing the outcome of the previous iteration in a pipelined fashion. In other words, consecutive VPC prediction iterations are fed into the pipeline of the conditional branch predictor one after another, one iteration per cycle. Pipelining VPC prediction is similar to supporting multiple iterations in parallel. As explained in Section 3.4, the VPCA value of a later iteration is not dependent on previous iterations; hence, VPCA values of different iterations are computed independently. The VGHR value of a later iteration is calculated assuming that previous iterations were "not-taken" since the VPC prediction process stops anyway when an iteration results in a "taken" prediction. If it turns out that an iteration is not needed because a previous iteration was predicted as "taken," then the later iterations in the branch predictor pipeline are simply discarded when they produce a prediction. As such, VPC prediction naturally yields itself to pipelining without significant hardware modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Hardware Cost and Complexity</head><p>The extra hardware required by the VPC predictor on top of the existing conditional branch prediction scheme is as follows:</p><p>1. Three registers to store iter, V P CA, and V GHR for prediction purposes (Algorithm 1).</p><p>9. Note that these extra BTB accesses for training are required only on a misprediction and they do not require an extra BTB read port. An extra BTB access holds only one BTB bank per training iteration. Even if the access results in a bank conflict with the accesses from the fetch engine for all the mispredicted indirect branches, we found that the performance impact is negligible due to the low frequency of indirect branch mispredictions in the VPC prediction mechanism. indirect branch throughout the pipeline. This value cannot be greater than MAX IT ER. 4. Three registers to store iter, V P CA, and V GHR for training purposes (Algorithms 2 and 3). 5. Two registers to store the V P CA and V GHR values that may be needed to insert a new target into the BTB (for the no-target case in Algorithm 3). Note that the cost of the required storage is very small. Unlike previously proposed history-based indirect branch predictors, no large or complex tables are needed to store the target addresses. Instead, target addresses are naturally stored in the existing BTB.</p><p>The combinational logic needed to perform the computations required for prediction and training is also simple. Actual PC and GHR values are used to access the branch prediction structure in the first iteration of indirect branch prediction. While an iteration is performed, the VPCA and VGHR values for the next iteration are calculated and loaded into the corresponding registers. Therefore, updating VPCA and VGHR for the next iterations is not on the critical path of the branch predictor access.</p><p>The training of the VPC predictor on a misprediction may slightly increase the complexity of the BTB update logic because it requires multiple iterations to access the BTB. However, the VPC training logic needs to access the BTB multiple times only on a target misprediction, which is relatively infrequent, and the update logic of the BTB is not on the critical path of instruction execution. If needed, pending BTB and branch predictor updates due to VPC prediction can be buffered in a queue to be performed in consecutive cycles. (Note that such a queue to update conditional branch prediction structures already exists in some modern processor implementations with limited number of read/write ports in the BTB or the direction predictor <ref type="bibr" target="#b40">[40]</ref>.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL METHODOLOGY</head><p>We use a Pin-based <ref type="bibr" target="#b38">[38]</ref> cycle-accurate x86 simulator to evaluate VPC prediction. The parameters of our baseline processor are shown in Table <ref type="table" target="#tab_3">2</ref>. The baseline processor uses the BTB to predict indirect branches <ref type="bibr" target="#b37">[37]</ref>.</p><p>The experiments are run using five SPEC CPU2000 INT benchmarks, five SPEC CPU2006 INT/Cþþ benchmarks, and two other Cþþ benchmarks. We chose those benchmarks in SPEC INT 2000 and 2006 INT/Cþþ suites that gain at least 5 percent performance with a perfect indirect branch predictor. Table <ref type="table">3</ref> provides a brief description of the other two Cþþ benchmarks.</p><p>We use Pinpoints <ref type="bibr" target="#b45">[45]</ref> to select a representative simulation region for each benchmark using the reference input set. Each benchmark is run for 200 million x86 instructions. Table <ref type="table">4</ref> shows the characteristics of the examined benchmarks on the baseline processor. All binaries are compiled with Intel's production compiler (ICC) <ref type="bibr" target="#b25">[25]</ref> with the -O3 optimization level.  We have provided an extensive performance characterization of VPC prediction on C/Cþþ applications in our previous paper <ref type="bibr" target="#b35">[35]</ref>. In particular, in <ref type="bibr" target="#b35">[35]</ref>, we provided the characteristics of indirect branch targets of C/Cþþ applications, performance comparisons to other indirect branch predictors, sensitivity of VPC prediction to microarchitecture parameters, and performance of VPC prediction on server applications. In this paper, after briefly summarizing the performance of VPC prediction, we focus our attention to the training options for VPC prediction (Section 5.3), power/ energy consumption analysis (Section 5.4), and the evaluation of VPC prediction on Java applications (Section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dynamic Target Distribution</head><p>We first briefly analyze the behavior of indirect branch targets in our benchmark set. Fig. <ref type="figure" target="#fig_12">5</ref> shows the distribution of the number of dynamic targets for executed indirect branches. In eon, gap, and ixx, more than 40 percent of the executed indirect branches have only one target. These single-target indirect branches are easily predictable with a simple BTB-based indirect branch predictor. However, in gcc (50 percent), crafty (100 percent), perlbmk (94 percent), perlbench (98 percent), sjeng (100 percent), and povray (97 percent), over 50 percent of the dynamic indirect branches have more than five targets. On average, 51 percent of the dynamic indirect branches in the evaluated benchmarks have more than five targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance of VPC Prediction</head><p>Fig. <ref type="figure">6a</ref> shows the performance improvement of VPC prediction over the baseline BTB-based predictor when MAX_ITER is varied from 2 to 16. Fig. <ref type="figure">6b</ref> shows the indirect branch MPKI in the baseline and with VPC prediction. In eon, gap, and namd, where over 60 percent of all executed indirect branches have at most two unique targets (as shown in Fig. <ref type="figure" target="#fig_12">5</ref>), VPC prediction with MAX_ITER¼2 eliminates almost all indirect branch mispredictions. Almost all indirect branches in richards have three or four different targets. Therefore, when the VPC predictor can hold four different targets per indirect branch (MAX_ ITER=4), indirect branch MPKI is reduced to only 0.7 (from 13.4 in baseline and 1.8 with MAX_ITER¼2). The performance of only perlbmk and perlbench continues to improve significantly as MAX_ITER is increased beyond 6, because at least 65 percent of the indirect branches in these two benchmarks have at least 16 dynamic targets. (This is due to the large switch-case statements in perl that are used to parse and pattern-match the input expressions. The most frequently executed/mispredicted indirect branch in perlbench belongs to a switch statement with 57 static targets.) Note that even though the number of mispredictions can be further reduced when MAX_ITER is increased beyond 12, the performance improvement actually decreases for perlbench. This is due to two reasons: 1) storing more targets in the BTB via a larger MAX_ITER value starts creating conflict misses and 2) some correct predictions take longer when MAX_ITER is increased, which increases the idle cycles in which no instructions are fetched.</p><p>On average, VPC prediction improves performance by 26.7 percent over the BTB-based predictor (when MAX_ ITER¼12), by reducing the average indirect branch MPKI from 4.63 to 0.52. Since a MAX_ITER value of 12 provides the best performance, most later experiments in this section use MAX_ITER¼12. We found that using VPC prediction does not significantly impact the prediction accuracy of conditional branches in the benchmark set we examined, as shown in <ref type="bibr" target="#b35">[35]</ref>. Fig. <ref type="figure" target="#fig_8">7</ref> shows the distribution of the number of iterations needed to generate a correct target prediction. On average, 44.6 percent of the correct predictions occur in the first iteration (i.e., zero idle cycles) and 81 percent of the correct predictions occur within three iterations. Only in perlbmk and sjeng, more than 30 percent of all correct predictions require at least five iterations. Hence, most correct predictions are performed quickly resulting in few idle cycles during which the fetch engine stalls.</p><p>Fig. <ref type="figure">8</ref> provides insight into the performance improvement of VPC prediction by showing the distribution of mispredictions per highly mispredicted static indirect branches using both the baseline BTB predictor and the VPC predictor. The left bar for each benchmark shows the distribution of mispredictions per the Nth most mispredicted static indirect branch, sorted by number of mispredictions, using the baseline BTB-based predictor. The portions of each bar labeled "1" and "2" are the fraction of all mispredictions caused by, respectively, the "most" and "second most" mispredicted indirect branch, and so on. The most mispredicted static indirect branch causes on average approximately 50 percent of all indirect branch mispredictions. (This fraction varies between 21 percent and 87 percent depending on the benchmark.) The data show that only a few indirect branches are responsible for the majority of the mispredictions. The second set of bars in Fig. <ref type="figure">8</ref> shows the of mispredictions for the same static indirect branches using the VPC predictor, normalized to the number of mispredictions with the BTB-based predictor. The VPC predictor significantly reduces or eliminates the mispredictions across the board, i.e., for almost all of the highly mispredicted indirect branches. We conclude that VPC prediction is effective at reducing misprediction rate across a large number of different indirect branches.</p><p>Even though VPC prediction is very effective at reducing the indirect branch misprediction rate, it does not completely eliminate indirect branch mispredictions. This is due to two reasons. The first reason is algorithmic: VPC prediction cannot correctly predict a target address when the target is not correlated with branch history in the way our prediction and training algorithms can capture. The second reason is due to resource contention: the contention and interference in BTB entries and conditional branch direction predictor entries between both conditional and indirect branches as well as different targets of indirect branches can lead to mispredictions. We analyzed the effects of such contention and interference in <ref type="bibr" target="#b35">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effect of VPC Training: Where to Insert the Correct Target Address</head><p>In Section 3.3.2, we described how the VPC training algorithm inserts the correct target into the BTB if the VPC prediction was wrong. Where the correct target is inserted in the BTB with respect to other targets of the branch could affect performance because 1) it determines which target will be replaced by the new target and 2) it affects the "order" of appearance of targets in a future VPC prediction loop. This section evaluates different policies for inserting a target address into the BTB upon a VPC misprediction. Fig. <ref type="figure" target="#fig_7">9</ref> shows the performance improvement provided by four different policies we examine. Naive-Insert-MAXITER inserts the target address into the BTB without first checking whether or not it already exists in the BTB entries corresponding to the virtual branches. The target address is inserted into the first available virtual branch position, i.e., that corresponding to a virtual branch that missed in the BTB. If none of the virtual branches had missed in the BTB, the target is always inserted in the MAX_ITER position. The benefit of this mechanism is that it does not require the VPC training logic to check all the BTB entries corresponding to the virtual branches; hence, it is simpler to implement. The disadvantage is that it increases the redundancy of target addresses in the BTB (hence, it reduces the areaefficiency of the BTB) since the target address of each virtual branch is not necessarily unique.</p><p>The other three policies we examine require each virtual branch to have a unique target address, but differ in which virtual branch they replace if the VPC prediction was wrong and neither the correct target of the indirect branch nor an empty virtual branch slot corresponding to the indirect branch was found in the BTB. Unique-Random Fig. <ref type="figure">8</ref>. Fraction of mispredictions caused by the Nth most mispredicted static indirect branch. The portions of each bar labeled "1" and "2" are the fraction of all mispredictions caused by, respectively, the "most" and "second most" mispredicted indirect branch, and so on. The data are normalized to the number of mispredictions in the baseline.  replaces a BTB entry randomly among all the virtual branches. Unique-LRU replaces the target address corresponding to the virtual branch whose entry has the leastrecently-used (LRU) value. Unique-LFU is the default scheme we described in Section 3.3.2, which replaces the target address corresponding to the virtual branch whose entry has the smallest LFU-value.</p><p>According to Fig. <ref type="figure" target="#fig_7">9</ref>, the performance of most benchmarks-except perlbmk, perlbench, and sjeng-is not sensitive to the different training policies. Since the number of dynamic targets per branch is very high in perlbmk, perlbench, and sjeng (shown in Fig. <ref type="figure" target="#fig_12">5</ref> and <ref type="bibr" target="#b35">[35]</ref>), the contention for virtual branch slots in the BTB is high. For our set of benchmarks, the Unique-LFU scheme provides the highest performance (1 percent and 2 percent better than Unique-LRU and Unique-Random, respectively). We found that frequently used targets in the recent past are more likely to be used in the near future, and therefore, it is better to replace less frequently used target addresses. Hence, we have chosen the Unique-LFU scheme as our default VPC training scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Effect on Power and Energy Consumption</head><p>Fig. <ref type="figure" target="#fig_0">10</ref> shows the impact of VPC prediction and TTC predictors of different sizes on maximum processor power, overall energy consumption, energy-delay product of the processor, and the energy consumption of the branch prediction logic (which includes conditional/indirect predictors and the BTB). We used the Wattch infrastructure <ref type="bibr" target="#b4">[5]</ref> to measure power/energy consumption, faithfully modeling every processing structure and the additional accesses to the branch predictors. The power model is based on 100 nm technology and a 4 GHz processor.</p><p>On average, VPC prediction reduces the overall energy consumption by 19 percent, which is higher than the energy reduction provided by the most energy-efficient TTC predictor (12 KB). The energy reduction is due to the reduced pipeline flushes and thus reduced amount of time the processor spends fetching and executing wrong-path instructions. Furthermore, VPC prediction reduces the energy-delay product (EDP) by 42 percent, which is also higher than the EDP reduction provided by the most energy-efficient TTC predictor. VPC prediction improves EDP significantly because it improves performance while at the same time reducing energy consumption.</p><p>VPC prediction does not significantly increase the maximum power consumption of the processor whereas even a 3 KB TTC predictor results in a 0.3 percent increase in maximum power consumption due to its additional hardware overhead. Note that relatively large TTC predictors significantly increase not only the complexity but also the energy consumption of the branch prediction unit. We conclude that VPC prediction is an energy-efficient way of improving processor performance without significantly increasing the complexity of the processor front end and the overall processor power consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">VPC PREDICTION AND COMPILER-BASED DEVIRTUALIZATION</head><p>Devirtualization is the substitution of an indirect method call with direct method calls in object-oriented languages <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[24]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b28">[28]</ref>. Ishizaki et al. <ref type="bibr" target="#b28">[28]</ref> classify the devirtualization techniques into guarded devirtualization and direct devirtualization. Guarded devirtualization. Fig. <ref type="figure" target="#fig_0">11a</ref> shows an example virtual function call in the Cþþ language. In the example, depending on the actual type of Shape s, different area functions are called at runtime. However, even though there could be many different shapes in the program, if the types of shapes are mostly either an instance of the Rectangle class or the Circle class at runtime, the compiler can convert the indirect call to multiple guarded direct calls <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b5">[6]</ref>, as shown in Fig. <ref type="figure" target="#fig_0">11b</ref>. This compiler optimization is called Receiver Class Prediction Optimization (RCPO) and the compiler can perform RCPO based on profiling.</p><p>The benefits of this optimization are: 1) it enables other compiler optimizations. The compiler could inline the direct function calls or perform interprocedural analysis <ref type="bibr" target="#b17">[18]</ref>. Removing function calls also reduces the register save/ restore overhead. 2) The processor can predict the virtual function call using a conditional branch predictor, which Fig. <ref type="figure" target="#fig_0">10</ref>. Effect of VPC on energy/power consumption. Fig. <ref type="figure" target="#fig_0">11</ref>. A virtual function call and its devirtualized form. usually has higher accuracy than an indirect branch predictor <ref type="bibr" target="#b5">[6]</ref>. However, not all indirect calls can be converted to multiple conditional branches. In order to perform RCPO, the following conditions need to be fulfilled <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b5">[6]</ref>:</p><p>1. The number of frequent target addresses from a caller site should be small (1-2). 2. The majority of target addresses should be similar across input sets. 3. The target addresses must be available at compiletime. Direct devirtualization. Direct devirtualization converts an indirect call into a single unconditional direct call if the compiler can prove that there is only one possible target for the indirect call. Hence, direct devirtualization does not require a guard before the direct call, but requires wholeprogram analysis to make sure that there is only one possible target. This approach enables code optimizations that would otherwise be hindered by the indirect call. However, this approach cannot usually be used statically if the language supports dynamic class loading, like Java. Dynamic recompilation can overcome this limitation, but it requires an expensive mechanism called on-stack replacement <ref type="bibr" target="#b28">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Limitations of Compiler-Based Devirtualization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Need for Static Analysis or Accurate Profiling</head><p>The application of devirtualization to large commercial software bases is limited by the cost and overhead of the static analysis or profiling required to guide the method call transformation. Devirtualization based on static analysis requires type analysis, which in turn requires whole program analysis <ref type="bibr" target="#b28">[28]</ref>, and unsafe languages like Cþþ also require pointer alias analysis. Note that these analyses need to be conservative in order to guarantee correct program semantics. Guarded devirtualization usually requires accurate profile information, which may be very difficult to obtain for large applications. Due to the limited applicability of static devirtualization, Ishizaki et al. <ref type="bibr" target="#b28">[28]</ref> report only an average 40 percent reduction in the number of virtual method calls on a set of Java benchmarks, with the combined application of aggressive guarded and direct devirtualization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Impact on Code Size and Branch Mispredictions</head><p>Guarded devirtualization can sometimes reduce performance since 1) it increases the static code size by converting a single indirect branch instruction into multiple guard test instructions and direct calls and 2) it could replace one possibly mispredicted indirect call with multiple conditional branch mispredictions, if the guard tests become hard-to-predict branches <ref type="bibr" target="#b48">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Lack of Adaptivity</head><p>The most frequently taken targets chosen for devirtualization can be based on profiling, which averages the whole execution of the program for one particular input set. However, the most frequently taken targets can be different across different input sets. Furthermore, the most frequently taken targets can change during different phases of the program. Additionally, dynamic linking and dynamic class loading can introduce new targets at runtime. Compilerbased devirtualization cannot adapt to these changes in program behavior because the most frequent targets of a method call are determined statically and encoded in the binary.</p><p>Due to these limitations, many state-of-the-art compilers either do not implement any form of devirtualization (e.g., GCC 4.0 [19] 10 ) or they implement a limited form of direct devirtualization that converts only provably monomorphic virtual function calls into direct function calls (e.g., the Bartok compiler <ref type="bibr" target="#b48">[48]</ref>, <ref type="bibr" target="#b42">[42]</ref> or the .NET Runtime <ref type="bibr" target="#b43">[43]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">VPC versus Compiler-Based Devirtualization</head><p>VPC prediction is essentially a dynamic devirtualization mechanism used for indirect branch prediction purposes. However, VPC's devirtualization is visible only to the branch prediction structures. VPC has the following advantages over compiler-based devirtualization:</p><p>1. As it is a hardware mechanism, it can be applied to any indirect branch without requiring any static analysis/guarantees or profiling. 2. Adaptivity: Unlike compiler-based devirtualization, the dynamic training algorithms allow the VPC predictor to adapt to changes in the most frequently taken targets or even to new targets introduced by dynamic linking or dynamic class loading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Because virtual conditional branches are visible only</head><p>to the branch predictor, VPC prediction does not increase the code size, nor does it possibly convert a single indirect branch misprediction into multiple conditional branch mispredictions. On the other hand, the main advantage of compilerbased devirtualization over VPC prediction is that it enables compile-time code optimizations. However, as we showed in our previous paper <ref type="bibr" target="#b35">[35]</ref>, the two techniques can be used in combination and VPC prediction provides performance benefits on top of compiler-based devirtualization. In particular, using VPC prediction on binaries that are already optimized with compiler-based devirtualization improves performance by 11.5 percent (see <ref type="bibr" target="#b35">[35,</ref><ref type="bibr">Section 6.3]</ref> for a detailed analysis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EVALUATION OF VPC PREDICTION ON OBJECT-ORIENTED JAVA APPLICATIONS</head><p>This section evaluates VPC prediction using a set of modern object-oriented Java applications, the full set of DaCapo benchmarks <ref type="bibr" target="#b3">[4]</ref>. Our goal is to demonstrate the benefits of VPC prediction on real object-oriented applications and to analyze the differences in the behavior of VPC prediction on object-oriented Java programs versus on traditional C/Cþþ programs (which were evaluated briefly in Section 5 and extensively in <ref type="bibr" target="#b35">[35]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Methodology</head><p>We have built an iDNA-based <ref type="bibr" target="#b2">[3]</ref> cycle-accurate x86 simulator to evaluate VPC prediction on Java applications.</p><p>10. GCC only implements a form of devirtualization based on class hierarchy analysis in the ipa-branch experimental branch, but not in the main branch <ref type="bibr" target="#b44">[44]</ref>.</p><p>iDNA <ref type="bibr" target="#b2">[3]</ref> is a dynamic binary instrumentation tool similar to Pin <ref type="bibr" target="#b38">[38]</ref>, but capable of tracing Java virtual machines. The DaCapo benchmarks are run with Sun J2SE 1.4.2_15 JRE on Windows Vista. Each benchmark is run for 200 million x86 instructions with the small input set. The parameters of our baseline processor are the same as those we used to evaluate VPC prediction on C/Cþþ applications as shown in Table <ref type="table" target="#tab_3">2</ref>. 11  Table <ref type="table" target="#tab_4">5</ref> shows the characteristics of the examined Java programs on the baseline processor. Compared to the evaluated C/C++ programs, the evaluated Java programs have significantly higher number of static and dynamic indirect branches and indirect branch misprediction rates (also see Table <ref type="table">4</ref>). We found that this difference is due to the object-oriented nature of the Java programs, which contain a large number of virtual functions, and the behavior of the Java Virtual Machine, which uses a large number of indirect branches in its interpretation and dynamic translation phases <ref type="bibr" target="#b14">[15]</ref>. As a result, the potential performance improvement possible with perfect indirect branch prediction is significantly higher in the evaluated Java applications (73.1 percent) than in the evaluated C/Cþþ applications (32.5 percent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Dynamic Target Distribution of Java Programs</head><p>Fig. <ref type="figure" target="#fig_9">12</ref> shows the distribution of the number of dynamic targets for executed indirect branches. Unlike C/Cþþ programs evaluated in Section 5.1, only 14 percent of executed indirect branches have a single target and 53 percent of them have more than 20 targets (recall that 51 percent of the indirect branches in the evaluated C/Cþþ programs had more than five targets). On average, 76 percent of the dynamic indirect branches in the evaluated Java benchmarks have more than five targets, in contrast to the 51 percent in the evaluated indirect-branch intensive C/Cþþ programs. Hsqldb is the only benchmark where more than 20 percent of the dynamic indirect branches have only one target, and these monomorphic branches are easily predictable with a simple BTB-based indirect branch predictor. The high number of targets explains why the evaluated Java programs have higher indirect branch misprediction rates than the evaluated C/Cþþ programs.</p><p>We found that there are two major reasons for the high number of dynamic targets in the Java applications: 1) The evaluated Java applications are written in object-oriented style. Therefore, they include many polymorphic virtual function calls, i.e., virtual function calls that are overridden by many derived classes, whose overridden forms are exercised at runtime. 2) The Java virtual machine itself uses a significant number of indirect jumps with many targets in its interpretation routines, as shown in previous work on virtual machines <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Performance of VPC Prediction on Java Programs</head><p>Fig. <ref type="figure" target="#fig_10">13a</ref> shows the performance improvement of VPC prediction over the baseline BTB-based predictor when MAX_ITER is varied from 2 to 16. Fig. <ref type="figure" target="#fig_10">13b</ref> shows the indirect branch misprediction rate (MPKI) in the baseline and with VPC prediction. Similarly to the results for C/Cþþ benchmarks, a MAX_ITER value of 12 provides the highest performance improvement. All of the 11 Java applications experience more than 10 percent performance improvement with VPC prediction and 10 of the 11 applications experience more than 15 percent performance improvement. This shows that the benefits of VPC prediction are very consistent across different object-oriented Java applications. On average, VPC prediction provides 21.9 percent performance improvement in the Java applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Analysis</head><p>Since the majority of indirect branches have more than 10 targets, as MAX_ITER increases, the indirect branch MPKI decreases (from 11.9 to 5.2), until MAX_ITER equals 12. The most significant drop in MPKI (from 10.9 to 7.9) happens when MAX_ITER is increased from 2 to 4 (meaning VPC prediction can store four different targets for a branch rather than two). However, when MAX_ITER is greater than 12, MPKI starts increasing in most of the evaluated Java applications (unlike in C/Cþþ applications where MPKI continues to decrease). This is due to the pressure extra virtual branches exert on the BTB: as Java applications 11. We use a BTB size of 8,192 entries to evaluate Java applications since they are very branch intensive. However, we also evaluate other BTB sizes in Section 7.5.1. have a large number of indirect branches with a large number of dynamically exercised targets, more targets contend for the BTB space with higher values of MAX_I-TER. As a result, BTB miss rate for virtual branches increases and the prediction accuracy of VPC prediction decreases. When the MPKI increase is combined with the additional iteration cycles introduced for some predictions by higher MAX_ITER values, the performance improvement of VPC prediction drops from 21.9 percent (for MAX_ITER¼12) to 20.4 percent (for MAX_ITER¼16).</p><p>Even though VPC prediction significantly reduces the misprediction rate from 11.9 to 5.2 MPKI in Java applications, a significant number of mispredictions still remain. This is in contrast to the results we obtained for C/Cþþ applications where VPC prediction was able to eliminate 89 percent of all mispredictions (down to 0.63 MPKI). Hence, indirect branches in Java applications are more difficult to predict. Therefore, other techniques like dynamic predication <ref type="bibr" target="#b31">[31]</ref>, <ref type="bibr" target="#b30">[30]</ref> might be needed to complement VPC prediction to further reduce the impact of indirect branches on Java application performance. Fig. <ref type="figure" target="#fig_11">14</ref> shows the distribution of the number of iterations needed to generate a correct target prediction. On average, 44.8 percent of the correct predictions occur in the first iteration (i.e., zero idle cycles) and 78.7 percent of the correct predictions occur within four iterations. Hence, most correct predictions are performed quickly resulting in few idle cycles during which the fetch engine stalls. Note that the number of iterations (cycles) it takes to make a correct prediction is higher for Java applications than for C/Cþþ applications because indirect branches in Java applications have a significantly higher number of dynamically exercised targets per indirect branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">VPC Prediction versus Other Indirect Branch</head><p>Predictors on Java Applications Fig. <ref type="figure" target="#fig_15">15</ref> compares the performance of VPC prediction with the tagged target cache (TTC) predictor <ref type="bibr" target="#b9">[10]</ref>. On average, VPC prediction provides performance improvement equivalent to that provided by a 3-6 KB TTC predictor (similarly to the results for C/Cþþ applications <ref type="bibr" target="#b35">[35]</ref>). 12 Fig. <ref type="figure" target="#fig_14">16</ref> compares the performance of VPC prediction with the cascaded predictor. On average, VPC prediction provides the performance provided by a 5.5-11 KB cascaded predictor. Because the number of static indirect branches is very high in Java applications, a small cascaded predictor (cascaded-704 B) performs significantly worse than the baseline BTB-based predictor. This behavior is not seen in C/C++ benchmarks because these benchmarks have much fewer indirect branches with smaller number of targets that do not cause significant contention in the tables of a small cascaded predictor. However, even though there are many static indirect branches in the examined Java applications, VPC predictor still provides significant performance improvements equaling those of large cascaded predictors, without requiring extra storage for indirect branch targets.</p><p>Note that the size of the TTC or cascaded predictor that provides the same performance as VPC prediction is smaller for Java applications than for C/Cþþ applications <ref type="bibr" target="#b35">[35]</ref>. In other words, TTC and cascaded predictors are relatively more effective in Java than C/Cþþ applications. This is because of the large indirect branch and target working set size of Java applications, which can better utilize the extra target storage space provided by specialized indirect branch predictors. 12. In the examined Java applications, increasing the size of the TTC predictor up to 48 KB continues providing large performance improvements, whereas doing so results in very little return in performance for C/ Cþþ applications. A larger TTC predictor is better able to accommodate the large indirect branch target working set of Java applications whereas a small TTC predictor is good enough to accommodate the small target working set of C/Cþþ applications. Hence the difference in the effect of TTC size on performance between Java versus C/Cþþ applications.  Table <ref type="table" target="#tab_5">6</ref> shows the effect of the baseline BTB size on VPC prediction performance on Java applications. Similarly to what we observed for C/Cþþ applications <ref type="bibr" target="#b35">[35]</ref>,</p><p>VPC prediction provides higher performance improvements as BTB size increases. However, with smaller BTB sizes, VPC prediction's performance improvement is smaller on Java applications than on C/Cþþ applications. For example, with a 512-entry BTB, VPC prediction improves the performance of Java applications by 6.3 percent whereas it improves the performance of C/Cþþ applications by 18.5 percent <ref type="bibr" target="#b35">[35]</ref>. As Java applications have very large indirect branch and target address working sets, VPC prediction results in a larger contention (i.e., conflict misses) in the BTB in these applications than in C/Cþþ applications, thereby delivering a smaller performance improvement. Even so, the performance improvement provided by VPC prediction with very small BTB sizes is significant for Java applications. We conclude that VPC prediction is very effective on Java applications for a wide variety of BTB sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.2">Effect of a Less Aggressive Processor</head><p>Fig. <ref type="figure" target="#fig_13">17</ref> shows the performance of VPC and TTC predictors on a less aggressive baseline processor that has a 20-stage pipeline, 4-wide fetch/issue/retire rate, 128-entry instruction window, 16 KB perceptron branch predictor, 4K-entry BTB, and 200-cycle memory latency. Similarly to our observation for C/Cþþ applications <ref type="bibr" target="#b35">[35]</ref>, since the less aggressive processor incurs a smaller penalty for a branch misprediction, improved indirect branch handling provides smaller performance improvements than in the baseline processor. However, VPC prediction still improves performance of Java applications by 11.1 percent on a less aggressive processor. In fact, all Java applications except xalan experience very close to or more than 10 percent performance improvement with VPC prediction. This is different from what we have seen for C/Cþþ applications on the less aggressive processor: some applications saw very large performance improvements with VPC prediction whereas others saw very small. Thus, we conclude that VPC prediction's performance improvements are very consistent across the Java applications on both aggressive and less aggressive baseline processors.</p><p>7.6 Effect of VPC Prediction on Power and Energy Consumption of Java Applications Fig. <ref type="figure" target="#fig_0">18</ref> shows the impact of VPC prediction and TTC/ cascaded predictors of different sizes on maximum processor power, overall energy consumption, energydelay product of the processor, and the energy consumption of the branch prediction logic. On average, VPC prediction reduces the overall energy consumption by 22 percent, and energy-delay product (EDP) by 36 percent.</p><p>Similarly to what we observed for C/Cþþ applications in Section 5.4, VPC prediction provides larger reductions in energy consumption on Java applications than the most energy-efficient TTC predictor (12 KB) as well as the most energy-efficient cascaded predictor (11 KB). Moreover, VPC prediction does not significantly increase maximum power consumption (less than 0.1 percent) whereas a 12 KB TTC predictor and an 11 KB cascaded predictor result in, respectively, 2.1 percent and 2.2 percent increase in power consumption due to the extra storage and prediction structures they require. We conclude that VPC prediction is an energy-and power-efficient indirect branch handling     written in object-oriented programming languages and that will make heavy use of polymorphism since these languages were shown to result in significantly more indirect branch mispredictions than traditional C/Fortran-style languages. By making available to indirect branches the rich, accurate, highly optimized, and continuously improving hardware used to predict conditional branches, VPC prediction can serve as an enabler encouraging programmers (especially those concerned with the performance of their code) to use object-oriented programming styles, thereby improving the quality and ease of software development.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Indirect branch mispredictions in Windows applications: (a) MPKI and (b) percent of mispredictions due to indirect branches.</figDesc><graphic url="image-1.png" coords="2,38.45,69.14,489.58,156.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An indirect branch example from GAP.</figDesc><graphic url="image-2.png" coords="3,292.49,69.14,244.83,142.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. High-level conceptual overview of the VPC predictor.</figDesc><graphic url="image-3.png" coords="5,29.45,69.14,244.83,129.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>committed. The detailed VPC training algorithm is shown in Algorithms 2 and 3. Algorithm 2 is used when the VPC prediction was correct and Algorithm 3 is used when the VPC prediction was incorrect. The VPC predictor trains both the BTB and the conditional branch direction predictor for each predicted virtual branch. The key functions of the training algorithm are:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. VPC prediction example: source, assembly, and the corresponding virtual branches.</figDesc><graphic url="image-4.png" coords="6,167.81,69.14,230.93,98.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Language and type of the benchmark (Lang/Type), baseline IPC (BASE IPC), potential IPC improvement with perfect indirect branch prediction (PIBP IPC Á), static number of indirect branches (Static IB), dynamic number of indirect branches (Dyn. IB), indirect branch prediction accuracy (IBP Acc), indirect branch mispredictions per kilo instructions (IB MPKI), conditional branch mispredictions per kilo instructions (CB MPKI). gcc06 is 403.gcc in CPU2006, and gcc is 176.gcc in CPU2000.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Distribution of the number of dynamic targets across executed indirect branches.</figDesc><graphic url="image-9.png" coords="9,32.15,69.14,239.55,118.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Performance impact of different VPC training schemes.</figDesc><graphic url="image-12.png" coords="10,293.57,69.14,242.43,132.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Distribution of the number of (for correct predictions) (MAX_ITER=12).</figDesc><graphic url="image-13.png" coords="10,31.19,69.14,241.47,117.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Distribution of the number of dynamic targets across executed indirect branches in the Java programs.</figDesc><graphic url="image-16.png" coords="13,294.29,619.28,240.99,115.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Performance of VPC prediction on Java applications: (a) IPC improvement and (b) indirect branch MPKI.</figDesc><graphic url="image-18.png" coords="14,39.47,69.14,487.66,152.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Distribution of the number of iterations (for correct predictions) in the Java programs (MAX_ITER¼12).</figDesc><graphic url="image-19.png" coords="14,31.25,621.32,240.99,113.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>7. 5</head><label>5</label><figDesc>Effect of Microarchitecture Parameters on VPC Prediction Performance on Java Applications 7.5.1 Effect of BTB Size</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. VPC prediction versus TTC on less aggressive processor.</figDesc><graphic url="image-20.png" coords="15,292.85,188.30,243.87,132.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Performance of VPC prediction versus cascaded predictor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Performance of VPC prediction versus tagged target cache.</figDesc><graphic url="image-21.png" coords="15,29.81,230.90,243.93,130.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Pipeline flushes and fetched/executed instructions. Fig. 18. Energy/power consumption on Java programs.</figDesc><graphic url="image-24.png" coords="16,293.33,69.14,242.91,135.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 Possible</head><label>1</label><figDesc>VPC Predictor States and Outcomes When Branch in Fig.4bis Predicted 8. It is possible to have more than one virtual branch update the prediction structures by increasing the number of write ports in the BTB and the direction predictor. We do not pursue this option as it would increase the complexity of prediction structures.</figDesc><table><row><cell cols="3">Algorithm 3. VPC training algorithm when the branch target</cell></row><row><cell cols="3">is mispredicted. Inputs: PC, GHR, CORRECT_TARGET</cell></row><row><cell>iter</cell><cell>1</cell></row><row><cell>V PCA</cell><cell>P C</cell></row><row><cell>V GHR</cell><cell>GHR</cell></row><row><cell cols="2">found correct target</cell><cell>F ALSE</cell></row><row><cell cols="3">while ((iter MAX IT ER) and (found correct target ¼</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 2 Baseline</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>TABLE 3</cell></row><row><cell>Processor Configuration</cell><cell>Evaluated C++ Benchmarks that Are Not Included in SPEC</cell></row><row><cell></cell><cell>CPU 2000 or 2006</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 5</head><label>5</label><figDesc>Characteristics of the Evaluated Java Applications (See Table4for Explanation of Abbreviations)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 6</head><label>6</label><figDesc>Effect of Different BTB Sizes in Java Applications</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors thank the anonymous reviewers for their feedback. They also thank Thomas Puzak, Joel Emer, Paul Racunas, John Pieper, Robert Cox, David Tarditi, Veynu Narasiman, Rustam Miftakhutdinov, Jared Stark, Santhosh Srinath, Thomas Moscibroda, Bradford Beckmann, and the other members of the HPS research group for their comments and suggestions. They gratefully acknowledge the support of the Cockrell Foundation, Intel Corporation, Microsoft Research, and the Advanced Technology Program of the Texas Higher Education Coordinating Board. This paper is an extended version of <ref type="bibr" target="#b35">[35]</ref>.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>technique that provides significant performance improvements in object-oriented Java applications without significantly increasing the energy consumption or complexity of the processor front end.</p><p>To provide more insight into the reduction in energy consumption and EDP, Fig. <ref type="figure">19</ref> shows the percentage change in pipeline flushes, fetched instructions, and executed instructions due to VPC prediction and TTC/cascaded predictors. VPC prediction reduces the number of pipeline flushes by 30.1 percent, which results in a 47 percent reduction in the number of fetched instructions and a 23.4 percent reduction in the number of executed instructions. Hence, VPC prediction reduces energy consumption significantly due to the large reduction in the number of fetched/executed instructions. Note that even though a 12 KB TTC predictor provides a larger reduction in pipeline flushes, it is less energy efficient than the VPC predictor due to the significant extra hardware it requires.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">OTHER RELATED WORK</head><p>We have already discussed related work on indirect branch prediction in Section 2.2. <ref type="bibr" target="#b35">[35]</ref>, and Sections 5, 6, and 7 provide extensive comparisons of VPC prediction with three of the previously proposed indirect branch predictors, finding that VPC prediction, without requiring significant hardware, provides the performance benefits provided by other predictors of much larger size. Here, we briefly discuss other related work in handling indirect branches.</p><p>We <ref type="bibr" target="#b31">[31]</ref>, <ref type="bibr" target="#b30">[30]</ref> recently proposed handling hard-to-predict indirect branches using dynamic predication <ref type="bibr" target="#b36">[36]</ref>. In this technique, if the target address of an indirect branch is found to be hard to predict, the processor selects two (or more) likely targets and follows the control-flow paths after all of the targets by dynamically predicating the instructions on each path. When the indirect branch is resolved, instructions on the control-flow paths corresponding to the incorrect targets turn into NOPs. Unlike VPC prediction, dynamic predication of indirect branches requires compiler support, new instructions in the instruction set architecture, and significant hardware support for dynamic predication (as described in <ref type="bibr" target="#b36">[36]</ref>). However, the two approaches can be combined and used together: dynamic predication can be a promising approach to reduce the performance impact of indirect branches that are hard to predict with VPC prediction.</p><p>Roth et al. <ref type="bibr" target="#b46">[46]</ref> proposed dependence-based precomputation, which precomputes targets for future virtual function calls as soon as an object reference is created. This technique avoids a misprediction if the result of the computation is correct and ready to be used when the future instance of the virtual function call is fetched. However, it requires a dedicated and costly precomputation engine. In contrast, VPC prediction has two advantages: 1) it does not require any pre-computation logic and 2) it is generally applicable to any indirect branch rather than only for virtual function calls.</p><p>Pure software approaches have been proposed specifically for mitigating the performance impact due to virtual function calls. These approaches include the method cache in Smalltalk-80 <ref type="bibr" target="#b10">[11]</ref>, polymorphic inline caches <ref type="bibr" target="#b23">[23]</ref>, and type feedback/devirtualization <ref type="bibr" target="#b24">[24]</ref>, <ref type="bibr" target="#b28">[28]</ref>. As we show in Section 6, the benefit of devirtualization is limited by its lack of adaptivity. We compare and contrast VPC prediction with compiler-based devirtualization extensively in Section 6.</p><p>Finally, Ertl and Gregg <ref type="bibr" target="#b14">[15]</ref> proposed code replication and superinstructions to improve indirect branch prediction accuracy on virtual machine interpreters. In contrast to this scheme, VPC prediction is not specific to any platform and is applicable to any indirect branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>This paper proposed and evaluated the VPC prediction paradigm. The key idea of VPC prediction is to treat an indirect branch instruction as multiple "virtual" conditional branch instructions for prediction purposes in the microarchitecture. As such, VPC prediction enables the use of existing conditional branch prediction structures to predict the targets of indirect branches without requiring any extra structures specialized for storing indirect branch targets. Our evaluation shows that VPC prediction, without requiring complicated structures, achieves the performance provided by other indirect branch predictors that require significant extra storage and complexity. On a set of indirect branch intensive C/Cþþ applications and modern object-oriented Java applications, VPC prediction, respectively, provides 26.7 percent and 21.9 percent performance improvement, while also reducing energy consumption significantly.</p><p>We believe the performance impact of VPC prediction will further increase in future applications that will be . For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">AMD Athlon( TM ) XP Processor Model 10 Data Sheet</title>
				<imprint>
			<publisher>Advanced Micro Devices, Inc</publisher>
			<date type="published" when="2003-02">Feb. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Software Optimization Guide for AMD Family 10h Processors</title>
		<imprint>
			<date type="published" when="2008-04">Apr. 2008</date>
			<publisher>Advanced Micro Devices, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Framework for Instruction-Level Tracing and Analysis of Programs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhansali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Drinic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mihocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second Int&apos;l Conf. Virtual Execution Environments (VEE &apos;06)</title>
				<meeting>Second Int&apos;l Conf. Virtual Execution Environments (VEE &apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bentzur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Guyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hosking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jump</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E B</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Phansalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stefanovi C</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vandrunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dincklage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiedermann</surname></persName>
		</author>
		<title level="m">Proc. 21st Ann. ACM SIGPLAN Conf. on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA &apos;06)</title>
				<meeting>21st Ann. ACM SIGPLAN Conf. on Object-Oriented Programming Systems, Languages, and Applications (OOPSLA &apos;06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>The DaCapo Benchmarks: Java Benchmarking Development and Analysis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wattch: A Framework for Architectural-Level Power Analysis and Optimizations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;00)</title>
				<meeting>27th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;00)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reducing Indirect Function Call Overhead in C++ Programs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st ACM SIGPLAN-SIGACT Symp. Principles of Programming Languages (POPL &apos;94)</title>
				<meeting>21st ACM SIGPLAN-SIGACT Symp. Principles of Programming Languages (POPL &apos;94)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Quantifying Behavioral Differences between C and C++ Programs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Programming Languages</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="351" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On Understanding Types, Data Abstraction, and Polymorphism</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cardelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wegner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="523" />
			<date type="published" when="1985-12">Dec. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving Branch Prediction Accuracy by Reducing Pattern History Table Interference</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Parallel Architectures and Compilation Techniques (PACT &apos;96)</title>
				<meeting>Conf. Parallel Architectures and Compilation Techniques (PACT &apos;96)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Target Prediction for Indirect Jumps</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;24)</title>
				<meeting>24th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;24)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient Implementation of the Smalltalk-80 System</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Schiffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Symp. Principles of Programming Languages (POPL &apos;84)</title>
				<meeting>Symp. Principles of Programming Languages (POPL &apos;84)</meeting>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate Indirect Branch Prediction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Driesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ho ¨lzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;98)</title>
				<meeting>25th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;98)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Cascaded Predictor: Economical and Adaptive Branch Target Prediction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Driesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ho ¨lzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Ann. ACM/ IEEE Int&apos;l Symp. Microarchitecture (MICRO &apos;31)</title>
				<meeting>31st Ann. ACM/ IEEE Int&apos;l Symp. Microarchitecture (MICRO &apos;31)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-Stage Cascaded Prediction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Driesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ho ¨lzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Parallel Processing</title>
				<meeting>European Conf. Parallel essing</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing Indirect Branch Prediction Accuracy in Virtual Machine Interpreters</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ertl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gregg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Programming Language Design and Implementation (PLDI &apos;03)</title>
				<meeting>Conf. Programming Language Design and Implementation (PLDI &apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An Analysis of Correlation and Predictability: What Makes Two-Level Branch Predictors Work</title>
		<author>
			<persName><forename type="first">M</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Chappell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;25)</title>
				<meeting>25th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;25)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><surname>The</surname></persName>
		</author>
		<author>
			<persName><surname>Group</surname></persName>
		</author>
		<ptr target="http://www.gap-system.org/" />
		<title level="m">GAP System for Computational Discrete Algebra</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Measurement and Application of Dynamic Receiver Class Distributions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chambers</surname></persName>
		</author>
		<idno>UW-CS 94-03-05</idno>
		<imprint>
			<date type="published" when="1994-03">Mar. 1994</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Washington</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<idno>GCC-4.0</idno>
		<ptr target="http://gcc.gnu.org/" />
		<title level="m">GNU Compiler Collection</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Gochman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Anati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berkovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kurts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Valentine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Intel Pentium M Processor: Microarchitecture and Performance</title>
				<imprint>
			<date type="published" when="2003-05">May 2003</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Profile-Guided Receiver Class Prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Tenth Ann. Conf. Object-Oriented Programming Systems, Languages, and Applications (OOPSLA &apos;95)</title>
				<meeting>Tenth Ann. Conf. Object-Oriented Programming Systems, Languages, and Applications (OOPSLA &apos;95)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Upton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carmean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kyker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roussel</surname></persName>
		</author>
		<title level="m">The Microarchitecture of the Pentium 4</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><surname>Processor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intel Technology J</title>
		<imprint>
			<date type="published" when="2001-02">Feb. 2001, Q1 2001 Issue</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimizing Dynamically-Typed Object-Oriented Languages with Polymorphic Inline Caches</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ho ¨lzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Object-Oriented Programming (ECOOP &apos;91)</title>
				<meeting>European Conf. Object-Oriented Programming (ECOOP &apos;91)</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimizing Dynamically-Dispatched Calls with Run-Time Type Feedback</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGPLAN Conf. Programming Language Design and Implementation (PLDI &apos;94)</title>
				<meeting>ACM SIGPLAN Conf. Programming Language Design and Implementation (PLDI &apos;94)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<ptr target="http://www.intel.com/cd/software/products/asmo-na/eng/compilers/284264.htm" />
		<title level="m">ICC 9.1 for Linux</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<ptr target="http://processorfinder.intel.com/Details.aspx?sSpec=SL8VT" />
		<title level="m">Intel Core Duo Processor T2500</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<ptr target="http://www.intel.com/vtune/" />
		<title level="m">Intel VTune Performance Analyzers</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Study of Devirtualization Techniques for a Java Just In-Time Compiler</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ishizaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawahito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yasue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Komatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th ACM SIGPLAN Conf. Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA &apos;00)</title>
				<meeting>15th ACM SIGPLAN Conf. Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA &apos;00)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic Branch Prediction with Perceptrons</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jime</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Seventh Int&apos;l Symp. High Performance Computer Architecture (HPCA &apos;00)</title>
				<meeting>Seventh Int&apos;l Symp. High Performance Computer Architecture (HPCA &apos;00)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving the Performance of Object-Oriented Languages with Dynamic Predication of Indirect Jumps</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Int&apos;l Conf. Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;08)</title>
				<meeting>13th Int&apos;l Conf. Architectural Support for Programming Languages and Operating Systems (ASPLOS &apos;08)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic Predication of Indirect Jumps</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Branch History Table Predictions of Moving Target Branches due to Subroutine Returns</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Emma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;91)</title>
				<meeting>18th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;91)</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Predicting Indirect Branches via Data Compression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kalamatianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Ann. ACM/IEEE Int&apos;l Symp. Microarchitecture (MICRO &apos;98)</title>
				<meeting>31st Ann. ACM/IEEE Int&apos;l Symp. Microarchitecture (MICRO &apos;98)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Alpha 21264 Microprocessor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="1999-04">Mar./Apr. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">VPC Prediction: Reducing the Cost of Indirect Branches via Hardware-Based Dynamic Devirtualization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 34th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;07)</title>
				<meeting>34th Ann. Int&apos;l Symp. Computer Architecture (ISCA &apos;07)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Diverge-Merge Processor (DMP): Dynamic Predicated Execution of Complex Control-Flow Graphs Based on Frequently Executed Paths</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
				<meeting>null</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>39th Ann. Microarchitecture (MICRO &apos;06</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Branch Prediction Strategies and Branch Target Buffer Design</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1984-01">Jan. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pin: Building Customized Program Analysis Tools with Dynamic Instrumentation</title>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Programming Language Design and Implementation (PLDI &apos;05)</title>
				<meeting>Programming Language Design and Implementation (PLDI &apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simics: A Full System Simulation Platform</title>
		<author>
			<persName><forename type="first">P</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christensson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eskilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hallberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hogberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moestedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Werner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2002-02">Feb. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Microprocessor with Branch Target Address Cache Update Queue</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>US patent 7,165,168</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Combining Branch Predictors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcfarling</surname></persName>
		</author>
		<idno>TN-36</idno>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
		<respStmt>
			<orgName>Digital Western Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<ptr target="http://research.microsoft.com/act/" />
		<title level="m">Bartok Compiler</title>
				<imprint>
			<publisher>Microsoft Research</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Digging into Interface Calls in the .NET Framework: Stub-Based Dispatch</title>
		<author>
			<persName><forename type="first">V</forename><surname>Morrison</surname></persName>
		</author>
		<ptr target="http://blogs.msdn.com/vancem/archive/2006/03/13/550529.aspx" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Novillo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
	<note>Personal communication</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pinpointing Representative Portions of Large Intel Itanium Programs with Dynamic Instrumentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Charney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karunanidhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
				<meeting>null</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>37th Ann. Microarchitecture (MICRO &apos;04</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improving Virtual Function Call Target Prediction via Dependence-Based Pre-Computation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Supercomputing (ICS &apos;99)</title>
				<meeting>Int&apos;l Conf. Supercomputing (ICS &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A Case for (Partially) Tagged Geometric History Length Branch Prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Instruction-Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2006-02">Feb. 2006</date>
		</imprint>
	</monogr>
	<note>JILP)</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Tarditi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
	<note>Personal communication</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sinharoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-10">Oct. 2001</date>
		</imprint>
	</monogr>
	<note>POWER4 System Microarchitecture,&quot; IBM Technical White Paper</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Wolczko</surname></persName>
		</author>
		<ptr target="http://research.sun.com/people/mario/java_benchmarking/richards/richards.html" />
		<title level="m">Benchmarking Java with the Richards Benchmark</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Increasing the Instruction Fetch Rate via Multiple Branch Prediction and Branch Address Cache</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Seventh Int&apos;l Conf. Supercomputing (ICS &apos;93)</title>
				<meeting>Seventh Int&apos;l Conf. Supercomputing (ICS &apos;93)</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
