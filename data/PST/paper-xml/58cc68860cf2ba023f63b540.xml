<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Guided Image Filtering Using Nonconvex Potentials</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Bumsub</forename><surname>Ham</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minsu</forename><forename type="middle">•</forename><surname>Cho</surname></persName>
							<email>mscho@postech.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Bumsub Ham is with</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Jean</forename><surname>Ponce</surname></persName>
							<email>jean.ponce@ens.fr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="laboratory">Bumsub Ham is with</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<settlement>Pohang</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">École Normale Supérieure / PSL Research University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">UMR 8548)</orgName>
								<orgName type="institution">CNRS/ENS</orgName>
								<address>
									<settlement>Paris</settlement>
									<country>INRIA, France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Guided Image Filtering Using Nonconvex Potentials</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1D51E162A05432ADB798B0915CA08B34</idno>
					<idno type="DOI">10.1109/TPAMI.2017.2669034</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2017.2669034, IEEE Transactions on Pattern Analysis and Machine Intelligence SUBMISSION TO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, 2016 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Guided image filtering</term>
					<term>joint image filtering</term>
					<term>nonconvex optimization</term>
					<term>majorize-minimization algorithm Joint image filtering Dynamic guidance Static guidance SD filtering Dynamic guidance filtering Static guidance filtering Input image</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Filtering images using a guidance signal, a process called guided or joint image filtering, has been used in various tasks in computer vision and computational photography, particularly for noise reduction and joint upsampling. This uses an additional guidance signal as a structure prior, and transfers the structure of the guidance signal to an input image, restoring noisy or altered image structure. The main drawbacks of such a data-dependent framework are that it does not consider structural differences between guidance and input images, and that it is not robust to outliers. We propose a novel SD (for static/dynamic) filter to address these problems in a unified framework, and jointly leverage structural information from guidance and input images. Guided image filtering is formulated as a nonconvex optimization problem, which is solved by the majorize-minimization algorithm. The proposed algorithm converges quickly while guaranteeing a local minimum. The SD filter effectively controls the underlying image structure at different scales, and can handle a variety of types of data from different sensors. It is robust to outliers and other artifacts such as gradient reversal and global intensity shift, and has good edge-preserving smoothing properties. We demonstrate the flexibility and effectiveness of the proposed SD filter in a variety of applications, including depth upsampling, scale-space filtering, texture removal, flash/non-flash denoising, and RGB/NIR denoising.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>M ANY tasks in computer vision and computational photog- raphy can be formulated as ill-posed inverse problems, and thus theoretically and practically require filtering and regularization to obtain a smoothly varying solution and/or ensure stability <ref type="bibr" target="#b0">[1]</ref>. Image filtering is used to suppress noise and/or extract structural information in many applications such as image restoration, boundary detection, and feature extraction. In this setting, an image is convolved with a spatially invariant or variant kernel. Linear translation invariant (LTI) filtering uses spatially invariant kernels such as Gaussian and Laplacian ones. Spatially invariant kernels enable an efficient filtering process, but do not consider the image content, smoothing or enhancing both noise and image structure evenly.</p><p>Recent work on joint image filtering (or guided image filtering) <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> uses an additional guidance image to construct a spatially variant kernel. The basic idea is that the structural information of the guidance image can be transferred to an input image, e.g., for preserving salient features such as corners and boundaries while suppressing noise. This provides a new perspective on the filtering process, with a great variety of applications including stereo correspondence <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, optical flow <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, semantic flow <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, joint upsampling <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, dehazing <ref type="bibr" target="#b1">[2]</ref>, noise reduction <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b12">[13]</ref>, and texture removal <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>.</p><p>Joint image filtering has been used with either static or dynamic guidance images. Static guidance filtering (e.g., <ref type="bibr" target="#b1">[2]</ref>) modulates the input image with a weight function depending only on features of the guidance image, as in the blue box of Fig. <ref type="figure">1</ref>.</p><p>Fig. <ref type="figure">1</ref>. SD filtering for depth upsampling: Static guidance filtering convolves an input image (a low-resolution depth image) with a weight function computed from a fixed guidance signal (a high-resolution color image), as in the blue box. Dynamic guidance filtering uses weight functions that are repeatedly obtained from filtered input images, as in the red box. We have observed that static and dynamic guidance complement each other, and exploiting only one of them is problematic, especially in the case of data from different sensors (e.g., depth and color images). The SD filter takes advantage of both, and addresses the problems of current joint image filtering. (Best viewed in colour.)</p><p>This guidance signal is fixed during the optimization. It can reflect internal properties of the input image itself, e.g., its gradients <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b16">[17]</ref>, or be another signal aligned with the input image, e.g., a near infrared (NIR) image <ref type="bibr" target="#b3">[4]</ref>. This approach assumes the structure of the input and guidance images to be consistent with each other, and does not consider structural (or statistical) dependencies and inconsistencies between them. This is problematic, especially in the case of data from different sensors (e.g., depth and color images). Dynamic guidance filtering (e.g., <ref type="bibr" target="#b15">[16]</ref>) uses weight functions that are repeatedly obtained from filtered input images, as in the red box of Fig. <ref type="figure">1</ref>. It is assumed that the weight between neighboring pixels can be determined more accurately from the filtered input image than from the initial one itself <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>. This method is inherently iterative, and the dynamic guidance signal (the filtered input image, i.e., a potential output image) is updated at every step until convergence. Dynamic guidance filtering takes into account the properties of the input image, but ignores the additional information available in the static guidance image, which can be used to impose image structures lost in the input data, e.g., in joint upsampling <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>.</p><p>We present in this paper a unified framework for joint image filtering taking advantage of both static and dynamic guidance, called the SD filter (Fig. <ref type="figure">1</ref>). We address the aforementioned problems by adaptively fusing data from the static and dynamic guidance signals, rather than unilaterally transferring the structure of the guidance image to the input one. To this end, we combine static guidance image weighting with a nonconvex penalty on the gradients of dynamic guidance, which makes joint image filtering robust to outliers. The SD filter has several advantages over current joint image filters: First, it effectively controls image structures at different scales, and can handle a variety of types of data from different sensors. Second, it has good edge-preserving properties, and is robust to artifacts, such as gradient reversal and global intensity shift <ref type="bibr" target="#b1">[2]</ref>.</p><p>Contributions. The main contributions of this paper can be summarized as follows:</p><p>• We formulate joint image filtering as a nonconvex optimization problem, where Welsch's function <ref type="bibr" target="#b18">[19]</ref> (or correntropy <ref type="bibr" target="#b19">[20]</ref>) is used for a nonconvex regularizer. We solve this problem by the majorize-minimization algorithm, and propose to use an l 1 regularizer to compute an initial solution of our solver, which accelerates the convergence speed (Section 3).</p><p>• We analyze several properties of the SD filter including scale adjustment, runtime, filtering behavior, and its connection to other filters (Section 4). • We demonstrate the flexibility and effectiveness of the SD filter in several computer vision and computational photography applications including depth upsampling, scale-space filtering, texture removal, flash/non-flash denoising, and RGB/NIR denoising (Section 5).</p><p>A preliminary version of this work appeared in <ref type="bibr" target="#b20">[21]</ref>. This version adds (1) an in-depth presentation of the SD filter; (2) a discussion on its connection to other filtering methods; (3) an analysis of runtime; (4) an extensive experimental evaluation and comparison of the SD filter with several state-of-the-art methods; and (5) an evaluation on the localization accuracy of depth edges for depth upsampling. To encourage comparison and future work, the source code of the SD filter is available at our project webpage: http://www.di.ens.fr/willow/research/sdfilter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Image filtering and joint image filtering</head><p>Joint image filters can be derived from minimizing an objective function that usually involves a fidelity term (e.g., <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b21">[22]</ref>), a prior smoothness (regularization) term (e.g., <ref type="bibr" target="#b16">[17]</ref>), or both (e,g., <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>). Regularization is implicitly imposed on the objective function with the fidelity term only. The smoothness term encodes an explicit regularization process into the objective function. We further categorize joint image filtering (static or dynamic guidance filtering) into implicit and explicit regularization methods. The SD filter belongs to the explicit regularization that takes advantage of both static and dynamic guidance.</p><p>Implicit regularization stems from a local filtering framework. The input image is filtered using a weight function that depends on the similarity of features within a local window in the guidance image <ref type="bibr" target="#b2">[3]</ref>, allowing the structure of the guidance image to be transferred to the input image. The bilateral filter (BF) <ref type="bibr" target="#b21">[22]</ref>, guided filter (GF) <ref type="bibr" target="#b1">[2]</ref>, weighted median filter (WMF) <ref type="bibr" target="#b10">[11]</ref>, and weighted mode filter (WModF) <ref type="bibr" target="#b24">[25]</ref> are well-known implicit regularization methods, and they have been successfully adapted to static guidance filtering. They regularize images through a weighted averaging process <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b21">[22]</ref>, a weighted median process <ref type="bibr" target="#b10">[11]</ref>, or a weighted mode process <ref type="bibr" target="#b24">[25]</ref>. Two representative filtering methods using dynamic guidance are iterative nonlocal means (INM) <ref type="bibr" target="#b17">[18]</ref> and the rolling-guidance filter (RGF) <ref type="bibr" target="#b15">[16]</ref>. These methods share the same filtering framework, but differ in that INM aims at preserving textures during noise reduction, while RGF aims at removing them through scale-space filtering. The implicit regularization involved is simple and easy to implement, but it has some drawbacks. For example, it has difficulties handling sparse input data (e.g., in image colorization <ref type="bibr" target="#b25">[26]</ref>), and often introduces artifacts (e.g., halos and gradient reversal <ref type="bibr" target="#b1">[2]</ref>) due to its local nature. Accordingly, implicit regularization has mainly been applied in highly controlled conditions, and is typically used as pre-and/or post-processing for further applications <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b26">[27]</ref>.</p><p>An alternative approach is to explicitly encode the regularization process into the objective function, while taking advantage of the guidance image. The weighted least-squares (WLS) framework <ref type="bibr" target="#b22">[23]</ref> is the most popular explicit regularization method in static guidance filtering <ref type="bibr" target="#b11">[12]</ref>. The objective function typically consists of two parts: A fidelity term captures the consistency between input and output images, and a regularization term, modeled using a weighted l 2 norm <ref type="bibr" target="#b22">[23]</ref>, encourages the output image to have a similar structure to the guidance one. Many other regularization terms, e.g., l 1 norm in total generalized variation (TGV) <ref type="bibr" target="#b9">[10]</ref>, l 0 norm in l 0 norm minimization <ref type="bibr" target="#b23">[24]</ref>, or relative total variation (RTV) <ref type="bibr" target="#b14">[15]</ref>, have also been employed, so that the filtered image is forced to have statistical properties similar to those of the desired solution. Anisotropic diffusion (AD) <ref type="bibr" target="#b16">[17]</ref> is an explicit regularization framework using dynamic guidance. In contrast to INM <ref type="bibr" target="#b17">[18]</ref> and RGF <ref type="bibr" target="#b15">[16]</ref>, AD updates both input and guidance images at every step. Filtering is performed iteratively with the filtered input and updated guidance images. This explicit regularization enables formulating a task-specific model, with more flexibility than implicit regularization. Furthermore, it overcomes several limitations of implicit regularization, such as halos and gradient reversal for example, at the cost of global intensity shift <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b22">[23]</ref>.</p><p>Existing image filtering methods typically apply to a limited range of applications and suffer from various artifacts: For example, RGF is applicable to scale-space filtering only, and suffers from poor edge localization <ref type="bibr" target="#b15">[16]</ref>. In contrast, our approach provides a unified model for many applications, gracefully handles most artifacts, and outperforms the state of the art in all the applications considered in the paper. Although the proposed model is superficially similar to WLS <ref type="bibr" target="#b22">[23]</ref> and RGF <ref type="bibr" target="#b15">[16]</ref>, our nonconvex objective function requires a different solver, which gives theoretical reasoning for RGF. Our model is also related to a diffusion-reaction equation <ref type="bibr" target="#b27">[28]</ref>, the steady-state solution of which has a similar form to the SD filter. However, the SD filter has an additional weight function using static guidance, as described (e) Our model. Fig. <ref type="figure">2</ref>. Comparison of static and dynamic guidance filtering methods. Given (a) a high-resolution color image, (b) a low-resolution depth image is upsampled (×8) by our model in (1) using (c) static guidance only (e.g., <ref type="bibr" target="#b22">[23]</ref>), (d) dynamic guidance only (e.g., <ref type="bibr" target="#b15">[16]</ref>), and (e) joint static and dynamic guidance. Static guidance filtering restores smoothed depth edges, as in the red boxes of (c). However, this method transfers all the structural information of the color image to the depth image, such as the weak color edges between the board and background and the color stripes on the tablecloth in the blue boxes of (c). Dynamic guidance filtering avoids this problem, as in the blue boxes of (d), but this method does not use the structural information of the high-resolution color image, smoothing or even eliminating depth edges as in the red boxes of (d). The SD filter jointly uses the structure of color and depth images, and does not suffer from these problems as in the blue and red boxes of (e). See Section 5.1 for details. (Best viewed in colour.) in Section 4.4 in detail. While Badri et al. <ref type="bibr" target="#b28">[29]</ref> used a similar nonconvex objective function for image smoothing, our model provides a more generalized objective for joint image filtering. Shen et al. <ref type="bibr" target="#b29">[30]</ref> used the common structure in input and guidance images, but the local filtering formulation of the filter introduces halo artifacts and limits the applicability. The closest work to ours is a recently introduced a learning-based joint filter <ref type="bibr" target="#b30">[31]</ref> using convolutional neural networks (CNNs). This deep joint filter considers the structures of both input and guidance images, but requires a large number of annotated images for training the deep model for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Joint image filtering for high-level vision</head><p>Joint image filtering has shown great success in low-level vision tasks, but little attention has been paid to applying it to highlevel vision problems. Motivated by the fact that contrast-sensitive potentials <ref type="bibr" target="#b31">[32]</ref> typically used in conditional random fields (CRFs) have a similar role to static guidance image weighting (e.g., see <ref type="bibr" target="#b4">(5)</ref> in <ref type="bibr" target="#b31">[32]</ref>), Krähenbühl and Koltun <ref type="bibr" target="#b32">[33]</ref> used joint image filtering for an efficient message passing scheme, enabling an approximate inference algorithm for fully connected CRF models. In a similar manner that joint image filtering is used for many applications (e.g., joint upsampling), the CRF model has been widely used to refine low-resolution CNN outputs, e.g., in semantic segmentation <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. Recent works <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref> learn parameters of both a joint image filter and a CNN model in an end-to-end manner to upsample low-resolution network outputs. As in existing joint image filters, however, the refinement methods use the structure of high-resolution color images (static guidance) only, while ignoring additional information available in the CNN outputs. We believe that using the SD filter will improve the refinement by considering the structures of both inputs and outputs of the CNN in the endto-end learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation and problem statement</head><p>There are pros and cons in filtering images under static or dynamic guidance. Let us take the example of depth upsampling in Fig. <ref type="figure">2</ref>, where a high-resolution color image (the guidance image) in (a) is used to upsample (×8) an input low-resolution depth image in (b). Static guidance filtering reconstructs destroyed depth edges using the color image with high signal-to-noise ratio (SNR) <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b9">[10]</ref>, as in the red boxes of (c). However, this approach does not handle differences in structure between depth and color images, transferring all the structural information of the color image to the depth image, as in the blue boxes of (c). For regions of highcontrast in the color image, the depth image is altered according to the texture pattern, resulting in texture-copying artifacts <ref type="bibr" target="#b37">[38]</ref>. Similarly, depth edges are smoothed in low-contrast regions on the color image (e.g., weak color edges), causing jagged artifacts in scene reconstruction <ref type="bibr" target="#b38">[39]</ref>. Dynamic guidance filtering utilizes the content of the depth image 1 , avoiding the drawbacks of static guidance filtering, as in the blue boxes of (d). The depth edges are preserved, and unwanted structures are not transferred, but dynamic guidance does not take full advantage of the abundant structural information in the color image. Thus, depth edges are smoothed, and even eliminated for regions of low-contrast in the depth image, as in the red boxes of (d).</p><p>This example illustrates the fact that static and dynamic guidance complement each other, and exploiting only one of them is not sufficient to infer high-quality structural information from the input image. This problem becomes even worse when input and guidance images come from different data with different statistical characteristics. The SD filter proposed in this paper jointly leverages the structure of static (color) and dynamic (depth) guidance, taking advantage of both, as shown in (e).</p><p>1. Dynamic guidance is initialized with the interpolated depth image using static guidance as shown in Fig. <ref type="figure">2(c)</ref>, not with the low-resolution depth image itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model</head><p>Given the input image f , the static guidance g, and the output image u (dynamic guidance), we denote by f i , g i , and u i the corresponding image values at pixel i, with i ranging over the image domain I ⊂ N 2 . Our objective is to infer the structure of the input image by jointly using static and dynamic guidance, and to make joint image filtering robust to outliers in a unified framework. The influence of the guidance images on the input image varies spatially, and is controlled by weight functions that measure the similarity between adjacent pixels in the guidance images. Various features (e.g., spatial location, intensity, and texture <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b39">[40]</ref>) and metrics (e.g., Euclidian and geodesic distances <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b22">[23]</ref>) can be used to represent distinctive characteristics of pixels on images and measure their similarities.</p><p>We minimize an objective function of the form:</p><formula xml:id="formula_0">E(u) = i c i (u i -f i ) 2 + λΩ(u, g),<label>(1)</label></formula><p>which consists of fidelity and regularization terms, balanced by the regularization parameter λ. The first (fidelity) term helps the solution u to harmonize well with the input image f with confidence c i ≥ 0. The regularization term makes the solution u smooth while preserving salient features (e.g., boundaries). We propose the following regularizer:</p><formula xml:id="formula_1">Ω(u, g) = i,j∈N φ µ (g i -g j )ψ ν (u i -u j ),<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">ψ ν (x) = (1 -φ ν (x))/ν,<label>(3) and φ</label></formula><formula xml:id="formula_3">(x) = exp(-x 2 ).<label>(4)</label></formula><p>Here, µ and ν control the smoothness bandwidth, and N is the set of image adjacencies, defined in our implementation on a local 8-neighborhood system. The first term, φ µ in the regularizer is a weight function using intensity difference between adjacent pixels in the guidance g. This function approaches to zero as the gradient of the guidance g becomes larger (e.g., at the discontinuities of g), preventing smoothing the output image u in those regions. That is, the weight function φ µ transfers image structures from the static guidance g to the output image u. The second one ψ ν , called Welsch's function <ref type="bibr" target="#b18">[19]</ref>, regularizes the output image u, and makes joint filtering robust to outliers, due to its nonconvex shape and the fact that it saturates at 1 (Fig. <ref type="figure">4</ref>). Note that convex potentials in existing joint image filters regularize the structure of the output image u and bring the structure through static guidance image weighting φ µ . In contrast, the nonconvex potential ψ ν penalizes large gradients of the output image u (dynamic guidance) less than a convex one during filtering <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, and preserves features having high-frequency structures (e.g., edges and corners) better. This means the use of nonconvex potentials relax the strict dependence of the existing joint image filters on the static guidance g, and allows to leverage the structure of the dynamic guidance u as well. Accordingly, by combining static guidance image weighting φ µ with the nonconvex penalty ψ ν on the gradients of the dynamic guidance u, the SD filter adaptively fuses data from the static and dynamic guidances. This effectively reflects structural differences between guidance and input images, and makes joint image filtering robust to outliers. Although nonconvex potentials preserve some noise, the static guidance g with high SNR in our model alleviates this problem. Note that in order to</p><formula xml:id="formula_4">E(u) Q k (u) u k u k+1 Fig. 3. Sketch of the majorize-minimization algorithm. At step k, a surrogate function Q k is constructed given some estimate u k of the minimum of E, such that Q k (u k ) = E(u k ) and Q k (u) ≥ E(u). At step k + 1, the next estimate u k+1 is obtained by minimizing Q k . These two steps are repeated until convergence.</formula><p>adaptively fuse data from the static and dynamic guidances, one might attempt to add a weight function φ ν using the dynamic guidance u in the regularizer as follows:</p><formula xml:id="formula_5">Ω(u, g) = i,j φ µ (g i -g j )φ ν (u i -u j )ψ ν (u i -u j ).<label>(5)</label></formula><p>This regularizer, however, is hard to optimize and may be unstable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimization algorithm</head><formula xml:id="formula_6">Let f = [f i ] N ×1 , g = [g i ] N ×1 , and u = [u i ] N ×1 denote</formula><p>vectors representing the input image, static guidance and the output image (or dynamic guidance), respectively, where</p><formula xml:id="formula_7">N = |I| is the size of the images. Let W g = [φ µ (g i -g j )] N ×N , W u = [φ ν (u i -u j )] N ×N , and C = diag ([c 1 , . . . , c N ]</formula><p>). W g and W u denote weight matrices of the 8-neighborhood system for static and dynamic guidances, respectively. We can rewrite our objective function in matrix/vector form as:</p><formula xml:id="formula_8">E(u) = (u -f ) T C (u -f ) + λ ν 1 T (W g -W) 1,<label>(6)</label></formula><p>where W = W g • W u , and • denotes the Hadamard product of the matrices defined as the element-wise multiplication of their elements. 1 is a N × 1 vector, where all the entries are 1. The diagonal entries c i of C are confidence values for the pixels i in the input image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">The majorize-minimization algorithm</head><p>Our objective function is not convex, and thus it is non-trivial to minimize the objective function of <ref type="bibr" target="#b5">(6)</ref>. In this work, we compute a local minimum of ( <ref type="formula" target="#formula_8">6</ref>) by iteratively computing a convex upper bound (surrogate function) and solving the corresponding convex optimization problems. Concretely, we use the majorizeminimization algorithm (Fig. <ref type="figure" target="#fig_1">3</ref>) <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, which guarantees convergence to a local minimum of the nonconvex objective function <ref type="bibr" target="#b45">[46]</ref>. This algorithm consists of two repeated steps: In the majorization step, given some estimate u k of the minimum of</p><formula xml:id="formula_9">E at step k, a convex surrogate function Q k is constructed, such that ∀ u Q k (u k ) = E(u k ) Q k (u) ≥ E(u) .<label>(7)</label></formula><p>In the minimization step, the next estimate u k+1 is then computed by minimizing Q k . These steps are repeated until convergence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Implementation details</head><p>The nonconvexity of our objective function comes from Welsch's function ψ ν . As shown in Appendix A, a convex surrogate function Ψ y ν for ψ ν , such that ∀x, y,</p><formula xml:id="formula_10">Ψ y ν (y) = ψ ν (y) Ψ y ν (x) ≥ ψ ν (x) ,<label>(8)</label></formula><p>is given by</p><formula xml:id="formula_11">Ψ y ν (x) = ψ ν (y) + (x 2 -y 2 )(1 -νψ ν (y)).<label>(9)</label></formula><p>The surrogate function Ψ y ν (x) is an upper bound on ψ ν (x) and coincides with ψ ν (x) only when x is equal to y (Fig. <ref type="figure">4</ref>).</p><p>Majorization step: Let us now use this result to compute the surrogate function Q k for E by substituting ψ ν with Ψ y ν in (2) as follows:</p><formula xml:id="formula_12">Q k (u) = u T C + λL k u -2f T Cu + f T Cf (10) -λu kT L k u k + λ ν 1 T W g -W k 1. L k = D k -W k is a dynamic Laplacian matrix at step k, where W k = W g • W u k and D k = diag d k 1 , . . . , d k N where d k i = N j=1 φ µ (g i -g j )φ ν (u k i -u k j ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minimization step:</head><p>We then obtain the next estimate u k+1 by minimizing the surrogate function Q k w.r.t. u as follows 2 :</p><formula xml:id="formula_13">u k+1 = arg min u Q k (u) = (C + λL k ) -1 Cf . (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>The above iterative scheme decreases the value of E monotonically in each step, i.e.,</p><formula xml:id="formula_15">E(u k+1 ) ≤ Q k (u k+1 ) ≤ Q k (u k ) = E(u k ),<label>(12)</label></formula><p>where the first and the second inequalities follow from ( <ref type="formula" target="#formula_9">7</ref>) and <ref type="bibr" target="#b10">(11)</ref>, respectively, and converges to a local minimum of E <ref type="bibr" target="#b45">[46]</ref>. The static guidance affinity matrix W g is fixed regardless of steps, while the dynamic guidance matrix W u k is iteratively updated. Thus, we jointly use the structure of static and dynamic guidance to compute the solution u. Note that all previous joint image filters (e.g., <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[25]</ref>) except recently proposed ones <ref type="bibr" target="#b29">[30]</ref>,</p><p>2. In case of a color image, the linear system is solved in each channel. <ref type="bibr" target="#b30">[31]</ref> determine the structure of the output image by the weight function of the static guidance image (W g ) only. We overcome this limitation by using an additional weight function of the dynamic guidance image (W u k ) in each round of an intermediate output u k , thus reflecting the structures of both static and dynamic guidance images simultaneously during the optimization process. The majorize-minimization algorithm generalizes other wellknown optimization methods <ref type="bibr" target="#b46">[47]</ref>, e.g., the expectationmaximization (EM) algorithm <ref type="bibr" target="#b47">[48]</ref>, iteratively reweighted leastsquares (IRLS) <ref type="bibr" target="#b48">[49]</ref>, the Weiszfeld's method <ref type="bibr" target="#b49">[50]</ref>, and the halfquadratic (HQ) minimization <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref>. Nikolova and Chan <ref type="bibr" target="#b52">[53]</ref> have shown that the method where the solution of the objective function is computed by iteratively solving linear systems at each step as in our solver is equivalent to the HQ minimization (of multiplicative form). That is, both methods give exactly the same iterations. Thus, our solver gives an identical solution to the HQ minimization (of multiplicative form) for ( <ref type="formula" target="#formula_8">6</ref>), if initializations are the same.</p><p>Algorithm 1 summarizes the optimization procedure.</p><p>Algorithm 1 The SD filter. 1: Input: f (an input image); g (a static guidance image); u 0 (an initial estimate for a dynamic guidance image). 2: Parameters: µ (a bandwidth parameter for g); ν (a bandwidth parameter for u); λ (a regularization parameter); K (the maximum number of steps). Compute an affinity matrix for the dynamic guidance image</p><formula xml:id="formula_16">u k , W u k = φ ν (u k i -u k j ) N ×N . 7:</formula><p>Compute a dynamic Laplacian matrix</p><formula xml:id="formula_17">L k = D k -W k where W k = W g • W u k and D k = diag d k 1 , . . . , d k N where d k i = N j=1 φ µ (g i -g j )φ ν (u k i -u k j ). 8:</formula><p>Update u k+1 by solving (C + λL k )u k+1 = Cf . 9: end for 10: Output: u K (a final estimate).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Initialization</head><p>Our solver finds a local minimum, and thus different initializations for u 0 (dynamic guidance at k = 0) may give different solutions. In this work, we compute the initial estimate u 0 by minimizing the objective function of (1) and using an upper bound on Welsch's function in the regularizer (Fig. <ref type="figure">5</ref>). Two functions are used for initialization. l 2 initialization. Welsch's function is upper bounded by an l 2 regularizer, i.e., ∀x, x 2 ≥ ψ ν (x). This can be easily shown by using the inequality exp(x) ≥ 1 + x. The initial estimate u 0 is computed by minimizing the objective function in <ref type="bibr" target="#b0">(1)</ref> with a weighted l 2 norm as a regularizer, i.e., using the WLS framework <ref type="bibr" target="#b22">[23]</ref>:</p><formula xml:id="formula_18">Ω l2 (u, g) = i,j∈N φ µ (g i -g j )(u i -u j ) 2 . (<label>13</label></formula><formula xml:id="formula_19">)</formula><p>x The l 2 initialization is simple, but may yield a slow convergence rate as illustrated by Fig. <ref type="figure">6(a)</ref>. l 1 initialization. A good initial solution accelerates the convergence of our solver. We propose to use the following regularizer to compute the initial estimate u 0 :</p><formula xml:id="formula_20">Ω l1 (u, g) = i,j∈N φ µ (g i -g j )α|u i -u j |, (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>where α is set to a positive constant, chosen so α|x| is a much tighter upper bound on Welsch's function than the l 2 regularizer, as shown in Fig. <ref type="figure">5</ref>. This regularizer is convex, and thus the global minimum <ref type="foot" target="#foot_0">3</ref> is guaranteed <ref type="bibr" target="#b48">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ANALYSIS</head><p>In this section, we analyze the properties of the SD filter, including runtime and scale adjustment, and illustrate its convergence rate and filtering behavior with different initializations. A connection to other filtering methods is also presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Runtime</head><p>The major computational cost of the SD filter comes from solving the linear system of (11) repeatedly. We use a local 8neighborhood system, resulting in the sparse matrix (C + λL k ). This matrix has a positive diagonal and four sub-diagonals on each side. These sub-diagonals are not adjacent, and their separation is proportional to the image width. It is therefore not banded with a fixed bandwidth. Yet, it is sparse and positive semidefinite, thus (11) can be solved efficiently using sparse Cholesky factorization. We use the CHOLMOD solver <ref type="bibr" target="#b53">[54]</ref> of MATLAB in our implementation. Running k = 5 steps of our algorithm from an l 1 or l 2 initialization takes about 2.5 seconds for an image of size 500 × 300 on a 4.0GHz CPU <ref type="foot" target="#foot_1">4</ref> . The l 1 and l 2 initializations take about 1.2 and 0.4 seconds, respectively, on average for the same image size. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Steps</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sum of Intensity Differences Between Steps</head><formula xml:id="formula_22">u 0 = ul 2 u 0 = ul 1 (b) (c) Input image. (d) u 0 = u l 2 , k = 30.</formula><p>(e) u 0 = u l 1 , k = 7.</p><p>(f) u 0 = u l 1 , k = 30. Fig. <ref type="figure">6</ref>. Examples of (a) energy evolution of (6) and (b) a sum of intensity difference between successive steps (i.e., u ku k+1 1 ), given (c) the input image. Our solver converges in fewer steps with the l 1 initialization (u 0 = u l 1 ) than with the l 2 one (u 0 = u l 2 ), with faster overall speed. In contrast to most filtering methods, it does not give a constant-value image in the steady-state: (d) u 0 = u l 2 , k = 30, (e) u 0 = u l 1 , k = 7, and (f) u 0 = u l 1 , k = 30. In this example, for removing textures, static guidance is set to the Gaussian filtered version (standard deviation, 1) of the input image (λ = 50, µ = 5, ν = 40). See Section 5.2 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Influence of initialization</head><p>As explained earlier, the majorize-minimization algorithm is guaranteed to converge to a local minimum of E in (6) <ref type="bibr" target="#b45">[46]</ref>. In this section, we show the convergence rate of (11) as the step index k increases, and observe its behavior with different initializations, using u l2 and u l1 , the global minima of (1) using Ω l2 and Ω l1 as regularizers, respectively. Figure <ref type="figure">6</ref> shows how (a) the energy E of ( <ref type="formula" target="#formula_8">6</ref>) and (b) the intensity differences (i.e., u ku k+1 1 ) evolve over steps for a sample input image (Fig. <ref type="figure">6(c</ref>)). In this example, our solver converges in fewer steps with the l 1 initialization (u 0 = u l1 ) than with the l 2 one (u 0 = u l2 ), with faster overall speed, despite the overhead of the l 1 minimization: Our solver with the l 2 and l 1 initializations converges in 30 and 7 steps (Fig. <ref type="figure">6(d</ref>) and (e)), taking 45 and 20 seconds (including initialization), respectively. Although our solver with the l 2 initialization converges more slowly, the per-pixel intensity difference still decreases monotonically in (b). Note that after few steps (typically from 5), the solver gives almost the same filtering results. For example, after 5 steps, the average and maximum values of the per-pixel intensity difference are 9.4×10 -5 and 1.7×10 -3 , respectively, with the l 2 initialization, and 4.3×10 -5 and 8.7×10 -4 with the l 1 initialization 5 . It should also be noted that most filtering methods, except the recently proposed RGF <ref type="bibr" target="#b15">[16]</ref>, eventually give a constant-value image, if they are performed repeatedly, regardless of whether the filters have implicit or explicit forms (e.g., BF <ref type="bibr" target="#b21">[22]</ref> and AD <ref type="bibr" target="#b16">[17]</ref>). In contrast, the SD filter does not give such an image no matter how many steps are performed (Fig. <ref type="figure">6</ref>(e) and (f)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Scale adjustment</head><p>There are two approaches to incorporating scale information in image filtering <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b22">[23]</ref>. In implicit regularization methods, an intuitive way to adjust the degree of smoothing is to use an isotropic Gaussian kernel. Due to the spatially invariant properties of the kernel, this approach regularizes both noise and features evenly without considering image structure <ref type="bibr" target="#b16">[17]</ref>. RGF addresses this problem in two phases: Small-scale structures are removed by the Gaussian kernel, and large-scale ones are then recovered <ref type="bibr" target="#b15">[16]</ref>. Since RGF <ref type="bibr" target="#b15">[16]</ref> is based on the Gaussian kernel, it inherits its limitations. This leads to poor edge localization at coarse scales, with rounded corners and shifted boundaries. The regularization parameter is empirically used to adjust scales in explicit regularization methods <ref type="bibr" target="#b22">[23]</ref>. It balances the degree of influence between fidelity and regularization terms in such a way that a large value leads to more regularized results than a small one. Now, we will show how the regularization parameter λ controls scales in the SD filter. It follows from <ref type="bibr" target="#b10">(11)</ref> that</p><formula xml:id="formula_23">(C + λD k )u k+1 -λW k u k+1 = Cf . (<label>15</label></formula><formula xml:id="formula_24">)</formula><p>Let us define diagonal matrices A and A as</p><formula xml:id="formula_25">A = (C + λD k ) -1 C,<label>(16)</label></formula><p>and</p><formula xml:id="formula_26">A = λ(C + λD k ) -1 D k ,<label>(17)</label></formula><p>such that A + A = I. By multiplying the left-and right-hand sides of ( <ref type="formula" target="#formula_23">15</ref>) by (C + λD k ) -1 , we obtain</p><formula xml:id="formula_27">u k+1 = (I -λ(C + λD k ) -1 D k A P k ) -1 (C + λD k ) -1 C A=I-A f<label>(18)</label></formula><p>= A(I -A P k ) -1 f , where P k = (D k ) -1 W k . Note that this gives the exact same form as random walk with restart <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>, except that P k is updated at every step in our case. It has been shown that the restarting probability A controls the extent of smoothing in different scales in the image <ref type="bibr" target="#b55">[56]</ref>. In our case, the regularization parameter λ determines the restarting probability, which shows that by varying this parameter, we can adjust the degree of smoothing.</p><p>5. We normalize the intensity range to [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Connections with other filters</head><p>Let us consider the objective function of ( <ref type="formula" target="#formula_0">1</ref>), but without the regularization term. We can implicitly impose joint regularization on the objective function by introducing a spatial weight function φ s and static guidance weighting φ µ to the fidelity term. The objective function is then</p><formula xml:id="formula_28">E(u) = i j∈η φ s (i -j)φ µ (g i -g j )(u i -f j ) 2 , (<label>19</label></formula><formula xml:id="formula_29">)</formula><p>where s is a spatial bandwidth parameter and η is the local neighborhood of the pixel i. The solution of this objective function can be computed as follows:</p><formula xml:id="formula_30">u k+1 i = j∈η φ s (i -j)φ µ (g i -g j )f j j∈η φ s (i -j)φ µ (g i -g j ) . (<label>20</label></formula><formula xml:id="formula_31">)</formula><p>This becomes equivalent to the joint BF <ref type="bibr" target="#b2">[3]</ref> (or BF <ref type="bibr" target="#b21">[22]</ref> by setting g = f ). By further introducing Welsch's function ψ ν to <ref type="bibr" target="#b18">(19)</ref>, we obtain the following objective function:</p><formula xml:id="formula_32">E(u) = i j∈η φ s (i -j)φ µ (g i -g j )ψ ν (u i -f j ),<label>(21)</label></formula><p>We can compute a local minimum of this objective function by the majorize-minimization algorithm as follows (see Appendix B):</p><formula xml:id="formula_33">u k+1 i = j∈η φ s (i -j)φ µ (g i -g j )φ ν (u k i -f j )f j j∈η φ s (i -j)φ µ (g i -g j )φ ν (u k i -f j ) . (<label>22</label></formula><formula xml:id="formula_34">)</formula><p>This again becomes the joint BF <ref type="bibr" target="#b2">[3]</ref> with φ ν (x) = 1. A variant of RGF <ref type="bibr" target="#b15">[16]</ref> can be derived by setting φ µ (x) = 1.</p><p>Let us now consider the case when f , g, and u are continuous functions over a continuous domain. A continuous form of the objective function of (1) can then be written as <ref type="bibr" target="#b58">[59]</ref>:</p><formula xml:id="formula_35">J c i (u i -f i ) 2 + λφ µ ( ∇g ) ψ ν ( ∇u ) dJ ,<label>(23)</label></formula><p>where J ⊂ R 2 + and ∇ denotes the gradient operator. This function can be minimized via gradient descent using the calculus of variations <ref type="bibr" target="#b58">[59]</ref> as follows:</p><formula xml:id="formula_36">∂u ∂k = c i (u i -f i ) + λdiv [φ µ ( ∇g ) φ ν ( ∇u ) ∇u] ,<label>(24)</label></formula><p>where ∂k and div represent a partial derivative w.r.t. k and the divergence operator, respectively. This is a variant of the diffusionreaction equation <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b27">[28]</ref> with an additional term φ µ ( ∇g ) involving the static guidance g. The result of the SD filter is a steady-state solution of this scheme. Note that while being widely used in image filtering, nonconvex potentials have never been implemented before in the context of joint image filtering to the best of our knowledge. In our approach, nonconvex potentials make joint image filtering robust to outliers by effectively exploiting structural information from both guidance and input images. If one uses <ref type="bibr" target="#b23">(24)</ref> with φ ν (x) = 1 (i.e., without dynamic guidance), the steady-state solution of (24) can be found in closed form, and is exactly same as the result obtained by the WLS framework <ref type="bibr" target="#b22">[23]</ref>. With φ µ (x) = 1 (i.e., without static guidance), the steady-state solution of ( <ref type="formula" target="#formula_36">24</ref>) is found by solving the following equation <ref type="bibr" target="#b27">[28]</ref>:</p><formula xml:id="formula_37">0 = c i (u i -f i ) + λ∇ • [φ ν ( ∇u ) ∇u] .<label>(25)</label></formula><p>In this case, the solution cannot be computed in closed form, but it can be obtained by repeatedly solving <ref type="bibr" target="#b10">(11)</ref> with</p><formula xml:id="formula_38">W k = W u k .</formula><p>This corresponds to a variant of RGF <ref type="bibr" target="#b15">[16]</ref> with the fidelity term. (a) Middlebury dataset <ref type="bibr" target="#b59">[60]</ref>.  Average PBP (δ = 1) on the Middlebury dataset <ref type="bibr" target="#b59">[60]</ref> with varying the regularization parameter λ. PBP is defined as the percentage of bad pixels for all regions as in <ref type="bibr" target="#b25">(26)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Depth error tolerance</head><formula xml:id="formula_39">u l 2 u l 1 Ours Ours (u 0 = u l 2 ) (u 0 = u l 1 ) λ avg</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">APPLICATIONS</head><p>We apply the SD filter to depth upsampling, scale-space filtering, texture removal, flash/non-flash denoising, and RGB/NIR denoising. In each application, we compare the SD filter to the state of the art. The results for the comparison have been obtained from source codes provided by the authors, and all the parameters for all compared methods have been empirically set to yield the best average performance through extensive experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Depth upsampling</head><p>Acquiring range data through an active sensor has been a popular alternative to passive stereo vision. Active sensors capture dense range data in dynamic conditions at video rate, but the acquired depth image may have low resolution, and be degraded by noise.</p><p>These problems can be addressed by exploiting a registered highresolution RGB image as a depth cue <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>. We apply the SD filter to this task. We will show that, contrary to existing methods, the robust and nonconvex regularizer in the SD filter avoids smoothing depth edges, and gives a sharp depth transition at depth discontinuities.</p><p>Parameter settings. In our model, input and guidance images (f and g) are set to sparse depth and dense color (or intensity) high-resolution images, respectively, and c i is set to 1 if the pixel i of the sparse depth image f has valid data, and 0 otherwise. The bandwidths, µ and ν, and the step index k are fixed to 60, 30, and 10, respectively, in all experiments, unless otherwise specified. The regularization parameter λ is set to 0.1 for synthetic examples, and is set to 5 for real-world examples due to the huge amount of noise. For the quantitative comparison, we measure the percentage of bad matching pixels for all regions (PBP) defined as follows:</p><formula xml:id="formula_40">PBP = 1 N i u i -u gt i &gt; δ , (<label>26</label></formula><formula xml:id="formula_41">)</formula><p>where δ is a depth error tolerance <ref type="bibr" target="#b59">[60]</ref>. [•] is the Iverson bracket where it is 1 if the condition is true, and 0 otherwise. u i and u gt i represent upsampled and ground-truth depth images at the pixel i, respectively. We also measure the percentage of bad matching pixels near depth discontinuities (PBP ) using a ground-truth index map for discontinuous regions, provided by <ref type="bibr" target="#b59">[60]</ref>. PBP is measured only when the index map is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Synthetic data</head><p>We synthesize a low-resolution depth image by downsampling (×8) ground-truth data from the Middlebury benchmark dataset <ref type="bibr" target="#b59">[60]</ref>: Tsukuba, venus, teddy, cones, art, books, dolls, laundry, moebius, and reindeer, and use the corresponding color image as static guidance.</p><p>Performance evaluation. We compare the average PBP (δ = 1) of the results obtained by the SD filter with the l 2 and l 1 initializations and the corresponding initial estimates (u l2 and u l1 ) while varying the regularization parameter λ in Table <ref type="table">1</ref>. A first important conclusion is that the nonconvex regularizer in the SD filter shows a better performance than the convex ones. The table also shows that the results of the l 1 regularizer are strongly influenced by the regularization parameter, whereas the SD filter gives almost the same PBP regardless of the initialization. For example, when λ is set to 10, the SD filter reduces the average PBP from 16.8 and 35.0 for u l2 and u l1 , respectively, to 10.3. Table <ref type="table">2</ref> compares the average PBP (δ = 1) and processing time  (d) GF <ref type="bibr" target="#b1">[2]</ref>.</p><p>(e) RWR <ref type="bibr" target="#b61">[62]</ref>. (f) Park et al. <ref type="bibr" target="#b11">[12]</ref>. (g) TGV <ref type="bibr" target="#b9">[10]</ref>.</p><p>(h) WMF <ref type="bibr" target="#b10">[11]</ref>.</p><p>(i) WModF <ref type="bibr" target="#b24">[25]</ref>.</p><p>(j) u l 2 .</p><p>(k) u l 1 .</p><p>(l) SD filter. Fig. <ref type="figure">8</ref>. Visual comparison of upsampled depth images on a snippet of the books sequence in the Middlebury dataset <ref type="bibr" target="#b59">[60]</ref>: (a) A high-resolution color image, (b) a ground-truth depth image, (c) bilinear interpolation, (d) GF <ref type="bibr" target="#b1">[2]</ref>, (e) RWR <ref type="bibr" target="#b61">[62]</ref>, (f) Park et al. <ref type="bibr" target="#b11">[12]</ref>, (g) TGV <ref type="bibr" target="#b9">[10]</ref>, (h) WMF <ref type="bibr" target="#b10">[11]</ref>, (i) WModF <ref type="bibr" target="#b24">[25]</ref>, (j) u l 2 , (k) u l 1 , and (l) SD filter (u 0 = u l 1 ). In contrast to the static guidance filters such as GF <ref type="bibr" target="#b1">[2]</ref> and WMF <ref type="bibr" target="#b10">[11]</ref>, the SD filter interpolates the low-resolution depth image using the structure of both color and depth images, preserving sharp depth edges.</p><p>of the SD filter with the l 2 and l 1 initializations while varying the number of steps k. This table shows that the results obtained by the l 1 initialization converges faster than with the l 2 one. The l 1 and l 2 initializations converge in 5 and 35 steps, respectively. Both initializations give almost the same error at the convergence, but the l 1 initialization takes less time (7s) until convergence than the l 2 one (18s). We fix the step index k to 10, regardless of the initialization.</p><p>Comparison with the state of the art. We compare the average PBP (δ = 1) of the SD filter and the state of the art in Table <ref type="table" target="#tab_2">3</ref>. Superscripts indicate the rank of each method in each column. This table shows that WMF <ref type="bibr" target="#b10">[11]</ref> and WModF <ref type="bibr" target="#b24">[25]</ref> give better quantitative results than other state-of-the-art methods, but that the SD filter outperforms all methods on average, regardless of the initialization. Figure <ref type="figure" target="#fig_6">7</ref>(a) shows the variation of the average PBP as a function of the depth error tolerance δ. The SD filter outperforms other methods until the error tolerance δ reaches around 4, and after that all methods show the similar  PBP performance. Figure <ref type="figure">8</ref> shows a visual comparison of the upsampled depth images on a snippet of the books sequence, and it clearly shows the different behavior of static guidance and joint static/dynamic guidance models: The upsampled depth image has a gradient similar to that of the color image in static guidance methods such as GF <ref type="bibr" target="#b1">[2]</ref> and WMF <ref type="bibr" target="#b10">[11]</ref>, which smooths depth edges and causes jagged artifacts in scene reconstruction (Fig. <ref type="figure">9</ref>). In contrast, the SD filter interpolates the low-resolution depth image using joint static and dynamic guidance, and provides a sharp depth transition by considering the structure of both color and depth images (Fig. <ref type="figure">8(l)</ref>). The upsampled depth image of u l1 also preserves depth discontinuities, since the l 1 regularizer is robust to outliers. The l 1 regularizer, however, favors a piecewise constant solution. This is problematic in regions that violate the fronto-parallel surface assumption (e.g., a slanted surface), and every pixel in this surface has the same depth value (Fig. <ref type="figure">8(k)</ref>). TGV <ref type="bibr" target="#b9">[10]</ref> addresses this problem using a piecewise linear model, but this approach still smooths depth edges in low-contrast regions on the color image (Fig. <ref type="figure">8</ref>(g)). Note that bilinear interpolation gives better quantitative results (Table <ref type="table" target="#tab_2">3</ref>) than the GF <ref type="bibr" target="#b1">[2]</ref> and RWR <ref type="bibr" target="#b61">[62]</ref>, although its subjective quality looks worse than these methods (e.g., depth edges in Fig. <ref type="figure">8(c-e</ref>)). This is because PBP does not differentiate depth discontinuities from other regions. Table <ref type="table" target="#tab_3">4</ref> shows the average PBP (δ = 1) measured near depth discontinuities, and it clearly shows the superior performance of the SD filter around these discontinuities. This can be further verified by observing the statistical distribution of the upsampled depth image as shown in Fig. <ref type="figure" target="#fig_10">10</ref>. Bilinear interpolation loses most (d) TGV <ref type="bibr" target="#b9">[10]</ref>.</p><p>(e) WMF <ref type="bibr" target="#b10">[11]</ref>.</p><p>(f) SD filter. Fig. <ref type="figure">9</ref>. Examples of (top) point cloud scene reconstruction using (bottom) depth images computed by (a) the ground truth, (b) bilinear interpolation, (c) GF <ref type="bibr" target="#b1">[2]</ref>, (d) TGV <ref type="bibr" target="#b9">[10]</ref>, (e) WMF <ref type="bibr" target="#b10">[11]</ref>, and (f) SD filter (u 0 = u l 2 ). Current depth upsampling methods smooth depth edges, causing jagged artifacts.</p><p>Difference in depth between adjacent pixels. The Kullback-Leibler divergence between the normalized histograms of depth gradients computed from the ground-truth and upsampled depth images.</p><p>Bilinear Int. 230.73 10 GF <ref type="bibr" target="#b1">[2]</ref> 108.19 9 RWR <ref type="bibr" target="#b61">[62]</ref> 96.43 8 TGV <ref type="bibr" target="#b9">[10]</ref> 22.43 5 WMF <ref type="bibr" target="#b10">[11]</ref> 86.33 7 WModF <ref type="bibr" target="#b24">[25]</ref> 13.11 4   u l 2 25.36 6 u l 1 9.72 3</p><p>Ours (u 0 = u l 2 ) 4.19 1 Ours (u 0 = u l 1 )</p><p>4.63 2   of the high-frequency information. Static guidance filtering methods show different statistical distributions from the ground-truth depth image. In contrast, the SD filter considers characteristics of depths as well, and delivers almost the same distribution as the ground truth depths. For evaluating this quantitatively, we also measure the Kullback-Leibler divergence between the statistical distributions of depth gradients obtained from the ground-truth and upsampled depth images in Table <ref type="table">5</ref>. From this table, we can see that the methods using a robust convex regularizer such as TGV <ref type="bibr" target="#b9">[10]</ref> give better quantitative results than other methods, and the SD filter outperforms all methods. This verifies once more the importance of using a robust nonconvex regularizer and using both static and dynamic guidance in joint image filtering. (d) GF <ref type="bibr" target="#b1">[2]</ref>.</p><p>(e) RWR <ref type="bibr" target="#b61">[62]</ref>.</p><p>(f) TGV <ref type="bibr" target="#b9">[10]</ref>.</p><p>(g) WMF <ref type="bibr" target="#b10">[11]</ref>.</p><p>(h) WModF <ref type="bibr" target="#b24">[25]</ref>.</p><p>(i) u l 2 .</p><p>(j) u l 1 .</p><p>(k) SD filter (u l 2 ). (l) SD filter (u l 1 ). Fig. <ref type="figure">11</ref>. Visual comparison of upsampled depth images on a snippet of the shark sequence in the Graz dataset <ref type="bibr" target="#b9">[10]</ref>: (a) A high-resolution intensity image, (b) a ground-truth depth image, (c) bilinear interpolation, (d) GF <ref type="bibr" target="#b1">[2]</ref>, (e) RWR <ref type="bibr" target="#b61">[62]</ref>, (f) TGV <ref type="bibr" target="#b9">[10]</ref>, (g) WMF <ref type="bibr" target="#b10">[11]</ref>, (h) WModF <ref type="bibr" target="#b24">[25]</ref>, (i) u l 2 , (j) u l 1 , (k) SD filter (u 0 = u l 2 ), and (l) SD filter (u 0 = u l 1 ). Note that the l 1 regularizer in (j) favors a piecewise constant solution, and this is problematic in a slanted surface. TGV denotes the results provided by the authors of <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Real data</head><p>Recently, Ferstl et al. <ref type="bibr" target="#b9">[10]</ref> have introduced a benchmark dataset that provides both low-resolution depth images captured by a ToF camera and highly accurate ground-truth depth images acquired λ = 5 λ = 20 with structured light. We have performed a quantitative evaluation using this dataset <ref type="bibr" target="#b9">[10]</ref> in Fig. <ref type="figure" target="#fig_6">7</ref>(b): We measure the average PBP of upsampled depth images with varying the depth error tolerance δ. This shows that the SD filter outperforms all methods for all ranges of δ, regardless of the initialization. A qualitative comparison can be found in Fig. <ref type="figure">11</ref>. Although most methods reduce sensor noise relatively well, they smooth depth edges as well. In contrast, the SD filter preserves sharp depth discontinuities, while suppressing sensor noise. The amount of noise in low-resolution depth images may change. We can deal with this by adjusting the regularization parameter that determines the degree of smoothing in the upsampled depth image, as shown in Fig. <ref type="figure" target="#fig_12">12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Scale-space filtering and texture removal</head><p>In natural scenes, various objects appear in different sizes and scales <ref type="bibr" target="#b62">[63]</ref>, and they contain a diversity of structural information from small-scale (e.g., texture and noise) to large-scale structures (e.g., boundaries). Extracting this hierarchy is an important part of understanding the relationship between objects, and it can be done by smoothing a scene through image filtering. We apply the SD filter to two kinds of scene decomposition tasks: Scale-space filtering and texture removal.</p><p>Parameter settings. For scale-space filtering, the input image f is guided by itself (g = f ). The regularization parameter λ varies from 5 × 10 to 5 × 10 4 . In texture removal, the static guidance image is set to a Gaussian-filtered of the input image, g = G σ f where G σ is the Gaussian kernel with standard deviation σ. The regularization parameter λ and σ vary from 5 × 10 to 2 × 10 3 and from 1 to 2, respectively. The bandwidths, µ and ν, the step index k, and the confidence value c i are fixed to 5, 40, 5, and 1, respectively, for both applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Scale-space filtering</head><p>We obtain a scale-space representation by applying the SD filter while increasing the regularization parameter, as shown in Fig. <ref type="figure" target="#fig_8">13</ref>. The SD filter preserves object boundaries well, even at coarse scales, and it is robust to global intensity shift.</p><p>Comparison with the state of the art. We compare the scale-space representation of WLS <ref type="bibr" target="#b22">[23]</ref>, RGF <ref type="bibr" target="#b15">[16]</ref>, and the SD filter in Fig. <ref type="figure" target="#fig_8">13</ref>. The WLS framework <ref type="bibr" target="#b22">[23]</ref>, a representative of static guidance filtering, alters the scale of image structure by varying the regularization parameter. It suffers from global intensity shifting <ref type="bibr" target="#b1">[2]</ref> (Fig. <ref type="figure" target="#fig_8">13(a-b</ref>)), and may not preserve image structures at coarse scales (Fig. <ref type="figure" target="#fig_8">13(a)</ref>). RGF <ref type="bibr" target="#b15">[16]</ref> is the state of the art in scale-space filtering, and dynamic guidance in RGF could alleviate these problems. However, this filter does not use the structure of the input image, and controls the scale by the isotropic Gaussian kernel, leading to poor boundary localization at coarse scales (Fig. <ref type="figure" target="#fig_8">13(c</ref>)). The SD filter uses the structure </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 6</head><p>Evaluation of boundary localization accuracy on the BSDS300 database <ref type="bibr" target="#b63">[64]</ref>. Scale-space is constructed by WLS <ref type="bibr" target="#b22">[23]</ref> (µ = 40), RGF <ref type="bibr" target="#b15">[16]</ref> (σr = 0.05, k = 5), and the SD filter (u 0 = u l 2 and u 0 = u l 1 ), with varying scale parameters. of input and desired output images, and the scale depends on the regularization parameter, providing well localized boundaries even at coarse scales. Moreover, it is robust to global intensity shift (Fig. <ref type="figure" target="#fig_8">13(d-e</ref>)). For a good scale-space representation, object boundaries should be sharp and coincide well with the meaningful boundaries at each scale <ref type="bibr" target="#b16">[17]</ref>. There is no universally accepted evaluation method for scale-space filtering. Motivated by the evaluation protocol for boundary detection, we measure ODS and OIS <ref type="bibr" target="#b64">[65]</ref> with the BSDS300 database <ref type="bibr" target="#b63">[64]</ref>, and evaluate boundary localization accuracy of scale-space filtering in Table <ref type="table">6</ref>. ODS is the F-measure 6 at a fixed contour threshold across the entire dataset, while OIS 6. The F-measure is the harmonic mean of precision and recall. (c) RGF <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>(d) SD filter (u 0 = u l 2 ). Fig. <ref type="figure">14</ref>. Examples of the gradient magnitude averaged over scale-space: Given (a) an input image, scale-space is obtained by (b) WLS <ref type="bibr" target="#b22">[23]</ref> (µ = 40), (c) RGF <ref type="bibr" target="#b15">[16]</ref> (σr = 0.05, k = 5), and (d) the SD filter (u 0 = u l 2 ) with varying scale parameters. For each method, we set the maximum scale parameters manually, such that all the filtered images have similar smoothing levels. The gradient magnitude is then computed at each scale and averaged over scale-space.</p><p>refers to the per-image best F-measure. For all images in the dataset, ODS and OIS are measured using the gradient magnitudes of filtered images, each of which is averaged over scale-space, as shown in Fig. <ref type="figure">14</ref>. We obtain the filtered images from the input image while varying scale parameters, i.e., λ in WLS <ref type="bibr" target="#b22">[23]</ref> and the SD filter, and σ s in RGF <ref type="bibr" target="#b15">[16]</ref>. The maximum scale parameter is set manually for each method, such that all the filtered images are smoothed with similar levels. Similarly, we also measure ODS (resp. OIS ) with the gradient images of filtering results, but using a fixed scale parameter that provides maximum ODS (resp. OIS) for each image. That is, ODS (resp. OIS ) is the maximum value of ODS (resp. OIS) over scale-space. In both cases, the SD filter outperforms other filtering methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Texture removal</head><p>For removing texture while maintaining other high-frequency image structures, we need a guidance image that does not have the texture, but contains large image structures. Since it is hard to get such an image, we set the static guidance image to the Gaussianfiltered version of the original image with standard deviation σ. This removes the textures of scale σ, but it also smooths structural edges (e.g., boundaries). Our dynamic guidance and fidelity term reconstruct smoothed boundaries as shown in Fig. <ref type="figure">15</ref>.</p><p>Comparison with the state of the art. As in scale-space filtering, to the best of our knowledge, there is no universally accepted evaluation protocol for texture removal. Filtering examples of (top) regular and (bottom) irregular textures are shown in Fig. <ref type="figure">15</ref>. Most methods extract prominent image structures while filtering out textures. The Cov. M1 method <ref type="bibr" target="#b13">[14]</ref> adopts a weighted average process to eliminate textures. The weight is computed using the covariance of features in a local patch to encode the repetitive patterns of textures. This method, however, smooths object boundaries and corners (Fig. <ref type="figure">15(b)</ref>), and needs lots of computational cost for weight computation. RTV <ref type="bibr" target="#b14">[15]</ref> optimizes an objective function similar to the SD filter, but with relative total variation. Although this method uses a nonconvex regularizer, it penalizes large gradients similar to the total variation regularizer, which smooths structural edges (Fig. <ref type="figure">15(c)</ref>). As pointed out in <ref type="bibr" target="#b14">[15]</ref>, RTV cannot perfectly extract image structures that have similar scale and appearance to the underlying textures. RGF <ref type="bibr" target="#b15">[16]</ref> can control the scale of image structure to be extracted, and preserves object boundaries well. However, it does not protect corners, possibly due to the inherent limitation of the Gaussian kernel used in RGF, and color artifacts are observed (Fig. <ref type="figure">15(d)</ref>). On the other hand, the SD filter removes textures without artifacts, and maintains small, high-frequency, but important structures to be preserved such as corners (Fig. <ref type="figure">15(e-f</ref>)). We can see that the SD filter with the l 1 initialization better preserves edges and corners than with the l 2 one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Other applications</head><p>The SD filter can be applied to joint image restoration tasks. We apply it to RGB/NIR and flash/non-flash denoising problems as shown in Figs. <ref type="figure">16</ref> and<ref type="figure" target="#fig_6">17</ref>, respectively. In RGB/NIR denoising, the color image f is regularized with the flash NIR image g. Similarly, the non-flash image f is regularized with the flash image g. Since there exist structural dissimilarities between static guidance and input images (g and f ), the results might have artifacts and unnatural appearance. For example, static guidance filtering (e.g., GF <ref type="bibr" target="#b1">[2]</ref>) cannot deal with gradient reversal in flash NIR images <ref type="bibr" target="#b3">[4]</ref>, resulting in smoothed edges. The SD filter handles structural differences between guidance and input images, and gives qualitative results comparable to the state of the art <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>We have presented a robust joint filtering framework that is widely applicable to computer vision and computational photography tasks. Contrary to static guidance filtering methods, we leverage dynamic guidance images, and can exploit the structural information of the input image. Although our model does not have a closed-form solution, the corresponding optimization problem can be solved by an efficient algorithm that converges rapidly to a local minimum. The simple and flexible formulation of the SD filter makes it applicable to a great variety of applications, as demonstrated by our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A</head><p>Proposition 1. Ψ y ν is a surrogate function of ψ ν . Proof. Let us consider the following function:</p><formula xml:id="formula_42">f ν (x) = (1 -exp(-νx))/ν. (<label>27</label></formula><formula xml:id="formula_43">)</formula><p>Since f ν (x) &lt; 0, this function is strictly concave, i.e., ∀x, y, f ν (x) ≤ f ν (y) + (x -y)f ν (y),</p><p>with equality holding when x is equal to y. Thus, a surrogate function f y ν is f y ν (x) = f ν (y) + (x -y)f ν (y) (29) = f ν (y) + (x -y)(1 -νf ν (y)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It follows that</head><formula xml:id="formula_45">ψ ν (x) = f ν (x 2 ) ≤ f y 2 ν (x 2 )<label>(30)</label></formula><p>= ψ ν (y) + (x 2 -y 2 )(1 -νψ ν (y)) = Ψ y ν (x). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Color image. (b) Depth image. (c) Static guidance. (d) Dynamic guidance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3 :</head><label>3</label><figDesc>Compute a confidence matrix C = diag ([c 1 , . . . , c N ]) where c i ≥ 0. 4: Compute an affinity matrix for the static guidance image g, W g = [φ µ (g i -g j )] N ×N , where φ µ (x) = exp(-µx 2 ). 5: for k = 0, . . . , K do 6:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>x 2 Fig. 5 .</head><label>25</label><figDesc>Fig. 5. Upper bounds on Welsch's function ψν : An l 2 regularizer x 2 and an l 1 regularizer α|x| (a tight upper bound on ψν ), when ν is set to 1. (Best viewed in colour.)</figDesc><graphic coords="6,335.20,159.68,103.20,78.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>0 = u l2 ) Ours (u 0 = u l1 ) (b) Graz dataset<ref type="bibr" target="#b9">[10]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Average PBP on (a) the Middlebury dataset [60] and (b) the Graz dataset [10] as a function of the depth error tolerance δ. (Best viewed in colour.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(a) Color image. (b) Ground truth. (c) Bilinear Int.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>3</head><label>3</label><figDesc>22.80 4 15.10 3 Ours (u 0 = u l 2 ) 10.40 1 5.10 2 20.30 2 12.40 1 Ours (u 0 = u l 1 ) 10.80 2 4.83 1 20.00 1 12.40 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Log 10 of the normalized histograms (probability) of relative depths between adjacent pixels. Each histogram is computed using depth gradients along x-and y-axis, and then averaged on the Middlebury dataset [60]. (Best viewed in colour.)</figDesc><graphic coords="10,317.40,384.23,56.76,56.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Ground truth. (c) Bilinear Int.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Influence of the regularization parameter λ on the upsampled depth image. The results become smooth as the parameter λ increases.</figDesc><graphic coords="11,52.27,43.53,118.67,89.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>RGF<ref type="bibr" target="#b15">[16]</ref>.(d) SD filter (u 0 = u l 2 ).(e) SD filter (u 0 = u l 1 ). Fig. 13. Examples of scale-space filtering. (a) WLS [23] (from left to right, λ = 5 × 10, 2 × 10 3 , 5 × 10 4 , µ = 5), (b) WLS [23] (from left to right, λ = 5 × 10 3 , 2 × 10 5 , 5 × 10 6 , µ = 40), (c) RGF [16] (from left to right, σs = 5, 5 × 10, 2.5 × 10 2 , σr = 0.05, k = 5), (d) SD filter (u 0 = u l 2 , and from left to right, λ = 5 × 10, 2 × 10 3 , 5 × 10 4 ), (e) SD filter (u 0 = u l 1 , and from left to right, λ = 5 × 10, 2 × 10 3 , 5 × 10 4 ). In these examples, we manually pick the scale parameter λ of the SD filter between 5 × 10 to 5 × 10 4 . The parameters for other methods are similarly chosen, such that all methods have similar smoothing levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>(a) Input image.(b) WLS<ref type="bibr" target="#b22">[23]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>(a) Input image and snippets.(b) Cov. M1<ref type="bibr" target="#b13">[14]</ref>.(c) RTV<ref type="bibr" target="#b14">[15]</ref>. (d) RGF<ref type="bibr" target="#b15">[16]</ref>.(e) SD filter. (f) SD filter. Fig. 15. Visual comparison of texture removal for (top) regular and (bottom) irregular textures. (a) Input image, (b) Cov. M1 [14] (σ = 0.3, r = 10), (c) RTV [15] (λ = 0.01, σ = 6), (d) RGF [16] (σs = 5, and from top to bottom, σr = 0.1, 0.05, k = 5), (e) SD filter (u 0 = u l 2 , and from top to bottom, λ = 1 × 10 3 , 1 × 10 2 , σ = 2), (f) SD filter (u 0 = u l 1 , and from top to bottom, λ = 2 × 10 3 , 3 × 10 2 , σ = 2). We set all parameters through extensive experiments for the best qualitative performance. (a) RGB images. (b) NIR images. (c) GF [2]. (d) Results of [4]. (e) SD filter (u 0 = u l 2 ). (f) SD filter (u 0 = u l 1 ). Fig. 16. RGB and flash NIR image restoration. (a) RGB images, (b) NIR images, (c) GF [2] (r = 3, ε = 4 -4 ), (d) results of [4], (e) SD filter (u 0 = u l 2 , λ = 10, µ = 60, ν = 30, k = 5), (f) SD filter (u 0 = u l 1 , λ = 10, µ = 60, ν = 30, k = 5). The results of (d) are from the project webpage of [4].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Best viewed in colour.)</head><label></label><figDesc>Fig. 4. Welsch's function ψν and its surrogate functions Ψ y ν , when ν is set to 1. The convex surrogate function Ψ y ν (x) is an upper bound on ψν (x) and coincides with ψν (x) only when x is equal to y. (</figDesc><table><row><cell>1.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>A 8 (x)</cell><cell></cell><cell></cell></row><row><cell>1.2 1.4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">* y 8 (x); y = 1 * y 8 (x); y = 2 * y 8 (x); y = 3</cell><cell></cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-3 0</cell><cell>-2</cell><cell>-1</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>. ± std. avg. ± std. avg. ± std.avg. ± std.</figDesc><table><row><cell cols="2">0.001 10.0±4.7</cell><cell>10.9±6.1</cell><cell>7.0±3.4</cell><cell>7.1±3.4</cell></row><row><cell cols="2">0.005 10.0±4.7</cell><cell>10.9±6.1</cell><cell>7.0±3.4</cell><cell>7.1±3.4</cell></row><row><cell cols="2">0.010 10.0±4.7</cell><cell>10.9±6.1</cell><cell>7.0±3.4</cell><cell>7.1±3.4</cell></row><row><cell cols="2">0.050 10.0±4.7</cell><cell>11.4±6.5</cell><cell>7.1±3.4</cell><cell>7.1±3.4</cell></row><row><cell cols="2">0.100 10.0±4.8</cell><cell>12.1±7.0</cell><cell>7.1±3.4</cell><cell>7.1±3.4</cell></row><row><cell cols="2">0.200 10.1±4.8</cell><cell>13.4±7.9</cell><cell>7.1±3.5</cell><cell>7.1±3.4</cell></row><row><cell cols="2">0.500 10.4±5.0</cell><cell>16.2±9.5</cell><cell>7.2±3.5</cell><cell>7.2±3.5</cell></row><row><cell cols="2">1.000 10.9±5.3</cell><cell>19.5±11.2</cell><cell>7.4±3.7</cell><cell>7.4±3.6</cell></row><row><cell cols="2">10.00 16.8±9.8</cell><cell>35.0±19.4</cell><cell>10.3±6.0</cell><cell>10.3±6.0</cell></row><row><cell></cell><cell></cell><cell>TABLE 2</cell><cell></cell><cell></cell></row><row><cell cols="5">Average PBP (δ = 1) and processing time on the Middlebury</cell></row><row><cell cols="5">dataset [60] with varying the number of steps k.</cell></row><row><cell>1</cell><cell>10.0±4.8</cell><cell>0.7</cell><cell>7.6±3.5</cell><cell>4.9</cell></row><row><cell>5</cell><cell>7.2±3.5</cell><cell>2.7</cell><cell>7.1±3.4</cell><cell>7.0</cell></row><row><cell>10</cell><cell>7.1±3.4</cell><cell>5.4</cell><cell>7.1±3.4</cell><cell>9.6</cell></row><row><cell>30</cell><cell>7.1±3.4</cell><cell>15.5</cell><cell>7.1±3.4</cell><cell>19.6</cell></row><row><cell>35</cell><cell>7.0±3.4</cell><cell>18.1</cell><cell>7.1±3.4</cell><cell>22.3</cell></row><row><cell>100</cell><cell>7.0±3.4</cell><cell>51.9</cell><cell>7.1±3.4</cell><cell>55.7</cell></row></table><note><p><p>Ours (u 0 = u l 2 )</p>Ours (u 0 = u l 1 ) k avg. ± std. time (s) avg. ± std. time (s)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 PBP</head><label>3</label><figDesc>(δ = 1) comparison with the state of the art on the Middlebury dataset<ref type="bibr" target="#b59">[60]</ref>. Superscripts indicate the rank of each method for each image.MethodTsukuba Venus Teddy Cones Art Books Dolls Laun. Moeb. Rein. avg. ± std. Bilinear Int. 10.40 10 3.29 10 11.80 10 14.60 10 34.59 9 13.07 7 14.59 6 22.85 10 17.15 8 17.48 8 15.98±8.29 9 GF [2] 9.87 9 2.74 9 15.50 11 15.50 11 45.31 11 19.14 10 19.64 11 26.89 11 22.22 11 21.70 9 19.85±11.2 11 RWR [62] 9.63 8 1.36 7 11.40 9 11.70 9 41.07 10 17.67 9 18.36 10 21.74 9 21.28 10 25.71 11 17.99±10.8 10 Park et al. [12] --10.10 8 9.71 7 27.81 8 11.18 5 15.23 7 18.27 8 13.82 7 12.35 6 14.81±5.97 8 TGV [10] 5.40 6 1.31 6 9.82 7 10.20 8 23.59 7 13.14 8 16.14 9 15.12 7 18.26 9 10.42 5 12.34±6.40 7 WMF [11] 6.14 7 1.03 5 7.88 3 8.10 5 22.13 6 8.67 1 9.58 1 14.26 6 10.52 4 10.04 3 9.84±5.48 4 WModF [25] 4.35 5 0.61 3 9.51 5 9.43 6 12.39 3 10.68 4 11.48 4 9.91 3 8.60 1 12.63 7 8.96±3.76 3 u l 2 3.60 4 1.60 8 9.28 4 7.86 4 17.88 4 11.90 6 12.63 5 11.74 4 13.61 6 10.28 4 10.04±4.78 5 u l 1 2.59 3 0.67 4 9.51 5 7.56 3 17.98 5 19.29 11 15.86 8 12.75 5 13.08 5 21.85 10 12.11±7.03 6 Ours (u 0 = u l 2 ) 2.39 1 0.52 1 7.39 1 5.24 1 10.04 2 9.79 3 10.84 3 8.11 1 9.49 2 6.93 1 7.07±3.43 1 Ours (u 0 = u l 1 ) 2.45 2 0.52 1 7.42 2 5.36 2 9.96 1 9.52 2 10.77 2 8.22 2 9.49 2 6.98 2 7.07±3.38 1</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 4 PBP</head><label>4</label><figDesc>(δ = 1) comparison on the Middlebury dataset<ref type="bibr" target="#b59">[60]</ref>.Bilinear Int.46.3010 37.10 10 35.30 10 35.80 11 GF [2] 43.20 9 26.50 9 37.50 11 34.40 10 RWR [62] 39.50 8 12.30 6 27.50 8 25.40 9 Park et al. [12] --25.40 6 19.90 7 TGV [10] 23.90 6 14.40 7 29.00 9 23.60 8 WMF [11]28.00 7 10.10 5 22.203 19.20 5 WModF<ref type="bibr" target="#b24">[25]</ref> </figDesc><table><row><cell>Method</cell><cell>Tsukuba Venus Teddy Cones</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>We use IRLS<ref type="bibr" target="#b48">[49]</ref> to find the solution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>The SD filter of<ref type="bibr" target="#b10">(11)</ref> applies the very popular WLS filter<ref type="bibr" target="#b22">[23]</ref> iteratively with a fixed input image, allowing us to use many acceleration techniques for WLS filtering<ref type="bibr" target="#b28">[29]</ref>,<ref type="bibr" target="#b54">[55]</ref>. When using MEX implementation of the fast WLS algorithm in<ref type="bibr" target="#b54">[55]</ref>, we obtain the filtering result with 0.1 seconds for the same image size.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Francis Bach for helpful discussions. This work was supported in part by the ERC grant VideoWorld and the Institut Universitaire de France.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B</head><p>Let us consider the following objective function: ), (d) result of <ref type="bibr" target="#b12">[13]</ref>, (e) result of <ref type="bibr" target="#b3">[4]</ref>, (f) SD filter (u 0 = u l 2 , λ = 15, µ = 60, ν = 30, k = 5). The results of (d) and (e) are from the project webpages of <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b3">[4]</ref>, respectively.</p><p>The surrogate function of (31) can be found using the inequality in (9) as follows:</p><p>where w ij ≡ φ s (i -j) and w g ij ≡ φ µ (g i -g j ). Then,</p><p>. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deterministic edge-preserving regularization in computed imaging</title>
		<author>
			<persName><forename type="first">P</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Blanc-Féraud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="298" to="311" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Guided image filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1397" to="1409" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint bilateral upsampling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Uyttendaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="96" to="100" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Crossfield joint image restoration via scale map</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1537" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast costvolume filtering for visual correspondence and beyond</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hosni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bleyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="504" to="511" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive support-weight approach for correspondence search</title>
		<author>
			<persName><forename type="first">K.-J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="650" to="656" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">EpicFlow: Edge-preserving interpolation of correspondences for optical flow</title>
		<author>
			<persName><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1164" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Proposal flow</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">FlowWeb: Joint image set alignment by weaving consistent, pixel-wise correspondences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1191" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image guided depth upsampling using anisotropic total generalized variation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ferstl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Reinbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rüther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="993" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Constant time weighted median filtering for stereo matching and beyond</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">High quality depth map upsampling for 3D-TOF cameras</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1623" to="1630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Digital photography with flash and no-flash image pairs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Petschnigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="664" to="672" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Structure-preserving image smoothing via region covariances</title>
		<author>
			<persName><forename type="first">L</forename><surname>Karacan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Erdem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structure extraction from texture via relative total variation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="139" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rolling guidance filter</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="815" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient nonlocal means for denoising of textural patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1083" to="1092" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust regression using iteratively reweighted least-squares</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="813" to="827" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Correntropy: Properties and applications in non-Gaussian signal processing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Pokharel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Príncipe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5286" to="5298" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust image filtering using joint static and dynamic guidance</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="4823" to="4831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Edge-preserving decompositions for multi-scale tone and detail manipulation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Farbman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image smoothing via l 0 gradient minimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Depth video enhancement based on weighted mode filtering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1176" to="1190" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Colorization using optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="689" to="694" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Practical temporal consistency for image-based graphics applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aydin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smolic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphic</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A review of nonlinear diffusion filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Scale-Space Theories in Computer Vision</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast edge-aware processing via first order proximal approximation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Badri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yahia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aboutajdine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="743" to="755" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mutual-structure for joint filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3406" to="3414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep joint image filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust higher order potentials for enforcing label consistency</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ladicky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected CRFs with Gaussian edge potentials</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with deep convolutional nets and fully connected CRFs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liang-Chieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Conditional random fields as recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1529" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The fast bilateral solver</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with task-specific edge detection using CNNs and a discriminatively trained domain transform</title>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A noise-aware filter for real-time depth upsampling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Buisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis. Workshops</title>
		<meeting>Eur. Conf. Comput. Vis. Workshops</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Patch based synthesis for single depth image super-resolution</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="71" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Crisp boundary detection using pointwise mutual information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="799" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast bilateral filtering for the display of highdynamic-range images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dorsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="266" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Robust statistics: The approach based on influence functions</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Hampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Ronchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Stahel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">On the convergence of the concave-convex procedure</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1759" to="1767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Incremental majorization-minimization optimization with application to large-scale machine learning</title>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1402.4419</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Surrogate maximization/minimization algorithms for adaboost and the logistic regression model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Machine Learning</title>
		<meeting>Int. Conf. Machine Learning</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">117</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the convergence properties of the EM algorithm</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annals of statistics</title>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="95" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A tutorial on MM algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The EM algorithm and extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishnan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">382</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Iteratively reweighted least-squares minimization for sparse recovery</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Devore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fornasier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Güntürk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Open questions concerning Weiszfeld&apos;s algorithm for the fermat-weber location problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Programming</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="293" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Constrained restoration and the recovery of discontinuities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="367" to="383" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Analysis of half-quadratic minimization methods for signal and image recovery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on scientific computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="937" to="966" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The equivalence of half-quadratic minimization and the gradient linearization iteration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1623" to="1627" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Algorithm 887: Cholmod, supernodal sparse Cholesky factorization and update/downdate</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajamanickam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fast global image smoothing based on weighted least squares</title>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5638" to="5653" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Generative image segmentation using random walks with restart</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vis</title>
		<meeting>Eur. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="264" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Automatic multimedia cross-modal correlation discovery</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
		<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="653" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Fast random walk with restart and its applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Data Mining</title>
		<meeting>IEEE Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Robust anisotropic diffusion</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Marimont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="432" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A taxonomy and evaluation of dense twoframe stereo correspondence algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scharstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="42" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Joint geodesic upsampling of depth images</title>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Taguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A generalized random walk with restart and its application in depth up-sampling and interactive segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2574" to="2588" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Segmentation as selective search for object recognition</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1879" to="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Conput. Vis</title>
		<meeting>Int. Conf. Conput. Vis</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
