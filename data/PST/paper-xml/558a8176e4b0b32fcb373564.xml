<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pattern Recognition Using a Family of Design Algorithms Based Upon the Generalized Probabilistic Descent Method</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Pattern Recognition Using a Family of Design Algorithms Based Upon the Generalized Probabilistic Descent Method</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E172881F09F337DD195602218004EDEA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayes decision theory</term>
					<term>discriminant function approach</term>
					<term>discriminative feature extraction</term>
					<term>discriminative training</term>
					<term>generalized probabilistic descent method</term>
					<term>minimum classification error learning</term>
					<term>pattern recognition</term>
					<term>speech recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Invited Paper</head><p>This paper provides a comprehensive introduction to a novel approach to pattern recognition, which is based on the generalized probabilistic descent method (GPD) and its related design algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The paper contains a survey of recent recognizer design techniques, the formulation of GPD, the concept of minimum classification error learning that is closely related to the GPD formalization, a relational analysis between GPD and other important design methods, and various embodiments of GPDbased design, including segmental-GPD, minimum spotting error training, discriminative utterance verification, and discriminative feature extraction. GPD development has its origins in basic pattern recognition and Bayes decision theory. It represents a simple but careful re-investigation of the classical theory and successfully leads to an innovative framework. For clarity of presentation, detailed discussions about its embodiments are provided for examples of speech pattern recognition tasks that use a distance-based classifier. Experimental results in speech pattern recognition tasks clearly demonstrate the remarkable utility of the family of GPD-based design algorithms.</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Pattern recognition has long been a topic of fundamental importance in a wide range of science and technology. In these days of rapidly growing information-oriented societies, improvement in its performance is an urgent technological issue. In particular, a mathematically proven, effective, and efficient method is desired for designing highly accurate recognizers. As one of the solutions for meeting this need, a discriminative training method called the gen-Manuscript received November 1, 1997; revised <ref type="bibr">April 17, 1998</ref>. S. Katagiri is with ATR Human Information Processing Research Laboratories, Kyoto 619-02 Japan (e-mail: katagiri@hip.atr.co.jp).</p><p>B.-H. Juang and C.-H. Lee are with Bell Laboratories, Lucent Technologies, Murray Hill, NJ 07974-0636 USA (e-mail: bjuang@lucent.com; chl@research.bell-labs.com).</p><p>Publisher Item Identifier S 0018-9219(98)07864-5.</p><p>eralized probabilistic descent method (GPD) was developed for classifier design <ref type="bibr" target="#b53">[54]</ref>. This method has been shown to be very useful in various speech pattern classification tasks. Since its development it has been deeply analyzed and further extended to a more general methodological framework for pattern recognition (the terminological difference between "classification" and "recognition" will be shown later). This paper is therefore devoted to providing a comprehensive review of the GPD-based approach to pattern recognition. GPD is a general pattern recognition framework. For clarity of presentation, we consider here the problem of speech pattern recognition, which is one of the crucial research areas in the development of multimedia and artificial intelligence technologies. In the following paragraphs of this section, we shall summarize the motivations for GPD's development, addressing problems in speech recognizer design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Speech Pattern Recognition Using Modular Systems</head><p>We refer to the acoustic output of the human speech production system as a speech instantiation, and it can be considered as a sequence of linguistic units, such as phonemes and words. The goal of speech recognition then is to map a speech instantiation to its corresponding correct sequence of linguistic units.</p><p>As can be easily observed, the duration of each linguistic unit is highly variable, mainly due to speaking-rate changes. This indicates that a speech instantiation is a dynamic (variable-durational) temporal sample. In addition, the acoustic properties of speech waves are highly variable due to various factors such as the speakers themselves and the speaking fluency. The size of a vocabulary, i.e., the number of words used, often exceeds several tens of thousands of words. From this, it is obvious that coping with various issues appropriately and comprehensively is an indispensable requirement in the design of the recognizer. However, it is not necessarily recommended to start introductory discussions with such a large-scale complicated design framework. Let us therefore start preparations on discussions by using the following basic statement: speech recognition involves a process of mapping a dynamic speech instantiation, which is a priori correctly extracted from its surrounding acoustic signal and belongs to one of a given set of speech classes, to a class index; We specially consider the design problem of training the adjustable parameter set of a recognizer (see below for a more precise description), aiming at achieving the optimal (i.e., best in recognition accuracy for all future instantiations) recognition decision performance.</p><p>One of the fundamental approaches to this problem is the Bayes approach using the following Bayes decision rule, the rigorous execution of which is well known to lead to the minimum recognition error rate:</p><formula xml:id="formula_0">iff (1)</formula><p>where is a dynamic speech instantiation with length represents the recognition operation, and it is assumed that the a posteriori probability for the dynamic instantiation exists and is known. A training goal in this approach is to find a state of that enables the corresponding estimate which is a function of to precisely approximate the true a posteriori probability <ref type="bibr">(density)</ref> or in other words, to adjust so that can approximate as precisely as possible. For example, one could attempt a direct estimate of this a posteriori probability for the dynamic instantiation by using a system having a sufficiently large approximation capability. However, to the best of the authors' knowledge, there has not been a successful design example based on such an optimistic strategy. Therefore, an alternative to this ideal but simple-minded attempt is obviously needed.</p><p>Actually, most speech recognizers are transparent (i.e., an internal process is explicitly described) modular systems. Such a recognizer consists of several observable modules, each of which is carefully designed based on scientific experiences. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, a typical recognizer consists of: 1) a feature extractor (feature extraction module) and 2) a classifier (classification module) that is further divided into a language model and an acoustic model. Let us represent the adjustable parameter sets of the feature extractor, the acoustic model, and the language model by and respectively: The feature extraction module converts a speech wave sample to a dynamic pattern that is a sequence of static (fixeddimensional)</p><p>-dimensional acoustic feature vectors, where is the duration of the dynamic pattern and is the th feature vector of the sequence. The feature vector is generally made up of cepstrum or bank-of-filters output coefficients.</p><p>is then the designable parameter set, such as lifter and bank-of-filters functions, that controls the nature of the feature vectors. Next, the classification module assigns a class index to this converted feature pattern. This assignment is generally performed by using the classification rule iff <ref type="bibr" target="#b1">(2)</ref> which is conceptually equivalent to <ref type="bibr" target="#b0">(1)</ref>. Note in (2) that in accordance with the Bayes rule of probability, the a posteriori probability is replaced by the conditional probability (density) and the a priori probability, which are both suited for the estimation based on the well-analyzed maximum likelihood (ML) method. In fact, the conditional probability [density] is often computed as the estimate using hidden Markov models (HMM's) for the acoustic models; corresponds to a set of model parameters, such as the HMM state transition probabilities and the mean vectors of the Gaussian continuous HMM's. Also, the a priori probability is often computed as the estimate using a language model such as an -gram and a probabilistic context-free grammar; then corresponds to the probability of the -gram and the parameters that determine the grammatical rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Classifier Design Based on ML Method</head><p>In the same sense as <ref type="bibr" target="#b0">(1)</ref>, substituting accurate estimates for the probabilities in (2) enables one to fundamentally achieve the optimal, minimum classification error status. Thus, it seems plausible to consider the accurate estimation of these conditional and a priori probabilities to be a desirable design objective. Actually, the classifiers of most existing recognizers have been designed based on the design principle of this ML approach (to classification); that is, the expectation-maximization method, which is an extended ML estimation method for incomplete data<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b27">[28]</ref>, and segmental -means clustering <ref type="bibr" target="#b49">[50]</ref> are used for training the HMM acoustic model, and a simple computation of the relative frequency of occurrence of symbols (e.g., phonemes or words) is used for designing the -gram language model <ref type="bibr" target="#b48">[49]</ref>. Note here that the minimum distortion principle, which underlies the design of the reference pattern-based models of a distance classifier (widely used prior to HMM classifiers) is fundamentally equivalent to this ML principle.</p><p>However, this conventional ML-based approach actually has a basic problem in that the functional form of the class distribution (the conditional probability density) function to be estimated is in practice rarely known, and the likelihood maximization of these estimated functions, performed to model each entire class distribution individually, is not direct with regard to the minimization of classification errors (the accurate estimate of class boundaries). Also, the ML-based approach covers only the classifier design; it does not optimize the overall recognizer, or in other words, its design target is too far from emulating the original decision strategy <ref type="bibr" target="#b1">(2)</ref>.</p><p>The techniques of feature extraction and probability estimation are described in detail in textbooks such as <ref type="bibr" target="#b84">[85]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Classifier Design Based on a Discriminant Function Approach</head><p>Recently, an alternative to the common ML approach, based on the concept of discriminative training, has been vigorously investigated to especially improve the acoustic model parameter</p><p>Discriminative training has been called many different names because it has various backgrounds, including multivariate analysis, artificial intelligence, and artificial neural networks (ANN). In fact, it is sometimes called competitive learning and discriminant analysis. In this paper, we refer to it as the discriminant function approach (DFA) that has been widely used in pattern recognition.</p><p>In DFA, a discriminant function is introduced (for to measure the class membership of the input (the degree to which belongs to one class), where one should note that the discriminant function is a function of the classifier parameters This discriminant function does not need to be a probability function; it can be any reasonable type of measure, such as distance or similarity. In the approach, the following decision rule is used in place of (2): iff</p><p>In this approach, is trained in order to reduce a loss that reflects a classification error in a certain manner. Since the classification result is evaluated in the design stage, this approach is fundamentally more direct with regard to the minimization of classification errors than the ML-based approach where class model parameters are designed independently of each other. In fact, designs using this approach have successfully improved the classification accuracy of ML-based baseline systems in various speech classification tasks, as will be discussed later. However, there was plenty of room left for improvement in this apparently powerful DFA: each of these designs had a mathematical or procedural inadequacy, as summarized in the following.</p><p>1) Execution of rule (3) using an arbitrary measure as the discriminant function does not necessarily lead to the minimum Bayes error probability situation.</p><p>2) The design scope stays within the acoustic modeling and does not cover the overall recognizer.</p><p>3) Most of the existing training procedures are empirical or heuristic, and their mathematical optimality is thus unclear.</p><p>The following is a review of the research situation concerning DFA-based acoustic model training in the years around 1990, which was actually a direct motivation for GPD development. In the early stages of investigation, attempts were made to improve HMM acoustic models. The concept of maximum mutual (interclass) information was incorporated in the model design <ref type="bibr" target="#b6">[7]</ref>, and corrective training similar to traditional error-correction training was developed <ref type="bibr" target="#b7">[8]</ref>. In the next stage, ANN concepts such as feed-forward network (FFN) <ref type="bibr" target="#b90">[91]</ref> and learning vector quantization (LVQ) <ref type="bibr" target="#b60">[61]</ref> were applied to the acoustic modeling. Typical examples of such applications are categorized as follows, based on system structure and training methods. 2) A hybrid of an ANN and nonlinear dynamic time warping (DTW).</p><p>a) ANN classifiers with a time-delay structure were used for front-end processing of DTW <ref type="bibr" target="#b73">[74]</ref>. b) FFN estimation of local probabilities of discriminative HMM's were used for front-end processing of DTW <ref type="bibr" target="#b15">[16]</ref>. c) DTW was used for front-end processing of ANN static pattern classifiers <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b91">[92]</ref>.</p><p>3) A discriminative HMM based on ANN design concepts.</p><p>a) LVQ was used for designing the codebook of a discrete HMM <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b108">[109]</ref>. b) Empirical training rules similar to LVQ were applied to the design of the mean vectors of the Gaussian distributions of a continuous (Gaussian) HMM <ref type="bibr" target="#b74">[75]</ref>. c) The concept of a recurrent network was applied to an HMM, and discriminative HMM classifiers were designed by using a training objective, which is equivalent in its fundamentals to the maximization of mutual information <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b77">[78]</ref>.</p><p>Actually, these methods led to successful results to some extent. However, as cited before, the resulting recognizers were not necessarily satisfactory. There are two likely causes. The first is that, as summarized in the following, the discriminative training procedures used therein were mathematically inadequate.</p><p>1) Empirical rules such as error correction learning and LVQ did not have enough of a mathematical basis to guarantee design optimality.</p><p>2) The mathematical properties, such as training convergence, of an adaptive version of the error-back propagation (EBP) used for designing the FFN's were unclear. Note that here the term "adaptive" means a procedure in which learning (adjustment) was performed every time one design sample was presented. 3) As is well known, the minimization of the squared error (MSE) loss between a classifier output and its corresponding supervising signal is not necessarily equivalent to the minimization of misclassifications <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b38">[39]</ref>. 4) The maximization of mutual information does not necessarily imply the minimization of misclassifications (see Section IV).</p><p>The second possibility is that improvement efforts were too limited to acoustic modeling and lacked the global scope of designing an overall recognizer. With this in mind, we reexamine the classifier examples introduced above and recategorize them according to the location of the DFA-based design execution in Fig. <ref type="figure" target="#fig_2">2</ref>. Fig. <ref type="figure" target="#fig_2">2</ref>(A) illustrates a method of using DFA to increase the classification accuracy of short speech fragments, each being merely a part of the input feature pattern (usually consisting of one or several adjacent feature vectors). The original input dynamic feature pattern is first mapped to a new dynamic pattern by using highly discriminative (DFA-designed) fragment models, then this new pattern is classified with DTW; that is, this acoustical modeling is performed using a hybrid form of the highly discriminative modeling of short fragments and the DTWbased concatenation of these models. Note here that the effort made to increase classification capability does not bear directly on the classification of the overall dynamic pattern, and also that the DTW process is based on the minimum distortion or ML principles, which is not necessarily relevant to an increase of classification accuracy. It is therefore obvious that this improvement attempt is not consistent with the optimal classification of the dynamic pattern. On the other hand, Fig. <ref type="figure" target="#fig_2">2</ref>(B) illustrates a method of first mapping the input dynamic pattern to a static pattern with DTW and then performing classification with highly discriminative acoustic models, which are designed for this new static pattern representation. Here, the static pattern models are designed based on a minimum loss principle (e.g., MSE loss) that is different from the minimization of classification error counts. It is thus obvious that these hybrid methods are also inconsistent with the optimal structure for classifying the dynamic pattern. The method shown in Fig. <ref type="figure" target="#fig_2">2</ref>(C) trains HMM parameters by using a discriminative training method, aiming at a direct increase of dynamic pattern classification accuracy. This is clearly a more advanced approach than before because it attempts to directly improve the HMM acoustical models corresponding to the dynamic pattern representation. However, the figure obviously shows that even this method suffers from the problem of narrow design scope, as had the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Motivation of GPD Development and Paper Organization</head><p>From the above survey, one may recognize the necessity of a novel design method for pursuing the overall optimality of a recognizer that covers the acoustic modeling process as well as the feature extraction and language modeling processes. Note here that although we have discussed the problems in speech recognition, most of the arguments hold true in many other cases of pattern recognition. The development of GPD was motivated by such circumstances in the problems of pattern recognizer design.</p><p>GPD relies on traditional adaptive discriminative training, which is called the probabilistic descent method (PDM) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, for pattern classification. In the early stage of development, GPD was formalized as a training algorithm for classifiers <ref type="bibr" target="#b53">[54]</ref>. It was then extended to a more general method for designing an entire recognizer, e.g., <ref type="bibr" target="#b57">[58]</ref>; it was also extended to particular tasks such as keyword spotting, e.g., <ref type="bibr" target="#b62">[63]</ref>; it was applied to speaker recognition as well, e.g., <ref type="bibr" target="#b65">[66]</ref>. Its extension through such continued research efforts has resulted in a novel family of discriminative training methods, members of which are based upon the original formalization concept of GPD.</p><p>In this paper, we shall comprehensively present the GPD-based approach to pattern recognizer design. The paper is organized as follows. Following the development history of the original formalization of GPD and its extensions, we start our description by focusing on design problems in pattern classification. In Section II, we provide the fundamentals of the conventional, DFAbased pattern classification, and discuss the background of GPD development. In Section III, we introduce GPD. Its formalization and mathematical nature, such as the training optimality, are described in detail. So as to maintain the concreteness of the formulation as well, we focus in this section on classifier design problems using a multiple reference distance classifier which has long been used for speech pattern classification and is the structure for the LVQ pattern quantizer. In Section III we also summarize the concept of minimum classification error learning (MCE), which is closely related to the GPD formalization and has a significant theoretical contribution to pattern classification study <ref type="bibr" target="#b51">[52]</ref>. In Section IV we discuss the relationship between GPD and existing design methods. In Section V we introduce derivatives of GPD, or in other words, algorithms based on extensions of the GPD concept. The paper is then concluded in Section VI. Several additional issues related to GPD implementation are finally provided in the Appendixes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DISCRIMINATIVE PATTERN CLASSIFICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Bayes Decision Theory</head><p>We first summarize the Bayes decision theory, which underlies most approaches to pattern classification, including the DFA approach. We assume for simplicity of discussion that given an observed feature pattern sample, we aim to classify it accurately. What is "accuracy" here? The meaning of this common term is not necessarily clear for a particular operation of classification. A significant contri-bution of the Bayes decision theory is to give this accuracy a general statistics-based definition, i.e., the minimum expected loss (risk) situation, and to show that this situation can be achieved by observing the Bayes decision rule.</p><p>For the general task of classifying -class patterns, the Bayes theory is formulated as follows (see <ref type="bibr" target="#b28">[29]</ref> for details). According to the conventional approach in this theoretical framework, we assume a sample to be static. A static feature pattern is given. To measure the accuracy, the theory first introduces an (individual) loss that is incurred by judging the given pattern's class to be one of the possible classes, where denotes the classification operation, as in <ref type="bibr" target="#b0">(1)</ref>. It is obvious that the accuracy of the task should be evaluated over all of the possible samples. Thus, based on statistics, the theory next introduces an expected loss incurred by classifying called the conditional risk, as <ref type="bibr" target="#b3">(4)</ref> and also introduces an expected loss associated with called the overall risk, as <ref type="bibr" target="#b4">(5)</ref> where is the following indicator function</p><formula xml:id="formula_2">(if is true) (otherwise). (<label>6</label></formula><formula xml:id="formula_3">)</formula><p>The accuracy is accordingly defined by the overall risk.</p><p>The smaller the overall risk, the better its corresponding classification result. A desirable decision is thus the very one that minimizes the overall risk. Consequently, the theory leads to the following well-known Bayes decision rule that is justified by <ref type="bibr" target="#b4">(5)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule 1 (Bayes Decision Rule):</head><p>To minimize the overall risk, compute all of the possible conditional risks and select the for which is minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Minimum Error Rate Classification</head><p>Using the loss enables one to evaluate classification results flexibly. This is one of the big attractions of the Bayes decision theory. However, in practice, a loss that evaluates results uniformly for all of the possible classes (i.e., class-independent loss) has been used widely due to the difficulty of setting losses in a reasonable class-by-class manner. A natural loss in this simple case is the following error count loss:</p><p>(otherwise) <ref type="bibr" target="#b6">(7)</ref> and then its corresponding conditional risk becomes <ref type="bibr" target="#b7">(8)</ref> and the overall risk becomes the average probability of error. Thus, the minimization of the overall risk using <ref type="bibr" target="#b6">(7)</ref> leads to the minimization of the average probability of error, or in other words, the minimum error rate classification (e.g., <ref type="bibr" target="#b28">[29]</ref>). According to the above Bayes decision rule, it is obvious that the desirable classification decision is the one that minimizes the conditional risk <ref type="bibr" target="#b7">(8)</ref>, or maximizes the a posteriori probability As far as minimum error classification is concerned, the best classifier design is theoretically achieved by simulating (8) as accurately as possible. Hence this way of thinking justifies the Bayes approach of aiming at a correct estimation of the a posteriori probability, or its corresponding a priori probability and conditional probability. Note here that we assume the Bayes approach includes the ML method and the so-called Bayesian approach <ref type="bibr" target="#b28">[29]</ref>. The principal attraction of the Bayes approach may be that the classifier design is primarily based on a mathematically well-analyzed probability computation. However, in realistic situations where only limited resources are available, an accurate estimation of these probability functions is difficult, and generally this approach does not achieve satisfactory design results.</p><p>Originally, the probability functions are given for the task at hand. In the Bayes approach, the classifier design is replaced by the estimation of these functions. Taking into account the fact that these given functions are unobservable and essentially difficult to estimate accurately, one may have to find an alternative approach to the design; that is, one can consider that the design is to execute an accurate evaluation based on (7) for every sample. This is the very concept of DFA design. However, unfortunately, this point of view has not been explicitly indicated in most conventional DFA design attempts. Usually, the design formalization has started with (3), i.e., merely selecting arbitrary discriminant functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discriminant Function Approach</head><p>Let us discuss in more detail the DFA design for a task of classifying the static pattern</p><p>The decision rule is iff <ref type="bibr" target="#b8">(9)</ref> As cited before, DFA design is fundamentally performed in a competitive way (with regard to classes), aimed at realizing the discriminant function set (consequently that achieves the least classification error over the design sample set. Its implementation is basically characterized by the following factors:</p><p>1) functional form of the discriminant function (classifier structure or measure); 2) design (training) objective; 3) optimization method; 4) consistency with unknown samples (robustness, generalization capability, or estimation sensitivity).</p><p>Classifier structure, which determines the type of is generally selected based on the nature of the patterns, and this selection often determines the selection of the measure or the selection of</p><p>The linear discriminant function is a typical example of a classical classifier structure, and the measure used therein is a linearly-weighted sum of input vector components. A distance classifier that uses the distance between an input and a reference vector as the measure is another widely used example.</p><p>The design objective is a function used for evaluating a classification result in the design stage and is equivalent to the concept of risk in Bayes decision theory. Usually, an individual loss that is a design criterion for an individual design sample is first introduced; the individual loss for is denoted by As discussed in the previous section, a natural loss form is the classification error count as (otherwise) <ref type="bibr" target="#b9">(10)</ref> where the fact that is included in the loss definition means that the individual loss is a function of Next, similar to the overall risk, an ideal overall loss, i.e., the expected loss, is defined using the individual loss as <ref type="bibr" target="#b10">(11)</ref> However, since sample distributions are essentially unknown, it is impossible to use this expected loss in practice. For this reason, an empirical average loss is usually used, as defined in the following: <ref type="bibr" target="#b11">(12)</ref> where of explicitly means that the sample is the th sample of the finite (consisting of samples) design sample set</p><p>In the case of using the error count loss of <ref type="bibr" target="#b9">(10)</ref>, this empirical average loss becomes the total count of classification errors measured over</p><p>In addition to <ref type="bibr" target="#b9">(10)</ref>, several different forms of loss have been used, e.g., perceptron loss, squared error loss (between a discriminant function and its corresponding supervising signal), and mutual information. However, these are merely temporary expedients, and it is known that the design results obtained by using them are not necessarily consistent with minimum classification error probability condition (e.g., see <ref type="bibr" target="#b28">[29]</ref>; also see Section IV-B for the use of mutual information).</p><p>Optimization is a method of finding the state of that minimizes loss over and its embodiments are grouped into a heuristic method and a mathematically proven algorithm.</p><p>Among the many examples of heuristic optimization, error correction training has been widely used (e.g., see <ref type="bibr" target="#b78">[79]</ref>). Most of these heuristic methods do not guarantee, however, the achievement of a true optimal situation due to the lack of a theoretical justification.</p><p>The mathematically proven methods are further grouped into ones which search for locally optimal conditions and ones which search for a globally optimal condition. Traditionally, a practical, gradient search-based, local optimization method such as the steepest descent method has been used. In recent ANN frameworks, global optimization methods, such as simulated annealing and its special case, called the Boltzmann machine, have also been extensively studied <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b90">[91]</ref>. Their fundamental capability of globally optimizing the objective function is fascinating, even though the optimization is done in a probabilistic sense. Moreover, these ANN-related methods do not require the continuity, or the smoothness (being at least the first differentiable in system parameters), of the loss function (see the following paragraphs in this section and Section II-D3). In fact, simulated annealing was applied to the minimization of the unsmooth, average empirical loss based on <ref type="bibr" target="#b9">(10)</ref>  <ref type="bibr" target="#b3">[4]</ref>. However, these global optimization methods are usually impractical due to their time-consuming nature.</p><p>Optimization methods are categorized from another point of view, i.e., the batch type search versus the adaptive search. The batch type search aims to minimize (or locally minimize) the average empirical loss. The steepest descent method is a typical example of the batch type local minimization method. The adaptive search minimizes the individual loss for a small set of design samples (usually one sample) randomly selected from the adjustment of is repeated while changing this set of samples. Methods based on stochastic approximation are traditional examples of adaptive local minimization (e.g., <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b31">[32]</ref>).</p><p>Ideally, the purpose of classifier design is to realize a state of that leads to accurate classification over all of the samples of a task at hand instead of the given design samples. Remember that the expected loss was defined as an ideal overall loss. Thus it is desirable that the design result obtained by using design samples be consistent with unknown samples too. Obviously, the pursuit of such a result for unknown data requires some assumptions concerning unobservable, unknown samples or about the entire sample distribution of the task. In contrast with the Bayes approach, measures to increase the consistency in DFA are generally moderate: the loss is individually defined for every design sample, and the design is essentially formed using the given design samples, as shown in the use of the average empirical loss <ref type="bibr" target="#b11">(12)</ref>.</p><p>Naturally, the most practical method of DFA is to search for the state of that corresponds to the minimum of the average empirical loss consisting of <ref type="bibr" target="#b9">(10)</ref>. However, <ref type="bibr" target="#b9">(10)</ref> is not a smooth function (not differentiable in Thus, the corresponding average empirical loss may be difficult to minimize directly. Moreover, this average empirical loss is sensitive only to design samples (see Section III-C), which means that a design using this loss may not clearly contribute to increasing the consistency with unknown samples. Consequently, a fundamental improvement for DFA is desired.</p><p>We have considered the classification of static patterns in this section. The issues discussed above also hold true in the classification of dynamic speech patterns: the discussion does not depend upon the static nature of patterns. Hence, the most effective design method for dynamic pattern classification can again be the local minimization of the average empirical, classification error count loss. Detailed discussions about dynamic pattern classification will be given in Section II-D3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Probabilistic Descent Method</head><p>1) Formalization: Almost 30 years ago, PDM was developed as a practical method for locally minimizing the expected loss based on the gradient search <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. In particular, its minimization mechanism is based on sto-chastic approximation. Clearly, this method can be applied to locally minimizing the practical, average empirical loss consisting of individual classification error count losses. The use of stochastic approximation for pattern classification has a long history and, in fact, many studies have been done to deal with it, as shown in <ref type="bibr" target="#b28">[29]</ref> and <ref type="bibr" target="#b31">[32]</ref>. However, PDM is clearly distinguished from other stochastic approximation-based methods by the following two points.</p><p>1) It proves that the reduction of individual losses leads to a reduction of the expected loss in the probabilistic sense.</p><p>2) It proposes a design concept that enables the classifier design problem to be handled systematically by incorporating the classification process in a three-step functional formalization.</p><p>Our purpose in this section is to show the background of GPD development by reviewing classical PDM. Let us consider the previous -class pattern classification task. It is assumed in PDM that a pattern is static. As cited in Section I-D, we use a distance classifier consisting of multiple reference vectors as our formalization framework:</p><p>where is the th closest reference vector of (in the sense of squared Euclidean distance to an input pattern described later) defined in the same vector space as and is the number of 's reference vectors. The classification rule that we consider is iff <ref type="bibr" target="#b12">(13)</ref> which is essentially the same as (3). Suppose our design is to be done adaptively; that is, we update the classifier parameters every time one design sample is presented, and we pursue the optimal status of the parameters by repeating this updating procedure. Let us assume that of is presented at the design stage time index (natural number). PDM is then formalized in the following three-step manner.</p><p>The first step is to choose the discriminant function Naturally, for every class, we define the function as the squared Euclidean distance between the input and its closest reference vector where <ref type="bibr" target="#b13">(14)</ref> In the second step, a misclassification measure is introduced so as to emulate the decision process of (13), i.e., the comparison/decision among the competing classes <ref type="bibr" target="#b14">(15)</ref> where is a set of confusing classes defined as <ref type="bibr" target="#b15">(16)</ref> and is the number of classes. Note in ( <ref type="formula">15</ref>) that ( <ref type="formula">13</ref>) is represented by a scalar value decision. A positive value of means a misclassification, and a negative value means a correct classification.</p><p>The third step conforms to the same loss evaluation as DFA. The misclassification measure is embedded in a loss in order to evaluate the corresponding classification result. A general form of the loss is represented as <ref type="bibr" target="#b16">(17)</ref> where is a monotonically increasing function. Various definitions of the loss are possible; for example (otherwise) ( <ref type="formula">18</ref>) and <ref type="bibr" target="#b18">(19)</ref> where and are positive numbers. The loss in ( <ref type="formula">19</ref>) is a linear approximation of the classification error count. In particular, the loss in <ref type="bibr" target="#b17">(18)</ref> approximates the classification error count when similarly, the loss in ( <ref type="formula">19</ref>) approximates the classification error count when</p><p>2) Probabilistic Descent Theorem: The PDM training by which the parameters are adjusted through the above threestep formalization is summarized in the following probabilistic descent theorem.</p><p>Theorem 1 (Probabilistic Descent Theorem): Assume that a given design sample belongs to If the classifier parameter adjustment is specified by <ref type="bibr" target="#b19">(20)</ref> where is a positive-definite matrix and is a small positive real number, then <ref type="bibr" target="#b20">(21)</ref> Furthermore, if an infinite sequence of randomly selected samples is used for learning (designing) and the adjustment rule of ( <ref type="formula">20</ref>) is utilized with a corresponding [learning] weight sequence which satisfies</p><formula xml:id="formula_4">(22)<label>(23)</label></formula><p>then the parameter sequence (the state of at according to <ref type="bibr" target="#b23">(24)</ref> converges with probability one to which is at least a local minimum of The nature of the adjustment convergence, such as accuracy and speed, is analyzed in detail in <ref type="bibr" target="#b1">[2]</ref>.</p><p>It is obviously unrealistic to rigidly observe the infinitely repeated probabilistic descent adjustments. In practice, the learning coefficient is often approximated by a finite monotonically decreasing function such as <ref type="bibr" target="#b24">(25)</ref> where is a preset number of adjustment repetitions. In particular, when the individual loss of ( <ref type="formula">19</ref>) is used and is assumed for simplicity to be a unit matrix, the adjustment rule for our multireference distance classifier is given "speciously" (the reason for using this particular "critical" term will be shown later) as follows. If and only if holds for and for and otherwise</p><p>The probabilistic descent theorem shows that an infinite repetition of the adjustment <ref type="bibr" target="#b19">(20)</ref> based on the gradient computation of the individual loss for one training sample leads to a local minimum of the expected loss. Using an infinite number of samples is essentially equivalent to a situation in which the corresponding sample distribution is accessible. Therefore, criticizing that the minimum classification error probability status is known in this ideal situation, one may doubt the technical significance of PDM (or the methods based on the stochastic approximation).</p><p>However, the contribution of PDM is clear. In reality, design samples are finite and it is impossible to know the minimum classification error probability situation. In the Bayes approach, the estimation of the class distributions obviously suffers from estimation errors that may spread over the entire sample space instead of the region near the class boundaries. Note here that accurate classification relies on an accurate estimation of the class boundary. In contrast with this approach, PDM aims to minimize the average empirical loss in a manner that corresponds directly to the classification task [the classification rule (13)]; in particular, PDM design using <ref type="bibr" target="#b18">(19)</ref> will minimize the actual classification error count, resulting in an accurate class boundary estimation. This point is clearly distinct from other DFA methods as well as the Bayes approach when the exact distribution form is not known to the designer. If this minimization (even the local minimization) is done successfully, the resulting classification performance should be superior to that of the Bayes approach. Moreover, though finite, a huge number of design samples are often used. In fact, it is often difficult to store all of the design samples for training. Given a finite set of design samples the PDM adjustment will be repeated by extracting a sample randomly from Furthermore, it is often desired that a classifier be adaptable to new circumstances in a realistic situation where future samples cannot be observed in the design stage. PDM provided a fundamental solution based on simple gradient computation to this adaptive design. Therefore, the true fundamental value of PDM should be widely recognized, even though the practical aspects of its adaptive learning mechanism must be further investigated.</p><p>Recall the adaptive training version of EBP and LVQ. Both are useful but have only intuitive validity (meaning that the convergence mechanism has not been mathematically elaborated). One should note that the probabilistic descent adjustment is quite similar to adaptive EBP <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b4">[5]</ref>. In fact, the adjustment principle of adaptive EBP is to locally minimize the loss for a given design sample according to its gradient; also, the mechanism of error back-propagation is simply a special case of differential calculus for a functional embedded in a smooth functional form. Moreover, one should note that (26) closely resembles LVQ, especially an improved version of LVQ2 <ref type="bibr" target="#b68">[69]</ref>. Furthermore, the monotonically-decreasing learning weight function used in these learning methods is essentially the same as <ref type="bibr" target="#b24">(25)</ref>. Thus, it appears that PDM may be useful for analyzing these recent implementations of DFA.</p><p>3) Problems: Encouraged by the advantages of PDM, i.e., the direct minimization of the classification error count and the use of an adaptive training mechanism, which were described in the last few paragraphs of Section II-D2, one might attempt to classify dynamic patterns with PDM. However, PDM is a method for the classification of static patterns. Some additional procedures will thus be needed for applying this method to dynamic pattern classification. Furthermore, the formulation of PDM actually suffers from a mathematical difficulty. Solving this inadequacy was the motivation for the development of the more general GPD. In this section, we clarify the problems of PDM.</p><p>Recall that we used the critical term "speciously" in the derivation of <ref type="bibr" target="#b25">(26)</ref>. Actually, the derivation is mathematically impossible.</p><p>The probabilistic descent adjustment rule is based on gradient computation. The overall process included in the formulation must thus be differentiable. However, the "min" operation selecting the closest reference vector, in <ref type="bibr" target="#b13">(14)</ref>, is not a differentiable function; can change discretely when changes, with the result that the misclassification measure is also discontinuous. It then becomes apparent that the PDM formalization is inadequate. To apply the probabilistic descent adjustment in the right way, this lack of smoothness must therefore be overcome.</p><p>One should note that the above smoothness difficulty does not appear in some special cases. In fact, the problem concerning <ref type="bibr" target="#b13">(14)</ref> does not occur for a classifier that represents each class by only one reference pattern. Moreover, the problem concerning ( <ref type="formula">14</ref>) does not occur in a two-class task However, these are very limited and unrealistic situations. A satisfactory method should be able to handle general and realistic tasks.</p><p>Let us next consider the task of classifying spoken English letter syllables, such as and by using a distance classifier. We assume here that each syllable is uttered in an isolated mode and is converted to an acoustic feature vector sequence with some preset feature extractor. It is also assumed that speech signal is correctly extracted from its surrounding signal and input to the system. A dynamic pattern to classify is then represented as <ref type="bibr" target="#b26">(27)</ref> where is the fixed -dimensional component vector (usually corresponding to an acoustic feature vector or a short sequence of such acoustic feature vectors) at the time ( where is a fixed natural number), and is a variable but finite natural number that represents the duration of the component vector sequence.</p><p>A simple application of PDM for classifying this dynamic speech pattern would be similar to the structural hybrid system described in Section I; i.e., PDM would be used to increase the discriminative power of a distance classifier consisting of reference vectors defined in the samedimensional component vector space, and DTW would be incorporated with this classifier in order to handle the dynamics of the entire input pattern. However, this local improvement of classification capability is not necessarily consistent with improvement of classification accuracy for the dynamic pattern. Thus, a natural solution to this problem must be to improve the overall classification process, including the dynamics normalization of a DTW distance classifier (which has long been used in speech pattern classification) by using PDM.</p><p>A DTW distance classifier is generally given as <ref type="bibr" target="#b27">(28)</ref> where is 's th finite-length dynamic reference pattern. <ref type="foot" target="#foot_2">2</ref> The distance computation based on the DTW procedure between dynamic patterns is used for the classification decision. First, a DTW matching path and its corresponding path distance is introduced between an input pattern and each reference pattern. The path distance is given as <ref type="bibr" target="#b28">(29)</ref> where is the th component vector of to which the th component vector of corresponds along the th matching path of which is a local distance defined by the squared Euclidean distance between these corresponding component vectors (note that the local distance can be defined by using any other reasonable distance measure); is a weight coefficient. Next, using the path distances, the distance between an input and each reference pattern, i.e., a reference pattern distance, is defined as the smallest (best) path distance for each reference pattern <ref type="bibr" target="#b29">(30)</ref> Usually, the search for the smallest path distance is performed by dynamic programming (DP). Lastly, the discriminant function that represents the degree to which an input belongs to each class is defined as the reference pattern distance of the closest [in the sense of ( <ref type="formula">30</ref>)] reference to the input where <ref type="bibr" target="#b30">(31)</ref> The most direct use of PDM for this classifier is to adjust by using the discriminant function <ref type="bibr" target="#b30">(31)</ref>. However, ( <ref type="formula">31</ref>) is doubly unsmooth: this new discriminant function includes the unsmooth operation of "min" in both the best path search and the closest reference search. Obviously, there is a fundamental difficulty in designing the DTW distance classifier with PDM in its original form.</p><p>However, the reason for the difficulty in applying PDM to dynamic pattern classification is the same as the problem included in the formulation of the PDM training method. The fundamental problem to be solved is that the functions used are discontinuous, i.e., not differentiable in Therefore, we come naturally to the motivation for the development of GPD, which is to reformulate PDM using some smoothing function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GENERALIZED PROBABILISTIC DESCENT METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Formalization Concept</head><p>The fundamental concept of the GPD formalization is to directly embed the overall process of classifying a dynamic pattern of speech acoustic vectors in a smooth functional form (at least first order differentiable with respect to classifier parameters) that is suited for the use of a practical optimization method, especially gradient search optimization <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b55">[56]</ref>. As can be easily noticed from the previous discussions, a key point for achieving this formalization is to overcome the discontinuity of PDM. For this purpose, GPD uses the norm form and a sigmoidal function that is widely used in ANN implementations.</p><p>Similar to PDM, GPD uses an adaptive update mechanism. However, the above formalization concept can be achieved, without any lack of formal rigor, even using a batch-type optimization such as the steepest descent method. Clearly, the selection of optimization methods is distinct from the formalization of the emulation of the classification decision process.</p><p>In the following subsection, we present in detail an embodiment of GPD for the distance classifier, defined by <ref type="bibr" target="#b27">(28)</ref>, for the task used in Section II-D3, i.e., the classification of class feature vector sequence patterns, each corresponding to an isolated spoken syllable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. GPD Embodiment for Distance Classifier 1) Discriminant Function for Dynamic Patterns:</head><p>The problem with PDM in handling dynamic patterns is shown in ( <ref type="formula">30</ref>) and ( <ref type="formula">31</ref>), i.e., the discriminant function includes a discontinuous search for the closest reference and for the best matching path. To solve this, GPD defines the discriminant function as <ref type="bibr" target="#b31">(32)</ref> where is a generalized reference pattern distance between and and is a positive constant; also it defines this generalized reference pattern distance as <ref type="bibr" target="#b32">(33)</ref> where is the path distance of ( <ref type="formula">29</ref>) and is a positive constant. Accordingly, the method achieves a smooth discriminant function for the dynamic pattern by replacing the two "min" operations by the norm form functions. The use of the norm form affords us an interesting flexibility in the implementation. Let and approach Then, clearly, (32) approximates the operation of searching for the closest reference pattern and (33) for operation of searching for the best matching path. Thus, these smooth definitions are generalized versions of the existing search operation.</p><p>2) Formulation: GPD uses the three-step formalization of PDM in order to represent the task at hand (classification in our case) in a smooth functional form. The classification rule here is iff <ref type="bibr" target="#b33">(34)</ref> which is essentially the same as <ref type="bibr" target="#b12">(13)</ref>, except that the pattern is dynamic. We already described the first step of defining the discriminant function; the function is given as <ref type="bibr" target="#b31">(32)</ref>.</p><p>The second step defines a smooth misclassification measure. Among many possibilities, the following is a typical definition for <ref type="bibr" target="#b34">(35)</ref> where is a positive constant. Similar to <ref type="bibr" target="#b14">(15)</ref>, indicates a misclassification and indicates a correct classification. Similar to and controlling enables one to simulate various decision rules. In particular, when approaches <ref type="bibr" target="#b34">(35)</ref> resembles <ref type="bibr" target="#b33">(34)</ref>. The third step of defining the loss is almost the same as in PDM. GPD defines an individual loss as a smooth, monotonically increasing function of the misclassification <ref type="bibr" target="#b35">(36)</ref> There are various possibilities for defining the loss. Among them, the GPD method usually uses a smooth function as <ref type="bibr" target="#b36">(37)</ref> where and are constants. We shall mention the selection of the loss function again later.</p><p>The embodiment is completed by deriving an adjustment rule such as <ref type="bibr" target="#b25">(26)</ref> according to the probabilistic descent theorem. Given a dynamic input pattern at the design stage time index i.e., the resulting adjustment rule using loss <ref type="bibr" target="#b36">(37)</ref> for the reference patterns is given as for for <ref type="bibr" target="#b37">(38)</ref> where</p><formula xml:id="formula_6">(39) (40) (41) (42)<label>(43)</label></formula><p>and indicates the component vector index of to which the th component vector of corresponds along the th matching path of In ( <ref type="formula">38</ref>), the adjustment is done for all of the possible paths and all of the possible reference patterns. This is a remarkable distinction from <ref type="bibr" target="#b25">(26)</ref>, in which the adjustment is selectively done. Furthermore, treating 's as adjustable parameters, one can achieve an adjustment rule similar to <ref type="bibr" target="#b37">(38)</ref>, though we omit the result. See this point in <ref type="bibr" target="#b19">[20]</ref>.</p><p>The rule of ( <ref type="formula">38</ref>) is rather complicated. In the last paragraph of the implementation, we present for informational purposes an extremely simplified version of this rule. That is, letting and approach we can rewrite (38) as for and for and otherwise <ref type="bibr" target="#b43">(44)</ref> where and is the class having the smallest discriminant function value among classes other than i.e., the most likely competing class. This simple result weakens the smoothness policy of the GPD formalization, but it increases its feasibility by focusing on the most likely rival class instead of all rival classes. The rule in <ref type="bibr" target="#b43">(44)</ref> will be referred to later in Section IV-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Design Optimality</head><p>In a realistic situation where only finite design samples are available, the state of that can be achieved by probabilistic descent training is at most a local optimum over a set of design samples. Morever, in the case of finite learning repetitions, does not necessarily achieve even the local optimum solution. However, GPD addresses this problem in a more advanced way than the previous DFA-based methods.</p><p>To discuss this point we consider an illustrative task. The task is to classify one-dimensional static patterns as one of two classes. The distribution of samples is shown on the horizontal axis in Fig. <ref type="figure" target="#fig_3">3</ref>. In the same figure, the classification error count, which is a function of the estimated class boundary position, is also shown. This error count is equivalent to the average empirical loss using <ref type="bibr" target="#b9">(10)</ref> and is a discontinuous step function. Note that the classification error count graph changes only at the locations of the design samples. Moreover, in Fig. <ref type="figure" target="#fig_3">3</ref>, several continuous curves, each corresponding to the average empirical loss using the smooth classification error count loss <ref type="bibr" target="#b36">(37)</ref>, are shown; the difference among these continuous loss curves relies on the value setting of in <ref type="bibr" target="#b36">(37)</ref>. These curves change smoothly, even at positions other than the sample positions, which demonstrates that controlling in <ref type="bibr" target="#b36">(37)</ref> can produce an interesting change in the smoothness of the loss.</p><p>As shown in Fig. <ref type="figure" target="#fig_3">3</ref>, conventional use of the discontinuous loss does not take into account the sample distribution at locations other than the given sample positions. In contrast, GPD substantially incorporates the region around the given samples in the design process by using the smooth representation <ref type="bibr" target="#b50">[51]</ref>. Methods in the Bayes approach usually attempt to solve this sparse sample problem by introducing parametric distribution models. Compared with them, GPD assumes only the continuity of the sample distribution. This modeling is moderate but quite natural. Thus, GPD aims to increase consistency with unknown samples for the estimate of the proper decision boundary simply by making use of the sample distribution's continuity.</p><p>Fig. <ref type="figure" target="#fig_3">3</ref> also suggests a way to alleviate the problems of local optima during training; that is, one sets the smoothing larger in the early stage of training and gradually decreases it as training proceeds <ref type="bibr" target="#b58">[59]</ref>. Learning is first done in a coarse but global search mode and gradually changes to a fine-adjustment search mode. This is similar to the idea in <ref type="bibr" target="#b41">[42]</ref> as well as the simulated annealing global search optimization <ref type="bibr" target="#b34">[35]</ref>.</p><p>Consequently, we can argue that GPD has a larger fundamental possibility of achieving the (global) minimum of the loss than the traditional PDM. This characteristic of GPD can be a useful mathematical framework for advanced analysis, such as for training robustness to unknown samples. It is also worthwhile noting that this characteristic can be applied to the entire recognition problem, as well as for the classification discussed in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Minimum Classification Error Learning</head><p>The ultimate goal of recognizer/classifier design is to find the parameter set that achieves the condition of minimum error. In this section we summarize the results of <ref type="bibr" target="#b51">[52]</ref>, which successfully showed that a GPD-formalization based minimization of the expected smooth classification error count loss, i.e., MCE, possesses a fundamental capability for achieving this minimum error condition. Let us indicate here that this discussion holds true in general approaches to minimum-Bayes-risk recognition as well as in classification.</p><p>To maintain the mathematical rigor of our discussions for handling dynamic patterns, we begin our summary by providing a new probability measure for dynamic patterns. Let us assume that this probability can be computed by an HMM which has been widely used in speech recognition.</p><p>First, let us consider an (unrealistic) case where the true functional form of the probability is known. We assume that a parameter set determining the functional form is We also consider a discriminant function that is computed by the HMM probability <ref type="bibr" target="#b44">(45)</ref> The classification rule used here is (2). Then, for example, defining the misclassification measure as <ref type="bibr" target="#b45">(46)</ref> we can rewrite the expected loss, defined by using the smooth classification error count loss <ref type="bibr" target="#b36">(37)</ref> in the GPD formalization, as follows: <ref type="bibr" target="#b46">(47)</ref> where is the entire sample space of the dynamic patterns 's, and it is assumed that Controlling the smoothness of functions such as norm and the sigmoidal function, we can arbitrarily make closer to the last equation in <ref type="bibr" target="#b46">(47)</ref>. Note here that we use Based on this fact, the status of that corresponds to the minimum of in <ref type="bibr" target="#b46">(47)</ref> (which is achieved by adjusting ) is clearly equal to the that corresponds to a true probability, or in other words, achieves the maximum a posteriori probability condition. Accordingly, the minimum condition of can become arbitrarily close to the minimum classification error probability <ref type="bibr" target="#b47">(48)</ref> where is a partial space of that causes a classification error according to the maximum a posteriori probability rule, i.e., <ref type="bibr" target="#b48">(49)</ref> The above result is quite interesting, since it shows that one can achieve the minimum classification error probability situation with DFA. However, the assumption that is known is obviously unsatisfactory, similar to the criticism of the Bayes approach. Recent results concerning the ANN's approximation capability have provided useful suggestions for studying this inadequacy. In the literature, e.g., <ref type="bibr" target="#b32">[33]</ref>, it was shown that the three-layer perceptron has the fundamental capability of approximating an arbitrary function. In <ref type="bibr" target="#b39">[40]</ref> and <ref type="bibr" target="#b83">[84]</ref> it was also shown that the radialbasis function (RBF) network had universal approximation capability. Furthermore, a mixtured Gaussian distribution function was shown to approximate an arbitrary function in the sense of the minimum norm distortion <ref type="bibr" target="#b94">[95]</ref>. Based on these results, one could argue that an HMM with sufficient adjustable parameters has the fundamental capability of modeling an [unknown] true probability function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>If</head><p>(and ) has a unique minimum, and if and (and ) are monotonic to each other, then the minimum corresponds to the case in which is equal to the true probability function. Thus, it follows that under this assumption, which is softer (more realistic) than that in the preceding paragraph, DFA enables one to fundamentally achieve minimum classification error probability, even if the true parametric form of the probability function is unknown.</p><p>The preceding discussions assumed the impractical condition that sufficient design samples and classifier parameters are given, allowing the remarkable results concerning the fundamental capability of DFA to be shown. However, one should notice that MCE shows a high degree of utility and originality in practical circumstances in which only finite resources are available. In fact, the more limited the design resources are, the more distinctive from others the MCE result is: MCE always directly pursues the minimum classification error situation, conditioned by given circumstances, while the Bayes approach aims at estimating the entire probability function and, moreover, the conventional DFA methods aim at minimizing the average empirical loss, which is not necessarily consistent with the classification error count. It may be appropriate in such practical circumstances to treat the probability form discriminant function as a class membership function that expresses the possibility that the input belongs to its corresponding class, instead of as an estimate of probability concerning sample distribution <ref type="bibr" target="#b82">[83]</ref>. This type of understanding would greatly help to extend the application range of MCE.</p><p>The above argument is independent of the selection of practical minimization methods, such as the probabilistic update of GPD. Instead, an essential point included therein is the use of the three-step formalization of GPD and the smooth classification error count loss such as <ref type="bibr" target="#b36">(37)</ref>. This interpretation is the reason why we refer to the result in <ref type="bibr" target="#b51">[52]</ref> as MCE and distinguish it from GPD.</p><p>Although MCE is a somewhat separate concept from GPD, as shown above, it is quite natural that an implementation of GPD design uses the smooth classification error count loss. Actually, most GPD applications use this smooth classification-oriented loss, and such combined usage is often referred to as an MCE/GPD training, e.g., <ref type="bibr" target="#b57">[58]</ref>. In the rest of this section and in Section IV, we use the combined naming, MCE/GPD, so as to make clear the fact that the GPD implementations introduced therein each use a smooth classification error count loss such as <ref type="bibr" target="#b36">(37)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Speech Recognition Using MCE/GPD-Trained Distance Classifiers</head><p>Let us examine the power of MCE/GPD by summarizing speech pattern classification results produced by the multireference distance classifier represented in (28) <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b61">[62]</ref>. The adjustment rules used were basically the same as <ref type="bibr" target="#b37">(38)</ref> and <ref type="bibr" target="#b43">(44)</ref>. The task was to classify nine-class spoken American E-rhyme letter syllables. In most of the experimental settings of <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, and <ref type="bibr" target="#b61">[62]</ref>, for a step-bystep analysis only the reference patterns were considered to be adjustable, while the weights 's were fixed to a constant value of one. Results for the training of the weights were reported in <ref type="bibr" target="#b18">[19]</ref> and <ref type="bibr" target="#b19">[20]</ref>. For simplicity, the smoothing of the sigmoidal error count loss was fixed, and the learning factor was set to a finite sequence of small, monotonically decreasing numbers, as in <ref type="bibr" target="#b24">(25)</ref>, i.e., the training did not use the global optimum search strategy described in Section III-C. Instead, the reference patterns were initialized by using the conventional, modifiedmeans clustering, which basically relies on the minimum distortion design principle: it was expected that this initialization reduced the risk that the GPD-based gradient search would fall into a local optimum.</p><p>The data of this task consisted of the nine-class E-rhyme letter syllables: b, c, d, e, g, p, t, v, z Each sample was recorded over dial-up telephone lines from 100 (50 male and 50 female) untrained speakers. The sampling rate was 6.67 kHz, and each sample was converted to a sequence of 24-dimensional acoustic feature vectors (12 cepstral coefficients and 12 delta-cepstral coefficients) by shifting a time window of 300 samples with a window overlap of 200 samples. Speaking was done in isolated mode. Since all of the samples included the common phoneme and were recorded over telephone lines, this task was rather difficult. Recognition experiments were done in multispeaker mode, i.e., each speaker uttered each of the -set syllables twice, once for designing and once for testing. Thus, for every class, the design and testing data sets consisted of 100 samples, respectively.</p><p>Let us first observe the classification results with the conventional, modified -means clustering that was used for initialization. The following classification rates are all obtained over the unknown testing data. The comparison in resultant accuracy (classification rates) between the conventional method and MCE/GPD will illustrate the effectiveness of MCE/GPD.</p><p>According to <ref type="bibr" target="#b61">[62]</ref>, the modified -means clustering results ranged from 55.0%-59.8% in the case of using one reference pattern for every class. MCE/GPD achieved rates ranging from 74.2%-75.4% for the same classifier. In the case of using three reference patterns for every class, the modified -means clustering resulted in the range of 64.1%-64.9%; with 74.0%-77.2% for MCE/GPD. <ref type="foot" target="#foot_3">3</ref>References <ref type="bibr" target="#b18">[19]</ref> and <ref type="bibr" target="#b19">[20]</ref> investigated an implementation somewhat different from ( <ref type="formula">38</ref>) and ( <ref type="formula">44</ref>), using an exponential-form distance measure and also considering the weights 's to be adjustable. Consequently, in these further experiments the classification accuracy increased to 79.4% with the use of only one reference pattern per class and reached a remarkable 84.4% by using four references for every class.</p><p>For comparison, let us summarize the classification results of HMM classifiers, each designed by using the very same acoustic feature extraction module. Each of the HMM systems had a left-to-right, no skip, mixtured Gaussian structure and was designed by the conventional segmental -means clustering. Its accuracy was 61.7% for the five-state and five-component mixtured Gaussian structure, 66.7% for the ten-state and five-component mixtured Gaussian structure, and 69.0% for the 15-state and five-component mixtured Gaussian structure. These results illustrate that the task was quite difficult and that the achievable classification rate of conventional design methods was 70% at most.</p><p>The results clearly demonstrate the high utility of MCE/GPD. In particular, it is worthwhile noting that the method achieved a higher accuracy with the smaller size For example, the MCE/GPD-designed classifier that used only one reference per class had an error rate about three fourths that of the conventionally designed, 12-times larger classifier, which used 12 references per class (see footnote 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Remarks</head><p>Although we have used the task of classifying dynamic speech patterns as our basis for discussing the GPD formalism, one may notice that the resultant MCE/GPD training rules can be used for the classification of various kinds of (static and dynamic) patterns other than speech sounds. In fact, MCE/GPD applications to signals other than speech are being reported in current literature, e.g., <ref type="bibr" target="#b75">[76]</ref>, <ref type="bibr" target="#b92">[93]</ref>, and <ref type="bibr" target="#b106">[107]</ref>. However, every class of signals has its own special nature, and there are also a variety of possible task goals, in other words, a variety of recognition criteria (the Bayes decision rule being one among many). Therefore, we should state here that applying GPD to a new task always requires some (usually small) effort to adapt the basic GPD formulations so that they adequately reflect the unique nature of the signals at hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RELATIONSHIPS BETWEEN MCE/GPD AND OTHERS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Relation with LVQ</head><p>As seen in <ref type="bibr" target="#b60">[61]</ref> and <ref type="bibr" target="#b66">[67]</ref>, several implementations of LVQ have been reported. However, the following fundamental concept of LVQ underlies all of the implementations, that is, only if a given design sample is misclassified and is located near the actual class boundary are the reference patterns of the correct class (of the given sample) and those of some competing classes adjusted so as to increase the possibility of classifying the sample correctly. Moreover, all of them have in common a heuristic window function for restricting the adjustment to the class boundary region.</p><p>Recall the simplified MCE/GPD adjustment rule for the distance classifier, i.e., <ref type="bibr" target="#b43">(44)</ref>. One can easily see that in the circumstances of handling static patterns, this rule is quite similar to an improved version of LVQ, which is characterized as follows <ref type="bibr" target="#b68">[69]</ref>. If and only if a given sample is misclassified and is located in a small region (window) near the actual class boundary, then 1) the closest reference (to the sample) of the correct class is pushed closer to the sample and 2) the closest reference of the best (most probable) competing class is pulled farther from the sample; otherwise no adjustment is incurred. Clearly, the adjustment mechanism of this LVQ training is realized in <ref type="bibr" target="#b43">(44)</ref>. In particular, it is worth noting that the window set in LVQ corresponds to a derivative function of the MCE/GPD's smooth classification error count loss. Consequently, this correspondence proves that in substance, LVQ uses the design objective of classification error count.</p><p>In LVQ, the adjustment was generally performed only when a sample was misclassified. In contrast with this, (44), incorporating <ref type="bibr" target="#b36">(37)</ref>, performs the adjustment when a sample is correctly classified but the corresponding misclassification measure is small (close to zero), i.e., when the certainty of the corresponding classification decision is small. This is a natural result of the MCE/GPD formalization using the smooth decision process. Consequently, this "learning-incorrect" contributes to increasing design robustness <ref type="bibr" target="#b61">[62]</ref>. The effect of "learning-in-correct" is also reported in <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b56">[57]</ref>, and <ref type="bibr" target="#b96">[97]</ref>.</p><p>The close relation between MCE/GPD and LVQ enables us to use many application results of LVQ as circumstantial evidence of the effectiveness of MCE/GPD <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b69">[70]</ref>. The inadequacy of LVQ, which was reported in the literature, e.g., <ref type="bibr" target="#b47">[48]</ref>, may be due to a lack of consistency with regard to the design objective (loss) formulation between a given task and the LVQ training. In most cases, LVQ has been used for reducing the misclassification of static patterns, such as the elemental acoustic feature vectors of the dynamic speech pattern to be classified originally. Solving this inconsistency was one of the motivations for the development of MCE/GPD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relation with Maximization of Mutual Information</head><p>As befits the Bayes decision theory, we have considered classification error count loss in this paper. On the other hand, various other objective functions have also been extensively studied for the sake of increasing classification accuracy. Among them, the use of mutual information has attracted much research interest in speech pattern classification <ref type="bibr" target="#b6">[7]</ref>.</p><p>This approach aims to select the state of so as to increase as much as possible the mutual information between class and a sample which is defined in the following: <ref type="bibr" target="#b49">(50)</ref> Let us consider the effect of maximizing the mutual information in the GPD (instead of MCE/GPD) framework. For convenience, we use a negative value of mutual information. Thus, the goal of GPD design is to minimize this negative measure. The negative mutual information is rewritten as <ref type="bibr" target="#b50">(51)</ref> Here, defining the logarithmic likelihood as the discriminant function, one can treat the bottom line expression of (51) as a kind of misclassification measure <ref type="bibr" target="#b51">(52)</ref> Then, the inequality <ref type="bibr" target="#b52">(53)</ref> holds true, and therefore maximizing the mutual information leads at least to minimizing the misclassification measure <ref type="bibr" target="#b51">(52)</ref>. Consequently, it turns out that a classifier design based on maximizing mutual information has the same effect as a GPD design that uses the misclassification measure <ref type="bibr" target="#b51">(52)</ref> and the linear loss function. Note here that the loss used is not a smoothed error count but a simple linear function of the misclassification measure. Obviously, this method is not guaranteed to be consistent with the minimum classification error condition unless a nonlinear function is imposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Relation with MSE Loss</head><p>Most ANN classifiers have used the squared error between the teaching signal and the classifier output (the value of the discriminant function) as the loss; the design employed therein aims to minimize the expected loss or the average empirical loss, computed by using this individual squared error loss. Similar to the mutual information maximization method, let us consider the nature of this squared error loss minimization method in the GPD framework. First, the squared error loss is represented as <ref type="bibr" target="#b53">(54)</ref> where is a teaching signal which is usually set, for a design sample to</p><formula xml:id="formula_7">(otherwise). (<label>55</label></formula><formula xml:id="formula_8">)</formula><p>The loss is thus rewritten as <ref type="bibr" target="#b55">(56)</ref> Then, we can treat the bottom line expression of ( <ref type="formula">56</ref>) as a kind of misclassification measure (57) It turns out that the reduction of the squared error loss results in the reduction of this misclassification measure. Hence, we can conclude that the MSE leads at least to an optimal situation, in the GPD sense, which is based on the linear loss using the misclassification measure <ref type="bibr" target="#b56">(57)</ref>. Note here again that the loss used is not a smoothed classification error count but a simple linear function of the misclassification measure. Obviously, it is not guaranteed that the resulting status of this method is consistent with that of the minimum classification error condition.</p><p>Equation ( <ref type="formula">57</ref>) is difficult to use as the misclassification measure. Since the second term (of the right-hand side) of ( <ref type="formula">57</ref>), i.e., the average discriminant function of the competing classes, is not normalized by the number of possible classes the design result using this measure is fundamentally affected by the number of classes. Furthermore, since the discriminant function of is compared with the squared values of the other competing class discriminant functions, the scalar decision based on <ref type="bibr" target="#b56">(57)</ref> does not emulate the classification appropriately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DERIVATIVES OF GPD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>The key concept of GPD formalization is to emulate the overall process of a task at hand in a tractable functional form. Actually, the implementation of MCE/GPD presented in Section III properly realized this concept for the task of classifying a dynamic speech pattern. However, in the example task, the pattern to be classified was a priori extracted from its surrounding input signal and was represented in the preset form of an acoustic feature vector sequence. The task defined therein is one simplified and limited case among many. Clearly, the design concept of GPD should be applied directly to more complicated and realistic task situations. For example, the concept of GPD development should be applied to either a connected word recognition task or an open-vocabulary speech recognition task. It should also be applied to the entire process of recognition, which includes the spotting (detection) of target speech sounds, the design of the feature extraction parameters, and the design of the language model. In this light GPD has actually been quite extensively studied, and its original formalization for classification has been dramatically extended to a new family of discriminative design methods which are more suitable for handling complex real-world tasks. In this section, we shall summarize several important members of the GPD family, such as segmental GPD, minimum spotting error learning (MSPE) <ref type="bibr" target="#b62">[63]</ref>, discriminative utterance verification <ref type="bibr" target="#b88">[89]</ref>, discriminative feature extraction (DFE), e.g., <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b57">[58]</ref>, and also introduce application examples of GPD to speaker recognition <ref type="bibr" target="#b65">[66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Segmental-GPD for Continuous Speech Recognition</head><p>Most definitions used in the simple example task of classifying spoken syllables, in Sections II and III, can be applied to a more realistic task of classifying continuous speech utterances. The most important issue in this advanced application is still to embed the entire process of classification in an appropriate GPD-based functional form. For example, for a connected word recognition task, a discriminant function should be defined so as to directly measure the degree to which a connected word sample belongs to its corresponding class. Due to resource restrictions, most continuous speech recognizers employ subword models, such as phonemes, as the basic unit of acoustic modeling, and represent words and connected words by concatenating the subword models. The classification process in this task consequently includes the mechanism of dividing a long input of continuous speech into short subword segments. Also, due to the need for tackling the statistical variation of speech sounds, most present continuous speech recognizers use HMM-based acoustic models. Efforts of applying GPD to continuous speech recognition must appropriately take into account these two requirements, i.e. the segmentation mechanism and the probabilistic modeling. Indeed, the development of segmental GPD was motivated by these concerns <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b52">[53]</ref>.</p><p>Assume the use of a modular connected word recognizer that consists of a feature extraction module and a classification module. Then consider to be speech input to the classifier, where is an acoustic feature vector (observation) at time index Also let be a word sequence that usually constitutes a sentence. Generally, an HMM classifier for is defined by using a first-order -state Markov chain governed by the following manifolds:</p><p>1) a state transition probability matrix where is the probability of making a transition from state to state ; 2) an initial state probability which specifies the state of the system at time index ; 3) an observation emission probability according to a distribution which is usually defined with a mixtured Gaussian distribution.</p><p>Accordingly, assuming that is a set of the above probability parameters, i.e., the state transition probabilities, the initial state probabilities, and the observation emission probabilities, the discriminant function for is given as the following likelihood measure: <ref type="bibr" target="#b57">(58)</ref> where th best word sequence best state sequence according to <ref type="bibr" target="#b58">(59)</ref> and is the joint state-word sequence likelihood.</p><p>The goal of training is to find an optimal that leads to accurate classification of word sequences. Given for training, segmental GPD defines the misclassification measure as <ref type="bibr" target="#b59">(60)</ref> where is the total number of the competing word sequences, different from that will be taken into consideration in training. The training procedure of segmental GPD is then completed by embedding this misclassification measure in the smooth error count loss, as in Section III. Note here that by setting to a small number in <ref type="bibr" target="#b59">(60)</ref>, in other words, by focusing only on a limited number of likely rival classes, one can make the adjustment more simple.</p><p>Clearly, the Markov modeling satisfies the above two requirements for continuous speech recognition: it performs the segmentation process with its state transition mechanism, and it also provides a probabilistic representation framework. A point to note here is that an implementation with probabilistic models should maintain the probabilistic constraint of the model parameters, i.e., the sum of the probabilistic parameters, such as the state transition probability, over all the possible cases should be equal to one. Segmental-GPD thus uses parameter transformation as where <ref type="bibr" target="#b60">(61)</ref> in the parameter adaptation.</p><p>The power of segmental GPD has been demonstrated in several experimental tasks. For example, <ref type="bibr" target="#b23">[24]</ref> reported quite successful recognition results in the nine-class American English E-ryhme task, used in Section III, i.e., an HMM recognizer with ten-state, five-component mixtured Gaussian(/state) models scored 99% over the training data and 88% over the testing data. For the connected word case, <ref type="bibr" target="#b24">[25]</ref> and <ref type="bibr" target="#b25">[26]</ref> reported results in the TI connecteddigit recognition task. In particular, in <ref type="bibr" target="#b25">[26]</ref> the best results reported so far on the database (a string error rate of 0.72% and a word error rate of 0.24% on testing data) were successfully achieved by a segmental GPD-trained, context-dependent subword model system.</p><p>The same design concept employed in segmental GPD, i.e., optimizing to increase recognition accuracy for concatenated word inputs, has been tested in several slightly different ways and has further demonstrated its high utility <ref type="bibr" target="#b71">[72]</ref>, <ref type="bibr" target="#b72">[73]</ref>, <ref type="bibr" target="#b86">[87]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Minimum Error Training for Open-Vocabulary Speech Recognition</head><p>1) Open-Vocabulary Speech Recognition: Spontaneous conversation utterances usually contain speech segments that are not directly relevant to the tasks at hand, such as false-starts, interjections, and repairs, and they also suffer from various acoustic problems such as increased coarticulation. Many large-vocabulary continuous-speech recognizers have been successfully developed for dictationstyle (recognition of read speech) tasks, but the recognition of such casual conversational utterances is still an important research issue <ref type="bibr" target="#b107">[108]</ref>. Actually, it is costly to fully model the highly variable acoustic phenomena of largevocabulary conversational utterances. Therefore, there has been increasingly more interest recently in a practical alternative, i.e., an open-vocabulary paradigm where only selected keywords are to be recognized. Fig. <ref type="figure" target="#fig_4">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>illustrates the mechanism of open-vocabulary speech recognition.</head><p>There are two main approaches to open-vocabulary recognition <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b89">[90]</ref>. The first is keyword spotting based on a threshold comparison. A system prepares keyword models, computes the similarity between a segment of input utterance and each keyword model, and decides whether the segment contains the keyword or not by comparing a similarity value and a preset threshold. The second is to use a continuous-speech recognizer having a "filler" model. In this case, the recognizer attempts to segment and classify an input utterance in the same manner as conventional speech recognizers for isolated or concatenated spoken words do, but here a nonkeyword segment is classified as the class corresponding to the filler model. Note also that here the filler model can fundamentally cover an infinite number of nonkeyword segments, and accordingly, a continuous-speech recognizer with this filler model can run as an open-vocabulary system. There are clear differences between the two approaches, especially in terms of segmentation strategy and implementation approach. However, one can also note that the approaches still have a close link to each other because the similarity comparison between the filler class and keyword classes works as a kind of thresholding operation. Evaluation of these approaches is one of the important on-going research issues in the speech recognition field.</p><p>2) Minimum Spotting Error Learning: Depending upon the decision strategy used for spotting, one can clearly note that spotting performance relies heavily upon the adequacy of the model and the threshold. Conventionally, the model has been designed using ML training, as is done for standard continuous speech recognition, and the threshold has been simply determined in a trial-and-error fashion. Obviously, such an unintegrated design method does not guarantee optimal spotting accuracy. One natural solution to this problem is to design both the model and the threshold jointly in the sense of minimizing spotting errors. In this light, GPD was reformulated as MSPE for keyword spotting in <ref type="bibr" target="#b62">[63]</ref>.</p><p>Since spotting can be done in keyword-by-keyword mode, or in other words independently for each keyword class, in the algorithm described here we will consider a simple task with only one keyword class and thus a spotter (spotting system) that contains a single keyword model (such as reference patterns or HMM's) and its threshold</p><p>The goal of MSPE design is to optimize For clarity of description, we assume to be a referencepattern-based keyword model, i.e., a sequence of reference patterns, each defined in the acoustic feature vector space. A spotting decision is fundamentally done at every time index. Therefore, a discriminant function is defined as a function that measures a distance between a selected segment of input utterance and the model and the spotting decision rule is formalized as: if the discriminant function meets <ref type="bibr" target="#b61">(62)</ref> then the spotter judges at " " that a keyword exists in the segment no keyword is spotted otherwise. Importantly, this type of decision could produce in principle two types of spotting errors: false-detection (the spotter decides that does not include the keyword when actually includes.) and false-alarm (the spotter decides that includes the keyword even when does not include.). Similar to original GPD, the MSPE formalization aims to embed the above-cited spotting decision process in an optimizable functional form and to provide a concrete algorithm of optimization so that one can consequently reduce the spotting errors. The spotting decision process is then emulated as spotting measure which is defined as <ref type="bibr" target="#b62">(63)</ref> where is a short segment which is set for increasing the reliability and stability of the decision around the time position, , is the size of (the number of acoustic feature frames in ), and is a positive constant. A positive value of implies that at least one keyword exists in and a negative value implies that no keyword exists in Decision results are evaluated by using a loss function that is defined by using two types of smoothed functions, illustrated in Fig. <ref type="figure" target="#fig_5">5</ref> </p><p>Fig. <ref type="figure">6</ref>. A speech recognizer with the capability for verifying the word hypotheses produced by a continuous speech recognizer (after <ref type="bibr" target="#b73">[74]</ref> with some simplification).</p><p>approximates: 1) one for one false-detection [the left side of Fig. <ref type="figure" target="#fig_5">5(a)</ref>]; 2) for one false-alarm [the right side of Fig. <ref type="figure" target="#fig_5">5(b)</ref>]; and 3) zero for correct spotting (the right side of and the left side of ), where is a parameter controlling the characteristics of the spotting decision. By setting to one, all of the errors can be treated evenly. By letting be less than one, the system can be tuned toward reduction of false-detection errors, which are often more troublesome than false-alarm errors in many application situations.</p><p>The training procedure of MSPE is accordingly obtained by applying the adjustment rule <ref type="bibr" target="#b23">(24)</ref> of the probabilistic descent theorem to the above-defined functions, i.e., the loss, the spotting measure, and the discriminant function. In <ref type="bibr" target="#b62">[63]</ref>, readers can find its promising aspects, demonstrated in a task of spotting Japanese consonants.</p><p>Even in the open-vocabulary situation, a system is often required to spot a sequence (or set) of keywords instead of only one single keyword. In order to meet this requirement, MSPE was reformulated as the minimum error classification of keyword-sequences method (MECK). See <ref type="bibr" target="#b63">[64]</ref> for details.</p><p>3) Discriminative Utterance Verification: One can easily notice that the keyword spotting procedure is considered a hypothesis testing problem, based especially on Neyman-Pearson testing and a likelihood ratio test (LRT). The design concept of GPD was also used to increase the LRTbased keyword spotting capability of a continuous speech recognizer employing a filler model. Fig. <ref type="figure">6</ref> illustrates a recognizer used for the above-cited spotting purpose. The system consists of two subclassifiers: 1) the target classifier and 2) the alternate classifier. The target classifier labels an input as a sequence of the hypothesized keyword and the out-of-vocabulary filler segments. The alternate classifier then generates an alternate hypotheses for the LRT test at the segment where the keyword is hypothesized by the target classifier. An LRT tests the hypothesis that an input is generated by the model corresponding to the keyword versus , having been generated by an imposter model corresponding to the alternate hypothesis according to the likelihood ratio Accordingly, if the ratio exceeds a preset threshold, the system accepts the hypothesized keyword; otherwise it rejects the hypothesis.</p><p>Obviously, the quality of hypothesis testing relies on the adequacy of the estimated likelihood values. However, similar to most cases of the ML-based speech recognition, it is quite difficult to achieve accurate estimates due to the fact that both the probability density functions and their parameterization forms are often unknown. To alleviate this problem, GPD was used as a design algorithm for directly minimizing the false-detection errors and the false-alarm errors <ref type="bibr" target="#b88">[89]</ref>. Fig. <ref type="figure" target="#fig_6">7</ref> illustrates the GPD-based training scheme of the keyword hypothesis verification, i.e., discriminative utterance verification (DUV). The training first defines a distance based on the likelihood ratio as <ref type="bibr" target="#b64">(65)</ref> One should notice here that a positive value of the distance implies hypothesis rejection and a negative value implies hypothesis acceptance. Thus, a loss is defined so as to embed the two types of errors, i.e., the false-detection and the false-alarm, directly as <ref type="bibr" target="#b65">(66)</ref> where is a smooth monotonic function. Clearly, a training target here is to minimize the loss over possible design samples in the same manner as the other GPD training cases. Refer to <ref type="bibr" target="#b88">[89]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. DFE 1) Fundamentals:</head><p>In the previous sections, we have considered only the GPD applications to the postend decision modules, such as the classification (or identification) module, the spotting decision module, and the verification module. Actually, several more advanced applications of GPD have been reported where the GPD training was applied to both the acoustic modeling and the language modeling <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b95">[96]</ref>, and the training scope was extended to the front-end feature extraction stage <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b14">[15]</ref>. In  particular, in recent years, GPD-based overall design of the feature extraction and classification modules has attracted the attention of speech researchers who recognize the importance of feature space design (on which the quality of the post-end classification decision indispensably relies), and who also seek solutions to unsatisfactory aspects of current feature extractor design techniques. DFE, which is one of the most straightforward embodiments of GPD's concept of global optimization, is becoming a novel paradigm for design algorithm study <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b81">[82]</ref>, <ref type="bibr" target="#b85">[86]</ref>.</p><p>The formalization of DFE is provided by simply replacing the classification rule (3) with the following recognition rule for an input instantiation in the GPD paradigm: iff (67) where is a feature extraction operation with the designable parameters One should notice that the feature extraction process is embedded in the discriminant function, and that by assuming the feature extraction process to be differentiable in both the feature extractor parameters and the classifier parameters now become the targets of the GPD optimization.</p><p>is trained in the very same manner as that of GPD training for classification, and is trained by using the chain rule of differential calculus that is additionally used for back-propagating the derivative of the loss to the feature extraction module. Fig. <ref type="figure" target="#fig_7">8</ref> illustrates the DFE training strategy. One should clearly notice here that the DFE design jointly optimizes the overall recognizer with the single objective of minimizing recognition errors.</p><p>In <ref type="bibr" target="#b66">(67)</ref> we used the speech wave sample However, one can use any reasonable form of input which may be interpreted as an intermediate feature representation of the original utterance input, such as a sequence of FFTcomputed power spectrum vectors. In such cases, the DFE training scope is slightly limited but the training can be performed without any degradation of formalization rigor.</p><p>In the DFE framework, any reasonable differentiable (in function, e.g., linear transformation <ref type="bibr" target="#b13">[14]</ref>, MLP-based nonlinear transformation, or filtering <ref type="bibr" target="#b81">[82]</ref>, can be applied to the design of the feature extraction module. In the rest of this section we particularly focus on one example of a direct DFE application, in which a linear transformation called liftering is used, and on two [slightly advanced] topics related to DFE training.</p><p>2) An Example Implementation for Cepstrum-Based Speech Recognition: Among many implementation possibilities, <ref type="bibr" target="#b14">[15]</ref> studies DFE applied to the design of a cepstrum-based speech recognizer. The cepstrum is one of the most widely used parameter selections for the acoustic feature vector. It has been shown that its low-quefrency components contain salient information for speech recognition, and various lifter shapes have been investigated with the aim of more accurate recognition. However, since there were no methods to design the lifter shape under the criterion of minimizing recognition errors, the shape has usually been determined in an trial-and-error fashion. Obviously, such conventional lifter shapes are not guaranteed to be optimal. An expectation of DFE here is therefore that DFE training can lead to more accurate recognition through the realization of an optimal design for both the lifter feature extractor and the postend classifier.</p><p>Fig. <ref type="figure" target="#fig_8">9</ref> shows a typical DFE-trained lifter shape, which was obtained in the Japanese five-vowel pattern-recognition task <ref type="bibr" target="#b14">[15]</ref>. One can find that this lifter de-emphasizes: 1) the high-quefrency region that corresponds to pitch harmonics and minute spectral structure and 2) the lower quefrency region (0-2 frequency region) that is dominated by the bias and slant of the overall spectrum while enhancing the region of 3-20 quefrency that corresponds primarily to the formant structure. The observed shape suggests that the DFE training successfully extracted the salient features for vowel pattern recognition. The training actually achieved a clear error reduction, from 14.5% (best by a baseline system) to 11.3% (DFE-trained system), over unknown testing data using the very same size of recognizer.</p><p>3) Discriminative Metric Design: Feature extraction can be viewed as a process that forms a metric for measuring the class membership of an input pattern. In general, however, the definition of class identity can be different from class to class. Thus, the feature representation framework, or metric, does not have to be common to all of the classes, i.e. each class could have its own metric that is suitable for representing its identity as effectively as possible. From this point of view, DFE, whose formalization originally assumed a feature extractor common to all sample classes, is not quite sufficient. Motivated by this point, DFE was extended to the discriminative metric design method (DMD) by using the subspace method (SM) paradigm <ref type="bibr" target="#b102">[103]</ref>.</p><p>A recognition decision rule of the DMD framework is as follows: iff <ref type="bibr" target="#b67">(68)</ref> where is a class-specific feature extractor for Note that for each class the feature extractor is embedded in its corresponding discriminant function, i.e., Similar to the DFE formalization, DMD has many implementation possibilities. Among them, <ref type="bibr" target="#b102">[103]</ref> in particular studied implementation using a quadratic discriminant function, which is shown to be closely related to MCE/GPD training for Gaussian kernel functions and accordingly to recent MCE/GPD applications in HMM speech recognizers.</p><p>Readers are referred to <ref type="bibr" target="#b102">[103]</ref> and <ref type="bibr" target="#b104">[105]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Minimum Error</head><p>Learning SM: Recognition-oriented feature design has been most extensively studied in the SM paradigm, especially for problems in character and image recognition <ref type="bibr" target="#b80">[81]</ref>. SM originated from the similarity method where the recognition (classification) decision was made by measuring the angle between a pattern (vector) to be recognized and a class model for every class. In particular, a recognizer based on this method is defined by (lower dimensional) class subspaces, each assumed to represent the salient features of its corresponding class. There is no distinction between the feature extraction process and the classification process in this system framework. Given an input sample, the recognizer computes the orthogonal projection of the input onto each class subspace and then classifies the pattern to the class giving the maximum projection value.</p><p>The performance of SM-based recognizers relies on the quality of the class subspaces. The most fundamental algorithms for designing the subspaces were the class-featuring information compression (CLAFIC) <ref type="bibr" target="#b101">[102]</ref> and the multiple similarity method (MSM) <ref type="bibr" target="#b45">[46]</ref>, where each class subspace was designed by running the Karhunen-Love Transformation or principal component analysis over the design data of its corresponding class. Obviously, this class-by-class design does not directly guarantee recognition error reduction; the recognition error of design samples are not reflected in the subspace design. These methods were later improved, aiming at increasing recognition accuracy. The CLAFIC was extended to the learning subspace method (LSM) (e.g., <ref type="bibr" target="#b80">[81]</ref>); the MSM was reformed as the compound similarity method <ref type="bibr" target="#b45">[46]</ref>. In these new versions, subspaces are trained iteratively (adaptively) depending upon the recognition result of each design sample; i.e., when an input design pattern is misrecognized, the subspace of the true class and that of the most likely but incorrect class are adjusted so that projection onto the true class subspace increases and projection onto the competing incorrect class subspace decreases. This discriminative iteration actually contributed to improvements in accuracy. However, the training mechanism had only an intuitive validity, and its mathematical optimality in terms of error minimization has long remained unclear.</p><p>To alleviate the above problem, <ref type="bibr" target="#b103">[104]</ref> studied a DFE formalization for the SM framework and proposed the minimum error learning subspace (MELS) method that guarantees the optimal subspace design in the MCE/GPD sense. Detailed discussions, including the training convergence proof, are included in <ref type="bibr" target="#b103">[104]</ref> and <ref type="bibr" target="#b105">[106]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Speaker Recognition Using GPD</head><p>Speaker recognition is usually classified into two major categories, i.e., speaker identification, which is the process of identifying an unknown speaker from a known population, and speaker verification, which is the process of verifying the identity of a claimed speaker from a known population. Given a test utterance which is assumed to be represented as a sequence of feature vectors, the likelihood of observing being generated by speaker is denoted as , where is a set of trainable recognizer parameters. Then, the decision operation of speaker identification is formalized as <ref type="bibr" target="#b68">(69)</ref> with being the identified speaker, attaining the highest likelihood score among all competing speakers; the decision operation of speaker verification is formalized as: if the likelihood meets <ref type="bibr" target="#b69">(70)</ref> then the recognizer accepts the claimed speaker identity ; the recognizer rejects it otherwise. One can easily notice here that the formalization for speaker identification is equivalent to that for speech recognition and also that the formalization for speaker verification is essentially the same as that for keyword spotting. One may also notice that the recognizer training here incurs the same difficulty in the likelihood estimation as does the conventional training of continuous speech recognizers and keyword spotters. To alleviate the problem, in <ref type="bibr" target="#b65">[66]</ref> GPD training was successfully applied to the design of both an HMM-based speaker identification system and an HMM-based speaker verification system. The derivation of GPD-based training is fundamentally the same as that for speech recognition. Note that whereas GPD training was applied to threshold training in MECK <ref type="bibr" target="#b62">[63]</ref>, the threshold was determined experimentally in <ref type="bibr" target="#b65">[66]</ref>. Refer to <ref type="bibr" target="#b65">[66]</ref> for details of the implementation and experimental results.</p><p>For speaker verification, <ref type="bibr" target="#b65">[66]</ref> also proposed the use of a GPD-trained normalized likelihood score. The decision rule in this case is formalized as: if the likelihood meets <ref type="bibr" target="#b70">(71)</ref> then the recognizer accepts the claimed speaker identity ; the recognizer rejects it otherwise, where is the claimed speaker and is the antispeaker (the set of speakers other than ). Clearly, the likelihood ratio of ( <ref type="formula">71</ref>) is quite similar to the misclassification measure of GPD, and one can naturally expect that the discriminative power of the normalized score is increased by GPD training. In <ref type="bibr" target="#b65">[66]</ref>, a remarkable improvement due to GPD training was actually demonstrated.</p><p>To see other GPD applications to the task of speaker recognition, readers are referred to recent literature such as <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b67">[68]</ref>, <ref type="bibr" target="#b93">[94]</ref>, and <ref type="bibr" target="#b97">[98]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUDING REMARKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Recent Progress of DFA-Based Speech Recognition</head><p>In this paper, we have reviewed a recent approach to pattern recognizer design, based on the GPD method. Since our main purpose is to introduce this recent design approach comprehensively, we have focused our discussions on issues rather closely related to the GPD family of methods.</p><p>This type of close focus may give readers a somewhat biased understanding, however. Thus, for the purpose of being informative and to avoid misunderstanding, we provide a brief review on the current situation of discriminative training methods, other than GPD, in the speech recognition field.</p><p>As cited in Section I, the development of GPD was motivated by the insufficiency of DFA-based speech pattern recognition in the years of around 1990 and the classical formulation of PDM. However, in parallel with the progress of the family of GPD methods, several other DFA-based methods, such as hybrid HMM/ANN methods (e.g., <ref type="bibr" target="#b76">[77]</ref>), have also been greatly extended in this decade.</p><p>We showed, in Section IV, that the MSE loss is not directly tied to the minimization of classification errors. On the other hand, it has been shown that a discriminant function based on this minimization method can be an estimate of the corresponding class a posteriori probability function in the statistical sense (e.g., see <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b35">[36]</ref>). Actually, several hybrid HMM/ANN speech recognizers, in which the ANN works as an a posteriori probability estimator, have successfully utilized the discriminative power of MSEbased training in advanced frameworks suited for making classification decisions for the entire speech input instead of its elemental acoustic feature vectors (e.g., <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b76">[77]</ref>).</p><p>Concerning MSE-based training, it seems that there is still some gap between the theoretical criticisms being made and some practical successes; actually, it has also been pointed out that fundamentally, the MSE-based estimation of a posteriori probabilities is not accurate in the class boundary region that is usually represented by small values in the sample distribution function <ref type="bibr" target="#b28">[29]</ref>, but which is important for classification. This point may be a good future research issue.</p><p>Efforts to integrate classification decision results, one for every acoustic feature vector, into an overall classification result for an entire speech input have also been made for the framework of time-delay neural network (TDNN) <ref type="bibr" target="#b100">[101]</ref>. That is, TDNN has been successfully extended to multiplestate TDNN (MSTDNN), in which a loss function is defined over the entire input and explicitly reflects the classification decision at the level of the final category outputs of the problem <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. In the MSTDNN framework, most parts of the network classifier are adjusted under a single training objective, defined for the entire speech input, i.e., the MSE objective in <ref type="bibr" target="#b36">[37]</ref> and the maximization of mutual information (MMI) objective in <ref type="bibr" target="#b37">[38]</ref>.</p><p>Moreover, a similar effort has been made for another type of ANN/HMM hybrid <ref type="bibr" target="#b10">[11]</ref>, in which the MMI objective is used for training. Clearly, the global design scope of these advanced methods, which attempts to reflect the classification decision of the entire speech input in the training step, is in the same spirit as that of the GPD formalism, though the MMI criterion used therein is different from the MCE training target.</p><p>It may be worthwhile to mention the fact that the MMIbased discriminative training has attracted research interest in recent years, though its mathematical rigor is not suffi-ciently guaranteed (e.g., see Section IV of this paper and <ref type="bibr" target="#b76">[77]</ref>). Among the many accessible reports, <ref type="bibr" target="#b87">[88]</ref> specially evaluates MMI-based training for recurrent networks, and <ref type="bibr" target="#b79">[80]</ref> and <ref type="bibr" target="#b99">[100]</ref> do the same for HMM classifiers.</p><p>In this decade, there has been remarkable progress not only in research on DFA-based design algorithms (e.g., the one based on GPD methods), but also on speech recognition technology in general. A survey of this advancement would be beyond the scope of this paper, and we refer reader to recent reviews such as <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b76">[77]</ref>, and <ref type="bibr" target="#b107">[108]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Advantages of GPD Formalization</head><p>The most important point of the GPD concept is to embed the entire process of a given recognition task into a smooth functional form so that one can optimize all of the adjustable system parameters in a manner consistent with the design objective of minimizing recognition errors.</p><p>There is the natural intuition that discriminative design methods such as GPD can achieve a higher recognition accuracy using fewer trainable system parameters than methods based on the ML principle: the discriminative design method focuses on classification results near the class borders. In fact, we demonstrated this efficiency in terms of the number of trainable system parameters in many experimental results in literature, e.g., <ref type="bibr" target="#b72">[73]</ref>, a GPD-trained prototype, reference pattern-based classifier achieved higher recognition scores than an ML-trained hidden Markov network having about twenty times more trainable parameters than that of the GPD-trained system. Unfortunately, this "efficiency" advantage has often been criticized: the high discriminative power is considered to lead to a less robust design result, i.e., an overlearning of the given design samples. However, such criticism is simplistic and misses an essential point. The overlearning phenomenon is commonly observed in any system with a surplus of adjustable parameters; on the other hand, it is rarely observed in discriminative designs using fewer parameters. Any overlearning in a discriminative design has its basis in the directness by which such designs are linked to a given classification task and therefore demonstrates the power of the approach.</p><p>The significance of GPD is that it has both mathematical rigor and a great degree of practicality. GPD was shown to provide attractive solutions to three of the four major DFA issues: 1) the design objective; 2) optimization method; and 3) design consistency with unknown samples. In addition, the high utility of GPD has been demonstrated in various experiments, as were introduced in the paper. The remaining DFA issue, i.e., the selection of the discriminant function form, has not been fully studied to date. Basically, this point should be investigated in a task-by-task basis, and GPD, which gives a sound mathematical framework for the other design issues, can be quite useful in this future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Future Issues in GPD-Based Pattern Recognition</head><p>As introduced in this paper, GPD provides useful solutions to many of the existing problems in speech pattern recognition. However, there are still issues needing further investigation. A point of utmost importance is the discovery (for any given task) of a desirable form for the discriminant function, as cited in the last paragraph of the previous subsection. Solving this problem will dramatically advance speech recognition technology, but it is obviously difficult and needs significant research effort. Another important point is to find a reasonable way of controlling the smoothness of the functions, such as the smooth classification error count loss, defined in the GPD training. This point is closely linked to the issue of training sensitivity to unknown samples, and study on the point may necessitate advanced analyses from the viewpoint of statistics. The following points are rather minor (compared with the issues of the discriminant function form selection and smoothness control) but clearly important for the effective implementation of GPD methods. 1) DFA-based training suffers essentially from a scaling problem, that is, in a large-scale task such as largevocabulary continuous speech recognition, extensive computation is involved in evaluating the interclass competition over the tremendous number of possible classes (of connected words). Obviously, the misclassification measure of GPD possesses the same problem. In addition to the simplification based on the use of the norm function, further simplification, such as the use of -best hypotheses <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b52">[53]</ref>, may be needed to reduce the adjustment computation in the training stage.</p><p>2) The gradient search optimization used in GPD is usually slower than the common expectationmaximization (EM) method, especially in a largescale task. Incorporating a faster optimization mechanism in the GPD formalism will clearly be useful.</p><p>3) The success of the gradient-based adjustment relies on a good selection of several controllable parameters such as the learning factor. The selection often controls the balance of interaction among the modules (such as the feature extractor and the classifier) as well as the speed of training convergence. Since the selection is usually performed experimentally due to a lack of theory, a more systematic and theoretically grounded selection method is needed.</p><p>The most important concept of the GPD formalization is, in short, to formalize the overall procedure of the task at hand into an optimizable design process. As the original form of GPD for classification problems has been greatly extended so as to cope with various aspects of pattern recognition, such as the open vocabulary problem and speaker verification, we could further extend the family to other types of tasks as well. The simple but significant concept of GPD, i.e., formalizing the overall procedure of the task at hand into an optimizable design process, can be quite useful in general fields such as system design and information processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Probabilistic Descent Theorem for Probability-Based Discriminant Functions</head><p>In the case of using a probability function as the discriminant function, the adjustment convergence of (20) no longer holds true; the probabilistic descent theorem assumed the classifier parameter to be arbitrary scalar variables and/or arbitrary vector variables and did not anticipate that each class parameter vector had to meet the following probability constraint: and for (72</p><formula xml:id="formula_10">)</formula><p>where we assume that is of -dimension. The HMM state transition probability and the mixture coefficients of the mixtured Gaussian HMM are typical examples of this type of constrained parameter vector.</p><p>One solution to this problem is to use the transformation of (61). In addition, <ref type="bibr" target="#b53">[54]</ref> and <ref type="bibr" target="#b55">[56]</ref> provides a more general solution, i.e., the following, constrained probabilistic descent theorem for applying the GPD-based adjustment to the constrained parameters.</p><p>Theorem 2 (Constrained Probabilistic Descent Theorem): Assume that a design sample is given and a classifier parameter set for includes the parameter vector set that satisfies the constraint of <ref type="bibr" target="#b71">(72)</ref>. Then, the adjustment using which is obtained by projecting of (20) to the 's subspace that is spanned according to the constraint, reduces in the sense of expectation; here is the orthogonal projection of the parenthesized parameter vector onto the (72)-based subspace of the parameter vector space.</p><p>Proof: Considering that the gradient computation is independently done for every dimensional element of the parameter vector, we can prove the theorem by showing that the adjustment in terms of one parameter vector which satisfies the constraint, reduces in the expectation sense. In fact, the following inequality clearly proves that the adjustment can reduce in the expectation sense <ref type="bibr" target="#b72">(73)</ref> where is the angle between and and always holds true. Now it is clear that the characteristics of the original theorem, such as the stochastic approximation-based convergence to a locally optimal situation, hold true.</p><p>Let us point out that even in the case of using the probability-based discriminant function, all the parameters do not need to observe the constrained probabilistic descent adjustment. For example, the mean vector of the component Gaussian distribution of the mixtured Gaussian HMM system can be updated according to <ref type="bibr" target="#b19">(20)</ref>. Moreover, the covariance matrix of the component distribution can be updated in the same way. The adjustment of the diagonal covariance matrix, which is widely used in speech pattern recognition, is actually easy. The adjustment of the full covariance matrix is somewhat complicated and difficult: it should satisfy the positive-definiteness constraint of the matrix. However, it can be done fundamentally based on <ref type="bibr" target="#b19">(20)</ref>. A GPD implementation for this case is presented in detail in <ref type="bibr" target="#b102">[103]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Selection of Discriminant Function Forms</head><p>In this paper, we have especially used the distance classifier for explanations. Thus, the form of the discriminant function used has been distance. We have also mentioned briefly the case of the probability function form of the discriminant function. Obviously, the distance is closely related to the probability function, and thus it is unreasonable to consider these two forms to be separate. In order to embody GPD effectively, we should comprehensively understand the nature of the discriminant functions selected. In light of this, we summarize here the nature of several important discriminant function forms (or the structure of classifiers).</p><p>Discussions focusing on the fixed-dimensional sample space cannot necessarily be applied directly to the classification of dynamic patterns. However, it should be of some help to summarize various structures of the static pattern classifiers.</p><p>As shown in the literature, such as <ref type="bibr" target="#b32">[33]</ref>, it is known that the multilayer perceptron (MLP), having a sigmoidal output function at its hidden nodes, possesses quite a large potential for function approximation. Reference <ref type="bibr" target="#b51">[52]</ref> introduced the GPD implementation for this type of nonlinear network classifier and demonstrated the high efficiency and effectiveness of its training.</p><p>There are several other types of feedforward networks that are similar to MLP in terms of structure but that compute different measures of distance. Among them, let us focus on a three-layer RBF network. Interestingly, it is shown that this type of network achieves universal function approximation under mild conditions, even though linear (e.g., see <ref type="bibr" target="#b39">[40]</ref>). Thus, similar to the above MLP case <ref type="bibr" target="#b51">[52]</ref>, an RBF network trained with GPD would thus greatly contribute to achieving the minimum classification error probability condition.</p><p>If the three-layer RBF network uses a continuous probabilistic basis function and, furthermore, the upper connection coefficients satisfy the probability constraint (72), the network works as a likelihood network that uses probability or likelihood as the discriminant function <ref type="bibr" target="#b54">[55]</ref>. In particular, a likelihood network using the Gaussianform probability function as the discriminant function, i.e., a mixtured Gaussian likelihood network, would be quite useful due to its simple computation. Due to the probability constraint, a likelihood network would not have the universal approximation capability of the original RBF network in the sense of <ref type="bibr" target="#b39">[40]</ref>. However, it was shown that the mixtured Gaussian density function could approximate an arbitrary continuous probability density function in the sense of minimizing the norm error between the two corresponding density functions <ref type="bibr" target="#b94">[95]</ref>. These results would therefore enable us to expect highly effective applications of GPD to this Gaussian-basis likelihood network.</p><p>The mixtured Gaussian likelihood network is obviously equivalent to the one state case of the mixtured Gaussiancomponent, continuous HMM. The discussions of the above paragraphs thus suggest that the GPD-trained mixtured Gaussian-component HMM classifier would have a large potential for achieving the minimum error probability condition of dynamic pattern classification.</p><p>Similar to the Mahalanobis distance, several likelihoodbased distance measures can be defined based on the Gaussian distribution probability density function. The squared Euclidean distance is the most limited but simplest version among these likelihood-based distances. Let us replace the probability computation with a computation using one of these distances in a Gaussian-basis likelihood network. We assume here that the lower connection weights correspond to the mean vectors of the Gaussian-basis function. Then, the resulting network is obviously equivalent to a distance network using the distance between an input vector and a reference vector as the discriminant function <ref type="bibr" target="#b54">[55]</ref>. One may note here that this distance network can also be seen as a generalized version of a distance classifier. Fundamentally, in a distance network, the output nodes are fully connected to the hidden nodes. On the other hand, as described in Section II-D, a distance classifier usually assigns one reference vector to one of all of the possible classes exclusively. The distance network does not take such a priori assignment of the reference vectors; instead, this network attempts to share the reference vectors (inner models) among the classes. The same concept of sharing is also implemented for a continuous HMM <ref type="bibr" target="#b43">[44]</ref>.</p><p>In practical applications of RBF networks and distance networks for classification, the network classifiers usually use a much smaller number of hidden nodes than given design samples. That is, any clustering concept for the given samples underlies the setting of the hidden nodes. Let us consider the situation in which as we increase the number of hidden nodes, we decrease the size of the cluster corresponding to each hidden node. In the extreme case in which each hidden-node cluster corresponds to one sample, the RBF network performs a generalized Parzen approximation and the distance network works as a generalized -nearest neighbor classifier. The generalization here relies on flexibility in determining the upper layer connection weights. The Parzen estimate of probability distribution is an unbiased and consistent estimate of the true distribution function. Moreover, the error probability of the -nearest neighbor method is bounded to be below twice the Bayes error probability. These well known characteristics suggest that the distance network is also worth further study.</p><p>Fundamentally, one should select classifier structures, discussed above, that determine the discriminant function forms, based on ease of hardware implementation, computational efficiency, and the nature of a given feature representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Various Definitions of Discriminant Functions, Misclassification Measures, and Losses</head><p>There is a large variety in the defining functions used in GPD, such as the discriminant functions and the misclassification measures. Assuming that the discriminant function represents the degree to which an input sample belongs to a class, we present several examples of definitions which have not been used in the previous sections. Note that we assume a dynamic pattern to be an input.  Discriminant function <ref type="bibr" target="#b73">(74)</ref>  Misclassification measure <ref type="bibr" target="#b74">(75)</ref> (76) <ref type="bibr" target="#b76">(77)</ref> The form of (77) was given in <ref type="bibr" target="#b23">[24]</ref>.</p><p> Loss <ref type="bibr" target="#b77">(78)</ref> where is such a usual loss as <ref type="bibr" target="#b36">(37)</ref>, and is a symbolic distance between and which is often determined by parsing in speech recognition. Equation <ref type="bibr" target="#b77">(78)</ref> was proposed in <ref type="bibr" target="#b70">[71]</ref>. Using this loss, one can attempt to pursue the minimum of a specific risk to a given task instead of the general misclassification account.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Typical structure of a modular speech recognizer.</figDesc><graphic coords="2,307.56,55.02,236.16,93.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 )</head><label>1</label><figDesc>Discriminative (of DFA) ANN with a time-delay structure. a) FFN-and LVQ-based systems with a timedelay structure were proposed, aiming to accurately classify a short speech fragment [70], [101]. b) An analog ANN with a time-delay structure was developed for continuous speech pattern classification [99].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Schematic explanation of the role of the discriminant function approach classification in recent ANN-based approaches to speech pattern recognition.</figDesc><graphic coords="5,100.86,55.01,387.00,524.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The relation in smoothness between the smooth classification error count loss and its corresponding empirical average loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Concept of open-vocabulary speech recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. An example of loss functions for keyword spotting: (a) for false-detection and (b) for false-alarm (after<ref type="bibr" target="#b51">[52]</ref>).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Block diagram illustrating a GPD-based discriminative training for a speech recognizer verifying hypothesized vocabulary words (after<ref type="bibr" target="#b73">[74]</ref> with some simplification).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Training strategy of discriminative feature extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9.A typical DPE-trained lifter shape: (a) the entire view issued from the uniform initialization that set the lifter values at a constant before DFE training and (b) the same lifter with a focus on the lower quefrency region (after<ref type="bibr" target="#b10">[11]</ref>).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The incompleteness here corresponds to the fact that one cannot observe the state transition behavior of HMM.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>PROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>Note that in this simple case for introductory discussions, we consider only the acoustic model of the classifier, assuming that the classifier has no language model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>Additionally, it was reported that a larger size distance classifier having 12 reference patterns for every class produced only 67.6%. For this classifier, no result based on MCE/GPD was reported.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to express their thanks to their many colleagues at the Bell Laboratories and the ATR Laboratories for their significant contributions over the years to the development of the GPD family. In particular, they thank A. Biem, W. Chou, E. McDermott, H. Watanabe, and E. Woudenberg, whose contributions made possible the authors' development work. They would also like to give special thanks to E. Woudenberg for his patience and assistance during the preparation of this paper. Finally, the authors acknowledge the careful review work of their two reviewers. Their detailed comments greatly helped to substantially improve the quality of this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Biing-Hwang Juang (Fellow, IEEE) received the B.Sc. degree in electrical engineering from National Taiwan University, Taipei, in 1973 and the M.Sc. and Ph.D. degrees in electrical and computer engineering from the University of California, Santa <ref type="bibr">Barbara, in 1979 and</ref><ref type="bibr">1981, respectively.</ref> In </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theory of adaptive pattern classifiers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Electron. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="299" to="307" />
			<date type="published" when="1967-03">Mar. 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Information Theory II-Geometrical Theory of Information</title>
		<imprint>
			<date type="published" when="1968">1968</date>
			<publisher>Kyoritsu</publisher>
			<pubPlace>Tokyo</pubPlace>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">Neural Network Model and Connectionism</title>
		<meeting><address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<publisher>Tokyo Univ. Press</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A clustering algorithm to minimize recognition error function</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ozeki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. A</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="360" to="367" />
			<date type="published" when="1991-03">Mar. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Asou</surname></persName>
		</author>
		<title level="m">Neural Network Information Processing-Introduction to Connectionism, or Toward Soft Symbolic Representation</title>
		<meeting><address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<publisher>Sangyo Tosho</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonlinear data analysis and multilayer perceptrons</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE IJCNN</title>
		<meeting>IEEE IJCNN</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="411" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum mutual information estimation of hidden Markov model parameters for speech recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;86</title>
		<meeting>IEEE ICASSP&apos;86</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new algorithm for the estimation of hidden Markov model parameters</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE. ICASSP&apos;98</title>
		<meeting>IEEE. ICASSP&apos;98</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="493" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical inference for probabilistic functions of finite state Markov chains</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Petrie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1554" to="1563" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Growth functions for transformations on manifolds</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Sell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific J. Math</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="227" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Global optimization of a neural network-hidden Markov model hybrid</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Flammia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kompe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="252" to="259" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Feature extraction based on minimum classification error/generalized probabilistic descent method</title>
		<author>
			<persName><forename type="first">A</forename><surname>Biem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;93</title>
		<meeting>IEEE ICASSP&apos;93</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="275" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discriminative feature extraction for speech recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Biem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1993 IEEE Workshop Neural Networks for Signal Processing III</title>
		<meeting>1993 IEEE Workshop Neural Networks for Signal essing III</meeting>
		<imprint>
			<biblScope unit="page" from="392" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminative feature extraction to filter bank design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Biem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1996 IEEE Workshop Neural Networks for Signal Processing VI</title>
		<meeting>1996 IEEE Workshop Neural Networks for Signal essing VI</meeting>
		<imprint>
			<biblScope unit="page" from="273" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pattern recognition using discriminative feature extraction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Biem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="500" to="504" />
			<date type="published" when="1997-02">Feb. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Links between Markov models and multilayer perceptrons</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wellekens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1167" to="1178" />
			<date type="published" when="1990-12">Dec. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Connectionist Speech Recognition-A Hybrid Approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morgan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Alpha-nets: A recurrent &apos;neural&apos; network architecture with a hidden Markov model interpretation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bridle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="83" to="92" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative template training for dynamic programming speech recognition</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;92</title>
		<meeting>IEEE ICASSP&apos;92</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="493" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative training of dynamic programming based speech recognizers</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="135" to="143" />
			<date type="published" when="1993-02">Feb. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An N-best candidates-based discriminative training for speech recognition applications</title>
		<author>
			<persName><forename type="first">J.-K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="206" to="216" />
			<date type="published" when="1994-01">Jan. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Use of generalized dynamic feature parameters for speech recognition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chengalvarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="232" to="242" />
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HMM-based speech recognition using state-dependent, discriminatively derived transforms on Mel-warped DFT features</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="243" to="256" />
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Segmental GPD training of HMM based speech recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;92</title>
		<meeting>IEEE ICASSP&apos;92</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="473" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Minimum error rate training based on N-best string models</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;93</title>
		<meeting>IEEE ICASSP&apos;93</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="652" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Minimum error rate training of inter-word context dependent acoustic model units in speech recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICSLP&apos;94</title>
		<meeting>ICSLP&apos;94</meeting>
		<imprint>
			<biblScope unit="page" from="439" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Signal conditioned minimum error rate training</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buhrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;95</title>
		<meeting>EUROSPEECH&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="495" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
		<title level="m">Pattern Classification and Scene Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Integrated optimization of feature transformation for speech recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Euler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;95</title>
		<meeting>EUROSPEECH&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="109" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Speaker recognition using neural networks and conventional classifiers</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mammone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Assaleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="194" to="205" />
			<date type="published" when="1994-01">Jan. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Introduction to Statistical Pattern Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the approximate realization of continuous mappings by neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Funahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="183" to="191" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">HMM-based warping in neural networks</title>
		<author>
			<persName><forename type="first">Y.-Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;90</title>
		<meeting>IEEE ICASSP&apos;90</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="501" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984-06">June 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A probabilistic approach to the understanding and training of neural network classifiers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;90</title>
		<meeting>IEEE ICASSP&apos;90</meeting>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1361" to="1364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Integrating time alignment and neural networks for high performance continuous speech recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;91</title>
		<meeting>IEEE ICASSP&apos;91</meeting>
		<imprint>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A new probabilistic framework for connectionist time alignment</title>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICSLP&apos;94</title>
		<meeting>ICSLP&apos;94</meeting>
		<imprint>
			<biblScope unit="page" from="1559" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A novel objective function for improved phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hampshire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="216" to="228" />
			<date type="published" when="1990-03">Mar. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Layered neural networks with Gaussian hidden units as universal approximations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kowalski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="210" to="215" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimization of speech parameter weighting for CDHMM word recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ayarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Monte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;95</title>
		<meeting>EUROSPEECH&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural computation of decisions in optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hopfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="141" to="152" />
			<date type="published" when="1985">1985</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The multi-layer perceptron as a discriminating post processor for hidden Markov networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th FASE Symp</title>
		<meeting>7th FASE Symp</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="1389" to="1396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ariki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jack</surname></persName>
		</author>
		<title level="m">Hidden Markov Models For Speech Recognition</title>
		<meeting><address><addrLine>Edinburg, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Edinburg Univ. Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unified stochastic engine (USE) for speech recognition</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Belin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;93</title>
		<meeting>IEEE ICASSP&apos;93</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="636" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Iijima</surname></persName>
		</author>
		<title level="m">Pattern Recognition Theory</title>
		<meeting><address><addrLine>Tokyo</addrLine></address></meeting>
		<imprint>
			<publisher>Morikita</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A hybrid speech recognition system using HMM&apos;s with an LVQtrained codebook</title>
		<author>
			<persName><forename type="first">H</forename><surname>Iwamida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tohkura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="277" to="286" />
			<date type="published" when="1990-09">Sept. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Re-evaluation of LVQ-HMM hybrid algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Iwamida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="267" to="274" />
			<date type="published" when="1993-07">July 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Self-organized language modeling for speech recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jelinek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM T. J. Watson Research Center</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<pubPlace>Yorktown Heights, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The segmental K-means algorithm for estimating parameters of hidden Markov models</title>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech Signal Processing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1639" to="1641" />
			<date type="published" when="1990-09">Sept. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Discriminative training</title>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="333" to="339" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Discriminative learning for minimum error classification</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="3043" to="3054" />
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Minimum classification error rate methods for speech recognition</title>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="257" to="265" />
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A generalized probabilistic descent method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASJ Autumn Conf</title>
		<meeting>ASJ Autumn Conf</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="141" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Discriminative multi-layer feed-forward networks</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Neural Networks for Signal Processing</title>
		<meeting>IEEE Workshop Neural Networks for Signal essing</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">New discriminative training algorithms based on the generalized probabilistic descent method</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Neural Networks for Signal Processing</title>
		<meeting>IEEE Workshop Neural Networks for Signal essing</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="299" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A new hybrid algorithm for speech recognition based on HMM segmentation and learning vector quantization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="421" to="430" />
			<date type="published" when="1993-04">Apr. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Discriminative feature extraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Biem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks for Speech and Vision</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Mammone</surname></persName>
		</editor>
		<meeting><address><addrLine>London, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman and Hall</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="278" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A unified approach to pattern recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISANN&apos;94</title>
		<meeting>ISANN&apos;94</meeting>
		<imprint>
			<biblScope unit="page" from="561" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Speaker-independent vowel classification using hidden Markov models and LVQ2</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kimber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tajchman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;90</title>
		<meeting>IEEE ICASSP&apos;90</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="497" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The self-organizing map</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-09">Sept. 1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1464" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">GPD training of dynamic programming-based speech recognizers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Komori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="341" to="349" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A minimum error approach to spotting-based pattern recognition</title>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. Inform. Syst</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1032" to="1043" />
			<date type="published" when="1995-08">Aug. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A novel spotting-based approach to continuous speech recognition: Minimum error classification of keywordsequences</title>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="147" to="157" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
		<title level="m">Automatic Speech and Speaker Recognition</title>
		<meeting><address><addrLine>Norwell, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A study on minimum error discriminative training for speaker recognition</title>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoustical Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="637" to="648" />
			<date type="published" when="1995-01">Jan. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Recognition of phonemes in continuous speech using a modified LVQ2 method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="351" to="360" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A study of speaker adaptation based on minimum classification error training</title>
		<author>
			<persName><forename type="first">T</forename><surname>Matsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Furui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;95</title>
		<meeting>EUROSPEECH&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="81" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">LVQ3 for phoneme recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASJ Spring Conf</title>
		<meeting>ASJ Spring Conf</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="151" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">LVQ-based shift-tolerant phoneme recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1398" to="1411" />
			<date type="published" when="1991-06">June 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Prototype-based MCE/GPD training for word spotting and connected word recognition</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;93</title>
		<meeting>IEEE ICASSP&apos;93</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="291" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Prototype-based MCE/GPD training for various speech units</title>
	</analytic>
	<monogr>
		<title level="j">Comput. Speech Language</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="351" to="368" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">String-level MCE for continuous phoneme recognition</title>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;97</title>
		<meeting>EUROSPEECH&apos;97</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="123" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Integrated training for spotting Japanese phonemes using large phonemic time-delay neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Miyatake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Minami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;90</title>
		<meeting>IEEE ICASSP&apos;90</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="449" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A discriminative training method for continuous mixture density HMM&apos;s and its implementation to recognize noisy speech</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mizuta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="389" to="393" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Discriminative learning for minimum error classification with reject options</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mizutani</surname></persName>
		</author>
		<idno>PRMU97-245</idno>
	</analytic>
	<monogr>
		<title level="j">IEICE</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<pubPlace>Tokyo</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Neural networks for statistical recognition of continuous speech</title>
		<author>
			<persName><forename type="first">N</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Bourlard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="742" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Combining hidden Markov model and neural network classifier</title>
		<author>
			<persName><forename type="first">L</forename><surname>Niles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;90</title>
		<meeting>IEEE ICASSP&apos;90</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="417" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">The Mathematical Foundations of Learning Machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nilsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">High-performance connected digit recognition using maximum mutual information estimation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Normandin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="299" to="311" />
			<date type="published" when="1994-02">Feb. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<title level="m">Subspace Methods of Pattern Recognition. Letchworth</title>
		<imprint>
			<publisher>Research Studies Press</publisher>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Minimum classification error training algorithm for feature extractor and pattern classifier in speech recognition</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bacchiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sagisaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;95</title>
		<meeting>EUROSPEECH&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="541" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Adaptive Pattern Recognition and Neural Networks</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Pao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Universal approximation using radialbasis-function networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sandberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="246" to="257" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<title level="m">Fundamentals of Speech Recognition</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Simultaneous ANN feature and HMM recognizer design using string-based minimum classification error (MCE) training</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICSLP&apos;96</title>
		<meeting>ICSLP&apos;96</meeting>
		<imprint>
			<biblScope unit="page" from="1824" to="1827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Minimum error classification training of HMM&apos;s-Implementation details and experimental results</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rainton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ, J. Acoustical Soc. Japan (E)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="379" to="387" />
			<date type="published" when="1992-11">Nov. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">An application of recurrent nets to phone probability estimation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="298" to="305" />
			<date type="published" when="1994-03">Mar. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A training procedure for verifying string hypothesis in continuous speech recognition</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP&apos;95</title>
		<meeting>ICASSP&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="281" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Word spotting from continuous speech utterances</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech and Speaker Recognition: Advanced Topics</title>
		<editor>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</editor>
		<meeting><address><addrLine>Norwell, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="303" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><surname>Research Group</surname></persName>
		</author>
		<title level="m">Parallel Distributed Processing</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Speaker-independent word recognition using dynamic programming neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Isotani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Iso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;89</title>
		<meeting>IEEE ICASSP&apos;89</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A learning method for definite canonicalization based on minimum classification error</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PRMU</title>
		<imprint>
			<biblScope unit="page" from="97" to="244" />
			<date type="published" when="1998">1998</date>
			<publisher>IEICE</publisher>
			<pubPlace>Tokyo</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Results of a speaker verification service trial using HMM models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUROSPEECH&apos;95</title>
		<meeting>EUROSPEECH&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="639" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Recursive Baysian estimation using Gaussian sums</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sorenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alspach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="465" to="479" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">A unified framework to incorporate speech and language information in spoken language processing</title>
		<author>
			<persName><forename type="first">K.-Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP&apos;92</title>
		<meeting>ICASSP&apos;92</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="185" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Speech recognition using weighted HMM and subspace projection approaches</title>
		<author>
			<persName><forename type="first">K.-Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. Speech Audio Processing</title>
		<imprint>
			<date type="published" when="1994-01">Jan. 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="69" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Minimal classification error optimization for a speaker mapping neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kurinami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Neural Networks for Signal Processing II</title>
		<meeting>IEEE Workshop Neural Networks for Signal essing II</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Connected-digit speaker-dependent speech recognition using a neural network with time-delayed connections</title>
		<author>
			<persName><forename type="first">K</forename><surname>Unnikrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hopfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="698" to="713" />
			<date type="published" when="1991-03">Mar. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Lattice-based discriminative training for large vocabulary speech recognition</title>
		<author>
			<persName><forename type="first">V</forename><surname>Valtchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Odell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;96</title>
		<meeting>IEEE ICASSP&apos;96</meeting>
		<imprint>
			<biblScope unit="page" from="605" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hanazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="328" to="339" />
			<date type="published" when="1989-03">Mar. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Evaluation and selection of variables in pattern recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Kulikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer and Information Sciences</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Tou</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="91" to="122" />
			<date type="published" when="1967">1967</date>
			<publisher>Academic</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A novel approach to pattern recognition based on discriminative metric design</title>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Neural Networks for Signal Processing</title>
		<meeting>IEEE Workshop Neural Networks for Signal essing</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="48" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Discriminative subspace method for minimum error pattern recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Neural Networks for Signal Processing</title>
		<meeting>IEEE Workshop Neural Networks for Signal essing</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Discriminative metric design for robust pattern recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2655" to="2662" />
			<date type="published" when="1997-11">Nov. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Subspace method for minimum error pattern recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. Inform. Syst</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1195" to="1204" />
			<date type="published" when="1997-12">Dec. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Minimum detection error training for acoustic signal monitoring</title>
		<author>
			<persName><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;98</title>
		<meeting>IEEE ICASSP&apos;98</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1193" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">A review of large-vocabulary continuous-speech recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Mag</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="45" to="57" />
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Discriminant continuous speech recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Russel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP&apos;90</title>
		<meeting>IEEE ICASSP&apos;90</meeting>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="685" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">His current research interests include studies on discriminative training, the learning capability of artificial neural networks, and speech recognition. Dr. Katagiri was a co-recipient of the 22nd Sato Paper Award of the Acoustical Society of Japan (ASJ), the 27th Sato Paper Award of the ASJ, and the IEEE Signal Processing Society 1993 Senior Award in 1982, 1987, and 1994, respectively. He is a Senior Member of the IEEE Signal Processing Society (SPS) and a member of the</title>
		<author>
			<persName><forename type="first">Shigeru</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">(senior</forename><surname>Member</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ieee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Dr</surname></persName>
		</author>
		<author>
			<persName><surname>Eng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">as Secretary of the Technical Committee on Neural Networks for Signal Processing of the IEEE Signal Processing Society</title>
		<title level="s">the IEEE Signal Processing Society</title>
		<meeting><address><addrLine>Sendai, Japan; Tokyo, Japan; Kyoto, Japan, as a Visiting Professor</addrLine></address></meeting>
		<imprint>
			<publisher>IEICE) of Japan, and the Japanese Society for Artificial Intelligence</publisher>
			<date type="published" when="1977">1977. 1979. 1982. 1994-1997. 1997-1998</date>
		</imprint>
		<respStmt>
			<orgName>Tohoku University ; Nippon Telegraph and Telephone Public Corporation ; Kyoto University</orgName>
		</respStmt>
	</monogr>
	<note>He has served as Associate Editor of the IEEE TRANSACTIONS ON SIGNAL PROCESSING. and as the Vice-Chair of the Tokyo Chapter. He has also served as an Associate Editor of the Transactions of IEICE D-II. As Program Chair he organized the 1996 IEEE Signal Processing Society Workshop on Neural Networks for Signal Processing (NNSP&apos;96</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
