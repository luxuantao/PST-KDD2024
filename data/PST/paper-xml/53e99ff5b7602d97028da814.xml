<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">41E9A92564E55A3E358141D0532159FA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quadratic Optimization of Motion Coordination and Control</head><p>Abstract-This paper presents algorithms for continuous-time and adaptive control may act in concert in the case of unknown or uncertain system parameters. The solution results in natural design parameters in the form of square weighting matrices as known from linear quadratic optimal control. The proposed optimal control is useful both for motion control, trajectory planning, and motion analysis.</p><p>quadratic optimization of motion control. Explicit solutions to the Hamilton-Jacobi equation for optimal control of rigid body motion are found by solving an algebraic matrix equation. The system stability is investigated according to Lyapunov function theory and it is shown that global asymptotic stability holds. It is also shown how optimal control Position error 4 = qq, State of motion x = ( q T 4:)'</p><p>Error state of motion 2 = ( g T @ T ) T</p><p>Reference state of motion x, = (q: q:)' q E R " QER" 4,ER" @ E R "</p><p>.?ER2" X E R2"</p><p>X,E R2" B. Torques, Forces, Inertias 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applied torques or forces T E R " M ( q )</head><p>Moment of inertia M ( q ) = M T ( q ) &gt; 0 M E R n X n</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G ( q )</head><p>Gravitational forces G E R "</p><p>Control variable U = M ( q ) T , $ + (+hi( q , q ) + N( q , q))T, 2 C( q , q)q Coriolis, centripetal, and frictional forces C € R n x n N ( q , q)q Workless forces of 7 N E R " ~"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PURPOSE of motion control is to maintain a prescribed</head><p>A motion for the control object by applying compensating corrective torques or forces. Motion controlled systems intended for autonomous operation need optimization as well as a capacity of adapting to new and rapidly changing operating conditions.</p><p>The optimality of such control design is therefore meaningful to consider, Linear optimal control based on linearized equations of motion is a standard approach to the solution of such problems. Nonlinear dynamics with motion constraints and rapidly changing operating conditions sometimes make such control problems difficult. The rigid body mechanics of flight control or robot manipulator motion is often formulated with the general equations obtained from Lagrangian mechanics (time arguments omitted)</p><p>The position coordinates q E R " with associated velocities q and accelerations q are controlled with the driving forces r E R " . The (generalized) moment of inertia M ( q ) , the Coriolis, centripetal, and frictional forces C(q, q)q, and the gravitational forces G ( q ) all vary along the trajectories.</p><p>The control problem can be stated as follows: to find the torques (forces) 7 so that the control object follows a trajectory, provided that equations (1) of the rigid body mechanics are known. From the standpoint of linear quadratic control theory, it is natural to include the torques (forces) in the performance index. Attempts to design linear quadratic control often fail, however, due to the position-dependent nonlinear behavior of the system expressed in (1).</p><p>Both optimal control and adaptive control [ 111 are relevant in this context. Various adaptive control algorithms were earlier proposed in robotics by Tomizuka et al. <ref type="bibr" target="#b29">[31]</ref>. Dubowsky and  DesForges [7] proposed an adaptive control that adjusts feedback gains to follow a reference model. <ref type="bibr">Koivo and Guo [20]</ref> used an autoregressive model to fit data. Both these teams assumed the interaction forces among the joints to be negligible. The idea is to use state feedback to enable exact cancellation of nonlinear terms and factors followed by optimal control design for the simplified system.</p><p>Linear optimal control solutions are standard and rely on linearized equations with regard to an operating point. <ref type="bibr">Saridis and Lee [28]</ref> made early work on self-optimizing control in robotics and <ref type="bibr">Luo and Saridis [25]</ref> studied linear quadratic design of PID controllers. Apart from approximate solutions, there are also approaches with suboptimal solutions based on the nonlinear equations. <ref type="bibr">Lee and Chen [22]</ref> proposed a suboptimal nonlinear control design based on quasi-linearization and linear optimal control. Discrete-time adaptive control, based on linearized dynamics around preplanned trajectories, was proposed by Lee and  Chung [23].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">PROBLEM STATEMENT</head><p>There are two natural choices of the control variable for computation of optimal motion control. One approach is based on minimization of local accelerations, velocities, and positions. Solution of the linear quadratic control problem provides the optimal accelerations and the corresponding torques can be calculated with the ''exact linearization" or "computed torque" method. This optimization is based on linear system dynamics with double integrator action and does not include the nonlinear dynamics of (1). Thus, control is not optimized with respect to the applied torques.</p><p>However, optimization criteria with penalties on the torques rather than accelerations lead to complicated trajectory-dependent mathematical problems. Methods hitherto published generally require cumbersome trajectory-dependent numerical or approximate solutions 1221, [28], <ref type="bibr" target="#b30">[32]</ref>.</p><p>There would appear to exist no analytic solution to the quadratic control problem of motion described by equations of Lagrangian mechanics. It is the purpose of this paper to present stable analytic solutions to the problem of quadratic optimal control of motion control with minimization of the applied torques (forces) when velocity and position measurements are available. An optimal control approach is adopted to solve a Hamilton -Jacobi equation and present feedback solutions to the stated optimal motion control problem. The given problem is reduced into two separate problems:</p><p>1) explicit solution of an optimal tracking problem with the Hamilton-Jacobi equation,</p><p>2) adaptive control.</p><p>The solutions to the two problems permit the following:</p><p>-optimization of a performance index, -stability, -trajectory planning. Thus, separated solutions are obtained for optimality and adaptation. The approach should be of interest in robot manipulator control, biomechanics, flight control, and other branches of applied mechanics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RIGID BODY DYNAMICS</head><p>We model the motion dynamics as a set of n rigid bodies connected and described by a set of generalized coordinates q E R " . The derivation of the motion equations (1) applying the methods of the Lagrange theory [2], [lo] involves explicit expressions of kinetic energy .T and potential energy ?/ to form the Euler-Lagrange equations of motion where r denotes the externally applied torques and forces. The Lagrangian Y of mechanical motion in a space with a velocitj independent gravitation potential is 1 Y ( q , 4 ) = 7 ( 4 , 4 ) -9 ( q ) = 7 GTM(4)4 -j / ( q ) .</p><p>(3</p><formula xml:id="formula_0">(1</formula><p>The standard general equations <ref type="bibr">( I )</ref> are obtained from (3) as M ( q ) i j + c(q, 4 ) 4 + G ( q ) = 7.</p><p>It is assumed that the positions q and velocities q , but not the accelerations q , are available for measurement. It is further assumed that the torque vector 7 is available as the control input. It is assumed that the matrices M , C , G are of known structure and contain constant parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Control Objective</head><p>The desired reference trajectory for the control object to follow is assumed to be available as bounded functions of time in terms of generalized positions qr E 'd" and its corresponding accelerations q, and velocities 4,. All variables q r , q,, 4, are assumed to be within the physical and kinematic limits of the control object. The variables q,, q,, qr may be conveniently generated with some bounded reference signal r and a reference model of the type The dynamic system (4) with the n x n-matrices K,, K , , , K , which verifies need to be stable. Define the errors of accelerations, velocities, and positions as 1 . i a 2 2 a4 N ( q , q ) q = -M ( q , 4)4 ---(4TM(q)4) (12)</p><p>The control objective is to follow a given bounded reference trajectory q,, qr without position errors q, or velocity errors 6.</p><p>It is straightforward to verify that the work done on the system by the applied forces TK may be simplified to 1 B. A State-Space Description /r:gdt</p><formula xml:id="formula_1">= I qT( M ( q ) q + M ( q , 4 ) ) q d t . (<label>14</label></formula><formula xml:id="formula_2">)</formula><p>The full error state-space representation is found as</p><formula xml:id="formula_3">P ( t ) = ( i T ( t ) g T ( t ) ) T ; PER^".<label>(6)</label></formula><p>The error dynamics of the manipulator may be obtained from <ref type="bibr">(I)</ref>, (4), and ( <ref type="formula" target="#formula_3">6</ref>) as a state-space description, where the derivative of P is It is a standard result from Lagrangian mechanics that the third term N ( q , q ) q of (12) represents the workless forces of the system. Natural choices of the control variable to minimize are for this reason either</p><p>or rK itself (or some linear combination). To minimize the necessary forces (torques) we include this choice of the control variable in the more general definition with 2 and T I introduced via the following state-space transfor-(7) mation of 2:</p><p>This definition includes forces (torques) affecting kinetic energy (lo), reference trajectories (5), and a state-space transformation (17). The terms including the matrix N ( q , 4) may be regarded as optional. The equations of motion (7) from U to P are then where 7 is available for assignment of the control law.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. What Control Effort Should be Minimized?</head><p>A natural aim is to minimize velocity and position errors (state errors) with a minimum of applied torque and energy consumption. The Euler-Lagrange equations give for a veloc-dP dt ity-independent potential energy W -= A I ( &amp; 4 ) P + B , ( q ) u Changes in potential energy due to gravitation are inevitable and can be determined from the start and end points only. Thus, there is little point in trying to optimize gravitation-dependent torques or forces. Consider, therefore, the applied torques rK that selectively affect the kinetic energy To investigate the properties of r K , we introduce the skew-symmetric matrix N ( q , 4) with elements n j j defined from the components m ; , of M ( q ) as with and B , ( q ) = T i I B M ( q ) -I .</p><p>(</p><formula xml:id="formula_4">)<label>18</label></formula><p>The control variable U of ( <ref type="formula">16</ref>) can be reduced to rK of (10) for q, = 0, TI, = I n x n , and TI, = 0 so that u = M ( q ) 4 + j 5 M ( q . 4 ) 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+N(47,8))4</head><p>1 .</p><p>= 7 -G ( q ) + ( 7 M ( q , 4) + N ( q , 4) -C ( q , 4 ) ) 4 .</p><p>(</p><p>V. A QUADRATIC OPTIMIZATION PROBLEM We include the motion control problem in the following somewhat more general optimization problem. The assumptions made may be summarized as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Basic Assumptions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A I :</head><p>The motion equations are M ( q ) q + C ( q , q ) q + G ( q )</p><p>= 7 with coordinates q and external torques (forces) 7.</p><p>A2: Reference trajectory given within physical and kinematic limits as qr, qr, q l e L m , and qr in %'I with the error state x = (4"T 4"T).</p><p>A3: A state-space transformation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4:</head><p>The control action to be minimized is 1 . </p><formula xml:id="formula_6">U = ( y M ( q , 4 ) + N ( q , 4 ) BTTo2 + M ( q ) B T T o i ; B = ( : x n ) . (<label>21</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>To derive optimal feedback, the control problem is formulated as a quadratic optimization problem with a performance index J( U ) subject to the previous assumptions A1 -A7 able for measurement. <ref type="bibr" target="#b20">(22)</ref> with the Lagrangian <ref type="formula">1</ref>1</p><formula xml:id="formula_7">J ( u ) = l o m L ( 2 , U ) dt</formula><formula xml:id="formula_8">L ( 2 , U ) = -ZT(t)QZ(t) + -u T ( t ) R u ( t ) 2 2 1 Q I I Q12 1 2</formula><p>Given the performance index J ( u ) , we find an optimal control U = U* that will transfer from an initial state to a desired state.</p><p>The control U = U* moves the system from an arbitrary initial state .F(to) to the origin of the error space while minimizing J U ) The control variable U is weighted with the matrix R = R &gt; 0, and the vector of velocity and position errors 2 is weighted with the matrix Q = QT &gt; 0. The rate of compensation can be adjusted by choosing proper weights Q. The term uTRu guarantees smoothness of operation.</p><p>(6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. THE HAMILTON-JACOBI EQUATION Define the Hamiltonian of optimization as</head><p>where V satisfies the partial differential equation av <ref type="bibr">(2,t)</ref> av(a,t) '.</p><p>-</p><formula xml:id="formula_9">-= ~ ( a n ) Z + L ( Z . , u ) . (25) a t</formula><p>A necessary and sufficient condition for optimality [SI, <ref type="bibr" target="#b22">[24]</ref> is to choose a value function V that satisfies the Hamilton-Jacobi equation av av</p><p>This minimum is attained for the optimal control U = U* and the Hamiltonian</p><formula xml:id="formula_10">U H* = min H = min . (<label>27</label></formula><formula xml:id="formula_11">)</formula><p>The optimal value function V that satisfies (26) for U = U* is the Hamilton's principal function [lo] of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma I:</head><p>The following function I/ composed of 2 , q,(t), To, M , and a symmetric matrix K E R n x n satisfies the Hamilton-Jacobi equation and constitutes a Hamilton's principal function for the optimization problem ( <ref type="formula">22</ref>) and ( <ref type="formula">23</ref>) under the assumptions made in Al-A7 for K , To solving the algebraic matrix equation</p><p>The optimal feedback control law U = U* that minimizes J is <ref type="bibr" target="#b28">(30)</ref> Proof: See Appendix I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>u * ( t ) = -R -~B ~T ~. ? ( ~) .</head><p>U Remark: The matrix solution K of ( <ref type="formula">28</ref>) and ( <ref type="formula">29</ref>) is not unique. Another solution to (29) may be obtained by adding any All optimal control based on the solution ( <ref type="formula" target="#formula_10">27</ref>)- <ref type="bibr" target="#b28">(30)</ref> to the Hamilton-Jacobi equation does not necessarily guarantee stable closed-loop behavior. However, only the solutions that do guarantee a stable closed-loop behavior are of any interest for control design purposes. Sufficient conditions for stable optimal control require that K = K T &gt; 0, as formulated in the following theorem.</p><p>Theorem I: Let the weighting matrices Q, R with Cholesky factors Q, , Q2, R I be chosen such that n x n skew-symmetric matrix to K .</p><p>Let To, K be chosen as the matrices <ref type="bibr" target="#b30">(32)</ref> Subject to the assumptions made in Al-A7, the optimal control solution of <ref type="bibr" target="#b20">(22)</ref> then gives an L2-stable closed-loop system with the optimal feedback control law</p><formula xml:id="formula_12">U = U* U*( t ) = -R -l ~T ~o n ( t ) . (<label>33</label></formula><formula xml:id="formula_13">)</formula><p>The minimal optimization criterion is then obtained as</p><formula xml:id="formula_14">P O J J( U*) = min /,o L ( 2, U ) dt U = 2, U * ) dt = V ( 2( t o ) , t o ) (<label>34</label></formula><formula xml:id="formula_15">)</formula><p>where V satisfies the Hamilton-Jacobi equation ( <ref type="formula">26</ref>) 0</p><p>Remark: Consider an optimization criterion J , where the matrix S is used for weighting of the cross term between 2 and</p><formula xml:id="formula_16">J I ( " ) = L m L l ( 2 , U ) d t ; Pro08 See Appendix 11. U U 1 L,( 2, U ) = -2 ' ( t ) Q 2 ( t ) 2</formula><p>The Lagrangian L , of (36) can be reformulated as in (37) similar to ( <ref type="formula">22</ref>) and ( <ref type="formula">23</ref>), provided that the symmetric matrix</p><formula xml:id="formula_17">Q -STR-'S &gt; 0 L , ( ~, u ) = -( u ( t ) + R -1 S 2 ( t ) ) T R ( u ( f ) + R P 1 S 2 ( t ) ) 1 2 1 2 + -2 ' ( f ) ( Q -S T R -' S ) 2 ( f ) . (37)</formula><p>The optimal feedback control law U = U* that minimizes J , is</p><formula xml:id="formula_18">~* ( t ) = -R -~( s + B ~T , ) P ( ~) (38)</formula><p>for K , To solving the algebraic matrix equation</p><formula xml:id="formula_19">(( 5') + Q -( S + BTTo)'R-I(S + .'To)) = 0. (39)</formula><p>These equations ( <ref type="formula">30</ref>) and <ref type="bibr" target="#b29">(31)</ref> follow from the same arguments as used in the proof of Lemma 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U VII. ASYMPTOTIC STABILITY</head><p>The function V ( 2 , t ) of ( <ref type="formula">35</ref>) can be viewed as the aggregate of kinetic and potential energy inherent in a set of springs with a stiffness matrix K . The controlled motion remains stable with an equilibrium on the prescribed reference trajectory as long as V does not grow. This physical analogy can be formalized in a stability proof as follows.</p><p>Theorem 2: The function V of ( <ref type="formula">35</ref>) is a Lyapunov function for the system controlled with the optimal control (33) under the assumptions made in Al-A7.</p><p>The Lyapunov function derivative 6' = dV/dt &lt; 0 for 11 I ( 1 # 0 and uniform global asymptotic stability holds for Q &gt; 0, R &gt; 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. THE CONTROL LAW</head><p>The optimal control was calculated with respect to the generalized forces that affect kinetic energy and not with respect to all of the applied forces (gravitation-dependent forces excluded). The optimal control was given as the feedback control</p><formula xml:id="formula_20">U * ( f ) = -R-1B'T02(t). (<label>41</label></formula><formula xml:id="formula_21">)</formula><p>The appropriate external torques T* to apply are then calculated in accordance with the assumptions made in Al-A7 and (l), (17), and ( <ref type="formula">22</ref>)</p><formula xml:id="formula_22">7* = M W ( qr -T,'T,,qL -T,'M(q)-I 1 (( 2 k(q, 4) + N ( q , 4 ) ) BTTo2 + U*)) + c(q, 4)4 + G ( q ) . (<label>42</label></formula><formula xml:id="formula_23">)</formula><p>This control law is considerably simplified for a diagonal TI , = t , , I,,,,,, t , , E R which is obtained for a special choice of Q, R (and S ) , when it becomes unnecessary to involve the complicated M( q ) I in the control law calculations.</p><p>A further simplification of (43) to a case with qr 0, TI, = 0 gives the control law U* with the physical interpretation (10) of minimized torque.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. SELF-OPTIMIZING ADAPTATION</head><p>The calculation of the appropriate applied torques T* corresponding to the optimal control (43) can be viewed as a feedforward control with respect to M , C , G and its accuracy is thus dependent on adequate knowledge of M , C , G (cf. "exact linearization" or the "computed torque" method). In cases with uncertain or time-varying parameters of M , C , G, there is a need of identification and adaptation of the optimal control to the operating conditions. Adaptation of the "exact linearization" or the "computed torque" method is easily implemented only if accelerations are available to measurement. The optimal control algorithm (43) presented here, however, is easily modified for self-optimizing adaptive control.</p><p>The matrices M, C , G are assumed in A6 to have a known structure but the parameters are now assumed unknown (cf. A7). Let the optimal control law be expressed in terms of unknown parameters 0 E R P of M , C , G and the data matrices $ E R" x p , $ O ~R " .</p><p>The matrices $, $o contain terms of T* that can be computed without reference to unknown or uncertain parameters</p><p>The adaptive control la_w is a modification of (44) with 8 replaced by an estimate 0</p><formula xml:id="formula_24">1 t I 1 T = -($6 + $0 + .*)</formula><p>In the case of uncertain parameters, the resulting effective control variable U can be computed from ( <ref type="formula">44</ref>) and ( <ref type="formula">45</ref>) as</p><formula xml:id="formula_25">U = U* + $6; U* = -R -~B ~T ~z (46)</formula><p>where 6 denotes the vector of parameter errors 6 = e^ -8. This control law is no longer optimal in_the sense of ( <ref type="formula">22</ref>) due to the term $0, Let the parameter error 8 be included in a new state vector X that suffices to describe the error dynamics x = (f).</p><p>(47)</p><p>The following Lyapunov design of parameter adjustment can make the solution systematically tend toward the optimal solu- tion. Introduce the following Lyapunov function candidate V,:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vx( x, t ) = v( 2, t ) + V,(6)</head><p>where V is the solution to the Hamilton-Jacobi equation ( <ref type="formula">26</ref>) and Ve is a quadratic functional of parameter errors. Moreover, V, is a function of the full error state with a unique minimum at the origin of error state space. The function V, , is thus feasible as a Lyapunov function candidate for the adaptive (sub)optimal system with the derivative Thus, the system is shown to be globally stable (in the sense of Lyapunov), and the adaptation eventually optimizes the control system. The adaptation thus enables the system to function as a self-optimizing control system or an extremum controller. Performance degradation due to the parameter errors can be evaluated as</p><formula xml:id="formula_26">l o m Z T ( Q + TzBR-'BTTo)Zdt I V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>x ( Z ( t o ) , t o ) = J ( u * ) + VO(B(t0)). (52)</head><p>We summarize and formalize the given statements (44-( <ref type="formula">52</ref>) as shown below in Theorem 3. Theorem 3: Assume that the optimal control U* is determined as stated in Theorem 2. Let the optimal control law be expressed in terms of unknown parameters 8 E R P of M , C , G and the data matrices $ E R" x p , $, E R". The vectors $o contain terms of T* that can be computed without reference to unknown or uncertain parameters M ( q ) ( t l l i j r -TI,$) --k(q, 4)BTToX</p><formula xml:id="formula_27">1 2 + t l l ( C ( q , 4 ) 4 + G ( q ) ) = $8 + $0. (53)</formula><p>The adaptive control law with 0 replaced by an estimate e^ E R is 1</p><formula xml:id="formula_28">tl I T = -($e^ + $0 + U*) e^ = -K , l + T ~T ~o ~. (<label>54</label></formula><formula xml:id="formula_29">)</formula><p>with the adaptation law</p><formula xml:id="formula_30">(55)</formula><p>The Lyapunov function V ,</p><formula xml:id="formula_31">V,@, t ) = -i To T ( M f ) i ) T o i + 2 1 , OTK,6; 2 K O = K T &gt; 0 (56)</formula><p>with the negative semidefinite derivative 1 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6',= 6'+ Po = --Z T ( Q + T r B R -' B T T o ) i ~O ;</head><p>V Z # 0 (57)</p><p>then assures that the self-optimizing adaptive (sub)optimal control solution (54) and ( <ref type="formula">55</ref>) is L2-stable and uniformly globally stable, in the sense of Lyapunov, for constagt parameters 0. The solution reaches the optimal solution for 0 = 0. The adaptive control tracking errors globally converge to zero with all signals remaining bounded. (kg), lengths I,, 1, (m), angular positions q , , q2 (rad): and torques 7 , , r2 (N * m). The cost functional to minim~ze is assumed to be the following:</p><formula xml:id="formula_32">J ( u ) = im(qT q T ) Q ( i) + u T R u d t ; U = r -G ( q )</formula><p>( 5 <ref type="formula">8</ref>)</p><p>with Q = Z4x4, and R = 0.000212,2. The reference values of ( <ref type="formula">4</ref>) are qr = 0, qr = 0. The motion equations of Lagrangian mechanics may be derived from the kinetic and potential energies.</p><p>1 kinetic energy potential energy</p><formula xml:id="formula_33">f ( 4 , q ) = 2 4TM(4)4, 9 (4) = ( m , + m 2 ) gI,c, + m2g12c2,<label>(59)</label></formula><p>-with Fig. <ref type="figure">2</ref> . A two-link manipulator with masses m , and m2 are (60)</p><p>with the short notation c, = cos(q,), s, = sin(q,), etc. The motion equations are 7 = M(q)4 + c(q, 4 where 1 .</p><p>c(q, 4) = 7 M ( q , 4) 4 + G ( q ) ; 0 = m2 <ref type="bibr">(61)</ref> and the gravitation Theorems 1 and 2 are valid for this example with T I , = T2, = &amp;I2</p><p>= 4. The applied forces according to (45) and t</p><p>The resulting control law is then (65)</p><p>Theorems 1 and 2 are valid for this example so that stable optimal control can be anticipated. Simulations are shown in Fig. <ref type="figure" target="#fig_5">3</ref> for m , = 1 (kg), m2 = 10 (kg), I, = 1 (m), and 12.r 1 (m) and initial values q , = q2 = ?r/2 (rad) and zero velocities.</p><p>Notice that the Lyapunov function decreases everywhere (Fig.</p><p>Assume now that the weight of the load m2 = 0 = 10 (kg) is unknown so that adaptation is necessary. Choose the adaptation matrix K O = 0.03. The resulting control law of (54) and ( <ref type="formula">55</ref>) is then 3).</p><p>(66)</p><p>A simulation that includes the self-optimizing adaptation is shown in Fig. <ref type="figure">4</ref> with the initial estimate 0 = 1. All other initial conditions and system parameters are the same as in Fig. <ref type="figure" target="#fig_5">3</ref>. Upper graphs show q l , q2 and middle graphs show 7 , , 7 2 . The lower left graph shows the performance index J ( u ) of ( <ref type="formula">22</ref>), and the lower right graph the Lyapunov function ( <ref type="formula">35</ref>) that decreases everywhere. All graphs versus time (s). Apart from the initial adaptation transients, the result is very similar to the optimal control simulation of Fig. <ref type="figure" target="#fig_5">3</ref>, and thus the algorithm is capable of compensating for tenfold gain variations in the moment of inertia with quite good results.</p><p>XI. DISCUSSION A N D CONCLUSIONS A time-variant optimal control problem of rigid body motion has been solved with explicit solutions to the Hamilton-Jacobi equation. The algorithm optimizes the trajectories with respect to position errors, velocity errors, and the forces (torques) that affect the kinetic energy, but not with respect to gravitation. The optimal solution provides asymptotically stable optimal control. Globally stable adaptive control for self-optimization has been designed to solve the case of uncertain parameters.</p><p>The proposed solutions contribute to an understanding of the close connections between classical mechanics and optimization theory for motion control. The matrix K of (35) represents a spring action around the given reference position, whereas terms containing M ( q ) represent kinetic energy. The Hamiltonian Y = .T+ i/ of analytical mechanics may be compared to the Hamilton-Jacobi solution V ( 2 , t ) that represents a sum of kinetic energy and "potential" energy of a spring action described by a stiffness matrix K . The spring action thus formally replaces gravitation as the source of potential energy.</p><p>The optimal control algorithm presented here exhibits a certain similarity to the linear quadratic control problem. Equation ( <ref type="formula">29</ref>) and the algebraic Riccati equation are similar, but the solutions are very different. Although the Riccati equation solution is positive definite, the present algorithm does not generally provide a symmetric weighting matrix To. Secondly, the sohtion to the Hamilton-Jacobi equation in the linear quadratic control case differs in structure from the solution (35) of the present work.</p><p>The optimal control is globally asymptotically stable, whereas the self-optimizing adaptive control is globally stable in the sense of Lyapunov. In both cases there is global convergence of tracking errors. That there is uniform global asymptotic stability follows from the Lyapunov function property of the solution V( 2, t ) to the Hamilton-Jacobi equation. The uniform stability in the sense of Lyapunov follows from the existence of a negative semidefinite Lyapunov function derivative as shown in Theorem 3. Finite initial conditions and q r , q r € L" mean that ?(a( to), to) is bounded. A finite value of the Lyapunov function V necessarily means a finite magnitude of the tracking errors 4, 4. The L"-stability follows from the fact that the Lyapunov function can only decrease with time. The adaptive control tracking errors globally converge to zero with all signals remaining bounded.</p><p>The solution V ( 2 , t ) to the Hamilton-Jacobi equation has all standard properties of a Lyapunov function with interpretations of energy. Similar Lyapunov functions have been presented outside the context of optimization by <ref type="bibr">Bayard and Wen [3,</ref> although their results are restricted to local stability for certain initial conditions of finite magnitude. Lyapunov design based on similar Lyapunov functions and with global stability properties has been presented in [ 181.</p><p>The control law contains nonlinear and linear compensations that can be calculated with algebraic matrix equations <ref type="bibr" target="#b30">(32)</ref>. The matrices T , I , T I , providing velocity and position feedback are easily computed from the weighting matrices of control optimization. The closed-loop properties may be effectively chosen with the weighting matrices Q , R of <ref type="bibr" target="#b21">(23)</ref>. In turn, these matrices may be chosen according to general design experience in linear quadratic optimal control, the self-optimizing adaptation being chosen with the weighting matrix K O .</p><p>The original problem formulation focuses attention on the minimization of the control effort associated with kinetic energy. This suggests that the term N( q, q ) q of (16) should be included in the considered control variable U although this is a choice and no technical necessity. The forces N ( q , q ) q represent workless forces of the system which may or may not be included in the optimization problem as motivated by applications. The matrix N ( q , q ) may also be replaced in ( <ref type="formula" target="#formula_5">19</ref>) and ( <ref type="formula" target="#formula_6">21</ref>) by some other skew-symmetric matrix that eliminates the third term of (19) in cases when no friction is included in C(q, q ) [so that U = 7 -G(q)]. No restrictions are therefore imposed and we avoid the attention to skew-symmetric matrices appearing recently from technical motivations in robotics [3], [ 191, <ref type="bibr" target="#b28">[30]</ref>, <ref type="bibr" target="#b32">[34]</ref>.</p><p>A noteworthy feature is that the optimization presupposes a nonzero T I , of the state transformation matrix of V to guarantee asymptotic stability. The degenerate solution K = 0 with T ! , = 0, T I , # 0 appears for QZ2 = 0 of ( <ref type="formula">23</ref> This means that velocity and position coordinates are necessarily dependent. The state-space transformation (17) may therefore serve to eliminate some redundance while keeping the full 4) verification that V solves (26). state-space order (cf. <ref type="bibr" target="#b4">[4]</ref>).</p><p>As many practical applications of controlled motion consider operations that must be solved in finite time, it might be argued that the infinite-time problem is less relevant for applied motion control. However, a minor reformulation of the optimization 3) derivation of the U that minimizes H of (24).</p><p>First, it is necessary to verify that V , and thus M ( q ) , is a function of 2 and t only. Notice that the reference value q,(t) is by definition a function of t only. It is then obvious that M ( q ) = M ( 4 + q r ( t ) ) = M ( 2 , t ) . ( A l . 1 ) problem under consideration here suggests that in fact it has wide practical application. The problem with an infinite-time optimization criterion may be viewed as a finite-time problem with a performance optimization together with an end point condition at t = tJ on the closed-loop stability</p><formula xml:id="formula_34">= ./J:L(i,u*) dt + V x ( z ( t f ) , t f ) . (68)</formula><p>Notice that the Lagrangian L is positive so that V,( z( t f ) , t f ) 5 Vx( :(to), to). This makes possible learning action applicable to finite-time operation with periodic or iterative motion. The self-optimizing adaptation of an optimal trajectory intended for periodic motion may thus be made by a few repetitive trials.</p><p>The application potential of the proposed methodology lies in the control design in areas such as robotics and flight control and in motion control analysis (e.g., of biomechanics). Both optimal feedback control laws can be derived and optimal trajectory planning performed with the present approach. The self-optimizing adaptation is valuable both in cases of uncertain or timevarying system parameters and for reconfiguration of the control system. The algorithm determines an optimal trajectory in configuration space that obviously generates a trajectory in Cartesian space. The inverse problem (i.e., the determination of a trajectory in Cartesian space that is translated to configuration space) has not been treated here.</p><p>Only rigid body motion has been explicitly treated here. Structural flexibilities that can be modeled by methods of analytical mechanics may be included in the equations <ref type="bibr">( I )</ref> and thus in the optimal control solution. It should be borne in mind, however, that the method presented here is dependent on access to measurements of all velocity and position variables, a prerequisite which may be a disadvantage with regard to such practical applications as active damping of vibrations.</p><p>Several extensions of the methods described here are possible. Finite-time optimization with a time-varying K ( t ) leads to matrix equations that require matrix inversion of M ( q ) and is thus computationally more complicated than the solution presented here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">APPENDIX I PROOF OF LEMMA 1 A . The Hamilton-Jacobi Equation</head><p>The theorem claims that the Hamilton-Jacobi equation</p><p>The inertia matrix M ( q ) is thus a function of the error state 2 and the time t which implies that V = V ( 2 , t ) . The time derivative of the inertia matrix can be expressed as d M ( <ref type="formula">4</ref>) where q,(t) according to definition is a function of time t only so that </p><formula xml:id="formula_35">dM( 4 + q r ( t ) ) -- - dt dt d M ( q ) d M ( Q + q r ( t</formula><formula xml:id="formula_36">at x k + = Z, an,</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Recently, several others have proposed adaptive control solutions which take the nonlinear actions into account [3], [6], [18], [301, Wl. "Exact linearization" of nonlinear systems as a method for control design has recently attracted considerable interest, both in theory 1151, [27], [29], and in such practical fields as flight control [14] and robotics ("computed torque") [9], [21], [26].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Positions and velocities of rigid body motion are avail-A6: Known structure of M , C , G. A7: Known parameters of M , C , G.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>0Proof:</head><label></label><figDesc>The quadratic function V ( 2, t ) is a suitable Lyapunov function candidate because it is positive radially growing :oL 1201 with ( 1 211. It is continuous and has a unique minjmum at the origin of the error space. It remains to show that V &lt; 0 for all (1 2 1 1 # 0. From the solution of the Hamilton-Jacobi equation (25) it follows that dV/dt + L = aV/at + H * = 0 is constant for U = U* so that d derivative (40) is negative definite and the proposition of the theorem then follows directly from the 0 properties of Lyapunov functions (see [ 121).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>law (45) assures that fix is equal to 6' of (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>0</head><label></label><figDesc>Proof: See Appendix 111.X. A SIMULATED EXAMPLEWe consider trajectory planning for a weight-lifting operation of the two-link example in Fig.1with point masses m , ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Simulation of the robot (61) with the optimal control law (65).Upper graphs show q l , q2 and middle graphs show 7 , , 7 2 . The lower left graph shows the performance index J ( u ) of (22), and the lower right graph the Lyapunov function (35) that decreases everywhere. All graphs versus time (s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 . 2 .</head><label>42</label><figDesc>Fig. 4. Simulation of the robot (61) subject to the self-optimizing adaptive control law (66). Upper graphs show q l . q 2 , and middle graphs 7 ] and r 2 . The lower left graph shows the estimate e^ of m,, and the lower right graph the Lyapunov function (35) that decreases everywhere. All graphs versus time (s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>), i.e., in cases without any penalty on position errors. The state-space transformation obtained with To might be understood from a linear systems viewpoint. State-space equations of stable linear systems expressed in variables of velocities and positions (4) contain a dynamics matrix with eigenvectors U = (. : , , ; ) obtained from the eigenvalue problem i -:d -0". j (1; j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1 )</head><label>1</label><figDesc>a M ( n, t ) 2 n a M ( 2 , t ) derivatives of the function V need to be evaluated in order to test the hypothesis that V solves the Hamilton-Jacobi equation. The partial derivative of V with respect to time is The gradient of V with respect to the error state 2 is av(n, t )is satisfied for a function ___ = T l ( M ( n ' t , oflxfl)verification that V = V ( 2 , t ) , 2) evaluation of partial derivatives of V , O n x n O n x n 2the interior of V( .f( t ) , t ) = v, and continuity considerations 1211 C. S . G. Lee. "Robot arm kinematics. dvnamics and control." IEEE based on (A3.2) show that .f(t)must also penetiate this interior. 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>) ) --d M ( n + x r ( t ) )</figDesc><table><row><cell>--</cell><cell>-</cell><cell></cell></row><row><cell>dt</cell><cell>dt</cell><cell>dt</cell></row><row><cell></cell><cell>2n a M ( n , t )</cell><cell>a M ( a , t )</cell><cell>(AI .2)</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A fourth step is now to verify that the suggested V satisfies (26).</p><p>The time derivative of V is composed of (A1.9) and (A1.4)-(A1.5) KT,'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">(23)</head><p>---F( (i</p><p>A candidate of the Hamiltonian H (24) is the sum of (Al.9) and (23). A third step is now to evaluate how H depends on U E R " .</p><p>The U = U* for which H has its minimum value is obtained </p><p>The optimal feedback control law</p><p>Let the weighting matrix Q, R of the Lagrangian be factorized with Cholesky factorizations Ql , Q 2 , R I of (3 1) and choose</p><p>Application of these factorizations and the conditions of <ref type="bibr" target="#b29">(31)</ref> directly show that K = K T &gt; 0. The matrices K , To of <ref type="bibr" target="#b30">(32)</ref> solve the algebraic matrix equation of ( <ref type="formula">29</ref>)</p><p>or with application of <ref type="bibr" target="#b30">(32)</ref> (A2.</p><p>2)</p><p>The Hamilton-Jacobi equation is satisfied because Notice that V L 0 for all positive definite K . The cost function may then be evaluated as</p><p>The optimality of the control follows from (A2.3) and it follows that 8 ~L ~( t , , t,), V t &gt; to. The claim on L2-stability follows immediately from (Ad4). From <ref type="bibr" target="#b29">(31)</ref> and <ref type="bibr" target="#b30">(32)</ref> it follows that K = K &gt; 0 and the inertia matrix M ( q ) is positive definite by definition <ref type="bibr" target="#b6">(1)</ref>. The function V has a unique minimum at the origin. It is also nonnegative and radially growing w.r.t. )I 211 for all t L to so that it fulfills all requirements on a Lyapunov function candidate. The time derivative dV/dt &lt; 0 which implies that Y is a Lyapunov function for a uniformly globally 0 asymptotically stable system. This finishes the proof.</p><p>APPENDIX 111 PROOF OF THEOREM 3</p><p>The scalar function Vx( 2, t ) of (56) subject to the conditions 1) Vx( X , t ) &gt; 0 and Vx( 2, t ) = 0 if and only if 2 = 0 for 2) v,(X, t ) is conQnuous at 2 = o for all t , 3) limII,ql14m V,(X, t ) = + C O for all r , 4) d V x ( X , t ) / d t 5 0 for 2 # 0 for all t [cf. (57)] of the theozem is such that: all t , and thus fulfills requirements of Lyapunov functions 1121, <ref type="bibr">[24, pp. 396-3971.</ref> Equation ( <ref type="formula">57</ref>) is immediately verified by application of ( <ref type="formula">55</ref>) to (49) under the conditions of constant parameters 8 and Theorems 1 and 2. It follows-from (57) that V, can only dscrease .w$h time so that X E L" and thus, so that X , 8, @, @,e, U* EL". The Lyapunov-function derivative is negative semidefinite with respect to X and negative definite with respect to I. The solution reaches the optimal solution for e = 0. Bounded reference values qr, qr,jr E L" and finite initial conditions of q, q imply that V x ( X ( t o ) , to) is bounded. The following performance measure derived from (57), <ref type="bibr">(46)</ref> gives that:</p><p>It follows that 2,. U * , @, G,E L2 and thus 2 , g, 4, U* E L2 f l L".</p><p>The derivatives 8, I$, i, 2, the matrices $, $o, and the control variables U , 7 are continuous bounded functions-in L" of the variables 2 , q, q, q r , q r , q,. This implies that X , I, @, and 4" are continuous functions of time.</p><p>The convergence of 2( t ) can be studied by integrating (57) as -1 L;2'QI + u*TRu*dt where the right-hand side is a monotonously decreasing function of time. Note that the level loci</p><p>are compact subsets of R2" for each c E R , . Thus, each such level locus separates the space R2" into two regions and the origin lies in Ihe interior region where V ( 2 , t ) 5 c. For each initial point X ( t o ) E R2"+P-consider the solution curve X ( t ) initiating at X ( to). Along X ( t ) we compute the rate of change of V (and V X ) according to_ (57) and so I( t ) zemains within the region V ( Z ( t ) , f) &lt; V x ( X ( t o ) , to). Thus, X l t ) and I(t) are define? on to 5 t &lt; y. Moreover, if X ( t o ) = 0, then Vx( X , t ) = 0 so that X ( t ) = 0 and 2 ( t ) = 0. If I([,) # 0, then I(t) tends inwards across the level hypersurfaces of V ( I , t ) as follows from (A3.2). Assume that Iimt+" V ( R ( t ) , t ) = Y, L 0. If V, &gt; 0, then some point Im in the hypersurface V ( 2, t ) = V, must be approached arbitrarily closely by I( t).</p><p>However, the solution commencing at Im # 0 penetrates into</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">On the stability of PID-feedback with sensory information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miyazaki</surname></persName>
		</author>
		<editor>Robotics Research, M. Brady and R. P. Paul</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Arnold</surname></persName>
		</author>
		<title level="m">Mathematical Methods of Classical Mechanics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page">255</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">New class of control laws for robotic manipulators, Part 2: Adaptive case</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Bayard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Contr</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">we conclude that V, = 0 and 1imt+, 2(r) = 0</title>
		<author>
			<persName><surname>Thus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>M.I.T. Press</publisher>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="7" to="1406" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Control of constrained systems of controllability index two</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Ceranowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Wyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hemami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1102" to="1111" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Introduction to Robotics-Mechanics and Control</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Craig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
	<note>ch. 6</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive control of mechanical manipulators</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Robot. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The application of model reference adaptive control to robotic manipulators</title>
		<author>
			<persName><forename type="first">'</forename><forename type="middle">S</forename><surname>Dubowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Desforges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. ASME J . Dynam. Syst., Meas.. Contr</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<publisher>DD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Rishel</surname></persName>
		</author>
		<title level="m">Deiehninkic and Stochastic Optimal Control</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The structure of decoupled nonlinear systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Freund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Contr</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="443" to="450" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
		<title level="m">CIassical Mechanics</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Goodwin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Sin</surname></persName>
		</editor>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Adaptive Filtering, Prediction and Control</publisher>
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Hahn</surname></persName>
		</author>
		<title level="m">Stability of Motion</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">55</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonlinear decoupling via feedback: A differential geometric approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hemami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">A</forename><surname>Isidori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><surname>Monaco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="331" to="345" />
			<date type="published" when="1981">1984. 1981</date>
		</imprint>
	</monogr>
	<note>Int. J . Robot. Res.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Global transformations of nonlinear systems</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="24" to="31" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Direct adaptive control-Global Lyapunov stability and exponential convergence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th IEEE CDC</title>
		<meeting>25th IEEE CDC<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parametric models of linear multivariable systems for adaptive control</title>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="303" to="313" />
		</imprint>
	</monogr>
	<note>Lyapunov design for adaptive control of robots</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IFAC Nonlinear Contr. Syst. Design Symp</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<pubPlace>Capri, Italy</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Natural control of robot arms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koditschek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Decision Contr</title>
		<meeting>IEEE Conf. Decision Contr<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="733" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive linear controller for robotic manipulators</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Koivo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="94" to="97" />
			<date type="published" when="1975">1975</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">~-Computer</forename><surname>Mag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="62" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A suboptimal control design for mechanical manipulators</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACC</title>
		<meeting>ACC</meeting>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="1056" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An adaptive control strategy for mechanical manipulators</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="837" to="840" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Markus</surname></persName>
		</author>
		<title level="m">Foundations of Optimal Control Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">348</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Linear quadratic design of PID controllers for robot arms</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Saridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J . Robot. Automat</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
	<note>RA-I</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Paul</surname></persName>
		</author>
		<title level="m">Robot Manipulators-Mathematics, Programming and Control</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Diagonalization and inverses for nonlinear systems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Eontr</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="67" to="76" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An approximation theory of optimal control for trainable manipulators</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Saridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="152" to="159" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Decoupling in a class of nonlinear systems by state variable feedback</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Rugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. ASME J . Dynam. Syst., Measure., Contr</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="323" to="324" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the adaptive control of robot manipulators</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J E</forename><surname>Slotine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Robot. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="49" to="59" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modelling and identification of mechanical systems with nonlinearities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jabbarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Auslander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Denome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th IFAC/IFORS Symp</title>
		<meeting>7th IFAC/IFORS Symp<address><addrLine>Identfication, York, U.K</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="845" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A method for optimal synthesis of manipulation robot trajectories</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vukabratovif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kirfanski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Dynam. Syst., Meas., Contr</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="188" to="193" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards nonadaptive and adaptive control of manipulation robots</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vukabratovid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stokid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kirfanski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="841" to="844" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">New class of control laws for robotic manipulators. Part. 1. Non-adaptive case</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Bayard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J . Contr</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1361" to="1386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>M.I.T. Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m">Rolf Johansson (S&apos;81-M&apos;82) was born in Osby, Scandinavia. He received the M.D. degree from Lund University, Lund, Sweden, and the Ph.D. degree in control theory from the Lund Institute of Technology</title>
		<meeting><address><addrLine>Lund, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">He is currently with the faculty of the Department of Automatic Control at the Lund Institute of Technology, Lund, Sweden, and is also associated with the Department of Otorhinolaryngology</title>
	</analytic>
	<monogr>
		<title level="m">His research interests are in control theory, robotics, system identification, signal processing, biomedical engineering, and neurophysiology</title>
		<imprint>
			<publisher>Lund University Hospital</publisher>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
	<note>he spent six months with CNRS at the Laboratoire d&apos;Automatique de Grenoble, France</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
