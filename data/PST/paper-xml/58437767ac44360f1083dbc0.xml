<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HEVC-compliant Tile-based Streaming of Panoramic Video for Virtual Reality Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alireza</forename><surname>Zare</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Signal Processing</orgName>
								<orgName type="institution">Tampere University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alireza</forename><surname>Aminlou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Signal Processing</orgName>
								<orgName type="institution">Tampere University of Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nokia Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miska</forename><forename type="middle">M</forename><surname>Hannuksela</surname></persName>
							<email>miska.hannuksela@nokia.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Nokia Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Moncef</forename><surname>Gabbouj</surname></persName>
							<email>moncef.gabbouj@tut.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Signal Processing</orgName>
								<orgName type="institution">Tampere University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">HEVC-compliant Tile-based Streaming of Panoramic Video for Virtual Reality Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4DADD9F9FAC20961DF48E7404A9108D1</idno>
					<idno type="DOI">10.1145/2964284.2967292</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Video Coding</term>
					<term>HEVC</term>
					<term>Tiles</term>
					<term>Panoramic Video Streaming</term>
					<term>Virtual Reality</term>
					<term>Head-mounted Display (HMD)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Delivering wide-angle and high-resolution spherical panoramic video content entails a high streaming bitrate. This imposes challenges when panorama clips are consumed in virtual reality (VR) head-mounted displays (HMD). The reason is that the HMDs typically require high spatial and temporal fidelity contents and strict low-latency in order to guarantee the user's sense of presence while using them. In order to alleviate the problem, we propose to store two versions of the same video content at different resolutions, each divided into multiple tiles using the High Efficiency Video Coding (HEVC) standard. According to the user's present viewport, a set of tiles is transmitted in the highest captured resolution, while the remaining parts are transmitted from the low-resolution version of the same content. In order to enable selectively choosing different combinations, the tile sets are encoded to be independently decodable. We further study the tradeoff in the choice of tiling scheme and its impact on compression and streaming bitrate performances. The results indicate streaming bitrate saving from 30% to 40%, depending on the selected tiling scheme, when compared to streaming the entire video content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS Concepts</head><p>• Multimedia and Vision➝Video coding and streaming in support of vision applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This work is motivated by the fact that in many displaying situations only part of the whole video frame is displayed while the remaining parts are decoded but not displayed. For example, this occurs in applications where the same wide-angle high-resolution video content serves a number of devices with different specifications (e.g. display size). One approach would be to deliver a spatially down-sampled representation of the entire video to suit the end-user device's capability. However, this approach results in a decreased sense of immersion at the client terminal, which contradicts with the gist of virtual reality (VR) applications where an immersive viewing experience is the main goal. This paper studies such condition in panoramic video streaming for VR applications using head-mounted displays (HMD). The field of view (FOV) in the current commercially available HMDs is in the range of 96° to 110° <ref type="bibr" target="#b4">[4]</ref>. Considering the limited HMD's FOV, only part of the video frame is needed to be displayed at a time, while the input video for HMDs consumption often covers the entire 360°.</p><p>When using HMDs, as the user turns his/her head, an appropriate view, corresponding to the user's viewport, has to be presented. Latency to presenting a new perspective of the scene severely affects the usability of such devices. In fact, one of the most important attributes of the HMDs is to provide fast dynamic response to the user's interaction. This results in well synchronization of user's movements with the displayed scene. The conventionally streaming of the full 360° video content entails a high streaming bitrate, and may also cause a risk of network and/or access link congestion and re-buffering, which is an impediment to providing low enough latency operation. Furthermore, in the enduser device the coded pictures have to be fully decoded, since they have strong dependencies including: spatial dependencies (e.g., intra prediction), entropy coding dependencies, in-loop filtering dependencies, and spatio-temporal dependencies (i.e., motion vectors pointing to different parts of the reference pictures).</p><p>Tile-based panoramic video streaming is a particular way of panoramic video streaming, in which only part of the whole picture is transmitted, instead of the full picture. In the server side, an encoder is configured to divide video pictures into a desired number of tiles with various possible arrangements in order to meet the requirements of the application under consideration. In the client side, each user receives a set of tiles on the basis of, for example, the present viewing orientation or a region of interest (ROI). This approach relies on motion-constrained tile sets (MCTS) concept which enables the support for decoding a freely-selected set of tiles. MCTSs have been utilized for different applications in the literature. Both <ref type="bibr" target="#b2">[2]</ref> and <ref type="bibr" target="#b7">[7]</ref> propose compressed-domain approaches for merging different video contents using a combination of tiles and slices. These approaches were proposed to serve several purposes including: transport complexity reduction and enabling support for devices with a single hardware decoder. In <ref type="bibr" target="#b8">[8]</ref> a tilebased panoramic streaming solution is presented, with the aim of reducing the transmission bitrate at ROI switching points. This paper takes advantage of MCTSs for streaming panorama video to a HMD. In our work, similar encoder restrictions as proposed in <ref type="bibr" target="#b2">[2]</ref> and <ref type="bibr" target="#b7">[7]</ref> are used. Contrary to them, we allow motion vectors to point outside tile boundaries within a specific set of tiles which are always streamed together. In order to guarantee low latency operation, we propose to transmit the tile sets corresponding to the user's current viewport in the highest captured resolution and the remaining parts from a low-resolution representation of the captured scene.</p><p>The proposed method in this paper uses the standard HEVC decoding, unlike <ref type="bibr" target="#b2">[2]</ref>, which requires modifications to the candidate list derivation for HEVC motion vector prediction. Furthermore, we present methods to construct an HEVC full-picture-compliant bitstream out of a MCTS such that standard HEVC decoders can cope with that, as opposed to requiring a specialized decoder to Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. MM '16, October 15-19, 2016, Amsterdam, Netherlands © 2016 ACM. ISBN 978-1-4503-3603-1/16/10…$15.00 DOI: http://dx.doi.org/10.1145/2964284.2967292 process only the MCTS from the original panorama bitstream. We also study different tile partitioning arrangements for 360° panorama video and discuss the related practical limitations and respective solutions.</p><p>The rest of paper is organized as follows. Section 2 presents background. In Section 3, an overview of the proposed VR streaming system is provided and the proposed tiling schemes along with their practical limitations and respective solutions are described. The simulation results are evaluated in Section 4 and finally the paper is concluded in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>In the HEVC standard <ref type="bibr">[6]</ref>, a video picture is partitioned into squareshaped regions called coding tree unit (CTU) which represents the basis of the coding process. Similar to the slices, as already known from the Advanced Video Coding (AVC) standard, an integer number of CTUs are aggregated into a tile <ref type="bibr" target="#b5">[5]</ref> to form CTU-aligned picture partitioning. When tiling is enabled, a video picture is horizontally and vertically divided into columns and rows. Compared to slices, tiles are always rectangular. Furthermore, tiles provide more flexibility to partitioning and appear to incur less compression penalty since tiles do not contain any header.</p><p>Intra-picture prediction does not cross tile boundaries and entropy coding state is re-initialized at the beginning of every tile <ref type="bibr" target="#b9">[9]</ref>. Hence, each constructed tile is independently decodable from other tiles within the same picture. In terms of inter-picture prediction, however, motion vectors can freely point to any predictor beyond the co-located tile boundaries in the reference pictures. Nevertheless, following the spirit of isolated regions suggested in <ref type="bibr" target="#b3">[3]</ref>, motion vectors are restricted in encoding to only point to the co-located tiles in the reference pictures. This results in constructing motion-constrained tiles (MCT). Extending the restriction further onto a set of tiles leads to the concept of motionconstrained tile set (MCTS) in which motion vectors are allowed to cross tile boundaries within the tile set but not across the tile set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of the System</head><p>An overview of the proposed VR streaming system is depicted in Figure <ref type="figure">1</ref>, where the proposed tile-based streaming approach is employed. In the server side, we propose to store two versions of the same panoramic video content at different resolutions. An HEVC encoder, in which tile sets are motion constrained, is configured to divide video pictures into a desired number of tiles based on the tiling schemes described in the next subsection. The encoding may be performed offline or in real-time for live content. The encoding results in two separate HEVC-conforming bitstreams.</p><p>According to the present viewing orientation, a tile set request is signaled to the server by the end-user device. The server dynamically identifies the requested tile sets from the client based on a sensory feedback. An intermediate extractor, which may for example be a script running in an origin or edge server, extracts the tile set corresponding to present viewing orientation from the highresolution bitstream. The remaining parts are collected from the low-resolution bitstream, in order to cover the entire captured FOV. The extractor then constructs two independent full-picture bitstreams including the requested MCTS from the high-and lowresolution bitstreams. The outgoing bitstreams are HEVCcompliant. This allows to realize the proposed approach in realworld applications using HEVC Main Profile hardware decoders, available today in the market.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proposed Tiling Schemes</head><p>Assuming panoramic video playback in HMDs, three tiling arrangements are considered as follows: 1) the horizontal FOV is split into 6 tile columns with each having 60° FOV and the vertical FOV is divided into three tile rows with 45°-90°-45° FOVs, resulting into an 18-grid partitioning, 2) while in vertical direction the same tiling scheme as in 1 is considered, the horizontal FOV is split into 4 tile columns with each having 90° FOV, resulting into a 12-grid partitioning, and 3) in both directions a 90° FOV partitioning is performed, resulting into 4 tile columns and 2 tile rows, in total 8 tiles. The abovementioned tiling arrangements are depicted in Figure <ref type="figure">2a</ref>, Figure <ref type="figure">2b</ref>, and Figure <ref type="figure">1</ref>, respectively.</p><p>The idea behind the first two selected tiling schemes is that looking significantly upwards and downwards is rare while using HMDs. Therefore, the most top and bottom parts form separate tile rows from the middle tile row which comprises tiles with higher heights. This arrangement allows to either stream the top and bottom parts at a lower bitrate or avoid streaming them. The idea is further supported by typical trait of panoramic videos in which pixels at the top and bottom appear stretched. The third partitioning scheme is suggested to study the trade-off between simplifying the proposed approach and the cost introduced by the simplification. There are some cases where tiles are not CTU-aligned in the tiled high-and low-resolution video sequences. This may occur, for example, because of the considered restriction on the minimum tile width in the HEVC standard. Consequently, this results in different tiling scheme in the low-resolution video sequence than in the highresolution one. This introduces some overlap area between the selected tile sets from high-and low-resolution bitstreams. The third scheme allows avoiding such situation. In addition, it is adequate for applications in which wide FOV in both vertical and horizontal directions is required (e.g., because video sequences do not have the abovementioned trait). Furthermore, we assume that it is relatively rare that the user would peek straight at the middle of tiles, in which case a single tile would often be sufficient to cover central part of FOV while periphery area are taken from a lowresolution bitstream. Consequently, in most cases, a 2x2 set of highresolution tiles need to be transmitted (see Figure <ref type="figure">1</ref>).</p><p>In the first two selected tiling scheme, the proposed MCTS is realized in such way that top and bottom tile rows are allowed to be predicted from the middle tile row within the same tile column. However, motion vectors from the middle tile row are restricted to point to the top and bottom tile rows. This is suggested based on the fact that tiles from the middle tile row within a tile set are always subject to be transmitted. In the third scheme, motion vectors are restricted within tile boundaries and are not allowed to break tile set boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Practical Limitations and Solutions</head><p>There are some limitations which have to be addressed in order to deploy the proposed approach in real-world applications. These limitations and respective solutions are discussed in the following:</p><p>1) At view switching points, the switching between tile sets can only take place at an intra-coded picture. As a solution, the entire low-resolution video sequence, which contains all view orientations, can be transmitted in order to provide no latency at view switching points. In this case, the entire low-resolution bitstream is streamed along with the selected tile set from highresolution bitstream at all times.</p><p>2) There are some cases in which the extracted tile set from the lowresolution bitstream cannot be arranged within a single picture (e.g., because of having tiles with different widths/heights). Here the extractor uses an artificially generated tile with the minimal bitstream size in order to provide a conforming extracted bitstream.</p><p>3) In the HEVC standard, the end of a slice is indicated using entropy-coded end_of_slice_flag which is set to one if the current CTU is the last CTU in the slice. This causes the extractor to construct a non-confirming bitstream in cases where the right-most tile, in which the flag is set, in the high-resolution bitstream is not included in the extracted tile set. The reason is that the decoder does not meet the end of slice condition while decoding the last CTU within the picture in the extracted bitstream. We propose two alternatives to deal with this problem. The first solution is to attach a dummy tile of minimal size at the end of each picture in the compressed domain, such that the end of slice condition is met. The second solution is to use a combination of tiles and slices in a way that each tile contains one slice (i.e., their boundaries match). Both solutions come along with a cost of increase in bitrate because of dummy tile or slice header overhead, respectively. However, in our experiments, the dummy tile solution is shown to incur lower compression penalty at the cost of increasing complexity because of the required processes for attaching and decoding dummy tile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Conditions</head><p>The performance of the proposed tile-based streaming approach was evaluated in terms of storage and streaming bitrate measurements. The approach was also analyzed based on its benefit on decoding complexity reduction in an end-user device.</p><p>The proposed approach was compared against two legacy solutions: 1) an end-user device receives a panoramic video sequence with the entire captured FOV and 2) all possible tile sets are cropped from high-and low-resolution sequences, in pixel domain, and encoded as separate bitstreams in server side, in which no tiling is required.</p><p>The encoder was configured to divide the video sequences in a regular manner, in which each tile occupies the same spatial region over all pictures. MCTSs were implemented into the HEVC reference software (HM) version 16.7 <ref type="bibr" target="#b10">[10]</ref>. The standard HM decoder was used to examine HEVC conformance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Result Analysis</head><p>The usage of tiles and constraining motion within the tile set boundaries incur compression efficiency penalty since the imposed restrictions reduce the correlation among pixel samples. Table <ref type="table" target="#tab_1">1</ref> shows that on average the incurred penalties for the 18-grid, 12grid, and 8-grid partitioning schemes are 5.82%, 3.70%, and 3.18%, respectively. The finer the partitioning is, the higher compression loss occurs. As can be seen from Table <ref type="table" target="#tab_1">1</ref>, the compression loss is higher for sequences containing large object motion. In addition, the highest costs occur for sequences which were captured by moving cameras. This is explained due to crossing objects among tile sets that increases percentage of intra-coded blocks.</p><p>The basic alternative to the MCTS is pixel-domain cropping of all possible tile sets and encoding each tile set as separate sequence.</p><p>The compression performance of this technique is shown in Table <ref type="table">2</ref>, only average result is presented due to the lack of space. The result indicates that its compression penalty is very close to that of the proposed tile-based approach. However, if full panorama versions were to be also provided with this alternative, e.g. to serve legacy clients, the server-side storage requirement would be roughly doubled, compared to the proposed approach.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the streaming bitrate saving achieved by using the proposed approach, when compared with transmitting the entire captured FOV in high resolution. It shows significant reduction in streaming bitrate by 40.64%, 33.44%, and 29.58% on average for the 18-grid, 12-grid, and 8-grid partitioning schemes, respectively. It is expected to have less streaming bitrate saving as coarser partitioning scheme is used since the extracted high-resolution tile sets cover a higher FOV. For example, each extracted tile set in 18grid tiling scheme covers 120° horizontal FOV, while in case of 12grid tiling it covers 180° horizontal FOV. However, coarser partitioning allows higher switching view latency because of the provided extraneous peripheral vision.</p><p>As can also be observed from Table <ref type="table" target="#tab_2">3</ref>, in 18-grid scheme, the streaming bitrate saving is less for MyShelter-sta and MySheltermov sequences compared to the other sequences. This is because of the overlapping problem between the selected tile sets from highand low-resolution bitstreams, as discussed in Section 3.2. Furthermore, in order to address the problem of strict low-latency requirement at view switching points, one proposed solution (see Section 3.3) is to transmit the entire low-resolution bitstream, which contains all view orientations. In this experiment, this causes on average 12% streaming bitrate overhead compared with the case where the low-resolution is transmitted partially.</p><p>By comparing the results presented in Table <ref type="table" target="#tab_2">3</ref> and Table <ref type="table" target="#tab_3">4</ref>, we can see that both tile-base streaming approaches (i.e., the proposed tilebased streaming and its alternative, pixel-domain cropping of all possible tile sets) provide very close streaming bitrate saving. This is expected by noticing that both techniques provide similar compression performance, as discussed above.</p><p>In Figure <ref type="figure" target="#fig_1">3</ref>, rate-distortion curve for the Daisy sequence is illustrated. It can be observed that higher streaming bitrate saving is achieved at higher bitrates. This is appreciated in HMDs which typically consume high-quality content. Although only the RD curve related to the Daisy sequence is presented, the similar behavior is observed for the other video sequences.</p><p>Although a comparison of decoder complexity between the proposed tile-base streaming approach and the case where the decoder receives entire captured FOV is not presented, it is obvious that the proposed solution provides a much lower decoding complexity by lowering the computational burden of decoding. The number of pixels to be decoded is reduced by approximately 69%, 47%, and 37% for 18-, 12-, and 8-grid partitioning schemes, respectively, when compared to decoding of high-resolution panorama video clips.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION AND FUTURE WORK</head><p>In this paper, we proposed an HEVC-compliant approach for efficient streaming of panoramic video clips for virtual reality applications using motion-constrained tile sets. The encoder restrictions necessary to enable the proposed tile-based streaming technique were discussed. We studied the performance of the proposed approach based on three tiling variants that are adequate to be utilized in head-mounted displays. While smaller tile size enables higher streaming bitrate saving, it introduces more compression loss. The incurred compression penalty in order to enable the proposed solution ranged from 3% to 6%, depending on the selected tiling scheme. However, a significant streaming bitrate saving from 30% to 40% was achieved. This enables greater flexibility of streaming VR content in high fidelity over various access networks. In addition, the proposed approach considerably reduces the computational burden of decoding. This leads to battery power saving in end-user devices. The simulation results demonstrated the approach practical to be deployed in the realworld applications in the future. As the next step in our future work, we plan to enable the proposed approach for stereoscopic panoramic video contents. Additionally, we plan to assess and validate the perceived user experience of the proposed approach.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .Figure 1 .</head><label>21</label><figDesc>Figure 2. a) 18-grid tiling b) 12-grid tiling</figDesc><graphic coords="2,323.80,630.00,231.30,74.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. RD-curve, tile-based vs. entire FOV streaming, for Daisy sequence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The reported experiments were conducted on eight equirectangular video sequences with divergent contents in different spatial resolutions, namely, MyShelter-sta, MyShelter-mov, Daisy, Lisboa, Sheriff, VRC-concert, Kremlin, and Moscow. The first five sequences contain large and slow-motion objects. VRC-concert sequence captured a detailed scene with slow-motion objects. The two last sequences show detailed scenes containing fast-motion objects, which in the case of Kremlin are caused due to the sequence being a time-lapse video clip. MyShelter-mov, Lisboa, and VRC-concert sequences were acquired by moving cameras. All sequences were captured in real world except the Sheriff sequence which is a computer animated sequence. The high-resolution sequences were down-sampled by a factor of two in both horizontal and vertical directions in order to obtain the low-resolution versions. The simulations were performed using Main profile random access configuration with 49 frames per sequence and quantization parameters (QP) values 22, 26, 30, and 34. The compression performance and streaming bitrate saving measurements are expressed in terms of Bjøntegaard Delta-rate (BD-rate) criterion<ref type="bibr" target="#b1">[1]</ref> for luma pictures, where positive/negative values indicate how much the bitrate is increased/reduced for the same peak signal-tonoise (PSNR) value.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 . Compression performance of MCTS (BD-Rate (%))</head><label>1</label><figDesc></figDesc><table><row><cell>Sequences</cell><cell>Resolution</cell><cell>18-grid</cell><cell>12-grid</cell><cell>8-grid</cell></row><row><cell></cell><cell>(WxH)</cell><cell>tiling</cell><cell>tiling</cell><cell>tiling</cell></row><row><cell>MyShelter-sta.</cell><cell>2048x1024</cell><cell>5.42</cell><cell>4.16</cell><cell>3.16</cell></row><row><cell cols="2">MyShelter-mov. 2048x1024</cell><cell>12.08</cell><cell>7.14</cell><cell>6.02</cell></row><row><cell>Daisy</cell><cell>3072x1536</cell><cell>4.20</cell><cell>2.78</cell><cell>3.35</cell></row><row><cell>VRC-concert</cell><cell>3072x1536</cell><cell>10.42</cell><cell>5.95</cell><cell>3.97</cell></row><row><cell>Kremlin</cell><cell>4096x2048</cell><cell>1.27</cell><cell>0.87</cell><cell>0.59</cell></row><row><cell>Lisboa</cell><cell>4096x2048</cell><cell>8.02</cell><cell>5.11</cell><cell>4.91</cell></row><row><cell>Moscow</cell><cell>4096x2048</cell><cell>1.59</cell><cell>1.14</cell><cell>1.16</cell></row><row><cell>Sheriff</cell><cell>4096x2048</cell><cell>3.53</cell><cell>2.42</cell><cell>2.29</cell></row><row><cell>Average loss</cell><cell></cell><cell>5.82</cell><cell>3.70</cell><cell>3.18</cell></row><row><cell cols="5">Table 2. Compression performance of pixel-domain cropping</cell></row><row><cell cols="4">tile sets technique (BD-Rate (%))</cell><cell></cell></row><row><cell></cell><cell>18-grid</cell><cell>12-grid</cell><cell>8-grid</cell><cell></cell></row><row><cell></cell><cell>tiling</cell><cell>tiling</cell><cell>tiling</cell><cell></cell></row><row><cell>Average loss</cell><cell>5.73</cell><cell>3.73</cell><cell>3.18</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 . Streaming bitrate performance of tile-based streaming technique using MCTS (BD-Rate (%)), compared with transmitting the entire captured FOV</head><label>3</label><figDesc></figDesc><table><row><cell>Sequences</cell><cell>18-grid</cell><cell>12-grid</cell><cell>8-grid</cell></row><row><cell></cell><cell>tiling</cell><cell>tiling</cell><cell>tiling</cell></row><row><cell>MyShelter-sta.</cell><cell>-34.60</cell><cell>-31.99</cell><cell>-27.57</cell></row><row><cell cols="2">MyShelter-mov. -32.10</cell><cell>-30.44</cell><cell>-26.47</cell></row><row><cell>Daisy</cell><cell>-41.90</cell><cell>-34.64</cell><cell>-27.74</cell></row><row><cell>VRC-concert</cell><cell>-41.85</cell><cell>-34.23</cell><cell>-29.56</cell></row><row><cell>Kremlin</cell><cell>-42.66</cell><cell>-33.87</cell><cell>-30.28</cell></row><row><cell>Lisboa</cell><cell>-44.96</cell><cell>-34.66</cell><cell>-32.43</cell></row><row><cell>Moscow</cell><cell>-44.14</cell><cell>-34.43</cell><cell>-31.69</cell></row><row><cell>Sheriff</cell><cell>-42.90</cell><cell>-33.29</cell><cell>-30.91</cell></row><row><cell>Average gain</cell><cell>-40.64</cell><cell>-33.44</cell><cell>-29.58</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 . Streaming bitrate performance of pixel-domain cropping tile sets technique (BD-Rate (%)), compared with transmitting the entire captured FOV 18-grid tiling 12-grid tiling 8-grid tiling Average gain</head><label>4</label><figDesc></figDesc><table><row><cell>-40.49</cell><cell>-33.88</cell><cell>-31.89</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Calculation of average psnr differences between rd-curves, document VCEG-M33</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bjøntegard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient stream-reassembling for video conferencing applications using tiles in HEVC</title>
		<author>
			<persName><forename type="first">C</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cellarius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MMEDIA 2013, The Fifth International Conferences on Advances in Multimedia</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Isolated regions in video coding</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hannuksela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Multimedia</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="259" to="267" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">VR HMD Roundup: Technical Specs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Mason</surname></persName>
		</author>
		<ptr target="http://uploadvr.com/vr-hmd-specs/" />
		<imprint>
			<date type="published" when="2016-04-20">2016. April 20</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An overview of tiles</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Segall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuldseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Sig-nal Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="969" to="977" />
			<date type="published" when="2013-12">2013. Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Rosewarne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naccari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sharman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sullivan</surname></persName>
		</author>
		<title level="m">High Efficiency Video Coding (HEVC) test model 16 (HM 16), Document JCTVC-U1002</title>
		<meeting><address><addrLine>Warsaw</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06">2015. Jun. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Low complexity cloud-video-mixing using HEVC</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Globisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schierl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CCNC -Multimedia Networking, Services and Applications</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compressed domain video processing for tile based panoramic streaming using HEVC</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Skupin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schierl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference onImage Processing (ICIP)</title>
		<meeting><address><addrLine>Quebec City, QC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Block structures and parallelism features in HEVC</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schierl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Efficiency Video Coding (HEVC): Algorithms and Architectures</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="49" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="https://hevc.hhi.fraunhofer.de/" />
		<title level="m">High Efficiency Video Coding (HEVC) reference software HM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Fraunhofer Institute for Telecommunications, Heinrich Hertz Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
