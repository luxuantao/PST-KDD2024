<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Y</forename><surname>Li</surname></persName>
							<email>ye.li@siat.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">search Center for Health Big Data Intelligent Analysis Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institutes of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Shenzhen Institutes of advanced technology. Shenzhen</orgName>
								<orgName type="laboratory">Key Laboratory for Health Informatics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B4002CD984CF26CD5165576C2731E425</idno>
					<idno type="DOI">10.1109/JBHI.2018.2858789</idno>
					<note type="submission">received December 31, 2017.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-Atrial fibrillation (AF) is one of the most common sustained chronic cardiac arrhythmia in elderly population, associated with a high mortality and morbidity in stroke, heart failure, coronary artery disease, systemic thromboembolism, etc. The early detection of AF is necessary for averting the possibility of disability or mortality. However, AF detection remains problematic due to its episodic pattern. In this paper, a multiscaled fusion of deep convolutional neural network (MS-CNN) is proposed to screen out AF recordings from single lead short ECG recordings. The MS-CNN employs the architecture of two-stream convolutional networks with different filter sizes to capture features of different scales. The experimental results show that the proposed MS-CNN achieves 96.99% of classification accuracy on ECG recordings cropped/padded to 5 seconds. Especially, the best classification accuracy, 98.13%, is obtained on ECG recordings of 20 seconds. Compared with artificial neural network (ANN), shallow single-stream convolutional neural network (CNN), and Visu-alGeometry group network (VGGNet), the MS-CNN can achieve better classification performance. Meanwhile, visualization of the learned features from the MS-CNN demonstrates its superiority in extracting linear separable ECG features without hand-craft feature engineering. The excellent AF screening performance of the MS-CNN can satisfy most elders for daily monitoring with wearable devices.</p><p>Index Terms-Deep convolutional neural network, ECG, atrial fibrillation, deep learning, classification, biomedical monitoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The boom of the aging population has raised more concerns about the health problem of elders. Cardiovascular disease, which is the age-related disease, has been identified as the leading cause of morbidity and mortality in developed countries <ref type="bibr" target="#b0">[1]</ref>. More importantly, atrial fibrillation (AF) which stems from disordered activation and irregular atrial contraction is associated with cardiovascular disease, with a substantial increase in the risk of stroke, heart failure, coronary artery disease, systemic thromboembolism etc. <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. The attack of AF is often paroxysmal and happens outside the hospital. Dynamic electrocardiogram (ECG), a long-term and continuous physiological signal collected by Holter, is one important tool to monitor AF. However, wearing Holter is cumbersome and has a great impact on people's daily activities. An alternative solution is to utilize wearable devices, with portability, usability, and comfortability, to monitor AF. Wearable devices conventionally acquire single lead dynamic ECG recordings, but there is much high noises and artifacts. Therefore, the early diagnosis of AF using such dynamic ECG recordings is of great significance.</p><p>Generally, an ECG recording, which is conventionally used for AF detection, consists of P, Q, R, S, T, and U wave. Fig. <ref type="figure" target="#fig_0">1</ref> shows an ECG recording acquired from an AF patient with characteristics of P-wave absence or irregular variability of RR intervals. In the past few decades, researchers have proposed lots of effective automatic detectors of AF using ECG recordings acquired by Holter. These automatic AF detectors can be summarized as being based on P-wave absence <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> or variability of RR interval. The automatic detectors of AF based on P-wave absence has not gained wide application in Holter monitoring due to its significant limitations. It is a pretty difficult task to locate the fiducial position of a small P wave, especially in the case of noise. Subsequently, the variability of RR intervals has been more frequently used for automatic detection of AF instead. Dash et al. <ref type="bibr" target="#b5">[6]</ref> proposed an automatic detection algorithm of AF based on the randomness, variability and complexity of the heartbeat interval time series. Lian et al. <ref type="bibr" target="#b6">[7]</ref> proposed an AF detection algorithm based on a map that showed the scatter plot of RR intervals versus change of RR intervals. Roonizi et al. <ref type="bibr" target="#b7">[8]</ref> extended nonlinear Bayesian filtering framework for analysis of AF in single channel ECG recordings. Huang et al. <ref type="bibr" target="#b8">[9]</ref> proposed a novel method for detection of the transition between AF and sinus rhythm based on RR intervals. Even though existing automatic detection methods of AF based on the variability of RR intervals has achieved high accuracy on ECG recordings acquired by Holter. However, these kind of methods still has deficiencies to obtain a good performance on screening out AF from single lead ECG recordings collected by wearable devices due to its high noise and artifacts.</p><p>Recent years, deep convolutional neural networks, with a strong capability in feature extraction, have achieved a great success in computer vision <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>.  <ref type="bibr" target="#b15">[16]</ref> developed a novel computationally intelligence-based automatic AF detection method using deep convolutional networks. The features of AF were learned automatically and then utilized in classification module. This method simplified the feature extraction process without the help of feature engineering by expert to define appropriate and critical features. Limam et al. <ref type="bibr" target="#b16">[17]</ref> proposed a convolutional recurrent neural network (CRNN). The CRNN consisted of two independent CNNs to extract related features, one from ECGs and the other from heart rates. The final performance was evaluated by support vector machine(SVM). Yao et al. <ref type="bibr" target="#b17">[18]</ref> proposed a multi-scale convolutional neural networks (MCNN), which applied time scaling on input signals and detected AF based on scaled inputs. In their experiment a strong correlation between the depth of the MCNN and the detection performance was shown. Although the above mentioned methods are effective on solving the problem of AF detection, AF detection remains problematic as this kind of methods are generally limited in applicability. Their good performances are achieved based on carefully-selected often clean data and only a small number of patients were used. Reliable AF detection from single lead short ECG recordings is still a big challenge and particularly difficult due to the limited rhythms information.</p><p>In this study, a multi-scaled fusion of deep convolutional neural network (MS-CNN), inspired by <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, is proposed to detect AF signals based on single lead short ECG recordings. To summarize, the main contributions are described to be: <ref type="bibr" target="#b0">(1)</ref> The proposed MS-CNN employs two streams of convolutional networks with different filter size, which could capture ECG features with different scales and achieve a excellent performance for screening out AF from single lead short ECG recordings. <ref type="bibr" target="#b1">(2)</ref> The effect of the proposed feature learning mechanism is investigated extensively by visualizing learned features in different depths of layers.</p><p>This paper is organized as follows: Section II introduces the architecture of the MS-CNN. And the detailed experimental process is described in section III. Section IV presents the experimental results and discussions. Section V concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><p>The task of real-time AF detection is to identify the AF signals from single lead short ECG recordings. The training set X = {(x (1) , y (1) ), (x (2) , y (2) ), • • • , (x (m) , y (m) )} consists of input ECG recording x (i) and label y (i) , where x (i) ∈ R n and y (i) ∈ {0, 1}. The label y (i) = 1 means that the corresponding input ECG recording x (i) is the AF recording. The label y (i) = 0 corresponds to the normal sinus ECG recording. The proposed MS-CNN accepts x (i) as input and z (i) as output. The details refer to equation (1) which can be defined as:</p><formula xml:id="formula_0">z (i) = F (x (i) ; θ) (1)</formula><p>where F (•) is the function which describes the process of an ECG recording from the input layer to the last fully connected layer. The θ is the related parameters of the MS-CNN. Equation ( <ref type="formula" target="#formula_1">2</ref>) is the softmax function which transforms output value z (i) into possibility to categorize the input ECG recording as a normal or AF signal.</p><formula xml:id="formula_1">p(z (i) ) = exp (z (i) ) ∑ j exp (z (i) )<label>(2)</label></formula><p>where p{•} is the probability which the MS-CNN assigns to the i-th output label taking the input value z (i) . The cross entropy of these outputs with respects to their true labels is then calculated to generate a loss, which effectively evaluates the performance of the model on training data. For m observable instances in the training set, the objective loss function can be defined as:</p><formula xml:id="formula_2">L(X) = - 1 m m ∑ i=1 1 ∑ j=0 1{y (i) = j} log p(z (i) )<label>(3)</label></formula><p>where 1{•} is the indicator function, so that 1{•} = 1 if the statement is true, and 1{•} = 0 if the statement is false. p{•} is the function from equation <ref type="bibr" target="#b1">(2)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Model Architecture</head><p>The architecture of the MS-CNN is designed and built drawing on the experiences of VGGNet(VisualGeometry group network) <ref type="bibr" target="#b9">[10]</ref>, a mature neural network which has been proved to be effective in solving a variety of problems in computer vision field. The MS-CNN is composed of 2 streams of 13-layer convolutional neural networks (Conv) and 3 fully connected layers (FC) after them, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. The nonparametric layers, including five pooling layers and one softmax layer, also play important roles in this architecture. Each fully connected layer provides a transformation function f (•) mapping input x to its output y <ref type="bibr" target="#b18">[19]</ref>. The detailed form of this function is given as:</p><formula xml:id="formula_3">y = f (W x + b) (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where W is a weight matrix and b is a bias vector. They are all trainable variables which help to form various linear transformations, and f (•) is the predefined activation function adding nonlinearity to this function. Convolutional layers in the fully convolutional neural networks use convolution to replace the multiplication in the fully connected layers. As the outputs of convolutional layers </p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride </p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride </p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride </p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride </p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride</p><p>Max-pooling, Stride maintain spatial locality, they are commonly referred to as feature maps. The corresponding function is defined to be:</p><formula xml:id="formula_43">y j = f ( ∑ i∈M k ij * x i + b j ) (<label>5</label></formula><formula xml:id="formula_44">)</formula><p>where M is the filter size, j denotes the index of convolution kernels, i denotes the index of input feature maps, and k ij denotes the convolution kernel for the i-th input map and jth output map. This transition greatly reduces the number of parameters needed to be trained, and leads to better utilities as convolution has already been widely used in signal filtering. Meanwhile, multiple feature maps are generated using different trainable kernels, in order to compensate for the reduced transformation complexity. Pooling layers reduce the size of input by assembling neighboring data points. The max-pooling layers used in the proposed model choose to output only the largest number in each size-predefined blocks. These layers help to reduce the complexity of following calculation, and also introduce translation invariance to the model. Each stream of 13-layer convolutional neural networks, which refers to the VGGNet, has 13 convolutional layers and 5 max-pooling layers. 2 or 3 convolutional layers are grouped together, sharing the same number of filters, and groups are separated by max-pooling layers. Therefore, 2 groups of 2 convolutional layers, and 3 groups of 3 convolutional layers form the entire convolutional network, together with maxpooling layer behind right after the group. The number of convolutional filters is 64 in the first group and then increases by a factor of two after each max-pooling layer, until it reaches 512.</p><p>In one stream of convolutional neural network, the kernel size in all layers is three. In another stream, the convolutional kernels sizes in first four layers are set larger, in order to capture features of different scales from the input ECG recordings. In this paper, the alternative filter sizes including 3, 5, 7, 9 are tested. In remaining layers, the kernel size remains to be three. The stride of the initial two max-pooling layers is three, which enables more aggressive computing complexity reduction while the feature extraction performance wouldn't be compromised much as these features are very shallow. In addition, a stride size of two is applied in the remained maxpooling layers due to the concentration of feature information in deeper layers. At the end of the MS-CNN, softmax layer is applied to transform real values into probabilities. The detailed configurations of the MS-CNN evaluated in this paper are outlined in Table <ref type="table">I</ref>. The MS-CNN (3, n) denotes that the receptive field sizes of two stream neural networks in first four convolutional layers are 3 and n, respectively. The activation function that all hidden layers of the MS-CNN are equipped with is rectified linear unit (ReLU) <ref type="bibr" target="#b19">[20]</ref>, which has many advantages such as sparse activation, efficient gradient propagation, and efficient computation. Mini-batch gradient descent <ref type="bibr" target="#b20">[21]</ref> is utilized as the optimizer, which computes the gradients and updates the network parameters based on a small batch of samples in each step. L2 regularization is a good way to improve generalization error and used in the last three fully connected layers of the MS-CNN <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENT</head><p>The experiment on atrial fibrillation detection consists of data preprocessing, cross validation, and model parameter optimization. Details of this experiment process are illustrated in Fig. <ref type="figure" target="#fig_3">3</ref>.</p><p>A. Data Preprocessing 1) Downsampling: It is known that the complexity of neural networks is partially dependent upon the input size. In order to reduce the proposed model size and shorten the training time, downsampling technology is employed in this paper. According to the periodograms which represent input records' power spectral density showed in Fig. <ref type="figure" target="#fig_4">4</ref>, ECG components with cut-off frequency higher than 60 Hz can be negligible on an AF detection problem. In accordance with the main frequency range presented, input ECG recordings are filtered with a 512-order lowpass finite impulse response (FIR) filter which has a cut-off frequency of 60 Hz, and then downsampled from original 300 Hz to 120 Hz. The FIR filter is applied to avoid aliasing, and the cut-off frequency is determined by the Nyquist Theorem <ref type="bibr" target="#b22">[23]</ref>.</p><p>2) Normalization: There is a large variation in terms of amplitudes of ECG recordings among different people, or even the same person with different lead positions. In practice, it is found that neural network models tend to converge better when all inputs have similar distributions. So we subtracted the mean value from each recording and then divided them with their standard deviation, by which the effects of different amplitudes among ECG recordings can be eliminated. The normalization function is defined as:</p><formula xml:id="formula_45">N ormalized(X) = X -X S (<label>6</label></formula><formula xml:id="formula_46">)</formula><p>where X refers to the ECG recording values, and X, S refers to the average and standard error of these values, correspondingly.</p><p>3) Data Balance: For ECG datasets, it is common that the number of ECG recordings labeled with AF are less than that of ECG recordings labeled with normal. This biased distribution results in much higher difficulty to screen an AF patient than a normal case. Meanwhile, imbalanced training To solve this problem, AF recordings can be replicated in the training dataset to enhance effects on the gradient direction. In this paper, the AF recordings are replicated three times in the training dataset. This replication operation makes AF recordings more than 30% in the input ECG recordings, which could balance the data-biased distribution and overfitting problem.</p><p>4) Cropping and Padding: The input ECG recordings have varied lengths from 9 to 61 seconds. Varied-length input fails to fit with convolutional neural network models. Thus, short ECG recordings in fixed length of 5 seconds, 10 seconds, 20 seconds, and 30 seconds are selected as the input of the MS-CNN to verify the influence of different input sizes on the model performance. ECG recordings that are too long should be cropped and those that are too short should be padded with zeros in order to fit the model. However, fixed cropping fails to utilize the entire training dataset. Therefore, the MS-CNN is programed to be able to automatically fetch data batches from the dataset and crop or pad them randomly. In contrast, the test data are centrally cropped or padded to have fair performance measurement between models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Cross Validation</head><p>As the target dataset is relatively small, 10-fold cross validation is introduced. The original dataset is randomly partitioned into ten equal sized subsets. 10 models are trained with each of the 10 subsets used exactly once as the test data and remaining parts as training data. Then, classification results of these models are gathered and combined, to estimate the model's average performance on the entire dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Model Parameters Selection</head><p>1) Activation function: Activation function plays a very important role since it introduces nonlinear factors into deep learning model. However, the gradient saturation problem exists in common used activation function, such as sigmoid <ref type="bibr" target="#b23">[24]</ref> and tanh <ref type="bibr" target="#b24">[25]</ref>. ReLU (Rectified Linear Unit) function is a popular activation function in convolutional network in recent years. Compared with sigmoid and tanh function, the gradient saturation problem can be avoided well in ReLU function when the input is positive. Therefore, the ReLU function is chosen as the activation function of the MS-CNN. And the ReLU function is defined as:</p><formula xml:id="formula_47">f (x) = { 0, x &lt; 0 x, x ≥ 0 (7)</formula><p>2) Model Optimization: Starting from the fundamental gradient descent algorithm, optimization algorithms of deep learning have been constantly developed. Mini-batch gradient descent, also known as stochastic gradient descent in deep learning, is introduced to reduce the time cost of each step of training. Momentum <ref type="bibr" target="#b25">[26]</ref> is introduced to avoid the local optima problem. Adaptive gradient descent (Adagrad) <ref type="bibr" target="#b26">[27]</ref> adapts the learning rate to different parameters, performing larger updates for infrequent parameters and smaller updates for frequent parameters. Adaptive moment estimation (Adam) <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, which stores exponentially decaying averages of both past gradients and past squared gradients and updates parameters based on them, is usually considered having the best overall performance. Nevertheless, in many practices it has been found that stochastic gradient descent (SGD) with a simple learning rate decay schedule usually manages to find a minimum, though with other optimizers model converges faster. Therefore, in this experiment, simple stochastic gradient descent with batch size of 128, initial learning rate of 0.01, and exponential learning rate decay of 10 times in every 300 epoch, is applied. The learning rate η is decayed as following:</p><formula xml:id="formula_48">η = η 0 • 0.1 N 300 (8)</formula><p>where η 0 is the initial learning rate, and N is the number of epochs.</p><p>3) L2 Regularization: In the field of machine learning, the problem of over-fitting becomes more serious when the learned model is with high complexity, which tends to fit not only between data and label, but also between noise and random error. To avoid over-fitting, regularization is introduced to the MS-CNN. In this experiment, L2 norm of model parameters for the last three fully connected layers are added to the loss function, with a penalty factor λ.</p><formula xml:id="formula_49">l(x) = L(X) + λ 3 ∑ i=1 ∥W i ∥ 2<label>(9)</label></formula><p>where l(•) is the total loss function with L2 regularization. L(•) is the cross entropy loss from equation (3). W i is the weight parameters of the i-th fully connected layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Environment</head><p>The MS-CNN runs on the prevailing deep learning framework Tensorflow1.2.1, using the CentOS7.3 operating sys- tem. The platform of Tensorflow is deployed on the highperformance computing server equipped with two 16-core Intel Xeon E5-2640 V3 processors with 128GB memory. The computing server is also equipped with eight NVIDIA Tesla K80 with 13 multi-processors (total 19,968 cores) and 12GB memory (total 96GB memory).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data Source</head><p>Provided by the PhysioNet 1 , a total of 8,528 ECG records (about 23,878,400 heartbeats) lasting from 9s to 61s were gathered to support its Computing in Cardiology Challenge 2017. One of three generations of AliveCor's single-channel ECG device was utilized to collect ECG recordings from 1 https://www.physionet.org/challenge/2017/ health-monitored users. These noise-contaminated recordings sampled at 300Hz were labelled by an ECG expert in four classes, normal rhythm, AF rhythm, other rhythm and noisy recordings. While those recordings are suitable for practical analysis for their varied length and noise-contaminated feature, they are also seriously imbalanced, for only 771 in 8528 of the total records are of AF rhythm, which are of major concern. The class distribution of the dataset is shown in Table <ref type="table">V</ref>.</p><p>In this paper, normal and AF recordings are selected in this work, as strong waveform variation lies in the group of ECG recordings annotated as other rhythms and noisy recordings. 5154 normal sinus recordings and 771 AF recordings are used in experiments, with aforementioned strategy to tackle with the problem of unbalanced distribution.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Classification Performance</head><p>In this paper, sensitivity (Sen), specificity (Spe), precision (P re) and accuracy (Acc) are four metrics for evaluating classification performance of the MS-CNN. Based on true positive (T P ), true negative (T N ), false positive (F P ) and false negative (F N ), the definition of this four metrics can be defined as:</p><formula xml:id="formula_50">Sen = #(T P ) #(T P ) + #(F N ) (10) Spe = #(T N ) #(T N ) + #(F P )<label>(11)</label></formula><formula xml:id="formula_51">P re = #(T P ) #(T P ) + #(F P ) (<label>12</label></formula><formula xml:id="formula_52">)</formula><formula xml:id="formula_53">Acc = #(T P ) + #(T N ) #(T P + T N + F N + F P )<label>(13)</label></formula><p>The MS-CNN with different configuration of convolutional filter sizes are evaluated. At the same time, input ECG recordings of different lengths (5 seconds, 10 seconds, 20 seconds, and 30 seconds) are tested. The experimental results show that the MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b4">5)</ref> achieves the best classification accuracy, 96.99%, when the input ECG recording is 5 seconds long. A typical 5-second ECG signal contains about 6-7 heartbeats. For an ECG recording of this length, the classification accuracies of the MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b4">5)</ref>, MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b6">7)</ref>, and MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b8">9)</ref> are almost the same but better than that of the MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b2">3)</ref>. It is likely that the MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b2">3)</ref> can not capture multi-scaled features from ECG recordings due to its same filter size. Through the case of the MS-CNN(3,7)'s performance in classification of longer input recordings, it is demonstrated that multi-scaled filters could increase the AF screening performance. For the ECG length of 10 seconds, 20 seconds, and 30 seconds, the MS-CNN(3, 7) has outperformed other configurations. Using this configuration, the highest classification accuracy of 98.13% is achieved when the length of input recordings is 20 seconds. In theory, a longer ECG signal, which covers more heartbeat rhythm information, would lead to better classification performance. However, in all configurations the best classification performance is achieved when input ECG recordings are 20 seconds long. This result is strongly related to the length distribution of the ECG dataset we used. 10.95% of ECG recordings are shorter than 30 seconds while about 6.77% of ECG recordings are shorter than 20 seconds. An ECG signal needs to be padded with zeros when its length is shorter than the length of the ECG recordings for the MS-CNN. The number of input ECG recordings which need to be padded to 30 seconds long are larger than that of those which need to be padded to 20 seconds long. More noises are introduced to the input ECG recordings when more zeros are padded into an ECG recording, which also lead to worse AF screening performance. Meanwhile, The MS-CNN(3, 7), the filter sizes of which are much different in two-stream convolutional networks, has the ability to obtain the features with different scales. Therefore, the classification performance of the MS-CNN on 20-second-long ECG recordings is better than that on 30-second-long ECG recordings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Visualization of Learned Features</head><p>The MS-CNN(3, 7) which performs better in most of cases is selected to visualize the learned features. Eight healthy and eight AF cases are randomly selected from test set as the input. The input ECG recordings are cropped/padded to 20 seconds long. Instead of applying softmax function and outputting the classification results, the softmax layer is discarded, the remaining layers of the MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b6">7)</ref> are utilized as a feature extractor. The generated feature vectors consist of 256 values, outputted by 256 neurons in the final fully connected layer. In order to get better representative features, our experiments take advantage of unsupervised principle component analysis (PCA) method to reduce the dimension of feature vectors from 256 to 5. The first 5 feature attributes cover over 80% information showed in Fig. <ref type="figure">5 (b)</ref>. And the top two components take up 66% of feature information. Meanwhile, visualization of learned features on a heat map is drawn in Fig. <ref type="figure">5 (a</ref>). The 8 cases on the left side of the horizontal axis are healthy cases, and the 8 cases on the right side of the horizontal axis are AF cases. The top 5 components from the PCA method is on the vertical axis. As shown in Fig. <ref type="figure">5</ref> (a), healthy cases and AF cases could be clearly discriminated using those 5 representative features. Associated with the top one feature (1st row in Fig. <ref type="figure">5 (a)</ref>), the feature colors of healthy cases are more light than that of AF cases. Compared with AF cases, the second and third features (2nd and 3rd row) are in darker colors. There is no big difference on the 4th and 5th features which cover feature information lower than 4.5%. Even so, the clear difference of the top 3 learned features between healthy and AF cases help to explain why the proposed MS-CNN(3, 7)'s classification performs well.</p><p>To further capture and understand the learning procedure of the MS-CNN <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b6">7)</ref> , some representative layers (2nd layer, 4th layer, 7th layer, 10th layer, 13th layer, and 16th layer) are selected to extract low dimensional features from feature mapping vectors using PCA method respectively. Fig. <ref type="figure">6</ref> shows the first two principal components of those aforementioned 16th recordings. It is demonstrated obviously that healthy and AF cases become more distinguishable as the depth of the MS-CNN(3, 7) increases. For example, AF and healthy cases are mingled together tightly in the 2nd layer (Fig. <ref type="figure">6 (a)</ref>). In the 4th and 7th layer (Fig. <ref type="figure">6</ref> (a) and (b)), both AF and healthy cases are slowly clustering but not clearly separated. When the depth of the MS-CNN(3, 7) increases to 10 layers (Fig. <ref type="figure">6 (d)</ref>), over half of healthy cases can be separated from the AF cases. In the 13th layer (Fig. <ref type="figure">6</ref> (e)), most of healthy and AF cases are separated well and just a few cases are mingled together. As shown in Fig. <ref type="figure">6</ref> (f), AF and healthy cases can be well separated linearly in the 16th layer (final layer in the MS-CNN). It is also observed that AF cases are more concentrated than health cases, which can be ascribed to the facts that healthy cases have more waveform patterns such as P wave ,and the number of health cases are much more than that of AF cases. Nevertheless, the experiment results show that the MS-CNN(3, 7)'s classification performance is not affected by this biased distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Classification Performance Comparison</head><p>In this paper, three popular machine learning methods named artificial neural network (ANN) <ref type="bibr" target="#b29">[30]</ref>, convolutional neural network (CNN) <ref type="bibr" target="#b15">[16]</ref>, and VGGNet <ref type="bibr" target="#b9">[10]</ref> are implemented to address AF screening problem for comparison. The implemented ANN is a very classical model, consisting of one input layer, one hidden layer, and one output layer. The sizes of input and output layers depends upon the problem, and they are set to be the length of input ECG recordings and the number of output classes correspondingly in this experiment. The implemented CNN consists of five layers, including one convolutional layer, one pooling layer, and one fully connected layer, except input and output layers. Compared with the proposed MS-CNN, this CNN model uses a very aggressive dimension reduction strategy in its pooling layer, and is proved to be successful in screening paroxysmal AF using long and clean ECG recordings <ref type="bibr" target="#b15">[16]</ref>. It also has a comparatively larger filter kernel size, but not as deep as the proposed method. The implemented VGGNet, whose convolutional layers compose one stream of MS-CNN, consists of 13 convolutional layers with kernel size 3 and 3 fully connected layers. Meanwhile, the same data processing operations of the MS-CNN are done on the same training dataset and test dataset for models of the ANN, CNN, and VGGNet.</p><p>The experimental results show that there is an obvious difference of classification performance among the ANN, CNN, VGGNet, and MS-CNN. As shown in Table <ref type="table">IV</ref>, the proposed MS-CNN outperforms the other three methods in all kinds of the fixed length of input ECG recordings. The ANN fails to recognize the underlying features inside ECG recordings, and tends to classify most input ECG recordings as healthy cases. It leads to low sensitivity and precision defined in Equation ( <ref type="formula">10</ref>) and <ref type="bibr" target="#b12">(13)</ref>. The high specificity of the ANN (over 90%) results in 80% of its classification accuracy because of a high identification of health cases. Compared with the ANN, the classification metrics of sensitivity and specificity of the shallow CNN in detecting AF recordings are at least improved by 40% and 35%, respectively. The CNN has better classification performance than the ANN. However, the classification performance of the CNN in short ECG recordings is still not satisfying, demonstrating that a model with higher representing ability is needed to extract detailed features in ECG waveforms. When input ECG signal is short, it is vital to extract as many details as possible from the waveforms, while AF detection in longer recordings have abundant information concerning one's ECG rhythms. The proposed MS-CNN therefore outperforms CNN in all metrics, reaching nearly 30% increment in sensitivity and precision, and more than 8% reduction in overall error rate, compared to the CNN. Although classification performance on AF versus normal sinus rhythm of the VGGNet is not lower too much than the MS-CNN, the MS-CNN outperforms the VGGNet obviously in screening out AF from other rhythms showed in Table <ref type="table">V</ref>. It is likely that the MS-CNN could capture more kinds of rhythm information than the VGGNet. At the same time, it is known that an AF detection method developed by AliveCor has FDA (Food and Drug Administration) clearance and CE (Conformity Europe) mark <ref type="bibr" target="#b30">[31]</ref>. In order to detect AF episodes in real time, the length of the ECG signal analyzed by AliveCor is 30 seconds. This method, which requires a longer input ECG recording, identifies AF versus normal sinus rhythm with 85% sensitivity and 90% specificity. Compared with our proposed method with 94% sensitivity and 98% specificity in 5-second-long ECG recordings, the method developed by AliveCor performs worse in screening out AF recordings.</p><p>Receiver operating characteristic (ROC) analysis is related in a direct and natural way to compare the effectiveness of the aforementioned three methods (the ANN, CNN, and MS-   <ref type="bibr" target="#b31">[32]</ref> 81.97% 98.42% 83.10% 96.99% Limam <ref type="bibr" target="#b16">[17]</ref> 72.70% 98.60% --The proposed 80.26% 98.84% 87.14% 97.19% CNN). As shown in Fig. <ref type="figure" target="#fig_6">7</ref>, four ROC curves are drawn from the ANN, CNN, and MS-CNN in input ECG recordings of 5 seconds, 10 seconds, 20 seconds and 30 seconds. Compared with the ANN and CNN, our proposed MS-CNN obtains the best value of area under the curve (AUC) in all kinds of input ECG recordings. The AUC values of the MS-CNN for input ECG recordings are 0.990, 0.994, 0.994, and 0.989 respectively, which demonstrates that the MS-CNN has a higher classification performance in detecting short AF recordings.</p><p>Apart from validating the MS-CNN on screening AF versus normal sinus rhythm, we also evaluate the identification capability of the MS-CNN on AF versus other rhythm, which is another common clinical situation. As shown in Table <ref type="table">V</ref>, the proposed MS-CNN obtains 80.26% sensitivity, 98.84% specificity, and 97.19% accuracy. Compared with the state of the art methods, the proposed method is more competitive in identifying AF from other rhythms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this paper, we propose a multi-scaled fusion of deep convolutional neural network named MS-CNN for screening out AF recordings from single lead short ECG recordings. The proposed MS-CNN can capture different scaled feature information without hand-craft engineering by its specified network architecture, which consists of three fully connected layers and two streams of 13-layer convolutional neural networks with different filter sizes in first four hidden layers. By visualizing the representative layers, the learned features become linear separable as the depth of layers increases. The experimental results show that the proposed MS-CNN achieves 96.99% of classification accuracy on ECG recordings cropped/padded to 5 seconds. Especially, the best classification accuracy, 98.13%, is obtained on input ECG recordings of 20 seconds. Meanwhile, three popular machine learning methods (ANN, CNN, and VGGNet) are implemented to detect AF recordings on the same training and test dataset for comparison. Our proposed MS-CNN outperforms the ANN, CNN, and VGGNet in all classification metrics. What's more, the lowest AUC value of the MS-CNN is up to 0.989 which further demonstrates its high classification performance. However, the MS-CNN can still has the potential to improve the capability of screening AF from other rhythms, which we will focus on in our future research work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An AF patient ECG recording with characteristics of P-wave absence or irregular variability of RR interval</figDesc><graphic coords="2,48.96,56.05,251.89,80.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The network architecture of the MS-CNN. The MS-CNN has two stream networks, which consist of 13 layer convolutional neural network (Conv), 5 maxpooling layers, and 3 fully connected layers (FC).</figDesc><graphic coords="3,61.82,56.00,488.80,141.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Block diagram of AF screening experimental pipeline.</figDesc><graphic coords="4,318.26,55.46,239.06,501.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Power spectral density estimate using periodogram. Cut-off frequency of FIR filter is 60 Hz</figDesc><graphic coords="5,61.52,55.90,226.33,173.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Visualization of the learned features (a) Heat map of learned features from healthy and AF cases. The first eight columns correspond to the AF patient cases. The remaining columns are healthy cases. The rows are the representative features from the final layers features through PCA. The features between AF patients and healthy individuals are easily discriminated. (b) Pareto of learned features. Top 5 features take up over 80% information of all features.</figDesc><graphic coords="6,48.97,226.84,164.69,123.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Receiver operating characteristic curve (ROC): (a) 5 seconds, (b) 10 seconds, (c) 20 seconds, (d) 30 seconds</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1</head><label></label><figDesc>Multi-Scaled Fusion of Deep Convolutional NeuralNetworks for Screening Atrial Fibrillation from Single Lead Short ECG Recordings Xiaomao Fan, Qihang Yao, Yunpeng Cai, Fen Miao, Fangmin Sun, Ye Li, Member, IEEE,</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. Ruxin Wang and Liyan Yin who give their precious suggestions to improve the quality of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>, IEEE Journal of Biomedical and Health Informatics This work was supported in part of Major Special Project of Guangdong Province(2017B030308007), Shenzhen Basic Research Projects (JCYJ20170818163445670, JCYJ20170413161515911, JCYJ20170412110753954), Guangdong Applied Special Project for Research and Development (2015B010129012), and Special Fund Project for Overseas High-level Talents Innovation and Entrepreneurship(KQJSCX20170731165939298). X. Fan, Q. Yao, Y. Cai, F. Miao, and F. Sun are with Joint Engineering Re-</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Prevention of cardiovascular events in elderly people</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Andrawes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bussy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Belmin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drugs &amp; aging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="859" to="876" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Guidelines for the management of atrial fibrillation: the task force for the management of atrial fibrillation of the european society of cardiology (esc)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Camm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kirchhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y H</forename><surname>Lip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Schotten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Savelieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Van Gelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hindricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Prendergast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europace</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1360" to="1420" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Impact of the presence of noise on rr interval-based atrial fibrillation detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electrocardiology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="947" to="951" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The signal-averaged p wave duration: a rapid and noninvasive marker of risk of atrial fibrillation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Guidera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Steinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American College of Cardiology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1645" to="1651" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detection and delineation of p and t waves in 12-lead electrocardiograms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lingayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanghvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="143" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic real time detection of atrial fibrillation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Raeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1701" to="1709" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A simple method to detect atrial fibrillation using rr intervals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Muessig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American journal of cardiology</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1494" to="1497" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An extended bayesian framework for atrial and ventricular activity separation in atrial fibrillation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kheirati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A novel method for detection of the transition between atrial fibrillation and sinus rhythm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1113" to="1119" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">High performance offline handwritten chinese character recognition using googlenet and directional feature maps</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="846" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the performance of googlenet and alexnet applied to sketches</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1124" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="568" to="576" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional twostream network fusion for video action recognition</title>
		<author>
			<persName><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1933" to="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep convolution neural networks and learning ecg features for screening paroxysmal atrial fibrillatio patients</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pourbabaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Roshtkhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Khorasani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems Man and Cybernetics Systems</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Af detection and ecg classification based on convolutional recurrent neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Limam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Precioso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing in Cardiology Conference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Atrial fibrillation detection by multiscale convolutional neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Fusion (Fusion), 2017 20th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On optimization methods for deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Prochnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning (ICML-11)</title>
		<meeting>the 28th international conference on machine learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Communication in the presence of noise</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IRE</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="21" />
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Michalski</surname></persName>
		</author>
		<title level="m">Machine Learning</title>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gated feedback recurrent neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2067" to="2075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the momentum term in gradient descent learning algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An overview of gradient descent optimization algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04747</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Detection of atrial fibrillation using model-based ecg analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Couceiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Antunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Habetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition, 2008. ICPR 2008. 19th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Alivecor heart monitor and aliveecg app (kardia mobile) for detecting atrial fibrillation</title>
		<author>
			<persName><surname>Alivecor</surname></persName>
		</author>
		<ptr target="https://www.nice.org.uk/advice/mib35/chapter/technology-overview" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rhythm and quality classification from short ecgs recorded using a mobile device</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Behar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Oster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing in Cardiology Conference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
