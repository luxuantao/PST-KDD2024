<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">S3: Syntax-and Semantic-Guided Repair Synthesis via Programming by Examples</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuan-Bach</forename><forename type="middle">D</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Duc-Hiep</forename><surname>Chu</surname></persName>
							<email>duc-hiep.chu@ist.ac.at</email>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Lo</surname></persName>
							<email>davidlo@smu.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Claire</forename><surname>Le Goues</surname></persName>
							<email>clegoues@cs.cmu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Willem</forename><surname>Visser</surname></persName>
							<email>wvisser@cs.sun.ac.za</email>
						</author>
						<author>
							<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
						</author>
						<author>
							<persName><surname>S3</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Singapore Management University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Science and Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Singapore Management University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Stellenbosch University</orgName>
								<address>
									<country key="ZA">South Africa</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">S3: Syntax-and Semantic-Guided Repair Synthesis via Programming by Examples</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CAAAEB0709B6B60CC55F139EA26F9DEB</idno>
					<idno type="DOI">10.1145/3106237.3106309</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Program Repair</term>
					<term>Programming by Examples</term>
					<term>Inductive Synthesis</term>
					<term>Symbolic Execution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A notable class of techniques for automatic program repair is known as semantics-based. Such techniques, e.g., Angelix, infer semantic specifications via symbolic execution, and then use program synthesis to construct new code that satisfies those inferred specifications. However, the obtained specifications are naturally incomplete, leaving the synthesis engine with a difficult task of synthesizing a general solution from a sparse space of many possible solutions that are consistent with the provided specifications but that do not necessarily generalize.</p><p>We present S3, a new repair synthesis engine that leverages programming-by-examples methodology to synthesize high-quality bug repairs. The novelty in S3 that allows it to tackle the sparse search space to create more general repairs is three-fold: (1) A systematic way to customize and constrain the syntactic search space via a domain-specific language, (2) An efficient enumerationbased search strategy over the constrained search space, and (3) A number of ranking features based on measures of the syntactic and semantic distances between candidate solutions and the original buggy program. We compare S3's repair effectiveness with state-ofthe-art synthesis engines Angelix, Enumerative, and CVC4. S3 can successfully and correctly fix at least three times more bugs than the best baseline on datasets of 52 bugs in small programs, and 100 bugs in real-world large programs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Bug fixing is notoriously difficult, time-consuming, and costly <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b45">46]</ref>. Hence, automating bug repair, to reduce the onerous burden of this task, would be of tremendous value. Automatic program repair has been graining ground, with substantial recent work devoted to the problem <ref type="bibr">[6, 20, 24-26, 29, 32, 34-36, 51, 52]</ref>, inspiring hope of future practical adoption. One notable line of work in this domain is known as semantics-based program repair, most recently embodied in Angelix <ref type="bibr" target="#b35">[36]</ref>. This class of techniques uses semantic analysis (typically dynamic symbolic execution) and a set of test cases to infer behavioral specifications of the buggy code, and then program synthesis to construct repairs that conform to those specifications. Such approaches have recently been shown to scale to bugs in large, real-world software <ref type="bibr" target="#b35">[36]</ref>.</p><p>Although scalability has been well-addressed, one pressing concern in program repair is patch quality, sometimes quantified in terms of patch overfitting or generalizability <ref type="bibr" target="#b42">[43]</ref>. Generated repairs can sometimes overfit to the tests used for repair, and fail to generalize to a different set of tests. This may be caused by weak or incomplete tests, or even simply the nature of the repair technique <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b42">43]</ref>. Various repair approaches have been shown to suffer from overfitting, including GenProg <ref type="bibr" target="#b28">[29]</ref>, RSRepair <ref type="bibr" target="#b38">[39]</ref> and SPR <ref type="bibr" target="#b31">[32]</ref>. Semantics-based approaches like Angelix <ref type="bibr" target="#b35">[36]</ref>, are no exception to this issue, as partially shown in recent studies <ref type="bibr" target="#b26">[27]</ref>. Overfitting, and patch quality generally, remains a challenging problem in the program repair field.</p><p>One reason for patch overfitting is that the repair search space is often sparse, containing many plausible solutions that can lead the buggy program to pass a given test suite, but that may still be judged incorrect <ref type="bibr" target="#b32">[33]</ref>. One way to tackle overfitting is thus to constrain the search space to patches that are more likely to generalize. Other strategies for increasing the quality of output patches include higher-granularity mutation operators <ref type="bibr" target="#b18">[19]</ref>, antipatterns <ref type="bibr" target="#b44">[45]</ref>, history-based patterns <ref type="bibr" target="#b27">[28]</ref>, feedback from execution traces <ref type="bibr" target="#b7">[8]</ref>, or document analysis <ref type="bibr" target="#b50">[51]</ref>. Angelix <ref type="bibr" target="#b35">[36]</ref> eagerly preserves the original syntactic structure of the buggy program via PartialMaxSMT-based constraint solving <ref type="bibr" target="#b34">[35]</ref> and componentbased synthesis <ref type="bibr" target="#b15">[16]</ref>. However, such enforcement alone may not be enough <ref type="bibr" target="#b7">[8]</ref>. Furthermore, incorporating other strategies or criteria into a constraint-based synthesis approach is non-obvious, since doing so typically requires novel, and often complicated constraint encodings (this problem has been pointed out by others, see, e.g., Chapter 7 of <ref type="bibr" target="#b13">[14]</ref> or Section 2 of <ref type="bibr" target="#b44">[45]</ref>). This motivates the design of a new repair synthesis technique that can consolidate various restrictions or patch generation criteria, enabling an efficient search over a constrained space for potentially higher-quality patches.</p><p>We present S3 (Syntax-and Semantic-Guided Repair Synthesis), a new, scalable repair synthesis system. S3 addresses the challenge of synthesizing generalizable patches via our novel design of three main components: (1) An underlying domain-specific language (DSL) that can systematically customize and constrain the syntactic search space for repairs, (2) An efficient enumeration-based search strategy over the restricted search space defined by the DSL to find solutions that satisfy correctness specifications, e.g., as induced by test suites, and (3) Ranking functions that serve as additional criteria aside from the provided specifications to rank candidate solutions, to prefer those that are more likely to generalize. Our ranking functions are guided by the intuition that a correct patch is often syntactically and semantically proximate to the original program, and thus measure such syntactic and semantic distance between a candidate solution and the original buggy program. Unlike other constraint-based repair synthesis techniques, our framework is highly customizable by design, enabling the easy inclusion of new ranking features -its design is inspired by the programming-byexamples (PBE) synthesis methodology <ref type="bibr" target="#b13">[14]</ref>.</p><p>Given a buggy program to repair and a set of test cases (passing and failing), S3 works in two main phases. The first phase automatically localizes a repair to one or more target repair expressions (e.g., branch condition, assignment right-hand-side, etc.). S3 runs dynamic symbolic execution on the test cases to collect failure-free execution paths through the implicated expressions. It then solves the collected path constraints to generate concrete expression values that will allow the tests to pass. These specifications, expressed as input-and desired-output examples, are input to the synthesis phase. The synthesis phase first constrains the syntactic search space of solutions via a DSL that we extend from SYNTH-LIB <ref type="bibr" target="#b2">[3]</ref>. Our extension allows it to specify a starting sketch, or an expression that gives S3 clues about what possible solutions might look like. Here, the sketch is the original buggy expression under repair. Next, S3 forms a solution search space of expressions of the same size as the sketch. Finally, it ranks candidate solutions via a number of features that approximate the syntactic and semantic distance to the specified sketch. If S3 cannot find any solution of the same size as the sketch, it investigates expressions that are incrementally smaller or larger than the sketch, and repeats the process.</p><p>We evaluate S3 by comparing its expressive power and the quality of the patches it generates to state-of-the-art baseline techniques (Angelix <ref type="bibr" target="#b35">[36]</ref>; and Enumerative <ref type="bibr" target="#b2">[3]</ref>, and CVC4 <ref type="bibr" target="#b40">[41]</ref> two alternative syntax-guided synthesis approaches), on two datasets. The first dataset includes 52 bugs in small programs, a subset of the IntroClass benchmark <ref type="bibr" target="#b29">[30]</ref> translated to Java <ref type="bibr" target="#b9">[10]</ref>. <ref type="foot" target="#foot_0">1</ref> The Intro-Class dataset contains only small programs, but provides two highcoverage test suites for each, allowing an independent assessment of repair quality. The second dataset includes 100 large real-world Java bugs that we collected from GitHub. We focus on Java, and build a new dataset of real-world Java bugs, for several reasons. First, Java is the most popular and widely-used programming language, and its influence is growing rapidly. <ref type="foot" target="#foot_1">2</ref> Second, a realistic, real-world dataset with transparent ground truth -fixes submitted by developers -can simplify the critical process of assessing the correctness of fixes generated by program repair tools in the absence of two independent, high-quality test suites. Existing benchmarks often include bug fixes with many changed lines, which can include tangled changes such as new features or code refactoring <ref type="bibr" target="#b14">[15]</ref>; even curated datasets such as Defects4J <ref type="bibr" target="#b17">[18]</ref> contain many changes involving a large number of lines. This complicates evaluation of generated patch correctness. Our dataset is restricted to bugs whose fixes involve fewer than five lines of code, alleviating the risk of tangled code changes. As many current state-of-the-art repair tools target bugs that require only a small number of changed lines <ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref>, our dataset is sufficient for assessing current research.</p><p>We assess the quality and correctness of generated repairs in several ways. For the IntroClass bugs, we assess correctness on independent, held-out test suites (those provided with the benchmark, as well as additional tests we generate), separate from those used to guide the repair. We use the developer-provided patches as ground truth for the 100 real-world bugs. For these bugs, we consider a generated patch correct if it is either (1) syntactically identical to the developer-provided patch, or (2) semantically equivalent via some (basic) transformations. On both datasets, S3 substantially outperforms the baselines. S3 generates correct patches for 22 of 52 bugs from the first dataset; Angelix, Enumerative, and CVC4 can generate correct patches for 7, 1, and 1 bug(s), respectively. On the large real-world dataset, S3 generates correct patches for 20 out of 100 bugs, while Angelix, Enumerative, and CVC4 can only generate correct patches for 6, 6, and 5 bugs, respectively.</p><p>In summary, our novel contributions include:</p><p>• We present S3, a scalable repair synthesis engine that is geared towards synthesizing generalizable repairs. • We propose a novel combination of syntax-and semantic-guided ranking features to effectively synthesize high-quality repairs. New features along these lines can be straightforwardly integrated into S3, by design.   <ref type="figure" target="#fig_3">1</ref>. We use M1 and M2 to refer to the conditions in columns 3-4 in subsequent exposition. The last column represents the desired output of the overall branch decision.</p><p>• We release source code for S3 and the aforementioned dataset, along with all results, in support of open science. <ref type="foot" target="#foot_2">3</ref>The rest of the paper is structured as follows. Section 2 describes a motivating example, followed by Section 3 explaining our approach. Section 4 describes our experiments, results, and observations. Section 5 presents related work; Section 6 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MOTIVATING EXAMPLE</head><p>We begin by motivating our approach and illustrating its underlying insight by way of example. Figure <ref type="figure" target="#fig_3">1</ref> shows changes made to address a bug in the Closure compiler at revision 1e070472. The bug lies in the if-condition expression at lines 3-4; the developer-submitted fix is depicted at lines 5-6. This bug can be repaired by simply changing charno &lt; sourceExcerpt.length() to charno &lt;= sourceExcerpt.length(), while the rest of the condition expression remains unchanged. Table <ref type="table" target="#tab_5">2</ref> shows example input and desired-output examples extracted for this bug at the buggy if-condition on two failing test cases. For each test run, the input includes runtime values of variables and method calls at the buggy lines, while the output is the value of the branch condition for the buggy lines that would cause the test to pass. For example, for test 1, the input includes runtime values for method calls excerpt.equals(LINE) and the variable charno. The desired output of the branch condition is true. These input-output examples constitute incomplete specifications for each buggy line considered in the program; although they are incomplete, they are scalably and automatically derivable from provided test cases.</p><p>Given these specifications (examples), the space of possible satisfying solutions is large, and contains many undesirable options, such as excerpt.equals(LINE), excerpt.equals(LINE)|| 0 &lt; charno, both of which, among others, would lead to the desired outputs on the considered expressions. Such solutions, if returned by a repair synthesis engine, create low-quality, overfitting repairs that lead the program to pass all provided tests but are not correct. In fact, Angelix <ref type="bibr" target="#b35">[36]</ref> generates an overfitting repair for this bug, substituting 0 &lt; charno for the entire if-condition expression on lines 3-4 (Section 4 provides details on our straightforward port of Angelix to Java). This repair is quite different from the original expression both syntactically (despite Angelix's use of constraints to enforce minimal syntactic differences from an original expression) and semantically. The generated condition is indifferent to values of excerpt.equals(LINE) and sourceExcerpt.length(), substantially weakening the branch condition with respect to the original buggy version.</p><p>These observations inform insights that can be used to filter trivial solutions. In this case, the correct solution is syntactically and semantically close to the original buggy expression. Fusing syntactic and semantic measures of proximity can help rank the solution space to favor those that are more likely to be correct. Our approach, S3, estimates these distances in several ways to constrain the syntactic solution synthesis space, increasing the likelihood or producing a generalizable patch (see Section 3.2.3). For the example in Figure <ref type="figure" target="#fig_3">1</ref>, S3 synthesizes a patch that is identical to the one submitted by the developer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>S3 works in two main phases. Given a buggy program and a set of test cases, the first phase (Section 3.1) localizes potentially buggy program locations and, for each buggy location, extracts input and desired output examples that describe passing behavior. The extracted examples are input to the second phase (Section 3.2), which synthesizes repairs that satisfy and also generalize beyond the provided examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Automatic Example Extraction</head><p>S3 first uses fault localization to identify likely-buggy expressions or statements in the buggy program. S3 runs the test cases and uses Ochiai <ref type="bibr" target="#b1">[2]</ref> to calculate suspiciousness scores that indicate how likely a given expression or a statement is to be buggy. S3 iterates through each identified buggy location (or group of locations in the case of multi-location repair), to extract input-output examples via a selective, dynamic symbolic execution <ref type="bibr" target="#b6">[7]</ref>. <ref type="foot" target="#foot_3">4</ref> For each buggy location, S3 inserts a symbolic variable to represent/replace the expression at the selected location. It then invokes test cases on the instrumented programs to collect path conditions that do not lead to runtime errors such as assertion errors, array index out of bound errors, etc. Solving these failure-free execution paths returns concrete values of symbolic variables that then can serve as input-output examples. We implement selective symbolic execution procedure on top of Symbolic PathFinder (SPF) <ref type="bibr" target="#b37">[38]</ref>.</p><p>For example, consider the buggy code snippet in Figure <ref type="figure" target="#fig_3">1</ref>. S3 identifies that the if-condition at lines 3-4 may be buggy. S3 then replaces the buggy if-condition with a symbolic variable α, making the if-condition becomes "if( α)". S3 runs dynamic symbolic execution on the instrumented program using the provided test cases to collect failure-free execution paths, runtime variable values, and method calls involved in the buggy location. Solving the collected path conditions returns the values in the output column of Figure <ref type="figure">2</ref>, corresponding to desired values of the symbolic variable α.</p><p>Although this phase shares the same spirit as the specification inference step in Angelix <ref type="bibr" target="#b35">[36]</ref>, there are key differences. Angelix infers specifications by solving models of the form pc ∧ O a = O e , where pc is a path condition produced by symbolic execution of a test, O a is the actual output, and O e is the expected output that is typically manually provided by a user. <ref type="foot" target="#foot_4">5</ref> The models capture the idea that if the expected output matches the actual concrete test output, the corresponding path condition is a test-passing path. Solving all test-passing paths returns specifications that lead all tests to pass. This process, however, can be tedious and error-prone, since it usually requires users to instrument output variables manually. For instance, if the output is a large array of many elements, users must give all expected outputs for all the elements of the array.</p><p>S3 extracts examples in an automated manner by building on SPF <ref type="bibr" target="#b37">[38]</ref> automatic JUnit-test interpretation abilities. For a location i, S3 extracts examples by solving models of the form pc ∧ no errors. pc is the path condition: i j=1 pc j . The "no errors" notation means that the conditions describe paths that are guaranteed to not yield assertion errors (as described above). If the path condition pc yields an assertion error, S3 automatically discards that path. In another case, if an array-out-of-bound error happens, S3 pops the latest pc i leading to the error, keeping previous ones: i-1 j=1 pc j . This frees S3 users from manual effort, while guaranteeing that the examples are still failure-free.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Repair Synthesis from Examples</head><p>Examples extracted in the previous phase are input as correctness specifications to the repair synthesizer. The goal of the synthesizer is to inductively construct a solution that satisfies and also generalizes beyond the provided specifications. This synthesis procedure is composed of three main parts: (1) a domain-specific language (DSL), (2) a search procedure, and (3) ranking features. We begin with an overview, and detail each component subsequently.</p><p>We start with a DSL (extended from SYNTH-LIB <ref type="bibr" target="#b2">[3]</ref>) over the integer and boolean domains. Given a background theory T permitted by the DSL, let u be the original buggy expression, ϕ a formula over the vocabulary of T representing the correctness specifications (input-output examples), and L a set of expressions over the vocabulary of T of the same type as u. A candidate fix is an expression e ∈ L such that ϕ[u/e] is valid modulo T .</p><p>Our algorithm then systematically enumerates all candidate fix expressions, considering them in ranked order. The ranking is performed by a set of N ranking functions r i (1 ≤ i ≤ N ), each of which measures the distance between two expressions e 1 and e 2 of the same type. These ranking features estimate the syntactic and semantic distance between a candidate fix and the original buggy expression. The intuition is that expressions that are closer to the buggy program are more likely to constitute high-quality repairs.</p><p>Note, however, that the size of L (the search space) is often too large to be truly exhaustively enumerated. For practical purposes, we greedily favor candidate expressions of similar size and syntax to the original buggy expression. As described in Section 3.2.2, we systematically partition the search space, enabling different heuristics to be built without difficulty.</p><p>Algorithm 1 presents pseudocode for S3. At a high level, the search procedure enumerates all expressions in the grammar at a certain expression-size range (Line 4). S3 finds all candidate enumerated expressions that are consistent with the specifications (Line 7). Each candidate is assigned a ranking score by calculating the distance between it and the original buggy expression (Lines 8); candidates are sorted by score (Line 12). The process returns the solution in L with the smallest distance, if L ∅ (Line 14). Otherwise, it continues until all expression size ranges have been exhausted (Line 3). S3 starts enumerating at the size of the original buggy expression (Line 2), and modifies the size range accordingly up to a bound b (Line 3). The original buggy expression and its size are made available to the synthesis procedure through our "sketch" extension to the SYNTH-LIB syntax (Section 3.2.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Enumeration-based synthesis procedure</head><formula xml:id="formula_0">Input: u ▷ Original buggy expression ϕ ▷ Correctness specifications G ▷ SYNTH-LIB grammar (extended) R ▷ Set of ranking features b ▷ Synthesis bound 1: function Synthesis(u,ϕ,G,R,b) 2: i ← size of u 3: for k ← 0 to b do 4: A ← {e in grammar G | e of size from i -k to i + k } 5: L ← {} 6:</formula><p>for all e ∈ A do </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>sort (L)</head><p>▷ by ascending order of score return FAIL 18: end function</p><p>We next explain the DSL in detail (Section 3.2.1), the enumerationbased search procedure (Section 3.2.2), and the ranking features that we propose for the program repair domain (Section 3.2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Domain-Specific</head><p>Language via SYNTH-LIB. We extend SYNTH-LIB <ref type="bibr" target="#b2">[3]</ref> to systematically constrain S3's search space. We choose SYNTH-LIB for three reasons:</p><p>(1) Balanced Expressivity. SYNTH-LIB is adequately expressive for various tasks in the program repair domain, while still sufficiently restrictive to allow an efficient search procedure. Figure <ref type="figure" target="#fig_1">3</ref> describes a simplified grammar for SYNTH-LIB. Note that it allows the definition of integer expressions (IntExpr ), including integer constants (N ), integer variables, and binary relations. Boolean expressions are defined similarly. Although simple, this grammar is sufficiently expressive for repairs over integers in booleans, including linear computations and logical relationships.</p><p>(2) Availability. SYNTH-LIB is not esoteric, but instead, broadly available to various tools for Syntax-Guided Synthesis (SyGuS) <ref type="bibr" target="#b2">[3]</ref>. This allows for easy comparisons between tools, and indeed we use SYNTH-LIB to compare S3 with two other state-of-the-art SyGuS solvers (Enumerative <ref type="bibr" target="#b2">[3]</ref> and CVC4 <ref type="bibr" target="#b40">[41]</ref>). We believe that an abundance of synthesis techniques will benefit the program repair domain, given the rapid growth of the SyGuS research community, along with publicly available implementations <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b40">41]</ref>.</p><p>(3) Cost Metrics. SYNTH-LIB allows for definition of cost metrics like expression size; this is useful for calculating ranking features. We further extended SYNTH-LIB to allow the specification of a starting sketch, which gives clues on where the enumeration procedure should start. In our case, the starting sketch is the original buggy expression, capturing our idea that the correct fix is more likely to be syntactically and semantically close to the original code.</p><p>The sketch allows ranking features to measure the distance between candidate solutions and the original expression(s).</p><p>We illustrate with a SYNTH-LIB script for the example in Figure <ref type="figure" target="#fig_3">1</ref>; Figure <ref type="figure">4</ref> shows the corresponding SYNTH-LIB script. In Figure <ref type="figure">4</ref>, the first line sets the background theory of the language to Linear Integer Arithmetic (LIA). The function being synthesized f is of type int→int→bool→bool, (keyword synth-f un). The permitted solution space for the function f is described in its body, which allows expressions of type boolean. Each boolean expression can then be formed by logical relationships between any two integer or boolean expressions, via relational or logical operators. Expressions can also be variables; M1 in this case is a boolean expression. The allowed integer expression in the grammar is defined via IntExpr , which includes integer variables such as charno and M2, and constants such as 0.</p><p>We next define the constraints consisting of input-output examples and the starting sketch. Each constraint is defined by the keyword constraint. In our example, the first constraint says that if the value of M2 is 7, the value of M1 is true, and the value of charno is 7, the expected output of the function f over charno, M2, and M1 is true. The second constraint can be interpreted similarly. These constraints corresponding to the extracted input-output examples described in Figure <ref type="figure">2</ref>. A sketch, the starting-point expression, is defined by the keyword sketch. Here, the sketch is the original buggy expression u. Finally, the keyword check-synth instructs a synthesizer to start the synthesis process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.2</head><p>Enumeration-based Synthesis. S3 automatically generates a SYNTH-LIB script for each location under repair, and then uses an enumerative search to synthesize generalizable repair expressions conforming to the generated script. We note that multilocation repair can be achieved by generating the grammar for multiple functions simultaneously; we describe the process with respect to a single function for simplicity. We first explain how the SYNTH-LIB script is generated, and then the search procedure.</p><p>We divide the search space into multiple layers, each of which allows different components or operators, to appear in the SYNTH-LIB grammar script. If S3's search procedure cannot find a solution at a lower layer, it advances to the next. This approach tractably constrains the synthesis search space <ref type="bibr" target="#b36">[37]</ref>. Figure <ref type="figure">5</ref> shows the six layers. The first layer allows alternatives of operators existing in the original buggy expression. For example, a pair {"&amp;&amp;", "||"} means that the operators in the pair are alternatives of one another. If the search procedure cannot find any solution, the grammar then cumulatively allows additional variables that do not exist in the original buggy expression, denoted by the "Variables" component in the Figure <ref type="figure">5</ref>. At the second layer, the grammar allows basic-inequalities operators (= and !=), in addition to operators in the original expression. Again, if this search fails, it cumulatively allows for additional Variables. Subsequent layers can be interpreted similarly. We note that at the last (sixth) layer, the grammar allows all components, including integer constants appearing in the input-output examples. The reason integer constants are considered last is that such constants may unduly allow trivial solutions; this choice is influenced by previous studies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>The design of separate sub-search-spaces systematically allows us to either prioritize which space to explore first, or unify the spaces freely. We heuristically prioritize the search space by automatically analyzing the surrounding context of the original buggy statement, such as the method declaration that contains the buggy statement. Particularly, S3 automatically looks for expressions in the surrounding context that use the same variables appearing in the buggy statement, and analyzes the components used in those expressions. This gives S3 clues on which search space to start from. If the prioritized search space does not help find solutions, S3 searches in the unified search space (the sixth layer). If S3 cannot find context to help prioritize the space, it follows the procedure described previously, starting from the first layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Ranking Features.</head><p>We employ the insight that a correct repair is often syntactically and semantically close to a buggy expression/statement <ref type="bibr" target="#b7">[8]</ref>. We thus propose features that measure the syntactic and semantic distance between a candidate solution and the original buggy code. The final ranking score of a candidate solution is the sum of individual feature scores. S3 allows new features to be incorporated without difficulty; by contrast, constraint-based synthesis approaches (e.g. <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref>) typically require non-obvious Satisfiable Modulo Theory (SMT) encodings for new features <ref type="bibr" target="#b44">[45]</ref>.</p><p>Syntactic Features. Syntactic features look at differences between candidate solutions and the original buggy expression at the Abstract Syntax Tree (AST) level. We do this in three ways: • AST differencing. We use GumTree <ref type="bibr" target="#b11">[12]</ref> to compare ASTs.</p><p>GumTree produces transformations between ASTs in the form of actions on AST nodes such as insert, delete, update, or move. We measure the number of actions needed to transform the original buggy AST to the candidate solution AST. This feature can be easily calculated by directly applying GumTree on the ASTs produced by parsing the SYNTH-LIB grammar script. • Cosine similarity. An AST can also be represented as a vector of node occurrence counts <ref type="bibr" target="#b16">[17]</ref>. The occurrence of each node type (e.g., integer variables or constants, or a binary operation) in an AST, represent a vector of the AST. The similarity of two ASTs can then be represented by the cosine similarity of their representative vectors, denoted as cosine_score. We then define the distance from the solution's AST to the original AST as: 1 -cosine_score (cosine_score of 1 denotes that two vectors are identical). A SYNTH-LIB grammar explicitly enables type checking, meaning this feature is easy to calculate via an AST traversal to collect type information. • Locality of variables and constants. Variables and constants are the primary ingredients of expressions. Thus, in addition to capturing abstract changes on the AST, we capture lowerlevel differences via the locations of variables and constants in expressions. We compute the Hamming distance between two vectors representing locations of variables and constants in each expression. <ref type="foot" target="#foot_5">6</ref> For example, consider a ∧ (b &lt; 1) as the original expression, a ∧ (b ≤ 1) as the first solution, and (b ≤ 1) ∧ a as the second solution. The hamming distance from the original expression for the first and second solutions are 0 and 3 respectively. Although both solutions are semantically equivalent, we may want to prefer the first in the interest of change minimality.</p><p>Semantic Features. Semantic features look at either the difference between a solution S i and the original expression u, or the semantic quality of S i itself. We propose three semantic features: • Model counting. Model counting (c.f. <ref type="bibr" target="#b47">[48]</ref>) is often used to count the number of models satisfying a particular formula. We use this feature to measure the level of "disagreement" between any two boolean expressions. That is, we say that a solution S i and the original expression u disagree with each other if the formula (S i ∧ ¬u) ∨ (¬S i ∧ u) is valid, meaning that S i and u cannot be both valid at the same time. We then define the level of disagreement between S i and u by the number of models that satisfy the formula, which accounts for the semantic distance between them. As a simple example, assume that we have: a &lt; 10 as the original expression u, a ≤ 13 as a solution S 1 , and a ≤ 15 as a solution S 2 . The semantic distance via model counting between these solutions and u is 4 and 6, respectively. This simple example generalizes naturally to the typical off-byone bug in • Anti-patterns. This feature aims to heuristically prevent synthesis from generating trivial solutions. Particularly, these patterns are anti-duplicate and -constant expressions, e.g., a &lt; a, 0 1, etc. Expressions containing these patterns typically evaluate to a constant true or false , and are thus likely to overfit.</p><p>We filter out these expressions during the synthesis process. Again, this can be easily done by traversing the AST produced by the SYNTH-LIB grammar. The utility of anti-patterns has been explored for search-based program repair <ref type="bibr" target="#b44">[45]</ref>, but not for semantics-based counterparts, partially because it is difficult to integrate additional such measures directly in the constraintbased synthesis approach <ref type="bibr" target="#b44">[45]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental setup</head><p>We ran all experiments on a Intel Corei5 machine with 4 cores and 8GB of RAM.</p><p>Baseline approaches and settings. We compare S3 to Angelix <ref type="bibr" target="#b35">[36]</ref>, Enumerative <ref type="bibr" target="#b2">[3]</ref>, and CVC4 <ref type="bibr" target="#b40">[41]</ref>. Angelix offers its specification inference engine and synthesis engine in separate code packages. Although the specification inference engines behind Angelix and S3 work on C and Java programs, respectively, Angelix's synthesis engine takes as input example-based specifications like the synthesis engine of S3. Thus, to enable comparisons between S3 and Angelix, we instruct S3's inference engine to generate the same type of specifications that Angelix's synthesis engine uses, and instruct both S3's and Angelix's synthesis engines to synthesize the repair based on the same provided specifications. Enumerative <ref type="bibr" target="#b2">[3]</ref> and CVC4 <ref type="bibr" target="#b40">[41]</ref> are state-of-the-art Syntax-Guided Synthesis (SyGuS) engines which both take input in the form of SYNTH-LIB scripts, like S3. <ref type="foot" target="#foot_6">7</ref> This allows straightforward comparison between the tools.</p><p>For single-line patches, we run a repair synthesis tool on each buggy location of each program in parallel, and stop once a repair is found. The timeout for synthesis task is set to three minutes each. For multi-line-patches, we implement the approach described bellow.</p><p>Angelix tackles patches involving multiple lines <ref type="bibr" target="#b35">[36]</ref> by grouping multiple buggy locations, and synthesizing repairs for several locations at once. Angelix clusters buggy locations into groups of a user-specified size by either locality or suspiciousness score produced by fault localization. We reimplemented this feature, following Angelix's source code. <ref type="foot" target="#foot_7">8</ref> Angelix's synthesis engine are run on these specifications.</p><p>We implemented our own strategy to tackle multi-line patches for S3, Enumerative, and CVC4. Each buggy location is repaired separately, after which patches for certain locations are grouped. Given a test suiteT , and patches {P i } generated by a repair synthesis tool for location i. Assuming each patch p ∈ P i leads the program to pass a set of tests T i ⊂ T , we iterate through all patches and combine those that have ∪T i = T . The intuition is that combining these patches may render the whole test suite T to pass, which we then verify dynamically.</p><p>Datasets. We consider two datasets of buggy programs: • Small programs associated with high coverage test suites.</p><p>We experiment with 52 Java bugs in the smallest subject programs of the IntroClass program repair benchmark <ref type="bibr" target="#b29">[30]</ref> translated to Java <ref type="bibr" target="#b9">[10]</ref>. The programs are student-written homework assignment from an introductory programming class; the goal of the programs is to find the smallest number between four integer numbers. Although the programs are small, they feature possibly complicated fixes involving changes in multiple if-then-else structures. We include only syntactically distinct programs. We focus on smallest because it only includes integerand boolean-related fixes. Neither Angelix nor our framework can yet handle, e.g., floating point numbers or strings, primarily due to the limited capability of the constraint solving techniques used in symbolic execution.</p><p>A key benefit of focusing on these small programs is that the problems in IntroClass are associated with two independent, high-quality test suites. We use one test suite to guide the search for a repair and the other to assess produced patch quality. We further augment the dataset by using Symbolic PathFinder <ref type="bibr" target="#b37">[38]</ref> to generate additional tests. We do this by manually adding correctness specifications such as logical assertions, on the buggy programs, and use SPF to generate test inputs that expose bugs, e.g., assertion violations. This results in 16 additional tests.</p><p>• Large real-world programs. Our second dataset consists of 100 large real-world Java bugs from 62subject programs, featuring ground truth bug fixes submitted by developers. Our dataset only includes bugs with patches that change fewer than five lines of code. This simplifies quality and correctness assessment of machine-generated patches, which is especially important because real-world test cases can be incomplete or weak specifications of desired behavior <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b42">43]</ref>. We build our dataset based on a previously-proposed bug fix history dataset <ref type="bibr" target="#b27">[28]</ref>, which originally consists of around 3000 likely bug-fixing commits of fewer than five lines of code collected from GitHub. To further ensure that the collected commits are actually bug fixes, we randomly sampled 500 commits, and manually checked them to ensure that the commits compile and that the program test cases expose bugs pre-commit (as compared to post-commit test behavior). We treat tests that fail in the before-patched version but pass in the patched version as the failing tests addressed by the bug fixing commit. Since this process is time consuming, we stopped once we found 100 bugs from 62 programs. Table <ref type="table" target="#tab_4">1</ref> shows the top five largest programs for which S3 can correctly patch bugs. "KLoc" depicts the number of lines of Java code in each project.  Research questions and metrics. Our core metric is the number of buggy programs that a tool correctly patches. Fully assessing repair quality and correctness is an open problem in program repair research, and thus we approximate in several ways. For the IntroClass bugs, we designate a patch correct if it passes all held-out test cases, described above. We divide the SPF-generated tests randomly, using half to augment the tests used to repair and the other half to augment the held-out tests. For the real-world bugs, a patch is deemed correct if it is syntactically identical to the developer-produced patch. We also manually inspect all the results (produced by all repair tools) as a sanity check. In our inspection, if it is possible for a machine-generated patch to be converted into the corresponding developer's patch via basic transformations, we also consider it as correct. These patches are the minority in our evaluation; we separate these in our results and present the patches in prose. We report overfitting rate, or the percentage of produced patches that are incorrect, for each tool (lower is better); and expressive power in terms of the unique buggy programs each tool correctly patches. Our two research questions are then divided by dataset: RQ1. How does each tool perform on the dataset of small programs associated with high coverage test cases, in terms of correct patches generated, overfitting rate, and expressive power? RQ2. How does each tool perform on the dataset of real-world programs, in terms of correct patches generated, overfitting rate, and expressive power?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance on IntroClass</head><p>Table <ref type="table" target="#tab_5">2</ref> shows the results of each repair synthesis tool on 52 bugs from the IntroClass dataset. The "Produced" column shows the total number of patches that each tool generated that pass the provided test cases, while the "Pass held-out tests" shows the number of produced patches that generalize to pass all held-out evaluation tests (and that we thus consider correct). "% Overfit" shows the percentage of produced patches that do not generalize to the heldout tests (lower is better). Note that Angelix's multi-line patch facility is driven by two parameters: number of buggy locations in a group <ref type="bibr" target="#b0">(1)</ref><ref type="bibr" target="#b1">(2)</ref><ref type="bibr" target="#b2">(3)</ref><ref type="bibr" target="#b3">(4)</ref>, and the criterion used to group them (either by locality or suspiciousness score). These results are based on score-based grouping, which uniformly outperformed the alternative in our experiments (results not shown). When the group size is set to 1, we allow Angelix to try our own multi-line patch strategy, in case single-line repair is unsuccessful. Table <ref type="table" target="#tab_5">2</ref> shows that S3 substantially outperforms the baselines, generating significantly more patches, all of which generalize to the held out test cases. The degree to which Angelix patches overfit varied by lines considered, ranging from a minimum of 61% to a maximum of 82%. Enumerative and CVC4 perform comparably, with a very high percentage of overfitting patches. S3 generates correct patches for all the bugs for which Angelix, Enumerative, and CVC4 can fix. S3 also generated almost exclusively multi-line patches (with one exception).</p><p>We speculate that the underlying synthesis techniques are the primary source of the baselines' weak performance. Enumerative enumerates expressions in increasing size, while CVC4 uses unsatisfiability (unsat) cores to synthesize solutions; neither rank candidate solutions, but instead conservatively return the first satisfying solution identified. Angelix encodes a simple patch minimality preference criteria in constraints suitable for PartialMax SMT. However, in these experiments, we observed that Angelix frequently generated patches that are quite different from the original buggy expressions (typically much smaller in size). These results and observations suggest that S3's combination of a customizable search space, an appropriately-managed expression-size-wise search strategy, and numerous ranking functions, all contribute to its successful generation of generalizable patches. Figure <ref type="figure">6</ref> shows an example of a bug that S3 patches correctly but to which the baselines overfit. For brevity, we only show patches from S3 and Angelix. This code snippet requires a multi-line patch to multiple if-conditions. We show the replacement if-expressions from S3 and Angelix in the code comments. From the first ifcondition, the Angelix fix is already incorrect, as it fails to capture the necessary relationship between variables a and b. The condition from S3 shares the structure of the original buggy expression, capturing the relationships between all variables. Producing this patch is likely assisted by S3's expression-size-wise enumerative search, which starts from the size of the original buggy expressions.  shows the total number of bugs for which each tool generated a patch. Because we lack second independent test suites for these programs, we use a direct syntactic match to the developer patch to define correctness (row "Syntax match"). We additionally found, via manual inspection, a small number of additional patches that appear semantically identical to the developer patches; we describe these patches for S3 below. The last two rows show the percentage of produced patches that fail to generalize to capture the developerwritten patch, as judged via strict syntactic match ("Overfit, Syn") or via both syntactic match and manual inspection ("Overfit, Both").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance on real-world programs</head><p>S3 again substantially outperforms the baseline techniques, generating correct patches for many more programs. Only 4 of the 20 S3 patches fail to strictly syntactically match the developer fixes. Although manual author inspection, is an inadequate mechanism for rigorously assessing patch quality, simple syntactic transformation rules can convert these patches to their developer equivalents; we separate these out in Figure <ref type="figure" target="#fig_0">7</ref>.</p><p>In terms of overfitting, only 20% of S3's patches fail to generalize when judged by perfect syntactic fidelity; when manual inspection is considered, none of the patches overfit. For Angelix, Enumerative, and CVC4, 54%, 58%, and 54% of the produced patches overfit, respectively.</p><p>In these experiments, we also evaluate the relative contribution of S3's syntactic versus semantic feature sets for ranking -S3 syn and S3 sem in the table, respectively. When only either syntactic or semantic features are used to rank the solution space, the performances of S3 varies. S3 syn and S3 sem generate fewer correct patches, with slightly higher overfitting rates, suggesting that both kinds of features are beneficial for S3's performance.</p><p>All programs that are correctly fixed by other tools are also fixed by S3. We note that the number of correctly-fixed bugs by the three baselines can be increased (to 9 bugs) if we combine all bugs correctly repaired by them. This combination is, however, still inferior to S3's performance.</p><p>The first bug in Figure <ref type="figure" target="#fig_0">7</ref> is an example of a bug that S3 fixes correctly, while the others do not. Enumerative and CVC4 generate the same fix with each other, that does not ultimately pass all tests (both synthesize (0 == 0) to replace the if condition); Angelix generates no fix for this bug. S3's fix is not syntactically identical but it is semantically equivalent to the developer's fix. This can be demonstrating by transforming S3's patch using basic transformation rules, e.g., swapping both left and right hand sides of the "||" operator, and converting the integer 46 to the character ". ". The fix generated by Enumerative and CVC4, on the other hand, cannot be transformed to the developer's fix. We note that the incorrect fix generated by Enumerative and CVC4 is largely destructive, since it converts the branch condition to always evaluate to true. This kind of destructive fix can be prevented in S3 via the anti-patterns feature, as described in Section 3.2.3. In general, S3 generates more correct patches than the other approaches, judged via both syntactic fidelity to the developer fix and via fidelity with respect to basic syntactic transformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discussion, Limitations, and Threats</head><p>Discussion and Limitations. Semantics-based repair in general exclusively modifies expressions in conditions or on the right-hand side of assignments. Additionally, such techniques can only synthesize or reason about replacement code including boolean or integer types. Our experience suggests that these limitations are the primary reasons for unrepaired bugs in our experiments. Some bugs require large changes to semantic or control-flow structure (e.g., a change from if(...){A};if(...){B} to if(...){A} else if(...){B}), the insertion of new statements, or manipulation of variables of types that existing constraint solving technology cannot handle. Resolving these challenges remains future work, and can progress apace with progress in the synthesis domain. However, it is noteworthy that semantics-based repair techniques are reasonably expressive despite these limitations.</p><p>Threats to validity. Our results may not generalize to other subject programs beyond those upon which our experiments were conducted. We mitigate this risk by evaluating our solution on 100 real bugs from many real-world programs. The size of this bug set is commensurate with those used to evaluate prior automated repair techniques, e.g., <ref type="bibr" target="#b28">[29]</ref>. Another threat to the validity of our results is our reimplementation of the multi-line patch feature of Angelix (Section 4.1). However, we note this feature is simple, and only takes around 70 lines of Python code, and that we used the existing released implementation as reference.</p><p>Finally, we seek to assess the quality of the produced patches, in terms of the degree to which they overfit to the provided test cases (or, by contrast, generalize beyond them). Patch quality, especially in an automated repair context, is an unsolved research problem. We assess patch quality using several objective and established measures. We use independent test suites, when possible, to quantify overfitting (an established methodology <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b42">43]</ref>). For real-world programs, we use syntactic fidelity to the developer patches as the gold standard for correctness. Bugs may often be patched multiple ways, and thus this standard is likely stricter than correctness truly requires. We also manually inspect all produced patches, a process subject to bias but important to safeguard against mistakes. We present a number of these patches in this paper, and publicly release all the results, experimental data, and our code for open investigations. <ref type="foot" target="#foot_8">9</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Program repair. General program repair techniques can typically be divided into two main branches: heuristic-and semanticsbased repair. Heuristics-based repair includes techniques like Gen-Prog <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b49">50]</ref>, which heuristically searches for repairs via genetic programming algorithm. RSRepair <ref type="bibr" target="#b38">[39]</ref> and AE <ref type="bibr" target="#b48">[49]</ref> replace the search strategy in GenProg by random and adaptive search strategies, respectively. These techniques, despite scaling well, have been shown to produce patches that overfit to the provided test suites <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b42">43]</ref>. PAR <ref type="bibr" target="#b19">[20]</ref> generates repairs based on repair templates manually learned from human written patches. More recently, Prophet <ref type="bibr" target="#b33">[34]</ref> and HDRepair <ref type="bibr" target="#b27">[28]</ref> also use heuristic search to generate patches, augmented with mined repair models from historical data to rank patches, preferring those that match frequent human fix patterns. Tan et al. propose anti-patterns to prevent heuristic tools from generating trivial repairs <ref type="bibr" target="#b44">[45]</ref>. ACS <ref type="bibr" target="#b50">[51]</ref> targets if-condition defects by using fix templates (rules) to generate patches. It then leverages document analysis (such as on javadoc comments) as an additional criterion to rank patches.</p><p>Semantics-based repair techniques, such as SemFix <ref type="bibr" target="#b36">[37]</ref>, Direct-Fix <ref type="bibr" target="#b34">[35]</ref>, and Angelix <ref type="bibr" target="#b35">[36]</ref>, use symbolic execution and program synthesis to synthesize repairs. Such techniques, however, either do not have a notion of patch ranking or only include simple ranking criteria such as syntactic structural differences. As such, semantics-based repair approaches can also produce overfitting patches <ref type="bibr" target="#b26">[27]</ref>, motivating stronger techniques that can generalize beyond weak specifications inferred from tests. Other semantics-based techniques include SPR <ref type="bibr" target="#b31">[32]</ref>, which targets defects in if-conditions; SPR can also produce trivial or functionality-deleting repairs <ref type="bibr" target="#b35">[36]</ref>. Nopol <ref type="bibr" target="#b52">[52]</ref> works in a similar spirit to SPR and SemFix, targeting if-condition defects using SMT-based synthesis. Qlose <ref type="bibr" target="#b7">[8]</ref> uses program execution traces as an additional criteria to rank patches, and encode program repair problem into a program synthesis tool namely SKETCH <ref type="bibr" target="#b43">[44]</ref>. SearchRepair <ref type="bibr" target="#b18">[19]</ref> lies between heuristicand semantic-based repair, using semantic search as its underlying mutation approach to produce higher-granularity, high-quality patches. However, it does not yet scale as well as other approaches.</p><p>Our technique, S3, belongs to the semantics-based family, and thus, is different in kind from the heuristic techniques. S3 can target more bug types than SPR, Nopol, and ACS (which focus on if condition-based defects) including incorrect assignments, ifand loop-conditions, and expressions in return statements. Unlike ACS, S3 does not use explicit fix templates or document analysis to generate or rank patches; integrating such approaches in ranking especially is a possible avenue for future work. S3 is more scalable compared to various semantics-based counterparts such as SemFix, DirectFix, Qlose, and SearchRepair. S3 also allows the inclusion of a variety of ranking features beyond syntactic structural differences considered in prior work. Indeed, S3's ability to incorporate new ranking criteria is an important novelty, overcoming a known challenge in SMT-based synthesis <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b44">45]</ref>.</p><p>Program synthesis. Generally, techniques in this area include inductive (example-based) synthesis and deductive (logical reasoning based) synthesis. S3 belongs to the inductive family. Flash-Fill <ref type="bibr" target="#b12">[13]</ref> synthesizes programs that work on string domain. FlashExtract <ref type="bibr" target="#b22">[23]</ref> synthesize programs that automate the data extraction process. Singh et al. use programming by examples (PBE) to automatically transform spreadsheet data types <ref type="bibr" target="#b41">[42]</ref>. FlashNormalize <ref type="bibr" target="#b20">[21]</ref> automatically normalizes texts using PBE. Refazer uses a PBE-based approach to automatically learn program transformations. NoFAQ synthesizes command repairs from input-output examples <ref type="bibr" target="#b8">[9]</ref>. Programming via sketching <ref type="bibr" target="#b43">[44]</ref> uses a sketch as partial specifications, and search for an implementation that satisfies the specification; we use a similar idea in the DSL that uses a starting sketch to help rank candidate solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We proposed S3, a new repair synthesis system that is able to generate high-quality, general patches for bugs in real programs. S3 consists of two main phases, which serve to: <ref type="bibr" target="#b0">(1)</ref> Automatically extract examples that serve as a specification of correct behavior, using dynamic symbolic execution on provided test cases, and (2) Use a synthesis procedure inspired by the programming-byexamples methodology to synthesize general patches. The efficiency and effectiveness of the synthesis procedure is enabled by our novel designs of three main parts, including a domain-specific language, which we extend from SYNTH-LIB <ref type="bibr" target="#b2">[3]</ref>; an expressionsize-wise enumerative search; and syntax-and semantic-guided ranking features that help rank the highest quality solutions highest in the solution space. Our results showed that S3 generates many more high-quality bug fixes than even the best performing baseline from prior work.</p><p>Beyond these results, our approach opens a number of opportunities for future repair synthesis techniques. The specifications, in the form of input-output examples, can be strengthened with specifications inferred by specification mining and other inference techniques <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22]</ref>, possibly enabling integration of inductive and deductive synthesis for a more expressive overall system. Our framework's flexible design allows more features to be investigated and easily integrated into our ranking technique, such as, for example frequent fix patterns mined from human written patches <ref type="bibr" target="#b27">[28]</ref>. Our dataset can also be extended, and used to evaluate many more repair systems. We plan to extend the SYNTH-LIB grammar to represent more tasks in the program repair domain, e.g., nonlinear computations on the integer domain. Finally, machine learning might be useful in automatically classifying bug types <ref type="bibr" target="#b46">[47]</ref>, to more effectively deal with different kinds of defects automatically.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>7 :</head><label>7</label><figDesc>if ϕ[e/u] is valid then 8: e.score ← r i ∈R r i (e,u)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Simplified SYNTH-LIB grammar used in S3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 ( 4 ( 5 ( 13 (Figure 4 :Figure 5 :</head><label>1451345</label><figDesc>Figure 4: SYNTH-LIB script generated by S3 for the example in Figure 1, derived using the "Alternatives" layer described in Figure 5. M1 stands for excerpt.equals(LINE), and M2 stands for sourceExcerpt.length().</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 .</head><label>1</label><figDesc>• Output coverage. This feature looks at how much a solution covers the set of outputs in the set of input-output examples. For instance, assume input-output examples (constraints) for two tests T 1 and T 2 , on an input i, and an output o:T 1 : i = 5 → o = 5 T 2 : (i = 6 → o = 5) ∨ (i = 6 → o = 6) A trivialsolution for this example is simply the constant 5; Another solution is the expression i. The first solution overfits to only one output despite the presence of three examples that have two distinct outputs. The second solution covers all output scenarios in the provided examples, making it intuitively less overfitting as compared to the first. A solution S i receives a O cov i score of N c /N o , where N o is the number of output scenarios in the provided input-output examples, and N c is the number of output scenarios that the solution S i covers. The feature score of a solution S i is defined as 1 -O cov i . The higher O cov i , the better the solution S i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 2 / 3 / 6 / 7 // By Angelix: no change 8 Figure 6 :</head><label>236786</label><figDesc>Figure 6: A bug in a smallest program correctly fixed exclusively by S3. We show the patches from S3 and Angelix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Bugs for which S3 generates patches that are not syntactically identical but semantically equivalent to the developer fixes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>&lt; to a &lt;= in the second line of the if condition.</figDesc><table><row><cell cols="4">1 if ( sourceExcerpt != null ) {</cell><cell></cell></row><row><cell>2</cell><cell>...</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3</cell><cell cols="4">-if ( excerpt . equals ( LINE ) &amp;&amp; 0 &lt;= charno</cell></row><row><cell>4</cell><cell>-</cell><cell cols="3">&amp;&amp; charno &lt; sourceExcerpt . length () ) {</cell></row><row><cell>5</cell><cell cols="4">+ if ( excerpt . equals ( LINE ) &amp;&amp; 0 &lt;= charno</cell></row><row><cell>6</cell><cell>+</cell><cell cols="3">&amp;&amp; charno &lt;= sourceExcerpt . length () ) {</cell></row><row><cell>7</cell><cell>...</cell><cell></cell><cell></cell><cell></cell></row><row><cell>8 }</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Figure 1: A bug in Closure compiler, revision 1e070472. The</cell></row><row><cell cols="6">bug is at lines 3-4. The developer fix is shown on lines 5-6;</cell></row><row><cell cols="4">it turns a Input</cell><cell></cell><cell>Desired</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(M1)</cell><cell>(M2)</cell></row><row><cell cols="6">Test charno excerpt.equals(LINE) sourceExcerpt.length() Output</cell></row><row><cell>A</cell><cell></cell><cell>7</cell><cell>true</cell><cell>7</cell><cell>true</cell></row><row><cell>B</cell><cell></cell><cell>10</cell><cell></cell><cell></cell></row></table><note><p>true 10 true Figure 2: Input-output examples for both variables and conditions, extracted for the Closure compiler bug described in Figure</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Top 5 largest programs that S3 can correctly patch. Math refers to the Apache Commons Math library</figDesc><table><row><cell></cell><cell cols="5">Closure OrientDB Math Molgenis Heritrix</cell></row><row><cell>KLoc</cell><cell>237</cell><cell>203</cell><cell>175</cell><cell>54</cell><cell>48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Repair tool performance on 52 IntroClass bugs.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Angelix</cell><cell></cell></row><row><cell></cell><cell cols="3">S3 Enum CVC4</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell>Produced</cell><cell>22</cell><cell>13</cell><cell>13</cell><cell>17</cell><cell>18</cell><cell>17</cell><cell>20</cell></row><row><cell>Pass all held-out tests</cell><cell>22</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>7</cell><cell>4</cell><cell>4</cell></row><row><cell>% Overfit</cell><cell>0%</cell><cell>92%</cell><cell cols="5">92% 82% 61% 76% 80%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Repair tool performance on 100 real-world bugs.</figDesc><table><row><cell></cell><cell cols="6">S3 S3 syn S3 sem Enum CVC4 Angelix</cell></row><row><cell>Produced</cell><cell>20</cell><cell>15</cell><cell>12</cell><cell>13</cell><cell>12</cell><cell>13</cell></row><row><cell>Syntax match</cell><cell>16</cell><cell>11</cell><cell>7</cell><cell>5</cell><cell>4</cell><cell>4</cell></row><row><cell>Manual</cell><cell>4</cell><cell>1</cell><cell>4</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>Overfit, Syn</cell><cell>20%</cell><cell>27%</cell><cell>42%</cell><cell>62%</cell><cell>67%</cell><cell>69%</cell></row><row><cell>Overfit, Both</cell><cell>0%</cell><cell>20%</cell><cell>8%</cell><cell>54%</cell><cell>58%</cell><cell>54%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3</head><label>3</label><figDesc>shows the results of applying each considered repair tool on 100 real-world bugs from our second dataset. The first row 1 ...First bug... 2 -if (Character.isDigit(next)// Buggy if-condition 3 + if (Character.isDigit(next) || next == . ) // fix by developer 4 + if ((46 == next) || Character.isDigit(next)) // fix by S3 5 6 ...Second bug...</figDesc><table><row><cell cols="2">7 -return (csvBuffer.getMark() &gt;= (bufferIndex -1))// fix buggy expression</cell></row><row><cell cols="2">8 + return (bufferIndex) &lt; (csvBuffer.getMark() + 1)// fix by developer</cell></row><row><cell cols="2">9 + return (csvBuffer.getMark() &gt; (bufferIndex -1))// fix by S3</cell></row><row><cell>10</cell><cell></cell></row><row><cell cols="2">11 ...Third bug...</cell></row><row><cell cols="2">12 -while (newLength &gt; offset)// fix buggy expression</cell></row><row><cell cols="2">13 + while (newLength &lt; offset)// fix by developer</cell></row><row><cell cols="2">14 + while (offset &gt; newLength)// fix by S3</cell></row><row><cell>15</cell><cell></cell></row><row><cell cols="2">16 ...Fourth bug...</cell></row><row><cell cols="2">17 if(this.runningState != STATE_RUNNING &amp;&amp; this.runningState !=</cell></row><row><cell></cell><cell>STATE_SUSPENDED) {</cell></row><row><cell>18</cell><cell>throw new IllegalStateException("...");</cell></row><row><cell>19 }</cell><cell></cell></row><row><cell>20 -</cell><cell>stopTime = System.currentTimeMillis();</cell></row><row><cell>21 +</cell><cell>if(this.runningState == STATE_RUNNING) { // fix by developer</cell></row><row><cell>22 +</cell><cell>if(this.runningState != STATE_SUSPENDED) // fix by S3</cell></row><row><cell>23 +</cell><cell>stopTime = System.currentTimeMillis();</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use the subset of IntroClass to which our repair tools can apply, given their applicability to strictly integer and boolean domains.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://xuanbachle.github.io/semanticsrepair/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>For simplicity, we describe the process with respect to a single location; it extends naturally, by installing symbolic variables at multiple locations at once.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>We refer readers to the Angelix manual: https://github.com/mechtaev/angelix/blob/ master/doc/Tutorial.md</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://en.wikipedia.org/wiki/Hamming_distance</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>We refer interested readers to<ref type="bibr" target="#b0">[1]</ref> and http://www.sygus.org/ for a full comparison between SyGuS engines</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>https://github.com/mechtaev/angelix. The implementation for this feature in Angelix's source is approximately 70 lines of Python code.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>https://xuanbachle.github.io/semanticsrepair/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is supported in part by the National Science Foundation under grant CCF-1563797. Duc-Hiep Chu was supported in part by the Austrian Science Fund (FWF) under grants S11402-N23 (RiSE/SHiNE) and Z211-N23 (Wittgenstein Award).</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>: Syntax-and Semantic-Guided Repair Synthesis via Programming by Examples. In Proceedings of 2017 11th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, Paderborn, Germany, September 4-8, 2017 (ESEC/FSE'17), 12 pages.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Syntax-guided Synthesis</title>
		<ptr target="http://www.sygus.org/" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the accuracy of spectrum-based fault localization</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Zoeteweij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjan Jc</forename><surname>Van Gemund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION</title>
		<imprint>
			<publisher>TAICPART-MUTATION</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Armando Solar-Lezama, Emina Torlak, and Abhishek Udupa</title>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rastislav</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garvit</forename><surname>Juniwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milo Mk</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukund</forename><surname>Raghothaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanjit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Syntax-guided synthesis. Dependable Software Systems Engineering</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Scaling Enumerative Program Synthesis via Divide and Conquer</title>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Alur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Radhakrishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Udupa</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Tom</forename><surname>Britton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Jeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Carver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Cheak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomer</forename><surname>Katzenellenbogen</surname></persName>
		</author>
		<title level="m">Reversible Debugging Software</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>University of Cambridge, Judge Business School</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Shaon Barman, and Rastislav Bodik. 2011. Angelic debugging</title>
		<author>
			<persName><forename type="first">Satish</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emina</forename><surname>Torlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE&apos;11</title>
		<imprint>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Selective symbolic execution</title>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Chipounov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Zamfir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Candea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Hot Topics in System Dependability</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>HotDep</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Qlose: Program repair with quantitative objectives</title>
		<author>
			<persName><forename type="first">Loris D'</forename><surname>Antoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roopsha</forename><surname>Samanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Aided Verification (CAV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="383" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">NoFAQ: Synthesizing command repairs from examples</title>
		<author>
			<persName><forename type="first">Loris D'</forename><surname>Antoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Vaughn</surname></persName>
		</author>
		<ptr target="ESEC/FSE&apos;17" />
	</analytic>
	<monogr>
		<title level="m">Joint Conference on European Software Engineering Conference and International Symposium on Foundations of Software Engineering</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">IntroClassJava: A Benchmark of 297 Small and Buggy Java Programs</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Monperrus</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-01272126/document" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
		<respStmt>
			<orgName>Universite Lille</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Daikon system for dynamic detection of likely invariants</title>
		<author>
			<persName><forename type="first">Jeff</forename><forename type="middle">H</forename><surname>Michael D Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">J</forename><surname>Perkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Mccamant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">S</forename><surname>Pacheco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Tschantz</surname></persName>
		</author>
		<author>
			<persName><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science of Computer Programming</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fine-grained and accurate source code differencing</title>
		<author>
			<persName><forename type="first">Jean-Rémy</forename><surname>Falleri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Floréal</forename><surname>Morandat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Blanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matias</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Software Engineering (ASE&apos;14</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automating string processing in spreadsheets using inputoutput examples</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="317" to="330" />
			<date type="published" when="2011">2011</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Programming by Examples (and its applications in Data Wrangling)</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Esparza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orna</forename><surname>Grumberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salomon</forename><surname>Sickert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<publisher>Verification and Synthesis of Correct and Secure Systems</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The impact of tangled code changes</title>
		<author>
			<persName><forename type="first">Kim</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Conference on Mining Software Repositories (MSR)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Oracleguided Component-based Program Synthesis</title>
		<author>
			<persName><forename type="first">Susmit</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanjit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName><surname>Tiwari</surname></persName>
		</author>
		<idno type="DOI">10.1145/1806799.1806833</idno>
		<ptr target="http://dx.doi.org/10.1145/1806799.1806833" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<meeting><address><addrLine>Cape Town, South Africa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deckard: Scalable and accurate tree-based detection of code clones</title>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghassan</forename><surname>Misherghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhendong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Glondu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Defects4J: A database of existing faults to enable controlled testing studies for Java programs</title>
		<author>
			<persName><forename type="first">René</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darioush</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Software Testing and Analysis</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
	<note>ISSTA &apos;14</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Repairing Programs with Semantic Code Search</title>
		<author>
			<persName><forename type="first">Yalin</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">T</forename><surname>Stolee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Brun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic patch generation learned from human-written patches</title>
		<author>
			<persName><forename type="first">Dongsun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaechang</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE &apos;13</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="802" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FlashNormalize: Programming by Examples for Text Normalization</title>
		<author>
			<persName><forename type="first">Dileep</forename><surname>Kini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="776" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Synergizing specification miners through model fissions and fusions (t)</title>
		<author>
			<persName><forename type="first">Tien-Duy B</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan-Bach D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Beschastnikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="115" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Flashextract: A framework for data extraction by examples</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGPLAN Notices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="542" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">JFIX: Semantics-Based Repair of Java Programs via Symbolic PathFinder</title>
		<author>
			<persName><forename type="first">Xuan-Bach D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duc-Hiep</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willem</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Software Testing and Analysis</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>to appear. IS-STA&apos;17</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Enhancing Automated Program Repair with Deductive Verification</title>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quang</forename><surname>Loc Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Maintenance and Evolution (ICSME)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="428" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Should fixing these failures be delegated to automated program repair</title>
		<author>
			<persName><forename type="first">Xuan-Bach D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien-Duy B</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Software Reliability Engineering (ISSRE)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="427" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Empirical study on synthesis engines for semantics-based program repair</title>
		<author>
			<persName><forename type="first">Xuan-Bach D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Maintenance and Evolution</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="423" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">History driven program repair</title>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Analysis, Evolution, and Reengineering (SANER)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="213" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A systematic study of automated program repair: Fixing 55 out of 105 bugs for $8 each</title>
		<author>
			<persName><forename type="first">Claire</forename><surname>Le Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dewey-Vogt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Westley</forename><surname>Weimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE&apos;12)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The ManyBugs and IntroClass benchmarks for automated repair of C programs</title>
		<author>
			<persName><forename type="first">Claire</forename><surname>Le Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neal</forename><surname>Holtschulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Devanbu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Westley</forename><surname>Weimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Software Engineering (TSE)</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1236" to="1256" />
			<date type="published" when="2015-12">2015. Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">GenProg: A Generic Method for Automatic Software Repair</title>
		<author>
			<persName><forename type="first">Claire</forename><surname>Le Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanhvu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Westley</forename><surname>Weimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="54" to="72" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Staged Program Repair with Condition Synthesis</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Software Engineering Conference and International Symposium on Foundations of Software Engineering</title>
		<imprint>
			<publisher>ESEC/FSE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="166" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An analysis of the search spaces for generate and validate patch generation systems</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="702" to="713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic Patch Generation by Learning Correct Code</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Principles of Programming Languages (POPL)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="298" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Directfix: Looking for simple program repairs</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Mechtaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jooyong</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhik</forename><surname>Roychoudhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Angelix: Scalable multiline program patch synthesis via symbolic analysis</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Mechtaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jooyong</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhik</forename><surname>Roychoudhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="691" to="701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semfix: Program repair via semantic analysis</title>
		<author>
			<persName><forename type="first">Hoang</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="772" to="781" />
		</imprint>
	</monogr>
	<note>Abhik Roychoudhury, and Satish Chandra</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Symbolic PathFinder: integrating symbolic execution with model checking for Java bytecode analysis</title>
		<author>
			<persName><forename type="first">Corina</forename><forename type="middle">S</forename><surname>Păsăreanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willem</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bushnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaco</forename><surname>Geldenhuys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Mehlitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neha</forename><surname>Rungta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="391" to="425" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The strength of random search on automated program repair</title>
		<author>
			<persName><forename type="first">Yuhua</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziying</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="254" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An analysis of patch plausibility and correctness for generate-and-validate patch generation systems</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Achour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Rinard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Software Testing and Analysis (ISSTA)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="24" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Counterexample-guided quantifier instantiation for synthesis in SMT</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Deters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kuncak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cesare</forename><surname>Tinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clark</forename><surname>Barrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Aided Verification (CAV)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="198" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transforming spreadsheet data types using examples</title>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGPLAN Notices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="343" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Is the cure worse than the disease? overfitting in automated program repair</title>
		<author>
			<persName><forename type="first">K</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Earl</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><surname>Brun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering</title>
		<meeting>the 2015 10th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="532" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Programming by sketching for bit-streaming programs</title>
		<author>
			<persName><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodric</forename><surname>Rabbah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGPLAN Notices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="281" to="294" />
		</imprint>
	</monogr>
	<note>Rastislav Bodík, and Kemal Ebcioğlu</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Anti-patterns in search-based program repair</title>
		<author>
			<persName><forename type="first">Shin</forename><surname>Hwei Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhik</forename><surname>Mukul R Prasad</surname></persName>
		</author>
		<author>
			<persName><surname>Roychoudhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Foundations of Software Engineering</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="727" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The economic impacts of inadequate infrastructure for software testing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tassey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Planning Report</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Active semi-supervised defect categorization</title>
		<author>
			<persName><forename type="first">Ferdian</forename><surname>Thung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan-Bach D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Program Comprehension</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="60" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">What makes killing a mutant hard</title>
		<author>
			<persName><forename type="first">Willem</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="39" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Leveraging program equivalence for adaptive program repair: Models and first results</title>
		<author>
			<persName><forename type="first">Westley</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">P</forename><surname>Fry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Forrest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Software Engineering (ASE)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="356" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Automatically finding patches using genetic programming</title>
		<author>
			<persName><forename type="first">Westley</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanhvu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Forrest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="364" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Precise condition synthesis for program repair</title>
		<author>
			<persName><forename type="first">Yingfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Runfa</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiachen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering (ICSE)</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="416" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Germany</forename><surname>Paderborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xuan-Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duc-Hiep</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">Le</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willem</forename><surname>Goues</surname></persName>
		</author>
		<author>
			<persName><surname>Visser</surname></persName>
		</author>
		<title level="m">ESEC/FSE&apos;17</title>
		<imprint>
			<date type="published" when="2017">September 4-8, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs</title>
		<author>
			<persName><forename type="first">Jifeng</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matias</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Favio</forename><surname>Demarco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Clément</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Lamelas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Le Berre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
