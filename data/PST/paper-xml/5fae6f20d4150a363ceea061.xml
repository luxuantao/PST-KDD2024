<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Journal Pre-proof A Survey on Empathetic Dialogue Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-05-20">May 20, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Khanh</roleName><forename type="first">Yukun</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Linh</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Frank</forename><forename type="middle">Z</forename><surname>Xing</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Linh</forename><surname>Khanh</surname></persName>
						</author>
						<author>
							<persName><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">†air</forename><surname>Labs</surname></persName>
						</author>
						<author>
							<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Continental</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Survey on Empathetic Dialogue Systems, Information Fusion</orgName>
								<address>
									<postCode>2020)</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">‡School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Journal Pre-proof A Survey on Empathetic Dialogue Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-05-20">May 20, 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">57F0AFF5094CE67B9DF46FA3ADD4D883</idno>
					<idno type="DOI">10.1016/j.inffus.2020.06.011</idno>
					<note type="submission">Received date: 30 November 2019 Revised date: 20 May 2020 Accepted date: 23 June 2020 Preprint submitted to Journal of Information Fusion</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Fusion Artificial Intelligence</term>
					<term>Affective Computing</term>
					<term>Dialogue Systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The primary goal of building a dialogue system is to address users' questions and concerns via emulating the way humans communicate with each other. As human language is too complicated to be considered as a single target, dialogue systems have to model different aspects of human communication separately.</p><p>Recent years have witnessed the emergence of empathy models in the context of dialogue systems and, hence, an increasing attention from the natural language processing (NLP) community.</p><p>Empathy is the capability of projecting feelings and ideas of the other party to someone's knowledge <ref type="bibr" target="#b6">[1]</ref>. It plays an important part in the communication of human beings as it has the potential for enhancing their emotional bond.</p><p>As noted by a previous study <ref type="bibr" target="#b7">[2]</ref>, incorporating empathy into the design of a dialogue system is also vital for improving user experience in human-computer interaction. More importantly, being empathetic is a necessary step for the dialogue agent to be perceived as a social character by users <ref type="bibr" target="#b8">[3]</ref>. Building an empathetic dialogue system is then premised on the idea that it will result in improved user engagement and, consequently, more effective communication.</p><p>Research on dialogue system has elaborated on the concept on dialogue system mainly from perspective of features. For example, Loojie et al. <ref type="bibr" target="#b9">[4]</ref> stated that an empathetic dialogue system should be complimentary, attentive, and compassionate. In this survey, we are particularly concerned with the unique dimension of dialogue systems from the perspective of functions. Namely, what function has enabled empathetic behavior of a dialogue system. To our knowledge, this has not been discussed in depth by previous literature.</p><p>Early attempts to build dialogue systems can be dated back to the 1960s <ref type="bibr" target="#b10">[5]</ref>.</p><p>Since then, dialogue systems are either designed to perform specific tasks such as flight booking <ref type="bibr" target="#b11">[6]</ref>, healthcare <ref type="bibr" target="#b12">[7]</ref>, political debate <ref type="bibr" target="#b13">[8]</ref>, hence termed "taskspecific dialogue systems", or to chitchat as a way of entertainment <ref type="bibr" target="#b14">[9]</ref>, hence called "chatbots". A task-specific dialogue system <ref type="bibr" target="#b15">[10,</ref><ref type="bibr" target="#b16">11]</ref> often consists of multiple modules including language understanding, dialogue state tracking, dialogue policy, and dialogue generation. On the other hand, recent progress in deep learning <ref type="bibr" target="#b17">[12]</ref> also facilitates the use of end-to-end solutions to dialogue systems which can be more easily trained to simulate the behavior of human communication via access to a large amount of training data. As we will discuss in later sections, the process of generating responses conditioned on the existing contexts of a dialogue can be naturally modeled as a translation process where off-the-shelf end-to-end solutions such as the sequence-to-sequence (Seq2Seq) model <ref type="bibr" target="#b18">[13]</ref> have already been proven effective.</p><p>The rapid growth of dialogue systems and their applications have intrigued many comprehensive surveys in the past decade. Chen et al. <ref type="bibr" target="#b19">[14]</ref> mainly organize their survey by elaborating on each functional component of a dialogue system. Gao et al. <ref type="bibr" target="#b20">[15]</ref> proposed the most recent review with good coverage of related topics, mainly focused on neural network-based approaches for building dialogue systems. Unlike <ref type="bibr" target="#b19">[14]</ref> and <ref type="bibr" target="#b20">[15]</ref>, we position our perspective on dialogue systems with empathetic features. Related work <ref type="bibr" target="#b21">[16]</ref> viewed empathy to be equivalent to emotion. We argue that empathy is not all about emotions. Indeed, a non-empathetic dialogue system may disappoint and bore the user for that the responses are too robotic yet incoherent, and consequently leads to the loss of affection.</p><p>Introducing emotion into the generation of dialogue could only partially address the problem. As illustrated by Fig. <ref type="figure" target="#fig_0">1</ref>, a more comprehensive empathetic framework also has to access general knowledge as well as personalized knowledge. Personalization, in such a case, could increase the coherence and consistency of a dialogue system. With knowledge of user-specific information, the dialogue system could tailor responses towards the user's preference and address questions relevant to the user's untold background, and a virtuous cycle comes into form when the user tends to provide more information and clue about themselves. Moreover, external knowledge, being it task-specific or commonsense, usually complements the contexts of a conversation with additional background. Many facts that are obvious to human beings may be very opaque to a machine, for example: "I come to my friend's house. Jimmy is my friend" will be understood as it is when it comes to vanilla dialogue systems. It will not conclude that "my friend's house" means "Jimmy's house" unless we construct a relationship between them. This is where the knowledge part comes into play: it helps dialogue systems become smarter, sharper, and more interesting.</p><p>Although it seems prevalent to incorporate knowledge into dialogue systems, reasoning, retrieving and representing a large scale knowledge base remain challenging. All three components (i.e., emotion, personalization, and knowledge) work together to ensure a smooth and natural flow of the conversation. Considering such complexity of empathetic systems, we take a perspective that goes beyond the merely emotional definition of empathetic dialogue systems by identifying three pillars. Such pillars accordingly represent the three main sub-topics presented in this survey:</p><p>• perceiving and expressing emotion (Section 3 -Affective Dialogue Systems)</p><p>• caring each individual (Section 4 -Personalized Dialogue Systems), and</p><p>• casting into knowledge (Section 5 -Knowledgeable Dialogue Systems).</p><p>In addition to previous surveys <ref type="bibr" target="#b19">[14]</ref>, we also cover the most recent advances in the area of empathetic dialogue systems. Especially, we would like to emphasize the end-to-end model more than traditional pipeline models as we believe the former represents the current trend of this field. To the best of our knowledge, we are the first to survey the empathetic features of a dialogue system. Overall, we primarily surveyed 35 papers selected from those published on prestigious venues in the past 10 years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Propaedeutic Background</head><p>A dialogue system is not a system built on top of one model. Instead, it is built on integrating multiple techniques due to the complexity of language and tasks. In this section, we present a technical introduction to recent techniques that serve as the backbone of an empathetic dialogue system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Neural Language Model</head><p>The language model generally defines a probability distribution over the sequence of words and thus plays an important part in a dialogue system. Tradition methods include N-gram models is based on statistics. Most recently, language models based on neural networks have achieved state-of-the-art performance in a variety of tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Recurrent Neural Network</head><p>Perhaps, one of the most well-known language models is the recurrent neural network (RNN) language model <ref type="bibr" target="#b22">[17]</ref> (Fig. <ref type="figure" target="#fig_2">2</ref>). As a notable feature of RNN, the history (or contexts) of a word sequence is encoded into a hidden layer via an input transformation and a recurrent connection. Each word in a sentence is first mapped to the word embedding space and then updates the history vector.</p><p>The history vector is then linearly transformed and normalized to represent a probability distribution of ejecting the next word. In theory, the greatest elegance of RNN is that it could encode contexts of arbitrary length. At each time-step t, RNN transforms the input vector and history vector as below:</p><formula xml:id="formula_0">H t = σ(W h * y t + W * H t-1 ) P (y t+1 ) = sof tmax(W o * H t )</formula><p>with h t being the hidden layer at time-step t, W is the fixed for different timesteps, y t is the word vector of current (input) word, and y t+1 represents the word vector of next (output) word. However, the linear transformation applied on the history vector is multiplied over time which leads to the gradient to vanish or explode when the sequence is long.  To overcome this problem, RNN variants such as gated recurrent unit (GRU) <ref type="bibr" target="#b23">[18]</ref> and long short-term memory (LSTM) <ref type="bibr" target="#b24">[19]</ref> have been proposed. A gating function is usually implemented as a sigmoid function that restricts the scale of gradients so that it would explode after multiple time steps. In LSTM, there are three gates: input gate, forget gate and output gate. At each time-step t, a LSTM cell transforms the input and memory cell as follows:</p><formula xml:id="formula_1">i t = σ(U i * y t + h t-1 * W i ) f t = σ(U f * y t + h t-1 * W f ) o t = σ(U o * y t + h t-1 * W o ) c t = σ(U c * y t + h t-1 * W c ) h t = o t * tanh(c t ) c t = f t * c t-1 + i t * c t</formula><p>where W i , W f , W o , W c are the linear transformation for hidden input, hidden forget gate, hidden output and hidden candidate gate, respectively. Similarly, U i , U f , U o , U c are the weight vectors for input gate, forget gate, output gate and candidate gate. y t is the input vector, h t is the current cell output, and c t is the current cell memory. Similarly, h t-1 is the previous cell output, and c t-1 is the previous cell memory. The forget gate may choose to forget certain content of the memory cell and input gate control how information flows from current input to the memory cell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural Language Understanding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State Tracker</head><p>Dialogue Policy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response Generation</head><p>Dialogue Management Encoder Decoder Figure <ref type="figure">3</ref>: A unified view of the architecture of a dialogue system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Sequence-to-Sequence Model</head><p>The generation of responses is conditioned on a given context. The probability distribution of generating a response can be seen as a conditional language model. Before going further into the details of language model, we would like to discuss the similarity and distinction between well-known encoder-decoder perspective of the dialogue system and the traditional modularized framework.</p><p>Fig. <ref type="figure">3</ref> shows an unified view of the system's architecture. A modularized system usually have four parts: an natural language understanding (NLU) module that extracts structural information from the input; a dialogue state tracker (DST) that infers the dialogue states; a dialogue policy (DP) module that decides actions to be taken by the system; and a response generator to generate responses based on the output of all the precedent modules. The DST and DP together might be also referred to as the dialogue management module. From an encoder-decoder perspective, the system is consisting of an encoder and decoder where the encoder plays an equivalent role as the combination of NLU, DST and DP. </p><formula xml:id="formula_2">h t = φ(x t , h t-1</formula><p>). The decoder then generates a sequence of hidden outputs </p><formula xml:id="formula_3">C = c 1 , c</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Attention Mechanism</head><p>The most straightforward way to represent a context of dialogue in a Seq2Seq model is to pass the last hidden output of the encoder to the decoder either by concatenating with the input embedding or by using it as the initial hidden state of the decoder. However, the last hidden output h N might be insufficient to encode information of the whole input sequence, especially when the length of the input sequence is long. Despite that gating function might help ease the problem, the recent study has suggested that the maximum number of words encoded by a LSTM network is still very limited. On the other hand, the emission of a word in the response may depend on a relevant excerpt of the context.</p><p>One of the most effective solutions is to have an 'alignment' model <ref type="bibr" target="#b25">[20]</ref> that allows the decoder to access a 'most relevant' position of the context. This can be achieved by computing a probability distribution over the encoder outputs denoting the probability of paying attention to one particular position, which is called attention mechanism. Both the soft version and stochastic version is possible to be used.</p><p>As shown in Fig. <ref type="figure" target="#fig_4">5</ref>, at each time step t of decoding, the attention weight on the jth input word is computed as</p><formula xml:id="formula_4">α tj = exp(g(h j , o t-1 )) k exp(g(h k , o t-1 ))</formula><p>Note that alpha is normalized over the input sequence so that it sums up to one. Therefore, it could also be interpreted as a distribution over the positions of the input sequence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Memory Networks</head><p>One of the more general views of the hidden space of an RNN is that it is a memory to be updated over time. However, as we have pointed out, such memory might be too small and desegregate to store the necessary contents <ref type="bibr" target="#b26">[21,</ref><ref type="bibr" target="#b27">22]</ref> and thus may fail in application areas such as dialogue where a long term memory is required to understand the context. To address this problem, Weston et al. <ref type="bibr" target="#b27">[22]</ref> proposed an architecture called memory network (MMN) which utilizes external memory slots and can be updated or read via writing a reading pointers.</p><p>As shown in Fig. <ref type="figure" target="#fig_5">6</ref>, the input sequence is encoded and passed to the generalization module of MMN which controls the update (write and read) of memory slots. There is another read action performed by the decoding process which decides what content of memory to be loaded to predict the next word. The reading and writing actions can be simply implemented as an attention mechanism over the memory slots. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Variation Autoencoder</head><p>As shown in Fig. <ref type="figure" target="#fig_6">7</ref>, variational autoencoder (VAE) <ref type="bibr" target="#b28">[23]</ref> defines a conditional probability distribution P (z z z|X) which can be used for drawing a vector of latent codes z z z to represent the internal state of the dialogue context. One popular choice for P (z z z|X) is normal distribution N (µ, Σ), where µ and Σ are the mean vector and covariance matrix, respectively. It is notable that presuming the forms of P (z z z|X) might be unreasonable, and it is also unnecessary. An auxiliary variable ẑ ẑ ẑ can be drawn from a simple standard normal distribution N (0, I), and an distribution of z z z of any form can then be obtained by a transformation function, f (ẑ). Moreover, all the parameters of f (•) can be learned in back-propagation. Note that normal distribution is continuous and not a natural choice for discrete variables. It works when the input data X is, for example, speech or image, while having difficulty in handling discrete data such as natural language. Most recently, related work has employed a re-parameterization technique called Gumbel-softmax <ref type="bibr" target="#b29">[24]</ref> to allow back-propagation on the nondifferentiable sampling processing of categorical distribution.</p><p>Besides the encoding process, VAE typically also comes with a generator.</p><p>As it suggests, the generator aims at reconstructing the input X given the latent code z z z. This autoencoding process enforces the sampling of z z z to encode information sufficient to produce X. The entire framework is trained by the Evidence Lower Bound Optimization (ELBO) on data log-likelihood, E z z z∼q(z z z|X) [log p(X|z z z)] -KL(q(z z z|X)||p(z z z)).</p><p>Maximizing the above evidence lower bound is equivalent to maximizing the log-likelihood of generating X given the latent code z z z while, at the same time, minimizing the KL divergence between q(z z z|X) and the prior distribution p(z z z).</p><p>In the problem setting of building a dialogue system, what we need is a model that can take as input the dialogue history (including previous turns within a conversation) and generates a proper response. As such, VAE has to be extended to conditional variational autoencoder (CVAE) <ref type="bibr" target="#b30">[25]</ref>, which models the conditional probability distribution P (Y |X) with X being the input and Y being the output response. The evidence lower bound of VAE can be rewritten as</p><formula xml:id="formula_5">E z z z∼q(z z z|X,Y ) [log p(Y |z z z, X)] -KL(q(z z z|X, Y )||p(z z z|X)).</formula><p>During training, the recognition model q(z z z|X, Y ) of CVAE is trained to approach the prior model p(z z z|X), while during testing, the generated response Y is not available as input, so the latent code outputted by the prior model will be passed to the generator. Let us take a close look at the objective function of ELBO, it should be noted that the maximization of log-likelihood is usually implemented by factoring log p(Y |z, X) into an element-wise form i log p(y i |z, X). It, of course, suffers from the problem that the element-wise loss fails to have a holistic view of the generation error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Generative Adversarial Network</head><p>As illustrated in Fig. <ref type="figure" target="#fig_7">8</ref>, the architecture of a generative adversarial network (GAN) <ref type="bibr" target="#b31">[26]</ref> is composed of a generator G and a discriminator D. It has achieved great success in multiple tasks ranging from image generation to transfer learning. The whole architecture is optimized based on a min-max game where the generator (G) is trained to fool the discriminator (D) by maximizing the classification error while D is trained to minimize the classification errors, defined as min</p><formula xml:id="formula_6">θG max θD E X∼p(X) [log D(X|θ D )] + E z∼p(z) [log(1 -D(G(z|θ G )|θ D )</formula><p>The generator G defines a generation function G(z, θ G ) parameterized by θ G .</p><p>G draws samples from a probability distribution p g based on a noise z. In the Intuitively, the generator receives feedback from the discriminator on how well the generated sample can confuse the discriminator.</p><p>On the one hand, the discriminator of GAN takes as input the generated sentence as a whole and measures its closeness to responses generated by human beings. On the other hand, the GAN framework is equivalent to optimizing the Jensen-Shannon divergence of which the global optimality of G if achieved when p g = p data <ref type="bibr" target="#b31">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Reinforcement Learning</head><p>Dialogue generation models based on Seq2Seq and its extensions (e.g., VAE)</p><p>have faced one fundamental issue on the learning objective. Commonly used objective functions including likelihood and ELBO do not have a clear link with the realistic goal of a dialogue system. A direct result is that the model trained using such objective functions are usually those frequently seen in the training data <ref type="bibr" target="#b32">[27]</ref>. For example, "i'm not sure" may be a response with high likelihood but is not a good response in the sense that it would not engage the user in further talking. Besides the dialogue generation model, the inherent states of user might also be introduced to dialogue management module of some systems <ref type="bibr" target="#b33">[28,</ref><ref type="bibr" target="#b34">29]</ref> which defines dialogue actions to be taken by the system.</p><p>Reinforcement learning, which has emerged as a powerful tool for both flexible reward function into the learning process and effectively modeling the transition of actions, has achieved enormous success in a variety of fields including dialogue system <ref type="bibr" target="#b35">[30,</ref><ref type="bibr" target="#b32">27]</ref>. For dialogue systems, reinforcement learning defines an 'environment' in which the dialogue agent can explore and receive feedbacks interactively. Since the key element of a dialogue is interaction, reinforcement learning could facilitate the use of ideal interactive patterns as rewards in learning the actions to be taken by the dialogue agent. A dialogue agent is supposed to take a "dialogue action" at each time step which results in a new state. The outcome of changing to a new state is measured by a reward function and is given to the agent as feedback from the environment. The objective is then selecting actions that could maximize the cumulative future rewards. In the context of building a dialogue system, a dialogue action a is usually generating a responsive utterance. In such sense, the action space is infinite for that the generated utterance is of arbitrary length and word choices. The state s can be any feature representation of the current conversation. For example, the dialogue state can be represented as the previous dialogue turns or previously extracted entities or slot values. When the action-to-take is concerned, a policy may be implemented as a probability distribution of taking an action a t given the current state s t , i.e., p(a t |s t ). In order to learn a proper action model, a variety of rewards have been explored in the literature for guiding the generation of meaningful and coherent responses, which we will cover in more detail in later sections.</p><p>However, one thing to note is that the action of generating an utterance is usually decomposed to a sequence of micro-actions that generate one word at a time. It is reasonable to assume that the environment is mostly not able to provide timely feedback to the generation of each word or even each utterance.</p><p>For example, in a conversation about flight booking, the agent will only receive the reward after the whole conversation is completed. In such a case, a delayed reward function might be used to update the action model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Affective Dialogue System</head><p>Emotion plays an important role in cognition and social behavior <ref type="bibr" target="#b36">[31]</ref>. Existing study suggest that emotion is a reaction and a social and cultural interaction that is continuously developing by the relationships between human and the surrounding environment <ref type="bibr" target="#b37">[32]</ref>. Yet, the definition and categorization of emotions remain fuzzy and long-debated among psychologists and philosophers <ref type="bibr" target="#b38">[33]</ref>. In the scope of this paper, we focus on the representation of emotion in dialogue system (or human-computer interaction) and its effectiveness, not emotion in terms of affective science or social sciences in general <ref type="bibr" target="#b39">[34]</ref>.</p><p>Moreover, emotion is argued to have more social functions such as eliciting people's particular response <ref type="bibr" target="#b40">[35]</ref>, coercing actions or recruiting social support <ref type="bibr" target="#b36">[31]</ref>. Most importantly, existing study suggests that emotion might be a related measure of decision making <ref type="bibr" target="#b41">[36]</ref>. These theories support that incorporating emotions is advantageous to dialogue system by allowing the dialogue system to emulate the conversational behavior of human beings and, at the same time, to strengthen the emotional connection with human users <ref type="bibr" target="#b42">[37]</ref>. Emotion might also increase the user's engagement in the conversation <ref type="bibr" target="#b43">[38,</ref><ref type="bibr" target="#b44">39]</ref>. On the other hand, it has been argued that emotion might introduce unpredictability into the system. Therefore, it has be to be placed in control with careful system design <ref type="bibr" target="#b45">[40]</ref>. In this survey, we intend to follow the literature by referring to such a dialogue system, which is capable of perceiving, understanding, expressing and regulating emotion, as an affective dialogue system <ref type="bibr" target="#b34">[29]</ref>. We then further define two groups of core features of an affective dialogue system. The first type of features, called emotion-awareness, is concerned with the representation of emotion expressed in the context of the conversation. Namely, the dialogue system should be able to detect the user's current emotional states given the conversation. The second type of features, called emotion-expressiveness, are mainly concerned with incorporating emotional information into generated responses.</p><p>In fact, early studies have attempted to do so, either by handling users' emotions <ref type="bibr" target="#b46">[41,</ref><ref type="bibr" target="#b47">42]</ref> or infusing emotional-rich features into the virtual agents <ref type="bibr" target="#b48">[43,</ref><ref type="bibr" target="#b49">44]</ref>. For example, being aware of the emotion in the contexts may implicitly result in generating emotion-expressive responses. The general framework of encoder-decoder can be extended to account for these two sets of features.</p><p>Table <ref type="table" target="#tab_1">1</ref> summarizes dialogue systems having at least one aforementioned affective features. It shows that most of the work being reviewed are taskindependent and have used various representations of emotions. We have also summarized datasets (see Table . 2) used in the references with short descriptions and URL links. These datasets fall into three categories: 1) user-generated conversations (e.g., tweets); 2) crowd-sourcing annotation; 3) simulated data.</p><p>Moreover, we illustrate typical architectures of vanilla encoder-decoder, emotionaware encoder, and emotion-expressive decoder in Fig. <ref type="figure" target="#fig_9">9</ref> to facilitate a more straightforward comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Emotion Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Studies of representing emotion date back to the 19th century, when Charles</head><p>Darwin proposed his theory of the origin of species. To date, many emotion categorization models have been proposed in the literature <ref type="bibr" target="#b69">[64]</ref>. One of the latest is the Hourglass of Emotions <ref type="bibr" target="#b70">[65]</ref>, a biologically-inspired and psychologicallymotivated emotion categorization model for sentiment analysis (Fig. <ref type="figure" target="#fig_10">10</ref>). One   of the peculiarities of this model is that it describes emotions both in a discrete and in a dimensional form, allowing for the prediction of both categories and intensities of emotions and sentiments <ref type="bibr" target="#b71">[66]</ref>.</p><p>In general, most computational models of emotion only fall into one of these three representation categories: the dimensional approach, the discrete approach, and the appraisal approach <ref type="bibr" target="#b8">[3]</ref>. In the dimensional approach, emotions are represented as vectors denoting arousal and valence <ref type="bibr" target="#b72">[67]</ref>. The advantage of having a dimensional space is that it allows for measuring the similarity between different emotions <ref type="bibr" target="#b73">[68,</ref><ref type="bibr" target="#b8">3]</ref> used a more fine-grained 32-class system while Zhou et al. <ref type="bibr" target="#b50">[45]</ref> uses 64 emojis.</p><p>The appraisal approach, finally, studies the links between emotions and elicited cognitive reactions <ref type="bibr" target="#b74">[69]</ref>.</p><p>Another type of emotion representation is distributional, i.e., using embedding to represent an emotion. The advantage of this representation is that emotion types become continuous while interpolation becomes possible. Also, the representation can be directly used as an input into deep learning models.</p><p>Multimodal emotion information concatenation <ref type="bibr" target="#b55">[50]</ref> also falls into this category.</p><p>The last type of emotion is pragmatic, such as politeness and satisfaction.</p><p>With the emotion representation defined, the task of emotion or sentiment analysis is to predict the emotion/sentiment given the sentence or contexts.</p><p>Namely, given the current utterance x i , the analyzer predicts the emotion label e i . The objective can be generally defined to learn the conditional probability distribution P (e i |x i ). By default, the emotion/sentiment is an attribute attached to the sentence or utterance as a whole which might be seen as an known as aspect-based analysis <ref type="bibr" target="#b75">[70,</ref><ref type="bibr" target="#b76">71,</ref><ref type="bibr" target="#b77">72]</ref>. For example, "the food is tasty but quite pricey" has expressed a completely opposite sentiment towards #FOOD-QUALITY# and #PRICE#. The objective of an aspect-based emotion analyzer is to learn to predict the emotion labels given both the aspect and sentence using P (e i |a i,t , x i ), where a i,t denotes the t-th attribute of the current utterance.</p><p>In the context of dialogue systems, the task setting may differ from the sentence-alone task. It can be mathematically defined as to predict the emotion label e i given a sequence of &lt; x i , s i &gt; pairs, where &lt; x i , s i &gt; represents an utterance and a speaker. Note that, sometimes, the prediction is online so that only dialogue history up to the current time step is visible.</p><p>The challenges of analyzing emotions in dialogues extend to several aspects. First of all, the emotion might be expressed in an obscure way, which requires reasoning over contextual information and calls for effective context modeling.</p><p>Secondly, emotions expressed in dialogues might be highly dependent on the in-herent and contextual emotional states of both the speaker itself and other parties (inter-personal dependencies). Finally, efficiently blending different modalities, e.g., text, audio, and video, may be required for the continuous interpretation of emotions in a conversation <ref type="bibr" target="#b78">[73]</ref> (Fig. <ref type="figure" target="#fig_11">11</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Emotion-aware Encoders</head><p>Emotion-aware encoders differ from general encoders for that the resulting context vector also encodes emotion-related information. As shown in Fig. <ref type="figure" target="#fig_9">9a</ref>, there exist three different ways of achieving emotion-awareness depending on whether an emotion label is available or not. If emotion label of context or user input is available, emotion-awareness can be easily achieved by feeding emotion labels as additional features to the encoder <ref type="bibr" target="#b50">[45,</ref><ref type="bibr" target="#b57">52,</ref><ref type="bibr" target="#b55">50]</ref>. In a more modularized framework, the emotion-aware encoder might also be viewed containing a dialogue management module where the dialogue actions based on emotional states as well as other internal states of a user is modeled as partial observable Markov decision process (POMDP) <ref type="bibr" target="#b33">[28,</ref><ref type="bibr" target="#b34">29,</ref><ref type="bibr" target="#b79">74]</ref>.</p><p>On the other hand, it makes sense that emotion labels might be absent from the testing phase. For example, some users do not use explicit emotion markers such as emoji in their inputs. One solution is to have an additional emotion detector that can infer the implicit emotion labels. For example, an additional emotion detector (i.e., emotion classifier) could be employed to recognize the emotion labels <ref type="bibr" target="#b51">[46,</ref><ref type="bibr" target="#b59">54,</ref><ref type="bibr" target="#b80">75,</ref><ref type="bibr" target="#b14">9,</ref><ref type="bibr" target="#b81">76]</ref>. The emotion detector can be trained on either the dialogue training set or supplementary data sets depending on the availability of emotion annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Emotion-expressive Decoder</head><p>Emotion-expressiveness aims at enforcing the generation of emotional responses. As shown in Fig. <ref type="figure" target="#fig_9">9b</ref>, it is typically achieved via emotion-specific training of the decoder or directly uses emotion as a controllable variable. We thus refer to such decoders as emotion-expressive decoders. Recent studies have mainly relied on techniques such as CVAE, GAN and reinforcement learning. The underlying assumption of a controllable emotion variable to the decoder is that there exist a single or multiple latent variables dominating the generation of responses. Some existing work refers to this set of latent variables as latent dialogue states <ref type="bibr" target="#b82">[77]</ref>. One natural choice of architecture for modeling the latent dialogue states are CVAEs. Hu et al. <ref type="bibr" target="#b83">[78]</ref> proposed that part of the latent dialogue states can be set to controllable variables such as sentiment. In doing so, the encoder is enforced to encode disentangled latent codes and can be seen as a classifier at the same time. On the other hand, the generation of responses is also controlled as these latent codes are feeding to the decoder as inputs.</p><p>One problem with CVAE is that it is usually designed to optimize an elementwise loss (i.e., assuming independence of words in the responses). A remedy to such a problem is using GAN framework that converts the learning to a minmax game which additionally optimizes a classification loss based on the overall structure of generated responses. Kong et al. <ref type="bibr" target="#b62">[57]</ref> regulated the emotion in generated responses using a discriminator that tells if the response is generated by human beings or the generator providing the emotion label. When maximizing the classification error, the generator is trained to approximate the humangenerated responses a simultaneously improves the compatibility of generated response and emotion label.</p><p>Although the GAN framework provides an alternative to the element-wise loss, the emotion is used only as an input rather than a learning objective. Yet, a more straightforward way of including emotion is to train the whole framework with emotion-enforced loss or rewards. Namely, design rewards that encourage generating the response with correct emotion, and set penalty for responses with no emotion expressed. However, such intuitive loss may not be differentiable and thus hard to be optimized by the back-propagation. It is then natural to adopt reinforcement learning due to its flexibility in incorporating non-differentiable rewards. More importantly, reinforcement learning allows the framework to learn continuously from user's feedback even after deployment. User's sentiment in such a case might serve as immediate rewards to the system <ref type="bibr" target="#b55">[50,</ref><ref type="bibr" target="#b50">45,</ref><ref type="bibr" target="#b54">49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Discussion</head><p>As mentioned earlier, existing work on affective dialogue systems has mainly focused on either emotion awareness or emotion expressiveness. There are two practical challenges for achieving these two functions:</p><p>• Shortage of emotion labels. It arises from the recognition of the emotional states of users. As mentioned in many research work <ref type="bibr" target="#b50">[45,</ref><ref type="bibr" target="#b55">50,</ref><ref type="bibr" target="#b59">54]</ref>, one of the practical challenges in achieving emotion awareness is the lack of human annotation due to the time-consuming annotation process of dialogues. It can be relieved by leveraging weak supervisions instead of ground-truth emotion labels. For example, one could use emotion labels generated by a pre-trained sentiment classifier <ref type="bibr" target="#b14">[9]</ref>. Alternatively, multiple data sources could be combined and refined to increase the scale.</p><p>• Evaluation of emotion. It is hard to evaluate the user's emotional states as there is sometimes no subtle emotion cue at word level <ref type="bibr" target="#b59">[54]</ref> and might exist gaps between the "intrinsic" emotional state of a user, and the one being expressed, and the one being perceived <ref type="bibr" target="#b84">[79]</ref>. One solution is to control the process of data collection to guide the user to have desired emotional states and model the "gap" as a noise in data collection.</p><p>• • Dependency between the controllable variable and generated words is modeled in the utterance (or turn) level. Not all words should be affected by emotion. For example, function words are mostly only affected by syntax while topical words are dominated by topics. In such a case, the interaction between emotion variables and the generator should be reformulated to enhance the impacts on the word or phrase level <ref type="bibr" target="#b54">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Personalized Dialogue System</head><p>The communication between a dialogue system and a human is generally desired to be adaptive to the variance in personal preferences to increase communication effectiveness <ref type="bibr" target="#b103">[97,</ref><ref type="bibr" target="#b104">98]</ref> based on appropriate perception of the speaker's personality of the speaker. On the other hand, personality affects the way of communication in various manners including both linguistic style <ref type="bibr" target="#b105">[99]</ref> and acoustic traits <ref type="bibr" target="#b106">[100]</ref>. As it feels more natural to interact with a 'thing' that has its own personality, implanting personality into dialogue agents would possibly increase the social attachment <ref type="bibr" target="#b107">[101,</ref><ref type="bibr" target="#b108">102]</ref>.</p><p>For example, a dialogue system designed to recommend items to a user should have a user preference model so that the recommendation could match the particular user might want to purchase. In this section, we select papers that focus on incorporating personal information into the dialogue system. These papers are sorted out among a wide range of top venues, considering mainly the novelty and impact. We have summarized the list of paper and data set in Table <ref type="table" target="#tab_5">3</ref> and Table <ref type="table" target="#tab_6">4</ref>.</p><p>In short, personalized information of a speaker is the key to precisely perceiving the speaker's intention and inherent states and consequently generate appropriate responses <ref type="bibr" target="#b109">[103]</ref>. Efforts have been made towards incorporating personalized features. As shown in Fig. <ref type="figure" target="#fig_14">13</ref>, we define the personalized dialogue system (PDS) as a virtual agent having the access to user-specific information without which it might be impossible to generate a proper response adapted to the user's implicit needs. For example, the dialogue agent may respond differently according to the user age group (i.e., old people versus young people) <ref type="bibr" target="#b91">[85]</ref>, personality (introverts versus extroverts) <ref type="bibr" target="#b110">[104]</ref>, or gender (woman versus man) <ref type="bibr" target="#b95">[89]</ref> that are mostly not part of a visible context.   A typical workflow of PDS reads the current input as well as dialogue history while using an explicit user model to enforce personalized generation of responses. We identify two major components that distinguish a PDS from standard dialogue systems: 1) user modeling and 2) personalized response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">User Modeling</head><p>How to represent personality has been the primary concern of many personality theories <ref type="bibr" target="#b110">[104]</ref>. Early works have used lexical approaches to describe personality with words or taxonomies <ref type="bibr" target="#b112">[106]</ref>, which eventually evolved into the well know theory of five-factor model of personality <ref type="bibr" target="#b113">[107]</ref>. In addition to the diversity of representation, it is yet challenging to draw a clear picture of the role that personality plays in conversation when considering the gap between "felt" and "perceived" and that between "intentional" and "instinctual" <ref type="bibr" target="#b84">[79]</ref>.</p><p>Existing work have been mostly using oversimplification of personality inspired by different personality theories (as shown in Fig. <ref type="figure" target="#fig_13">12</ref>). For example, one may use static features <ref type="bibr" target="#b65">[60]</ref> of a speaker, e.g., age group, or narrative facts <ref type="bibr" target="#b89">[83]</ref> like "She likes coffee" or triples, (Lily, speak, F rench) <ref type="bibr" target="#b86">[81]</ref>. Based on the classification of personality traits and how it is stored or utilized, we classify the user modeling method into two categories: identity-based and knowledge-based. There are also hybrid systems adopting more than one method of user representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Identity-based User Modeling</head><p>User modeling is constrained by the form of personal information accessible by the dialogue system. Amongst all types of personal information, the simplest form is the user's identity. Attached to the identity are the static attributes that describe the basic characteristics of the user. The simplicity of these static attributes usually allows low memory consumption so that the indexing and matching process can be very fast. On the other hand, identity-based features are reliable and can be used directly without the need for additional steps of information extraction.</p><p>Perhaps, one of the most common sources of identity-based features is the meta-data collected upon registration. Such data collection can not be very comprehensive and, sometimes too coarse-grained which constrains the applicability in various settings. For example, it is fair to state that gender information could help with recommending friends to a user.</p><p>As aforementioned, persona facts and identity features may join forces to personalize the response generation <ref type="bibr" target="#b91">[85,</ref><ref type="bibr" target="#b99">93,</ref><ref type="bibr" target="#b92">86,</ref><ref type="bibr" target="#b94">88]</ref>, thus makes use of both strengths from unstructured (more context-oriented) and structured data (persona-oriented).</p><p>For example, in restaurant booking, the identity-based features may provide information such as gender, age, or especially favorite food item <ref type="bibr" target="#b91">[85,</ref><ref type="bibr" target="#b99">93]</ref> that is complementary to the description of a user's hobby, which not only helps the system to suggest a suitable restaurant but also facilitates choices of words and speech style.</p><p>On the other hand, a range of features have been explored for identitybased user modeling. Notably, to utilize the identity-based features in neural nets, embedding layers are usually employed to map the discrete or continuous features to a dense vector. The vector can simply result from mapping the identities (i.e., user ID) or combined with attribute embeddings <ref type="bibr" target="#b100">[94,</ref><ref type="bibr" target="#b93">87,</ref><ref type="bibr" target="#b95">89]</ref>. For example, the speaker embedding of <ref type="bibr" target="#b100">[94]</ref> has a dialect, register, age, gender which are encoded using LSTM. <ref type="bibr" target="#b93">[87]</ref> had agent profile with key-value pairs &lt; k i , v i &gt;, in which were are attributes such as name, age, gender, hobby, specialty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Knowledge-based User Modeling</head><p>Knowledge-based user modeling uses structured data and predefined rules to match the existing user's information then produce a response. The knowledgebased user modeling is highly correlated with the knowledge-based dialogue system that will be discussed later. In short, a PDS with knowledge-based user modeling can be seen as an instance of a knowledge-based system where the knowledge being used is regarding the user.</p><p>As compared with the identity-based user modeling, knowledge-based user modeling is not limited to the meta-data of users. Instead, it could utilize both structured or unstructured information data sources. For example, triples representing the user habits or preferences could be extracted from the user's dialogue history <ref type="bibr" target="#b86">[81]</ref>. Sordoni et al. <ref type="bibr" target="#b87">[82]</ref> used the bag-of-words (BoW) embeddings of past dialogues of the same user as additional context, which is one of the first attempts to use prior knowledge (dialogue's history from the user) to curate responses. Similarly, Al-Rfou et al. <ref type="bibr" target="#b90">[84]</ref> used dialogue histories (context), response, input message, and author (user) as personalization features;</p><p>then defining user embeddings and the bag of n-gram embeddings to keep track of sentence structures and word order:</p><formula xml:id="formula_7">ψ(M 1 , ..., M n ) = 1 N 1≤i≤n w∈ngrams(Mi) φ ngram (w)</formula><p>where N is the total number of n-grams from all the messages {M 1 , ..., M n }.</p><p>Implementation and data source aside, we think conversation history serves as an anchor to the context which the dialogue system is trying to focus on, and that is the reason why it has been so widely utilized; especially in taskindependent dialogue systems where there is no clear goal to achieve but a more specific and meaningful conversation is desired. On the other hand, personality can also be characterized by a set of text description. For example, Mairesse et al. <ref type="bibr" target="#b104">[98]</ref> designed a set of questions for rating one's personality.</p><p>Personalization might also be a pre-requisite for many tasks. As shown in Fig. <ref type="figure" target="#fig_14">13</ref>, the dialogue system requires personal information to make the right recommendation. Personalized reasoning <ref type="bibr" target="#b91">[85]</ref> is a task that aims to retrieve the facts from a knowledge base that is related to a restaurant based on both attributes of the user and the restaurant itself. Conversation history was stored in the memory component <ref type="bibr" target="#b27">[22,</ref><ref type="bibr" target="#b99">93,</ref><ref type="bibr" target="#b86">81]</ref>. Similarly, Mo et al. <ref type="bibr" target="#b92">[86]</ref> also combined both fact-based features (user's utterances and agent's replies) and identitybased features (choices of coffee) for the online coffee shop's dialogue system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Personalized Response Generation</head><p>With the user modeling representing the personal information of a user, the next key step of a PDS is to generate (or retrieve) the personalized response. Previous works focused on two major approaches: generative methods, which generate appropriate responses during the conversation and retrievalbased methods (or ranking methods), which are capable of selecting suitable responses from a list of candidates or repository. However, the main goal of a PDS is to generate not only suitable but also engaging responses based on prior knowledge of the user. As for affective dialogue systems, we organize our discussion with two sub-topics based on how personalized information is integrated into the decoder (or generator): ( <ref type="formula" target="#formula_10">1</ref>) personality-aware model and</p><p>(2) personality-infused model to demonstrate the usefulness, capabilities, and limitations of each modeling type. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Personality-aware Model</head><p>A personality-aware model generates responses adapting to the personality of the user (or other parties of a conversation). In other words, the responses are composed of the awareness of the user's personalized preference. However, what differs significantly from the personality-infused model which will be discussed in the subsequent section is that it does not enforce a personality of the virtual agent itself.</p><p>With user modeling, the response can be simply retrieved from a candidate pool <ref type="bibr" target="#b86">[81]</ref>. Alternatively, the generator might be taught to generate the response word by word <ref type="bibr" target="#b87">[82]</ref> (as illustrated in Fig. <ref type="figure" target="#fig_17">15</ref>). For example, it can utilize Seq2Seq model that is both context-sensitive and data-driven. In addition to using input sentence, different context-sensitive information including context c, current message/sentence s t and response o might be used. Context c represents a sequence of past dialogue exchanges, then the receiver emits message s t to which the sender reacts by formulating its response, and the estimation of the generated response will be conditioned on past information c and s. Li et al. <ref type="bibr" target="#b100">[94]</ref> proposed (1) Speaker model (as illustrated in Fig. <ref type="figure" target="#fig_18">16</ref>) and ( <ref type="formula">2</ref>)</p><p>Speaker-Addressee model for personalization task. In (1), they put the Speakerlevel vector (which has identity-based features) into the target part of Seq2Seq model. Then they modeled similar words embedding to identify similar speaker embedding. ( <ref type="formula">2</ref>) is the Speaker-Addressee model, in which the authors did not only encode the speaker but the addressee as well. For example, if there are two pairs of speaker-addressee &lt; A, B &gt; and &lt; A , B &gt;, with speaker A is similar to A and B is similar to B ; so A and B will have a similar conversation and response as A and B, even if they never met before. This can be applied to a knowledge-based dialogue system, as we can now model knowledge like we model the speaker's profile. We can also do reverse mapping for a speaker in the larger set to condition on how it behaves back to the smaller set. One disadvantage is the speaker-addressee model is sensitive to the identity of the addressee, which will often generate sentences that have both the name and the identity of the original addressee.</p><p>User profile and conversational history might play a different role in the memory of speakers. Hence, it is reasonable to model them using separate structures. For example, Split Memory <ref type="bibr" target="#b91">[85]</ref> extends the original MMN by dividing the memory of the model into two: Profile attributes and Conversation history. The user's attributes are added as separated entries in the profile memory before the dialogue starts, and each dialogue turn is added to the memory.</p><p>The mechanism of selecting the best responses is the same as the original MMN.</p><p>The output from both memories are summed element-wise to get the final response. Similarly, Luo et al. <ref type="bibr" target="#b99">[93]</ref> gathered the conversations of similar speakers and maintained a global memory in addition to the profile embeddings. On the other hand, this solves the challenge of handling ambiguity among knowledgebased entities, such as the choice between "phone" and "social media", which takes the relation between a speaker profile and knowledge base into account. Likewise, Zhang et al. <ref type="bibr" target="#b65">[60]</ref> handle the history and profile by first performing attention over profiles memory in the first hop, then attention over dialogue histories in the next hops.</p><p>Most recently, Olabiyi et al. <ref type="bibr" target="#b98">[92]</ref> integrated speaker attributes with a hierarchical recurrent encoder-decoder network (HRED) <ref type="bibr" target="#b114">[108]</ref>. The output of the encoder is summarized via attention model and concatenated with the attribute embedding, thus allowing the generator to access the speaker's identity/attributes. The authors also employed the framework of GAN to enforce the awareness of personal information by the generator. Attribute-specific discriminators are used to distinguish responses generated with different user attributes. In doing so, the generator is capable of responding differently to input utterances.</p><p>In a large scale setting where numbers of users might present in the system, it can be quite difficult to have enough data for each type of user. It is possible to gather and transfer user knowledge generated in a particular domain or task setting to a new domain or task. Mo et al. <ref type="bibr" target="#b92">[86]</ref> proposed a transfer learning framework for an online coffee-delivery system to model the preferences of different speakers. Its goal is to extend a dialogue system to include a previously unseen concept and then adapt the existing dialogue management system to an extended one <ref type="bibr" target="#b115">[109]</ref>. The authors model the personalized Q-function as a general function plus a personal one which has the set of all possible choices of coffees and how it is done (latte, iced, macchiato, etc.), as well as the probability distribution of the speaker's orders. A personal reward point or "punishment" point will be given to the system which depends on the response from the speaker.</p><p>Yang et al. <ref type="bibr" target="#b94">[88]</ref> aim to incorporate personalization criteria. Their framework assumes a source domain D s and target domain D t . The model adaptation exploits user-specific information in the personalized dataset (target dataset D t )</p><p>to improve the performance of the personalized conversation system by firstly generating an intermediate response and then feed the middle response into the response agent to recover the input.</p><p>The main advantages of the transfer learning system include the ability to be trained in both semi-supervised and unsupervised adaptation settings by finetuning against different rewards, adequately leverage both paired and unpaired data in the target domain and the capability of exploring user-specific information. However, its disadvantages are large data requirements and need for extensive evaluation. In general, we can use a large collection of general training data as the source domain and the personalized data as a target domain and perform transfer learning from the source domain to the target domain.</p><p>Reinforcement learning can bypass the exposure bias and non-differentiable issues and maximize future reward in dialogue, thus generates better-personalized responses for different users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Personality-infused Agent Dialogue Systems</head><p>In addition to personality-aware dialogue systems, we have personality-infused agent dialogue systems. Instead of just conditioning on the user's profile or attributes alone, we can assign unique, distinctive personality or profile to an agent in order to make the conversation smoother, more flexible and natural.</p><p>Firstly, as illustrated in Fig. <ref type="figure" target="#fig_19">17</ref> The goal of ( <ref type="formula" target="#formula_10">1</ref>) is to select which profile value should be addressed in a generated response (if the user asks about a third-person, not the agent itself i.e.: "How is your sister?", then the agent will go ahead and generate response straight away). This component is a multi-class classifier that uses a multilayered perceptron (MLP) with the representation of the posts, the weight matrix, and key-values of the profiles. The optimal value is selected with the maximal probability.</p><p>Component ( <ref type="formula">2</ref>) is a decoder that aims to generate a response in which a profile value will be mentioned. It has a backward decoder and forward decoder but (3) will help to predict the start decoding position. On the other hand, component Most importantly, (3) has the ability to alter the training data. This system can provide a model that can generate responses that are coherent to a prespecified agent profile that does not require learning from dialogue data, and with (3) helps improving performance than a random position picking strategy.</p><p>Otherwise, it relies on profiles and requires manual labor works. In conclusion, this paper has the potential to develop more commonsense and better semantic reasoning and can auto-generate many combinations of profiles and improve a lot on a variety of responses.</p><p>Secondly, Zhang et al. <ref type="bibr" target="#b95">[89]</ref> solved the problem of incorporating specific personality traits into dialogue generation to deliver personalized dialogues. Its Personaldialogue dataset is also from Weibo, which is a multi-turn and each utterance is associated with a speaker who is annotated with traits. In this paper, the problem can be summarized as the following: Given a post X = x 1 , x 2 , ..., x n and a set of personality traits T = t 1 , t 2 , ..., t n , the system should give a response Y = y 1 , y 2 , ..., y n that embodies the personality traits in T . As mentioned before, each trait t i belongs to T is given as a key-value pair</p><formula xml:id="formula_9">t i =&lt; k i , v i &gt;.</formula><p>After having a persona representation, the authors proposed two methods:</p><p>( will result in the summary vector, which is also the persona representation where it captures both internal features and external features (contextual information, other characters' lines). Meanwhile, (2) incorporates description with skipthought vectors <ref type="bibr" target="#b116">[110]</ref> to initialize memory keys, and the values are learnable embeddings of trope categories. The final step is to calculate similarities between persona representation and keys.</p><p>In conclusion, this paper demonstrates that the use of a multilevel attention mechanism greatly outperforms a baseline GRU model, about the character trope classification task that serves as a testbed for learning and assigning personas from dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Knowledge-based Dialogue System</head><p>Generating a conversation is a process of searching and communicating with the knowledge that might come from multiple sources including the current dialogue, personal background, or even external knowledge sources such as a knowledge graph <ref type="bibr" target="#b117">[111]</ref>. The comprehension of dialogue thus requires access to the background knowledge which has created a gap between responses generated by human beings and those by data-driven dialogue agents <ref type="bibr" target="#b18">[13,</ref><ref type="bibr" target="#b53">48,</ref><ref type="bibr" target="#b23">18]</ref>. Fig. <ref type="figure" target="#fig_23">18</ref> shows an example in which the external knowledge plays an important role in inferring the appropriate word in response. It can be seen that without knowing "Universal studios" is at Sentosa and can be shortened as "USS", the generator is not able to infer such information from the given input. Therefore, given the need for modeling knowledge in dialogues, we refer to those dialogue systems with explicit access and modeling of external knowledge that are not visible in the current dialogue as a knowledge-based dialogue system.</p><p>Extending the basic architecture of encoder-decoder, a knowledge-based dialogue system typically has two additional components: 1) a knowledge encoder (see Section 5.1) encoding the knowledge into some sorts of representation and 2) a knowledge-aware decoder (see Section 5.2) generating responses conditioned on both the context and external knowledge. Based on a set of critical dimensions, we summarize all papers and datasets having been discussed in this section and related to incorporating into Table <ref type="table" target="#tab_8">5</ref> and Table <ref type="table">6</ref>.</p><p>It is hard to come up with a universal encoder because of the heterogeneous nature of knowledge. Instead, we classify knowledge encoders into two main categories based on if the knowledge to be encoded is structural or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Knowledge Encoding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Structured Knowledge</head><p>Structured knowledge plays an essential role in language understanding for their well-defined forms and simplicity in use. One of the criteria of a comprehensive and structured knowledge base is that it should be sufficiently general to account for a large number of concepts and their relations, and workable with real-world settings <ref type="bibr" target="#b134">[128]</ref>. Efforts on building a structured knowledge base can be dated back to the 1950s <ref type="bibr" target="#b135">[129]</ref> where the knowledge is represented in a set of rules expressing permissible transformation operations. Later, the structured  knowledge became the backbone of expert systems <ref type="bibr" target="#b136">[130]</ref> which is usually specific to a particular domain or task. However, the development and maintenance of these knowledge base systems are generally relying on human efforts and thus not scalable and hard to be generalized to other domains. Additionally, commonsense computing <ref type="bibr" target="#b137">[131]</ref> aims to develop large-scale commonsense knowledge bases, e.g., ConceptNet <ref type="bibr" target="#b138">[132]</ref> and SenticNet <ref type="bibr" target="#b139">[133]</ref>, that can be automatically built and updated over time.</p><p>Thanks to the rapid growth of large scale knowledge bases <ref type="bibr" target="#b140">[134]</ref>, structured knowledge is deemed as a main source for the dialogue agent to obtain relational information of different kinds of entities, e.g., named entities but also time expressions <ref type="bibr" target="#b141">[135]</ref>, which assists in understanding the semantics of language. In the light of recent progress in deep neural network, embedding-based knowledge encoder has adopted by existing frameworks. It can be represented as a set of relation triplets, i.e., {(e 1 , r, e 2 )}, where e 1 and e 2 are the two entities and r being the relation type. For example, ("Jimmy's House", Is A, "Friend's</p><p>Home") simply means that "Jimmy's house is my friend's home". Since entities and relations are all consisting of words, one of the most straightforward choices of an encoder is the BoW encoder <ref type="bibr" target="#b119">[113,</ref><ref type="bibr" target="#b121">115]</ref>. At first, each word of entities and relations is mapped to a dense vector via looking up in an embedding table. All the word vectors are then summed (or averaged) over to get a single vector for the triplet.</p><p>One problem with the BoW representation is that the structural information is lost to some extent. That said, it makes no difference whether a word appears in e 1 ,r, or e 2 . A more accurate encoder takes into consideration the word order by using a sequential model (e.g., an RNN) <ref type="bibr" target="#b142">[136]</ref> or separated parameters for the head, relation, and tail <ref type="bibr" target="#b126">[120]</ref>. Moreover, the triplet embedding considers only one triplet at a time and fails to account for the global structure of knowledge. Reddy et al. <ref type="bibr" target="#b125">[119]</ref> directly represent the data cell (containing multiple attributes and values) by a set of key-value pairs, while He et al. <ref type="bibr" target="#b118">[112]</ref> proposed a recursive graph embedding where information can propagate from neighbors to the entities of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Unstructured Knowledge</head><p>Perhaps, the biggest drawback of using structured knowledge in building dialogue systems is that the information required by the dialogue system may sometimes not be aligned with the structure of knowledge. Moreover, the process of structuring knowledge involves either human efforts or rule-based filters that are performed as a separate step which is typically not optimized together with the dialogue model. In comparison to structured knowledge, unstructured knowledge might be less constrained, available on a much larger scale, and contain richer information yet to be filtered. Since unstructured knowledge is usually in the form of plain texts, the suitable knowledge encoders for unstructured knowledge are mostly sequence encoders <ref type="bibr" target="#b102">[96,</ref><ref type="bibr" target="#b123">117]</ref> that were used to convert a sequence of words into a dense vector. Moreover, unstructured knowledge encoders can be trained end-to-end with the rest of the dialogue system to achieve optimal performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Knowledge-aware Decoding</head><p>Although some particular types of encoded knowledge (e.g., a count vector) might be simply passed to the decoder as additional input, it is still the biggest challenge of modeling in dialogue. This section will discuss how knowledge could be utilized to facilitate the generation of more informative and coherent responses. Generating responses typically involves two types of knowledge sources. The first one is from the history of dialogue, including utterances of previous turns as well as the user's input at the current dialogue turn. We refer to this knowledge source as the historical knowledge, while there is another source of knowledge to be embedded into the response, referred to as the predictive knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Knowledge Attention</head><p>The knowledge encoder converts the knowledge base into some representation. As seen from the previous section, the most popular representation is a form of dense vectors called knowledge embedding. Given the context and the set of knowledge embedding, it needs to read or retrieve the relevant knowledge that will be then used for conditioning the generation of a response.</p><p>The retrieval and searching process of knowledge can be done in a heuristic fashion, especially when the knowledge base is on a large scale. Lowe et al. <ref type="bibr" target="#b102">[96]</ref> retrieved unstructured texts using a combination of TD-IDF and hashing. One popular and probably more effective alternative dealing with a smaller (or refined) set of knowledge is to compute a weighted sum over the knowledge embedding. As we have discussed in the previous section on the attention model, the weights of subsets of knowledge bases (e.g., triples) can be obtained by computing an attention vector. As for the attention over a sequence of words, each encoded knowledge vector is passed to a MLP together with a query vector representing to current dialogue states. Zhou et al. <ref type="bibr" target="#b126">[120]</ref> proposed to learn hierarchical attention where the first layer is over the knowledge graphs while it has second layer attention over the triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Copy</head><p>Two extensions of attention mechanism playing an essential role in endto-end dialogue generation are pointer network <ref type="bibr" target="#b143">[137]</ref> and CopyNet <ref type="bibr" target="#b144">[138]</ref>. The main idea is to use the attention as pointers to select and copy words from the input. It was first proven by Eric et al. <ref type="bibr" target="#b145">[139]</ref> that augmenting the standard Seq2Seq framework with the copy mechanism could outperform retrieve-based methods. Later, Eric et al. <ref type="bibr" target="#b128">[122]</ref> propose adding to the vocabulary distribution a copy distribution over knowledge base entries. In other words, a word can be generated by either emitting from the distribution over a fixed vocabulary or by copying a word from the knowledge base. Madotto et al. <ref type="bibr" target="#b119">[113]</ref> introduced a memory augmented neural architecture with a differentiable external memory component storing the dialogue history as well as triples from a knowledge base. It differs from standard CopyNet in the sense that copy distribution is trained separately to minimize the loss on the heuristically generated ground truth pointers. Instead of using only one pointer to filter the knowledge and dialogue history, Wu et al. <ref type="bibr" target="#b121">[115]</ref> apply a global-to-memory pointer with a global memory to filter the knowledge and context and a local memory at the decoder side to copy words dynamically.</p><p>In addition to architectures working with triple embeddings, there also exist approaches to tackle with more structured knowledge representation. Reddy et al. <ref type="bibr" target="#b125">[119]</ref> apply a multi-level memory architecture to learn pointers to values hierarchically grouped by query, result, and attributes. Guo et al. <ref type="bibr" target="#b120">[114]</ref> model the inference of logical forms based on the current dialogue context as a sequence of actions. Copying a sub-sequence of actions is then considered as a particular type of action in decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Future Directions</head><p>Many research challenges remain in the context of empathetic dialogue systems. For example, little effort has been devoted to combine the three key components (i.e., personalization, knowledge, and emotion) to build a more comprehensive empathetic system. With advances in each subtopic, it becomes possible to further extend this research area on different fronts:</p><p>1. Multi-goal Management As pointed out by Pollack et al. <ref type="bibr" target="#b146">[140]</ref>, communication might be overloaded with multiple objectives. This becomes even more true when emotion, personality and knowledge are fused into the system. The dialogue agent should take into account all different aspects, exhibiting perception of the user's inherent states, communicating information, and minimizing the communicative efforts. The problem then becomes how to effectively search for an optimal solution to incorporate and optimize these objectives simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Explicit Affective Policy</head><p>Existing literature have used emotion to affect the choice of action (or implicit action in an end-to-end framework).</p><p>However, emotion can be considered as explicit actions in the action space to display the affective behavior more straightforwardly. For example, a virtual agent could take different strategies for parallel empathy (mirroring the other one's emotion) and reactive empathy (providing insight to recover from other one's emotional states) <ref type="bibr" target="#b44">[39]</ref>. The emotion and personality should be two correlated dimensions of the speaker, and thus should be jointly modeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Dialogue Generation with Emotion</head><p>Knowledge. An existing knowledge base might contain sentimental or emotional knowledge, e.g., Sentic-Net, that can help to recognize the emotional states of the speaker and understand background information beyond the context. On the other hand, such knowledge could also help generate emotion-coherent responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Incorporate Cues from Multimodal Input</head><p>The goal of modeling empathy in conversation is to personify the dialogue system. However, inspired by the fact that communication between humans could be multimodal, the output of a dialogue system could be extended to multiple modalities to make it more empathetic. Existing work has shown that multimodality helps to improve the accuracy of emotion detection from dialogue <ref type="bibr" target="#b150">[144,</ref><ref type="bibr" target="#b151">145,</ref><ref type="bibr" target="#b152">146,</ref><ref type="bibr" target="#b153">147,</ref><ref type="bibr" target="#b154">148]</ref>. In the future, it would be worth investigating whether empathy in dialogues could be enhanced by considering more input channels such as audio signals and body gestures. available on the market today approach conversations between user and chatbot merely as an information retrieval problem. Given a query from the user, their main goal is simply to retrieve the answer that is statistically more plausible. In the future, dialogue systems will have to do much more than that, e.g., create a model of each conversation, understand how user's emotions change throughout the conversation, remember prior conversations and preferences of the users, understand user's needs and intentions <ref type="bibr" target="#b109">[103]</ref>. This can be made possible by both applying more 'semantics-aware' deep learning techniques, e.g., capsule networks <ref type="bibr" target="#b155">[149]</ref>,</p><p>but also by deconstructing the problem into all the relevant subtasks involved in conversation understanding, e.g., sarcasm detection <ref type="bibr" target="#b85">[80]</ref>, time expression and named entity recognition <ref type="bibr" target="#b141">[135]</ref>, anaphora resolution <ref type="bibr" target="#b156">[150]</ref>,</p><p>microtext normalization [151], and more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>Although emotion, personality and knowledge have been considered key components by existing research on dialogue systems, little work has been done to-wards investigating the correlation between them in a broader context in order to enhance human-computer interaction. In this survey, we provided a unified view of these different research efforts under the topic of empathetic dialogue systems and discussed recent advancements and trends in this context. As one of the key features in next-generation dialogue systems, empathetic features are imposing more challenges to this research domain. Researchers have explored a variety of settings and problems related to empathy and have attained successful results. The road to emulating human-to-human conversations, however, is still long and bumpy. For each of the three sub-topics, we surveyed the most recent and representative work and outlined a logical storyline for ease of comprehension. Finally, we identified a few promising future directions for this exciting research area that could one day become the killer application of conversational artificial intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgements</head><p>This research is supported by the Agency for Science, Technology and Research (A*STAR) under its AME Programmatic Funding Scheme (Project #A18A2b0046).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Typical workflow of an empathetic dialogue system.</figDesc><graphic coords="6,117.94,151.10,334.49,144.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The two views of RNN language model.</figDesc><graphic coords="8,232.81,160.80,190.34,103.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The architecture of Seq2Seq model.</figDesc><graphic coords="10,117.94,151.10,334.49,122.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The architecture of attention mechanism.</figDesc><graphic coords="11,117.94,151.10,334.49,122.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The architecture of the memory network model.</figDesc><graphic coords="12,117.94,151.10,334.48,188.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The architecture of variational autoencoder.</figDesc><graphic coords="13,151.39,151.11,267.58,97.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Generative adversarial network.</figDesc><graphic coords="15,235.01,151.10,100.35,115.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) Emotion-aware encoder. (b) Emotion-expressive decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Typical architecture of encoder-decoders for affective dialogue generation model.</figDesc><graphic coords="20,117.94,411.30,334.49,122.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: The Hourglass of Emotions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Multimodal emotion flow in an Activation/Evaluation space throughout a sample conversation that went through both positive and negative emotions [73].</figDesc><graphic coords="24,118.28,397.33,157.20,147.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Emotion compliance with other goals. The emotion expression should comply with other goals, such as grammatical fluency and naturalness of the generated response. It might be solved by multi-objective optimization and multitask learning [80]. However, it remains an open research problem if the current framework can effectively resole the conflicts between objectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: From left to right: Knowledge-based, fact-based and identity-based personalization features.</figDesc><graphic coords="30,117.94,151.10,334.49,91.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Typical workflow of a personalized dialogue system.</figDesc><graphic coords="33,117.94,151.11,334.48,149.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Sample dialogue in a personalized dialogue system.</figDesc><graphic coords="34,117.94,257.19,334.48,297.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>p(s t+1 |s 1</head><label>1</label><figDesc>, ..., s t1 , c, s t ) = sof tmax(o t ) These context-sensitive models differ in terms of how they compose the context-message pair (c, s). The context representation does not change through time, hence it forces the context encoder to produce a representation general enough to be useful for generating all words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Two different Dynamic-Context Generative models (DCGMs<ref type="bibr" target="#b87">[82]</ref>) that make use of past dialogues (context) and current sentence to estimate a personalized response.</figDesc><graphic coords="36,137.56,165.54,137.93,100.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Use of speaker embeddings in encoder-decoder architecture.</figDesc><graphic coords="37,117.94,151.10,334.48,228.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Sample responses generated by Seq2Seq and personalized dialogue model.</figDesc><graphic coords="39,201.56,151.10,167.24,86.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>, it aims to assign personality and identity to a chat agent for more coherent, natural and realistic responses. The authors use Weibo dataset for the training stage. It has three main components: (1) Profile Detector, (2) Bidirectional Decoder and (3) Position Detector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>is designed to provide more supervision to the bidirectional decoder, which is only used during training (because during training the profile values are rarely mentioned in the responses, hence the bidirectional encoder is not aware of which word the decoding should start).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>Persona Aware Attention and (2) Persona Aware Bias.<ref type="bibr" target="#b6">(1)</ref> uses persona representation to generate the attention weights at each decoding position (which extends the computation of attention weights used in the decoder) to produce context vector computed at each position that conditioned on the persona representation. In this model, it is more of a personality-aware model. However, in<ref type="bibr" target="#b7">(2)</ref>, the authors apply directly to estimating the generation distribution by incorporate the representation vector in the output layer of the decoder (which is a 2-layer GRU).This system can generate responses incorporating certain traits and can choose proper personality traits for the different context, and also tackles the data sparsity issue because the trait representations and dialogue data across speakers are shared. However, it requires a lot of data. The bottom line is this model can integrate richer and subtler traits in the future. It can also learn to choose proper, suitable traits and speech styles or choices of words.Finally,<ref type="bibr" target="#b97">[91]</ref> aimed to predict the character trope based on similar characters across different movies from a database of movie and comic characters' quotes and lines. In the training data, each character will be assigned to different tropes (groups), each group contains several paragraphs describing character-istics, actions, and personalities, together with character's lines in a dialogue (prior knowledge).The authors proposed Attentive Memory Network (AMN), which consists of Attentive Encoders (1) and Knowledge-Store Memory Module (2). (1) has Attentive Snippet Encoder (individual level) to capture the features and the relevance of each word in the given text, and Attentive Inter-Snippet Encoder (across multiple snippets) captures the inter-snippet relationship. The attention mechanism is used to assign low attention scores to irrelevant snippets. Then<ref type="bibr" target="#b6">(1)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Example of external knowledge aiding dialogue generation.</figDesc><graphic coords="42,134.66,151.10,301.04,94.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>3 . 4 .</head><label>34</label><figDesc>Long-term Empathy Modeling The display of empathy in dialogues is usually engaged in long-term activities. A reliable model that can claim to have learned to be empathy must be based on analysis of long-term data. Also, the three main components -emotion, personality and knowledge are of both static and dynamic features. In other words, they have stable bases while also being subject to changes. It remains an open research and engineering challenge to build a framework that is capable of engaging users in long-term dialogue data collection and continuously develop the conversational model to adapt to changes. Dialogue Generation with Target-dependent Emotion Although emotion has been taken into consideration by the dialogue generation model, existing work has omitted the dependency of emotion and target. In other words, emotion has been assumed to be a uni-dimensional variable without considering it may be specified towards different targets. A similar problem has been raised for emotion or sentiment classification<ref type="bibr" target="#b147">[141,</ref><ref type="bibr" target="#b148">142,</ref><ref type="bibr" target="#b149">143]</ref>, but has been missing in the context of dialogue systems. A further study in this direction would be to combine targetdependent emotion with user modeling, as emotion is a particular dimension attached to the speaker and other participants of the conversation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>7 . 8 .</head><label>78</label><figDesc>Personalized Diversifying Dialogue Generation One of the biggest advantages brought by personalization is the diversity of responses. Namely, the responses generated or retrieved can be customized for a given user profile. Indirectly, this diversifies the responses generated. However, existing work ignores the fact that the model might always generate similar responses to the same group of users. One research problem is how to encourage the intra-group diversity of personalized dialogues. Deeper Conversation and User modeling Most dialogue systems</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>A summary of papers related to affective dialogue systems. TI stands for task-</figDesc><table><row><cell>Authors</cell><cell cols="3">Dialogue Emotion Feat. Emotion Rep.</cell><cell>Data Source</cell><cell>Keywords</cell></row><row><cell cols="2">Zhou and Wang [45] TI,ST</cell><cell>EA+EE</cell><cell>64 Emojis</cell><cell>Tweets</cell><cell>Conditional modeling; Reinforcement Learning</cell></row><row><cell>Lubis et al. [46]</cell><cell>TI,MT</cell><cell>EA</cell><cell>Latent Vector</cell><cell>SubTle corpus [47]</cell><cell>Training data processing</cell></row><row><cell>Zhou et al. [9]</cell><cell>TI,ST</cell><cell>EA+EE</cell><cell>6-categorical</cell><cell>STC [48]</cell><cell>Modified loss; Auxiliary vocabulary</cell></row><row><cell>Peng et al. [49]</cell><cell>TI,ST</cell><cell>EA+EE</cell><cell>VAD</cell><cell>Tweets</cell><cell>Word Embedding;Reinforcement-VAE</cell></row><row><cell>Shi and Yu [50]</cell><cell>TO,MT</cell><cell>EA+EE</cell><cell>Multimodal</cell><cell>DSTC-1 [51]</cell><cell>Policy learning</cell></row><row><cell>Huang et al. [52]</cell><cell>TI,MT</cell><cell>EA</cell><cell>9-categorical</cell><cell>SubTle [47], CBET [53]</cell><cell>Different fusion stage</cell></row><row><cell>Rashkin et al. [54]</cell><cell>TI,MT</cell><cell>EA</cell><cell>32-categorical</cell><cell>ParlAI</cell><cell>Transformer (multi-level attention)</cell></row><row><cell>Fung et al. [55]</cell><cell>TO</cell><cell>EA</cell><cell>6-categorical</cell><cell>TED-LIUM [56]</cell><cell>CNN + LSTM</cell></row><row><cell>Kong et al. [57]</cell><cell>TI</cell><cell>EA</cell><cell>Binary polarity</cell><cell>Single-turn Tweets</cell><cell>CVAE(g) + CGAN(d)</cell></row><row><cell cols="2">Niu and Bansal. [58] TI</cell><cell>EA</cell><cell cols="3">Politeness vector Stanford Politeness Corpus Fusion; Reinforcement learning</cell></row><row><cell>Peng et al. [59]</cell><cell>TI</cell><cell>EA</cell><cell>6-categorical</cell><cell cols="2">Chinese dialogue (NLPCC) Multi-attention; Topic (LDA)</cell></row><row><cell>Fung et al. [16]</cell><cell>TO</cell><cell>EA</cell><cell>N.A.</cell><cell>Single-turn Tweets</cell><cell>Memory-Knowledge enhanced</cell></row></table><note><p>independent; TO stands for tasks-oriented; ST stands for single-turn; MT stands for multiturn; EA stands for emotion-aware; and EE stands for emotion-expressive.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>List of data-set and resources for Affective Dialogue systems</figDesc><table><row><cell>Description</cell></row><row><cell>Dataset</cell></row></table><note><p>labeled 81k short text of 9-category emotion (anger, surprise, joy, love, sadness, fear, disgust, guilt, and thankfulness). http://github.com/chenyangh/CBET-dataset English ParlAI [54] Multiple, mainly Empathetic Dialog with approx. 24850 dialogues will be on ParlAI http://parl.ai English TED-LIUM [56, 55] TED-talk monologues http://openslr.org/7 English PERSONA-CHAT [60] Daily dialouge with facts about the speaker. http://github.com/facebookresearch/ParlAI/tree/master/projects/personachat</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Personalization Dialogue Systems related papers. TI stands for task-independent; TO stands for tasks-oriented; ST stands for single turn;MT stands for multi-turn.</figDesc><table><row><cell>Description</cell></row><row><cell>Dataset</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>List of data-set and resources for Personalized Dialogue systems</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Summary of work involving an external knowledge component</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We consider</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2-class sentiment as a type of coarse-grained emotion</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English</head><p>CoCoA Dataset <ref type="bibr" target="#b118">[112]</ref> This dataset was created by crowdsourcing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of interests</head><p>☒ The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p><p>☐The authors declare the following financial interests/personal relationships which may be considered as potential competing interests:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://github.com/google-research-datasets/simulated-dialogue" />
		<title level="m">Created from Wikipedia. Questions are classified as kinds of types (e.g., simple questions or logical reasoning)</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
		</imprint>
	</monogr>
	<note>GST: Dataset of conversations between an agent and a simulated user</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><surname>English</surname></persName>
		</author>
		<ptr target="http://sdspeople.fudan.edu.cn/zywei/data/acl2018-mds.zip" />
		<title level="m">Dialogues collected from Baidu Muzhi Doctor website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Chinese DX Medical Dialogue [116] Dialogues collected from another Chinese medical consulting web</title>
		<imprint/>
	</monogr>
	<note>dxy.com</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Assistant Dataset [122] Multi-domain dialog dataset collected using Crowd Sourcing</title>
		<author>
			<persName><forename type="first">N/A Chinese</forename><surname>Stanford</surname></persName>
		</author>
		<ptr target="http://github.com/HLTCHKUST/Mem2Seq" />
	</analytic>
	<monogr>
		<title level="m">Task-specific dialogues in the restaurant</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">This consists of a collection of scientific questions and a large scientific text corpus containing a large number of scientific facts</title>
		<ptr target="http://competitions.codalab.org/competitions/17184" />
	</analytic>
	<monogr>
		<title level="m">Questions describing events about daily activities</title>
		<imprint/>
	</monogr>
	<note>English ARC [124</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">English CamRes [126] Data on restaurant searching dialog for restaurants in the Cambridge area</title>
		<ptr target="http://github.com/rkadlec/ubuntu-ranking-dataset-creator" />
	</analytic>
	<monogr>
		<title level="m">English Ubuntu Dialog Corpus [96] Extracted from Ubuntu IRC chat logs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Nickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carlin</surname></persName>
		</author>
		<title level="m">Empathy and knowledge projection, The social neuroscience of empathy</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<title level="m">Embedded empathy in continuous, interactive health assessment, in: CHI Workshop on HCI Challenges in Health Assessment</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The conversational interface</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Mctear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Callejas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Griol</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Persuasive robotic assistant for health self-management of older adults: Design and evaluation of social behaviors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Looije</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Neerincx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cnossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="386" to="397" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Computer Power and Human Reason: From Judgment to Calculation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weizenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>W H Freeman &amp; Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A french oral dialogue system for flight reservations over the telephone</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Magadur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gavignet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Andry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Charpentier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third European Conference on Speech Communication and Technology</title>
		<imprint>
			<publisher>EUROSPEECH</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="1789" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A mixed-initiative conversational dialogue system for healthcare</title>
		<author>
			<persName><forename type="first">F</forename><surname>Morbini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Forbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Devault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIG-DIAL Conference</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="137" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Let&apos;s chat about brexit! a politically-sensitive dialog system based on twitter data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khatua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khatua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM Workshops</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="393" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="730" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<title level="m">Natural language dialog systems and intelligent assistants</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">End-to-end latent-variable task-oriented dialogue system with exact log-likelihood optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>World Wide Web</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Minaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nikzad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chenaghlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03705</idno>
		<title level="m">Deep learning based text classification: A comprehensive review</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A survey on dialogue systems: Recent advances and new frontiers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural approaches to conversational AI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="127" to="298" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bertero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>-S. Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<title level="m">Language Resources and Evaluation Conference (LREC)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Empathetic dialog systems</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cernocký</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCA</title>
		<imprint>
			<biblScope unit="page" from="1045" to="1048" />
			<date type="published" when="2010">2010</date>
			<publisher>INTERSPEECH</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<title level="m">Neural machine translation by jointly learning to align and translate</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning to execute</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.4615</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Memory networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<idno>CoRR abs/1410.3916</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Variational neural machine translation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="521" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
	<note>NIPS&apos;14</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A tractable hybrid ddn-pomdp approach to affective dialogue modeling for probabilistic frame-based dialogue systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nijholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zwiers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="307" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Affective dialogue management using factored pomdps</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zwiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nijholt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interactive Collaborative Information Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="207" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Reinforcement learning for adaptive dialogue systems: a data-driven methodology for dialogue management and natural language generation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lemon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Computationally modeling human emotion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Marsella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gratch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="56" to="67" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Emotions in Social Interactions: Unfolding Emotional Experience</title>
		<author>
			<persName><forename type="first">C</forename><surname>Marinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parkinson</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-15184-2_3</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="31" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">What are emotions? and how can they be measured?</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1177/0539018405058216</idno>
		<idno>doi:10.1177/0539018405058216</idno>
		<ptr target="https://doi.org/10.1177/0539018405058216" />
	</analytic>
	<monogr>
		<title level="j">Social Science Information</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="695" to="729" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">How emotion is made and measured</title>
		<author>
			<persName><forename type="first">K</forename><surname>Boehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Depaula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dourish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sengers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhcs.2006.11.016</idno>
		<ptr target="https://doi.org/10.1016/j.ijhcs.2006.11.016" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Hum.-Comput. Stud</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="291" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Frijda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Emotion, cognitive structure, and action tendency</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="115" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Integrating emotional processes into decision-making models, Integrated models of cognitive systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dimperio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Jessup</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">213</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Affective interaction: How emotional agents affect users</title>
		<author>
			<persName><forename type="first">R</forename><surname>Beale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Creed</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhcs.2009.05.001</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S1071581909000573" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="755" to="776" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Activating humans with humor-a dialogue system that users want to interact with</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dybala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ptaszynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rzepka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Araki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE TRANS-ACTIONS on Information and Systems</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2394" to="2401" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Affective learning: Empathetic agents with emotional facial and tone of voice expressions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Moridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Economides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="260" to="272" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<title level="m">Affective computing</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Computers that recognise and respond to user emotion: theoretical and practical implications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="169" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Employing personality-rich virtual personsnew tools required</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Iurgel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Marcos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="827" to="836" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Handling Emotions in Human-Computer Dialogues, 1st Edition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pittermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pittermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Minker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer Publishing Company, Incorporated</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Exploring expressivity and emotion with artificial voice and speech technologies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pauletto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Balentine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pidcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottaci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aretoulaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Mundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Balentine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Logopedics Phoniatrics Vocology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="115" to="125" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Mojitalk: Generating emotional responses at scale, in: Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1128" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Eliciting positive emotion through affect-sensitive dialogue response generation: A neural network approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5293" to="5300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">i am your father: dealing with out-of-domain requests by using movies subtitles</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ameixa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Coheur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Conference on Intelligent Virtual Agents</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Human-machine dialogue modelling with the fusion of word-and sentence-level emotions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="page">105319</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sentiment adaptive end-to-end dialog systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1509" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Let&apos;s go public! taking a spoken dialog system to the real world</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth European conference on speech communication and technology</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automatic dialogue generation with expressed emotions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R</forename><surname>Zaïane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dziri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Current state of text sentiment analysis from opinion to emotion mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yadollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Shahraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R</forename><surname>Zaiane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">I know the feeling: Learning to converse with empathy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<idno>CoRR abs/1811.00207</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A virtual interactive dialogue system incorporating emotion, sentiment and personality recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Siddique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bertero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics (COLING)</title>
		<meeting><address><addrLine>Zara</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="278" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Enhancing the ted-lium corpus with selected data for language modeling and more ted talks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Deléglise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Esteve</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>LREC</publisher>
			<biblScope unit="page" from="3935" to="3939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">An adversarial approach to high-quality, sentiment-controlled neural dialogue generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno>abs/1901.07129</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Polite dialogue generation without parallel data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="373" to="389" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Topic-enhanced emotional conversation generation with attention mechanism</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Based Systems</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="429" to="437" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Personalizing dialogue agents: I have a dog, do you have pets too?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07243</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A computational approach to politeness with application to social factors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Processing and Chinese Computing: 6th CCF International Conference</title>
		<meeting><address><addrLine>Dalian, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017-11-08">2017. November 8-12, 2017. 2018</date>
			<biblScope unit="volume">10619</biblScope>
		</imprint>
	</monogr>
	<note>NLPCC</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bravo-Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salameh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiritchenko</surname></persName>
		</author>
		<title level="m">Proceedings of The 12th International Workshop on Semantic Evaluation, Association for Computational Linguistics</title>
		<meeting>The 12th International Workshop on Semantic Evaluation, Association for Computational Linguistics<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
	<note>SemEval-2018 task 1: Affect in tweets</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">A review of emotion sensing: Categorization models and algorithms</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Multimedia Tools and Applications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The hourglass model revisited</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Livingstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">How intense are you? predicting intensities of emotions and sentiments using stacked ensemble</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="75" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A multimodal database for affect recognition and implicit tagging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Soleymani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lichtenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="55" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">AffectiveSpace 2: Enabling affective intuition for concept-level sentiment analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bisio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="508" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Computational models of emotion, A Blueprint for Affective Computing-A sourcebook and manual</title>
		<author>
			<persName><forename type="first">S</forename><surname>Marsella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Petta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="21" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Improving on LDA with semantic similarity for aspect-based sentiment analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bisio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lda</forename><surname>Sentic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>IJCNN</publisher>
			<biblScope unit="page" from="4465" to="4473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Sentic LSTM: a hybrid network for targeted aspect-based sentiment analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="639" to="650" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Learning multi-grained aspect target sequence for chinese sentiment analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="167" to="176" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Sentic blending: Scalable multimodal fusion for continuous interpretation of semantics and sentics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<editor>IEEE SSCI</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="108" to="117" />
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Interactive double states emotion cell model for textual dialogue emotion prediction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page">105084</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Modeling the user state for contextaware spoken interaction in ambient assisted living</title>
		<author>
			<persName><forename type="first">D</forename><surname>Griol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Callejas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="749" to="771" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Modeling and evaluating empathy in embodied companion agents</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mcquiggan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="348" to="360" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Unsupervised discrete sentence representation learning for interpretable neural dialog generation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1098" to="1107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Toward controlled generation of text</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Emotion, affect and personality in speech and language processing</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Batliner</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Sentiment and sarcasm classification with multitask learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="38" to="43" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Example-based chat-oriented dialogue system with personalized long-term memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 International Conference on Big Data and Smart Computing (BIGCOMP)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="238" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><surname>Dolan</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06155</idno>
		<title level="m">A persona-based neural conversation model</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pickett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Snaider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<title level="m">Conversational contextual cues: The case of personalization and history for response ranking</title>
		<imprint>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.07503</idno>
		<title level="m">Personalization in goal-oriented dialog</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Personalizing a dialogue system with transfer reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Assigning personality/profile to a chatting machine for coherent conversation generation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4279" to="4285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Personalized response generation by dual-learning based domain adaptation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="72" to="82" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09672</idno>
		<title level="m">Personalized dialogue generation with diversified traits</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Aiming to know you better perhaps makes me a more engaging dialogue partner</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zemlyanskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Natural Language Learning, Association for Computational Linguistics</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning, Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="551" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Learning perso nas from dialogue with attentive memory networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vijayaraghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2638" to="2646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A persona-based multi-turn conversation model in an adversarial learning framework</title>
		<author>
			<persName><forename type="first">O</forename><surname>Olabiyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khazane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th IEEE International Conference on Machine Learning and Applications</title>
		<meeting><address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-17">2018. December 17-20, 2018, 2018</date>
			<biblScope unit="page" from="489" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.04604</idno>
		<title level="m">Learning personalized endto-end goal-oriented dialog</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="994" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Incorporating unstructured textual knowledge sources into neural dialogue systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems Workshop on Machine Learning for Spoken Language Understanding</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Evaluating the effect of gesture and language on personality perception in conversational agents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Virtual Agents</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Allbeck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Badler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Bickmore</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Pelachaud</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Safonova</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="222" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Towards personality-based user adaptation: Psychologically informed stylistic language generation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11257-010-9076-2</idno>
		<ptr target="https://doi.org/10.1007/s11257-010-9076-2" />
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="278" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Controlling user perceptions of linguistic style: Trainable generation of personality traits</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="488" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">PERSONALITY IN SPEECH</title>
		<author>
			<persName><forename type="first">T</forename><surname>Polzehl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Can robots manifest personality?: An empirical test of personality recognition, social responses, and social presence in human-robot interaction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1460-2466.2006.00318.x</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="754" to="772" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Does computer-generated speech manifest personality? an experimental test of similarity-attraction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/332040.332452</idno>
		<ptr target="https://doi.org/10.1145/332040.332452" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;00</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="329" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Intention awareness: Improving upon situation awareness in human-centric environments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-centric Computing and Information Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Recent trends in deep learning based personality detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="2313" to="2339" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">2800 personality trait descriptors-normative operating characteristics for a university population</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Norman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Personality structure: Emergence of the five-factor model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Digman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of psychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="417" to="440" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">A hierarchical recurrent encoder-decoder for generative context-aware query suggestion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Grue</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">POMDP-based dialogue manager adaptation to extended domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gašić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breslin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tsiakoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
		<meeting>the SIGDIAL 2013 Conference<address><addrLine>Metz, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="214" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
	<note>NIPS&apos;15</note>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marttinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.00388</idno>
		<title level="m">A survey on knowledge graphs: Representation, acquisition and applications</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1766" to="1776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Mem2seq: Effectively incorporating knowledge bases into end-to-end task-oriented dialog systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1468" to="1478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Dialog-to-action: Conversational question answering over a large-scale knowledge base</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2946" to="2955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04713</idno>
		<title level="m">Global-to-local memory pointer networks for task-oriented dialogue</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10623</idno>
		<title level="m">End-to-end knowledge-routed relational dialogue system for automatic diagnosis</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>-T. Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<title level="m">A knowledge-grounded neural conversation model, in: Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Dialogue learning with human teaching and feedback in end-to-end trainable task-oriented dialogue systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2060" to="2069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Multi-level memory for task oriented dialogs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.10647</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Commonsense knowledge aware conversation generation with graph attention</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<editor>IJ-CAI</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4623" to="4629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<title level="m">Task-oriented dialogue system for automatic diagnosis, in: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="201" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Charette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="37" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07683</idno>
		<title level="m">Learning end-to-end goal-oriented dialog</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tafjord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05457</idno>
		<title level="m">Think you have solved question answering? try arc, the ai2 reasoning challenge</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">Semeval-2018 task 11: Machine comprehension using commonsense knowledge, in: Proceedings of the 12th International Workshop on semantic evaluation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ostermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="747" to="757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Duh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Carreras</surname></persName>
		</editor>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00057</idno>
		<title level="m">Frames: A corpus for adding memory to goal-oriented dialogue systems</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title level="m" type="main">Knowledge representation and reasoning with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Neelakantan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts Amherst</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Report on a general problem solving program</title>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IFIP congress</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="1959">1959</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Large theory reasoning with sumo at casc</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pease</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Communications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="137" to="144" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eckl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Common sense computing: From the society of mind to digital intuition and beyond</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5707</biblScope>
			<biblScope unit="page" from="252" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Representing general relational knowledge in conceptnet 5</title>
		<author>
			<persName><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>LREC</publisher>
			<biblScope unit="page" from="3679" to="3686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Discovering conceptual primitives for sentiment analysis by means of context embeddings</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SenticNet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1795" to="1802" />
			<date type="published" when="2018">2018</date>
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">New avenues in knowledge bases for natural language processing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Extracting time expressions and named entities with constituent-based tagging schemes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Cognitive Computation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Augmenting end-to-end dialogue systems with commonsense knowledge</title>
		<author>
			<persName><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="4970" to="4977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><surname>Pointer Networks</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Incorporating copying mechanism in sequenceto-sequence learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">A copy-augmented sequence-to-sequence architecture gives good performance on task-oriented dialogue</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EACL</title>
		<imprint>
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page">468</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Overloading intentions for efficient practical reasoning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Noûs</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="536" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Effective lstms for target-dependent sentiment classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3298" to="3307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Gated neural networks for targeted sentiment analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-T</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Targeted aspect-based sentiment analysis via embedding commonsense knowledge into an attentive LSTM</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="5876" to="5883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">Conversational memory network for emotion recognition in dyadic dialogue videos</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NAACL</publisher>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Dialogue systems with audio context</title>
		<author>
			<persName><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pandelea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="102" to="109" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">A face-to-face neural conversation model</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7113" to="7121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">An attentive rnn for emotion detection in conversations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><surname>Dialoguernn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="6818" to="6825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Fuzzy commonsense reasoning for multimodal sentiment analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Satapathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cavallari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="264" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Towards scalable and reliable capsule networks for challenging NLP applications</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1549" to="1559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Anaphora and coreference resolution: A review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthanker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thirunavukarasu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="139" to="162" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">A review of shorthand systems: From brachygraphy to microtext and beyond</title>
		<author>
			<persName><forename type="first">R</forename><surname>Satapathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
