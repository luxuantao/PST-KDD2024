<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Drug-Target Interaction Prediction with Graph Attention networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-07-10">10 Jul 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Haiyang</forename><surname>Wang</surname></persName>
							<email>wanghaiyang@stu.pku.edu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Zhiyuan College</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guangyu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siqi</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
							<email>weiwang@cs.ucla.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Drug-Target Interaction Prediction with Graph Attention networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-07-10">10 Jul 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2107.06099v1[q-bio.QM]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Motivation: Predicting Drug-Target Interaction (DTI) is a well-studied topic in bioinformatics due to its relevance in the fields of proteomics and pharmaceutical research. Although many machine learning methods have been successfully applied in this task, few of them aim at leveraging the inherent heterogeneous graph structure in the DTI network to address the challenge. For better learning and interpreting the DTI topological structure and the similarity, it is desirable to have methods specifically for predicting interactions from the graph structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results:</head><p>We present an end-to-end framework, DTI-GAT (Drug-Target Interaction prediction with Graph ATtention networks) for DTI predictions. DTI-GAT incorporates a deep neural network architecture that operates on graph-structured data with the attention mechanism, which leverages both the interaction patterns and the features of drug and protein sequences. DTI-GAT facilitates the interpretation of the DTI topological structure by assigning different attention weight to each node with the self-attention mechanism. Experimental evaluations show that DTI-GAT outperforms various state-of-the-art systems on the binary DTI prediction problem. Moreover, the independent study results further demonstrate that our model can be generalized better than other conventional methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Detecting drug-target interactions (DTIs) potentially facilitates therapeutic target identification <ref type="bibr" target="#b39">(Xia et al., 2010;</ref><ref type="bibr" target="#b26">Petta et al., 2016)</ref> and novel drug design <ref type="bibr" target="#b31">(Skrabanek et al., 2008;</ref><ref type="bibr" target="#b0">AY et al., 2007;</ref><ref type="bibr" target="#b11">Janga and Tzakos, 2009;</ref><ref type="bibr" target="#b19">Kuhn et al., 2008)</ref>. Until quite recently, pharmacological effects were often discovered using primitive trial and error procedures, such as applying plant extracts on living systems and observing the outcomes <ref type="bibr" target="#b30">(Singh et al., 2016)</ref>. However, experiment-based methods remain expensive, laborintensive and time-consuming <ref type="bibr" target="#b6">(Dickson and Gagnon, 2004;</ref><ref type="bibr" target="#b18">Kola and Landis, 2004;</ref><ref type="bibr" target="#b14">Kapetanovic, 2008)</ref>. Evidently, there is an immense need for reliable computational approaches to identify and characterize DTIs, hoping to accelerate the pace and reduce the cost of drug development.</p><p>With the rapid development of machine learning techniques, various computational prediction approaches have been proposed to predict drugtarget interactions. <ref type="bibr" target="#b41">Yamanishi et al. (2010)</ref> integrated the relationship among the pharmacological space, the chemical space, and the topology of drug-target interaction networks to predict the associations between drugs and targets, and their experimental results have demonstrated that drug-target interactions are more correlated with pharmacological effect similarity than with chemical structure similarity. According to the similarity of chemical information, <ref type="bibr" target="#b15">Keiser et al. (2009)</ref> proposed a method to explore the associations between drugs and targets. They selected 30 of predicted results for biological experiments and finally confirmed 23 with interrelationships. <ref type="bibr" target="#b36">Wang et al. (2010)</ref> used supervised machine learning methods to predict the relationship between drugs and targets. To solve the problem of sample imbalance, they are collecting the positive samples from the database, and the negative samples using the random selection method. The input features of the classifier consist of the chemical structure of the drug and the sequence information of the protein. <ref type="bibr" target="#b4">Chen et al. (2012)</ref> developed a novel method of Network-based Random Walk with Restart on the Heterogeneous (NRWRH) network to predict potential drug-target interactions on a large scale. The excellent experimental results show that the proposed method can discover new potential drug-target interactions for drug development. These approaches provide feasible solutions to the problem. However, the extracted features used in these approaches only have limited coverage on interaction information, since they are dedicated to specific facets of the protein and the drug profiles.</p><p>To alleviate the inadequacy of statistical learning methods, deep learning algorithms provide the powerful functionality to represent large-scale raw data for different tasks and thus facilitate the learning of latent patterns in the data <ref type="bibr" target="#b20">(LeCun et al., 2015)</ref>. Recently, deep learning architectures have produced powerful systems to address several estimation problems related to protein sequences, such as proteinprotein interaction <ref type="bibr" target="#b3">(Chen et al., 2019)</ref>, protein binding affinity upon mutation <ref type="bibr" target="#b43">(Zhou et al., 2020)</ref>, and protein structural changes <ref type="bibr" target="#b28">(Senior et al., 2020)</ref> estimation. These works typically use convolutional neural networks (CNNs) for automatically selecting local features, recurrent neural networks (RNN) that aim at preserving the contextualized and longterm ordering information or the combination of both CNNs and RNNs. In contrast, fewer efforts have been made to capture the pairwise interactions of the protein drug interaction with deep learning, which remains a non-trivial problem with the following challenges: (i) Characterization of the proteins and drugs requires a model to effectively filter and aggregate their local features, while preserving significant contextualized and sequential information of the amino acids and drug fingerprints; (ii) Constructing a deep neural architecture without biological insights often suffers from the interpretation issue; (iii) An effective mechanism is also needed to apprehend the mutual influence of protein-drug pairs in DTI prediction. Moreover,the framework needs to be scalable to large data. Corresponding methods, including DeepDTI <ref type="bibr" target="#b37">(Wen et al., 2017)</ref>, RFDT <ref type="bibr">(Wang et al., 2018a)</ref>, DeepDTA <ref type="bibr">(?zt?rk et al., 2018)</ref> and DeepConv-DTI <ref type="bibr" target="#b21">(Lee et al., 2019)</ref>, employed deep neural networks on DTI prediction tasks. Specifically, DeepDTI built by <ref type="bibr" target="#b37">Wen et al. (2017)</ref> used the deep belief network (DBN), with features such as the composition of amino acids, dipeptides, and tripeptides for proteins and fingerprints for drugs. RFDT by <ref type="bibr">Wang et al. (2018a)</ref> employed stacked Auto-Encoder (AE) to abstract original features into a latent representation with a small dimension. With latent representation, they trained a Random Forest (RF), which performed better than previous methods. DeepDTA <ref type="bibr">(?zt?rk et al., 2018)</ref> and DeepConv-DTI <ref type="bibr" target="#b21">(Lee et al., 2019)</ref> both used CNN to extract local residue patterns to predict the binding affinity between drugs and targets. They performed convolution on various lengths of the subsequences' amino acids to capture local residue patterns of generalized protein classes.</p><p>The previous DTI prediction methods can be mainly separated into two categories: similarity-based methods and feature-based methods. Similarity-based methods assume that similar drugs or proteins may have similar interaction patterns. These methods use many different similarity measures based on fingerprint, chemical structure, sequence data and so on to identify drug-target interaction. Feature-based methods solve drug-target interaction prediction as a binary classification problem, such as DeepConv-DTI <ref type="bibr" target="#b21">(Lee et al., 2019)</ref>, use known drug-target pairs as positive sample. To combine both the similarity and feature vectors, the neural network models require a mechanism to represent both the interaction patterns and the features of drug and protein sequences.</p><p>In this paper, we introduce DTI-GAT (Drug-Target Interaction prediction with Graph ATtention networks), a deep neural network architecture that operates on graph-structured data with attention mechanism. First, it converts the position-specific scoring matrix (PSSM) and the drug fingerprint as feature vectors for all the target proteins and drugs. Secondly, a DTI graph is constructed based on the similarity of feature vectors. Each node represents a protein or a drug and the nodes are lined by edges representing interactions between protein-drug, protein-protein and drug-drug separately. The graph attention network is then applied on the built graph to generate embeddings for each protein and drug, followed by a final decoder architecture to predict the interaction result. Notably, based on the assumption that different neighbors' importance are different and the DTI graph is heterogeneous, we don't know which neighbor or domain knowledge (protein or drug) is more important for a given node in the DTI prediction task. The Graph attention (GAT) layer applies self-attention mechanism, which allows for assigning different attentional weight to neighbor nodes, enabling a leap in model capacity. Furthermore, analyzing the learned weights with attention can lead to benefits in interpreting the DTI topological structure and similarity.</p><p>Our contributions are 3-fold. First, we provide an approach to transform the feature representations of proteins and drugs into a proteindrug interaction graph. We emphasize the need to extend the bipartite graph to a heterogeneous graph, by adding drug-drug and proteinprotein similarities. Second, we demonstrate that the attention mechanism can automatically extract the important high-level relationships among proteins and drugs by assigning different weights to each edge and drop all structural information. Third, we provide an extensive analysis to show the better interpretability of learned attention weights for representing the topological structure and similarity. Last, DTI-GAT is highly efficient, as the operation of the self-attentional layer can be parallelized across all edges, and the computation of output features can be parallelized across all nodes. DTI-GAT significantly outperforms various state-ofthe-art approaches on the DTI binary prediction task, which confirms the effectiveness of the graph attention strategy in identifying drug-target interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Protein feature representation</head><p>In this work, protein sequences are represented as pseudo-position specific scoring matrix (PsePSSM) features to encode the evolution and sequential information for proteins with different lengths of sequences. Note that this setting is consistent with previous studies <ref type="bibr" target="#b29">(Shi et al., 2019)</ref>.</p><p>For a target protein sequence pm with L amino acid residues, we use the position-specific scoring matrix (PSSM) as its descriptor introduced by <ref type="bibr" target="#b12">Jones (1999)</ref>. The PSSM with a dimension of L ? 20 can be expressed as:</p><formula xml:id="formula_0">P SSM (pm) = ? ? ? ? ? ? E 1?1 E 1?2 ? ? ? E 1?20 E 2?1 E 2?2 ? ? ? E 2?20 . . . . . . . . . . . . E L?1 E L?2 ? ? ? E L?20 ? ? ? ? ? ?</formula><p>, where each element E i?j in the PSSM matrix is then normalized to the interval (0, 1) as:</p><formula xml:id="formula_1">E i?j = 1 1 + exp(E i?j )<label>(1)</label></formula><p>To make the PSSM descriptor a uniform representation despite proteins with different lengths correspond to different numbers of rows, we represent the uniformed PSSM of pm as:</p><formula xml:id="formula_2">P SSM (pm) = [E 1 , E 2 , ..., E 20 ] T , (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where T is the transpose operator. Here, E j = 1 L L i=1 E i?j computes the average score of the residue in protein pm during the process of evolution, which is the mutation from amino acid type i to j. To retain the sequence information after Eq. 2, the pseudo-position specific scoring matrix (PsePSSM) for protein pm is computed as:</p><formula xml:id="formula_4">P ? Pse(pm) = [E 1 , ..., E 20 , G 1 1 , ..., G 1 20 , ..., G ? 1 , ...G ? 20 ] T ,<label>(3) i i</label></formula><p>"DTI" -2021/7/14 -1:01 -page 3 -#3</p><formula xml:id="formula_5">i i i i i i DTI-GAT 3 Message passing Protein sequence Drug structure d n &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W X c Y n j L 5 r h k / 8 v e N 6 K F N P 8 q Q z a o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K 9 g P a U D a b S b t 0 s w m 7 G 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 y R T D F s s E Y n q B l S j 4 B J b h h u B 3 V Q h j Q O B n W B 8 O / M 7 T 6 g 0 T + S j m a T o x 3 Q o e c Q Z N V Z 6 C A d y U K 2 5 d X c O s k q 8 g t S g Q H N Q / e q H C c t i l I Y J q n X P c 1 P j 5 1 Q Z z g R O K / 1 M Y 0 r Z m A 6 x Z 6 m k M W o / n 5 8 6 J W d W C U m U K F v S k L n 6 e y K n s d a T O L C d M T U j v e z N x P + 8 X m a i a z / n M s 0 M S r Z Y F G W C m I T M / i Y h V 8 i M m F h C m e L 2 V s J G V F F m b D o V G 4 K 3 / P I q a V / U P b f u 3 V / W G j d F H G U 4 g V M 4 B w + u o A F 3 0 I Q W M B j C M 7 z C m y O c F + f d + V i 0 l p x i 5 h j + w P n 8 A U m s j c k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W X c Y n j L 5 r h k / 8 v e N 6 K F N P 8 q Q z a o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K 9 g P a U D a b S b t 0 s w m 7 G 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 y R T D F s s E Y n q B l S j 4 B J b h h u B 3 V Q h j Q O B n W B 8 O / M 7 T 6 g 0 T + S j m a T o x 3 Q o e c Q Z N V Z 6 C A d y U K 2 5 d X c O s k q 8 g t S g Q H N Q / e q H C c t i l I Y J q n X P c 1 P j 5 1 Q Z z g R O K / 1 M Y 0 r Z m A 6 x Z 6 m k M W o / n 5 8 6 J W d W C U m U K F v S k L n 6 e y K n s d a T O L C d M T U j v e z N x P + 8 X m a i a z / n M s 0 M S r Z Y F G W C m I T M / i Y h V 8 i M m F h C m e L 2 V s J G V F F m b D o V G 4 K 3 / P I q a V / U P b f u 3 V / W G j d F H G U 4 g V M 4 B w + u o A F 3 0 I Q W M B j C M 7 z C m y O c F + f d + V i 0 l p x i 5 h j + w P n 8 A U m s j c k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W X c Y n j L 5 r h k / 8 v e N 6 K F N P 8 q Q z a o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K 9 g P a U D a b S b t 0 s w m 7 G 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 y R T D F s s E Y n q B l S j 4 B J b h h u B 3 V Q h j Q O B n W B 8 O / M 7 T 6 g 0 T + S j m a T o x 3 Q o e c Q Z N V Z 6 C A d y U K 2 5 d X c O s k q 8 g t S g Q H N Q / e q H C c t i l I Y J q n X P c 1 P j 5 1 Q Z z g R O K / 1 M Y 0 r Z m A 6 x Z 6 m k M W o / n 5 8 6 J W d W C U m U K F v S k L n 6 e y K n s d a T O L C d M T U j v e z N x P + 8 X m a i a z / n M s 0 M S r Z Y F G W C m I T M / i Y h V 8 i M m F h C m e L 2 V s J G V F F m b D o V G 4 K 3 / P I q a V / U P b f u 3 V / W G j d F H G U 4 g V M 4 B w + u o A F 3 0 I Q W M B j C M 7 z C m y O c F + f d + V i 0 l p x i 5 h j + w P n 8 A U m s j c k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W X c Y n j L 5 r h k / 8 v e N 6 K F N P 8 q Q z a o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K 9 g P a U D a b S b t 0 s w m 7 G 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A X X x n W / n d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 6 y R T D F s s E Y n q B l S j 4 B J b h h u B 3 V Q h j Q O B n W B 8 O / M 7 T 6 g 0 T + S j m a T o x 3 Q o e c Q Z N V Z 6 C A d y U K 2 5 d X c O s k q 8 g t S g Q H N Q / e q H C c t i l I Y J q n X P c 1 P j 5 1 Q Z z g R O K / 1 M Y 0 r Z m A 6 x Z 6 m k M W o / n 5 8 6 J W d W C U m U K F v S k L n 6 e y K n s d a T O L C d M T U j v e z N x P + 8 X m a i a z / n M s 0 M S r Z Y F G W C m I T M / i Y h V 8 i M m F h C m e L 2 V s J G V F F m b D o V G 4 K 3 / P I q a V / U P b f u 3 V / W G j d F H G U 4 g V M 4 B w + u o A F 3 0 I Q W M B j C M 7 z C m y O c F + f d + V i 0 l p x i 5 h j + w P n 8 A U m s j c k = &lt; / l a t e x i t &gt; p m &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V 1 W J z D T 4 J 2 t V 9 B + W 4 w k m Q y y 8 t 9 8 = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z Q O S J c x O Z p M h M 7 P L T K 8 Q Q j 7 B i w d F v P p F 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 b Z I Z x h s s k Y l p R 9 R y K T R v o E D J 2 6 n h V E W S t 6 L R 7 c x v P X F j R a I f c Z z y U N G B F r F g F J 3 0 k P Z U r 1 z x q / 4 c Z J U E O a l A j n q v / N X t J y x T X C O T 1 N p O 4 K c Y T q h B w S S f l r q Z 5 S l l I z r g H U c 1 V d y G k / m p U 3 L m l D 6 J E + N K I 5 m r v y c m V F k 7 V p H r V B S H d t m b i f 9 5 n Q z j 6 3 A i d J o h 1 2 y x K M 4 k w Y T M / i Z 9 Y T h D O X a E M i P c r Y Q N q a E M X T o l F 0 K w / P I q a V 5 U A 7 8 a 3 F 9 W a j d 5 H E U 4 g V M 4 h w C u o A Z 3 U I c G M B j A M 7 z C</formula><p>m y e 9 F + / d + 1 i 0 F r x 8 5 h j + w P v 8 A V p w j d Q = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = "</p><formula xml:id="formula_6">V 1 W J z D T 4 J 2 t V 9 B + W 4 w k m Q y y 8 t 9 8 = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z Q O S J c x O Z p M h M 7 P L T K 8 Q Q j 7 B i w d F v P p F 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 b Z I Z x h s s k Y l p R 9 R y K T R v o E D J 2 6 n h V E W S t 6 L R 7 c x v P X F j R a I f c Z z y U N G B F r F g F J 3 0 k P Z U r 1 z x q / 4 c Z J U E O a l A j n q v / N X t J y x T X C O T 1 N p O 4 K c Y T q h B w S S f l r q Z 5 S l l I z r g H U c 1 V d y G k / m p U 3 L m l D 6 J E + N K I 5 m r v y c m V F k 7 V p H r V B S H d t m b i f 9 5 n Q z j 6 3 A i d J o h 1 2 y x K M 4 k w Y T M / i Z 9 Y T h D O X a E M i P c r Y Q N q a E M X T o l F 0 K w / P I q a V 5 U A 7 8 a 3 F 9 W a j d 5 H E U 4 g V M 4 h w C u o A Z 3 U I c G M B j A M 7 z C</formula><p>m y e 9 F + / d + 1 i 0 F r x 8 5 h j + w P v 8 A V p w j d Q = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = "    where</p><formula xml:id="formula_7">V 1 W J z D T 4 J 2 t V 9 B + W 4 w k m Q y y 8 t 9 8 = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z Q O S J c x O Z p M h M 7 P L T K 8 Q Q j 7 B i w d F v P p F 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 b Z I Z x h s s k Y l p R 9 R y K T R v o E D J 2 6 n h V E W S t 6 L R 7 c x v P X F j R a I f c Z z y U N G B F r F g F J 3 0 k P Z U r 1 z x q / 4 c Z J U E O a l A j n q v / N X t J y x T X C O T 1 N p O 4 K c Y T q h B w S S f l r q Z 5 S l l I z r g H U c 1 V d y G k / m p U 3 L m l D 6 J E + N K I 5 m r v y c m V F k 7 V p H r V B S H d t m b i f 9 5 n Q z j 6 3 A i d J o h 1 2 y x K M 4 k w Y T M / i Z 9 Y T h D O X a E M i P c r Y Q N q a E M X T o l F 0 K w / P I q a V 5 U A 7 8 a 3 F 9 W a j d 5 H E U 4 g V M 4 h w C u o A Z 3 U I c G M B j A M 7 z C m y e 9 F + / d + 1 i 0 F r x 8 5 h j + w P v 8 A V p w j d Q = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " V 1 W J z D T 4 J 2 t V 9 B + W 4 w k m Q y y 8 t 9 8 = " &gt; A A A B 6 n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z Q O S J c x O Z p M h M 7 P L T K 8 Q Q j 7 B i w d F v P p F 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 b Z I Z x h s s k Y l p R 9 R y K T R v o E D J 2 6 n h V E W S t 6 L R 7 c x v P X F j R a I f c Z z y U N G B F r F g F J 3 0 k P Z U r 1 z x q / 4 c Z J U E O a l A j n q v / N X t J y x T X C O T 1 N p O 4 K c Y T q h B w S S f l r q Z 5 S l l I z r g H U c 1 V d y G k / m p U 3 L m l D 6 J E + N K I 5 m r v y c m V F k 7 V p H r V B S H d t m b i f 9 5 n Q z j 6 3 A i d J o h 1 2 y x K M 4 k w Y T M / i Z 9 Y T h D O X a E M i P c r Y Q N q a E M X T o l F 0 K w / P I q a V 5 U A 7 8 a 3 F 9 W a j d 5 H E U 4 g V M 4 h w C u o A Z 3 U I c G M B j A M 7 z C m y e 9 F + / d + 1 i 0 F r x 8 5 h j + w P v 8 A V p w j d Q = &lt; / l a t</formula><formula xml:id="formula_8">I(p m , d n ) = 0 or 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X + y 9 t B 3 e J 6 Z V 3 i o 0 F o j R T O K M 8 4 w = " &gt; A A A C C X i c b V D L S s N A F J 3 4 r P V V d e l m s A g V p C Q i 6 E Y o u t F d B f u A J o T J Z N I O n U z C z I 1 Y Q r d u / B U 3 L h R x 6 x + 4 8 2 + c P h b a e l a H c + 7 l 3 n O C V H A N t v 1 t L S w u L a + s F t a K 6 x u b W 9 u l n d 2 m T j J F W Y M m I l H t g G g m u G Q N 4 C B Y O 1 W M x I F g r a B / N f J b 9 0 x p n s g 7 G K T M i 0 l X 8 o h T A k b y S / i m k v r x M Q 5 9 e Y R d t 3 i B b e w C e 4 A c J w o P s e O X y n b V H g P P E 2 d K y m i K u l / 6 c s O E Z j G T Q A X R u u P Y K X g 5 U c C p Y M O i m 2 m W E t o n X d Y x V J K Y a S 8 f J x n i Q 6 O E O D K n o 0 Q C H q u / N 3 I S a z 2 I A z M Z E + j p W W 8 k / u d 1 M o j O v Z z L N A M m 6 e R Q l A k M C R 7 V g k O u G A U x M I R Q x c 2 v m P a I I h R M e U V T g j M b e Z 4 0 T 6 q O X X V u T 8 u 1 y 2 k d B b S P D l A F O e g M 1 d A 1 q q M G o u g R P a N X 9 G Y 9 W S / W u / U x G V 2 w p j t 7 6 A + s z x / / H p d Y &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X + y 9 t B 3 e J 6 Z V 3 i o 0 F o j R T O K M 8 4 w = " &gt; A A A C C X i c b V D L S s N A F J 3 4 r P V V d e l m s A g V p C Q i 6 E Y o u t F d B f u A J o T J Z N I O n U z C z I 1 Y Q r d u / B U 3 L h R x 6 x + 4 8 2 + c P h b a e l a H c + 7 l 3 n O C V H A N t v 1 t L S w u L a + s F t a K 6 x u b W 9 u l n d 2 m T j J F W Y M m I l H t g G g m u G Q N 4 C B Y O 1 W M x I F g r a B / N f J b 9 0 x p n s g 7 G K T M i 0 l X 8 o h T A k b y S / i m k v r x M Q 5 9 e Y R d t 3 i B b e w C e 4 A c J w o P s e O X y n b V H g P P E 2 d K y m i K u l / 6 c s O E Z j G T Q A X R u u P Y K X g 5 U c C p Y M O i m 2 m W E t o n X d Y x V J K Y a S 8 f J x n i Q 6 O E O D K n o 0 Q C H q u / N 3 I S a z 2 I A z M Z E + j p W W 8 k / u d 1 M o j O v Z z L N A M m 6 e R Q l A k M C R 7 V g k O u G A U x M I R Q x c 2 v m P a I I h R M e U V T g j M b e Z 4 0 T 6 q O X X V u T 8 u 1 y 2 k d B b S P D l A F O e g M 1 d A 1 q q M G o u g R P a N X 9 G Y 9 W S / W u / U x G V 2 w p j t 7 6 A + s z x / / H p d Y &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X + y 9 t B 3 e J 6 Z V 3 i o 0 F o j R T O K M 8 4 w = " &gt; A A A C C X i c b V D L S s N A F J 3 4 r P V V d e l m s A g V p C Q i 6 E Y o u t F d B f u A J o T J Z N I O n U z C z I 1 Y Q r d u / B U 3 L h R x 6 x + 4 8 2 + c P h b a e l a H c + 7 l 3 n O C V H A N t v 1 t L S w u L a + s F t a K 6 x u b W 9 u l n d 2 m T j J F W Y M m I l H t g G g m u G Q N 4 C B Y O 1 W M x I F g r a B / N f J b 9 0 x p n s g 7 G K T M i 0 l X 8 o h T A k b y S / i m k v r x M Q 5 9 e Y R d t 3 i B b e w C e 4 A c J w o P s e O X y n b V H g P P E 2 d K y m i K u l / 6 c s O E Z j G T Q A X R u u P Y K X g 5 U c C p Y M O i m 2 m W E t o n X d Y x V J K Y a S 8 f J x n i Q 6 O E O D K n o 0 Q C H q u / N 3 I S a z 2 I A z M Z E + j p W W 8 k / u d 1 M o j O v Z z L N A M m 6 e R Q l A k M C R 7 V g k O u G A U x M I R Q x c 2 v m P a I I h R M e U V T g j M b e Z 4 0 T 6 q O X X V u T 8 u 1 y 2 k d B b S P D l A F O e g M 1 d A 1 q q M G o u g R P a N X 9 G Y 9 W S / W u / U x G V 2 w p j t 7 6 A + s z x / / H p d Y &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " X + y 9 t B 3 e J 6 Z V 3 i o 0 F o j R T O K M 8 4 w = " &gt; A A A C C X i c b V D L S s N A F J 3 4 r P V V d e l m s A g V p C Q i 6 E Y o u t F d B f u A J o T J Z N I O n U z C z I 1 Y Q r d u / B U 3 L h R x 6 x + 4 8 2 + c P h b a e l a H c + 7 l 3 n O C V H A N t v 1 t L S w u L a + s F t a K 6 x u b W 9 u l n d 2 m T j J F W Y M m I l H t g G g m u G Q N 4 C B Y O 1 W M x I F g r a B / N f J b 9 0 x p n s g 7 G K T M i 0 l X 8 o h T A k b y S / i m k v r x M Q 5 9 e Y R d t 3 i B b e w C e 4 A c J w o P s e O X y n b V H g P P E 2 d K y m i K u l / 6 c s O E Z j G T Q A X R u u P Y K X g 5 U c C p Y M O i m 2 m W E t o n X d Y x V J K Y a S 8 f J x n i Q 6 O E O D K n o 0 Q C H q u / N 3 I S a z 2 I A z M Z E + j p W W 8 k / u d 1 M o j O v Z z L N A M m 6 e R Q l A k M C R 7 V g k O u G A U x M I R Q x c 2 v m P a I I h R M e U V T g j M b e Z 4 0 T 6 q O X X V u T 8 u 1 y 2 k d B b S P D l A F O e g M 1 d A 1 q q M G o u g R P a N X 9 G Y 9 W S / W u / U x G V</formula><formula xml:id="formula_9">h pm &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L b W 5 o G r A c e R B U U 9 k G 4 j w x 2 o F m 6 A = " &gt; A A A B 7 n i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V o R 6 L X j x W s B / Q L k s 2 z b a h S T Y k W a E s / R F e P C j i 1 d / j z X 9 j 2 u 5 B W x 8 M P N 6 b Y W Z e r D g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p m D T T h L Z J y l P d i 7 G h n E n a t s x y 2 l O a Y h F z 2 o 0 n d 3 O / + 0 S 1 Y a l 8 t F N F Q 4 F H k i W M Y O u k 7 j j K V S R m U b X m 1 / 0 F 0 D o J C l K D A q 2 o + j U Y p i Q T V F r C s T H 9 w F c 2 z L G 2 j H A 6 q w w y Q x U m E z y i f U c l F t S E + e L c G b p w y h A l q X Y l L V q o v y d y L I y Z i t h 1 C m z H Z t W b i / 9 5 / c w m N 2 H O p M o s l W S 5 K M k 4 s i m a / 4 6 G T F N i + d Q R T D R z t y I y x h o T 6 x K q u B C C 1 Z f X S e e q H v j 1 4 O G 6 1 r w t 4 i j D G Z z D J Q T Q g C b c Q w v a Q G A C z / A K b 5 7 y X r x 3 7 2 P Z W v K K m V P 4 A + / z B 5 s 4 j 7 s = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L b W 5 o G r A c e R B U U 9 k G 4 j w x 2 o F m 6 A = " &gt; A A A B 7 n i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V o R 6 L X j x W s B / Q L k s 2 z b a h S T Y k W a E s / R F e P C j i 1 d / j z X 9 j 2 u 5 B W x 8 M P N 6 b Y W Z e r D g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p m D T T h L Z J y l P d i 7 G h n E n a t s x y 2 l O a Y h F z 2 o 0 n d 3 O / + 0 S 1 Y a l 8 t F N F Q 4 F H k i W M Y O u k 7 j j K V S R m U b X m 1 / 0 F 0 D o J C l K D A q 2 o + j U Y p i Q T V F r C s T H 9 w F c 2 z L G 2 j H A 6 q w w y Q x U m E z y i f U c l F t S E + e L c G b p w y h A l q X Y l L V q o v y d y L I y Z i t h 1 C m z H Z t W b i / 9 5 / c w m N 2 H O p M o s l W S 5 K M k 4 s i m a / 4 6 G T F N i + d Q R T D R z t y I y x h o T 6 x K q u B C C 1 Z f X S e e q H v j 1 4 O G 6 1 r w t 4 i j D G Z z D J Q T Q g C b c Q w v a Q G A C z / A K b 5 7 y X r x 3 7 2 P Z W v K K m V P 4 A + / z B 5 s 4 j 7 s = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L b W 5 o G r A c e R B U U 9 k G 4 j w x 2 o F m 6 A = " &gt; A A A B 7 n i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V o R 6 L X j x W s B / Q L k s 2 z b a h S T Y k W a E s / R F e P C j i 1 d / j z X 9 j 2 u 5 B W x 8 M P N 6 b Y W Z e r D g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p m D T T h L Z J y l P d i 7 G h n E n a t s x y 2 l O a Y h F z 2 o 0 n d 3 O / + 0 S 1 Y a l 8 t F N F Q 4 F H k i W M Y O u k 7 j j K V S R m U b X m 1 / 0 F 0 D o J C l K D A q 2 o + j U Y p i Q T V F r C s T H 9 w F c 2 z L G 2 j H A 6 q w w y Q x U m E z y i f U c l F t S E + e L c G b p w y h A l q X Y l L V q o v y d y L I y Z i t h 1 C m z H Z t W b i / 9 5 / c w m N 2 H O p M o s l W S 5 K M k 4 s i m a / 4 6 G T F N i + d Q R T D R z t y I y x h o T 6 x K q u B C C 1 Z f X S e e q H v j 1 4 O G 6 1 r w t 4 i j D G Z z D J Q T Q g C b c Q w v a Q G A C z / A K b 5 7 y X r x 3 7 2 P Z W v K K m V P 4 A + / z B 5 s 4 j 7 s = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L b W 5 o G r A c e R B U U 9 k G 4 j w x 2 o F m 6 A = " &gt; A A A B 7 n i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V o R 6 L X j x W s B / Q L k s 2 z b a h S T Y k W a E s / R F e P C j i 1 d / j z X 9 j 2 u 5 B W x 8 M P N 6 b Y W Z e r D g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p m D T T h L Z J y l P d i 7 G h n E n a t s x y 2 l O a Y h F z 2 o 0 n d 3 O / + 0 S 1 Y a l 8 t F N F Q 4 F H k i W M Y O u k 7 j j K V S R m U b X m 1 / 0 F 0 D o J C l K D A q 2 o + j U Y p i Q T V F r C s T H 9 w F c 2 z L G 2 j H A 6 q w w y Q x U m E z y i f U c l F t S E + e L c G b p w y h A l q X Y l L V q o v y d y L I y Z i t h 1 C m z H Z t W b i / 9 5 / c w m N 2 H O p M o s l W S 5 K M k 4 s i m a / 4 6 G T F N i + d Q R T D R z t y I y x h o T 6 x K q u B C C 1 Z f X S e e q H v j 1 4 O G 6 1 r w t 4 i j D G Z z D J Q T Q g C b c Q w v a Q G A C z / A K b 5 7 y X r x 3 7 2 P Z W v K K m V P 4 A + / z B 5 s 4 j 7 s = &lt; / l a t e x i t &gt; h dn &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k Q M D l A A U r i s W a X / f A 1 U P z Q v S q E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i x 6 8 V j B f k A b w m Y z a Z d u N m F 3 I 5 T Q H + H F g y J e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F m e D a u O 6 3 s 7 a + s b m 1 X d m p 7 u 7 t H x z W j o 4 7 O s 0 V w z Z L R a p 6 I d U o u M S 2 4 U Z g L 1 N I k 1 B g N x z f z f z u E y r N U / l o J h n 6 C R 1 K H n N G j Z W 6 o 6 C I A j k N a n W 3 4 c 5 B V o l X k j q U a A W 1 r 0 G U s j x B a Z i g W v c 9 N z N + Q Z X h T O C 0 O s g 1 Z p S N 6 R D 7 l k q a o P a L + b l T c m 6 V i M S p s i U N m a u / J w q a a D 1 J Q t u Z U D P S y 9 5 M / M / r 5 y a + 8 Q s u s 9 y g Z I t F c S 6 I S c n s d x J x h c y I i S W U K W 5 v J W x E F W X G J l S 1 I X j L L 6 + S z m X D c x v e w 1 W 9 e V v G U Y F T O I M L 8 O A a m n A P L W g D g z E 8 w y u 8 O Z n z 4 r w 7 H 4 v W N a e c O Y E / c D 5 / A I p p j 7 A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k Q M D l A A U r i s W a X / f A 1 U P z Q v S q E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i x 6 8 V j B f k A b w m Y z a Z d u N m F 3 I 5 T Q H + H F g y J e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F m e D a u O 6 3 s 7 a + s b m 1 X d m p 7 u 7 t H x z W j o 4 7 O s 0 V w z Z L R a p 6 I d U o u M S 2 4 U Z g L 1 N I k 1 B g N x z f z f z u E y r N U / l o J h n 6 C R 1 K H n N G j Z W 6 o 6 C I A j k N a n W 3 4 c 5 B V o l X k j q U a A W 1 r 0 G U s j x B a Z i g W v c 9 N z N + Q Z X h T O C 0 O s g 1 Z p S N 6 R D 7 l k q a o P a L + b l T c m 6 V i M S p s i U N m a u / J w q a a D 1 J Q t u Z U D P S y 9 5 M / M / r 5 y a + 8 Q s u s 9 y g Z I t F c S 6 I S c n s d x J x h c y I i S W U K W 5 v J W x E F W X G J l S 1 I X j L L 6 + S z m X D c x v e w 1 W 9 e V v G U Y F T O I M L 8 O A a m n A P L W g D g z E 8 w y u 8 O Z n z 4 r w 7 H 4 v W N a e c O Y E / c D 5 / A I p p j 7 A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k Q M D l A A U r i s W a X / f A 1 U P z Q v S q E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i x 6 8 V j B f k A b w m Y z a Z d u N m F 3 I 5 T Q H + H F g y J e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F m e D a u O 6 3 s 7 a + s b m 1 X d m p 7 u 7 t H x z W j o 4 7 O s 0 V w z Z L R a p 6 I d U o u M S 2 4 U Z g L 1 N I k 1 B g N x z f z f z u E y r N U / l o J h n 6 C R 1 K H n N G j Z W 6 o 6 C I A j k N a n W 3 4 c 5 B V o l X k j q U a A W 1 r 0 G U s j x B a Z i g W v c 9 N z N + Q Z X h T O C 0 O s g 1 Z p S N 6 R D 7 l k q a o P a L + b l T c m 6 V i M S p s i U N m a u / J w q a a D 1 J Q t u Z U D P S y 9 5 M / M / r 5 y a + 8 Q s u s 9 y g Z I t F c S 6 I S c n s d x J x h c y I i S W U K W 5 v J W x E F W X G J l S 1 I X j L L 6 + S z m X D c x v e w 1 W 9 e V v G U Y F T O I M L 8 O A a m n A P L W g D g z E 8 w y u 8 O Z n z 4 r w 7 H 4 v W N a e c O Y E / c D 5 / A I p p j 7 A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k Q M D l A A U r i s W a X / f A 1 U P z Q v S q E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i x 6 8 V j B f k A b w m Y z a Z d u N m F 3 I 5 T Q H + H F g y J e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F m e D a u O 6 3 s 7 a + s b m 1 X d m p 7 u 7 t H x z W j o 4 7 O s 0 V w z Z L R a p 6 I d U o u M S 2 4 U Z g L 1 N I k 1 B g N x z f z f z u E y r N U / l o J h n 6 C R 1 K H n N G j Z W 6 o 6 C I A j k N a n W 3 4 c 5 B V o l X k j q U a A W 1 r 0 G U s j x B a Z i g W v c 9 N z N + Q Z X h T O C 0 O s g 1 Z p S N 6 R D 7 l k q a o P a L + b l T c m 6 V i M S p s i U N m a u / J w q a a D 1 J Q t u Z U D P S y 9 5 M / M / r 5 y a + 8 Q s u s 9 y g Z I t F c S 6 I S c n s d x J x h c y I i S W U K W 5 v J W x E F W X G J l S 1 I X j L L 6 + S z m X D c x v e w 1 W 9 e V v G U Y F T O I M L 8 O A a m n A P L W g D g z E 8 w y u 8 O Z n z 4 r w 7 H 4 v W N a e c O Y E / c D 5 / A I p p j 7 A = &lt; / l a t e x i t &gt; h 0 pm &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G m O 1 9 l E R s D M f R D N g 6 X t m l R 2 A B D A = " &gt; A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b R U 9 k V Q Y 9 F L x 4 r 2 F p o l y W b Z t v Q J B u T r F C W / g k v H h T x 6 t / x 5 r 8 x b f e g r Q 8 G H u / N M D M v V p w Z 6 / v f X m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 T Z p p Q l s k 5 a n u x N h Q z i R t W W Y 5 7 S h N s Y g 5 f Y h H N 1 P / 4 Y l q w 1 J 5 b 8 e K h g I P J E s Y w d Z J n e F p l K t I T K J q z a / 7 M 6 B l E h S k B g W a U f W r 1 0 9 J J q i 0 h G N j u o G v b J h j b R n h d F L p Z Y Y q T E Z 4 Q L u O S i y o C f P Z v R N 0 4 p Q + S l L t S l o 0 U 3 9 P 5 F g Y M x a x 6 x T Y D s 2 i N x X / 8 7 q Z T a 7 C n E m V W S r J f F G S c W R T N H 0 e 9 Z m m x P K x I 5 h o 5 m 5 F Z I g 1 J t Z F V H E h B I s v L 5 P 2 e T 3 w 6 8 H d R a 1 x X c R R h i M 4 h j M I 4 B I a c A t N a A E B D s / w C m / e o / f i v X s f 8 9 a S V 8 w c w h 9 4 n z / 8 l o / s &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G m O 1 9 l E R s D M f R D N g 6 X t m l R 2 A B D A = " &gt; A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b R U 9 k V Q Y 9 F L x 4 r 2 F p o l y W b Z t v Q J B u T r F C W / g k v H h T x 6 t / x 5 r 8 x b f e g r Q 8 G H u / N M D M v V p w Z 6 / v f X m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 T Z p p Q l s k 5 a n u x N h Q z i R t W W Y 5 7 S h N s Y g 5 f Y h H N 1 P / 4 Y l q w 1 J 5 b 8 e K h g I P J E s Y w d Z J n e F p l K t I T K J q z a / 7 M 6 B l E h S k B g W a U f W r 1 0 9 J J q i 0 h G N j u o G v b J h j b R n h d F L p Z Y Y q T E Z 4 Q L u O S i y o C f P Z v R N 0 4 p Q + S l L t S l o 0 U 3 9 P 5 F g Y M x a x 6 x T Y D s 2 i N x X / 8 7 q Z T a 7 C n E m V W S r J f F G S c W R T N H 0 e 9 Z m m x P K x I 5 h o 5 m 5 F Z I g 1 J t Z F V H E h B I s v L 5 P 2 e T 3 w 6 8 H d R a 1 x X c R R h i M 4 h j M I 4 B I a c A t N a A E B D s / w C m / e o / f i v X s f 8 9 a S V 8 w c w h 9 4 n z / 8 l o / s &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G m O 1 9 l E R s D M f R D N g 6 X t m l R 2 A B D A = " &gt; A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b R U 9 k V Q Y 9 F L x 4 r 2 F p o l y W b Z t v Q J B u T r F C W / g k v H h T x 6 t / x 5 r 8 x b f e g r Q 8 G H u / N M D M v V p w Z 6 / v f X m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 T Z p p Q l s k 5 a n u x N h Q z i R t W W Y 5 7 S h N s Y g 5 f Y h H N 1 P / 4 Y l q w 1 J 5 b 8 e K h g I P J E s Y w d Z J n e F p l K t I T K J q z a / 7 M 6 B l E h S k B g W a U f W r 1 0 9 J J q i 0 h G N j u o G v b J h j b R n h d F L p Z Y Y q T E Z 4 Q L u O S i y o C f P Z v R N 0 4 p Q + S l L t S l o 0 U 3 9 P 5 F g Y M x a x 6 x T Y D s 2 i N x X / 8 7 q Z T a 7 C n E m V W S r J f F G S c W R T N H 0 e 9 Z m m x P K x I 5 h o 5 m 5 F Z I g 1 J t Z F V H E h B I s v L 5 P 2 e T 3 w 6 8 H d R a 1 x X c R R h i M 4 h j M I 4 B I a c A t N a A E B D s / w C m / e o / f i v X s f 8 9 a S V 8 w c w h 9 4 n z / 8 l o / s &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G m O 1 9 l E R s D M f R D N g 6 X t m l R 2 A B D A = " &gt; A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b R U 9 k V Q Y 9 F L x 4 r 2 F p o l y W b Z t v Q J B u T r F C W / g k v H h T x 6 t / x 5 r 8 x b f e g r Q 8 G H u / N M D M v V p w Z 6 / v f X m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 T Z p p Q l s k 5 a n u x N h Q z i R t W W Y 5 7 S h N s Y g 5 f Y h H N 1 P / 4 Y l q w 1 J 5 b 8 e K h g I P J E s Y w d Z J n e F p l K t I T K J q z a / 7 M 6 B l E h S k B g W a U f W r 1 0 9 J J q i 0 h G N j u o G v b J h j b R n h d F L p Z Y Y q T E Z 4 Q L u O S i y o C f P Z v R N 0 4 p Q + S l L t S l o 0 U 3 9 P 5 F g Y M x a x 6 x T Y D s 2 i N x X / 8 7 q Z T a 7 C n E m V W S r J f F G S c W R T N</formula><formula xml:id="formula_10">S M v V D G c 9 R v Q 4 a J E F q o i 9 8 F a 6 z x k = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 l E 0 G P R i 8 c K t h b a E D a b a b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 y R T D F s s E Y n q h F S j 4 B J b h h u B n V Q h j U O B D + H o Z u o / P K H S P J H 3 Z p y i H 9 O B 5 H 3 O q L F S Z 3 g a 5 F E g J 0 G 1 5 t b d G c g y 8 Q p S g w L N o P r V i x K W x S g N E 1 T r r u e m x s + p M p w J n F R 6 m c a U s h E d Y N d S S W P U f j 6 7 d 0 J O r B K R f q J s S U N m 6 u + J n M Z a j + P Q d s b U D P W i N x X / 8 7 q Z 6 V / 5 O Z d p Z l C y + a J + J o h J y P R 5 E n G F z I i x J Z Q p b m 8 l b E g V Z c Z G V L E h e I s v L 5 P 2 e d 1 z 6 9 7 d R a 1 x X c R R h i M 4 h j P w 4 B I a c A t N a A E D A c / w C m / O o / P i v D s f 8 9 a S U 8 w c w h 8 4 n z / r x 4 / h &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S M v V D G c 9 R v Q 4 a J E F q o i 9 8 F a 6 z x k = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 l E 0 G P R i 8 c K t h b a E D a b a b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 y R T D F s s E Y n q h F S j 4 B J b h h u B n V Q h j U O B D + H o Z u o / P K H S P J H 3 Z p y i H 9 O B 5 H 3 O q L F S Z 3 g a 5 F E g J 0 G 1 5 t b d G c g y 8 Q p S g w L N o P r V i x K W x S g N E 1 T r r u e m x s + p M p w J n F R 6 m c a U s h E d Y N d S S W P U f j 6 7 d 0 J O r B K R f q J s S U N m 6 u + J n M Z a j + P Q d s b U D P W i N x X / 8 7 q Z 6 V / 5 O Z d p Z l C y + a J + J o h J y P R 5 E n G F z I i x J Z Q p b m 8 l b E g V Z c Z G V L E h e I s v L 5 P 2 e d 1 z 6 9 7 d R a 1 x X c R R h i M 4 h j P w 4 B I a c A t N a A E D A c / w C m / O o / P i v D s f 8 9 a S U 8 w c w h 8 4 n z / r x 4 / h &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S M v V D G c 9 R v Q 4 a J E F q o i 9 8 F a 6 z x k = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 l E 0 G P R i 8 c K t h b a E D a b a b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 y R T D F s s E Y n q h F S j 4 B J b h h u B n V Q h j U O B D + H o Z u o / P K H S P J H 3 Z p y i H 9 O B 5 H 3 O q L F S Z 3 g a 5 F E g J 0 G 1 5 t b d G c g y 8 Q p S g w L N o P r V i x K W x S g N E 1 T r r u e m x s + p M p w J n F R 6 m c a U s h E d Y N d S S W P U f j 6 7 d 0 J O r B K R f q J s S U N m 6 u + J n M Z a j + P Q d s b U D P W i N x X / 8 7 q Z 6 V / 5 O Z d p Z l C y + a J + J o h J y P R 5 E n G F z I i x J Z Q p b m 8 l b E g V Z c Z G V L E h e I s v L 5 P 2 e d 1 z 6 9 7 d R a 1 x X c R R h i M 4 h j P w 4 B I a c A t N a A E D A c / w C m / O o / P i v D s f 8 9 a S U 8 w c w h 8 4 n z / r x 4 / h &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S M v V D G c 9 R v Q 4 a J E F q o i 9 8 F a 6 z x k = " &gt; A A A B 7 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 l E 0 G P R i 8 c K t h b a E D a b a b t 0 s 4 m 7 G 6 G E / g k v H h T x 6 t / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 y R T D F s s E Y n q h F S j 4 B J b h h u B n V Q h j U O B D + H o Z u o / P K H S P J H 3 Z p y i H 9 O B 5 H 3 O q L F S Z 3 g a 5 F E g J 0 G 1 5 t b d G c g y 8 Q p S g w L N o P r V i x K W x S g N E 1 T r r u e m x s + p M p w J n F R 6 m c a U s h E d Y N d S S W P U f j 6 7 d 0 J O r B K R f q J s S U N m 6 u + J n M Z a j + P Q d s b U D P W i N x X / 8 7 q Z 6 V / 5 O Z d p Z l C y + a J + J o h J y P R 5 E n G F z I i x J Z Q p b m 8 l b E g V Z c Z G V L E h e I s v</formula><formula xml:id="formula_11">G ? j = 1 L -? L-? i=1 [E i?j -E (i+?)?j ] 2 , (j = 1, ..., 20; 0 ? ? ? L).</formula><p>(4) Here, G ? j is the correlation factor of j th amino acid and L is the continues distance along the protein sequence. Therefore, a protein sequence can be expressed as Eq. 3 using PsePSSM and generates a 20+20?? dimensional feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Drug feature representation</head><p>It has been indicated in some studies that descriptors as molecular structure fingerprints can effectively represent the drug <ref type="bibr" target="#b7">(Ding et al., 2017;</ref><ref type="bibr" target="#b42">Yamanishi et al., 2011)</ref>. For drug molecules, we use the chemical structure of the molecular substructure fingerprints from the PubChem database <ref type="bibr" target="#b16">(Kim et al., 2019)</ref>. For each drug molecule, it defines an 881-dimensional binary vector Q to represent the molecular substructure, where the corresponding bits of the vector are encoded as 1s for existence of substructures and 0s for absence. Therefore, given a drug dn, its fingerprint feature is calculated as Q(dn) = [q1(dn), q2(dn), ...q881(dn)] Fingerprints property is "PUBCHEM_CACTVS_SUBSKEYS" in PubChem SDF files and is Base64 encoded, which provides a textual description by the binary data. The drug feature representations in this work are also consistent with the previous study <ref type="bibr">(Wang et al., 2018a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Problem statement</head><p>Given a set of N proteins P = (p 1 , p 2 , ..., p N ) and a set of M drugs D = (d 1 , d 2 , ..., d M ), our goal is to predict the interaction (I) between pm and dn based on the the protein's PsePSSM: P ? Pse(pm) and the drug's fingerprint: Q(dn), where pm ? P and dn ? D. I(pm, dn) = 1, interaction 0, no interaction (5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">DTI-GAT</head><p>We introduce DTI-GAT, a deep neural network architecture that operates on graph-structured data with attention mechanism for the feature-based DTI prediction task. The overall learning architecture is illustrated in Figure <ref type="figure">1</ref>. DTI-GAT consists of the following main components: First, given the pseudo-position specific scoring matrix (PsePSSM) of each protein and the fingerprint of each drug, a DTI graph is constructed based on the information about interaction target and similarity of local structure. Then, the graph attention network is applied to the built graph to integrate higher-level information and generate embeddings for each protein and drug. A final decoder architecture takes a pair of protein-drug embeddings and predicts the final interaction probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Graph construction</head><p>Given a protein set P = (p 1 , p 2 , ..., p N ),</p><formula xml:id="formula_12">p i ? R p , drug set D = (d 1 , d 2 , ..., d M ), d i ? R d ,</formula><p>and interaction targets set T = (t 1 , t 2 , ..., t k ), t i ? {1, -1}, where p is the PsePSSM feature dimension, d is the fingerprint dimension, we construct a DTI-Graph G(V, E).</p><p>First, we transform the PsePSSM and the fingerprint to the same dimension, so that nodes can be easily aggregated. In our experiment, we use two weight matrices, Wp ? R p?F and W d ? R d?F for transforming protein and drug separately, where F is the feature dimension, and ReLU nonlinearity to transform the feature dimension.</p><formula xml:id="formula_13">p i = ReLU (Wp ? p i ), p i ? R F (6) d i = ReLU (W d ? d i ), d i ? R F (7)</formula><p>Once obtained, then we combine the new protein set P = (p 1 , p 2 , ..., p N ), p i ? R F and the new drug set D</p><formula xml:id="formula_14">= (d 1 , d 2 , ..., d M ), d i ? R F to the graph node set H = (h 1 , h 2 , ..., h K ), h i ? R F ,</formula><p>where each node is represented as a vector. These nodes are linked by undirected edges, e ? {1, -1}, which are generated from the drug-protein interaction, drug-drug and protein-protein similarity.</p><p>The edge set, E, contains two different components: interaction edge and similarity edge. The interaction edge, e i , is either 1 or -1, referring positive relation and negative relation of two nodes. Since the positive relation is from the ground truth interaction targets set, T , the initial graph of the DTI is very sparse and has an imbalanced issue. To solve the above issues, the negative samples are selected randomly from the unidentified drug-target pairs. We assume that the positive sample is a small percentage of all possible samples, so there is a low probability that real interaction will be selected as a negative sample. Actually, the proportions of positive samples detected in each dataset are 0.99%(Enzymes), 3.49%(Ion channels), 2.99%(GPCR) and 6.40%(Nuclear receptors). In the experiment, we choose a negative sample with the same number of positive samples. However, the initial i i "DTI" -2021/7/14 -1:01 -page 4 -#4</p><formula xml:id="formula_15">i i i i i i 4</formula><p>Wang et al.</p><p>interaction edges are only between the drug-protein pairs, which construct a bipartite graph that limit the information flow. In order to aggregate more information, we transform the bipartite graph to a heterogeneous graph, by adding drug-drug and protein-protein similarities. Similarity edge, es, is based on the DTI bipartite graph and its common neighbor information. If the number of two nodes' common positive neighbor or negative neighbor is greater than a threshold, the two nodes will be connected by 1, which means they are similar.</p><formula xml:id="formula_16">es(i, j) = 1, if com_n(h i , h j ) &gt; ? 0, if com_n(h i , h j ) ? ? (<label>8</label></formula><formula xml:id="formula_17">)</formula><p>where com_n is the function to compute the common neighbor of two nodes and ? is the threshold. In our experiment, we use adjacent matrix A ? R K?K to represent E, where K is the number of node.</p><p>The interaction edge connects the protein-drug domain, similarity edge connects protein-protein domain and drug-drug domain separately, that allows information to flow across the entire DTI graph. What's more, positive edge (e.g. 1) means to pull two nodes closer and negative (e.g. -1) means to push them apart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Graph attention network</head><p>Our approach uses Graph Attention Network (GAT) <ref type="bibr" target="#b33">(Veli?kovi? et al., 2017)</ref> to adaptively learn weights for each edge and represent each node by message passing.</p><p>The input of GAT is a set of node feature</p><formula xml:id="formula_18">H = (h 1 , h 2 , ..., h K ), h i ? R F and DTI adjacent matrix A. H contains Hp = (hp 1 , hp 2 , ..., hp m ) and H d = (h d 1 , h d 2 , ..., h dn ) and A is generated by 2.2.1. The output is a new set of node feature, H = (h 1 , h 2 , ..., h K ), h i ? R F .</formula><p>In order to transform input features to higher level features, we apply a weight matrix, W ? R F ?F , to each node.</p><formula xml:id="formula_19">h i = ?(W ? h i ), h i ? R F<label>(9)</label></formula><p>Then we perform a self-attention mechanism on node pair, a : R F ? R F ? R, to compute attention weight, which indicates the importance of n j to n i , n j ? N i , where N i is the neighborhood of n i and itself in DTI graph.</p><formula xml:id="formula_20">w ij = a(h i , h j ), w ij ? R 1<label>(10)</label></formula><p>In GAT layer, the attention mechanism a is a single-layer neural network, parametrized by a weight matrix a ? R 2F . Then the LeakyReLU nonlinearity is applied.</p><formula xml:id="formula_21">w ij = LeakyReLU ( a T [h i ||h j ])<label>(11)</label></formula><p>where . T is transposition and || is the concatenation operation.</p><p>In the general formulation, attention mechanism allows every node to attend on every other node, dropping all structural information. To add graph structure information, we perform mask attention according to the DTI adjacent matrix A, which enables only the neighbor nodes to be attended. Then we normalize the attention weight across all choices of j using the softmax function to make it comparable of different nodes.</p><formula xml:id="formula_22">? ij = Sof tmax j (w ij ) = exp(w ij ) k?N i exp(w ik )<label>(12)</label></formula><p>where N i is the set of h i 's neighborhood and itself.</p><p>After obtaining the normalized attention score, we use message passing to compute a linear combination of the node features and output the final aggregated features of each node.</p><formula xml:id="formula_23">h i = ?( j?N i ? ij W h j ) (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>where ? is a nonlinearity, H is final aggregated features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Final decoder</head><p>The final decoder is a sample neural network, parametrized by a weight matrix W ? R 2F . It takes pairs of drug-protein embeddings, generated by GAT layer(e.g. h i and h j ), as input. Then the two node vector do an element-wise multiplication, p d ? v, v, p, d ? R F . Finally, through a layer of neural network v F ? R 1 and a Sigmoid activate function, produce a probability score indicating whether they interact:</p><formula xml:id="formula_25">s ij = Sigmoid(ReLU (W (h i h j )))<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Loss function</head><p>For training DTI-GAT, we assign a binary class label 0, 1 (interact or not) to each identified drug-protein pair. We assign positive labels to interacted drug-protein pairs and negative labels to non-interacted drugprotein pairs. The output is the interaction probability. The main learning objective is to minimize the following binary cross entropy loss (BCELoss) between the target X = (x 1 , x 2 , ..., x N ), x i ? {0, 1} and the output Y = (y 1 , y 2 , ..., y N ), y i ? (0, 1). The loss can be described as:</p><formula xml:id="formula_26">l(x, y) = {l 1 , l 2 , ..., l N } T (15) ln = -wn[yn ? log xn + (1 -yn) ? log (1 -xn)]<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5">Implementation details</head><p>In this experiment, we use PyTorch <ref type="bibr" target="#b25">(Paszke et al., 2019)</ref> for efficient GPUbased implementation and PyTorch geometric <ref type="bibr" target="#b8">(Fey and Lenssen, 2019)</ref> for a sparse Graph Attention Layer.</p><p>The DTI-GAT contains the feature (PsePSSM, Fingerprint) encoder, the GAT embedding module and a final interaction decoder. Feature encoder is implemented as two MLP layers for protein and drug respectively. The input dimensions are 220 (PsePSSM) and 881 (fingerprint) and the output dimensions are both 256. The GAT embedding module consists of a Multi-head GAT layer, based on PyTorch geometric <ref type="bibr" target="#b8">(Fey and Lenssen, 2019)</ref>. The hidden dimension and output dimension both are set to 256 for all datasets. In building the adjacency matrix, the setting of the common neighbor threshold is different in different datasets, it is set to 1 in Nuclear Receptor, 3 in GPCR, Ion Channel and Enzyme dataset. The final interaction decoder includes three MLP layers, which input dimension 2 ? 256 = 512 and the hidden dimension is also 256. The output is a scalar, then be computed by a sigmoid function to get the final interaction probability.</p><p>In our paper, the DTI-GAT are trained end-to-end using gradient descent based on Adam optimizer <ref type="bibr" target="#b17">(Kingma and Ba, 2014)</ref>. We perform batch gradient descent using the full dataset for every training iteration, which is a viable option as long as datasets fit in memory. Base on the implementation of PyTorch Geometric <ref type="bibr" target="#b8">(Fey and Lenssen, 2019)</ref>, we use a sparse representation for A. The memory requirement is O(|?|), which is linear in the number of edges. The learning rate ? is 0.0005 and the weight decay is 5e -4. Stochasticity in the training process is by dropout <ref type="bibr" target="#b32">(Srivastava et al., 2014)</ref>, which is set to 0.3. The model is trained until converging for each fold of the cross-validation, for which we set the epoch number to be 4000, 8000, 10000, 15000 for Nuclear Receptor, GPCR, Ion Channel and Enzyme, respectively. i i "DTI" -2021/7/14 -1:01 -page 5 -#5 i i i i i i   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We present the experimental evaluation of the proposed framework on the binary DTI prediction task. The experiments are conducted on the following datasets. q q q q q q q q q q 88 90 92 94 1 2 3 4 5 6 7 8 9 10</p><p>Common neighbor threshold ? Accuracy Fig. <ref type="figure">3</ref>: Performance evaluation on using different hyperparameters for PDI prediction on the Enzyme dataset. The accuracy is reported.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We use the interaction data between drugs and target proteins collected by <ref type="bibr" target="#b40">Yamanishi et al. (2008)</ref>, available at http://web.kuicr.kyotou.ac.jp/supp/yoshi/drugtarget. The dataset is collected from various databases like SuperTarget <ref type="bibr" target="#b9">(G?nther et al., 2007)</ref>, DrugBank <ref type="bibr" target="#b38">(Wishart et al., 2008)</ref>, KEGG BRITE <ref type="bibr" target="#b13">(Kanehisa et al., 2006)</ref>, and BRENDA <ref type="bibr" target="#b27">(Schomburg et al., 2004)</ref>. This dataset includes four main subsets: enzymes, ion channels (IC), G-protein-coupled receptors (GPCR) and nuclear receptors (NR). The statics of the interaction are shown in Table <ref type="table" target="#tab_3">1</ref>.</p><p>We obtained the protein sequence information from UniProt <ref type="bibr" target="#b5">(Consortium, 2019)</ref>, and the drug fingerprint data from PubChem <ref type="bibr" target="#b16">(Kim et al., 2019)</ref>.</p><p>Note that there are a few proteins and drugs that have been removed in the newer version of databases, so we did not include them in our training.</p><p>In addition to the above four benchmark datasets, we also use a dataset called drugbank_approved <ref type="bibr" target="#b1">(Ba-Alawi et al., 2016)</ref>, which contains all FDA-approved drugs and their corresponding protein targets in the DrugBank database <ref type="bibr" target="#b38">(Wishart et al., 2008)</ref>. After removing the non-existing proteins and drugs, the processed dataset contains 1555 drugs and 1591 targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation protocol</head><p>Following the settings in previous works <ref type="bibr">(Wang et al., 2018b,a;</ref><ref type="bibr" target="#b29">Shi et al., 2019)</ref>, we conduct 5-fold cross-validation (CV) on the five datasets of the enzyme, ion channel, GPCR, nuclear receptor and the drugbank_approved. Under the 5-fold CV setting, the data is equally divided into 5 nonoverlapping subsets, and each subset has a chance to train and to test the model so as to ensure an unbiased evaluation. We repeat the prediction model with 10 trials and record the mean and standard deviation of results. We aggregate fix metrics on the test cases of each fold, i.e. the overall accuracy (ACC), precision (PR), sensitivity (SE), specificity (SP), Matthews correlation coefficient (MCC) and Area under the curve (AUC). All these metrics are preferred to be higher to indicate better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baseline methods</head><p>We compare DTI-GAT with the following two groups of baselines:</p><p>1. Classical statistical learning models: SVM <ref type="bibr" target="#b2">(Cao et al., 2012)</ref>, Silico DVM <ref type="bibr" target="#b22">(Li et al., 2017)</ref>, and LRF <ref type="bibr" target="#b29">(Shi et al., 2019)</ref>. 2. Deep learning models: SAE+RF <ref type="bibr">(Wang et al., 2018a)</ref>, DeepDTA <ref type="bibr">?zt?rk et al. (2018)</ref>, and DeepConv-DTI <ref type="bibr" target="#b21">Lee et al. (2019)</ref>.</p><p>Note that LRF has been modified to perform data augmentation on the training set only, to ensure validation and training samples are fully separated. Also, note that DeepDTA is designed for Drug-Target Affinity Regression instead. We adapt it by using a threshold of 0.5 to do a binary classification in order to obtain the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Comparison with other methods</head><p>For the prediction of drug-target interactions, many prediction methods have been proposed. Figure <ref type="figure" target="#fig_2">2</ref> details the comparison between DTI-GAT with other baseline methods on enzymes, ion channels, GPCRs, nuclear receptors and Table <ref type="table" target="#tab_4">2</ref> shows the results on the larger drugbank_approved datasets.</p><p>As shown in Figure <ref type="figure" target="#fig_2">2</ref>, in general, the statistical baselines perform better than the deep learning methods. This shows that deep learning methods are not able to obtain enough information to generalize. The best performing model among them is Silico DVM, a statistical learning model that trains a discriminative vector machine classifier with a local binary pattern generated from PSSM. Our model DTI-GAT can generalize using additional information from the graph, thus achieving better performance than the baseline models. DTI-GAT outperforms Silico DVM on Enzyme, Ion channel and GPCR by 0.014, 0.054, 0.011 on MCC, but Silico DVM outperforms DTI-GAT on nuclear receptor by 0.018 on MCC. This attribute to the fact that DTI-GAT is able to extract more generalizable information from the graph of interaction, especially on a large, dense graph. i i "DTI" -2021/7/14 -1:01 -page 7 -#7</p><formula xml:id="formula_27">i i i i i i DTI-GAT<label>7</label></formula><p>Specifically, we can see that for the dataset of the enzyme, the accuracy rate of DTI-GAT reaches 93.75%, which is higher than other prediction methods. In addition, the AUC of the prediction model reaches 96.32%, comparable with the best performing model LRF of 96.64%. In the ion channel dataset, the accuracy of prediction in this paper is 94.38%, which is also higher than other prediction methods. Our AUC of 96.51%is the highest among other baselines. Similarly in the GPCR dataset, DTI-GAT outperforms all baselines in accuracy, precision, specificity, MCC and AUC. As for the nuclear receptor dataset, our prediction method accuracy rate is 91.11% and our AUC is 90.49%, slightly lower than the best performing Silico DVM. This is mainly due to the fact that the nuclear receptor dataset only contains a very limited number of samples for training and all the deep learning based methods suffers from it. However, we still drastically outperform other neural network based methods including SAE+RF, DeepDTA and DeepConv-DTI.</p><p>The results on the drugbank_approved dataset are shown in Table <ref type="table" target="#tab_4">2</ref>. With this larger dataset, we focus on comparing our model with four other methods including LRF, DeepConv-DTI, DeepDTA and SAE+RF. We can see from the table that the performances for all the methods drop by 5% to 10% comparing to the previous cross-validation results. This is because the larger drugbank_approved dataset contains more complicated and new protein-drug interactions, which make the learning process harder. However, the accuracy rate of DTI-GAT reaches 87.67% and the AUC of DTI-GAT reaches 92.30%, which are still higher than all the baseline methods and relatively robust in identifying new interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Independent Study</head><p>To show the generalizability of DTI-GAT, we evaluate the performance of different methods on an independent dataset. We construct the independent dataset using the five datasets we discussed in Table <ref type="table" target="#tab_3">1</ref>. This independent study dataset consists of a training set of enzyme, IC, GPCR and NR. The testing set comprises of the drugbank_approve dataset, with the proteindrug pairs that appear in the training set removed. Since the proteins and drugs have different names in different sources, we perform the matching and removal by directly comparing the PsePSSM and the fingerprints. After removing the similar sequences, we obtain the independent with 1883 drugs and 2048 proteins. Among them, 5113 interactions are used for training and the rest 5315 interactions are used for independent testing. Using this dataset, we can examine the ability of DTI-GAT to generalize the prediction to a larger protein network from a subset of networks.</p><p>We compare DTI-GAT with four baselines including SAE+RF, DeepDTA, DeepConv-DTI, and LRF. As shown in Table <ref type="table" target="#tab_5">3</ref>, DTI-GAT outperforms other methods by achieving the highest accuracy of 72.9%, sensitivity of 67.36%, MCC of 46.04% and AUC of 78.42%. Notice that LRF achieves high specificity with the cost of getting very low sensitivity, meaning that there are many false negatives (predicting many interactions to be non-interactions), which is not optimal for the DTI prediction task. The comparative results of DTI-GAT on the independent set demonstrate that DTI-GAT can generalize better than other methods to drugs and targets that share low sequence similarity with the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Parameter analysis</head><p>In our work, the main hyperparameter is the common neighbor threshold, ?. It is the key factor of similarity edge, es, for which links the protein and drug domain.</p><p>To further discuss the influence of common neighbors, we choose the Enzyme dataset, which has the most nodes. The result of different settings is illustrated by Figure <ref type="figure">3</ref>. ? = 1 means once two nodes have common neighbors, they will be linked. In our observation, there are some clustered graphs, many different drug nodes are linked to the same protein node. Once ? = 1, these drug nodes will be joined into a fully connected graph, the DTI graph structure and similarity information will be destroyed. That's why the performance of ? = 1 is lower than the others. As the ? increases, the DTI graph includes more and more useful similarity edges, leads to higher accuracy. What's more, if we delete all the es, means ? is infinite, no similarity edge, the score is only 87.01, much lower than others, that proves it is very important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">t-SNE visualization of the node embeddings by DTI-GAT</head><p>The effectiveness of the learned feature representations for each node may also be investigated qualitatively. For this purpose, we provide a visualization of the t-SNE <ref type="bibr" target="#b23">(Maaten and Hinton, 2008)</ref> transformed feature representations extracted by the output layer of the GAT model on the Enzyme dataset. The t-SNE visualizations are generated for both the view of protein nodes and the view of drug nodes as shown in Figure <ref type="figure">4a</ref> and Figure <ref type="figure">4b</ref>, respectively.</p><p>To show the 2D-projection of protein features, we choose the top 4 drugs as labels ordered by their number of connections to all proteins. We then filter out proteins that are not connecting to any of the selected drugs or ambiguously connecting to multiple selected drugs. The feature vectors of the rest proteins outputted by GAT are then transformed into 2D space by t-SNE. Similarly, we choose the top 4 proteins as labels and conduct the same filtering process on the drugs to visualize the drug node features.</p><p>As shown in Figure <ref type="figure">4a</ref>, each dot represents a protein and each color represents the drug that the protein is interacting with. Most proteins except the two blue ones are forming discernible clusters. that these clusters correspond to the labels of the common interacting drugs. Similarly in Figure <ref type="figure">4b</ref>, each dot represent a drug and each color represent the protein that the drug is interacting with. We can also see four clusters are formed based on the learned features of each drug. These two different views of visualizations in 2D space by t-SNE demonstrate that our learned attended vector can capture the important interactions while preserving the properties of each node.</p><p>To demonstrate the biological interpretability of the learned features, in addition to the internal distance within each cluster, we also examine the distance among different clusters. The distance also correlates with the pathway of the labeled proteins. For example, in Figure <ref type="figure">4b</ref>, the blue hsa:759 cluster has only metabolic pathways, and the green hsa:43 and red hsa:4129 clusters both participate in metabolism and other functions. These 3 clusters share the metabolic pathway. The purple one, hsa:1636 instead has pathways in the Renin system. Therefore, hsa:759 is closer to hsa:43 and hsa:4129 comparing to the distance between hsa:759 and hsa:1636.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.5">Attention weight analysis</head><p>To further illustrate the effectiveness of the graph attention approach, we also compute an attention graph from the training, shown in Figure <ref type="figure" target="#fig_5">5</ref>. We generate this figure using the attention value of the edges trained from the Nuclear Receptor dataset. From this graph, the proteins and drugs are able to form groups based on their similarities in the functions. We focus on analyzing two main groups.</p><p>First, we analyze the large group around proteins hsa:2099 (estrogen receptor alpha), hsa:2100 (estrogen receptor beta), and hsa:5241 (progesterone receptor), shown in the purple circle in the figure. The functions of these proteins are very similar. Therefore they are shown as connected and interact with many drugs. The drugs to the right of these proteins consist of a few progesterone receptor agonists (D00182, D00951, D01294, D00066, D00950, D00954, D01217, D02367). For some of the drugs, they only act as progesterone receptors, such as D00951 and D01217, and therefore have a large weight connecting to the progesterone receptor. On the other hand, drugs like Progesterone (D00066) also activate  the estrogen pathway and therefore are connected to the estrogen receptor pathway. Because of there similarity, these drugs also give attention to other drugs with a similar function, lowering the individual attention weight in the cluster. On the smaller cluster on the left of the estrogen receptors, we can also see a similar cluster of estrogen receptor agonists (D00554, D00105, D00067, D00312, D00577, D00898) and estrogen receptor antagonists (D01161). These proteins do not activate progesterone receptors, with a few of them only activate the alpha receptor (D00962, D02217).</p><p>In addition, we analyze the smaller cluster on the top right of the graph, shown in the green box. This cluster is disjoint from the rest of the graph, centered around Vitamin D Receptor (hsa:7421). There are 5 drugs around this receptor, which are the following:</p><p>? Vitamin D2 (Ergocalciferol, D00187) For these drugs, we can see that the receptor has placed more attention weights on the activated versions of the vitamin D (D00930 and D00129). And for these two drug, there are less attention on the receptor. This is because they pay more attention on itself, lowering their attention weight to the receptor. However, our graph is not able to predict the connection between the vitamins and their activated version due to insufficient information.</p><p>We can see that DTI-GAT is able to learn the importance of each interaction from the interaction graph of the dataset. This allows the model to effectively predict the interaction between the drug and the protein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we introduce a novel and comprehensive learning framework to predict the drug-target interactions. Our proposed framework, DTI-GAT, operates on the graph-structured data with the attention mechanism based on the deep neural network architecture. We provide an approach to transform the feature representations of proteins and drugs into a protein-drug interaction graph. We also emphasize the importance of adding the drug-drug and protein-protein similarities to the graph. With the attention mechanism, DTI-GAT can automatically extract the important high-level relationships by assigning different weights to each edge. Extensive experiments of both cross-validation and independent tests conducted on the five datasets demonstrate the promising performance of DTI-GAT. Moreover, we provide case studies to show the interpretability of DTI-GAT. As a future direction, we plan to explore other external knowledge including gene ontology and PPI networks, which can be integrated into DTI-GAT. To further improve the performance, we seek to incorporate the knowledge graph representation learning framework <ref type="bibr" target="#b10">(Hao et al., 2019)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>H 0 e 9 Z m m x P K x I 5 h o 5 m 5 F Z I g 1 J t Z F V H E h B I s v L 5 P 2 e T 3 w 6 8 H d R a 1 x X c R R h i M 4 h j M I 4 B I a c A t N a A E B D s / w C m / e o / f i v X s f 8 9 a S V 8 w c w h 9 4 n z / 8 l o / s &lt; / l a t e x i t &gt; h 0 dn &lt; l a t e x i t s h a 1 _ b a s e 6 4 = "</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 1: Architecture of DTI-GAT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: Evaluation of DTI prediction on the four datasets based on 5-fold cross-validation under 6 evaluation metrics. We report the mean and standard deviation for the test sets for all methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Fig. 4: t-SNE visualization of the protein (a) and drug (b) nodes embeddings generated by DTI-GAT on the Enzyme dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Attention graph of DTI-GAT on NUC.</figDesc><graphic url="image-1.png" coords="8,113.38,158.11,233.12,426.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>? activated Vitamin D2 (Paricalcitol, D00930) ? Vitamin D3 (Cholecalciferol, D00188) ? activated Vitamin D3 (Calcitriol, D00129) ? a synthetic vitamin D analog (Dihydrotachysterol, D00299)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Number of drugs, target and their interactions for 5 datasets used for cross-validation.</figDesc><table><row><cell></cell><cell cols="5">Enzyme IC GPCR NR Drugbank_approved</cell></row><row><cell>Drugs</cell><cell>445</cell><cell>210</cell><cell>223</cell><cell>54</cell><cell>1555</cell></row><row><cell>Targets</cell><cell>663</cell><cell>204</cell><cell>95</cell><cell>26</cell><cell>1591</cell></row><row><cell cols="4">Interactions 2925 1476 635</cell><cell>90</cell><cell>5831</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Evaluation of DTI prediction on the drugbank_approved dataset based on 5-fold cross-validation under 6 evaluation metrics. We report the mean and standard deviation for the test sets.</figDesc><table><row><cell></cell><cell></cell><cell>Acc Sen</cell><cell>Prec Spec Mcc Auc</cell></row><row><cell>SAE+RF*</cell><cell cols="2">mean 82.60 82.75 82.39 82.54 66.05 88.31</cell></row><row><cell></cell><cell>std</cell><cell>1.24 1.35 1.16 1.07 1.29 0.31</cell></row><row><cell>DeepDTA*</cell><cell cols="2">mean 82.13 83.61 81.29 80.65 64.34 87.36</cell></row><row><cell></cell><cell>std</cell><cell>0.96 1.76 2.15 2.94 1.92 0.77</cell></row><row><cell cols="3">DeepConv-DTI mean 84.54 83.44 85.31 85.65 69.02 91.73</cell></row><row><cell></cell><cell>std</cell><cell>0.65 0.72 0.83 0.98 1.21 0.34</cell></row><row><cell>LRF*</cell><cell cols="2">mean 86.11 83.45 88.18 88.78 72.38 92.20</cell></row><row><cell></cell><cell>std</cell><cell>0.45 2.40 1.13 1.56 0.77 0.75</cell></row><row><cell>DTI-GAT</cell><cell cols="2">mean 87.67 81.12 93.34 94.21 76.00 92.30</cell></row><row><cell></cell><cell>std</cell><cell>0.95 2.24 0.60 0.65 1.69 0.83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Evaluation of DTI predictions by different methods on the independent study set.</figDesc><table><row><cell></cell><cell>Acc Sen</cell><cell>Prec Spec Mcc Auc</cell></row><row><cell>SAE-RF*</cell><cell cols="2">64.20 55.30 69.30 77.30 32.10 71.20</cell></row><row><cell>DeepDTA*</cell><cell cols="2">64.82 67.33 59.80 62.75 29.95 73.04</cell></row><row><cell cols="3">DeepConv-DTI 68.60 58.50 73.20 78.60 37.90 74.30</cell></row><row><cell>LRF*</cell><cell cols="2">71.38 45.89 73.19 92.37 44.02 75.70</cell></row><row><cell>DTI-GAT</cell><cell cols="2">72.90 67.36 75.54 78.39 46.04 78.42</cell></row></table></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The source code and all datasets are available at https://github.com/Haiyang-W/DTI-GRAPH</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Drug-target network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1119" to="1127" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Daspfind: new efficient method to predict drug-target interactions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ba-Alawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale prediction of drug-target interactions using protein sequences and drug topological structures</title>
		<author>
			<persName><forename type="first">D.-S</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytica chimica acta</title>
		<imprint>
			<biblScope unit="volume">752</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multifaceted protein-protein interaction prediction based on siamese residual rcnn</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="305" to="314" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Drug-target interaction prediction by random walk on the heterogeneous network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular BioSystems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1970" to="1978" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uniprot: a worldwide hub of protein knowledge</title>
		<author>
			<persName><forename type="first">U</forename><surname>Consortium</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="506" to="D515" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Key factors in the rising cost of new drug discovery and development</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Gagnon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews Drug discovery</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="417" to="429" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Identification of drug-target interactions via multiple information integration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">418</biblScope>
			<biblScope unit="page" from="546" to="560" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Supertarget and matador: resources for exploring drug-target relationships</title>
		<author>
			<persName><forename type="first">S</forename><surname>G?nther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">suppl_1</biblScope>
			<biblScope unit="page" from="919" to="D922" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1709" to="1719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Structure and organization of drugtarget networks: insights from genomic approaches for drug discovery</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Janga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tzakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular BioSystems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1536" to="1548" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Protein secondary structure prediction based on position-specific scoring matrices</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of molecular biology</title>
		<imprint>
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">From genomics to chemical genomics: new developments in kegg</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kanehisa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">suppl_1</biblScope>
			<biblScope unit="page" from="354" to="D357" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Computer-aided drug discovery and development (caddd): in silico-chemico-biological approach</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kapetanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemico-biological interactions</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="176" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting new molecular targets for known drugs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Keiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">462</biblScope>
			<biblScope unit="issue">7270</biblScope>
			<biblScope unit="page" from="175" to="181" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pubchem 2019 update: improved access to chemical data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1102" to="D1109" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Can the pharmaceutical industry reduce attrition rates?</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Landis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews Drug discovery</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="711" to="716" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Large-scale prediction of drug-target relationships</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FEBS letters</title>
		<imprint>
			<biblScope unit="volume">582</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1283" to="1290" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deepconv-dti: Prediction of drug-target interactions via deep learning with convolution on protein sequences</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1007129</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">In silico prediction of drug-target interaction networks based on drug chemical structure and protein sequences</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">2008. Nov</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deepdta: deep drug-target binding affinity prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>?zt?rk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="821" to="829" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alch?-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modulation of protein-protein interactions for the development of novel therapeutics</title>
		<author>
			<persName><forename type="first">I</forename><surname>Petta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular Therapy</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="707" to="718" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Brenda, the enzyme database: updates and major new developments</title>
		<author>
			<persName><forename type="first">I</forename><surname>Schomburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">suppl_1</biblScope>
			<biblScope unit="page" from="431" to="D433" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improved protein structure prediction using potentials from deep learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicting drug-target interactions using lasso with random forest based on evolutionary information and chemical structure</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1839" to="1852" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Biological synthesis of nanoparticles from plants and microorganisms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in biotechnology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="588" to="599" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Computational prediction of protein-protein interactions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Skrabanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular biotechnology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">56</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A computational-based method for predicting drug-target interactions by using stacked autoencoder deep neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Biology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="361" to="373" />
		</imprint>
	</monogr>
	<note>(2018a)</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Rfdt: A rotation forest-based predictor for predicting drug-target interactions using drug structure and protein sequence information</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Protein and Peptide Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="445" to="454" />
			<date type="published" when="2018">2018b)</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Computationally probing drug-protein interactions via support vector machine</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Letters in Drug Design &amp; Discovery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="370" to="378" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep-learning-based drug-target interaction prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of proteome research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1401" to="1409" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Drugbank: a knowledgebase for drugs, drug actions and drug targets</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Wishart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">suppl_1</biblScope>
			<biblScope unit="page" from="901" to="D906" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Semi-supervised drug-protein interaction prediction from heterogeneous biological spaces</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMC systems biology</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">S6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Prediction of drug-target interaction networks from the integration of chemical and genomic spaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamanishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="232" to="240" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Drug-target interaction prediction from chemical, genomic and pharmacological data in an integrated framework</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamanishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="246" to="254" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Extracting sets of chemical substructures and protein domains governing drug-target interactions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamanishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1183" to="1194" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mutation effect estimation on protein-protein interactions using deep contextualized representation learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NAR Genomics and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
