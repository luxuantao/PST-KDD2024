<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">User-Level Psychological Stress Detection from Social Media Using Deep Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Huijie</forename><surname>Lin</surname></persName>
							<email>linhuijie@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education 3 Machine Intelligence Laboratory</orgName>
								<orgName type="department" key="dep2">College of Computer Science</orgName>
								<orgName type="laboratory">TNList and Key Laboratory of Pervasive Computing</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Jia</surname></persName>
							<email>jjia@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education 3 Machine Intelligence Laboratory</orgName>
								<orgName type="department" key="dep2">College of Computer Science</orgName>
								<orgName type="laboratory">TNList and Key Laboratory of Pervasive Computing</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Quan</forename><surname>Guo</surname></persName>
							<email>guoquanscu@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Yuanyuan</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lianhong</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ministry of Education 3 Machine Intelligence Laboratory</orgName>
								<orgName type="department" key="dep2">College of Computer Science</orgName>
								<orgName type="laboratory">TNList and Key Laboratory of Pervasive Computing</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Feng</surname></persName>
							<email>fengling@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<postCode>2014</postCode>
									<settlement>Orlando</settlement>
									<region>Florida</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">User-Level Psychological Stress Detection from Social Media Using Deep Neural Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Retrieval]: Information Retrieval and Indexing Algorithms, Human Factors Stress detection</term>
					<term>convolutional neural network</term>
					<term>cross auto encoders</term>
					<term>deep learning</term>
					<term>micro-blog</term>
					<term>social media</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is of significant importance to detect and manage stress before it turns into severe problems. However, existing stress detection methods usually rely on psychological scales or physiological devices, making the detection complicated and costly. In this paper, we explore to automatically detect individuals' psychological stress via social media. Employing real online micro-blog data, we first investigate the correlations between users' stress and their tweeting content, social engagement and behavior patterns. Then we define two types of stress-related attributes: 1) low-level content attributes from a single tweet, including text, images and social interactions; 2) user-scope statistical attributes through their weekly micro-blog postings, leveraging information of tweeting time, tweeting types and linguistic styles. To combine content attributes with statistical attributes, we further design a convolutional neural network (CNN) with cross autoencoders to generate user-scope content attributes from low-level content attributes. Finally, we propose a deep neural network (DNN) model to incorporate the two types of userscope attributes to detect users' psychological stress. We test the trained model on four different datasets from major micro-blog platforms including Sina Weibo, Tencent Weibo and Twitter. Experimental results show that the proposed model is effective and efficient on detecting psychological stress from micro-blog data. We believe our model would be useful in developing stress detection tools for mental health agencies and individuals.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION 1.1 Motivation</head><p>Psychological stress is the root cause to many health problems and mental diseases. Chronic stress increases the risk of developing health problems such as insomnia, obesity, heart diseases, cancer etc. <ref type="bibr" target="#b0">[1]</ref>. Many studies have revealed a link between stress and mental diseases like anxiety disorders, depression etc. <ref type="bibr" target="#b1">[2]</ref>. Stress has been a threat to human health for a long time. Time magazine's June 6, 1983 cover story called stress "The Epidemic of the Eighties" and referred to it as our leading health problem (http://www.stress.org/americas-1-healthproblem/). Meanwhile, stress has been progressively worsened and spread recent years. With the rapid development of modern society, many people feel increasingly stressed under the rapid pace of life. Numerous surveys have confirmed that adult Americans are feeling under much more stress than a decade or two ago. A 1996 Prevention magazine survey found that almost 75% feel they have "great stress" one day a week and with more than 30% indicating they feel this way more than twice a week, which is 55% compared to the same survey conducted in 1983 (http://www.anxietycentre.com/stress.shtml). In a word, the rapid increase of stress has become a great challenge to human health and life quality.</p><p>Psychological stress detection remains a large problem at the present stage. Detecting and managing stress before it turns into severe problems is of significant importance. Recent decades, many efforts have been devoted to stress detection by researchers from diverse areas. They have developed many methods to measure psychological stress, including psychological questionnaire based interviews <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> and physiological signal based measures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. However, these methods have their limitations in many aspects. Psychological questionnaires often contain a range of questions designed by psychologists. People are usually unwilling to do these questionnaires unless they have to. Physiological methods usually require professional devices to measure users' physiological and biochemical properties and need specialists to analyze the acquired data. Thus, it is very important and useful to find a way to detect user's stress state reliably, automatically and non-invasively.</p><p>With the fast development of social networks, people are widely using social media platforms to share their thoughts and feelings. A statistic report from statisticbrain.com (http://www.statisticbrain.com/twitter-statistics/) shows that by 2014.1.1, the total number of active registered users on Twitter has reached more than 645 million, with an average 58 million tweets posted per day. As for Sina weibo (the largest micro-blog platform in China), the number of weibo users has reached more than 600 million (http://www.comsoc.org/blog?page=3). People post tweets containing text and images on micro-blog platforms to share opinions, express emotions, record daily routines and communicate with friends. We can obtain linguistic and visual content that may indicate stress related symptoms. This makes the detection of users' psychological stress through their tweets and posting patterns from micro-blog feasible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Related Work</head><p>Existing methods for stress detection. Many efforts have been devoted to developing convenient tools for individual stress detection recent years. Researchers are trying to leverage pervasive devices like personal computers and mobile phones for routine stress detection. Hong L. etc. <ref type="bibr" target="#b6">[7]</ref> proposed StressSense to unobtrusively recognize stress from human voice using smartphones. Paredes, P. etc. <ref type="bibr" target="#b7">[8]</ref> investigated the initial lab evidence of the use of a computer mouse in the detection of stress. However, such applications rely on collecting one's real-life data, which is easy to trigger antipathy. It makes stress detection invasive to normal life, and can't be used widely in more people.</p><p>Researches on using social media for healthcare. With the rapid spread of social networks, researches on using social media data for physical and mental healthcare are also increasingly growing. Sadilek et al. <ref type="bibr" target="#b8">[9]</ref> leverage Tweeter postings to identify the spread of flu symptoms. Paul M.J. etc. <ref type="bibr" target="#b9">[10]</ref> apply the Ailment Topic Aspect Model to over 1.5 million health related tweets and discover correlations between behavioral risk factors and aliments. Munmun etc. <ref type="bibr" target="#b10">[11]</ref> leverage behavioral cues indicated from Twitter postings to predict depression before it is reported. These studies show the feasibility of harnessing social media data for developing healthcare tools. However, they mainly leverage the textual content in the social media data, while other equally important content, like images and social behavior are ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep learning approaches for cross-media data modeling.</head><p>Micro-blog data is typical cross-media data. Items may come from diverse sources and modalities. It is difficult to handle the heterogeneous cross-media data. Recent years, extensive researches on deep learning show superior ability of deep neural networks (DNN) in learning features from large scale unlabeled data <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> further extend the deep models for multimodal learning. <ref type="bibr" target="#b16">[17]</ref> design a cross-media learning method based on DNN, and leverage the model for detecting psychological states and corresponding categories from a single tweet. However, stress is a continuous state compared to instant emotions, indicating that the stressed stated can last for several days in psychology <ref type="bibr" target="#b2">[3]</ref>. It remains a challenge to make use of aggregated cross-media data for user-level modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Our Work</head><p>In this paper, we explore the potential to use social media to detect psychological stress for individuals. Micro-blog is one of the most popular social media that can be publicly accessed. People can post text with no more than 140 words, upload images or have social interactions with others. Employing real online micro-blog data, we first investigate the correlations between users' stress and their tweeting content, behavior patterns and social engagement. Then we define two types of stress-related attributes: 1) low-level content attributes from a single tweet, including text, images and social interactions like comments, retweets and favorites; 2) userscope statistical attributes through their weekly micro-blog postings, leveraging information of tweeting time, tweeting types, linguistic styles, and social engagement with friends indicated from the @-mentions and @-replies, etc. To combine low-level content attributes with user-scope statistical attributes, we further design a convolutional neural network (CNN) with cross autoencoders to learn the latent high-level attributes on crossmodal units <ref type="bibr" target="#b16">[17]</ref> <ref type="bibr" target="#b17">[18]</ref>. Finally, we propose a deep neural network (DNN) model to incorporate the two types of user-scope attributes to detect users' psychological stress. The experimental results on four datasets from different Micro-blog platforms indicate the effectiveness and efficiency of the proposed method.</p><p>We have to face several challenges in this work. And the corresponding contributions are:</p><p>1)Challenge 1: Micro-blog platforms contain massive data. It is infeasible to manually label the data. How to find effective methods to automatically label the ground truth remains a challenge. Our solution: Inspired by previous research <ref type="bibr" target="#b18">[19]</ref>, we have built a stressed-twitter-posting database using the "I feel stressed" sentence pattern as the ground-truth label for detecting stress from micro-blog data. With a small set of psychological stress scale score labeled dataset as test, it is proved that our ground truth labeling method is reliable;</p><p>2 ) Challenge 2: Attributes in a tweet come with multiple modalities and the components are often incomplete, which is a typical problem in cross-media. Numbers of tweets in a certain period of time also differ from person to person and from week to week. Traditional models have limited abilities to extract modality-invariant attributes from such data. Our solution: We design a convolutional neural network with cross autoencoders to aggregate low-level content attributes and generate modality-invariant user-scope attributes which support user-level stress detection;</p><p>3)Challenge 3: Modeling stress in user-level is more difficult than in discrete tweet-level, since both the overview and detailed attributes should be concerned about. Our solution: We propose a stress detection model based on DNN to incorporate content attributes and statistical attributes together. The DNN model along with CNN forms a unified integral deep network which can extract attributes from single tweets and detect user-level continuous psychological stress.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DATA OBSERVATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Observation dataset</head><p>We first crawl 350 million tweets data via Sina Weibo's streaming APIs from 2009.10 to 2012.10. Then we collect tweets containing sentence patterns like " I feel stressed this week" and "I feel stressed so much this week" as the weekly stressed state label, and tweets containing "I feel relaxed" and "I feel non-stressed" as the non-stressed state label. The "I feel" pattern has been proved to be  effective as ground truth data labels in emotion analysis in <ref type="bibr" target="#b18">[19]</ref>. In this way, we collect over 19000 weeks of users' tweets that are labeled as stressed, and over 17000 weeks of non-stressed users' tweets. There are 492,676 tweets from 23304 users in total. We take this dataset for observation and further experiments, which is represented by DB1 in this paper. The details of the dataset are shown in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Observation and analysis</head><p>We first conduct a series of analyses on the DB1 and present some patterns related to individuals' psychological stress reflected by tweets. In the analysis, we randomly pick 1000 weeks of stressed and non-stressed tweets from the DB1 and focus on the following aspects:</p><p>Content correlation: the difference of stressed and nonstressed tweets in tweets' content, including text and images;</p><p>Social engagement correlation: the difference between stressed and non-stressed weekly tweets on users' social interactions with friends via @-mentions, @-replies and tweets' comments, retweets and likes;</p><p>Behavioral correlation: the difference of stressed and nonstressed tweeting behavior in tweeting frequency, tweeting types and tweeting time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Observations on content correlation</head><p>Tweets on micro-blog mainly consist of text and images. We leverage a widely used psychological dictionary LIWC <ref type="bibr" target="#b19">[20]</ref> to measure the most frequently occurred words in stressed and nonstressed tweets text content. The results are shown in Figure <ref type="figure">1</ref>.</p><p>From the figure, we observe that there is evident difference in text content between the stressed and non-stressed tweets. For the stressed tweets, there are more words categories from negative emotions, social, friends and family etc. While for the nonstressed tweets, there exist more word categories from positive emotions, work, health and anxiety etc. As for the image content of tweets, we consider brightness and saturation as observed visual features. The results are shown in Figure <ref type="figure">2</ref>(a) and Figure <ref type="figure">2</ref>(b). From Figure <ref type="figure">2</ref>(a), we can observe that the presence of images with low brightness (&lt;0.3) from stressed class is obviously higher than that from non-stressed class, indicating that stressed users are more likely to post images with lower brightness. As for the saturation distribution in Figure <ref type="figure">2</ref>(b), we observe that the saturation of non-stressed users' images are more likely to be lower (&lt;0.5), while the stressed class is more likely to be in the higher range (&gt;0.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Observations on social engagement correlation</head><p>Micro-blog is an important platform for users to share information and interact with friends. The social interactions on micro-blog usually consist of @-mentions, @-replies, retweets, comments and likes etc. We analyze the correlation between social interactions and users' stress states.</p><p>Figure <ref type="figure" target="#fig_6">3</ref> shows the social interaction patterns from tweets of users in stressed and non-stressed states. The patterns are measured as the proportion of the numbers of comments, likes, retweets, @mentions and @-replies in users' weekly tweets.</p><p>From the figure, we observe that for the non-stressed class, users' tweets get more comments, likes and retweets from friends, indicating that people are generally more likely to interact with the followed users when they are at a non-stressed state. Meanwhile, compared to non-stressed weeks, the stressed weeks have less @-mentions and @-replies of friends. This also proves that stressed users are less social active than non-stressed users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Observations on Behavioral Correlation</head><p>As revealed by psychology theories <ref type="bibr" target="#b0">[1]</ref>, there are many common symptoms may be related to stress, including insomnia, social withdrawal .etc. These symptoms can also be reflected by tweeting behavior changes on micro-blog. We observe tweeting time distributions to measure users' tweeting behavior.</p><p>Figure <ref type="figure">4</ref> shows the results of tweeting time distribution of users from the two classes. Tweeting time distribution is measured in tweet postings in hours of a day. From the result, we observe that there are more stressed postings during 0 to 6 in the morning, revealing that stressed users are more likely to be insomnia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>To very briefly summarize, we have the following intuitions which will be further leveraged and incorporated in our method design:</p><p>The different content of a single tweet including text, image and social interactions are all related to different one's stress state at some point.</p><p>One's stress state can be related to the social engagement with friends in weekly unit.</p><p>One's stress state can also be related to the tweeting behavior on micro-blog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ATTRIBUTES DEFINITION</head><p>The micro-blog data is a typical type of cross-media data, containing text, emoticons, images and social interactions.</p><p>Besides, the patterns of micro-blog usage behavior in a period such as one week unit also contain useful information for stress detection. To leverage both content information contained in single cross-media micro-blog tweet and the micro-blog usage behavior in weekly tweets, guided by psychological theories, we define two sets of attributes to measure the differences of the stressed and non-stressed users on micro-blog: 1) content attributes from the content of a single tweet; 2) statistical attributes from the users' behavior of weekly tweet postings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Content Attributes</head><p>The content of a tweet from micro-blog usually consists of text, image and social interaction. We define linguistic, visual and social attributes from each part of a tweet respectively as follows:</p><p>1) Linguistic Attributes: As users usually express their emotions using tweets, we measure the emotions in a single tweet using linguistic attributes. To describe the linguistic attributes, we leverage a psychological dictionary named "Language Inquiry and Word Count Dictionary" <ref type="bibr" target="#b19">[20]</ref>. The simplified Chinese LIWC dictionary <ref type="bibr" target="#b20">[21]</ref> is developed by Chinese psychologists and linguists, based on the psycholinguistic dictionary LIWC (http://www.liwc.net), which has been proved to be effective on determining affect in Twitter. It is composed of almost 4500 words and categorized into over 60 categories <ref type="bibr" target="#b19">[20]</ref>. Based on the dictionary, we define the text content related features as the tweet's linguistic attributes:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive and Negative Emotion Words (2 dimension).</head><p>Measured by the number of positive and negative emotion words in the tweet's text, indicating how positive or negative emotions are expressed in the tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive and Negative Emoticons (2 dimensions).</head><p>Measured by the number of positive and negative emotions. Emoticons are widely used in micro-blog platforms to express users' emotional states. We manually categorize the 129 emoticons provided by Sina Weibo platform into positive and negative categories. Punctuation Marks and Associated Emotion Words (4 dimensions). We use this attribute to signify the intensity of emotion in a tweet, either positive or negative according to the associated emotional words. Four typical punctuation marks (exclamation mark, question mark, dot mark and the Chinese full stop mark "。") are considered. Degree Adverbs and Associated Emotion Words (2 dimensions). Degree adverbs are also used to express the degree of emotions. For example, "I feel a little bit sad" and "I feel terribly sad" express different level of negative feelings. We use a number range of 1-3 to represent neural, moderate and severe degrees of positive expression and the minus to represent the negative ones. Thus, we get 10-dimensional vector to denote the linguistic attributes from a tweet's text content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>Visual Attributes: Based on previous work on affective image classification <ref type="bibr" target="#b21">[22]</ref> and color psychology theories <ref type="bibr" target="#b22">[23]</ref>, we combine the following features as the visual middle-level representation:</p><p>Five-color theme (15 dimensions): a combination of five dominant in the HSV color space, representing the main color distribution of an image. It has been revealed to have important impact on human emotions according to psychology and art theories <ref type="bibr" target="#b21">[22]</ref>. Saturation (2 dimensions): the mean value of saturation and its contrast. Brightness (2 dimensions): the mean value of brightness and its contrast. Warm or cool color (1 dimension): ratio of cool colors with hue ([0-360]) in the HSV space between 30 and 110. Clear or dull color (1 dimension): ratio of colors with brightness ([0-1]) and saturation less than 0.6. Thus, based on the psychological studies and color theories, we finally get a 21 dimensional attributes from the tweet's image content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3)</head><p>Social Attributes: Besides the text content and image content of a tweet, some additional features like comments, retweets and likes indicate the tweet's social attention from one's friends. They can also imply one's stress state to some degree. We use the number of comments, retweets and likes of a tweet to measure the tweet's social attention degree into social attributes. Thus, we get a 3dimensional vector to represent the social attributes of a tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Statistical Attributes</head><p>Statistical attributes are summarized from users' tweets in a specific sampling period. We use one week as the sampling period in this paper. On one hand, psychological stress often results from cumulative events or mental states; on the other hand, users may express their chronic stress in a series of tweets rather than one. Appropriately designed statistical attributes can provide a macroscope of a user's stress states, and avoid noise or missing data. We define statistical attributes from three aspects to measure the differences between stressed and non-stressed states based on users' weekly tweet postings. The details of the statistical attributes are described as follows:</p><p>1) Social Engagement:</p><p>We consider 3 measures to characterize the social engagement from users' weekly tweet postings: the @-mentions, @-replies and the retweets from a user's friend. These three behaviors are the most commonly used ways to interact with friends on microblog platforms. Unlike the social attributes in a single tweet, the social engagement attributes are measured in numbers of @mentions and @-replies in weekly tweet postings, indicating one's social interaction activeness with friends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Behavioral Attributes:</head><p>We define a set of behavioral measures for users, including tweeting time and tweeting types, based on the weekly tweet postings. These measures are described as follows:</p><p>Tweeting time:</p><p>Tweeting time can indicate users' daily routines at some point. We consider two measures that derive from the tweeting time information of tweets: tweeting frequency and tweeting time distribution. Tweeting frequency is measured in the average number of tweets posted in a day, while tweeting time distribution is measured in numbers of tweets posted in hours with a 24 dimensional vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweeting Type:</head><p>Users usually post tweets on micro-blog with diverse motivations, making the tweets to be presented in different types. We categorize users' tweets into mainly four types: 1) image tweets (tweets containing images) 2) original tweets (tweets that are originally posted by tweets' users) 3) information query tweets 4) information sharing tweets (tweets that contain outside hyperlinks). We use a 4-dimensional vector of the numbers of tweets in the above 4 types respectively to represent the tweeting type attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Linguistic Style:</head><p>We introduce measures to characterize linguistic styles in users' weekly tweet postings using the psychological dictionary LIWC <ref type="bibr" target="#b19">[20]</ref>. LIWC categorizes frequently-used words into more than 60 categories. We adapt 10 categories from LIWC that are related to daily life, social events, e.g.: personal pronouns, home, work, money, religion, death, health, ingestion, friends and family. We extract words from users' weekly tweet postings and use a 10 dimensional vector of numbers of words in the 10 categories to represent the linguistic style attribute. Different from the linguistic attributes of a single tweet which mainly measures the emotions, the linguistic style can measure one's linguistic behavior in aggregated tweets. As described in section 3, we define low-level content attributes from each single tweet in tweet-scope, and statistical attributes from aggregated tweets in user-scope. In tweet-scope, we concern about the low-level content attributes of a single tweet as defined in Section 3.1, while in user-scope, we concern about one's states reflected by several tweets in a period. These two sets of attributes cannot be combined directly since their mathematical descriptions are not in the same domain. So we need to generate latent userscope content attributes from low-level content attributes at first. After that, both of the two user-scope attribute sets, including the content attributes and statistical attributes, can be finally fed into a classifier for user-level stress detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. List of notations used in</head><p>In the following sections, we will address our solution through the following two key components: 1) First we design a convolutional neural network with cross autoencoders to generate user-scope content attributes from low-level content attributes, thus the tweet-scope content attributes can be combined with the userscope statistical attributes; 2) We propose a deep neural network model to incorporate the two types of user-scope attributes for user-level psychological stress detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cross auto encoders</head><p>Rather than summarizing the user's state alone, we further incorporate the detail attributes with multiple modalities of every tweets by utilizing a recently proposed cross-media model, namely the Cross Autoencoders (CAE) <ref type="bibr" target="#b16">[17]</ref>.</p><p>An auto encoder is a basic unit in deep neural networks for learning distinctive attributes from data <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. It is a shallow network containing one hidden layer and paired input/output layers. The network is trained to reconstruct input pattern from activation of the hidden layer, which is actually stimulated by the input itself. The reconstruction can be formulated by</p><formula xml:id="formula_0">(1)</formula><p>where is the input pattern and is the activation of hidden units. denotes the reconstruction result from the hidden units. and are the connection weights while and are bias to the postsynaptic units. and are activation functions of the units, where sigmoid functions are rational choice in many scenario. In this work, we use the following sigmoid function as activation function of all neurons:</p><p>(2)</p><p>and its derivative is then given by .</p><p>To train the autoencoder to reconstruct input pattern and learn distinctive attributes on the hidden layer, we minimize the following performance function by updating the parameter set with gradient descent</p><formula xml:id="formula_1">(3)</formula><p>where the second term is a regularization to prevent model over fitting which is known as weight decay.</p><p>In order to learn attributes robust to partial corruption of the input pattern, <ref type="bibr">Vincent et</ref>  </p><p>where is the modality specified mapping and is data of modality . Denoting as the set of all modalities, is the set of modalities that data are available with.</p><p>is the encoder layer weight matrix while is the bias. is the activation function of hidden neurons and is activities of them. The last equation represents the decoder part.</p><p>is the weight matrix and is the bias. is the activation function of reconstruction neurons.</p><p>is the reconstruction for all modalities in the problem domain.</p><p>CAE can be trained with standard gradient descent algorithms, but with a special designed data set. Data available with all modalities are used for training. The network is fed with data which contain combination of modalities. Error feedback is calculated on all modalities and updates the network by back-propagation. The new performance function can be formulated by <ref type="bibr" target="#b4">(5)</ref> where we explicitly denote as a deterministic function of .</p><p>Figure <ref type="figure" target="#fig_2">5</ref> demonstrates a comparison on structure of standard autoencoder and CAE. The key idea here is, as data with is presented, data with all modalities are required to reconstruct. One limitation of this training method is that, in a real world problem, data with all modalities are rare. To make use of more data available with a couple of (not all) modalities, we further employ the Extended Feature Learning (EFL) phase. In this phase, error feedback is calculated for available modalities. Thus the performance function is given by <ref type="bibr" target="#b5">(6)</ref> where is the set of available modalities.</p><p>It has to be noticed that EFL should be carried out after initial training of CAE that general correlation between modalities are learned. Otherwise the network may tend to learn trivial attributes for each modality as mentioned in <ref type="bibr" target="#b14">[15]</ref>.</p><p>Micro-blog data is typical cross-media data. It consists of text body, emoticons, attached images, replies and retweets from other users etc. Meanwhile, these parts do not necessarily exist for any tweet item. Using CAE, we can model tweets to capture relationship of information with different modalities and learn modality-invariant attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Convolutional neural networks with CAE</head><p>The attributes of tweets from a user's weekly tweet postings in timeline form a time-series. To further model a user as a subject of series of tweets, we apply Convolutional Neural Networks (CNN) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b24">25]</ref>. CNNs have large learning capacity while having much fewer connections and parameters to learn comparing to similar size standard network layer. They focus on learning stationary local attributes for series like images (pixel series), speeches and other time-series. We can learn user-scope content attributes from a series of single tweet in time-series to describe one's stress state in a week.</p><p>After this step, all attributes of tweets in time-series are formed to a 1-Dimensional series. Figure <ref type="figure" target="#fig_3">6</ref> demonstrates a 2-D unit (left) which is often used in image processing and a 1-D unit (right) which is used in our model.</p><p>We propose to use CAE rather than standard units in CNN for tweet-series. 1) On one hand, CAE units works directly on multimodality attributes of tweets because CAE can learn modalityinvariant attributes of tweets directly. Consequently the generated attribute maps are also modality-invariant and the rest of the network can work in modality-invariant domain. 2) On the other hand, individuals may have fewer tweets than the patch size of convolutional units. We call it "missing tweet" phenomenon. In such case, we cannot apply attribute extraction with standard units, while we can handle such users with CAE by treating their tweetseries as incomplete patches.</p><p>Figure <ref type="figure" target="#fig_4">7</ref> presents a detailed view of CNN with CAE units. Each cylinder is a tweet instance with multiple modalities. Red circles with cross are attributes with missing modalities. The cylinders form a 1-D sequence along the time-line in a week. The leftmost red crosses are 'missing tweet' instances when the patch is applied to the first instance of the week. In our case, three continuous instances make a patch. CAE units are listed in the attribute maps. They connect to a patch of instance. CAE units take patches with ℎ missing modalities as well as 'missing' instance, and generate the modality-invariant attribute maps. The CAE units are used as filters in the 1D CNN (Fig. <ref type="figure" target="#fig_4">7</ref>) and convolute over the sequence of tweets to form one feature map. Thus the latent user-scope attributes can be generated from the low-level attributes from the single tweets.  Pooling is another important step to summarize attribute maps into fewer attribute instances. Though different users have different number of tweets in different weeks, the period of time that the tweets are sampled are the same. We simply pool each attribute map into one pooled attribute. There are two commonly used pooling operations: max-pooling and mean-pooling. When max pooling is used, the pooled attribute unit is assigned with the maximally activation among all units in the attribute map. When mean-pooling is applied, the mean of activations of all units in the attribute map is assigned to the pooled attribute unit. Since we pool over the period of time rather than a certain number of tweets, we consider using mean-over-instances (MOI) and mean-overtime (MOT). Mean-over-instances is simply the average value of activations of the units while mean-over-time can be calculated by summing up the activations since they are sampled in same length of time. We test all the three pooling methods in our experiments in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Classifiers</head><p>Through the key steps in the above section, we get two types of user-scope attributes: content attributes learnt by CNN with CAE units, and the manually defined statistical attributes (Section 3.2). We can measure one's stress using these user-scope attributes now. Determining the stress states of a user can be formulated as a typical binary classification problem. In general, any state-of-theart classifier can be utilized to predict one's stress states with the extracted attributes. In our work, we focus on using a deep neural network (DNN) over the extracted attributes for classification <ref type="bibr" target="#b13">[14]</ref>.</p><p>Deep neural networks have shown superior ability in a variety of classification tasks. The deep architecture of the network can further learn higher-level semantically related attributes from the user-scope attributes. Since both the content attributes learnt by CNN with CAE units and the manually defined statistical attributes are modality-invariant, we use standard fully-connected layers of stacked autoencoders and classify with a final logistic regression unit. A 4-layer architecture is used in this paper. Figure <ref type="figure" target="#fig_5">8</ref> demonstrates an overall architecture of our proposed model with DNN classifier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS 5.1 Experimental setup</head><p>Dataset. We perform our experiments on four datasets DB1-DB4 collected from three different micro-blog platforms: Sina Weibo, Tencent Weibo 1 , and Twitter. DB1 from Sina Weibo has the most number of tweets and users which has been described in Section 2, Table <ref type="table" target="#tab_0">1</ref>. The details of the other 3 datasets are shown in Table <ref type="table">3</ref>. The Tencent Weibo (DB3) and Twitter (DB4) are labeled using the sentence pattern method described in Section 2. Especially, to avoid the noise in data ground truth, we establish a small scale dataset DB2 from Sina Weibo. DB2 is collected from the users that have shared the score of a psychological stress scale 2 with 50 items via Sina Weibo. If the resulted score is over 80, then the test subject is claimed to be stressed. We crawl the shared scores and the corresponding users' information and weeks' tweets. In this way, for DB2 we finally get 98 weeks of stressed tweets (scale 5 http://t.qq.com another popular micro-blog platform in China. Comparison Methods. We compare the following classification methods for user-level psychological stress detection:</p><p>Naive Bayes (NB) is a simple probabilistic classifier based on Bayes' theorem that calculates the posterior probability by calculating prior probability of attributes. The classifier assigns sample with the largest calculated posterior <ref type="bibr" target="#b25">[26]</ref>. Support Vector Machine (SVM) is a popular and binary classifier that is proved to be effective on a huge category of classification problems. It tries to find a hyperplane that divides training samples into their classes with maximum margin <ref type="bibr" target="#b26">[27]</ref>. In our problem we use SVM with RBF kernel which can handle most nonlinear binary classifications better.</p><p>Random Forest (RF) is an ensemble learning method for decision trees by building a set of decision trees with random subsets of attributes and bagging them for classification results <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deep Neural Network (DNN).</head><p>The proposed model in this paper. We use a 4-layer DNN with a softmax classifier for the detection task. We also evaluate the influence of using different size of networks.</p><p>Measures. For a fully investigation of proposed methods, we consider the following aspects:</p><p>Performance. To evaluate the detection performance of our method, we evaluate the results with Accuracy and F1-score. True Negative (TN): non-stressed user sample correctly determined (true) as non-stressed (negative). Accuracy is the proportion of correct prediction or true results among testing samples. More formally it is given by <ref type="bibr" target="#b6">(7)</ref> F1-score, on the other hand, considers both the precision and recall of the result, which is given by <ref type="bibr" target="#b7">(8)</ref> Efficiency. We evaluate efficiency of the methods by comparing the CPU time of training each model. All experiments are conducted on a server running a Windows 7, with Intel(R) Core(TM) i7-3930K CPU @ 3.20GHz (12 CPUs) and 32 GB RAM. For DNN, we add up both pretraining time and fine-tuning for a fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Detection Performance</head><p>To evaluate the effectiveness of the proposed model, we first perform a fully test against large-scale DB1 from Sina Weibo. We consider working with statistical attributes and content attributes extracted by proposed CNN with CAE from cross-modal tweets data of a week respectively, and then using both of them together. For the pooling method, we also test the all three methods: max pooling, mean-over-instance (MOI) pooling and mean-over-time (MOT) pooling. For comprehensive comparisons, we test SVM, RF, NB as well as the proposed DNN as classifiers in this experiment. For this experiment, a 4-layer DNN is used. Table <ref type="table" target="#tab_2">4</ref> demonstrates the results of extensive experiments. Regarding different classifiers, SVM gets an accuracy of 75.62% and F1-score 0.8341 using both attributes together and max pooling. RF gets similar results where the accuracy is 76.75% and F1-score is 0.8341. NB does not work well with statistical attributes. It gets its best result working with content based attribute alone using MOI pooling. The proposed DNN classifier reaches the overall best performance with an accuracy of 78.57% and F1-score of 0.8443. Classification using two types of attributes together with MOT pooling outperforms all the baselines. It achieves a ~3% improvement over SVM and ~2% improvement over RF. When it works with the single type of attribute or other pooling methods it also get competitive results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Detection Performance</head><p>To evaluate the effectiveness of the proposed model, we first perform a fully test against large-scale DB1 from Sina Weibo. We consider working with statistical attributes and content attributes extracted by proposed CNN with CAE from cross-modal tweets data of a week respectively, and then using both of them together. For the pooling method, we also test the all three methods: max pooling, mean-over-instance (MOI) pooling and mean-over-time (MOT) pooling. For comprehensive comparisons, we test SVM, RF, NB as well as the proposed DNN as classifiers in this experiment. For this experiment, a 4-layer DNN is used. Table <ref type="table" target="#tab_2">4</ref> demonstrates the results of extensive experiments. Regarding different classifiers, SVM gets an accuracy of 75.62% and F1-score 0.8341 using both attributes together and max pooling. RF gets similar results where the accuracy is 76.75% and F1-score is 0.8341. NB does not work well with statistical attributes. It gets its best result working with content based attribute alone using MOI pooling. The proposed DNN classifier reaches the overall best performance with an accuracy of 78.57% and F1-score of 0.8443. Classification using two types of attributes together with MOT pooling outperforms all the baselines. It achieves a ~3% improvement over SVM and ~2% improvement over RF. When it works with the single type of attribute or other pooling methods it also get competitive results. As for comparison with previous work, due to the different goal, our results are not comparable with <ref type="bibr" target="#b16">[17]</ref>. Actually, the most related user-level prediction work is <ref type="bibr" target="#b10">[11]</ref>, with the best result of 74% for a binary choice. Our model can achieve a more compelling result of 84%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Factor Contribution Analysis</head><p>Impact of content and statistical attributes: Table <ref type="table" target="#tab_2">4</ref> also reveals the impact of two types of attributes. With solely statistical or content attribute, all classifiers get fair results around accuracy of 70%. While both types of attributes are used, there is a growth of about 5%. Trend of F1-score is similar that using both types of attributes provides a better result. These results show the effectiveness of combining both classes of attributes, which also prove that the proposed model is reliable for user-level stress detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of pooling methods:</head><p>Comparison results using max pooling, MOI pooling and MOT pooling are also shown in Table <ref type="table" target="#tab_2">4</ref>. We can see that MOT pooling gets an obvious better result working with DNN. When SVM or RF is considered, all three methods get similar results and max pooling is fractionally ahead in all three pooling methods. In summary, MOT is a better choice for high performance detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of different modalities in content attributes:</head><p>Tweets content come with multiple modalities. To evaluate the contribution of each data modality, we conduct experiments with different combination of attributes. Since text is the necessary part of a tweet, we test using solely text attributes, using combination of text and visual attributes, using combination of text and social attributes, as well as using all attributes.</p><p>As shown in Table <ref type="table" target="#tab_6">5</ref>, we report predict performance of using content attributes (composed with only the named attributes in Table <ref type="table" target="#tab_6">5</ref>) alone as well as combining with statistical attributes.</p><p>Using just text attribute gains rather high performance. Simply combining visual or social attributes even reduces the result, especially the social attributes. This trend is even more obvious when both types of attributes (content and statistical) are used.</p><p>Nevertheless, using all attributes together outperforms using only text attributes. Highest detection performance is observed when using all attribute and working with both types of attributes. We measure the overall quality by final detection performance. In order to focus the discussion on neural network model, we evaluate with all attributes and only use content attributes. Figure <ref type="figure" target="#fig_9">9</ref> shows the trend of detection performance with different proportion of training data. In our case, the size of time series sets is the number of weeks. We pretrain with all data in DB1 (Table <ref type="table" target="#tab_0">1</ref>) and each filter is trained with roughly 1M patches when 100% data is used. We can see the advantage of using larger training set from the result.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Model Efficiency</head><p>For the classification models aforementioned, we also consider their efficiency performance. Though the training of model can be done offline, efficiency is still a considerable factor for evaluating an algorithm. For DNN model, we sum up both pre-training phase and finetuning phase. Table <ref type="table" target="#tab_4">7</ref> lists the CPU time of each model to train with all labeled data. The results show that training DNN takes around 5 hours which is still reasonable while it get the best detection performance results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Results on Other Datasets</head><p>We further evaluate our model on other datasets DB2-DB4 to show that our model is a universal model. For this part of experiments, we use statistical attributes together with content attributes using MOT pooling, and with 4-layer DNN model. DB4 from Twitter. We also test against the twitter dataset. We still use the attribute extractor trained with large scale Sina Weibo dataset and only finetune the network with Twitter dataset in 5-fold. The accuracy is 67.43% and f1-score is 0.7224. One reason for this modest result is that users in Twitter dataset and Sina Weibo dataset come from different language and culture background. Another factor could be that the scale of this dataset is rather small. Subjects in the Twitter dataset are on the order of 10% of large scale Sina Weibo dataset. We look into the collected data and find that, by coincidence, all tweets in this dataset have no social activity. We suggest this is also a cause of the unsatisfactory result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DB2 from</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper, we present a user-level psychological stress detection from users' weekly micro-blog data. First we use the sentence patterns like "I feel stressed" to collect the ground truth labeled microblog data in week unit. Then we define a set of low-level content attributes from single tweet's text, images and social interactions. We also present a variety of statistical attributes like behavioral attributes, social engagement and linguistic style attributes from users' weekly tweet postings. A convolutional neural network with cross autoencoders is designed to aggregate weekly low-level content attributes and generate user-scope attributes. Finally we propose a deep neural network model to further learn attributes in user-scope and predict users' stress. In our proposed method, the userscope attribute extractor and classification model forms a uniform deep architecture which bridges the gap between each single tweet and user's psychological stress state. We test the model on four different datasets from major micro-blog platforms with different scales and ground truth labeling methods, and deeply discuss the influence of model parameters on experimental results. The results show that the proposed model is effective and efficient on detecting psychological stress from micro-blog data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .Figure 2 (Figure 2 (Figure 3 .Figure 4 .</head><label>12234</label><figDesc>Figure 1. The proportion of top 12 most frequently occurred word categories from non-stressed and stressed weeks of tweets</figDesc><graphic url="image-5.png" coords="3,54.00,179.35,243.15,71.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>the following sections. . An input pattern to the network Hidden activation of units in an AE Reconstruction of input pattern from an AE Connection weight matrix of layer in a network Activation bias of units of layer in a network Activation function of units of layer in a network Sigmoid function and its derivate The set of parameters in a network Performance function of a network Weight decay penalty Set of all modalities in the problem domain Number of modalities in the problem domain Subset of modalities, whose elements are actually presented to the network An input pattern with modality An input pattern with modalities in set Modality specified mapping of modality Weight matrix of modality Reconstruction of input pattern with modality from CAE Reconstruction of input pattern with modalities in set from CAE Subset of modalities, whose elements are available in dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Comparison of standard autoencoder and CAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. CNN units for 2-D convolution and 1-D convolution.</figDesc><graphic url="image-70.png" coords="7,54.00,245.44,241.26,139.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. CNN with CAE units.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Overall architecture of the proposed model with DNN classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Table 3 .</head><label>3</label><figDesc>6 http://types.yuzeli.com/survey/pstr50 The details of the collected tweet dataset DB2-DB4 from different micro-blog platforms. ) and 112 weeks of non-stressed tweets (scale score &lt; 80) as a small but reliable ground truth data to further validate the reliability of the sentence pattern based ground truth labeling method.In the following experiments, we first train and test our model on the large-scale Sina Weibo dataset DB1. Then we further test our model on the other 3 datasets to show effectiveness of the proposed model on different data sources or different ground truth labeling methods. For all of our analyses, we use 5-fold cross validation, over 10 randomized experimental runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>By dividing user samples as stressed (positive) and nonstressed (negative) ones, detection results of testing data can be categorized into the following classes: True Positive (TP): stressed user sample correctly detected (true) as stressed (positive). False Negative (FN): stressed user sample incorrectly determined (false) as non-stressed (negative). False Positive (FP): non-stressed user sample incorrectly detected (false) as stressed (positive).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>of scale of data. Model learning of the proposed CNN attributes extraction model with CAE is a key link of the whole framework. The model is trained in unsupervised scheme and takes advantage of large-scale unlabeled data. DNN classifier model also utilizes large-scale training data. We investigate the impact of data scale on training the network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Influence of data scale in training, measured in accuracy.We use DB1(Table1) in this experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . The details of the observation dataset (DB1).</head><label>1</label><figDesc></figDesc><table><row><cell>Tweets' label</cell><cell>Number of tweets</cell><cell>Number of users</cell><cell>Number of weeks</cell><cell>Number of tweets per week</cell></row><row><cell>Non-Stressed</cell><cell>253638</cell><cell>12230</cell><cell>17861</cell><cell>14.2</cell></row><row><cell>Stressed</cell><cell>239038</cell><cell>11074</cell><cell>19136</cell><cell>12.5</cell></row><row><cell>Summation</cell><cell>492676</cell><cell>23304</cell><cell>36997</cell><cell>13.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 . Comparison of results using different classification models.</head><label>4</label><figDesc></figDesc><table><row><cell>Pooling</cell><cell>Classifier</cell><cell>SVM</cell><cell>RF</cell><cell>NB</cell><cell>DNN</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 ) in this experiment. Impact of size of network.</head><label>1</label><figDesc>Size of network is a critical issue in setting up DNN model. Shallow networks result in trivial model that cannot catch any underlying correlation in data, whereas too deep networks lead to over-complex model which is difficult to tune and may suffer from problems like over-fitting. To choose an appropriate DNN model for classification, we test DNN with different number of layers.Table6summarizes the experiment results. It is clear that 2-layer is not enough for the model to get a satisfactory result. 3-layer model improve significantly while 4-layer model reaches the peak. 5-layer model does not get better result. This is mainly due to the network is too large that it cannot be tuned to a good local minimum with available data and within a feasible training time.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7 . Comparison of results using more classifiers.</head><label>7</label><figDesc>Sina Weibo with PSTR label. We use a matured model trained with large scale Sina Weibo dataset, and then test it against another set of subject independently sampled from Sina Weibo. For the test set, we collect weekly tweets from the users that have shared the score of a psychological stress scale with 50 items via Sina Weibo. Detection result shows that the test accuracy is 74.13% and f1-score is 0.7778, which approves that the overall model is consistent and the sentence pattern based ground truth labeling method is reliable.</figDesc><table><row><cell>0.65 0.67 0.69 0.71 0.73 0.75</cell><cell>0.6553</cell><cell>0.7136 0.7098 0.7167 0.7201 0.7216 0.7227</cell></row><row><cell></cell><cell cols="2">1.0% 10.0% 20.0% 40.0% 60.0% 80.0% 100.0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 . Comparison of results using different number of layers in DNN.</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell>Accuracy</cell><cell>F1-score</cell></row><row><cell>DNN-2</cell><cell>0.6843</cell><cell>0.7926</cell></row><row><cell>DNN-3</cell><cell>0.7816</cell><cell>0.8423</cell></row><row><cell>DNN-4</cell><cell>0.7857</cell><cell>0.8443</cell></row><row><cell>DNN-5</cell><cell>0.7762</cell><cell>0.8386</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 . Comparison of results using different attributes.</head><label>5</label><figDesc>We test on data collected from another major Chinese Micro-blog platform. For this test, we use the attribute extractor trained with large scale Sina Weibo dataset and only finetune the network with Twitter dataset in 5-fold. The accuracy is 76.78% and f1-score is 0.7915 which demonstrate the capability of the proposed model.</figDesc><table><row><cell></cell><cell></cell><cell>Text</cell><cell>Text + visual</cell><cell>Text + Social</cell><cell>All</cell></row><row><cell>content</cell><cell>Accuracy F1-score</cell><cell>0.7147 0.8031</cell><cell>0.7187 0.8054</cell><cell>0.7090 0.7993</cell><cell>0.7227 0.8072</cell></row><row><cell>both*</cell><cell>Accuracy F1-score</cell><cell>0.7613 0.8294</cell><cell>0.7610 0.8265</cell><cell>0.7228 0.8011</cell><cell>0.7849 0.8443</cell></row></table><note>*both content and statistical attributes DB3 from Tencent Weibo.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGMENTS</head><p>This work is supported by the National Basic Research Program of China ( 2011CB302201 ) , and also partially supported by (2012CB316401) and the National Natural, and Science Foundation of China (61370023, 61373022). We also thank Microsoft Research Asia-Tsinghua Univertity Joint Laboratory project：FY14-RES-SPONSOR-111 for its funding.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stress and health</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Kasl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of public health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="319" to="341" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stress and depression</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hammen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Clin. Psychol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="293" to="319" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A global measure of perceived stress</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kamarck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mermelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of health and social behavior</title>
		<imprint>
			<biblScope unit="page" from="385" to="396" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparison of two modes of stress measurement: Daily hassles and uplifts versus major life events</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Kanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Coyne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Lazarus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of behavioral medicine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The unfolded protein response: integrating stress signals through the stress sensor IRE1α</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martinon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Glimcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological Reviews</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1219" to="1243" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detecting stress during realworld driving tasks using physiological sensors. Intelligent Transportation Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="156" to="166" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">StressSense: Detecting stress in unconstrained acoustic environments using smartphones</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Frauendorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rabbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Mast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Chittaranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM Conference on Ubiquitous Computing</title>
				<meeting>the 2012 ACM Conference on Ubiquitous Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-09">2012. September</date>
			<biblScope unit="page" from="351" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sensor-less sensing for affective computing and stress management technology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pervasive Computing Technologies for Healthcare (PervasiveHealth), 2013 7th International Conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-05">2013. May</date>
			<biblScope unit="page" from="459" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling Spread of Disease from Social Interactions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sadilek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Silenzio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
				<imprint>
			<date type="published" when="2012-06">2012. June</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">You are what you Tweet: Analyzing Twitter for public health</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
				<imprint>
			<date type="published" when="2011-07">2011, July</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Predicting depression via social media</title>
		<author>
			<persName><forename type="first">M</forename><surname>De Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Weblogs and Social Media</title>
				<imprint>
			<date type="published" when="2013-07">2013, July</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning multiple layers of representation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="428" to="434" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multimodal deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
				<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multimodal Learning with Deep Boltzmann Machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2231" to="2239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Psychological Stress Detection from Cross-media Microblog Data Using Deep Sparse Neural Network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of IEEE International Conference on Multimedia &amp; Expo</title>
				<meeting>IEEE International Conference on Multimedia &amp; Expo</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">We feel fine and searching the emotional web</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Kamvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining</title>
				<meeting>the fourth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011-02">2011. February</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The psychological meaning of words: LIWC and computerized text analysis methods</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="54" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Developing Simplified Chinese Psychological Linguistic Analysis Dictionary for Microblog</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bibo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingshao</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Brain &amp; Health Informatics (BHI&apos;13)</title>
				<meeting><address><addrLine>Maebashi, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10">2013. Oct. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interpretable aesthetic features for a_ective image classi_cation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
				<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3230" to="3234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Affective image colorization</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1119" to="1128" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
				<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-07">2008, July</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">3361</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="841" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Random forest: a classification and regression tool for compound classification and QSAR modeling</title>
		<author>
			<persName><forename type="first">V</forename><surname>Svetnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Culberson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Feuston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and computer sciences</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1947" to="1958" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
