<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Near-Optimal Instruction Selection on DAGs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ryan</forename><surname>David</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><surname>Koes</surname></persName>
							<email>dkoes@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seth</forename><forename type="middle">Copen</forename><surname>Goldstein</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Near-Optimal Instruction Selection on DAGs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DB9563191A7AF7280675E38FCB11531A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.3.4 [Programming Languages]: Processors-Code generation</term>
					<term>Compilers</term>
					<term>Optimization Algorithm</term>
					<term>Performance Instruction Selection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Instruction selection is a key component of code generation. High quality instruction selection is of particular importance in the embedded space where complex instruction sets are common and code size is a prime concern. Although instruction selection on tree expressions is a well understood and easily solved problem, instruction selection on directed acyclic graphs is NP-complete. In this paper we present NOLTIS, a near-optimal, linear time instruction selection algorithm for DAG expressions. NOLTIS is easy to implement, fast, and effective with a demonstrated average code size improvement of 5.1% compared to the traditional tree decomposition and tiling approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The instruction selection problem is to find an efficient mapping from the compiler's target-independent intermediate representation (IR) of a program to a target-specific assembly listing. Instruction selection is particularly important when targeting architectures with complex instruction sets, such as the Intel x86 architecture. In these architectures there are typically several possible implementations of the same IR operation, each with different properties (e.g., on x86 an addition of one can be implemented by an inc, add, or lea instruction). CISC architectures are popular in the embedded space as a rich, variable-length instruction set can make more efficient use of limited memory resources.</p><p>Code size, which is often ignored in the workstation space, is an important optimization goal when targeting embedded proces-sors. Embedded designs often have a small, fixed amount of onchip memory to store and execute code with. A small difference in code size could necessitate a costly redesign. Instruction selection is an important part of code size optimization since the instruction selector is responsible for effectively exploiting the complexity of the target instruction set. Ideally, the instruction selector would be able to find the optimal mapping from IR code to assembly code.</p><p>In the most general case, instruction selection is undecidable since an optimal instruction selector could solve the halting problem (halting side-effect free code would be replaced by a nop and non-halting code by an empty infinite loop). Because of this, instruction selection is usually defined as finding an optimal tiling of the intermediate code with a set of predefined machine instruction tiles. Each tile is a mapping from IR code to assembly code and has an associated cost. An optimal instruction tiling minimizes the total cost of the tiling. If the IR is a sequence of expression trees, then efficient optimal tiling algorithms exist <ref type="bibr" target="#b2">[3]</ref>. However, if a more expressive directed acyclic graph (DAG) representation <ref type="bibr" target="#b0">[1]</ref> is used the problem becomes NP-complete <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>In this paper we describe NOLTIS, a near-optimal, linear time instruction selection algorithm for expression DAGs. NOLTIS extends existing instruction selection techniques. Empirically it is nearly optimal (an optimal result is found more than 99% of the time and the non-optimal solutions are very close to optimal). We show that NOLTIS significantly decreases code size compared to existing heuristics. The primary contribution of this paper is our near-optimal, linear time DAG tiling algorithm, NOLTIS. In addition, we</p><p>• prove that the DAG tiling problem is NP-complete without relying on restrictions such as two-address instructions, register constraints, or tile label matching,</p><p>• describe an optimal 0-1 integer programming formulation of the DAG tiling problem,</p><p>• and provide an extensive evaluation of our algorithm, as well as an evaluation of other DAG tiling heuristics, including heuristics which first decompose the DAG into trees and then optimally tile the trees.</p><p>The remainder of this paper is organized as follows. Section 2 provides additional background and related work. Section 3 formally defines the problem we solve as well as proves its hardness. Section 4 describes the NOLTIS algorithm. Section 5 describes a 0-1 integer program formulation of the problem we use to evaluate the optimality of the NOLTIS algorithm. Section 6 describes our implementation of the algorithm. Section 7 provides detailed empirical comparisons of the NOLTIS algorithm with other techniques. Section 8 discusses some limitations of our approach and opportunities for future work, and Section 9 provides a summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>The classical approach to instruction selection has been to perform tiling on expression trees. This was initially done using dynamic programming <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b35">36]</ref> for a variety of machine models including stack machines, multi-register machines, infinite register machines, and superscalar machines <ref type="bibr" target="#b6">[7]</ref>. These techniques have been further developed to yield code-generator generators <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b8">9]</ref> which take a declarative specification of an architecture and, at compilercompile time, generate an instruction selector. These code-generator generators either perform the dynamic programming at compile time <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b13">14]</ref> or use BURS (bottom-up rewrite system) tree parsing theory <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b31">32]</ref> to move the dynamic programming to compilercompile time <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">35]</ref>. In this paper we describe the NOLTIS algorithm, which uses an optimal tree matcher to find a near-optimal tiling of an expression DAG. Although we use a simple compiletime dynamic programming matcher, the NOLTIS algorithm could also easily use a BURS approach to matching.</p><p>Tiling expression DAGs is significantly more difficult than tiling expression trees. DAG tiling has been shown to be NP-complete for one-register machines <ref type="bibr" target="#b7">[8]</ref> and for two-address, infinite register machine models <ref type="bibr" target="#b3">[4]</ref>. Two-address machines have instructions of the form ri ← ri op rj and ri ← rj. Since one of the source operands gets overwritten, the difficulty lies in minimizing the number of moves inserted to prevent values from being overwritten. Even with infinite registers and simple, single node tiles, the move minimization problem is NP-complete although approximation algorithms exist <ref type="bibr" target="#b3">[4]</ref>. DAG tiling remains difficult on a three-address, infinite register machine if the exterior tile nodes have labels that must match <ref type="bibr" target="#b32">[33]</ref>. These labels may correspond to value storage locations (e.g. register classes or memory) or to value types. Such labels are unnecessary if instruction selection is separated from register allocation and if the IR has already fully determined the value types of edges in the expression DAG. However, we show in Section 3 that the problem remains NP-complete even without labels.</p><p>Although DAG tiling is NP-complete in general, for some tile sets it can be solved in polynomial time <ref type="bibr" target="#b14">[15]</ref>. If a tree tiling algorithm is adapted to tile a DAG and a DAG optimal tile set is used to perform the tiling, the result is an optimal tiling of the DAG. Although the tile sets for several architectures were found to be DAG optimal in <ref type="bibr" target="#b14">[15]</ref>, these tile sets used a simple cost model and the DAG optimality of the tile set is not preserved if a more complex cost model, such as code size, is used. For example, if the tiles in Figure <ref type="figure" target="#fig_0">1</ref> all had unit cost, they would be DAG optimal, but with the cost metric shown in Figure <ref type="figure" target="#fig_0">1</ref> they are not.</p><p>Traditionally, DAG tiling is performed by using a heuristic to break up the DAG into a forest of expression trees <ref type="bibr" target="#b4">[5]</ref>. More heavyweight solutions, which solve the problem optimally, include using binate covering <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>, using constraint logic programming <ref type="bibr" target="#b25">[26]</ref>, using integer linear programming <ref type="bibr" target="#b30">[31]</ref> or performing exhaustive search <ref type="bibr" target="#b22">[23]</ref>. In addition, we describe a 0-1 integer programming representation of the problem in Section 5. These techniques all exhibit worst-case exponential behavior. Although these techniques may be desirable when code quality is of utmost importance and compile-time costs are immaterial, we believe that our linear time, near-optimal algorithm provides excellent code quality without sacrificing compile-time performance scalability.</p><p>An alternative, non-tiling, method of instruction selection, which is better suited for linear, as opposed to tree-like, IRs, is to incorporate instruction selection into peephole optimization <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b9">10]</ref>. In peephole optimization <ref type="bibr" target="#b29">[30]</ref>, pattern matching transformations are performed over a small window of instructions, the "peephole." This window may be either a physical window, where the instructions considered are only those scheduled next to each other in the current instruction list, or a logical window where the instructions considered are just those that are data or control related to the instruction currently being scanned. When performing peephole-based instruction selection, the peepholer simply converts a window of IR operations into target-specific instructions. If a logical window is being used, then this technique can be considered a heuristic method for tiling a DAG.</p><p>Instruction selection algorithms have been successfully adapted to solve the technology mapping problem in the automated circuit design domain <ref type="bibr" target="#b24">[25]</ref>. Many domain-specific extensions to the basic tiling algorithm have been proposed (see <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b12">13]</ref> for references), but, to the best of our knowledge, all DAG tiling algorithms proposed in this area have resorted to simple, domain-specific, heuristics for decomposing the DAG into trees before performing the tiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM DESCRIPTION</head><p>Given an expression DAG which represents the computation of a basic block and a set of architecture specific instruction tiles, we wish to find an optimal tiling of the DAG which corresponds to the minimum cost instruction sequence. The expression DAG consists of nodes representing operations (such as add or load) and operands (such as a constant or memory location). We refer to a node with multiple parents as a shared node. The set of tiles consists of a collection of expression trees each with an assigned cost. If a leaf of an expression tree is not an operand, it is assumed that the inputs for that leaf node will be available from a register 1 . Similarly, the output of the tree is assumed to be written to a register. A tile matches a node in the DAG if the root of the tile is the same kind of node as the DAG node and the subtrees of the tile recursively match the children of the DAG node. In order for a tiling to be legal and complete, the inputs of each tile must be available as the outputs of other tiles in the tiling, and all the root nodes of the DAG (those nodes with zero in-degree) must be matched to tiles. The optimal tiling is the legal and complete tiling where the sum of the costs of the tiles is minimized. More formally, we define an optimal instruction tiling as follows:</p><formula xml:id="formula_0">Definition Let K be a set of node kinds; G = (V, E) be a directed acyclic graph where each node v ∈ V has a kind k(v) ∈ K, a set of children ch(v) ∈ 2 V such that ∀ c∈ch(v) (v → c) ∈ E,</formula><p>and a unique ordering of its children nodes ov : ch(v) → {1, 2, ...|ch(v)|}; T be a set of tree tiles ti = (Vi, Ei) where similarly every node vi ∈ Vi has a kind k(vi) ∈ K S {•} such that k(vi) = • implies outdegree(vi) = 0 (nodes with kind • denote the edge of a tile and, instead of corresponding to an operation or operand, serve to link tiles together), children nodes ch(vi) ∈ 2 V i , and an ordering ov i ; and cost : T → Z + be a cost function which assigns a cost to each tree tile. We say a node v ∈ V matches tree ti with root</p><formula xml:id="formula_1">r ∈ Vi iff k(v) = k(r), |ch(v)| = |ch(r)|,</formula><p>and, for all c ∈ ch(v) and ci ∈ ch(r), ov(c) = or(ci) implies that either k(ci) = • or c matches the tree rooted at ci. For a given matching of v and ti and a tree tile node vi ∈ Vi, we define mv,t i : Vi → V to return the node in V that matches with the subtree rooted at vi. A mapping f : V → 2 T from each DAG node to a set of tree tiles is legal iff ∀v ∈ V :</p><formula xml:id="formula_2">ti ∈ f (v) =⇒ v matches ti indegree(v) = 0 =⇒ |f (v)| &gt; 0 ∀ti ∈ f (v), ∀vi ∈ ti, k(vi) = • =⇒ |f (mv,t i (vi))| &gt; 0</formula><p>1 These are unallocated temporaries, not actual hard registers. In a simple cost model where every tile has a unit cost the top tiling would be optimal, but with the cost model shown the lower tiling is optimal.</p><p>An optimal instruction tiling is a legal mapping f which minimizes</p><formula xml:id="formula_3">X v∈V X t i ∈f (v) cost(ti)</formula><p>In some versions of the instruction tiling problem, the name of the storage location a tile writes or reads is important. For example, some tiles might write to memory or read from a specific register class. In this case, there is an additional constraint that a tile's inputs must not only match with other tiles' outputs, but the names of the respective input and output must also match. In practice, if instruction selection is performed independently of register allocation, the names of storage locations are irrelevant. Although previous proofs of the hardness of instruction selection have relied on complications such as storage location naming <ref type="bibr" target="#b32">[33]</ref> or two-address instructions <ref type="bibr" target="#b3">[4]</ref>, we now show that even without these restrictions the problem remains NP-complete. THEOREM 3.1. The optimal instruction tiling problem (is there an optimal instruction tiling of cost less than kconst?) is NPcomplete.</p><p>PROOF. Inspired by <ref type="bibr" target="#b32">[33]</ref>, we perform a reduction from satisfiability of Boolean expressions <ref type="bibr" target="#b19">[20]</ref>. Given a Boolean expression consisting of variables u ∈ U and Boolean connectives {∨, ∧, ¬}, we construct an instance of the optimal instruction tiling problem as follows:</p><p>Let the set of node kinds K be {∨, ∧, ¬, , R, v}. We refer to nodes with kind as box nodes. For every variable u ∈ U , create two nodes u1 and u2 and a directed edge (u1 → u2) in G such that k(u1) = and k(u2) = v. Similarly, for every Boolean operator op create two nodes op1 and op2 and a directed edge (op1 → op2) such that k(op1) = and k(op2) is the corresponding operation. Next, for every operation a op b create edges (op2 → a1) and (op2 → b1) where k(a1) = k(b1) = (in the case of the unary ¬ operation a single edge is created). Note the ordering of child nodes is irrelevant since the Boolean operators are commutative. Finally, create a node r and edge (r → op) such that k(r) = R and op is the root operation of the expression. An example of such a DAG is shown in Figure <ref type="figure" target="#fig_1">2(a)</ref>. Note that the only nodes with potentially more than one parent in this DAG are those box nodes corresponding to variables. Now let the tree tile set T be as shown in Figure <ref type="figure" target="#fig_1">2</ref>(b) where each tile contains a single non-box node and has unit cost. These tiles are designed so that it can be shown that a truth assignment of a Boolean expression corresponds directly with a legal tiling of a DAG constructed as described above. If a variable is true, then its corresponding node is covered with the tile v : T , otherwise it is covered with v : F . The rest of the tiling is built up in the natural way suggested from the tile names in Figure <ref type="figure" target="#fig_1">2(b</ref>). This tiling is optimal since every leaf node of the DAG will have exactly one tile covering it (corresponding to the truth assignment of that variable) and, since the parents of leaf nodes are the only shared nodes in the DAG (they may have multiple parents), no other non-box node in the DAG can be covered by more than one tile in this tiling. Therefore, the cost of the tiling is equal to the number of non-box nodes and is optimal.</p><p>Given an optimal tiling of a DAG derived from a Boolean expression, if the cost of the tiling is equal to the number of non-box nodes, then we can easily construct a truth assignment that satisfies the expression by observing the tiles used to cover the leaves of the DAG. If the cost of the tiling is greater than the number of non-box nodes then the expression is not satisfiable. If it were, a cheaper tiling would have to exist.. We have shown the boolean satisfiability reduces to the optimal instruction tiling problem, and, therefore, the optimal instruction tiling problem is NP-complete.</p><formula xml:id="formula_4">¬ ∨ ∧ R (a ∧ b) ∨ (¬b) va vb (a) R satisfied ∨ T: T ∨ T ∨ T: T ∨ F ∨ T: F ∨ T ∨ F: F ∨ F ¬ F: ¬T ¬ T: ¬F v v: F v v: T (b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">NOLTIS</head><p>The NP-complete nature of the optimal instruction tiling problem necessitates the use of heuristics when performing instruction selection. A common approach is to first decompose the DAG into a forest of trees and then use an optimal tree tiling algorithm to tile each tree. Every common subexpression in the DAG is therefore at the root of a tree in the forest. However, as we will show in Section 7, this approach is not as successful as algorithms which work directly on the DAG. For example, if all the tiles in Figure <ref type="figure" target="#fig_0">1</ref> were assigned a unit cost, the tree decomposition solution would be suboptimal.</p><p>In this section we present NOLTIS, a linear-time algorithm which obtains near-optimal tilings of expression DAGs. The algorithm applies tree tiling directly to the DAG without first performing tree decomposition, uses this tiling to decide which parts of the DAG can be productively decomposed into trees, and then retiles the partially decomposed DAG.</p><p>First we apply dynamic programming on the DAG ignoring the presence of shared nodes using the procedure BOTTOMUPDP from Listing 1. Conceptually, we are tiling the tree that would be formed if every shared node (and its descendants) was duplicated to convert the DAG into a potentially exponentially larger tree. However, the algorithm remains linear since each node is visited only once. Once dynamic programming has labeled each node with the best tile for that node, a top down pass, TOPDOWNSELECT, creates a tiling of the DAG. The existence of shared nodes may result in a tiling where nodes are covered by multiple tiles (i.e., the tiles overlap). However, since no node will be at the root of two tiles (this would imply that the exact same value would be computed twice), the number of tiles in a tiling is proportional to the number of nodes. Consequently, the top down pass, which traverses tiles, has linear time complexity.</p><p>The tiling found by the first tiling pass ignores the impact of shared nodes in the DAG and therefore may have excessive amounts of overlap. In the next step of the algorithm, we identify shared nodes where removing overlap locally improves the overall tiling. These nodes are added to the fixedNodes set. We then perform another tiling pass. In this pass, tiles are prohibited from spanning nodes in the fixedNodes set; these nodes must be matched to the root of a tile.</p><p>The procedure IMPROVECSEDECISIONS (Listing 2) is used to determine if a shared node should be fixed. For each shared node n with overlap we compute the cost of the overlap at n using the GETOVERLAPCOST function in Listing 3. This function computes the cost of the local area of overlap at n. Note that, in the rare case that the area of overlap subsumes another shared node, it is possible that IMPROVECSEDECISIONS will have super-linear time complexity; however, this can be addressed through the use of memoization, a detail which is not shown in the pseudocode.</p><p>The next step is to compute the cost which would be incurred if the tiles covering n were cut so that only a single tile, rooted at n, covered n. The cost of the tile tree rooted at n can be determined from the results of dynamic programming. To this cost we add the costs of cutting the tiles currently covering n, which are computed using the function GETTILECUTCOST shown in Listing 4. In determining the cost of cutting a tile t with root r at node n, we consider every tile which also matches at r and has n as an edge node. We then compute the cost difference between using this tile to match The dynamic programming is then recomputed with the requirement that the fixed node not be overlapped and the optimal solution is found. r and using t. We choose the minimum cost difference as the cost of cutting the tile. If the cost of the current overlapping tiling is more than the cost of removing the overlap and cutting the tiles, then we have found a local transformation which improves the existing tiling. Instead of immediately applying this transformation, we choose to fix node n, disabling overlap when we compute a new tiling. This results in a potentially better solution as the new tiling need not be limited to tiles rooted at r. Figure <ref type="figure" target="#fig_2">3</ref> shows the execution of the NOLTIS algorithm on the example from Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>The NOLTIS algorithm is not optimal as it depends upon several assumptions which do not necessarily hold. We assume that it is always possible to cut tiles at a shared node without affecting the tileability of the DAG. We assume that the best place to cut tiles to eliminate overlap is at a shared node. We assume the decision to fix a shared node can be made independently of other shared nodes. When deciding to fix a shared node we assume we can represent the impact of fixing the node by examining simple tile cuts. Despite these assumptions, in practice the NOLTIS algorithm achieves near-optimal results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">0-1 PROGRAMMING SOLUTION</head><p>In order to establish the near-optimality of our algorithm, we formulate the instruction tiling problem as a 0-1 integer program which can be solved to optimality using a commercial solver. The formulation of the problem is straightforward. For every node i and tile j we have binary variable Mi,j which is one if tile j matches node i (the root of tile j is at node i) in the tiling, zero otherwise. Let costj be the cost of tile j, roots be the root nodes of the DAG, and edgeN odes(i, j) be the nodes at the edge of tile j when rooted at node i, then the optimal instruction tiling problem is:</p><formula xml:id="formula_5">min X i,j costjMi,j subject to ∀i∈roots X j Mi,j &gt;= 1<label>(1)</label></formula><p>∀i,j∀ i ∈edgeN odes(i,j) Mi,j -</p><formula xml:id="formula_6">X j M i ,j ≤ 0<label>(2)</label></formula><p>Listing for n ∈ edgeNodes(bestTile) do 33:</p><p>q.push(n )</p><p>where <ref type="bibr" target="#b0">(1)</ref> requires that the root nodes of the DAG be matched to tiles and (2) requires that if a tile matches a node, then all of the inputs to that tile must be matched to tiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">IMPLEMENTATION</head><p>We have implemented our algorithm in the LLVM 2.1 <ref type="bibr" target="#b28">[29]</ref> compiler infrastructure targeting the Intel x86 architecture on the Ubuntu 7.10 Linux operating system. The default LLVM instruction selector constructs an expression DAG of target independent nodes and then performs a maximal munch algorithm <ref type="bibr" target="#b5">[6]</ref>. Tiles are selected from the top-down. The largest tile (the tile that covers the most nodes) is greedily selected. Tile costs are only used to break ties. We have modified the LLVM algorithm to use code size when breaking ties.</p><p>In addition to the default LLVM algorithm and the NOLTIS algorithm, we have implemented three other algorithms: cse-all The expression DAG is completely decomposed into trees and dynamic programming is performed on each tree. That is, every shared node is fixed. This is the conventional method for applying tree tiling to a DAG <ref type="bibr" target="#b4">[5]</ref>.</p><p>Listing 2 Given a DAG matching that ignored the effect of shared nodes, decide if the solution would be improved by pulling shared nodes out into common subexpressions (eliminating tile overlap). seen.add (t) 7: while ¬q.empty() do 8:</p><p>t ← q.pop() 9:</p><p>cost ← cost + cost(tile) 10:</p><p>for n ∈ edgeNodes(t) do 11:</p><p>if n is reachable from n then 12:</p><formula xml:id="formula_7">t ← bestChoiceForNode[t ].tile 13: if coveringTiles[n ].size() = 1 then 14: cost ← cost + bestChoiceForNode[n ].cost 15:</formula><p>else if t ∈ seen then 16:</p><p>seen.add (t ) 17:</p><p>q.push(t ) 18: return cost cse-leaves The expression DAG is partially decomposed into trees and dynamic programming is performed. If the subgraph rooted at a shared node can be fully covered by a single tile, the shared node remain unaltered, otherwise shared nodes become roots of trees to be tiled. That is, shared nodes are fixed unless they represent an expression that can be fully covered by a single tile.</p><p>cse-none The expression DAG is not decomposed into trees and dynamic programming is performed. That is, no shared nodes are fixed (this is equivalent to the solution found before the IMPROVECSEDECISIONS procedure is executed in the NOL-TIS algorithm).</p><p>All algorithms use the same tile set. The cost of each tile is the size in bytes of the corresponding x86 instruction(s). We do not allow tiles to overlap memory operations (i.e., a load or store node in the expression DAG will only be executed once). Similarly, as an implementation detail 2 , overlap of function call addresses is not allowed. Valueless token edges enforce ordering dependencies in the expression DAG. Despite the two-address nature of the x86 architecture, all tiles represent three-address instructions. A pass after instruction selection converts the code to two-address form. A scheduling pass, which converts the code from DAG form into 2 LLVM's support for different relocation models requires that function call addresses be part of the call instruction.  The improvement in tiling cost relative to the default maximal munch algorithm for individual SPEC CPU2006 benchmarks. The average improvements of the cse-all, cse-leaves, cse-none, and NOLTIS algorithms are -1.28%, 0.94%, 1.15%, and 2.68% respectively.</p><p>an assembly listing, attempts to minimize the register pressure of the schedule using Sethi-Ullman numbering <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RESULTS</head><p>We evaluate the various instruction selection algorithms by compiling the C and C++ benchmarks of the SPEC CPU2006 <ref type="bibr" target="#b37">[39]</ref>, MediaBench <ref type="bibr" target="#b36">[37]</ref>, MiBench [38], and VersaBench <ref type="bibr" target="#b38">[40]</ref> benchmark suites and observing both the immediate, post-selection cost of the tiling and the final code size of the benchmark. We evaluate the optimality of the NOLTIS algorithm, demonstrate its superiority compared to existing heuristics, investigate its impact on the code size of fully compiled code, and describe its compile-time behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Optimality</head><p>In order to determine an optimal solution for an expression DAG, we create a 0-1 integer programming problem as described in Section 5 and then solve it using ILOG CPLEX 10.0 <ref type="bibr" target="#b10">[11]</ref>. We evaluated all the basic blocks of the SPEC CPU2006 benchmarks, resulting in nearly half million tiling problems We utilized a cluster of Pentium 4 machines ranging in speed from 2.8Ghz to 3.0Ghz to solve the problems. CPLEX was able to find a provably optimal solution within a 15 minute time limit for 99.8% of the tiling problems. Of the problems with provably optimal solutions, the NOLTIS algorithm successfully found the optimal solution 99.7% of the time. Furthermore, suboptimal solutions were typically very close to optimal (only a few bytes larger). Of the 0.2% of problems where CPLEX did not find a provably optimal solution, the NOLTIS algorithm found a solution as good as, and in some cases better than, the best solution found by CPLEX 75% of the time implying our algorithm is effective even for very difficult tiling problems.</p><p>The overall improvement obtained by using the best CPLEX solution versus using the NOLTIS algorithm was a negligible 0.05%. We feel these results clearly demonstrate that the NOLTIS algorithm is, in fact, near-optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Comparison of Algorithms</head><p>In addition to being near-optimal, the NOLTIS algorithm provides significantly better solutions to the tiling problem than conventional heuristics. Detailed results for the SPEC CPU2006 benchmarks are shown in Figure <ref type="figure" target="#fig_3">4</ref> and average improvements are shown in Figure <ref type="figure" target="#fig_6">5</ref>. The cse-all algorithm, despite finding an optimal tiling for each tree in the full tree decomposition of the DAG, performs poorly relative to all other algorithms suggesting that DAG tiling algorithms are necessary for maximum code quality. Both the cseleaves and cse-none algorithms benefit from using dynamic programming and outperform the greedy algorithm, although neither algorithm is clearly superior to the other. The NOLTIS algorithm, as expected, significantly outperforms the other algorithms and has the best improvement in every benchmark.  The final code size improvement relative to the default maximal munch algorithm for individual SPEC CPU2006 benchmarks. The average improvements of the cse-all, cse-leaves, cse-none, and NOLTIS algorithms are -4.03%, -0.09%, 0.81%, and 1.20% respectively. The average improvement of the NOLTIS algorithm relative to the more traditional cse-all algorithm is 4.42%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Impact on Code Size</head><p>Instruction tiling is only one component of code generation. The two-address conversion pass, scheduling pass, and register allocation pass all further impact the final quality of the compiled code. Final code size results for the SPEC CPU2006 benchmarks are shown in Figure <ref type="figure" target="#fig_4">6</ref>  Although the average code size improvements exhibited by the NOLTIS algorithm may seem marginal, even such seemingly small code size reductions may be significant when targeting highly constrained embedded architectures. Furthermore, it is important to note that these results are relative to an algorithm that has already been adapted to work directly on expression DAGs. Compared to the classical textbook approach of tree decomposition (the cse-all algorithm), the NOLTIS algorithm exhibits an overall average code size improvement of 5.1%.</p><p>The mixed nature of the final code size results appears to be mostly caused by the interaction with the register allocator, in particular the number of loads and stores the allocator inserts. Decomposing the graph into trees results in the creation of temporaries with multiple uses. These potentially long-lived temporaries result in more register pressure and more values must be spilled to memory. Hence the cse-all algorithm performs particularly poorly. Allowing unlimited overlap can also have a negative effect on register allocation as the inputs of overlapping tiles are also potentially long lived temporaries. Another factor influencing register allocation is the number of tiles. If more, smaller, tiles are used, there are correspondingly more temporaries to allocate.</p><p>Ultimately, the interaction between instruction selection and register allocation cannot be easily characterized and is beyond the scope of this work. It is likely that architectures with complex instruction sets but plentiful (e.g., more than eight) registers would see more benefit from the NOLTIS algorithm. Furthermore, given a framework for characterizing the interaction between instruction selection and register allocation, the near-optimality of the NOLTIS algorithm would make it the natural choice for performing tiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Compile Time Performance</head><p>As shown in Figure <ref type="figure">8</ref>, the two pass nature of the NOLTIS algorithm means that its running time is slightly more than twice that of the other dynamic programming based algorithms. The dynamic programming algorithms are approximately 30% slower than the greedy algorithm since they must perform a tile selection operation at every node of the expression DAG. The greedy algorithm can ignore any nodes which are completely covered by the greedily selected tile. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">LIMITATIONS AND FUTURE WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average improvement in tiling cost</head><p>cse-all cse-leaves cse-none NOLTIS Although the NOLTIS algorithm is linear in the size of the program, its running time is largely determined by how efficiently the matching of a single node to a set of tiles can be performed. The algorithm, as we have presented it, uses a simple, but inefficient, matching algorithm. More efficient algorithms, such as tree parsing, exist <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b1">2]</ref> and should be used in a production implementation. Additionally, the second pass of dynamic programming could be made more efficient by intelligently recomputing only portions of the DAG.</p><p>The classical representation of instruction selection as a tiling problem relies on instructions being represented by tree tiles. In some cases, such as with single instruction multiple data (SIMD) instructions and instructions with side-effects, an instruction cannot be represented as a tree of data dependences. Additional, nontiling, techniques are required to handle such instructions.</p><p>The abstract machine model used by our tiling algorithms is a three-address, infinite register machine. Finding a linear time, nearoptimal algorithm that does not depend upon these assumptions remains an open problem. Given the hardness of the register alloca-  tion problem, it seems unlikely that such an algorithm exists. However, it may be possible to construct a framework which integrates register allocation and instruction selection. The two passes would then work cooperatively with the instruction selector guiding register allocation decisions and vice versa. For example, the instruction selector might generate an approximate tiling which the register allocator is responsible for finalizing based on register availability. Or the register allocator might provide feedback to the instruction selector which changes the costs of tiles. We believe that NOLTIS would be valuable part of such a framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">SUMMARY</head><p>In this paper we have described NOLTIS, an easy to implement, fast, and effective algorithm for finding an instruction tiling of an expression DAG. We have shown empirically that the NOLTIS algorithm achieves near-optimal results and significantly outperforms existing tiling heuristics. Although the interaction between instruction selection and register allocation bears further study, we have shown that NOLTIS is capable of improving code size compared to existing techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of instruction selection on a DAG. (a) The tile set used (commutative tiles are omitted). (b) Two possible tilings.In a simple cost model where every tile has a unit cost the top tiling would be optimal, but with the cost model shown the lower tiling is optimal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: (a) An example of an expression DAG that represents a Boolean expression. (b) The tiles used to cover such an expression DAG. Each tile has unit cost. The tiles representing ∧ are omitted, but are similar to the ∨ tiles with the two middle tiles having an additional box node at the root.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The application of the NOLTIS algorithm to the example from Figure 1. (a) BOTTOMPUPDP computes the dynamic programming solution for the DAG, initializing bestChoiceForNode. (b) TOPDOWNSELECT determines a tiling from the dynamic programming solution, initializing coveringTiles. (c) IMPROVECSEDECISIONS evaluates the shared node and determines it should be fixed. (d)The dynamic programming is then recomputed with the requirement that the fixed node not be overlapped and the optimal solution is found.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: The improvement in tiling cost relative to the default maximal munch algorithm for individual SPEC CPU2006 benchmarks. The average improvements of the cse-all, cse-leaves, cse-none, and NOLTIS algorithms are -1.28%, 0.94%, 1.15%, and 2.68% respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: The final code size improvement relative to the default maximal munch algorithm for individual SPEC CPU2006 benchmarks. The average improvements of the cse-all, cse-leaves, cse-none, and NOLTIS algorithms are -4.03%, -0.09%, 0.81%, and 1.20% respectively. The average improvement of the NOLTIS algorithm relative to the more traditional cse-all algorithm is 4.42%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>and average improvements are shown in Figure 7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The average improvement in tiling cost relative to the default maximal munch algorithm for four benchmark suites. sign domain. It remains an open question whether the NOLTIS algorithm can be successfully adapted to this domain where multiple optimization goals (area, delay, routing resources) must be simultaneously addressed.Although the NOLTIS algorithm is linear in the size of the program, its running time is largely determined by how efficiently the matching of a single node to a set of tiles can be performed. The algorithm, as we have presented it, uses a simple, but inefficient, matching algorithm. More efficient algorithms, such as tree parsing, exist<ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b1">2]</ref> and should be used in a production implementation. Additionally, the second pass of dynamic programming could be made more efficient by intelligently recomputing only portions of the DAG.The classical representation of instruction selection as a tiling problem relies on instructions being represented by tree tiles. In some cases, such as with single instruction multiple data (SIMD) instructions and instructions with side-effects, an instruction cannot be represented as a tree of data dependences. Additional, nontiling, techniques are required to handle such instructions.The abstract machine model used by our tiling algorithms is a three-address, infinite register machine. Finding a linear time, nearoptimal algorithm that does not depend upon these assumptions remains an open problem. Given the hardness of the register alloca-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>cse-all cse-leaves cse-none NOLTIS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: The average final code size improvement relative to the default maximal munch algorithm for four benchmark suites.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1</head><label></label><figDesc>Dynamic programming instruction selection with modifications for near-optimal DAG selection 1: DAG : expression DAG 2: bestChoiceForNode : Node → (Tile × int) 3: fixedNodes : set of Node 4: matchedTiles : set of Tile 5: coveringTiles : Node → set of Tile</figDesc><table><row><cell cols="3">6: procedure SELECT</cell></row><row><cell cols="3">7: f ixedN odes ← {}</cell></row><row><cell>8:</cell><cell cols="2">BOTTOMUPDP()</cell><cell>initializes bestChoiceForNode</cell></row><row><cell>9:</cell><cell cols="2">TOPDOWNSELECT()</cell><cell>initializes coveringTiles</cell></row><row><cell>10:</cell><cell cols="3">IMPROVECSEDECISIONS()</cell><cell>initializes fixedNodes</cell></row><row><cell>11:</cell><cell cols="2">BOTTOMUPDP()</cell><cell>uses fixedNodes</cell></row><row><cell>12:</cell><cell cols="2">TOPDOWNSELECT()</cell><cell>puts final tiling in matchedTiles</cell></row><row><cell cols="3">13: procedure BOTTOMUPDP</cell></row><row><cell>14:</cell><cell cols="3">for n ∈ reverseTopologicalSort(DAG) do</cell></row><row><cell>15:</cell><cell cols="3">bestChoiceForNode[n].cost ← ∞</cell></row><row><cell>16:</cell><cell cols="3">for tn ∈ matchingTiles(n) do</cell></row><row><cell>17:</cell><cell cols="3">if ¬hasInteriorFixedNode(tn , fixedNodes) then</cell></row><row><cell>18:</cell><cell cols="2">val ← cost(t)+</cell></row><row><cell></cell><cell>P</cell><cell cols="2">n ∈edgeNodes(tn ) bestChoiceForNode[n ].cost</cell></row><row><cell>19:</cell><cell cols="3">if val &lt; bestChoiceForNode[n].cost then</cell></row><row><cell>20:</cell><cell cols="3">bestChoiceForNode[n].cost ← val</cell></row><row><cell>21:</cell><cell cols="3">bestChoiceForNode[n].tile ← tn</cell></row><row><cell cols="4">22: procedure TOPDOWNSELECT</cell></row><row><cell>23:</cell><cell cols="2">matchedTiles.clear ()</cell></row><row><cell>24:</cell><cell cols="2">coveringTiles.clear ()</cell></row><row><cell>25:</cell><cell cols="2">q.push(roots(DAG))</cell></row><row><cell>26:</cell><cell cols="2">while ¬q.empty() do</cell></row><row><cell>27:</cell><cell cols="2">n ← q.pop()</cell></row><row><cell>28:</cell><cell cols="3">bestTile ← bestChoiceForNode[n].tile</cell></row><row><cell>29:</cell><cell cols="3">matchedTiles.add (bestTile)</cell></row><row><cell>30:</cell><cell cols="3">for every node nt covered by bestTile do</cell></row><row><cell>31:</cell><cell cols="3">coveringTiles[nt ].add (bestTile)</cell></row><row><cell>32:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>cost relative to default algorithm cse-all cse-leaves cse-none NOLTIS</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>5%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Improvement in tiling</cell><cell>-5% -4% -3% -2% -1%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>400.perlbench</cell><cell>401.bzip2</cell><cell>403.gcc</cell><cell>429.mcf</cell><cell>433.milc</cell><cell>444.namd</cell><cell>445.gobmk</cell><cell>450.soplex</cell><cell>453.povray</cell><cell>456.hmmer</cell><cell>458.sjeng</cell><cell>462.libquantum</cell><cell>464.h264ref</cell><cell>470.lbm</cell><cell>471.omnetpp</cell><cell>473.astar</cell><cell>482.sphinx3</cell><cell>483.xalancbmk</cell><cell>average</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>size improvement relative to default selector cse-all cse-leaves cse-none NOLTIS</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-2%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-4%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-6%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Code</cell><cell>-8%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-10%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>400.perlbench</cell><cell>401.bzip2</cell><cell>403.gcc</cell><cell>429.mcf</cell><cell>433.milc</cell><cell>444.namd</cell><cell>445.gobmk</cell><cell>450.soplex</cell><cell>453.povray</cell><cell>456.hmmer</cell><cell>458.sjeng</cell><cell>462.libquantum</cell><cell>464.h264ref</cell><cell>470.lbm</cell><cell>471.omnetpp</cell><cell>473.astar</cell><cell>482.sphinx3</cell><cell>483.xalancbmk</cell><cell>average</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Instruction selection algorithms have been used successfully to solve the technology mapping problem in the automated circuit de-Listing 4 Given a tile t and node n, determine the cost of cutting t at node n so that the root of t remains the same but n becomes an</figDesc><table><row><cell cols="2">edge node.</cell><cell></cell><cell></cell></row><row><cell cols="3">1: function GETTILECUTCOST(t,n)</cell><cell></cell></row><row><cell cols="2">2: bestCost ← ∞</cell><cell></cell><cell></cell></row><row><cell cols="2">3: r ← root(tile)</cell><cell></cell><cell></cell></row><row><cell cols="3">4: for t ∈ matchingTiles(r ) do</cell><cell></cell></row><row><cell>5:</cell><cell cols="2">if n ∈ edgeNodes(t ) then</cell><cell></cell></row><row><cell>6:</cell><cell cols="2">cost ← cost(t )</cell><cell></cell></row><row><cell>7:</cell><cell cols="3">for n ∈ edgeNodes(t ) ∧ n = n do</cell></row><row><cell>8:</cell><cell cols="4">cost ← cost + bestChoiceForNode[n ].cost</cell></row><row><cell>9:</cell><cell cols="2">if cost &lt; bestCost then</cell><cell></cell></row><row><cell>10:</cell><cell cols="2">bestCost ← cost</cell><cell></cell></row><row><cell>11:</cell><cell cols="2">for n ∈ edgeNodes(t) do</cell><cell cols="2">Subtract edge costs of</cell></row><row><cell cols="2">original tile</cell><cell></cell><cell></cell></row><row><cell>12:</cell><cell cols="3">if path r ; n ∈ t does not contain n then</cell></row><row><cell>13:</cell><cell cols="2">bestCost ← bestCost</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">-bestChoiceForNode[n ].cost</cell></row><row><cell>14:</cell><cell>return bestCost</cell><cell></cell><cell></cell></row><row><cell>5%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>4%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>-1%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>-2%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>-3%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>-4%</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>SPEC</cell><cell>MediaBench</cell><cell>mibench</cell><cell>VersaBench</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">ACKNOWLEDGEMENTS</head><p>This research was sponsored in part by the National Science Foundation under grant CCF-0702640.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimization of stright line programs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Code generation using tree matching and dynamic programming</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ganapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Tjiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="491" to="516" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimal code generation for expression trees</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="488" to="501" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Code generation for expressions with common subexpressions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="146" to="160" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<title level="m">Compilers: Princiles, Techniques, and Tools</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Modern Compiler Implementation in Java: Basic Techniques</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Appel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal code generation for expressions on super scalar machines</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Fall Joint Computer Conf</title>
		<meeting>of the ACM Fall Joint Computer Conf<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Code generation for a one-register machine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="502" to="510" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic derivation of code generators from machine descriptions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Cattell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="173" to="190" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Engineering a Compiler</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torczon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<ptr target="http://ilog.com/products/cplex" />
		<title level="m">CPLEX</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Code selection through object code optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="505" to="526" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Synthesis and Optimization of Digital Circuits</title>
		<author>
			<persName><forename type="first">G</forename><surname>De Micheli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>McGraw-Hill Higher Education</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Beg: a generation for efficient back ends</title>
		<author>
			<persName><forename type="first">H</forename><surname>Emmelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-W</forename><surname>Schröer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Landwehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/SIGPLAN Conf. on Prog. Lang. Design and Impl</title>
		<meeting>of ACM/SIGPLAN Conf. on Prog. Lang. Design and Impl<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="227" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimal code selection in dags</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/SIGPLAN-SIGACT Symposium on Principles of Prog. Lang</title>
		<meeting>of ACM/SIGPLAN-SIGACT Symposium on Principles of Prog. Lang<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Engineering a simple, efficient code-generator generator</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Proebsting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Lett. Prog. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="213" to="226" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Burg: fast optimal instruction selection and tree parsing</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Proebsting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="68" to="76" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Integrating code generation and optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Wendt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGPLAN Symposium on Compiler Construction</title>
		<meeting>of SIGPLAN Symposium on Compiler Construction<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="242" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic generation of fast optimizing code generators</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Wendt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/SIGPLAN Conf. on Prog. Lang. Design and Impl</title>
		<meeting>of ACM/SIGPLAN Conf. on Prog. Lang. Design and Impl<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Computers and Intractability: A Guide to the Theory of NP-Completeness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>W. H. Freeman &amp; Co</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A new method for compiler code generation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Glanville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/SIGPLAN-SIGACT Symposium on Principles of Prog. Lang</title>
		<meeting>of ACM/SIGPLAN-SIGACT Symposium on Principles of Prog. Lang<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="231" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Logic Synthesis and Verification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hassoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sasao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A dynamic programming approach to optimal integrated code generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bednarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM/SIGPLAN Workshop on Languages, Compilers and Tools for Embedded Systems</title>
		<meeting>of the ACM/SIGPLAN Workshop on Languages, Compilers and Tools for Embedded Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Peep: an architectural description driven peephole optimizer</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGPLAN Symposium on Compiler Construction</title>
		<meeting>SIGPLAN Symposium on Compiler Construction<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="106" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DAGON: technology binding and local optimization by dag matching</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM/IEEE Conf. on Design Automation</title>
		<meeting>of the ACM/IEEE Conf. on Design Automation<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="341" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graph-based code selection techniques for embedded processors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Leupers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bashford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Des. Autom. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="794" to="814" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Instruction selection using binate covering for code size optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devadas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tjiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE/ACM Intl. Conf. on Computer-aided Design</title>
		<meeting>of the IEEE/ACM Intl. Conf. on Computer-aided Design<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="393" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A new viewpoint on code generation for directed acyclic graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tjiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Des. Autom. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="51" to="75" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<ptr target="http://llvm.org" />
		<title level="m">The LLVM compiler infrastructure project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Peephole optimization</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Mckeeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="443" to="444" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Compiling with code-size constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. on Embedded Computing Sys</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="163" to="181" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Optimal code generation for expression trees: an application burs theory</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pelegrí-Llopart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/SIGPLAN-SIGACT Symposium on Principles of Prog. Lang</title>
		<meeting>of ACM/SIGPLAN-SIGACT Symposium on Principles of Prog. Lang<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="294" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Least-cost instruction selection in dags is NP-complete</title>
		<author>
			<persName><forename type="first">T</forename><surname>Proebsting</surname></persName>
		</author>
		<ptr target="http://research.microsoft.com/~toddpro/papers/proof.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simple and efficient burs table generation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Proebsting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/SIGPLAN Conf. on Prog. Lang. Design and Impl</title>
		<meeting>of ACM/SIGPLAN Conf. on Prog. Lang. Design and Impl<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Burs automata generation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Proebsting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Program. Lang. Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="461" to="486" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The generation of optimal code for arithmetic expressions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="715" to="728" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<ptr target="http://euler.slu.edu/~fritts/mediabench/" />
		<title level="m">MediaBench I</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><surname>Spec Cpu</surname></persName>
		</author>
		<ptr target="http://www.spec.org/cpu" />
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<ptr target="http://cag.csail.mit.edu/versabench/" />
		<title level="m">Benchmark Suite for Versatile Architectures</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
