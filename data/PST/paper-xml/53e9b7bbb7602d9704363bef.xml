<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stochastic Maximum Principle for Mean-Field Type Optimal Control under Partial Information</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Guangchen</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chenghui</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weihai</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">Stochastic Maximum Principle for Mean-Field Type Optimal Control under Partial Information</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8FD4BEBEB187BC68A996527C348F71AE</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Preprint submitted to IEEE Transactions on Automatic Control. Received: July 5, 2013 09:01:44 PST This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This technical note is concerned with a kind of partially observed optimal control problem, whose novel feature is that the cost functional is of meanfield type. Hence determining the optimal control is time inconsistent in the sense that Bellman's dynamic programming principle does not hold. A maximum principle is established using Girsanov's theorem and convex variation. Some nonlinear filtering results for backward stochastic differential equations (BSDEs) are developed by expressing the solutions of the BSDEs as some Itô's processes. An illustrative example is demonstrated in terms of the maximum principle and the filtering.</p><p>Index Terms-Maximum principle, Girsanov's theorem, nonlinear filtering, conditional density, linear-quadratic control, mean-field type.</p><p>) is a unique weak solution of (2) with (6). We now introduce a Limited circulation. For review only</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Let us consider a filtered complete probability space (Ω, F w1,z , (F w1,z t ) 0≤t≤1 , lP), on which an lR 2 -valued standard Brownian motion (w 1 (•), z(•)) is defined with (F w1,z t ) 0≤t≤1 being its natural filtration and F w1,z = F w1,z 1 . Throughout this technical note, we denote by lR n the n-dimensional Euclidean space, by f x the (partial) derivative of f with respect to x, by 1 f the reciprocal of f , by L 2 F w 1 ,z (0, 1; S) the set of all S-valued, F w1,z t -adapted and square-integrable processes. Some similar notations are given for other space, filtration and integral in a same situation.</p><p>Define a process y(•) by</p><formula xml:id="formula_0">dy(t) = f (t)dz(t), y(0) = 0,<label>(1)</label></formula><p>where f : [0, 1] → lR is a bounded and deterministic function with 1 f (•) also bounded. Let F y t = σ{y(s); 0 ≤ s ≤ t}. Clearly, F y t = σ{z(s); 0 ≤ s ≤ t}. Let U be a non-empty convex subset in lR. A control process v(•) : [0, 1] × Ω → Manuscript received October, 2011; revised ?, ?, ? and ?. First published ?; current version published ?. This work was partially supported by the National Natural Science Foundation of China (11001156, 51277116, 61034007, 61174078, 61174092), the Research Fund for the Taishan Scholar Project of Shandong Province of China, and the Program for New Century Excellent Talents in University of China (NCET-12-0338). Recommended by Associate Editor Yiguang Hong.</p><p>G. Wang is with the School of Control Science and Engineering, Shandong University, Jinan 250061, China, and the School of Mathematical Sciences, Shandong Normal University, Jinan 250014, China (e-mail: wguangchen@sdu.edu.cn).</p><p>C. Zhang is with the School of Control Science and Engineering, Shandong University, Jinan 250061, China (e-mail: zchui@sdu.edu.cn).</p><p>W. Zhang is with the College of Information and Electrical Engineering, Shandong University of Science and Technology, Qingdao 266590, China (email: w_hzhang@163.com).</p><p>Digital Object Identifier • • • U is called admissible, if v(t) is F y t -adapted and satisfies sup 0≤t≤1 lEv 8 (t) &lt; +∞. Write U ad for the set of all the admissible controls. Consider the following controlled stochastic differential equation (SDE):</p><formula xml:id="formula_1">dx(t) = b(t, x(t), v(t))dt + σ(t, x(t), v(t))dw 1 (t), x(0) = x 0 , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where b, σ : [0, 1] × lR × U → lR are given continuous functions, v(•) is an admissible control, and x 0 is a constant.</p><p>The following assumptions will be in force in Sections I and II.</p><p>(A1) For any t ∈ [0, 1], b and σ are continuously differentiable with respect to x and v; their derivatives b x , b v , σ x and σ v are uniformly bounded.</p><p>(A2) For any (t, x) ∈ [0, 1]×lR, the function h : [0, 1]×lR → lR is continuously differentiable with respect to x; h and its derivative h x are uniformly bounded.</p><p>For any v(•) ∈ U ad , (2) admits a unique solution</p><formula xml:id="formula_3">x v (•) ∈ L 2</formula><p>F w 1 ,z (0, 1; lR) under (A1), where the superscript v highlights the dependence on v(•). Then we introduce a process ρ v (•) by</p><formula xml:id="formula_4">ρ v (t) = exp t 0 h(s, x v (s)) f (s) dz(s) - 1 2 t 0 h 2 (s, x v (s)) f 2 (s) ds , (3) which is the solution of    dρ v (t) = h(t, x v (t)) f (t) ρ v (t)dz(t), ρ v (0) = 1.<label>(4)</label></formula><p>It is clear that</p><formula xml:id="formula_5">ρ v (t) is an (F w1,z t , lP)-martingale. Next, define a measure lP v by dlP v = ρ v (1)dlP. Therefore, Girsanov's theorem implies that z(t) - t 0 h(s,x v (s)) f (s)</formula><p>ds is a standard Brownian motion defined on (Ω, F w1,z , (F w1,z t ) 0≤t≤1 , lP v ), which is independent of w 1 (•) under lP v . Without loss of any generality, set</p><formula xml:id="formula_6">w v 2 (t) = z(t) - t 0 h(s, x v (s)) f (s) ds (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>and insert (5) into (1), then we have</p><formula xml:id="formula_8">dy(t) = h(t, x v (t))dt + f (t)dw v 2 (t), y(0) = 0.<label>(6)</label></formula><p>That is to say, for any v(•) ∈ U ad , (Ω, F w1,z , (F w1,z related cost functional</p><formula xml:id="formula_9">J(v(•)) =lE v 1 0 l(t, x v (t), lE v x v (t), v(t))dt + φ(x v (1), lE v x v (1)) . (7)</formula><p>Here lE v is the expectation with respect to lP v ; l : [0, 1] × lR × lR × U → lR and φ : lR × lR → lR are given mappings. Then the control problem under consideration here is as follows.</p><p>Problem (MFC): Seek u(•) ∈ U ad such that</p><formula xml:id="formula_10">J(u(•)) = min v(•)∈U ad J(v(•)).</formula><p>If such an identity holds, we call u(•) an optimal control and (x u (•), ρ u (•)) an optimal state. When there is no confusion, we adopt the notation θ(•) = θ u (•) with θ = x, ρ, w 2 for simplicity. Due to Bayes formula, <ref type="bibr" target="#b6">(7)</ref> can be rewritten as</p><formula xml:id="formula_11">J(v(•)) =lE 1 0 ρ v (t)l(t, x v (t), lE[ρ v (t)x v (t)], v(t))dt + ρ v (1)φ(x v (1), lE[ρ v (1)x v (1)]) . (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>Then Problem (MFC) is equivalent to minimizing (8) over U ad subject to (2) and (4). Note that ( <ref type="formula" target="#formula_11">8</ref>) is of mean-field type, which makes the problem time inconsistent in the sense that Bellman's optimality principle does not hold.</p><p>Problem (MFC) covers some existing models and plays an important role in many fields such as the large population game <ref type="bibr" target="#b6">[7]</ref>, actuarial science and financial engineering, where a typical example is the mean-variance portfolio selection problem with partial information as follows: let x(•) be an economic quantity which satisfies <ref type="bibr" target="#b1">(2)</ref>. Suppose that x(•) is only partially observed via a factor process</p><formula xml:id="formula_13">z(t) = t 0 1 β h(s, x(s)) - 1 2 β ds + w v 2 (t),</formula><p>where β is a positive constant, h satisfies (A2) and w v 2 (•) is defined by <ref type="bibr" target="#b4">(5)</ref> with f (•) ≡ 1. Note that a reasonable interpretation of z(•) in practice is the logarithm of the stock price S(•) related to x(•), i.e., S(t) = e βz (t) . Then the investment goal is to find a σ{z(s);</p><formula xml:id="formula_14">0 ≤ s ≤ t}-adapted control strategy v(•) such that lE v x v (1) -lE v x v (1) 2 -x v (1) is minimized. Clearly, this problem is included in Problem (MFC).</formula><p>Motivated by the examples above, this technical note is interested in Problem (MFC). One objective is to establish a maximum principle for optimal control. Similar to <ref type="bibr" target="#b1">[2]</ref>, Problem (MFC) can be formulated as a full information optimal control problem derived by the corresponding Zakai equation. However, the study of the Zakai equation is not an existing result. Thus we cannot derive the maximum principle directly. Then a certain new approach is expected to be introduced. Inspired by <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[12]</ref>, we use ( <ref type="formula" target="#formula_1">2</ref>) and ( <ref type="formula" target="#formula_8">6</ref>), rather than the filtering of x(t) on basis of F y t , to calculate the variation. Combining it with a dual method, we establish the maximum principle which is exactly the conditional expectation of a certain Hamiltonian function with respect to F y t , and hence another objective is to study some nonlinear filters of BSDEs in order to determine an optimal control. This topic is related to the recent works <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref>. To be specific, <ref type="bibr" target="#b0">[1]</ref> studied a full information mean-field type control; <ref type="bibr" target="#b8">[9]</ref> dealt with a partial information case where the admissible control is adapted to a sub σ-algebra of the underlying filtration but the observation equation and the filtering are not included; <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref> obtained some linear filtering equations for BSDEs. Due to the viewpoint from different angles, Problem (MFC) is distinguished from the existing literature. The rest of this technical note is organized as follows. In Section II, a maximum principle is derived. In Section III, some nonlinear filtering results for BSDEs are established. In Section IV, an example is given to demonstrate the application of the maximum principle and the nonlinear filtering equations. Finally, in Section V some concluding remarks are presented.</p><formula xml:id="formula_15">II. MAXIMUM PRINCIPLE FOR OPTIMALITY Let v(•) ∈ L 8 F y (0, 1; lR) be given such that u(•) + v(•) ∈ U ad . For any 0 ≤ ε ≤ 1, we take the variational control u ε (•) = u(•) + εv(•). Because U ad is convex, u ε (•) belongs to U ad .</formula><p>In this section, we denote by x ε (•) and ρ ε (•) the states of ( <ref type="formula" target="#formula_1">2</ref>) and ( <ref type="formula" target="#formula_4">4</ref>) along with the control u ε (•). Also, we use the notations for simplicity a = a (t, <ref type="formula" target="#formula_0">1</ref>)) and φ = φ (x(1), lE u x( <ref type="formula" target="#formula_0">1</ref>)), = x, y.</p><formula xml:id="formula_16">x(t), u(t)), a = b, σ, = x, v; h x = h x (t, x(t)); l(u(t)) = l(t, x(t), lE u x(t), u(t)) and l = l (t, x(t), lE u x(t), u(t)), = x, y, v; φ = φ(x(1), lE u x(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Variational equation</head><p>The first result below is related to some estimates of the state (x, ρ), which can be deduced by Gronwall's inequality and Burkholder-Davis-Gundy's inequality.</p><p>Lemma 2.1: Under (A1) and (A2), for any v(•) ∈ U ad , there is a constant κ such that</p><formula xml:id="formula_17">sup 0≤t≤1 lE[x v (t)] 8 ≤ κ(1 + sup 0≤t≤1 lEv 8 (t)), sup 0≤t≤1 lE[ρ v (t)] 8 ≤ κ, sup 0≤t≤1 lE[x ε (t) -x(t)] 8 ≤ κε 8 , sup 0≤t≤1 lE[ρ ε (t) -ρ(t)] 8 ≤ κε 8 .</formula><p>We introduce the variational equations</p><formula xml:id="formula_18">dx 1 (t) = b x x 1 (t) + b v v(t) dt + σ x x 1 (t) + σ v v(t) dw 1 (t), x 1 (0) =0, (9)    dρ 1 (t) = 1 f (t) ρ 1 (t)h(t, x(t)) + ρ(t)h x x 1 (t) dz(t), ρ 1 (0) =0. (10) In view of the boundedness of b x , b v , σ x , σ v , 1</formula><p>f , h and h x , (9) admits a unique solution x 1 (•) ∈ L 8  F w 1 ,z (0, 1; lR), and hence there exists a unique solution ρ 1 (•) ∈ L 8  F w 1 ,z (0, 1; lR) to <ref type="bibr" target="#b9">(10)</ref>.</p><formula xml:id="formula_19">Next, set ξ(•) = x ε (•)-x(•) ε -x 1 (•) and η(•) = ρ ε (•)-ρ(•) ε -ρ 1 (•).</formula><p>Using Lemma 2.1 and some standard techniques, we have Lemma 2.2: Let (A1) and (A2) hold. Then sup 0≤t≤1 lEξ 4 (t) → 0 and sup 0≤t≤1 lEη 2 (t) → 0 as ε → 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Variational inequality (A3)</head><p>For any (t, x, y, v) ∈ [0, 1] × lR × lR × U , l and φ are continuously differentiable with respect to (x, y, v) and (x, y), respectively. Moreover, there is a constant κ such that</p><formula xml:id="formula_20">|l(t, x, y, v)| + |φ(x, y)| ≤ κ(1 + x 2 + y 2 + v 2 ), |φ x (x, y)| + |φ y (x, y)| ≤ κ(1 + |x| + |y|), |l x (t, x, y, v)| + |l y (t, x, y, v)| + |l v (t, x, y, v)| ≤ κ(1 + |x| + |y| + |v|).</formula><p>Due to the optimality of u(•), it follows that</p><formula xml:id="formula_21">J(v(•)) -J(u(•)) ε ≥ 0</formula><p>for any v(•) ∈ U ad . Then Lemma 2.2 and Taylor's expansion imply that Lemma 2.3: Under (A1), (A2) and (A3), if u(•) is an optimal control, we have</p><formula xml:id="formula_22">0 ≤ lE u 1 0 l x x 1 (t) + l y lE u x 1 (t) + l v v(t) dt + φ x x 1 (1) + φ y lE u x 1 (1) + lE u 1 0 l y lE u (Γ(t)x(t)) + Γ(t)l(u(t)) dt + φ y lE u (Γ(1)x(1)) + φΓ(1) , where Γ(•) stands for ρ1(•) ρ(•) and satisfies    dΓ(t) = h x x 1 (t) f (t) dw 2 (t), Γ(0) = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Maximum principle</head><p>We first introduce the adjoint equations</p><formula xml:id="formula_23">-dP (t) = l(u(t)) + x(t)lE u l y dt -Q(t)dw 2 (t), P (1) = φ + x(1)lE u φ y ,<label>(11)</label></formula><formula xml:id="formula_24">           -dp(t) = b x p(t) + σ x q(t) + h x Q(t) f (t) + l x + lE u l y dt -q(t)dw 1 (t), p(1) = φ x + lE u φ y ,<label>(12)</label></formula><p>which are both mean-field BSDEs and admit unique solutions <ref type="bibr" target="#b3">[4]</ref>. Note that <ref type="bibr" target="#b10">(11)</ref> is not necessary in the case of full information. Then we define a generalized Hamiltonian function</p><formula xml:id="formula_25">H(t, x, y, v; p, q, Q) = b(t, x, v)p + σ(t, x, v)q + h(t, x) f (t) Q + l(t, x, y, v). (<label>13</label></formula><formula xml:id="formula_26">)</formula><p>It is time to state the maximum principle for Problem (MFC). Theorem 2.1: Under (A1), (A2) and (A3), if u(•) is an optimal control, it is necessary to satisfy that</p><formula xml:id="formula_27">lE u H v (t, x(t), y(t), u(t); p(t), q(t), Q(t))(v -u(t)) F y t ≥ 0</formula><p>for any v ∈ U , where Q(•) and (p(•), q(•)) are the solutions of ( <ref type="formula" target="#formula_23">11</ref>) and ( <ref type="formula" target="#formula_24">12</ref>), respectively. Proof: Applying Itô's formula to Γ(•)P (•) and p(•)x 1 (•), we derive</p><formula xml:id="formula_28">lE u Γ(1)φ + Γ(1)x(1)lE u φ y = lE u 1 0 Q(t)h x x 1 (t) f (t) -Γ(t) l(u(t)) + x(t)lE u l y dt and lE u x 1 (1) φ x + lE u φ y = lE u 1 0 b v p(t) + σ v q(t) v(t) -l x + h x Q(t) f (t) + lE u l y x 1 (t) dt.</formula><p>Inserting the above two equations into the variational inequality, we have</p><formula xml:id="formula_29">lE u 1 0 b v p(t) + σ v q(t) + l v v(t)dt ≥ 0.</formula><p>Since the inequality remains true for any v(•)</p><formula xml:id="formula_30">such that u(•) + v(•) ∈ U ad , it is easy to see that lE u 1 0 b v p(t) + σ v q(t) + l v (v -u(t))dt ≥ 0.</formula><p>Thereby, the proof is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OPTIMAL NONLINEAR FILTERING OF BSDES</head><p>The maximum condition in Theorem 2.1 involves the solutions (p(•), q(•)) and Q(•) of BSDEs <ref type="bibr" target="#b10">(11)</ref> and <ref type="bibr" target="#b11">(12)</ref>, respectively. Then it is necessary to calculate the filtering of (p(t), q(t)) and Q(t) with respect to F y t when we use the maximum condition to determine an optimal control. However, there still does not exist the general filtering for BSDEs. Therefore, in this section we aim to study the filtering within a general framework, which generalizes the results in <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Nonlinear filtering equations</head><p>We first state the problem in a mathematically rigorous way. Let (Ω, F, (F t ) 0≤t≤T , lP) be a filtered complete probability space, let (F t ) 0≤t≤T be a σ-algebra of F augmented by the collection of lP-null sets, and let T be a positive constant.</p><p>Suppose that (p(•), q 1 (•), q 2 (•)) is governed by</p><formula xml:id="formula_31">p(t) = ξ + T t</formula><p>g(s, ω, p(s), q 1 (s), q 2 (s))ds</p><formula xml:id="formula_32">- T t q 1 (s)dw 1 (s) - T t q 2 (s)dw 2 (s),<label>(14)</label></formula><p>where (w 1 (t), w 2 (t), F t ) is a 2-dimensional standard Brownian motion, ξ ∈ L 2 F (Ω; lR), and g : [0, T ]×Ω×lR×lR×lR → lR is a given function. The above ( <ref type="formula" target="#formula_32">14</ref>) is called a nonlinear BSDE, which admits a unique solution (p(•), q 1 (•), q 2 (•)) ∈ L 2 F (0, T ; lR 3 ) under some usual conditions <ref type="bibr" target="#b9">[10]</ref>. Note that the solution involves (q 1 (•), q 2 (•)), which can be regarded as a control term to the equation such that the adapted solutions exist. Thus, the BSDEs are remarkably different from the forward SDEs. Next, assume that the observable process y(•) is an Itô's process</p><formula xml:id="formula_33">y(t) = t 0 h(s, ω)ds + t 0 f (s)dw 1 (s),<label>(15)</label></formula><p>where f : [0, T ] → lR and h : [0, T ] × Ω → lR are given mappings. Let F y t = σ{y(s); 0 ≤ s ≤ t}. The optimal nonlinear filtering is to compute X(t) = lE[X(t)|F y t ], where X = p, q 1 , q 2 , lE[•|•] is the conditional expectation under lP. Since q i (•) can be calculated by the Malliavin derivative of p(•) with respect to w i (•) (i = 1, 2) <ref type="bibr" target="#b4">[5]</ref>, we are only interested in the filtering of p(•). For any t ∈ [0, T ], we adopt the notations for simplify ĥ</p><formula xml:id="formula_34">(t) = lE[h(t, ω)|F y t ], ĝ(t) = lE[g(t, ω, p(t), q 1 (t), q 2 (t))|F y t ], (ph)(t) = lE[p(t)h(t, ω)|F y t ]</formula><p>. Also, we need an assumption on the coefficients of ( <ref type="formula" target="#formula_32">14</ref>) and <ref type="bibr" target="#b14">(15)</ref>.</p><p>(A4) The function g(•, •, 0, 0, 0) ∈ L 2 F (0, T ; lR), and g is uniformly Lipschitz. f is bounded and deterministic, and 1 f is also bounded. h is in L 2 F (0, T ; lR). We now state a main result of this section, which plays a role in the area of partial information stochastic control for SDEs and BSDEs. See e.g. Section IV in this technical note and <ref type="bibr" target="#b5">[6]</ref>.</p><p>Theorem 3.1: Under (A4), the optimal filtering p(•) is governed by</p><formula xml:id="formula_35">p(t) = lE[ξ|F y T ] + T t ĝ(s)ds - T t q1 (s) + 1 f (s) (ph)(s) -p(s) ĥ(s) d w(s),<label>(16)</label></formula><p>where</p><formula xml:id="formula_36">w(t) = t 0 1 f (s)</formula><p>dy(s) -ĥ(s)ds (17</p><formula xml:id="formula_37">)</formula><p>is a 1-dimensional standard Brownian motion defined on (Ω, F y , (F y t ) 0≤t≤T , lP). Proof: <ref type="bibr" target="#b13">(14)</ref> admits a unique solution (p(•), q 1 (•), q 2 (•)) ∈ L 2 F (0, T ; lR 3 ), so p(•) can be rewritten as an Itô's process as follows: <ref type="figure">s,</ref><ref type="figure">ω,</ref><ref type="figure">p(s)</ref>, q 1 (s), q 2 (s))ds</p><formula xml:id="formula_38">p(t) = p(0) - t 0 g(</formula><formula xml:id="formula_39">+ t 0 q 1 (s)dw 1 (s) + t 0 q 2 (s)dw 2 (s).</formula><p>(18) Now ( <ref type="formula">18</ref>) and ( <ref type="formula" target="#formula_33">15</ref>) can be regarded as the state equation and the observation equation, respectively. Using Theorem 8.1 in <ref type="bibr" target="#b7">[8]</ref>, we have</p><formula xml:id="formula_40">p(t) = p(0) - t 0 ĝ(s)ds + t 0 q1 (s) + 1 f (s) (ph)(s) -p(s) ĥ(s) d w(s),</formula><p>where w(•) is given by (17). Similarly, we have</p><formula xml:id="formula_41">p(T ) = p(0) - T 0 ĝ(s)ds + T 0 q1 (s) + 1 f (s) (ph)(s) -p(s) ĥ(s) d w(s).</formula><p>Then it follows from p(t) -p(T ) that</p><formula xml:id="formula_42">p(t) = p(T ) + T t ĝ(s)ds - T t q1 (s) + 1 f (s)</formula><p>(ph)(s) -p(s) ĥ(s) d w(s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In addition, p(T ) = lE[ξ|F y</head><p>T ] also holds true. Thus the desired conclusion is drawn.</p><p>The following result is an immediate conclusion of Theorem 3.1.</p><p>Corollary 3.1: Under (A4), if g : [0, T ]×lR×lR → lR and h : [0, T ] × Ω → lR satisfy ĝ(t) = g(t, p(t), q1 (t)) and (ph)(t) = p(t) ĥ(t), respectively, then the optimal filtering (p(•), q1 (•)) is the solution of</p><formula xml:id="formula_43">p(t) = lE[ξ|F y T ] + T t g(s, p(s), q1 (s))ds - T t q1 (s)d w(s),</formula><p>where</p><formula xml:id="formula_44">w(t) = t 0 1 f (s)</formula><p>dy(s) -ĥ(s)ds is a 1-dimensional standard Brownian motion defined on (Ω, F y , (F y t ) 0≤t≤T , lP). Note that the filtering equation in Corollary 3.1 is a BSDE which admits a unique solution (p(•), q1 (•)) ∈ L <ref type="formula" target="#formula_1">2</ref>F y (0, T ; lR 2 ) due to (A4) and that lEξ 2 &lt; +∞. Therefore, Theorem 3.1 and Corollary 3.1 are distinguished from the classical filtering theory <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. SDEs for the conditional density</head><p>Suppose that the distribution lP(p(t) ≤ x|F y t ) has the conditional density ψ(t, x) = dlP(p(t)≤x|F y t ) dx , (t, x) ∈ [0, T ] × lR, which is (t, x, ω)-measurable. Let us derive the equation which the conditional density satisfies. Once ψ(•, •) is found, then the nonlinear filtering p(•) can be calculated by</p><formula xml:id="formula_45">p(t) = lE[p(t)|F y t ] = +∞ -∞ xψ(t, x)dx.</formula><p>We introduce the following assumptions: (A5) The function ϕ(•) : lR → lR and its derivatives up to order 2 are uniformly bounded.</p><p>(A6) The function ϕ(•) : lR → lR and its derivatives up to order 2 have compact supports.</p><p>(A7) The functions g : [0, T ] × lR × lR × lR → lR and h : [0, T ] × lR → lR are Borel measurable, and h is uniformly Lipschitz.</p><p>(A8) The solution of ( <ref type="formula" target="#formula_32">14</ref>) satisfies q i (t) = g i (t, p(t)), where</p><formula xml:id="formula_46">g i : [0, T ] × lR → lR (i = 1, 2) is also Borel measurable. (A9) The derivatives [ψ(t, x)g(t, x, ȳ1 , ȳ2 )] x , [ȳ 1 h(t, x)] x , [ψ(t, x)(h(t, x) -ĥ(t, x))g(t, x, ȳ1 , ȳ2 )] x , [(ȳ 2 1 + ȳ2 2 )ψ(t, x)] xx and [(ȳ 2 1 + ȳ2 2 )(h(t, x) -ĥ(t, x))ψ(t, x)] xx exist a.e., a.s. (A10) T 0 +∞ -∞ |ϕ(x)L * ψ(t, x)|dxdt &lt; +∞, lE T 0 +∞ -∞ ϕ 2 (x) ψ(t, x) h(t, x) -ĥ(t, x) + N * ψ(t, x) 2 dxdt &lt; +∞ with the notations L * ψ(t, x) = -[ψ(t, x)g(t, x, ȳ1 , ȳ2 )] x - 1 2 [ψ(t, x)(ȳ 2 1 + ȳ2 2 )] xx and N * ψ(t, x) = -[ψ(t, x)ȳ 1 ]</formula><p>x . Note that (A5), (A6), (A7), (A9) and (A10) are standard in the theory of nonlinear filtering, as well as (A8) is reasonable under some constraints on ξ and g. = ϕ x (p(s))g(s, p(s), q 1 (s), q 2 (s)) -</p><formula xml:id="formula_47">1 2 ϕ xx (p(s))(q 2 1 (s) + q 2 2 (s)) and N ϕ(p(s)) = ϕ x (p(s))q 1 (s),<label>and</label></formula><formula xml:id="formula_48">w(s) = s 0 1 f (t)</formula><p>dy(t) -ĥ(t, p(t)) dt.</p><p>(ii) If (A4), (A6), (A7), (A8), (A9) and (A10) hold, then the conditional density ψ(t, x) satisfies</p><formula xml:id="formula_49">ψ(t, x) = ψ(T, x) + T t L * ψ(s, x)ds - T t N * ψ(s, x) + 1 f (s) ψ(s, x) h(s, x) - +∞ -∞ h(s, x)ψ(s, x)dx d w(s).</formula><p>(20) Proof: (i) Applying Itô's formula to ϕ(p(t)), we have</p><formula xml:id="formula_50">ϕ(p(t)) = ϕ(ξ) + T t Lϕ(p(s))ds - T t ϕ x (p(s))q 1 (s)dw 1 (s) - T t ϕ x (p(s))q 2 (s)dw 2 (s).</formula><p>By the uniqueness of (p(•), q 1 (•), q 2 (•)), Theorem 8.1 in <ref type="bibr" target="#b7">[8]</ref> and Theorem 3.1, the nonlinear filtering equation is immediately solved.</p><p>(ii) Due to (A8), (19) can be rewritten as</p><formula xml:id="formula_51">+∞ -∞ ϕ(x)ψ(t, x)dx = +∞ -∞ ϕ(x)ψ(T, x)dx + I -II,<label>(21)</label></formula><p>where</p><formula xml:id="formula_52">I = T t +∞ -∞ Lϕ(x)ψ(s, x)dxds and II = T t +∞ -∞ N ϕ(x) + 1 f (s)</formula><p>ϕ(x) h(s, x) -ĥ(s, x) ψ(s, x)dxd w(s).</p><p>It follows from integration by parts and Fubini's theorem that</p><formula xml:id="formula_53">I = +∞ -∞ T t ϕ(x)L * ψ(s, x)dsdx. Similarly, II = +∞ -∞ T t ϕ(x) N * ψ(s, x) + 1 f (s)</formula><p>ψ(s, x) h(s, x) -ĥ(s, x) d w(s)dx.</p><p>Substituting the above two identities into (21), we obtain</p><formula xml:id="formula_54">+∞ -∞ ϕ(x)ψ(t, x)dx = +∞ -∞ ϕ(x) ψ(T, x) + T t L * ψ(s, x)ds - T t N * ψ(s, x) + 1 f (s)</formula><p>ψ(s, x) h(s, x) -ĥ(s, x) d w(s) dx.</p><p>The arbitrariness of ϕ(•) implies that (20) is true. The proof then is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. AN LQ CASE WITH PARTIAL INFORMATION</head><p>This section aims to illustrate Theorems 2.1 and 3.1 by a linear-quadratic (LQ) example, which is relevant to <ref type="bibr" target="#b2">[3]</ref>. To be specific, <ref type="bibr" target="#b2">[3]</ref> studied a full information LQ mean-field game, in which the diffusion coefficient of the dynamics of the player i is a deterministic function, while the drift coefficient depends on the symmetric influence of the rest of the players.</p><p>Example 4.1: Consider the following LQ optimal control problem with partial information:</p><formula xml:id="formula_55">min v(•)∈U ad J(v(•)), J(v(•)) = 1 2 lE v 1 0 M (t) x v (t) -lE v x v (t) 2 + L(t)v 2 (t) dt + N x v (1) -lE v x v (1) 2 subject to          dx v (t) = A(t)x v (t) + B(t)v(t) dt + C(t)x v (t) + D(t)v(t) dw 1 (t), x v (0) = x 0 , (<label>22</label></formula><formula xml:id="formula_56">)</formula><formula xml:id="formula_57">dy(t) = h(t, x v (t))dt + f (t)dw v 2 (t), y(0) = 0.<label>(23)</label></formula><p>Here</p><formula xml:id="formula_58">M (•) ≥ 0, L(•) &gt; 0, 1 L(•) , A(•), B(•), C(•)</formula><p>and D(•) are uniformly bounded and deterministic; N ≥ 0 is a constant; x 0 , h(•, •) and f (•) satisfy the assumptions introduced in Section I.</p><p>Note that neither Wonham's separation theorem nor Bellman's optimality principle works here. However, Theorem 2.1 obtained in this technical note is still valid. In what follows, we solve the LQ problem with the help of Theorems 2.1 and 3.1. Define the Hamiltonian function as below.</p><formula xml:id="formula_59">H(t, x, y, v; p, q, Q) = A(t)x + B(t)v p + C(t)x + D(t)v q + h(t, x) f (t) Q + 1 2 M (t) x -y 2 + L(t)v 2 . (<label>24</label></formula><formula xml:id="formula_60">)</formula><p>The corresponding adjoint equations are reduced to  Note that since u(•) depends on the mean value of the state via (p(•), q(•)), the control is different from its classical counterpart.</p><formula xml:id="formula_61">           -dP (t) = 1 2 M (t) x(t) -lE u x(t) 2 + 1 2 L(t)u 2 (t) -M (t)x(t)lE u x(t) dt -Q(t)dw 2 (t), P (1) = 1 2 N x(1) -lE u x(1) 2 (25) and            -dp(t) = A(t)p(t) + C(t)q(t) + 1 f (t) h x (t, x(t))Q(t) + M (t) x(t) -lE u x(t) dt -q(t)dw 1 (t), p(1) = N x(1) -lE u x(1) . (<label>26</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUDING REMARKS</head><p>Combining maximum principle with nonlinear filtering, we provide a novel approach to study Problem (MFC) in this technical note. First, we use Theorem 2.1 to find all candidate optimal controls, which are related to the conditional expectations of x t and (p t , q t , Q t ) with respect to F y t . Then we use Theorem 3.1 to calculate the conditional expectations. This approach avoids lots of complicated stochastic calculus in infinite dimensional spaces, in contrast with <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b14">[15]</ref>. Thus it is a more convenient and direct way to solve Problem (MFC).</p><p>We highlight that an explicit form of optimal control strongly depends on the special structure of the state, the cost and the observable information. Otherwise, it is hard to explicitly solve some general optimal control problems with partial information. Recently, <ref type="bibr" target="#b10">[11]</ref> investigated the structure of optimal control by the linearization of nonlinear problems. It is probably an alternative method to solve these problems, and we hope to study this topic in future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 f</head><label>1</label><figDesc>proceed to characterize (27) by using the filtering of BSDEs. Applying Theorem 3.1 to (26) and (23) with v = u, we derive the following nonlinear filtering equation:                     -dp(t) = A(t)p(t) + C(t)q(t) + 1 f (t) × Q(t)h x (t, x(t)) + M (t) x(t) -lE u x(t) dt -1 f (t) Õ p(t)h(t, x(t)) -p(t) ĥ(t, x(t)) w(t), p(1) = N x(1) -lE u x(1) ,where w(•) and x(•) are governed by w(t) = t 0 (s) dy(s)ĥ(s, x(s))ds and         dx(t) = A(t)x(t) + B(t)u(t) dt + 1 f (t) Õ x(t)h(t, x(t)) -x(t) ĥ(t, x(t)) d w(t),x(0) = x 0 , respectively. So we have Proposition 4.1. If u(•) is an optimal control, u(•) is identical with (27).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. , NO. , FEBRUARY 2014.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Preprint submitted to IEEE Transactions on Automatic Control. Received: July 5, 2013 09:01:44 PST</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank four anonymous referees for their valuable comments, which lead to a much better version of this technical note.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A maximum principle for SDE&apos;s of mean-field type</title>
		<author>
			<persName><forename type="first">D</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Djehiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Optimization</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="341" to="356" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bensoussan</surname></persName>
		</author>
		<title level="m">Stochastic Control of Partially Observable Systems</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Linearquadratic mean field games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bensoussan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C J</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C P</forename><surname>Yam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Yung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Working paper</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mean-field backward stochastic differential equations and related partial differential equations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Buckdahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and Their Applications</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="3133" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Backward stochastic differential equations in finance</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">El</forename><surname>Karoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Quenez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Finance</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="71" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A maximum principle for partial information backward stochastic control problems with applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2106" to="2117" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large-population LQG games involving a major player: the Nash certainty equivalence principle</title>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="3318" to="3353" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Liptser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Shiryayev</surname></persName>
		</author>
		<title level="m">Statistics of Random Processes</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A mean-field stochastic maximum principle via Malliavin calculus</title>
		<author>
			<persName><forename type="first">T</forename><surname>Meyer-Brandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Øksendal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastics: An International Journal of Probability and Stochastic Processes</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="643" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adapted solution of a backward stochastic differential equation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pardoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems &amp; Control Letters</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="55" to="61" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Control and Optimization: The Linear Treatment of Nonlinear Problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Rubio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Manchester University Press</publisher>
			<pubPlace>Manchester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The maximum principle for partially observed optimal control of stochastic differential equations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1596" to="1617" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Kalman-Bucy filtering equations of forward and backward stochastic systems and applications to recursive optimal control problems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">342</biblScope>
			<biblScope unit="page" from="1280" to="1296" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The filtering equations of forward-backward stochastic systems with random jump and applications to partial information stochastic optimal control</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Stochastic Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1003" to="1019" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the necessary conditions of optimal controls for stochastic partial differential equations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1462" to="1478" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
