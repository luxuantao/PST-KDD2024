<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Benchmark for Automatic Medical Consultation System: Frameworks, Tasks and Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-04-19">19 Apr 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
							<email>chenwei18@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiwei</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongyi</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qianyuan</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianye</forename><surname>Hao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Intelligence and Computing</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<postCode>300072</postCode>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiajie</forename><surname>Peng</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Research Institute of automatic and Complex Systems</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Data Science</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Research Institute of automatic and Complex Systems</orgName>
								<orgName type="institution" key="instit2">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Benchmark for Automatic Medical Consultation System: Frameworks, Tasks and Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-04-19">19 Apr 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/xxxxxx</idno>
					<idno type="arXiv">arXiv:2204.08997v1[cs.CL]</idno>
					<note type="submission">Received on XXXXX; revised on XXXXX; accepted on XXXXX</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motivation:</head><p>In recent years, interest has arisen in using machine learning to improve the efficiency of automatic medical consultation and enhance patient experience. In this paper, we propose two frameworks to support automatic medical consultation, namely doctor-patient dialogue understanding and taskoriented interaction. A new large medical dialogue dataset with multi-level fine-grained annotations is introduced and five independent tasks are established, including named entity recognition, dialogue act classification, symptom label inference, medical report generation and diagnosis-oriented dialogue policy. Results: We report a set of benchmark results for each task, which shows the usability of the dataset and sets a baseline for future studies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online medical consultation has shown great potential in improving the quality of healthcare services while reducing cost <ref type="bibr" target="#b1">(Al-Mahdi et al., 2015;</ref><ref type="bibr" target="#b30">Singh et al., 2018)</ref>, especially in the era of raging epidemics such as Coronavirus <ref type="bibr" target="#b31">(Singhal, 2020)</ref>. This fact has accelerated the emergence of online medical communities like SteadyMD<ref type="foot" target="#foot_0">1</ref> and Haodafu<ref type="foot" target="#foot_1">2</ref> . These platforms provide a medium for doctors and patients to communicate with each other remotely, which is called telemedicine <ref type="bibr" target="#b35">(Wootton, 2001;</ref><ref type="bibr" target="#b5">Craig and Petterson, 2005)</ref>.</p><p>Typically, in telemedicine, the patient first provides a brief summary of their physical condition, i.e., self-report, and then a doctor is designated to communicate with the patient to learn more about the patient's health condition. After sufficient inquiry, the doctor may make a diagnosis and provide further medical advice. The electronic record of this process is called Medical Consultation Record (MCR). Figure <ref type="figure">1</ref> demonstrates an example of MCR, which consists of patient's self-report, plain text of dialogue and corresponding disease category.</p><p>Recently, researchers have paid close attention to develop automatic approaches to facilitate online consultation service. Research topics include medical named entity recognition <ref type="bibr" target="#b45">(Zhou et al., 2021)</ref>, drug recommendation <ref type="bibr" target="#b44">(Zheng et al., 2021)</ref>, automatic text-based diagnosis <ref type="bibr" target="#b3">(Chen et al., 2020)</ref>, health question answering <ref type="bibr" target="#b8">(He et al., 2020)</ref>, medical report generation <ref type="bibr" target="#b10">(Joshi et al., 2020)</ref> and dialogue policy <ref type="bibr" target="#b33">(Wei et al., 2018)</ref>. Although progresses have been made to support automatic medical consultation from different perspectives, there is still a large gap between existing work and real-world application. We summarize this gap to two major limitations: 1) Lack of unified design of frameworks and tasks for automatic medical consultation; 2) Lack of benchmark datasets to support the development of research and application.</p><p>In this paper, we make the first step to build a framework for automatic medical consultation and propose several tasks to cover the entire procedure. Two modes of frameworks are proposed to support both ? ? "main" -2022/4/20 -0:56 -page 2 -#2</p><formula xml:id="formula_0">? ? ? ? ? ? 2</formula><p>Wei Chen et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>!"#$%&amp;"'()*+</head><p>!"#$%$"#&amp;%'#()%**&amp;+%,#-).+#/*#')0#1)2+'#%#(%"3! ,-.#(/0"+ !!"</p><p>!"#$"%4#5&amp;%1#(/+'#1&amp;+#$%$"6'#'1//7#7//8#7)8+9#:'#)1#;%1+*"#'1//7'9" &amp;'$()*$4#&lt;/2+1)2+'#;%1+*,#'/2+1)2+'#+==#'/&gt;?,#%@(#'/2+1)2+'#2&gt;'&amp;"3" !"#$"%4#A/+'#"/&gt;*#$%$"#&amp;%.+#%#-+.+*#/*#./2)1)@=9" &amp;'$()*$#"B/,#1&amp;+#C&amp;)7(#)'#)@#=//(#'?)*)1'3"</p><p>!"#$"%#"D%'#1&amp;+#$%$"#1%8+@#%@"#2+()C)@+'9" &amp;'$()*$#"!+()7%CE.)1%#%@(#2/@12/*)77/@)1+3"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>!!"</head><p>,-1".1"+2.*"/()3+</p><p>$%&amp;'()*+',%-+ Fig. <ref type="figure">1</ref>. An example of medical consultation record, where the text is translated from Chinese.</p><p>static and dynamic scenarios, namely, dialogue understanding and taskoriented interaction. The understanding framework aims to understand the doctor-patient dialogue and generate rich and useful labels to support various scenarios in automatic medical consultation. The interaction framework is designed to learn dialogue policy, i.e., play the role of agent to collect information from the patient and provide professional diagnosis and medical advice, etc. We build a corpus called DialoAMC with multilevel annotations to support the research and application development of five tasks under the two modes. We develop widely used neural-based models for each task and report a set of benchmark results, which shows the usability of the corpus and sets a baseline for future studies. We conduct a comprehensive analysis of our corpus and tasks to show great future opportunities.</p><p>The main contributions of this paper can be summarized as follows: 1) We propose a unified design of frameworks and tasks for automatic medical consultation and introduce DialoAMC, a large-scale annotated medical dialogue corpus, whose superiority makes it potentially a great benchmark for medical dialogue modeling; 2) We establish a series of tasks based on the corpus and report a set of benchmark results. We will release the corpus to the community for future research.</p><p>The rest of the paper is organized as follows: The related work is introduced in the Section 2. We introduce the design of frameworks and tasks for automatic medical consultation in Section 3. Section 4 demonstrates the corpus construction and analysis. In Section 5, we present the experimental settings and results, followed by the conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To build an automatic medical consultation system, learning from a large amount of actual doctor-patient conversations and directly imitate human behavior may be the best strategy. There are already a few medical dialogue corpus introduced by previous studies. These corpus can be roughly divided into two categories.</p><p>One such category is original medical conversations corpus between patients and doctors with no annotations. MedDialog <ref type="bibr" target="#b39">(Zeng et al., 2020)</ref> is a large scale medical dialogue dataset that contains a Chinese dataset with 3.4 million conversations covering 172 specialties of diseases and an English dataset with 0.26 million conversations covering 96 specialties of diseases. KaMed <ref type="bibr" target="#b13">(Li et al., 2021)</ref> is a knowledge aware medical dialogue dataset that contains over 60,000 medical dialogue sessions and is equipped with external medical knowledge from Chinese medical knowledge platform. The tasks built on these corpus are usually response generation in dialogue systems, on which researchers can build automated medical chatbots. However, the responses generated by such end-toend chatbots lack interpretability and controllability, which has strong limitations in healthcare applications.</p><p>Another category is the annotated doctor-patient medical dialogue corpus. The annotated content of these corpus is related to the task they focus on and the researchers establish a series of medical dialogue modeling tasks including natural language understanding (NLU), natural language generation (NLG) and dialogue policy (DP). MSL <ref type="bibr" target="#b29">(Shi et al., 2020)</ref> is a dataset for slot filling task which aims to transform a natural language medical query in which colloquial expressions exist into the formal representation with discrete logical forms to perform correct query. CMDD <ref type="bibr" target="#b18">(Lin et al., 2019)</ref>, SAT <ref type="bibr" target="#b7">(Du et al., 2019)</ref> and MIE <ref type="bibr" target="#b42">(Zhang et al., 2020)</ref> are datasets for medical information extraction task, which is extract mentioned entities and their corresponding status. MZ <ref type="bibr" target="#b33">(Wei et al., 2018)</ref>, DX <ref type="bibr" target="#b37">(Xu et al., 2019)</ref>, RD/SD <ref type="bibr" target="#b15">(Liao et al., 2020)</ref> are datasets that contain structured symptom features to learn the dialogue policy for symptom based automatic diagnosis. Chunyu <ref type="bibr" target="#b17">(Lin et al., 2021)</ref> is a dataset for endto-end diagnosis-oriented response generation task. Meddg <ref type="bibr" target="#b20">(Liu et al., 2020)</ref> contains more than 17K conversations with annotated entities, and two kinds of medical dialogue tasks are establish. One is the next entity prediction and the other is the doctor response generation.</p><p>One challenge of existing datasets is the medical label insufficiency problem. The majority of datasets only provide one specific medical labels, e.g., entities. Moreover, their labels are too coarse to distinguish the actual intents or actions of the utterance. Another challenge is the small scale of existing annotated datasets, typically on the order of hundreds of dialogues. Compared with existing datasets, DialoAMC is competitive in both annotation granularity and scale whose superiority makes it a great benchmark for automatic medical consultation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Automatic Medical Consultation: Frameworks and Tasks</head><p>We present our framework and task design in Figure <ref type="figure" target="#fig_0">2</ref>. The static framework is dedicated to extracting various knowledge representations from medical dialogues, while the dynamic framework aims to build interactive practical applications based on these extracted knowledge representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dialogue Understanding Framework</head><p>The understanding framework includes 4 tasks: Named Entity Recognition (NER), Dialogue Act Classification (DAC), Symptom Label Inference (SLI) and Medical Report Generation (MRG).</p><p>Named Entity Recognition Medical NER task aims to recognize predefined medical named entities from medical texts <ref type="bibr" target="#b45">(Zhou et al., 2021;</ref><ref type="bibr" target="#b34">Wen et al., 2021)</ref>  Dialogue Act Classification DAC is the task of classifying an utterance with respect to the function it serves in a dialogue, i.e. the act the speaker is performing <ref type="bibr" target="#b22">(Liu et al., 2017)</ref>. In medical dialogues, the identification of dialogue act is an important aspect in analyzing the doctor's and patient's intent and what they are trying to convey.</p><p>Symptom Label Inference Symptoms are the main topics discussed in medical dialogues and an important basis for doctors to make a diagnosis <ref type="bibr" target="#b18">(Lin et al., 2019)</ref>. The goal of SLI task is to identify mentioned symptoms from the dialogue, align them to standardized names, and determine whether a patient suffers from these symptoms. SLI task generates a clearer structured symptom features about the patient, which facilitates the doctor's clinical judgment in the next step.</p><p>Medical Report Generation Medical report captures and summarizes the important parts of the medical conversation needed for clinical decision making and subsequent follow ups <ref type="bibr" target="#b10">(Joshi et al., 2020)</ref>. As a way to record and convey medical information, MRG task addresses a practical need and plays an important role in medical practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task-oriented Interaction framework</head><p>The interaction framework controls the process of man-machine dialogue and determines the action to users at the moment according to the historical information. For interaction framework, we introduce Diagnosis-oriented Dialogue Policy (DDP) task which follows the setting of task-oriented dialogue system <ref type="bibr" target="#b33">(Wei et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diagnosis-oriented Dialogue Policy</head><p>The DDP task aims to learn the optimal policy for symptom-based automatic disease diagnosis. The policy is expected to efficiently find potential symptoms of patients and make a correct diagnosis, through several turns of interaction. It is worth noting that the training data required for DDP is exactly the structured symptom features the SLI task needs to predict.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Medical Dialogue Corpus: DialoAMC</head><p>'In this section, we present our collection and analysis of the annotated dataset. The raw data comes from Muzhi<ref type="foot" target="#foot_2">3</ref> , a Chinese online health community that provides professional medical consulting service to patients. We collect extensive medical consultation records (see in Figure <ref type="figure">1</ref>) for 10 pediatric diseases. After removing some incomplete samples and samples with too short dialogues, we annotate the filtered samples to form our our medical dialogue corpus, which we call DialoAMC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Annotation Scheme</head><p>The annotation scheme is designed by medical experts with consideration of our task design as well as actual scenarios of online consultation. Specifically, we collect multi-level annotations for each medical consultation record, including token level, utterance level, and dialogue level. At token level, the annotator is asked to find medical named entities; at utterance level, the intention of each utterance is annotated; at dialogue level, the symptom features are collected, and the medical report is manually written.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical Named Entity</head><p>We define 5 main categories of entities for annotation after discussing with domain experts, i.e., symptom (SX) , drug name (DN), drug category (DC), examination (EX) and operation (OP). These categories of entities we believe are important for understanding the doctor-patient dialogue. Among them, drug name represents a specific drug name while drug category represents a class of drugs with a certain efficacy. For example, "aspirin" belongs to DN while "anti-inflammatory drug" belongs to DC. Besides, OP represents related medical operations, such as "infusion", "atomization", etc. To facilitate understanding, several examples of each categories of entity are listed in Table <ref type="table" target="#tab_0">1</ref>. Inside-outside-beginning (BIO) <ref type="bibr" target="#b26">(Ramshaw and Marcus, 1999)</ref> tagging scheme is employed, where "B" and "I" determine the boundary of an entity. For each Chinese character, "B" stands for the beginning of the entity, "I" means inside, and "O" means other. This results in 11 possible tags for tokens. We assign an initial label to each token using a rule-based algorithm <ref type="bibr" target="#b0">(Aho and Corasick, 1975)</ref> to prompt the annotation process.</p><p>Dialogue Act The categories of dialogue acts are determined according to the specific content of the utterance. It can be broadly divided into two big categories: request (R) and inform (I), one means "ask for information", and another means "tell the information". We further categorize the content of information conveyed as: basic information (BI), symptom (SX), etiology (ETIOL), existing exam and treatment (EET), medical advice (MA), drug recommendation (DR), precautions (PRCTN), diagnose (DIAG). There are both request and inform versions for all categories except DIAG. Utterances that does not fall into the above categories will be labeled as other <ref type="bibr">(OTR)</ref>.</p><p>This results in a total of 16 possible categories of dialogue acts in our scheme. Each utterance in a dialogue is tagged with one of these categories. In this paper, we use abbreviations to denote specific dialogue acts. For example, R-SX is abbreviate for request-symptom, which represents the intent of asking someone for relevant symptoms. To be more intuitive, we list the example utterances corresponding to each dialogue act category in Table <ref type="table" target="#tab_1">2</ref>.</p><p>Symptom Label Based on the annotations of medical entities, all symptom entities that appear in a dialogue can be found using BIO tags. On this basis, each symptom is tagged with an extra label: Positive (POS), Negative (NEG) or Not Sure (NS), which indicates whether the patient really has the symptom. This label clarifies the relationship between the symptoms and the patient, as the patient does not necessarily suffer from all the symptoms that appear in the conversation. The label can be inferred by observing the utterance and its context in which the symptom is located. Besides, all identified symptoms are normalized by linking them to the most relevant one on SNOMED-CT2<ref type="foot" target="#foot_3">4</ref> , which can unify different expressions of the same symptom into one standard name. Symptoms mentioned in self-report are also identified and normalized.</p><p>Medical Report Annotators are also required to write a report in specified format to summarize the medical consultation case. It contains six parts: 1) chief complaint: patient's main symptoms or signs; 2) present disease: description of main symptoms; 3) auxiliary examination: the patient's existing examinations, examination results, records, etc; 4) past medical history: previous health conditions and illnesses; 5) diagnosis: diagnosis of disease; 6) suggestions: doctor's suggestions of inspection recommendations, drug treatment and precautions. Annotators are required to fill in these parts and leave it blank if the part is not mentioned in the dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inter-Annotator Agreement</head><p>For the annotation of medical dialogues, we develop a web-based tool which can be utilized for general-purpose multi-turn dialogue labeling. We recruit undergraduates and postgraduates in medical school to annotate our corpus. All annotators are people who are willing to participate and over the age of 18.</p><p>Two annotations per dialogue are gathered, and inconsistent parts are further finalized by a third annotator. We use Cohen's kappa coefficient <ref type="bibr" target="#b2">(Banerjee et al., 1999)</ref> to estimate the inter-annotator agreement. For the annotations of medical named entities and dialogue acts, the kappa coefficients are 83.11% and 76.41% respectively; For the annotations of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Corpus Analysis</head><p>Corpus Statistics DialoAMC contains a total of 4,116 annotated samples with 164,731 utterances, which covers 10 pediatric diseases: bronchitis, fever, diarrhea, upper respiratory infection, dyspepsia, cold, cough, jaundice, constipation and bronchopneumonia. Each dialogue contains an average of 40 utterances, 523 Chinese characters (580 characters if including self-report) and 26 entities (see in Table <ref type="table" target="#tab_2">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue Content Analysis</head><p>The distribution of number of entity categories and dialogue act categories are shown in Figure <ref type="figure" target="#fig_2">3</ref>(a) and 3(b). Briefly, symptom entities appear the most in conversations, about 58.3%. Similarly, the two categories with the highest proportion of dialogue acts are I-SX and R-SX. This indicates that doctor-patient conversations mainly discuss the patient's symptoms. Examinations, drugs, advice and precautions are also common topics, this suggests that patients try to find medical solutions in consultations.</p><p>It is worth noting that for any specific category of dialogue act, it is either almost from doctors or patients (Figure <ref type="figure" target="#fig_2">3(b)</ref>). However, there are some exceptions. For example, the category I-SX means telling the other about the symptoms, which intuitively will only come from the patient who tells the doctor his symptom. But sometimes the doctor may remind the patient what symptoms they actually have, based on the their previous vague description. For example, the utterance "your body temperature is relatively high, it is febrile" from the doctor will be labeled as I-SX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue Structure Analysis</head><p>Figure <ref type="figure" target="#fig_2">3</ref>(c) present the positional characteristics of dialogue acts. We divide utterances in a dialogue into five parts according to their locations. For example, 0-20% means the sentences appeared in the first fifth of the conversation. From the Figure, we conclude that with the in-depth of medical consultation, the focus gradually shifts from symptoms to drugs, treatments and precautions. Clearly, there are certain regularities in the structure of medical dialogues for the purpose of diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symptoms Analysis</head><p>We present the statistics of symptoms and symptom labels in Table <ref type="table" target="#tab_3">4</ref>. Each self-report and dialogue contains 1.7 and 6.6 (unique) symptom entities on average. In the dialogue, the number of non-positive symptom entities account for nearly 40%, which means that a large proportion of the symptoms in the conversation may not be related to the patient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Medical Reports Analysis</head><p>In the annotation of medical reports, without being provided with true disease labels, the annotators are required to populate the diagnosis part with the patient's disease they infer from  the conversation. Therefore, the accuracy of the content of this part can roughly assess how well the annotator understands the dialogue. By regex matching, we find that in 84.7% of the reports, the content of the diagnosis part contains the text of the actual disease or the key concepts" which ensures the quality of medical reports acceptably.</p><p>It is worth noting that some diseases are hard to distinguish from others, or are themselves a symptom of other diseases. In this case, annotators are easily confused. For example, when the real disease is Cold, only 65.6% of the reports contain the key concepts of cold in the diagnosis part. When the disease is Jaundice, the proportion is as high as 98.1%.</p><p>Besides, the Present disease and Suggestions part has about 30 and 20 words on average respectively, which occupy the main content of medical reports, while a considerable percentage (about 60%) of past medical history is empty, because this part is less involved in the dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DialoAMC as a New Benchmark</head><p>As introduced in Section 3, we break down the medical consultation modelling into two modes of frameworks, comprising a total of five tasks. To show the potential usefulness of DialoAMC, we establish a standard split for DialoAMC at the dialogue level, and report a benchmark result for each of the task: NER, DAC, SLI, MRG and DDP. The split is consistent across all tasks, consisting of a training set with 2,472 dialogues, a develop set with 833 dialogues and a test set with 811 dialogues.</p><p>Before presenting the experimental results, we first introduce some notations. Let X = {x 1 , x 2 , ..., x T } be a piece of doctor-patient dialogue, where x i = {x i,1 , x i,2 , ..., x i,n } is the i-th utterance, and x i,j ? V is the j-th token in x i . The self-report and the disease category of the patient are denoted as x 0 and y ? D respectively, then a medical consultation record can be represented as: {x 0 , X, y}.</p><p>The formalization of each task will be introduced in each subsection, and readers can refer to the notations in Table <ref type="table" target="#tab_4">5</ref> to better understand our task and evaluation settings. Table <ref type="table">6</ref>. Experimental results for medical NER task. The up arrows and down arrows indicate that the higher the better and the lower the better for the number in the column respectively. All the numbers are percentage values, with the highest value highlighted. It is the same for other tables of experimental results.</p><formula xml:id="formula_1">Models P ? R ? F1 ?</formula><p>Lattice LSTM <ref type="bibr" target="#b41">(Zhang and Yang, 2018)</ref> 90.80 90.23 90.52 BERT-CRF <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> 88.46 92.35 90.37 ERNIE <ref type="bibr" target="#b43">(Zhang et al., 2019)</ref> 88.87 92.27 90.53 FLAT <ref type="bibr" target="#b14">(Li et al., 2020)</ref> 88.76 92.07 90.38 LEBERT <ref type="bibr" target="#b21">(Liu et al., 2021)</ref> 87.43 92.58 89.93</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Named Entity Recognition</head><p>Task formalization Robust medical named entity recognition (NER) is the first step in understanding doctor-patient conversations. The NER task is designed to automatically predict the boundaries and categories of predefined medical named entities contained in the dialogue. Formally, the NER task aims to predict the BIO label b j i ? B for each token x i,j given the utterance x i .</p><p>Experimental settings We use several popular Chinese named entity models as baselines, including: 1) Lattice LSTM <ref type="bibr" target="#b41">(Zhang and Yang, 2018)</ref>, an extension of Char-LSTM that incorporates lexical information into native LSTM; 2) BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref>, a bidirectional Transformer encoder with large-scale language pre-training; 3) ERNIE <ref type="bibr" target="#b43">(Zhang et al., 2019)</ref>; an improved BERT that adopts entity-level masking and phraselevel masking during pre-training; 4) FLAT <ref type="bibr" target="#b14">(Li et al., 2020)</ref>, a flat-lattice Transformer that converts the lattice structure into a flat structure consisting of spans; 5) LEBERT <ref type="bibr" target="#b21">(Liu et al., 2021)</ref>, a lexicon enhanced BERT for Chinese sequence labelling, which integrates external lexicon knowledge into BERT layers by a lexicon adapter layer. We train each model for 10 epochs, using the default parameters of the corresponding code repository. For evaluation, we report token-level metrics, including Precision (P), Recall (R) and F1 Score (F1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head><p>In Table <ref type="table">6</ref>, we present the experimental results of the NER task. All baselines achieve F1 scores around 90%. Among them, Lattice LSTM has the highest Precision, while LEBERT performs best on Recall. The decent performance of the metrics show that the NER task for medical dialogue is highly feasible in our settings. Table <ref type="table">7</ref>. Experimental results for DAC task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Dialogue Act Classification</head><formula xml:id="formula_2">Models P ? R ? F1 ? Acc ?</formula><p>TextCNN <ref type="bibr" target="#b4">(Chen, 2015)</ref> 74.02 70.92 72.22 78.99 TextRNN <ref type="bibr" target="#b19">(Liu et al., 2016)</ref> 73.07 69.88 70.96 78.53 TextRCNN <ref type="bibr" target="#b12">(Lai et al., 2015)</ref> 73.82 72.53 72.89 79.40 DPCNN <ref type="bibr" target="#b9">(Johnson and</ref><ref type="bibr">Zhang, 2017) 74.30 69.45 71.28 78.75 BERT (Devlin et al., 2018)</ref> 75.35 77.16 76.14 81.62 ERNIE <ref type="bibr" target="#b43">(Zhang et al., 2019)</ref> 76.18 77.33 76.67 82.19 of each utterance, i.e., to predict the DA label a i ? A for each utterance x i .</p><p>Experimental settings DAC is a typical text classification task. Baseline models include non-pretrained models: TextCNN <ref type="bibr" target="#b4">(Chen, 2015)</ref>, TextRNN <ref type="bibr" target="#b19">(Liu et al., 2016)</ref>, TextRCNN <ref type="bibr" target="#b12">(Lai et al., 2015)</ref> and DPCNN <ref type="bibr" target="#b9">(Johnson and Zhang, 2017)</ref>, and pretrained models: BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> and ERNIE <ref type="bibr" target="#b43">(Zhang et al., 2019)</ref>. We report 4 metrics for evaluations, including Precision (P), Recall (R), F1 Score (F1) and Accuracy (Acc).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head><p>From the results in Table <ref type="table">7</ref>, it can be seen that the pre-trained model has obvious advantages over the traditional neural models in DAC task. The ERNIE model that pre-trained in the phraselevel and entity-level masking manner achieves the best results in the classification task, with the classification accuracy of 82% achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Symptom Label Inference</head><p>Symptom features are the key information to describe the patient's health condition and also the structured training data required for DDP task. The goal of the SLI task is to identify the patient's symptom features from the self-report and the dialogue, and it consists of two cognate sub-tasks: SLI-EXP and SLI-IMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task formalization</head><p>The SLI-EXP task aims to find out the patient's selfprovided symptoms in self-report x 0 , which is called explicit symptoms, denoted by {s 1 , ..., s k }, where s i ? S. In the contrast, the SLI-IMP task aims to find the symptoms and the corresponding labels in the dialogue X, which is called implicit symptoms, denoted by {(s k+1 , l k+1 ), ..., (sn, ln)}, where s j ? S and l j ? L. Compared with the SLI-EXP task, the SLI-IMP task not only needs to identify symptoms, but also predict the labels of symptoms. We do not need to predict symptom labels in the SLI-EXP task because symptoms in self-report are always positive.</p><p>Table <ref type="table">9</ref>. Experimental results for MRG task, where # Turns refers to the average number of interactions between the agent and the patient simulator.</p><formula xml:id="formula_3">Models R-1 ? R-2 ? R-L ? C-F1 ? RD-Acc ?</formula><p>Seq2seq <ref type="bibr" target="#b23">(Nallapati et al., 2016</ref><ref type="bibr">) 54.13 43.98 50.42 41.73 50.34 PG (See et al., 2017</ref><ref type="bibr">) 59.46 49.79 56.34 51.36 58.60 Transformer (Vaswani et al., 2017) 57.25 46.29 53.29 45.64</ref> 56.50 T5 <ref type="bibr" target="#b38">(Xue et al., 2020)</ref> 61.20 50.98 58.18 51.55 49.60 ProphetNet <ref type="bibr">(Qi et al., 2021) 61.18 50.33 57.94 54.61 57.36</ref> Experimental settings We treat the SLI task as a multi-label classification (MLC) problem, where the label space is S for SLI-EXP task and S ? L for SLI-IMP task. We use BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> as the encoder and obtain the latent vector of the self-report or the entire conversation, which is then mapped into the label space using an MLP layer. The training objectives are the binary Cross-Entropy loss between sigmoid activations of MLP outputs and actual labels. The model is denoted as BERT-MLC.</p><p>For SLI-IMP task, we additionally propose a multi-task learning (MTL) <ref type="bibr" target="#b27">(Ruder, 2017)</ref> based model called BERT-MTL that can utilize the BIO labels in NER during training. BERT-MTL has three additional MLP layers on top of BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref>. The role of these three MLP layers is to predict the BIO label of each token, the normalized name of each symptom entity, and the label of each symptom entity. For the first MLP, the input is the hidden vector of each token obtained by BERT encoder, and for the latter two MLPs, the input is the average hidden vector of each symptom entity. The three objectives are trained simultaneously to push the hidden vector of symptom entities to contain more contextual information. We evaluate symptom recognition and symptom inference separately. For symptom recognition, we report two categories of metrics for multi-label classification, including subset accuracy (SA)<ref type="foot" target="#foot_4">5</ref> , hamming loss (HL) and hamming score (HS) in example-based metrics, and precision (P), recall (R) and F1-score (F1) in label-based metrics <ref type="bibr" target="#b40">(Zhang and Zhou, 2013)</ref>. For symptom inference, we report the F1 scores for the three labels (POS, NEG, NS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Results</head><p>The performance of the SLI task is listed in Table <ref type="table" target="#tab_5">8</ref>. For symptom recognition, the performance of subset accuracy (SA) shows that the strict prediction of symptoms is very challenging, especially for implicit symptoms from the entire dialogue (only about 35%?40%). It is probably due to the exponential growth of the prediction space, as up to dozens of symptoms can be mentioned in a single dialogue. In non-strict cases, both SLI-EXP and SLI-IMP tasks can achieve good performance, with label-level F1 scores exceeding 90%. Moreover, the BERT-MLC model that utilizes BIO labels gets better recall in SLI-IMP task, which is also intuitive. For symptom inference, BERT-MTL has a slight advantage in the identification for the NEG and NS categories of symptoms. It is obvious that inferring the two categories of symptoms is obviously harder than POS, since it often requires more contextual information. Especially for the symptoms that appear in the doctor's utterances, it is highly probable that the patient's response needs to be observed and analyzed to determine the labels. The results suggest that more efforts are needed to improve the symptom inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Medical Report Generation</head><p>Task formalization The medical report is the summarized patient profile according to the medical consultation record. Formally, the MGR task aims to generate a piece of text R = {r 1 , ..., rm} based on the self-report and the dialogue, where r i ? V. Experimental settings We treat the MGR task as a text-to-text generation problem. The baseline models include: 1) Seq2seq <ref type="bibr" target="#b23">(Nallapati et al., 2016)</ref>, a LSTM-based encoder-decoder model with attention mechanism; 2) Pointer-Generator (PG) <ref type="bibr" target="#b28">(See et al., 2017)</ref>, a improved Seq2Seq model that allows tokens from the source to be directly copied during decoding; 3) Transformer <ref type="bibr" target="#b32">(Vaswani et al., 2017)</ref>, the basic model most commonly used in pre-training that based solely on attention mechanisms; 4) T5 <ref type="bibr" target="#b38">(Xue et al., 2020)</ref>, a unified Text-to-Text Transformer pre-trained on large text corpus; 5) ProphetNet <ref type="bibr" target="#b25">(Qi et al., 2021)</ref>, a large-scale pretrained generative Transformer based on future prediction strategies. We measure model performance on standard metrics of ROUGE <ref type="bibr" target="#b16">(Lin, 2004)</ref> scores that widely used for evaluating automatic summarization task, including ROUGE-1/2/L (R-1/2/L). Besides, we also report Concept F1 score (C-F1) <ref type="bibr" target="#b10">(Joshi et al., 2020)</ref> to measure the model's effectiveness in capturing the medical concepts that are of importance, and Regex-based Diagnostic Accuracy (RD-Acc), to measure the model's ability to judge the disease. To compute C-F1, we use the medical entity extractor (BERT-CRF) trained in our NER task to match entities in the predicted summary to the gold summary. Medical entities in the predicted summary that are not present in the original medical report would be false positives and vice versa for false negatives. For RD-Acc, we use the same regex-based approach mentioned in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental results</head><p>The results in Table <ref type="table">9</ref> illustrate that pretrained text generation models can improve the ROUGE scores of medical reports, and T5 performs the best on ROUGE scores. However, T5 performs mediocrely on C-F1 and D-Acc. The performance of the baseline models on C-F1 and D-Acc is still far from acceptable levels. Although pretrained models improve the fluency of the generated texts, there are still great challenges on tasks that are highly knowledge-dependent and require reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Diagnosis-oriented Dialogue Policy</head><p>Task formalization Different from the above tasks, the DDP task is dynamic task that requires interaction with the patient simulator P. Under the premise of knowing the patient's explicit symptoms, the goal of the DDP task is to collect the patient's implicit symptoms and predict the disease, through a limited number of interactions with P.</p><p>In this paper, the patient simulator follows the design of <ref type="bibr" target="#b33">(Wei et al., 2018)</ref>. It can be treated as a function, given the patient's id, and any symptom s ? S as input, P can output the patient's symptom label. An Unknown (UNK) label will be returned if the symptom s does not appear in the dialogue.</p><p>More specifically, the agent asks P for one symptom at each step, and after getting a reply, asks the next symptom, repeating several turns, until the agent obtains enough information to make a disease diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental settings</head><p>Baseline models include DQN <ref type="bibr" target="#b33">(Wei et al., 2018)</ref>, KR-DQN <ref type="bibr" target="#b37">(Xu et al., 2019)</ref>, REFUEL <ref type="bibr" target="#b11">(Kao et al., 2018)</ref>, GAMP <ref type="bibr" target="#b36">(Xia et al., 2020)</ref> and HRL <ref type="bibr" target="#b15">(Liao et al., 2020)</ref>. Except for GAMP, all other methods are based on reinforcement learning (RL). In RL settings, at each turn of interaction, the agent chooses an action from the action space of all symptoms and diseases, and hit symptom queries and correct disease diagnoses are positively rewarded, and the policy is learned by maximizing the expected cumulative reward. In the contrast, GAMP is a GAN-based method that uses the GAN network to avoid generating randomized trials of symptom, and add mutual information to encourage the model to select the most discriminative symptoms. We limit the maximum number of interactions between all agents and the patient simulator to 10.</p><p>Assuming there is no limit of turns of interactions for the agent, we can find all hidden symptoms simply by iterating over the set of all symptoms S. We use the complete symptoms as features to train an support vector machine (SVM) <ref type="bibr" target="#b24">(Noble, 2006)</ref> classifier, which we call the SVM upper Table <ref type="table" target="#tab_0">10</ref>. Experimental results for DDP task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Rec ? Acc ? # Turns SVM-UB <ref type="bibr" target="#b24">(Noble, 2006</ref>) -0.706 -DQN <ref type="bibr" target="#b33">(Wei et al., 2018)</ref> 0.047 0.408 9.75 KR-DQN <ref type="bibr" target="#b37">(Xu et al., 2019)</ref> 0.279 0.485 6.75 REFUEL <ref type="bibr" target="#b11">(Kao et al., 2018)</ref> 0.262 0.505 5.50 GAMP <ref type="bibr" target="#b36">(Xia et al., 2020)</ref> 0.067 0.500 1.78 HRL <ref type="bibr" target="#b15">(Liao et al., 2020)</ref> 0.295 0.556 6.99 bound (SVM-UB), and the accuracy of this model can provide a certain reference for the agent.</p><p>To evaluate the agent, we report three most concerned metrics, namely symptom recall (Rec), diagnostic accuracy (Acc), and average number of turns (# Turns). Symptom recall measures the agent's ability to find potential symptoms of the patient, diagnostic accuracy measures the agent's ability to make a diagnosis based on known symptom characteristics, and number of turns indicates the efficiency of the diagnostic process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental results</head><p>From the results in Table <ref type="table" target="#tab_0">10</ref>, HRL obtains the best symptom recall and diagnostic accuracy compared to other baselines, with an acceptable average number of turns. HRL groups diseases and works in a combination of master and multiple workers, which is more in line with the actual medical division of labor. However, even taking into account the confounding and possible labeling errors of some diseases, the diagnostic accuracy is still far from an acceptable level. It is promising that disease accuracy is now far from the upper bound of SVM classifier, indicating that there is still much room for improvement in the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we propose a unified design of frameworks and tasks for automatic medical consultation system to support both static and dynamic medical scenarios. We introduce a new medical dialogue dataset called DialoAMC with multi-level fine-grained annotations and establish five tasks under the proposed frame. We develop widely used neural-based models for each task and demonstrate experimental results to give an insight about the performance of different tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Funding</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Framework and task design for automatic medical consultation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>"main" -2022/4/20 -0:56 -page 4 -#4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Pie chart for number of entity categories, and bar chart and heat-map for the number and locations of dialogue acts respectively. Note that we exclude category other in the statistics of dialogue acts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Task formalization Dialogue act (DA) directly reflects the intention of the speaker. Formally, the goal of DAC task is to identify the DA category</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>This work is partially supported by Natural Science Foundation of China (No.71991471, No.6217020551), Science and Technology Commission of Shanghai Municipality Grant (No.20dz1200600, 21QA1400600) and Zhejiang Lab (No. 2019KD0AD01). Conflict of Interest: The authors declare no competing interests.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Instructions and examples of the categories we designate for medical named entities.</figDesc><table><row><cell>. Medical related entities are widely present in actual</cell></row><row><cell>doctor-patient conversations, and NER is a basic task for extracting</cell></row><row><cell>medical semantics.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Example of utterances corresponding to our defined categories for dialogue acts.</figDesc><table><row><cell>DA Category</cell><cell cols="2">Abbreviation Example</cell></row><row><cell>Request Basic Information</cell><cell>R-BI</cell><cell>Doctor: How old is the baby?</cell></row><row><cell>Inform Basic Information</cell><cell>I-BI</cell><cell>Patient: Ate some lean meat.</cell></row><row><cell>Request Symptom</cell><cell>R-SX</cell><cell>Doctor: Is this kid still vomiting?</cell></row><row><cell>Inform Symptom</cell><cell>I-SX</cell><cell>Patient: He still have a runny nose and a cough.</cell></row><row><cell>Request Etiology</cell><cell>R-ETIOL</cell><cell>Patient: does a bacterial infection cause diarrhea?</cell></row><row><cell>Inform Etiology</cell><cell>I-ETIOL</cell><cell>Doctor: May be related to fatigue and cold.</cell></row><row><cell cols="2">Request Existing Exam and Treatment R-EET</cell><cell>Doctor: When was glycerin enema used?</cell></row><row><cell cols="2">Inform Existing Exam and Treatment I-EET</cell><cell>Patient: Have been taking antiviral drugs.</cell></row><row><cell>Diagnose</cell><cell>DIAG</cell><cell>Doctor: The baby may have an upper respiratory infection.</cell></row><row><cell>Request Drug Recommendation</cell><cell>R-DR</cell><cell>Patient: There is cough syrup at home. Can the baby drink it?</cell></row><row><cell>Inform Drug Recommendation</cell><cell>I-DR</cell><cell>Doctor: Just drink some probiotics.</cell></row><row><cell>Request Medical Advice</cell><cell>R-MA</cell><cell>Patient: Is it useful to do pediatric massage?</cell></row><row><cell>Inform Medical Advice</cell><cell>I-MA</cell><cell></cell></row></table><note><p>Doctor: Yes, a blood test is required to identify the cause of the infection. Request Precautions R-PRCTN Patient: can i take her to bathe? Inform Precautions I-PRCTN Doctor: Appropriate to give the child more water to drink. Other OTR Patient: Got it, thank you.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Statistics of DialoAMC.</figDesc><table><row><cell>Statistics</cell><cell>Avg.</cell></row><row><cell># of utterances per dialogue</cell><cell>40</cell></row><row><cell># of characters per utterance</cell><cell>523</cell></row><row><cell># of characters per self-report</cell><cell>57</cell></row><row><cell># of entities per dialogue (annotated)</cell><cell>26</cell></row><row><cell># of characters per medical report (annotated)</cell><cell>88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Statistics of symptoms and symptom labels.</figDesc><table><row><cell></cell><cell cols="3">Self-Report Dialogue (POS / NEG / NS) Total</cell></row><row><cell># of Symptoms</cell><cell>1.7</cell><cell>4.0 / 1.6 / 1.0</cell><cell>8.3</cell></row><row><cell cols="4">symptom labels, the kappa coefficients is 92.71%; For medical reports,</cell></row><row><cell cols="2">both reports are remained for reference.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>List of notations for task formalization. The dimension column denotes the size of the set represented by these notations in our task settings. There are three elements in L, namely POS, NEG and NS.</figDesc><table><row><cell cols="2">Sign Description</cell><cell>Dimension</cell></row><row><cell>D</cell><cell>the set of all diseases</cell><cell>10</cell></row><row><cell>B</cell><cell>the set of all BIO tags for named entities</cell><cell>11</cell></row><row><cell>A</cell><cell>the set of all dialogue act categories</cell><cell>16</cell></row><row><cell>S</cell><cell>the set of all normalized symptom names</cell><cell>331</cell></row><row><cell>L</cell><cell>the set of symptom labels</cell><cell>3</cell></row><row><cell>V</cell><cell>vocabulary of source and target tokens</cell><cell>3,138</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8 .</head><label>8</label><figDesc>Experimental results for SLI task, where the value of hamming loss (HL) is multiplied by 1e4.</figDesc><table><row><cell>Models</cell><cell cols="3">Example Level SA ? HL ? HS ? P ? Label Level R ? F1 ?</cell></row><row><cell cols="4">SLI-EXP (Symptom Recognition)</cell></row><row><cell cols="2">BERT-MLC 76.08</cell><cell>8.82</cell><cell>86.25 93.13 89.74 91.40</cell></row><row><cell cols="4">SLI-IMP (Symptom Recognition)</cell></row><row><cell cols="2">BERT-MLC 35.88</cell><cell cols="2">34.57 84.27 92.31 90.66 91.48</cell></row><row><cell cols="2">BERT-MTL 40.19</cell><cell cols="2">31.89 85.26 89.34 94.49 91.84</cell></row><row><cell cols="3">SLI-IMP (Symptom Inference)</cell></row><row><cell></cell><cell cols="3">POS ? NEG ? NS ?</cell></row><row><cell cols="2">BERT-MLC 81.63</cell><cell cols="2">55.46 62.46</cell></row><row><cell cols="2">BERT-MTL 81.31</cell><cell cols="2">57.77 66.32</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.steadymd.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.haodf.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://muzhi.baidu.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.snomed.org/snomed-ct</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Subset accuracy is the most strict metric, indicating the percentage of samples that have all their labels classified correctly.</p></note>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Both code and data is available from https://github.com/lemuria-wchen/imcs21.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Efficient string matching: an aid to bibliographic search</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Corasick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="333" to="340" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Online medical consultation: A review of literature and practice</title>
		<author>
			<persName><forename type="first">I</forename><surname>Al-Mahdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Australasian workshop on health informatics and knowledge management</title>
		<meeting>the 8th Australasian workshop on health informatics and knowledge management</meeting>
		<imprint>
			<publisher>Australian Computer Society Sydney</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="27" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond kappa: A review of interrater agreement measures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian journal of statistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="23" />
			<date type="published" when="1999">1999</date>
			<publisher>Wei Chen et al</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards interpretable clinical diagnosis with bayesian network ensembles stacked on entity-aware cnns</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3143" to="3153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Convolutional neural network for sentence classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Introduction to the practice of telemedicine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Petterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of telemedicine and telecare</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="9" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Extracting symptoms and their status from clinical conversations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02239</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Infusing disease knowledge into bert for health question answering, medical inference and disease name recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.03746</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep pyramid convolutional neural networks for text categorization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="562" to="570" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Dr. summarize: Global summarization of medical dialogue by exploiting local structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.08666</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for text classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-ninth AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised variational reasoning for medical dialogue generation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="544" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Flat: Chinese ner using flat-lattice transformer</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11795</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Task-oriented dialogue system for automatic disease diagnosis via hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14254</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Looking for a few good metrics: Automatic summarization evaluation-how many samples are enough</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NTCIR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph-evolving meta-learning for low-resource medical dialogue generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="13362" to="13370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Enhancing dialogue symptom diagnosis with global attention and symptom graph</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5033" to="5042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Recurrent neural network for text classification with multi-task learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.05101</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Meddg: A large-scale medical consultation dataset for building medical dialogue system</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07497</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.07148</idno>
		<title level="m">Lexicon enhanced chinese sequence labeling using bert adapter</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using context information for dialog act classification in dnn framework</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2170" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Abstractive text summarization using sequenceto-sequence rnns and beyond</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.06023</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">What is a support vector machine?</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Noble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1565" to="1567" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Prophetnet-x: large-scale pre-training models for english, chinese, multi-lingual, dialog, and code generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08006</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Text chunking using transformation-based learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural language processing using very large corpora</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="157" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">An overview of multi-task learning in deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05098</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>See</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04368</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Understanding medical conversations with scattered keyword attention and weak supervision from responses</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8838" to="8845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Online medical consultation: A review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Community Med Public Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1230" to="1232" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A review of coronavirus disease-2019 (covid-19)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The indian journal of pediatrics</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="286" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Task-oriented dialogue system for automatic diagnosis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="201" to="207" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Medical named entity recognition from un-labelled medical records based on pre-trained language models and domain dictionary</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="402" to="417" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Telemedicine</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wootton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bmj</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">7312</biblScope>
			<biblScope unit="page" from="557" to="560" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generative adversarial regularized mutual information policy gradient framework for automatic diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1062" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">End-to-end knowledge-routed relational dialogue system for automatic diagnosis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7346" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11934</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Meddialog: Large-scale medical dialogue dataset</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A review on multi-label learning algorithms</title>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1819" to="1837" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02023</idno>
		<title level="m">Chinese ner using lattice lstm</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mie: A medical information extractor towards medical dialogues</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6460" to="6469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.07129</idno>
		<title level="m">Ernie: Enhanced language representation with informative entities</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Drug package recommendation via interactionaware graph induction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1284" to="1295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An end-to-end progressive multi-task learning framework for medical named entity recognition and normalization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6214" to="6224" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
