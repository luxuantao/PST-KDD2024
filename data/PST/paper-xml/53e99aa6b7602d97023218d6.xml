<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An OS Interface for Active Routers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Larry</forename><surname>Peterson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yitzchak</forename><surname>Gottlieb</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Hibler</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Tullmann</surname></persName>
							<email>tullmann@cs.utah.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jay</forename><surname>Lepreau</surname></persName>
							<email>lepreau@cs.utah.edu</email>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Schwab</surname></persName>
							<email>sschwab@nai.com</email>
						</author>
						<author>
							<persName><forename type="first">Hrishikesh</forename><surname>Dandekar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Purtell</surname></persName>
							<email>apurtell@nai.com</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">John</forename><surname>Hartman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">NAI Labs</orgName>
								<address>
									<addrLine>Network Associates</addrLine>
									<postCode>90034</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<postCode>85721</postCode>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An OS Interface for Active Routers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">068F2F9E6FB41B7DB56C64933CFE0596</idno>
					<note type="submission">received April 1, 2000; revised November 1, 2000.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Active networks</term>
					<term>operating systems</term>
					<term>programmable networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes an operating system (OS) interface for active routers. This interface allows code loaded into active routers to access the router's memory, communication, and computational resources on behalf of different packet flows. In addition to motivating and describing the interface, the paper also reports our experiences implementing the interface in three different OS environments: Scout, the OSKit, and the exokernel.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>one or more execution environments (EE) define a particular programming model for writing active applications (AAs). To date, several EEs have been defined, including ANTS <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b28">[29]</ref>, PLAN <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, and CANES <ref type="bibr" target="#b4">[5]</ref>. At the topmost level are the AAs themselves.</p><p>We were major contributors to developing and documenting the interface <ref type="bibr" target="#b0">[1]</ref> between the bottom two layers in Fig. <ref type="figure" target="#fig_0">1</ref>. This paper focuses on that interface, making two contributions. The first is to motivate and describe the NodeOS interface. While similar in many respects to a standard application programming interface (API), such as POSIX, the emphasis of an active router on forwarding packets makes this interface unique in many ways. The second contribution is to report our experiences implementing the interface in three different operating system (OS) environments: within the Scout kernel <ref type="bibr" target="#b20">[21]</ref>, using the OSKit component base <ref type="bibr" target="#b8">[9]</ref>, and above the exokernel <ref type="bibr" target="#b12">[13]</ref>. Although none of these implementations is complete, each exposes an interesting set of implementation issues for a significant subset of the NodeOS interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DESIGN RATIONALE</head><p>The goal of active networks is to make the network as programmable as possible, while retaining enough common interfaces so that AAs injected into the network can run on as many nodes as possible. In this context, it is not obvious where to draw the line between the EEs and the NodeOS. One answer is that there is no line: a single layer implements all the services required by the AAs. This is analogous to implementing a language runtime system directly on the hardware, as some JavaOSs have done. However, separating the OS from the runtime system makes it easier for a single node to support multiple languages. It also makes it easier to port any single language to many node types. This is exactly the rationale for defining a common NodeOS interface.</p><p>Deciding to separate the NodeOS and the EEs is only the first step; the second step is to decide where the EE/NodeOS boundary should be drawn. Generally speaking, the NodeOS is responsible for multiplexing the node's resources among various packet flows, while the EE's role is to offer AAs a sufficiently high-level programming environment. This is loosely analogous to the distinction between an exokernel and an OS library <ref type="bibr" target="#b12">[13]</ref>. Beyond this general goal, the NodeOS interface is influenced by both a set of high-level design goals, and our experiences implementing the interface on a collection of OS platforms. The rest of this section identifies the high-level design decisions that gave the interface its general shape, while Sections IV-VI discuss how various implementation factors influenced particular details of the interface.</p><p>The first and most important design decision was that the interface's primary role is to support packet forwarding, as opposed to running arbitrary computations. As a consequence, the interface is designed around the idea of network packet flows <ref type="bibr" target="#b5">[6]</ref>: packet processing, accounting for resource usage, and admission control are all done on a per-flow basis. Also, because network flows can be defined at different granularities-e.g., port-to-port, host-to-host, per-application-the interface cannot prescribe a single definition of a flow.</p><p>Second, we do not assume that all implementations of the NodeOS interface will export exactly the same feature set-some implementations will have special capabilities of which EEs (and AAs) may want to take advantage. The interface should allow access to these advanced features. One important feature is the hardware's ability to forward certain kinds of packets (e.g., nonactive IP) at very high speeds. Said another way, packets that require minimal processing should incur minimal overhead. A second feature is the ability to extend the underlying OS itself, i.e., extensibility is not reserved for the EEs that run on top of the interface. The NodeOS interface must allow EEs to exploit these extensions but for reasons of simplicity, efficiency, and breadth of acceptable implementations, the NodeOS need not provide a means for an EE to extend the NodeOS directly. Exactly how a particular OS is extended is an OS-specific issue.</p><p>Our final design decision was a pragmatic one: whenever the NodeOS requires a mechanism that is not particularly unique to active networks, the NodeOS interface should borrow from established interfaces, such as POSIX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ARCHITECTURE</head><p>The NodeOS interface defines five primary abstractions: thread pools, memory pools, channels, files, and domains <ref type="bibr" target="#b0">[1]</ref>. The first four encapsulate a system's four types of resources: computation, memory, communication, and persistent storage. The fifth abstraction, the domain, is used to aggregate control and scheduling of the other four abstractions. This section motivates and describes these five abstractions, and explains the relationships among them. Of the five abstractions, domains and channels are the most novel (NodeOS-specific), threads and memory are variations on traditional designs, and files are mostly standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Domains</head><p>The domain is the primary abstraction for accounting, admission control, and scheduling in the system. Domains directly  follow from our first design decision: each domain contains the resources needed to carry a particular packet flow. A domain typically contains the following resources (Fig. <ref type="figure" target="#fig_1">2</ref>): a set of channels on which messages are received and sent, a memory pool, and a thread pool. Active packets arrive on an input channel (inChan), are processed by the EE using threads and memory allocated to the domain (dotted arc), and are then transmitted on an output channel (outChan).</p><p>Note that a channel consumes not only network bandwidth but also CPU cycles and memory buffers. The threads that shepherd messages across the domain's channels come from the domain's thread pool and the cycles they consume are charged to that pool. Similarly, the input-output (I/O) buffers used to queue messages on a domain's channels are allocated from (and charged to) the domain's memory pool. In other words, one can think of a domain as encapsulating resources used across both the NodeOS and an EE on behalf of a packet flow, similar to resource containers <ref type="bibr" target="#b3">[4]</ref> and Scout paths <ref type="bibr" target="#b24">[25]</ref>.</p><p>A given domain is created in the context of an existing domain, making it natural to organize domains in a hierarchy, with the root domain corresponding to the NodeOS itself. Fig. <ref type="figure" target="#fig_2">3</ref> shows a representative domain hierarchy, where the second level of the hierarchy corresponds to EEs and domains at lower levels are EE-specific. In this example, the EE implemented in domain A has chosen to implement independent packet flows in their own domains (domains C through Z), while the EE running in domain B aggregates all packets on a single set of channel, memory, and thread resources. The advantage of using domains that correspond to fine-grained packet flows-as is the case with the EE contained in domain A-is that the NodeOS is able to allocate and schedule resources on a per-flow basis. (Domain A also has its own channels, which might carry EE control packets that belong to no specific subflow.)</p><p>The domain hierarchy is used solely to constrain domain termination. A domain can be terminated by the domain itself, by the parent domain that created it, or by the NodeOS because the domain has violated some resource usage policy. Domain termination causes the domain and all its children to terminate, the domain's parent to be notified, and all resources belonging to the terminated domains are returned to the NodeOS.</p><p>Each parent domain contains a handler that is invoked just before a child domain is terminated by the NodeOS. This "imminent termination" handler allows the parent domain (generally running the EE) to reconcile any state it may have associated with the dying domain and free any resources it may have allocated on the child domain's behalf. The handler is invoked in the context of a thread in the parent domain; thus, the parent domain pays for cleaning up an errant child domain. The handler is given a small, fixed amount of time to complete its cleanup. If the thread exceeds this limit, it and the domain in which it runs are terminated.</p><p>In contrast to many hierarchical resource systems (e.g., stride CPU schedulers <ref type="bibr" target="#b27">[28]</ref>), the domain hierarchy is independent of resource allocation. That is, each domain is allocated resources according to credentials presented to the NodeOS at domain creation; resources given a child domain are not deducted from the parent's allocation, and resources belonging to a child domain are not returned to the parent domain when the child terminates. This design was based on the observation that requiring resources to be allocated in the same hierarchical manner as domains results is an overly restrictive resource model. For example, suppose an ANTS EE runs in a domain and creates new (sub)domains in response to incoming code capsules. These new domains should be given resources based solely on their credentials (identity). They should not be restricted to some subset of the ANTS EE's resources, which they would be if resources followed the domain hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Thread Pool</head><p>The thread pool is the primary abstraction for computation. Each domain contains a single thread pool that is initialized when the domain is created. Several parameters are specified when creating a thread pool, including the maximum number of threads in the pool, the scheduler to be used, the cycle rate at which the pool is allowed to consume the central processing unit (CPU), the maximum length of time a thread can execute between yields, the stack size for each thread, and so on.</p><p>Because of our decision to tailor the interface to support packet forwarding, threads execute "end-to-end"; that is, to forward a packet they typically execute input channel code, EE-specific code, and output channel code. Since a given domain cuts across the NodeOS and an EE, threads must also cut across the NodeOS/EE boundary (at least logically). This makes it possible to do end-to-end accounting for resource usage. Note that from the perspective of the NodeOS interface, this means that the thread pool primarily exists for accounting purposes. Whether or not a given NodeOS preallocates the specified number of threads is an implementation issue. Moreover, even if the NodeOS does preallocate threads, these threads may not be able to handle all computation that takes place on behalf of the thread pool; for example, they may not be allowed to run in supervisor mode. Any thread running on behalf of the thread pool, no matter how its implemented, is charged to the pool.</p><p>The fact that a thread pool is initialized when a domain is created, and threads run end-to-end, has two implications. First, there is no explicit operation for creating threads. Instead, threads in the pool are implicitly activated, and scheduled to run, in response to certain events, such as message arrival, timers firing, and kernel exceptions. Second, there is no explicit operation for terminating a thread. Should a thread misbehave-e.g., run beyond its CPU limit-the entire domain is terminated. This is necessary since it is likely that a thread running in an EE has already executed channel-specific code, and killing the thread might leave the channel in an inconsistent state.</p><p>As just described, threads are short-lived, "data driven" entities with no need for explicit identities. While this is sufficient for many environments, our experience with Janos, detailed in Section V, indicates that some EEs require "system" threads that are long-lived and not associated with any particular packet flow. For example, a Java virtual machine (JVM)-based EE might have a global garbage collection thread that, when it runs, needs to first stop all other threads until it is done. To support these environments, the API defines a small set of pthread-inspired operations for explicit thread manipulation: sending an interrupt, blocking and unblocking interrupts, changing a scheduler-interpreted priority value, and attaching thread-specific data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Memory Pool</head><p>The memory pool is the primary abstraction for memory. It is used to implement packet buffers (see Section III.D) and hold EE-specific state. A memory pool combines the memory resources for one or more domains, making those resources available to all threads associated with the domains. Adding domains to a pool increases the available resources while removing domains decreases the resources. The amount of resources that an individual domain can contribute to a pool is either embodied directly in the domain's credentials or explicitly associated with the domain at creation time. The many-to-one mapping of domains to memory pools accommodates EEs that want or need to manage memory resources themselves. For example, as illustrated in Section V.A, this mapping is needed by a JVM-based EE that shares objects and JIT'ed code between domains.</p><p>Memory pools have an associated callback function that is invoked by the NodeOS whenever the resource limits of the pool have been exceeded (either by a new allocation or by removing a domain from the pool). The callback function is registered when a memory pool is created by an EE. The NodeOS relies on the EE to release memory when asked; i.e., the NodeOS detects when a pool is over limit and performs a callback to the EE to remedy the situation. If the EE does not free memory in a timely manner, the NodeOS terminates all the domains associated with the pool. The rationale for these semantics is similar to that for domain termination give above: the EE is given a chance to clean up gracefully but the NodeOS has fallback authority.</p><p>Memory pools can be arranged hierarchically to allow constrained sharing between pools. The hierarchy of mempools is not used to control the propagation of resources; rather, it is intended as an access control mechanism. Specifically, a "child" mempool does not inherit its memory resources from its "parent"; those resources come from domains that are attached to the pool. Instead, the mempool hierarchy allows for sharing of memory between pools: a parent may see all of a child's memory while limiting what the child may see of its own. The semantics of the mempool hierarchy are motivated by the desire to support multiple address spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Channels</head><p>Domains create channels to send, receive, and forward packets. Some channels are anchored in an EE; anchored channels are used to send packets between the execution environment and the underlying communication substrate. Anchored channels are further characterized as being either incoming (inChan) or outgoing (outChan). Other channels are cut-through (cutChan), meaning that they forward packets through the active node-from an input device to an output device-without being intercepted and processed by an EE. Clearly, channels play a central role in supporting our flow-oriented design. We crystallize this role at the end of this subsection; first we describe the various types of channels in more detail.</p><p>When creating an inChan, a domain must specify several things:</p><p>1) which arriving packets are to be delivered on this channel; 2) a buffer pool that queues packets waiting to be processed by the channel; and 3) a function to handle the packets. Packets to be delivered are described by a protocol specification string, an address specification string, and a demultiplexing (demux) key. The buffer pool is created out of the domain's memory pool. The packet handler is passed the packet being delivered, and is executed in the context of the owning domain's thread pool.</p><p>When creating an outChan, the domain must specify 1) where the packets are to be delivered and 2) how much link bandwidth the channel is allowed to consume (guaranteed to get). Packet delivery is specified through a protocol specification string coupled with an address specification string. The link bandwidth is described with an RSVP-like quality of service (QoS) specification <ref type="bibr" target="#b33">[34]</ref>.</p><p>Cut-through channels both receive and transmit packets. A cutChan can be created by concatenating an existing inChan to an existing outChan. A convenience function allows an EE to create a cutChan from scratch by giving all the arguments required to create an inChan/outChan pair. Cut-through channels, like input and output channels, are contained within some domain, that is, the cycles and memory used by a cutChan are charged to the containing domain's thread and memory pool. Fig. <ref type="figure" target="#fig_3">4</ref> illustrates an example use of cut-through channels, in which "data" packets might forwarded though the cut-through channel inside the NodeOS, while "control" packets continue to be delivered to the EE on an input channel, processed by the EE, and sent on an output channel. The protocol and address specifications for inChans and outChans are similar, and are largely adapted from Scout's path abstraction (Section IV). The protocol specification is composed of modules built into the NodeOS. For example, "ip", "udp", or "anep". Components are separated in the specification string by the '/' character. Included at one end of a protocol specification is the interface on which packets arrive or depart. Thus, a minimal specification is "if" (for all interfaces) or "if " where is the identifier of a specific interface. For example "if0/ip/udp/anep" specifies incoming active network encapsulation protocol (ANEP) packets tunneled through IP, while "ip/if" specifies outgoing IP packets. The address specification defines destination addressing information (e.g., the destination UDP port number). The format of the address is specific to the highest level protocol in the protocol specification (e.g., describing UDP addresses). cutChan protocol specifications have an identical syntax with the addition of a ' ' symbol to denote the transition from incoming packet processing to outgoing packet processing; e.g., example, "ip/udp udp/ip".</p><p>Simply specifying the protocol and addressing information is insufficient when an EE wants to demultiplex multiple packet flows out of a single protocol (e.g., from a single UDP port). The demux key passed to the inChan specifies a set of (offset, length, value, mask) 4-tuples. These tuples are compared in the obvious way to the "payload" of the protocol. The "payload" is defined as the nonheader portion of the packet for whatever protocol specification was given. For example, with a raw "if" specification, the payload is everything after the physical headers; with an "if/ip/udp" specification the payload is the UDP payload. Convenience functions are provided for creating filters that match well-known headers.</p><p>Note that demux keys and protocol specifications logically overlap. The distinction is in the processing done on the packets by the NodeOS. For example, an EE can receive UDP port 1973 packets by creating an inChan with a protocol of "if0" and demux key that matches the appropriate IP and UDP header bits, or by creating an inChan with a protocol of "if0/ip/udp". The important and critical distinction is that the former case will not catch fragments at all, while the latter will perform reassembly and deliver complete UDP packets. Additionally, the former will provide the IP and UDP headers as part of the received packet where the latter will not.</p><p>We conclude our description of channels by revisiting our design goals. First, it is correct to view channels and domains as collectively supporting a flow-centric model: the domain encapsulates the resources that are applied to a flow, while the channel specifies what packets belong to the flow and what function is to be applied to the flow. The packets that belong to the flow are specified with a combination of addressing information and demux key, while the function that is to be applied to the flow is specified with a combination of module names (e.g., "if0/ip/udp") and the handler function.</p><p>Second, cut-through channels are primarily motivated by the desire to allow the NodeOS to forward packets without EE or AA involvement. Notice that a cutChan might correspond to a standard forwarding path that the NodeOS implements very efficiently (perhaps even in hardware) but it might also correspond to a forwarding path that includes an OS-specific extension. In the former case, the EE that creates the cutChan is able to control the channel's behavior, similar to the control allowed by API defined for programmable networks <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b15">[16]</ref>. In the latter case, the EE that creates the cutChan is able to name the extension (e.g., "if0/ip/extension/if1") and specify parameters according to a standard interface, but exactly how this extension gets loaded and its interface to the rest of the kernel is an OS-specific issue; the NodeOS interface does not prescribe how this happens. In other words, cut-through channels allow EEs to exploit both performance and extensibility capabilities of the NodeOS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Files</head><p>Files provide persistent storage and coarse-grained sharing of data. Because we did not view active networks as requiring novel file system support, we adopted an interface that loosely follows POSIX 1003.1. Each EE sees a distinct view of the persistent filesystem, rooted at a directory chosen at configuration time. In other words, "/" for the ANTS EE is rooted at /ANTS. This insulates EEs from each other with respect to the persistent filesystem namespace. In order to accommodate environments in which EE file sharing is desirable, however, we expect to add an interface that allows EEs to access the shared portion of the namespace.</p><p>EEs may share information through the use of shared memory regions, which are created with a combination of shm open and mmap operations. A nonpersistent file object is first created with shm open, which allows the specification of a name, as well as access rights and other options. Once the file object is created, EEs may then mmap the object to create a region of memory that is either private (not shared), or shared among the EEs mapping that file object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMPLEMENTATION I: SCOUT</head><p>We have implemented the NodeOS in the Scout operating system, which encapsulates the flow of I/O data through the system-from input device to output device-in an explicit path abstraction <ref type="bibr" target="#b20">[21]</ref>. This similarity to the NodeOS interface allows Scout to implement both the traditional and active forwarding services using exactly the same mechanism. This makes it possible to integrate the NodeOS interface into a Scout-based router in a way that does not negatively impact our ability to forward nonactive packets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>Scout is a configurable system, where an instance of Scout is constructed from a set of modules. For example, Fig. <ref type="figure" target="#fig_4">5</ref> shows a portion of the module graph for an active router. Modules TCP, UDP, IP, and ANEP each implement a communication protocol. Modules JVM and NodeOS each implement an API-the former implements the JVM (see <ref type="bibr" target="#b9">[10]</ref>) and the latter implements the NodeOS.</p><p>Scout paths support data flows through the module graph between any pair of devices. When configured to implement a router, Scout supports network-to-network paths, which we call forwarding paths. For example, Fig. <ref type="figure" target="#fig_5">6</ref> depicts a forwarding path that implements a file transfer protocol (FTP) proxy.</p><p>The entity that creates a forwarding path specifies three pieces of information.</p><p>1) the sequence of modules that define how the path processes messages; 2) a demultiplexing key that identifies what packets will be processed by the path; and 3) the resource limits placed on the path, including how many packets can be buffered in its input queue, the rate at which it is allowed to consume CPU cycles, and the share of the link's bandwidth it may consume. This same information is required by the NodeOS: a domain is a container for the necessary resources (channels, threads, and memory), while a channel is specified by giving the desired processing modules and demultiplexing keys. As a consequence, the NodeOS module is able to implement domain, channel, thread, and memory operations as simple wrappers around Scout's path operations.</p><p>More interestingly, a cut-through channel is simply implemented by a Scout forwarding path that does not pass through the NodeOS module (similar to the one shown in Fig. <ref type="figure" target="#fig_5">6</ref>), while in and out channels map onto a Scout path that does include the NodeOS module (as shown in Fig. <ref type="figure" target="#fig_6">7</ref>). In the latter case, the inChan corresponds the portion of the forwarding path to the left of the NodeOS module, while the outChan corresponds to the portion of the forwarding path to the right of the NodeOS module.</p><p>The only issue is how to implement demultiplexing. In Scout, each module implements two functions: one that processes  packets as they flow along a path, and one that demultiplexes incoming packets to select which path should process the packet. Packet classification is accomplished incrementally, with each module's demux function making a partial classification decision using module-specific information. This approach to classifying packets causes two complications.</p><p>First, the NodeOS module's demux function must implement a programmable pattern matcher that recognizes application-specified keys. (Its processing function simply implements the wrappers described above.) Thus, to match a packet to an inChan that delivers "if/ip/udp/anep" packets for a specific ANTS protocol (e.g., protocol '8'), the interface's demux looks for type IP, IP's demux would look for protnum UDP, UDP's demux would look for the well-known ANEP port, and ANEP's demux would look for ANTS's well-known EE number. If we assume the ANTS protocol and capsule type fields are each four bytes, the NodeOS's demux would then match the pattern (3, 5, x08x00x00x00x02, xFFx00x00x00x02) to select the path that delivers packets to this specific ANTS protocol (i.e., to a specific AA running in the ANTS execution environment).</p><p>Second, the NodeOS does not tightly couple the demultiplex keys with the processing modules. Thus, it is possible to say that packets matching a certain IP address and TCP port numbers should be processed by just the IP module. This happens, for example, with transparent proxies. Scout, however, couples the two: creating a path with modules "if/ip/tcp" implies that both the demultiplexing and processing functions of all three modules are involved. Our experience implementing the NodeOS interface has caused us to change Scout so that processing and demultiplexing are not so tightly coupled. That is, path creation now takes two sets of module lists, one that identifies how the path processes packets and one that specifies how packets are classified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Integrated Perspective</head><p>The goal of the Scout-based router is to provide a single framework for vanilla IP forwarding, kernel extensions to IP forwarding, and active forwarding <ref type="bibr" target="#b13">[14]</ref>. From Scout's perspective, we can view a forwarding path as being constructed from a combination of system modules and user modules. Systems modules correspond to native Scout modules, which have two important attributes. First, they are trusted and can be safely loaded by verifying a digital signiture. Second, they assume the same programming environment (they are written in C and depend on Scout interfaces). In contrast, user modules are untrusted and can be implemented in any programming environ- ment. For example, an application that wants to establish a virtual private network might create a forwarding path that includes a virtual private network (VPN) module running over IP tunnels: "if/ip/[vpn]/ip/if", where we bracket VPN to denote that it is a user module.</p><p>Of course, the key to being able to run such user modules is to execute them in a wrapper environment, which in our case is provided by the NodeOS interface. The NodeOS, in turn, allows user-provided modules to define their own internal paradigm for extending router functionality. For example, the VPN module might be implemented in the ANTS execution environment. ANTS happens to depend on Java, which is an execution environment in its own right. In effect, if one were to "open" the user-provided VPN in this example, one might see the components shown in Fig. <ref type="figure" target="#fig_7">8</ref>, where VPN is one of possibly many AAs that ANTS might support at any given time. The only restriction on such nested environments is that the NodeOS is at the outermost level.</p><p>Given this perspective, we comment on several attributes of our design. First, some forwarding paths consist entirely of Scout modules; the vanilla IP forwarding path is a prime example. This makes it possible to implement high-performance paths that are not encumbered by the overheads of the NodeOS or Java wrapper environments. In fact, we expect that popular user-provided modules will be rewritten as system modules and migrate into the kernel over time. More generally, being able to run both system and user modules gives us a two-tier security model, allowing both trusted system adminsitrators and untrusted users to extend a router's functionality.</p><p>Second, a Scout forwarding path contains at most one user module but by being able to name the system modules that make up the rest of path, the user module is able to exploit legacy network modules. For example, in contrast to the overlay extension illustrated in Fig. <ref type="figure" target="#fig_7">8</ref> that logically runs on top of the fully-connected Internet, one could implement an extensible IP user module-think of this module as implementing IP version -that depends only on the ability to send and receive packets over the raw interface. The important point is that user-provided functionality can be inserted at any level of the network stack.</p><p>Third, there are two reasons for deciding to create a new forwarding path. One is that you want to bind a particular packet flow to a unique set of modules. For example, our router typically runs two vanilla IP forwarding paths: one that implements the fast path that consists of a single module that is optimized for moving option-free datagrams between a pair of similar devices, and a general forwarding path that deals with exceptional cases such as IP options and arbitrary interfaces. The second reason is that you want to treat a particular flow specially with respect to resource allocation. For example, there might be two forwarding paths consisting of the modules "if/ip/if" with one given best effort service and the other given some QoS reservation.</p><p>Fourth, forwarding paths exist in both the control and data plane, with control paths typically creating and controlling data paths. For example, a path constructed from modules "if/ip/udp/[rsvp]/udp/ip/if" might create the "if/ip/if" path described in the previous paragraph, and in doing so, set the amount of link and CPU resources that the flow is allowed to consume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance</head><p>We have implemented several forwarding paths, including ones that span the NodeOS. Table <ref type="table" target="#tab_0">I</ref> reports the performance of these paths on a 450 MHz Pentium-II processor with three Tulip 100 Mb/s ethernet interfaces. For each type of forwarding path, we give the aggregate rate, measured in packets-per-second (pps) at which the router can forward minimim-sized packets over that path.</p><p>The first three forwarding paths implement the standard IP forwarding yfunction under three different scenarios. The IP fast path represents the minimal work a Scout-based router can do to forward IP packets. It is implemented by a single Scout module that is optimized for a specific source/sink device pair. The general IP path includes option processing and handling other exceptional cases. This path is constructed from three separate Scout modules: the input device driver, IP, and the output device driver. Finally, the active IP path implements IP as a user module, wrapped in the NodeOS environment. The difference between this and the previous path measures the overhead of the NodeOS module.</p><p>The next pair of paths implement a transparent UDP proxy. The first (transparent kernel proxy) includes a null Scout proxy module, while the second (transparent active proxy) includes a null proxy running on top of the NodeOS interface. In practice, such proxies might apply some transformation to a packet flow without the knowledge of the end points. Since the numbers reported are for null proxies, they are independent of any particular transformation. The final two paths are for classical proxies, such as an FTP proxy that establishes an external TCP connection, receives a file name, and then establishes a internal TCP connection to the appropriate server. As before, we measure a null classical proxy running in both the kernel (classical kernel proxy) and on top of the NodeOS interface (classical active proxy)</p><p>Note that all of the numbers reported for the NodeOS assume the active code (user module) is written in C and compiled to the native architecture. It does not include the overhead of Java or some execution environment. We are currently porting the JVM and ANTS to the latest NodeOS interface but, based an implementation of the JVM and ANTS running on an earlier version of the interface, we expect an active Java module to add 3.5 /s of processing time to each packet, and ANTS to add an additional 37.5 /s to each packet. This would reduce the active IP forwarding rates, for example, to approximately 60.7 k and 18.5 k pps, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. IMPLEMENTATION II: JANOS</head><p>Our second example implementation is Janos, a "Java-oriented active network operating system." Janos has two primary research emphases: 1) resource management and control, and 2) first class support for untrusted AAs written in Java. Toward these goals, Janos necessarily encompasses both the EE and NodeOS layers of the canonical active network architecture <ref type="bibr" target="#b1">[2]</ref>. As Fig. <ref type="figure" target="#fig_8">9</ref> shows, Janos is a layered architecture with three components: ANTSR, the Janos Virtual Machine (JanosVM), and Moab. Though this section is primarily concerned with Moab, the Janos NodeOS, we introduce the other layers to provide a bit of context. A complete discussion of the Janos architecture, focusing on other issues, appears elsewhere in this journal <ref type="bibr" target="#b26">[27]</ref>.</p><p>AAs for Janos are written to use the ANTSR Java runtime environment. ANTSR, or "ANTS with resource management," exports to AAs essentially the same API as that exported by the standard ANTS active network runtime <ref type="bibr" target="#b29">[30]</ref>. However, ANTSR is rearchitected to take advantage of NodeOS and JanosVM services, and to support precise resource control. ANTSR runs atop the JanosVM, an extended JVM. In addition to providing the standard JVM services necessary for executing Java bytecode (e.g., threading, garbage collection, and JIT compilation), we have extended the JVM to support multiple namespaces and multiple heaps, providing independence between concurrently executing Java applications. The JanosVM also exports Java bindings for the NodeOS API, making it a potential host platform for other Java-based EEs. Together, ANTSR and the JanosVM form the EE layer of the active network architecture.</p><p>Underneath the JanosVM is Moab, a multithreaded, fully-preemptible single-address-space operating system implementing the NodeOS abstractions. Moab is built using the OSKit <ref type="bibr" target="#b8">[9]</ref>, a toolkit of components for building systems software. The OSKit includes suites of device drivers, numerous filesystems, a networking stack, and a thread implementation, as well as a host of support code for booting, remote debugging, memory management, and enabling hosted execution on UNIX systems.</p><p>The remainder of this section discusses our experiences with the NodeOS interface in Janos. We start by describing the integration of the NodeOS interface into Janos from two perspectives. First, we look at the part of Janos above the interface boundary, discussing how the requirements of the JanosVM influenced the design of the interface and how we leverage the resulting design in the JanosVM implementation. Second, we look below the boundary, briefly describing some of the issues involved with implementing the NodeOS interface on top of the OSKit. We conclude by presenting and briefly discussing some preliminary performance results for Moab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. NodeOS Design Issues</head><p>The JanosVM has two key properties that influenced the design of the NodeOS specification: its JVM heritage which strongly influences memory management, and its tight coupling with the NodeOS. In the following paragraphs, we explore these properties and how the NodeOS design supports them.</p><p>1) Memory Management: Fundamentally, the JanosVM, like typical high-level language runtimes, needs to do its own memory management. Not only does the VM allow the sharing of code and data between domains but it also maintains separate per-domain garbage-collected heaps. While it might be possible to use per-domain, NodeOS-enforced memory limits, at best these would be redundant mechanisms and at worst they would severely restrict how the JanosVM can use memory. Thus, the ability to aggregate memory from multiple domains into a single memory pool is essential to the JanosVM. This ability is enabled in the NodeOS interface by decoupling the domain and memory pool abstractions, allowing a memory pool to be specified explicitly at domain creation time. In the JanosVM, a single memory pool is created and all domains are associated with it. When a domain is created, its resources are added to this global pool. The JanosVM is responsible for making per-domain allocation decisions from this pool and enforcing per-domain memory limits. When a domain terminates, the memory pool's callback function is invoked, informing the JanosVM that it must return an amount of memory equal to that domain's share. The key point is that, with a single memory pool, the JanosVM is free to decide which memory pages are to be taken from the pool. Were there to be one memory pool per domain, the JanosVM would be forced to return the specific memory that was allocated to the terminated domain.</p><p>While the single memory pool enables the JanosVM to account for explicit allocations, one issue remains. In order for the JanosVM to accurately track all memory resources, it must also have a way to account for memory allocated within Moab on behalf of domains; that is, the implicitly allocated memory used for the internal state of NodeOS-provided objects. To accomplish this objective, the NodeOS interface was designed to provide "zero-malloc" object creation API calls in which the caller supplies pre-allocated memory for the NodeOS to use for the object state. Another advantage to this approach is that it allows the EE to embed actual NodeOS objects (as opposed to object references) in EE-provided objects, thus simplifying the code for managing these objects. The JanosVM exploits this feature by embedding NodeOS objects in the corresponding Java wrapper objects that are exposed to the ANTSR runtime via the Java NodeOS bindings. A final benefit of preallocation of object memory is that it makes object creation calls more predictable-they never block for memory allocation or throw a memory exception.</p><p>2) Tight Coupling: Another aspect of the JanosVM that had influence on the NodeOS interface is that the JanosVM and Moab are tightly coupled, with NodeOS API calls being implemented as direct function calls rather than as "system calls." The ability to share memory between the NodeOS and EE via direct pointers during object creation calls is an example of how the NodeOS interface is designed to efficiently support this model; that is, in an implementation where the NodeOS "trusts" an EE. The interfaces are designed to allow direct manipulation of all the NodeOS objects by the EE, making it possible, for example, to aggressively inline API calls in the EE code.</p><p>Another manifestation of the tight coupling of the EE and NodeOS is the way in which NodeOS exception conditions are handled. The NodeOS defers to the EE, via callbacks, whenever a domain terminates, faults, or exhausts some resource. The EE is expected to recover or clean up and destroy any affected state. Only if the EE doesn't respond in a timely manner will the NodeOS intervene, and then only in a very direct, albeit heavy-handed, way: by terminating the EE and reclaiming its resources. Graceful exception handling is the responsibility of the EE. This design is necessary because, as explained above under memory management, the EE has private knowledge of certain per-domain information.</p><p>Finally, the conscious effort to borrow from interfaces such as POSIX when designing the NodeOS interface is leveraged to great effect in the JanosVM. As the JanosVM is derived from Kaffe <ref type="bibr" target="#b30">[31]</ref>, a POSIX-hosted JVM, the similarity of the NodeOS thread, synchronization, and file interfaces to those in POSIX made porting the JanosVM to Moab much easier than it would otherwise have been.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. NodeOS Implementation Issues</head><p>The OSKit was designed for building operating system kernels, making it an obvious choice for constructing the Moab NodeOS. The richness of the OSKit environment gave us not only the ability to run directly on two different hardware platforms (x86 and StrongARM) and on top of various UNIX-like OSes (Linux, FreeBSD and Solaris) but also provided development tools for debugging, profiling, and monitoring. Its support for standard interfaces such as POSIX threads and files made mapping the analogous NodeOS interfaces straightforward. On the other hand, not all OSKit interfaces were well suited to the task. The base memory interface was too low-level, its generic nature hindering precise control of memory resources. The networking interface was too high-level, its coarse granularity limiting the options for channel composition. In the following paragraphs, we describe the Moab implementation of three NodeOS abstractions that best illustrate the good and bad characteristics of the OSKit as a NodeOS base.</p><p>1) Threads: The implementation of thread pools and the threading interface in Moab was, for the most part, straightforward due to the similarity between the NodeOS and POSIX (pthread) APIs. Just as this similarity helped "above" when mapping the JanosVM onto the API, it helps from "below" when implementing the API on top of the OSKit pthreads component. Most of the thread and synchronization primitives in the API mapped directly to pthread operations. There was one obvious performance problem caused by the direct mapping of NodeOS threads to pthreads: the NodeOS thread-per-packet model of execution led to creation and destruction of a pthread for every packet passing through the NodeOS. This was avoided by creating and maintaining a cache of active pthreads in every thread pool.</p><p>2) Memory: Memory pools represent one area where using the OSKit has made the implementation difficult. Tracking memory allocated and freed within OSKit components such as the network stack is easy but identifying the correct memory pool to charge or credit for that memory is not. In particular, all allocations in OSKit components eventually funnel down to a single interface. By providing the implementation of that interface within Moab, we have control over all memory allocated anywhere in the system. However, that interface includes no specific information about what the memory is being used for, nor any explicit indication as to the principal involved. We are left with the choice of charging either the memory pool of the current thread (charge the "current user") or the "root" memory pool (charge "the system"). At the moment, Moab charges all OSKit allocations to the root pool. The solution we are pursuing is to evolve the OSKit memory interfaces, either by exposing more domain specific allocation interfaces or by passing down the necessary information to the generic interfaces.</p><p>3) Channels: Channels were by far the most challenging of the NodeOS abstractions to implement using current OSKit components. Anchored channels in Moab are implemented in one of two ways corresponding to the protocol specification used: raw interface ("if") channels deliver packets directly from the device driver to Moab (and on to the JanosVM) while all others use a socket interface to deliver UDP or TCP packets from the device driver, through the OSKit networking stack, and up to Moab. In both cases, the OSKit's encapsulated legacy-code components do not match well with the NodeOS networking model.</p><p>Raw interface channels are implemented directly above the OSKit's encapsulated Linux device drivers using the standard OSKit network device interface. We modified the OSKit device driver glue code to use specialized "packet memory" allocation routines to avoid the previously described problems caused by the low-level generic memory interfaces. Our only remaining concern is the inherent performance limitations caused by using stock Linux device drivers. This is discussed further in Section V.C.</p><p>All other anchored channels are implemented directly on a BSD socket-style OSKit interface, allowing UDP/IP or TCP/IP protocol specifications. This provides only a limited subset of what the NodeOS interface supports-in particular, it does not support "IP-only" channels. To address this drawback, we are reimplementing these channels using Click <ref type="bibr" target="#b14">[15]</ref> routers. Click, a router component toolkit from MIT, provides a set of fine-grained elements-small components representing a unit of router processing-and a configuration language for combining these elements into router configurations. By using Click, we will be able to do the fine-grained protocol composition allowed by the NodeOS specification. Currently, we have a prototype implementation of Click-based UDP/IP inChans and outChans.</p><p>Cut-through channels are currently implemented as an unoptimized concatenation of NodeOS inChan/outChan pairs and can perform no additional protocol processing. Again, the coarse granularity of the OSKit networking interface does not allow access to individual protocols from within Moab. As with anchored channels, we have done preliminary work to make use of Click graphs to implement a more flexible form of cut-through channel currently as an extension to the NodeOS interface. With Click cutChans, the protocol specification is a Click router description. The Click router elements used to instantiate the graph run inside Moab with standard device driver elements replaced by elements to read from an inChan and write to an outChan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance</head><p>Our primary goals to date have been the implementation of the NodeOS abstractions and API in Moab and the integration of Moab with the JanosVM. With those goals largely met, we have now begun to look into measuring and improving the performance of Moab. In the following paragraphs, we present the results of some simple packet-forwarding tests to characterize that performance.</p><p>All testing used the facilities of emulab.net, the Utah Network Emulation Testbed <ref type="bibr" target="#b7">[8]</ref>. Testbed nodes are 600 MHz PentiumIII PCs using ASUS P3B-F motherboards with 128 MB of PC100 SDRAM and five Intel EtherExpress Pro/100+ 10/100-Mbit PCI Ethernet cards all connected to a Cisco 6509 switch. Our experiment consisted of three nodes, connected in a linear arrangement: a packet producer node was connected by a private VLAN to the packet router node, which in turn was connected via a second private VLAN to a packet consumer node. The producer and consumer nodes ran custom OSKit-based kernels while the router node ran one of three routers as described below.</p><p>The test was to generate and send 18-byte UDP (64-byte Ethernet) packets at increasing rates to discover the maximum packet forwarding rate of the router node as measured at the consumer node. As in the Scout IP Fast Path experiment, only minimal IP processing was performed on the router node. The results are summarized in Table <ref type="table" target="#tab_1">II</ref>.</p><p>The OSKit experiment establishes a performance baseline by measuring the raw packet forwarding rate of a simple OSKitbased router. This router has a single function which receives a packet pushed from the input interface driver, performs IP processing, and pushes the packet out on the output interface. This result represents the upperbound on performance of a system based on OSKit interfaces built on top of stock, interrupt-driven Linux device drivers. Given the differences in hardware configurations, the recorded 75 700 pps is comparable to the 84 000 the Click team reported for similar stock Linux device drivers. The Click work <ref type="bibr" target="#b14">[15]</ref>, as well as the Scout team's experience, also demonstrated the enormous improvement-exceeding a factor of three-in the forwarding rate of generic packets that polled device drivers provide. Based on those reports, converting Moab to use polled drivers should improve performance dramatically.</p><p>We then measured Moab using a cutChan to forward packets between the interfaces (Moab cutChan). The result was a 35% degradation of the OSKit forwarding rate, down to 48 700 pps. The bulk of the slowdown is attributable to the current unoptimized implementation of Moab cutChans. Since they are now implemented as a simple concatenation of an inChan and outChan, an actual Moab thread is dispatched for each arriving packet. This thread runs the cutChan function whose sole purpose is to send the packet on the outChan and release the packet buffer. Avoiding this scenerio is the purpose of cut-through channels, and we will optimize our implementation in the near future.</p><p>Finally, in C-based EE, we measured the performance of a C-language EE running on Moab using the NodeOS API. The EE consists of a domain with a single thread receiving packets on an inChan, performing the IP processing, and sending the packet on the outChan. This is exactly what the Moab cutChan forwarder does, only running outside the NodeOS API boundary. Hence, this test accurately demonstrates the overhead involved in crossing the API boundary. As one of the goals of Janos is the tight coupling of the EE and NodeOS, this result is important. In this configuration, there was an 8% drop to 45 000 pps. In absolute terms, the EE-level channel receive function took an average of nine 300 cycles (15.5 s) per call versus 6 900 (11.5 s) per call for the NodeOS-level function when receiving at a rate of 40 000 pps. Each EE-level invocation requires six API boundary crossings, for an average added cost of 400 cycles per crossing. This cost, which is somewhat high, will be reduced in the near future as we take further steps to optimize the implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. IMPLEMENTATION III: AMP</head><p>Our third implementation, called AMP, is layered on top of the exokernel (xok) and its POSIX-like libEXOS library OS <ref type="bibr" target="#b12">[13]</ref>. AMP's goal is to provide a secure platform upon which EEs and AAs can run, without unduly compromising efficiency. As illustrated in Fig. <ref type="figure" target="#fig_9">10</ref>, AMP consists of library code (libAMP), and four trusted servers, that jointly provide the NodeOS interface to an EE. One of our self-imposed design constraints was to avoid introducing new abstractions or mechanisms into xok, as we attempt to demonstrate that a secure system may be constructed entirely above an exokernel.</p><p>Comparing AMP to Janos, the same AAs and ANTSR EE are layered on the Janos Java NodeOS bindings. However, AMP implements its own subclasses of the NodeOS bindings, specialized to use the Java native method interface to make calls to the libAMP routines implemented in C. The Kaffe virtual machine has been ported to but not specialized in any significant way for the exokernel. LibAMP follows the exokernel library OS design approach of placing a copy of the OS in the same address space as the application. To provide protection of system-wide state information, portions of NodeOS abstractions are implemented within separate trusted servers, and libAMP invokes protected operations via cross-address space RPC. Trusted servers implement protected portions of these NodeOS abstractions: domains [security writer daemon (SWTD)], input channels [dynamic packet filter daemon (DPFD)], output channels [network transmission control daemon (NTCD)], and shared memory [shared memory daemon (SHMD)].</p><p>AMP shifts much of the protection burden away from the Janos VM and onto the trusted servers. There are two consequences of this design decision. First, AMP forgoes many of the opportunities for performance optimizations possible by exploiting a single-address space system. In particular, context switching costs related to RPC is a potentially significant performance bottleneck. Second, AMP is able to accomodate a wide range of EE implementations and languages. Because there is relatively little trust that must be placed in a given EE, AMP can limit the resources and operations that an EE is granted access to, thereby allowing more flexibility in configuring EEs to run within the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Design Issues</head><p>The exokernel provides a minimal set of abstractions above the raw hardware. Ideally, only those mechanisms required to control access to physical resources and kernel abstractions are provided. All other OS abstractions are implemented in user space. Exokernel implementations utilize library operating systems colocated in the address space of each application, as opposed to protected OS servers executing in their own address spaces. This implementation choice reduces one of the well known problems of microkernel architectures, namely, the high direct and indirect costs of invoking services via RPC <ref type="bibr" target="#b17">[18]</ref>. However, the exokernel also provides efficient support for RPC, which we have used extensively in our design and implementation.</p><p>AMP's influence on the NodeOS interface is reflected in the simplicity of the interface API with respect to security arguments. In fact, there is precisely one point, at domain creation, where credentials are passed to the NodeOS. These credentials represent the principal authorizing the domain's creation, and are used to determine limits on both resources and operations. By determining all rights for a domain exactly once, and at exactly one entry point in the NodeOS interface, this design facilitates the enforcement of security policies. AMP maps a domain's authorization to primitive protection mechanisms in the xok as described below.</p><p>The key to exokernel protection is the uniform support for hierarchically-named capabilities (CAPS). CAPS are more akin to an extensible Posix UID/GID mechanism than to capabilities, in that CAPS are checked against access control lists rather than naming and granting rights directly. Two properties of CAPS are essential to building a secure AMP system above xok. First, Kernel control over creation and use-xok maintains all CAPS in the system, controlling when new CAPS are created, associated with a process (environment abstraction in xok), and passed from one environment to another. Second, ubiquitous and exclusive use throughout the system call interface-every system call takes exactly one CAP as an argument to determine if the requesting entity has sufficient rights to perform the operation.</p><p>Together, these two properties provide the initial basis for assuring that the AMP system and its security mechanisms are tamperproof, nonbypassible, and intercept or enforce decisions on all requests for resources or services. By implementing the NodeOS abstractions and AMP security mechanisms above xok, development time is reduced, modularity is enhanced, and security requirements can be addressed in a straightforward manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. NodeOS Interface and Trusted Servers</head><p>Each NodeOS resource abstraction must be controlled in order to ensure separation between the various domains instantiated in the system. The domain abstraction is the container that holds other resources, along with the credentials that authorize the domain's actions. Trusted servers provide control over the NodeOS resources by enforcing the current policy. These servers are rightly viewed as extended parts of the operating system implemented in user space. As such, they have powers granted to them at boot time as trusted software in order to carry out their function. They enforce access to their resources in essentially the same manner as the xok system call enforcement mechanism. An xok CAP is passed as an argument of each RPC to a trusted server, and used to check that the request is allowed. In explaining the implementation details of each node OS abstraction in AMP, we focus on the consequences of layering above xok.</p><p>1) Packet Forwarding: Unlike a typical monolithic kernel, xok does not include IP routing functionality in the kernel. Instead, a dedicated, nonactive IP forwarder running in user space mimics the functionality provided within the kernel on other systems. One consequence is that IP forwarding is essentially identical to any other active network EE implementation running on the system. Our choice of a C implementation with support for a static IP forwarding function could easily be replaced by any EE ported to AMP, configured to run an AA that implements an appropriate IP forwarding function. However, this means that AMP can be expected to be somewhat slower forwarding IP packets than a corresponding Unix system because of the additional costs of copying all packets up to user space and then back down for transmission.</p><p>2) Domains: The trusted server directly involved in managing domains, SWTD, interprets high-level policy, tracks domains and their associated credentials, and informs the other servers regarding what system resources are authorized to domains. Domains are established via an RPC to SWTD, which relies on a credential service (not described) to retrieve, validate, and cache credentials. SWTD creates one xok CAP for each domain in the system. Since a CAP is passed on every system RPC to a trusted server, the CAP is actually used as an authenticated name for the domain. CAPs are never manipulated in user space since they are passed by reference and maintained in the kernel. The credentials supplied with the domain create operation are used to determine the specific resources or services that the domain is granted access to. Our design calls for a flexible policy language but our initial implementation hands out static policy mediation directives to each of the other trusted servers. For example, if a domain is created with the right to open certain input channels, then the policy mediation directives passed from SWTD to DPFD, which mediates inChan creation operations, would contain a canonical representation of the packet filter fields that must be specified by any inChan created by the domain.</p><p>There are several consequences to layering the domain abstraction above xok in this way. First and foremost, the kernel knows nothing about domains but rather tracks the CAPS associated with domains. This means that other abstractions can be added to the domain container by implementing additional trusted servers, and informing them of the CAP and policy mediation directives associated with a domain. Since trusted servers are only special by dint of their possession of CAPS and because they receive privileged communications from SWTD, it would not be difficult to extend the system. In fact, an EE or AA could play the role of trusted server with respect to control of an additional abstraction. Second, even though the domain hierarchy and CAP hierarchy were designed to be isomorphic, this property is not exploited at the trusted server level. The NodeOS interface allows parent domains to control their children domains; in theory, this could be implemented in AMP by having the parent use a CAP with the power of all its children's CAP's. Xok provides this exact functionality but AMP can directly add the additional rights granted to each child domain to the parent's set of allowed operations at creation time.</p><p>3) Channels: The channel implementation in AMP is split across three address spaces: DPFD, the libAMP code colocated with the EE, and NTCD. DPFD enforces the policy regarding what packet filtering rules may be installed into the xok DPF mechanism by a domain, thereby guaranteeing strong separation of domains with respect to packets received over the network. NTCD plays a similiar but not quite symmetric role for transmission of packets over output channels. The libAMP channel code does all the processing for ANEP, UDP, and IP. (TCP is currently unsupported.) Output channels use a set of buffers mapped into the address space of NTCD to pass packets along for transmission, and NTCD selects the correct physical inter-face based on the destination IP address, and constructs the Ethernet header. NTCD can optionally enforce both transmission limits and header content controls on packets. Transmission limits on a domain can be enforced by directly controlling how many packets or bytes are sent per second.</p><p>The DPF mechanism is reused in NTCD to limit the values of header fields in transmitted packets. NTCD clones both the DPF implemented in xok, and the packet filter mediation function (from DPFD) used to control which filters are inserted into the DPF set. We observe that there is no need for a tight-coupling between the EE/libAMP channel implementation that establishes an outChan and the DPF rules used to control packet transmission. A small change to the NodeOS interface would allow other implementations, including ones in which trusted AAs separately supplied the filtering rules.</p><p>4) Threads: Our prototype uses the Kaffe implementation, for which we have developed a thread package called xok-jthreads. Xok only supports processes, while providing primitive mechanisms useful for implementing threads in user space. The xok-jthreads package is used by Kaffe for creating its own threads, as well as by the channel stack. Our prototype does not migrate a thread from the inChan into the EE but rather delivers the packet and allows Kaffe to schedule one of its own threads to process the packet through the EE and AA. As threads are user space entities, we have designed (but not yet implemented) the machinery needed to limit CPU consumption by domains. In this design, a scheduler daemon acts as a first-level hierarchical scheduler, as well as controls all free scheduler time-slices (quantums). Xok provides an interface to control, allocate, and preempt quantums scheduled using a simple round-robin policy. The second-level scheduler inside each xok-jthreads implementation determines which thread inside the EE is run.</p><p>5) Files: CFFS is the native filesystem in AMP. Its operations are implemeted via a trusted server that is part of the original exokernel distribution. Our only design change is to control which portions of the file namespace are visible to the individual EEs. However, this is not adequate to assure the strong separation of different portions of the global filespace since symlinks and shared inodes may obscure when sharing is taking place. The NodeOS sharing abstraction implemented via shm open() and mmap() is intentionally restrictive in order to simplify the security aspects of controlling shared memory. The key restriction is that a shared region may only have a single writer. This obviates the need for controlling write access, implementing write locks, and reclaiming orphaned locks at domain termination. Moreover, it eliminates entirely the security policy and configuration that would be required to specify which entities had access to these ancillary operations. Instead, the SHMD needs only check that read or write access for the shared region is permitted. Memory is provided by the writer, out of their mempool. Mempools currently exist only at the level of the entire EE-resource limits control the entire amount of memory used by the EE and all subdomains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance</head><p>We report on the forwarding rates for AMP at various layers in the architecture for minimum sized ethernet packets. Channelized IP corresponds to a C implementation of a forwarding process layered above the NodeOS channel abstraction. This process necessarily runs in user space, as the xok kernel does not directly implement forwarding. The limited performance reflects the costs of two copies and four CPU context switches required per each packet. The next two entries correspond to implementations that process ANEP packets encapsulated within UDP/IP. The minimal ANEP header does not carry any options, such as those requiring CPU intensive crytographic operations. The rough doubling of performance between the two cases reflects the benefit of a cutChan over a separate inChan/outChan pair anchored in a Java EE. The final entry measures the rate at which a minimal ANTSR capsule is forwarded. All numbers were measured on a testbed consisting of three 750-MHz Pentium-III PCs with Intel EtherExpress Pro/100+-Mbit Ethernet cards connected to a Netgear FS516 switch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DISCUSSION</head><p>It is interesting to note how the differences between the three base systems impacted the way in which the domain abstraction was implemented. In Scout, the principal abstraction is the path, which essentially bundles a domain plus an inChan/outChan pair. In Moab, domains are closely associated with the JanosVM's abstractions for separate memory heaps and namespaces. Moab's support of threads as a first-class abstraction, coupled with the advantage of a single address space for memory, provide the right degree of support to allow the virtual machine to isolate and separately account for the resources used by AAs. In contrast to both of these, the exokernel allows AMP to map domains one-to-one with the fundamental protection mechanism of the system: hierarchically named capabilities. This translates into the exokernel's notion of a domain as an owner of more primitive resources. A domain, in the eyes of exokernel, is roughly the resources it is permitted to allocate, and operations it is permitted to invoke.</p><p>Turning to the channel abstraction, the differences between the Scout and AMP implementations illustrate how underlying system structure impacts the design choices, and permeates the system in subtle ways. Scout's channel implementation consists of a number of system forwarding modules strung together into a protocol stack. AMP adopts a similar architecture. However, Scout implements inChan demultiplexing rules by distributing the pattern matching functions across the layers of the protocol stack, while AMP centralizes the demultiplexing function by constructing and downloading the pattern into the kernel. The Scout implementation allows individual system modules a great deal of flexibility, while the AMP implementation facilitates the imposition of higher-level security policy by checking inChan demultiplexing filters for conformance with the policy before they are downloaded into the kernel.</p><p>With the memory pool abstraction, the central implementation issue hinges on how to treat an EE's internal use of memory versus the memory used by the NodeOS while performing an operation on behalf on a domain. Here, Moab assigns a single mempool to the entire JanosVM, and relies on the specific properties of that closely-coupled virtual machine to limit the memory used by individual domains within the EE. Most of the remaining work involves restructuring the memory allocation mechanisms below the Moab kernel interfaces to properly associate memory use with domains. AMP, on the other hand, has the goal of supporting EEs using different language technologies. Associating memory usage by specific domain is difficult, and requires modification of the EE implementations to create and manage mempools corresponding to separate virtual address spaces with both shared and private page ranges. As a simple step toward this goal, AMP includes a shared-memory abstraction that supports the inclusion of a set of physical pages into multiple virtual address spaces. Below the NodeOS interface, AMP has a relatively easy way to track memory. Because each domain has an assigned CAP, and every memory allocation operation requires that a CAP be provided, individual domain usage can be directly tracked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. RELATED WORK</head><p>The first known active network, Softnet <ref type="bibr" target="#b32">[33]</ref>, implemented a programmable packet radio network in 1983. It built upon what one could call the first NodeOS/EE, a Forth environment called MFORTH <ref type="bibr" target="#b31">[32]</ref>. This environment is consistent with the contemporary pattern of using special languages to program the network.</p><p>A more recent system, RCANE <ref type="bibr" target="#b18">[19]</ref>, defines a resource controlled framework for active network services. It supports the OCaml programming language <ref type="bibr" target="#b22">[23]</ref>, is implemented on the Nemesis operating system <ref type="bibr" target="#b16">[17]</ref>, and is interoperable with PLAN <ref type="bibr" target="#b10">[11]</ref>. RCANE supports resource reservations for network bandwidth, memory use, and computation, much like the NodeOS. The primary between RCANE and the NodeOS is the NodeOS's flexible communication abstraction. RCANE uses Nemesis's network, and allows only link layer communication, while the NodeOS allows any supported protocol to be used. (RCANE's link layer may be a virtual network implemented on top of UDP; nevertheless, RCANE does not allow the flexibility that the NodeOS provides.) Other differences include RCANE's reliance on a safe language to guarantee security.</p><p>Three recent router implementations-SuezOS <ref type="bibr" target="#b21">[22]</ref>, Click <ref type="bibr" target="#b14">[15]</ref>, and Router Plugins <ref type="bibr" target="#b6">[7]</ref>-allow some degree of extensibility. In each system, router functionality can be extended by configuring safe extensions into the kernel. This is similar to the use of system modules to extend the forwarding paths in the Scout kernel. In contrast, the NodeOS separates the core OS from the EE, thereby allowing different EEs to safely implement different programming environments on the same router.</p><p>Bowman <ref type="bibr" target="#b19">[20]</ref>, which runs on top of Solaris, was the first NodeOS that targeted the same community-developed active network and NodeOS architectures that we target. Bowman was developed in the early days of the specification, and therefore implements a subset of the interface. It also does not provide resource controls since it runs on a generic Unix substrate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSION</head><p>We have described an interface that allows AAs to access the resources available on an active router, and reported our experiences implementing the interface using three different operating systems. The interface is novel in how it is optimized to support packet forwarding, allows for fine-grain resource managment, and supports secure extensions. The three implementations not only demonstrate the feasibility of the interface but perhaps more importantly, they also strongly influenced the design of the interface in the first place.</p><p>Andrew Purtell is a Research Engineer with NAI Labs, the security research division of Network Associates, Inc., Los Angeles, CA, where he has developed high-speed firewall and active network prototypes. His research interests lie at the intersection of programming language technology and embedded operating systems.</p><p>Mr. Purtell is a member of the ACM.</p><p>John Hartman (M'95) received the Sc.B. degree in computer science from Brown University, Providence, RI, in 1987, and the M.S. and Ph.D. degrees in computer science from the University of California, Berkeley, CA, in 1990 and 1994, respectively.</p><p>He has been an Assistant Professor with the Department of Computer ence, University of Arizona, Tuscon, AZ, since 1995. His research interests include distributed systems, operating systems, and file systems.</p><p>Dr. Hartman is a member of the ACM.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Software layers running on an active router.</figDesc><graphic coords="1,391.50,147.78,70.32,86.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Domain consists of channels, memory, and threads needed for EE-specific processing.</figDesc><graphic coords="2,348.18,62.28,160.08,143.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Domain hierarchy.</figDesc><graphic coords="2,332.52,249.84,191.28,101.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Domain with a cut-through channel.</figDesc><graphic coords="4,355.86,62.28,144.72,129.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Module graph for an active router.</figDesc><graphic coords="5,366.66,62.28,120.00,131.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Example of forwarding path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. In and out channels connecting the NodeOS to the network.</figDesc><graphic coords="6,325.92,62.28,204.48,139.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Internal structure of a user-provided module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The Janos architecture and the corresponding DARPA active network architecture.</figDesc><graphic coords="7,312.78,62.24,228.00,106.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. AMP architecture.</figDesc><graphic coords="10,314.94,62.26,227.00,101.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PACKET</head><label>I</label><figDesc>FORWARDING RATES FOR VARIOUS PATHS, MEASURED IN THOUSANDS</figDesc><table /><note><p>OF PACKETS-PER-SECOND (KPPS)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II PACKET</head><label>II</label><figDesc>FORWARDING RATES AT VARIOUS LEVELS OF THE JANOS ARCHITECTURE, IN THOUSANDS OF PACKETS-PER-SECOND (KPPS)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III PACKET</head><label>III</label><figDesc>FORWARDING RATES FOR VARIOUS SOFTWARE LAYERS, MEASURED IN THOUSANDS OF PACKETS-PER-SECOND (KPPS)</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors are indebted to the many members of the active network community who contributed to the collaborative design effort that resulted in the DARPA active network architectural documents. The authors are grateful to the anonymous reviewers and to D. Wetherall for their many helpful comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by Defense Advanced Research Projects Agency (DARPA) under Contract N66001-96-8518, Contract N66001-97-C-8514, and Contract DABT63-94-C-0058, and in part by the National Science Foundation under Grant ANI-99-06704 and Grant ANI-00-82493. L. Peterson and Y. Gottlieb are with the Dept. of Computer Science,</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">NodeOS interface specification</title>
		<author>
			<orgName type="collaboration">Active Network NodeOS Working Group.</orgName>
		</author>
		<ptr target="http://www.cs.princeton.edu/nsg/papers/nodeos.ps" />
		<imprint>
			<date type="published" when="2000-01">2000. Jan</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Architectural framework for active networks</title>
		<ptr target="http://www.darpa.mil/ito/research/anets/Arcdocs.html" />
		<imprint>
			<date type="published" when="1999-07">1999, July</date>
		</imprint>
	</monogr>
	<note>Active Network Working Group. version 1.0. [Online</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active bridging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Nettles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM Conf</title>
		<meeting>ACM SIGCOMM Conf<address><addrLine>Cannes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-09">Sept. 1997</date>
			<biblScope unit="page" from="101" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Resource containers: A new facility for resource management in server systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Banga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Druschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mogul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Symp. Operating System Design, Implementation</title>
		<meeting>3rd Symp. Operating System Design, Implementation<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-02">Feb. 1999</date>
			<biblScope unit="page" from="45" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Congestion control and caching in CANES</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Calvert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zegura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>presented at the ICC</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The design philosophy of the DARPA internet protocols</title>
		<author>
			<persName><forename type="first">D</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM Symp</title>
		<meeting>SIGCOMM Symp<address><addrLine>Palo Alto, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-08">Aug. 1988</date>
			<biblScope unit="page" from="106" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Router plugins: A software architecture for next generation routers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Decasper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dittia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Parulkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Plattner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCOMM Conf</title>
		<meeting>SIGCOMM Conf<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">Sept. 1998</date>
			<biblScope unit="page" from="229" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">University of Utah network testbed and emulation facility web site</title>
		<ptr target="http://www.cs.utah.edu/flux/testbed/" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Flux Research Group, University of Utah</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The flux OSKit: A substrate for OS and language research</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lepreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shivers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th ACM Symp. Operating Systems Principles</title>
		<meeting>16th ACM Symp. Operating Systems Principles<address><addrLine>St. Malo, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-10">Oct. 1997</date>
			<biblScope unit="page" from="38" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Experiences building a communication-oriented JavaOS</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bavier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bigot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bridges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Montz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Piltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Proebsting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Spatscheck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software-Practice &amp; Experience</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1107" to="1126" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">PLAN: A packet language for active networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nettles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICFP</title>
		<meeting>ICFP</meeting>
		<imprint>
			<date type="published" when="1998-09">Sept. 1998</date>
			<biblScope unit="page" from="86" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">IEEE P1520: Proposed IEEE standard for application programming interfaces for networks-Web site</title>
		<ptr target="http://www.ieee-pin.org/" />
	</analytic>
	<monogr>
		<title level="m">IEEE P1520 Working Group</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Application performance and flexibility on exokernel systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Kaashoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Engler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Ganger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Briceno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mazieres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pinckney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mackenzie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th ACM Symp. Operating Systems Principles</title>
		<meeting>16th ACM Symp. Operating Systems Principles<address><addrLine>St. Malo, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-10">Oct. 1997</date>
			<biblScope unit="page" from="52" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">VERA: An extensible router architecture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE OPENARCH</title>
		<imprint>
			<date type="published" when="2001-04">Apr. 2001</date>
			<pubPlace>Anchorage, AK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The click modular router</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Kaashoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="263" to="297" />
			<date type="published" when="2000-11">Nov. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Open programmable architecture for Java-enabled network devices</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jaegeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hollingsworth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-08">Aug. 1999</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>IEEE Workshop Hot Interconnects, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The design and implementation of an operating system to support distributed multimedia applications</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roscoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fairbairns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Hyden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Select. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1280" to="1297" />
			<date type="published" when="1996-09">Sept. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving IPC by kernel design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liedtke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th ACM Symp. Operating Systems Principles</title>
		<meeting>14th ACM Symp. Operating Systems Principles<address><addrLine>Asheville, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-12">Dec. 1993</date>
			<biblScope unit="page" from="175" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">RCANE: A resource controlled framework for active network services</title>
		<author>
			<persName><forename type="first">P</forename><surname>Menage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Working Conf. Active Networks</title>
		<meeting>1st Int. Working Conf. Active Networks</meeting>
		<imprint>
			<date type="published" when="1999-07">July 1999</date>
			<biblScope unit="volume">1653</biblScope>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bowman: A node OS for active networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Merugu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zegura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Calvert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM</title>
		<meeting><address><addrLine>Tel-Aviv, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-03">Mar. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Making paths explicit in the Scout operating system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mosberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Symp. Operating System Design</title>
		<meeting>2nd Symp. Operating System Design<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996</date>
			<biblScope unit="page" from="153" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Computation Framework for an Extensible Network Router: Design, Implementation and Evaluation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-C</forename><surname>Chiueh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>SUNY Stony Brook ECSL TR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The Caml language</title>
		<ptr target="http://pauillac.inria.fr/caml/index-eng.html" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>INRIA</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Activating networks: A progress report</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Calvert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Orman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="32" to="41" />
			<date type="published" when="1999-04">Apr. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Defending against denial of service attacks in Scout</title>
		<author>
			<persName><forename type="first">O</forename><surname>Spatscheck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Symp. Operating System Design, Implementation</title>
		<meeting>3rd Symp. Operating System Design, Implementation<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-02">Feb. 1999</date>
			<biblScope unit="page" from="59" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Toward an active network architecture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tennenhouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wetherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Multimedia Computing and Networking</title>
		<imprint>
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Janos: A Java-oriented OS for active network nodes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tullmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hibler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lepreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Select. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Lottery and Stride Scheduling: Flexible Proportional-Share Resource Management</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Waldspurger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ph.D. Dissertation, Dept. Comput. Sci</title>
		<imprint>
			<date type="published" when="1995-09">Sept. 1995</date>
			<pubPlace>Massachusetts Institute of Technology, Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Active network vision and reality: Lessons from a capsule-based system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wetherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Symp. Operating Systems Principles</title>
		<meeting>17th Symp. Operating Systems Principles<address><addrLine>Kiawah Island, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-12">Dec. 1999</date>
			<biblScope unit="page" from="64" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">ANTS: A toolkit for building and dynamically deploying network protocols</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wetherall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tennenhouse</surname></persName>
		</author>
		<idno>IEEE OPENARCH</idno>
		<imprint>
			<date type="published" when="1998-04">Apr. 1998</date>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Kaffe-A virtual machine to compile and interpret Java bytecodes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wilkinson</surname></persName>
		</author>
		<ptr target="http://www.transvir-tual.com/kaffe.html" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">MFORTH-Programmer&apos;s Manual</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zander</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984-04">Apr. 1984</date>
		</imprint>
		<respStmt>
			<orgName>Linkvping University, Dept. of EE</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Techn. Rep. LiTH-ISY-I-0660</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">presented at the 2nd ARRL Amateur Radio Computer Networking Conf</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Forchheimer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983-03">Mar. 1983</date>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>Softnet-An approach to high level packet communication</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">RSVP: A new resource reservation protocol</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zappala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="8" to="18" />
			<date type="published" when="1993-09">Sept. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">He is also a member of the Internet&apos;s End-to-End research group, and a fellow of the ACM. Yitzchak Gottlieb received a Sc.B. degree in applied mathematics-computer science from Brown University</title>
		<author>
			<persName><forename type="first">Larry</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dr. Peterson is the Editor-in-Chief of the ACM Transactions on Computer Systems, has been on the editorial boards for IEEE/ACM Transactions on Networking and the IEEE Journal on Selected Areas in Communication, and has served on program committees for SOSP, SIGCOMM, OSDI, and ASPLOS</title>
		<meeting><address><addrLine>West Lafayette, IN; Princeton, NJ; Morgan Kauffman; Providence, RI; Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1982. 1985. 2000. 1998</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science with Princeton University</orgName>
		</respStmt>
	</monogr>
	<note>His research focuses on end-to-end issues related to computer networks and he has been involved in the design and implementation of x-kernel and Scout operating systems. He is currently working toward the Ph.D. degree in computer science at Princeton University</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">He is a Research Staff Member with the Flux Research Group, School of Computing, University of Utah, Salt Lake City. His research interest is operating system design and implementation including virtual memory systems, network support and security. He was a major contributor to the original BSD project and has been involved with the design and implementation of the Mach4, Fluke, and Moab research operating systems</title>
		<imprint>
			<date type="published" when="1980">1980. 1983</date>
			<publisher>Mike Hibler received the B.S. and M.S. degrees in computer science from New Mexico Institute of Technology</publisher>
			<pubPlace>Socorro, NM</pubPlace>
		</imprint>
	</monogr>
	<note>respectively</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">He is a Research Associate in the Flux Research Group, School of Computing, University of Utah. His research interests lie at the intersection of operating systems and high-level languages, and he has worked on the Fluke, Alta, and Moab operating systems in the Flux research group</title>
	</analytic>
	<monogr>
		<title level="s">Patrick Tullmann received the B.S. degree in computer science from the University of Vermont</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Burlington, VT; Salt Lake City, UT</pubPlace>
		</imprint>
	</monogr>
	<note>1995 and the M.S. degree in computer science from the University of Utah. Mr. Tullman is a member of the Usenix Association</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">He has interests in many areas of software systems, most of them originating in operating systems issues, although many go far afield. Those disparate areas include information and resource security, networking, programming and nontraditional languages, compilers, component-based systems, and even a pinch of software engineering and formal methods. In 1994, he founded the highly successful and prestigious OSDI conference series, one of the two premier OS conferences. His current service efforts are focused on developing a large-scale, reconfigurable</title>
		<imprint/>
		<respStmt>
			<orgName>Jay Lepreau heads the Flux Research Group, School of Computing, University of Utah</orgName>
		</respStmt>
	</monogr>
	<note>network emulation testbed that is universally available to remote researchers</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">where he manages projects investigating high-speed firewall technology and active networking. He has been involved in the development and application of technology in the areas of operating systems, security, high-performance networking and parallel computing</title>
	</analytic>
	<monogr>
		<title level="s">Stephen Schwab received the B.S. degree in electrical engineering and com</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Associates, Inc</publisher>
			<pubPlace>Pittsburgh, PA; Los Angeles, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note>He is a Senior Research Scientist with NAI Labs, the security research division of Network. Mr. Schwab is a member of the ACM</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">He is currently a Research Scientist with NAI Labs, the security research division of Network Associates, Inc., Los Angeles, CA, where he has been involved in implementing the NodeOS interface for active routers using the exokernel system</title>
	</analytic>
	<monogr>
		<title level="m">His research interests are in the areas of computer networking and operating systems</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Hrishikesh Dandekar received the B.S. degree in computer engineering from the University of Pune, Maharashtra, India, in 1996, and the M.S. in computer science from the University of Southern California</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
