<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nihal</forename><forename type="middle">V</forename><surname>Nayak</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abheesht</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Saiful</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thibault</forename><surname>Fevry</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Santilli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Srulik</forename><surname>Ben-David</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gunjan</forename><surname>Chhablani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Han</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><forename type="middle">Alan</forename><surname>Fries</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maged</forename><forename type="middle">S</forename><surname>Al-Shaibani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shanya</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Urmish</forename><surname>Thakker</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Khalid</forename><surname>Almubarak</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangru</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">2 Snorkel AI 3 Hugging Face 4 BITS Pilani 5 VU Amsterdam 6 NTU 7 BigScience 8 KFUPM 9 SAP 10 University of Rome 11 CMU 12 Technion 13 UCSD 14 NYU 15 Stanford University 16 Walmart Labs 17 SambaNova Systems 18 PSAU 19 Yale University 20 ZEALS * Equal Contribution</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively.</p><p>PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a communitydriven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. Prompt-Source is available at https://github. com/bigscience-workshop/ promptsource.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Prompt engineering is emerging as a new focus in NLP, particularly in zero-and few-shot learning settings. Prompting is the practice of representing a task as a natural language utterance in order to query a language model for a response <ref type="bibr" target="#b17">(Liu et al., 2021)</ref>. For example, if a language model is conditioned on the text "She hit a home run. The previous sentence is about ...", then the model's subsequent generation would be interpreted as a prediction of the topic of the preceding sentence, e.g. by mapping a response such as "sports" to a label class. In specific contexts, prompting has been shown to have advantages over traditional classification, for example facilitating adaptation of language models to ad-hoc tasks and improving sample efficiency in low-data settings <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr" target="#b28">Schick and Schütze, 2021b;</ref><ref type="bibr" target="#b9">Le Scao and Rush, 2021;</ref><ref type="bibr" target="#b6">Gao et al., 2021)</ref>. These advantages motivate a practical challenge: How can we enable users to create, refine, and share prompts?</p><p>The process of prompt engineering is critical for successful deployment as choices in prompting can affect downstream predictions significantly, particularly in the zero-shot setting <ref type="bibr" target="#b22">(Perez et al., 2021;</ref><ref type="bibr" target="#b37">Zhao et al., 2021;</ref><ref type="bibr" target="#b32">Webson and Pavlick, 2021)</ref>. Furthermore, training directly on collections of prompts can enable large models to generalize to new prompts more robustly <ref type="bibr">(Sanh et al., 2021;</ref><ref type="bibr">Wei et al., 2021;</ref><ref type="bibr" target="#b18">Min et al., 2021;</ref><ref type="bibr">Mishra et al., 2021)</ref>. There is therefore a growing need for tools that support the creation of corpora of prompts.</p><p>PromptSource is an integrated development environment and repository for natural language prompts to use in the context of zero-shot (or gradient-based few-shot) learning. It provides a Web-based GUI that enables developers to write prompts in a templating language and immediately view their outputs on different examples. The system is integrated with the HuggingFace Datasets library <ref type="bibr">(Lhoest et al., 2021)</ref>, so that users can load any dataset automatically, browse existing prompts, and create new ones. Through the course of writing thousands of prompts, we converged on three key arXiv:2202.01279v1 [cs.LG] 2 Feb 2022 aspects to the design of PromptSource:</p><p>• Flexible Templating Language. We adapt a templating language to represent prompts. Prompt authors can define prompts in terms of dataset fields, hard-coded text, and simple control logic. This choice provides the flexibility of a programming environment without the mental overhead of having to write and read arbitrary code. Prompt templates can easily be distributed and used in other systems. PromptSource includes a set of guidelines for prompting based on a large-scale prompt writing pilot. PromptSource's collection is meant to be useful for a wide range of research, based on iterative refinement of a set of quality standards. Prompts in PromptSource are also annotated with various pieces of metadata to make finding and using prompts easier. The PromptSource system includes over 2,000 open-source prompts for roughly 170 datasets, which have all been reviewed to meet the quality standards. This collection, which we call the Public Pool of Prompts (P3), allows users to materialize prompted forms of datasets for hundreds of different tasks. The T0 series of models <ref type="bibr">(Sanh et al., 2021)</ref> for zero-shot inference were fine-tuned on a subset of P3. Since then, PromptSource and P3 have been extended for research on multi-lingual prompting <ref type="bibr" target="#b16">(Lin et al., 2021)</ref> and priming, i.e., incontext few-shot learning <ref type="bibr" target="#b18">(Min et al., 2021)</ref>. The PromptSource system and associated content is a first step in the study of systems for prompt engineering, an area that is likely to continue to grow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>PromptSource builds on recent work in prompting and prompt engineering. It is also related to work on systems for other types of annotations. Prompting Recently, prompting has emerged as a new focus within NLP as it can dramatically improve language models' few-shot and zero-shot performance in a wide range of downstream tasks <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr" target="#b27">Schick and Schütze, 2021a;</ref><ref type="bibr">Sanh et al., 2021;</ref><ref type="bibr">Wei et al., 2021)</ref>. Prompts and prompt engineering come in several varieties <ref type="bibr" target="#b17">(Liu et al., 2021)</ref>. PromptSource is focused on facilitating research with human-written prompts, in which natural language is the medium for describing tasks. This approach has the advantage that prompts can be understood, modified, and applied without being tied to a specific model. In contrast, past work has also aimed to automatically construct prompts by framing the search for a good prompt as a learning problem. These prompts can either be expressed in natural language <ref type="bibr" target="#b6">(Gao et al., 2021;</ref><ref type="bibr" target="#b29">Shin et al., 2020)</ref> or as arbitrary vectors (a.k.a. "continuous" or "soft" prompts) not corresponding to words in the model's original vocabulary <ref type="bibr" target="#b11">(Lester et al., 2021;</ref><ref type="bibr" target="#b24">Qin and Eisner, 2021)</ref> When using human-written prompts, there are several possible approaches to learning. One is a zero-shot setting, where the goal is to generalize to prompts for which no training examples are given. Prompts can also be used in a few-shot setting, in which a model is either (1) trained on prompted examples of the target task via gradient updates, or (2) priming (i.e. in-context learning), in which labeled examples are included in an input sequence in order to prime models to make predictions without gradient updates <ref type="bibr" target="#b2">(Brown et al., 2020)</ref>.</p><p>PromptSource was originally designed for zeroshot learning, so it emphasizes explicit task instructions and no priming examples. If needed, users can extend PromptSource for few-shot learning (e.g., as done in <ref type="bibr" target="#b16">Lin et al., 2021 and</ref><ref type="bibr">Min et al., 2021, described in §7)</ref>.</p><p>Systems for Annotating Data Most work on collecting annotations has focused on labels and other annotations at the level of individual examples <ref type="bibr" target="#b20">(Neves and Ševa, 2021)</ref>. GATE <ref type="bibr" target="#b4">(Cunningham et al., 2002</ref>) was an early system for annotating text, and includes support for many data types such as labels and entity tags. Since then, many Webbased systems for annotating text have been developed <ref type="bibr" target="#b30">(Stenetorp et al., 2012;</ref><ref type="bibr" target="#b25">Salgado et al., 2012;</ref><ref type="bibr" target="#b3">Wei et al., 2013;</ref><ref type="bibr" target="#b36">Yimam et al., 2013;</ref><ref type="bibr" target="#b3">Chen and Styler, 2013;</ref><ref type="bibr" target="#b5">Eckart de Castilho et al., 2016;</ref><ref type="bibr" target="#b23">Putra et al., 2020)</ref>. Other systems support collaboration among multiple annotators <ref type="bibr" target="#b35">(Yang et al., 2018;</ref><ref type="bibr" target="#b31">Stewart et al., 2019)</ref>. More recently, many annotation systems have begun to incorporate learned models to improve workflow, using techniques such as ac- tive learning <ref type="bibr" target="#b15">(Lin et al., 2019;</ref><ref type="bibr" target="#b14">Li et al., 2021)</ref> and example recommendation <ref type="bibr" target="#b10">(Lee et al., 2020;</ref><ref type="bibr" target="#b8">Kiela et al., 2021)</ref>. These systems are possible because the annotations to be collected are labels, for which metrics like inter-annotator agreement and model confidence are available.</p><p>There has also been some work on collecting annotations other than labels. AlvisAE <ref type="bibr" target="#b21">(Papazian et al., 2012)</ref> and TreeAnnotator <ref type="bibr" target="#b7">(Helfrich et al., 2018)</ref> support creating ontologies and other structured annotations. Prompts differ from these annotations in that they are semi-structured functions, requiring new tools for developers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Design and Workflow</head><p>Creating prompts differs from other types of data collection and annotation. We note three different challenge axes along which prompting differs from traditional NLP annotation:</p><p>• Functions, not Labels. A single prompt is a function that maps dataset examples (dictionaries of arbitrary fields) to natural language input/target pairs. Creating a prompt is therefore more like programming than typical data annotation. How should a prompt format trade off between expressivity and simplicity? To illustrate these distinct axes, we start with a concrete overview of the prompt creation process of PromptSource. For this example, we imagine that a user of PromptSource is creating prompts for a natural language inference dataset, specifically SNLI <ref type="bibr" target="#b0">(Bowman et al., 2015)</ref>. The goal is to design a prompt query such that the answer can be mapped onto the SNLI classes. A prompt author can accomplish this goal with PromptSource via the following five steps (Figure <ref type="figure" target="#fig_0">1</ref>): S1: Dataset Exploration The prompt author first needs to read the dataset description, including linked READMEs and papers, and to browse through example rows. In this case, they would see that SNLI is a dataset for natural language inference: assume a given premise sentence is true, the goal is to determine whether a hypothesis sentence is true (entailment), false (contradiction), or undetermined (neutral).</p><p>S2: Prompt Writing The prompt author uses the sourcing mode to try out a prompt wording, and then adjusts it by observing prompted examples (Figure <ref type="figure" target="#fig_0">1</ref> middle, full example in Figure <ref type="figure" target="#fig_5">5</ref> and 6 in Appendix B).</p><p>S3: Prompt Documentation To facilitate using the prompt, the author fills in various metadata including possible metrics to evaluate the prompt , valid outputs if applicable , whether the prompt expresses the original intended task of the dataset and whether the template explicitly states the valid outputs.</p><p>S4: Iteration and Variation The prompt author then iterates through S2 and S3 to create multiple prompts for the dataset. Authors are encouraged to vary multiple factors such as the formulation of the prompt and the targeted task (see Section 6).</p><p>S5: Global Review The author saves the draft prompts in a structured file which are then verified by other contributors through code reviews. New prompts need to meet the quality standard with a series of automatic tests and by validation through prompted instances. Upon passing review, the new prompts can be merged into a global prompts collection.</p><p>Upon submission, prompts can be viewed through PromptSource by other users. The full collection is stored globally and can be used outside of the tool, for instance to be applied on an example from a dataset of the Datasets library <ref type="bibr">(Lhoest et al., 2021)</ref>. With this workflow in mind, we next describe the key aspects of the PromptSource system in greater detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Prompting Language</head><p>A key design decision is the format for prompts. We note that previous works on prompting tended to utilize code for specifying each prompt. We experimented with this format and found a trade-off between expressivity and explicit structure. On one side, a maximally expressive format such as pure Python code would let users write complex programs to manipulate the semi-structured examples into prompted examples. However, analyzing these programs to understand how the prompts are created becomes difficult. This difficulty limits downstream manipulation and analysis of the prompts, for example for possible future work on automatic prompt augmentation. On the other side, a maximally structured format, such as rule-based generation, limits the kinds of prompts that users can create. We found it infeasible to enumerate types of rules sufficient for the wide range of tasks and data formats for which we wanted prompts.</p><p>We therefore settled on a middle ground between the two: a templating language. Specifically, we use the Jinja2 templating engine<ref type="foot" target="#foot_0">1</ref> , originally designed for producing web markup. Users write templates as prompts with placeholders, such as If {{premise}} is true, is it also true that {{hypothesis}}? ||| {{entailed}}.</p><p>The separator ||| denotes the break between the conditioning text and the desired completion. Placeholders refer to fields in the underlying example (represented as a Python dict by Datasets <ref type="bibr">(Lhoest et al., 2021)</ref>). Users also have access to Jinja's built-in functions, such as manipulating strings and structured data. For each prompt, prompted examples are created by applying the prompt to all examples in the corresponding dataset. While Jinja is a complete programming language, our review guidelines encourage simple functions with minimal additional logic (see Figure <ref type="figure" target="#fig_5">5</ref> and 6 for example).</p><p>During the development of PromptSource, we found that a few idioms were particularly useful. First, not all templates are applicable to all examples in a dataset. Users can wrap templates in Jinja's built-in conditional statements, and any example that results in an empty prompted example is simply skipped. Second, many examples can be used to make multiple training instances, such as a question that has multiple valid answers. We therefore added a choice function that selects an element from a list in a way that can be controlled during dataset generation, such as picking a random element using a seeded random number generator or generating different prompts for each combination of elements in the template. Third, many tasks such as classification and binary question answering have a small set of possible valid completions, and it is common to make predictions for these tasks by scoring only the valid completions and returning the highest one <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr">Sanh et al., 2021;</ref><ref type="bibr">Wei et al., 2021)</ref>. Users therefore can list the valid completions in a separate field and access them as a list in their prompts (displayed as Answer choices in Figure <ref type="figure" target="#fig_5">5</ref> in the appendix). These completions are then explicitly available when evaluating predictions for these prompted examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The PromptSource UI</head><p>The PromptSource system is designed to enable prompt creators to view data (S1), write prompts in a standard format (S2, S3), and verify that their templates work correctly (S5). We implemented a lightweight interface for the tool in Streamlit<ref type="foot" target="#foot_1">2</ref> so that users could download, run locally in a web browser, and then upload their results to a central repository. Testing iterations of the interface on pilot template-writing tasks, we converged on three views for the interface.</p><p>V1: Sourcing This view (see Figure <ref type="figure" target="#fig_5">5</ref> in appendix) allows users to select a dataset to prompt, browse examples from that dataset in the form of tables, and enter a prompt for that dataset. As the user writes their template (S2), every time they save it, the output of the template applied to the current example is displayed next to the editor. We also collect metadata like a name for the template, and a reference for any bibliographic information or rationale for the template.</p><p>V2: Browse This view (see Figure <ref type="figure" target="#fig_2">2</ref>) lets users select prompts and browse the prompted examples generated by them (S4). The original example is viewed side-by-side with the resulting prompted example, with the substituted text highlighted to distinguish from text hard-coded in the template. Users can quickly scroll through many examples, verify the behavior of their prompt, and return to the sourcing view if changes are needed.</p><p>V3 : Helicopter This view (see Figure <ref type="figure" target="#fig_3">3</ref>) allows users to see what datasets are available for writing templates and how many are written for each, to prioritize user attention. This view is particularly useful for moving between datasets and for the prompt reviewers (S5). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Community Guidelines and Process</head><p>Due to the variety of existing NLP datasets, we found out it challenging to exhaustively describe the characteristics of a good prompt: there are no simple metrics like inter-annotator agreement on example-level labels. Instead, over a few iterations, we converged on community guidelines<ref type="foot" target="#foot_2">3</ref> with 3 objectives in mind: (a) provide a standardized vocabulary for discussing prompts between prompt authors, reviewers and users, and minimum requirements for a valid prompt, (b) highlight common errors, and best practices, (c) collect the necessary information about the prompts to support current and future research on prompt engineering. The guidelines were enforced in the use of Prompt-Source by a code review process in which each prompt was reviewed before being committed to the central repository.</p><p>Guidelines apply to the combination of a template (a function that maps an example into an input/target pair in natural language) and a set of metadata about the template. The most important constraint we imposed for a template to be valid is to be formulated in natural language (both for the input and the target). We forbid the used of nonnatural language prompts such as pure code. Each prompt should clearly state what task should be resolved, in a way a non-specialist adult can understand. We found this guideline strikes a good balance between freedom and expressivity in the wording of the prompts on one side and short generic prompts on the other side.</p><p>In early experiments, we found that user-written prompts that did not explicitly state the possible valid completions tended to perform worse in experiments than their counterparts in which the possible valid completions were listed. We encouraged prompt authors to explicitly state the valid outputs in the prompt. In addition, when working with training prompts that include target text, we found it useful to remove variations on the target format that led to spurious ambiguity. For instance, the target template should only contain the answer to the task. It should not contain any extra text such as "The answer is ...", which can be equivalently moved to the input template.</p><p>One of the research question we hope to enable with PromptSource is whether the diversity of the prompt formulation during training leads to models that are more robust to the prompt formulation at test time. Therefore, encouraged prompt authors to create between 5 and 10 (or more) prompts per dataset while varying the prompt formulation. For a given dataset, authors produce multiple prompts per example, sometimes for task formulations that differed from the original dataset. For instance, for question answering dataset, one prompt can ask to extract the answer to a given question from a given passage, while a second prompt can ask to generate a potential answer given an answer and a passage.</p><p>As part of the community process and to facilitate future research, PromptSource asks prompt authors to include additional few metadata for each prompt. Metadata fields include a name for the prompt, a reference to the paper it was extracted from (or any relevant explanation), whether the prompt expresses the task originally intended by the dataset, the valid outputs (if relevant), whether the input template states the valid outputs and possible metrics to evaluate the prompted examples. These can be used in future systems to evaluate how the style and structure of prompts leads to different downstream results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Case Studies</head><p>A system for creating, maintaining and using prompts is a key tool for supporting the emerging research area of prompt engineering in a standardized and reproducible manner. We highlight three recent research for which PromptSource was a necessary resource. Massively multitask fine-tuning <ref type="bibr">Sanh et al. (2021)</ref> study the question of zero-shot behaviors in large language models and asks whether zero-shot generalization can be induced by training a language model on a massively multitask mixture of tasks. To test this question, they use PromptSource to create diverse prompts for a large collection of NLP datasets. P3 is the result of this collection and allows training a language model on a massively multitask mixture of prompted datasets and evaluate the ability of models trained with such a procedure to perform unseen tasks. Multilingual prompting Lin et al. ( <ref type="formula">2021</ref>) study the zero-and few-shot learning abilities of an multilingual autoregressive language model trained on 30 languages. In particular, they are interested in the cross-lingual generalization of such models and benchmark a variety of tasks in multiple languages. PromptSource allows using a massive set of highquality English prompts. Moreover, the English prompts serve as support to create prompts in other languages (through either machine or human translation). Priming (In-Context Learning)</p><p>Min et al. ( <ref type="formula">2021</ref>) study improving models' few-shot priming performance by first fully training a model (with gradient updates) on a multitask mixture formatted with priming examples. They find that incorporating templates from P3 significantly further improves performance compared to training on priming examples alone. Although PromptSource was not originally designed for this specific form priming, users were able to easily use P3's template collection and the templating language for their own priming methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>PromptSource is an open-source system for creating, sharing and using natural language prompts and addresses the need for new collaborative and centralized tools to support the emerging research around prompt engineering. The tool is designed to answer three key needs: a flexible template language, a suite of tools for prompt management and community-driven quality standards. As of January 2022, PromptSource includes a growing collection of 2,000 public prompts for roughly 170 datasets, and has already been instrumental resource for multiple recent research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Data and Statistics</head><p>P3 is the largest public collection of English prompts and is actively growing. As of January 2022, it contains 2'052 English prompts for 170 English datasets (or 269 subsets, one dataset can contain multiple subsets with different prompts). There is an average of 7.6 prompts per data subset and an average 5.6 original-task prompts per data subset (see Figure <ref type="figure" target="#fig_4">4</ref>).</p><p>P3 was developed as part of the BigScience project for open research<ref type="foot" target="#foot_3">4</ref> . There was a open hackathon to collect prompts for as many English NLP dataset (or English subsets of datasets) as possible. Almost 50 unique contributors affiliated with more than 25 institutions in 10 countries participated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Examples of prompt creating in the "Sourcing" mode</head><p>The "Sourcing" mode lets prompt authors write prompts, and iterate on them while observing the resulting prompted example. Figure <ref type="figure" target="#fig_6">5 and 6</ref> shows two examples of different complexities.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Complete views</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The five stages of creating prompts in PromptSource. The Browse view for Dataset Exploration (S1). The Sourcing view for Prompt Writing (S2), Prompt Documentation (S3), and Iteration and Variation (S4). The Browse view for performing a Global Review (S5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>from promptsource.templates import DatasetTemplates prompts = DatasetTemplates("snli") prompt_key = "Based on the previous passage" p = prompts[prompt_key] result = p.apply(example) print("INPUT: ", result[0]) print("TARGET: ", result[1])</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Prompt creators can browse through the dataset examples (left-column) and their prompted form (right column) using the Browse view.</figDesc><graphic url="image-3.png" coords="5,70.87,70.87,226.77,117.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The Helicopter view indicates what datasets have prompts and how many prompts are available for each dataset.</figDesc><graphic url="image-4.png" coords="5,306.43,70.87,217.70,120.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Most of the datasets have between 5 and 10 prompts.</figDesc><graphic url="image-5.png" coords="10,70.87,70.87,226.77,171.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: With the Sourcing mode, prompt authors can write new prompts, fill in the associate metadata, observe the result on examples and iterate.</figDesc><graphic url="image-6.png" coords="10,306.14,126.07,226.78,180.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The templating language strikes a proper balance between expressivity and explicit structure. The following prompt for QA-ZRE (Levy et al., 2017), a dataset for zero-shot relation extraction, shows how to manipulate strings and do conditional statements with Jinja.</figDesc><graphic url="image-7.png" coords="10,306.14,470.39,226.75,163.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Complete view of the Sourcing mode.</figDesc><graphic url="image-8.png" coords="11,70.87,109.08,453.54,243.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Complete view of the Browse mode.</figDesc><graphic url="image-9.png" coords="11,70.87,464.02,453.52,241.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Complete view of the Helicopter mode.</figDesc><graphic url="image-10.png" coords="12,70.87,286.03,453.52,242.93" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://jinja.palletsprojects.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://streamlit.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Complete guidelines can be found at https: //github.com/bigscience-workshop/ promptsource/blob/main/CONTRIBUTING.md.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://bigscience.huggingface.co</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1075</idno>
		<title level="m">A large annotated corpus for learning natural language inference</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<idno>De- cember 6-12</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mc-Candlish, Alec Radford; NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>Ilya Sutskever, and Dario Amodei</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Anafora: A webbased general purpose annotation tool</title>
		<author>
			<persName><forename type="first">Wei-Te</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Styler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 NAACL HLT Demonstration Session</title>
				<meeting>the 2013 NAACL HLT Demonstration Session<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="14" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">GATE: an architecture for development of robust HLT applications</title>
		<author>
			<persName><forename type="first">Hamish</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Tablan</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073112</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="168" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A web-based tool for the integrated annotation of semantic and syntactic structures</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Eckart De Castilho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Éva</forename><surname>Mújdricza-Maydt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seid</forename><surname>Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvana</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)</title>
				<meeting>the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH)<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="76" to="84" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.295</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<title level="s">Long Papers</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3816" to="3830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TreeAnnotator: Versatile visual annotation of hierarchical text relations</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Helfrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Rieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Abrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Lücking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Mehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
				<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynabench: Rethinking benchmarking in NLP</title>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyansh</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grusha</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Ringshia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.324</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter</title>
				<meeting>the 2021 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4110" to="4124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">How many data points is a prompt worth?</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.208</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2627" to="2636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LEAN-LIFE: A label-efficient annotation framework towards learning from explanation</title>
		<author>
			<persName><forename type="first">Dong-Ho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinyuan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Boschee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.42</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.243</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3045" to="3059" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K17-1034</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
				<meeting>the 21st Conference on Computational Natural Language Learning<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. CoNLL 2017</date>
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Théo Matussière, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, François Lagunas, Alexander Rush, and Thomas Wolf. 2021. Datasets: A community library for natural language processing</title>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Villanova Del Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Šaško</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavitvya</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><surname>Brandeis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Patry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clément</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><surname>Delangue</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-demo.21</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Punta Cana; Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="175" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FITAnnotator: A flexible and intelligent text annotation system</title>
		<author>
			<persName><forename type="first">Yanzeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Quangang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-demos.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AlpacaTag: An active learning-based crowd annotation framework for sequence tagging</title>
		<author>
			<persName><forename type="first">Dong-Ho</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ouyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-3010</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="58" to="63" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Few-shot learning with multilingual language models</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian O'</forename><surname>Horo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><forename type="middle">T</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR, abs/2112.10668</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno>CoRR, abs/2107.13586</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Metaicl: Learning to learn in context</title>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno>CoRR, abs/2110.15943</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08773</idno>
		<title level="m">Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-task generalization via natural language crowdsourcing instructions</title>
				<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An extensive review of tools for manual annotation of documents</title>
		<author>
			<persName><forename type="first">Mariana</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jurica</forename><surname>Ševa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="163" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">AlvisAE: a collaborative web text annotation editor for knowledge acquisition</title>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Papazian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bossy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Nédellec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Linguistic Annotation Workshop</title>
				<meeting>the Sixth Linguistic Annotation Workshop<address><addrLine>Jeju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="149" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">True few-shot learning with language models</title>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">TIARA: A tool for annotating discourse relations and sentence reordering</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Wira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gotama</forename><surname>Putra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
				<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6912" to="6920" />
		</imprint>
	</monogr>
	<note>Kana Matsumura, and Takenobu Tokunaga</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning how to ask: Querying LMs with mixtures of soft prompts</title>
		<author>
			<persName><forename type="first">Guanghui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5203" to="5212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MyMiner: a web application for computer-assisted biocuration and text annotation</title>
		<author>
			<persName><forename type="first">David</forename><surname>Salgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Depaule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elodie</forename><surname>Drula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><forename type="middle">V</forename><surname>Tendulkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Leitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfonso</forename><surname>Valencia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Marcelle</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/bts435</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="2285" to="2287" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmish</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanya</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Sharma Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taewoon</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nihal</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debajyoti</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Tian-Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng Xin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshit</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<editor>Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan</editor>
		<imprint>
			<pubPlace>Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf</pubPlace>
		</imprint>
	</monogr>
	<note>Rush. 2021. Multitask prompted training enables zero-shot task generalization</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.20</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
				<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021a</date>
			<biblScope unit="page" from="255" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.185</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021b</date>
			<biblScope unit="page" from="2339" to="2352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasaman</forename><surname>Razeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.346</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4222" to="4235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">brat: a web-based tool for NLP-assisted text annotation</title>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Topić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
				<meeting>the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">Sophia Ananiadou, and Jun&apos;ichi Tsujii. 2012</date>
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Redcoat: A collaborative annotation tool for hierarchical entity typing</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Cardell-Oliver</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3033</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="193" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Do promptbased models really understand the meaning of their prompts?</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<idno>ArXiv, abs/2109.01247</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">PubTator: a web-based text mining tool for assisting biocuration</title>
		<author>
			<persName><forename type="first">Chih-Hsuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-Yu</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1093/nar/gkt441</idno>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">W1</biblScope>
			<biblScope unit="page" from="W518" to="W522" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">2021. Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><surname>Du</surname></persName>
		</author>
		<idno>CoRR, abs/2109.01652</idno>
		<editor>M. Dai, and Quoc V. Le.</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">YEDDA: A lightweight collaborative text span annotation tool</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingxuan</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-4006</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2018, System Demonstrations</title>
				<meeting>ACL 2018, System Demonstrations<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">WebAnno: A flexible, web-based and visually supported system for distributed annotations</title>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Eckart De Castilho</surname></persName>
		</author>
		<author>
			<persName><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Tony</forename><forename type="middle">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno>CoRR, abs/2102.09690</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
