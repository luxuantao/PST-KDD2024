<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Computational Learning Techniques for Intraday FX Trading Using Popular Technical Indicators</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><forename type="middle">A H</forename><surname>Dempster</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre for Financial Research</orgName>
								<orgName type="department" key="dep2">Judge institute of Management</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre for Financial Research</orgName>
								<orgName type="department" key="dep2">Judge institute of Management</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yazann</forename><surname>Romahi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre for Financial Research</orgName>
								<orgName type="department" key="dep2">Judge institute of Management</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><forename type="middle">W P</forename><surname>Thompson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre for Financial Research</orgName>
								<orgName type="department" key="dep2">Judge institute of Management</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Computational Learning Techniques for Intraday FX Trading Using Popular Technical Indicators</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3460DB79A4DF16D8DC99E694C52180DA</idno>
					<note type="submission">received October 16, 2000; revised February 27, 2001.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computational learning</term>
					<term>foreign exchange (FX)</term>
					<term>genetic algoriths (GA)</term>
					<term>linear programming</term>
					<term>Markov chains</term>
					<term>reinforcement learning</term>
					<term>technical trading</term>
					<term>trading systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There is reliable evidence that technical analysis, as used by traders in the foreign exchange (FX) markets, has predictive value regarding future movements of foreign exchange prices. Although the use of artificial intelligence (AI)-based trading algorithms has been an active research area over the last decade, there have been relatively few applications to intraday foreign exchange-the trading frequency at which technical analysis is most commonly used. Previous academic studies have concentrated on testing popular trading rules in isolation or have used a genetic algorithm approach to construct new rules in an attempt to make positive out-of-sample profits after transaction costs. In this paper we consider strategies which use a collection of popular technical indicators as input and seek a profitable trading rule defined in terms of them. We consider two popular computational learning approaches, reinforcement learning and genetic programming (GP), and compare them to a pair of simpler methods: the exact solution of an appropriate Markov decision problem and a simple heuristic. We find that although all methods are able to generate significant in-sample and out-of-sample profits when transaction costs are zero, the genetic algorithm approach is superior for nonzero transaction costs, although none of the methods produce significant profits at realistic transaction costs. We also find that there is a substantial danger of overfitting if in-sample learning is not constrained.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>S INCE the era of floating exchange rates began in the early 1970s, technical trading has become widespread in the foreign exchange (FX) markets. Academic investigation of technical trading however has largely limited itself to daily data. Although daily data is often used for currency overlay strategies within an asset-allocation framework, FX traders trading continuously throughout the day naturally use higher frequency data.</p><p>In this investigation, the relative performance of various optimization techniques in high-frequency (intraday) foreign exchange trading is examined. We compare the performance of a genetic algorithm (GA) and a reinforcement learning (RL) system to a simple linear program (LP) characterising a Markov decision process (MDP) and a heuristic.</p><p>In Section II, we give a brief literature review of preceding work in technical analysis. Sections III and IV then introduce the GA and RL methods. The stochastic optimization problem to be solved by all the compared methods is defined in Section V, while Sections VI-VIII describe in more detail how each approach can be applied to solve this optimization problem approximately. The computational experiments performed are outlined and their results given in Section IX. Section X concludes with a discussion of these results and suggests further avenues of research.</p><p>Reinforcement learning has to date received only limited attention in the financial literature and this paper demonstrates that RL methods show significant promise. The results also indicate that generalization and incorporation of constraints limiting the ability of the algorithms to overfit improves out-of-sample performance, as is demonstrated here by the genetic algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. TECHNICAL ANALYSIS</head><p>Technical analysis has a century-long history amongst investment professionals. However, academics have tended to regard it with a high degree of scepticism over the past few decades largely due to their belief in the efficient markets or random walk hypothesis. Proponents of technical analysis had until very recently never made serious attempts to test the predictability of the various techniques used and as a result the field has remained marginalized in the academic literature.</p><p>However, due to accumulating evidence that markets are less efficient than was originally believed (see, for example, <ref type="bibr" target="#b0">[1]</ref>), there has been a recent resurgence of academic interest in the claims of technical analysis. Lo and MacKinlay <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref> have shown that past prices may be used to forecast future returns to some degree and thus reject the random walk hypothesis for United States stock indexes sampled weekly.</p><p>LeBaron <ref type="bibr" target="#b0">[1]</ref> acknowledges the risk of bias in this research however. Since various rules are applied and only the successful ones are reported, he notes that it is not clear whether the returns achieved could have been attained by a trader who had to make the choice of rules in the first place. LeBaron argues that to avoid this bias it is best simply to look at rules that are both widely used and have been in use for a long period of time. Neely et al. <ref type="bibr" target="#b3">[4]</ref> use a genetic programming based approach to avoid this bias and found out-of-sample net returns in the 1-7% per annum range in currency markets against the dollar during 1981 to 1995.</p><p>Although there has been a significant amount of work in technical analysis, most of this has been based on stock market data. However, since the early 1970s this approach to trading has been widely adopted by foreign currency traders <ref type="bibr" target="#b3">[4]</ref>. A survey by Taylor and Allen <ref type="bibr" target="#b4">[5]</ref> found that in intraday trading 90% of respondents reported the use of technical analysis, with 60% stating that they regarded such information as at least as important as economic fundamentals. Neely et al. <ref type="bibr" target="#b3">[4]</ref> argue that this can be partly explained by the unsatisfactory performance of exchange rate models based on economic fundamentals. They cite Frankel and Rose <ref type="bibr" target="#b5">[6]</ref> who state that no model based on such standard fundamentals like money supplies, real incomes, interest rates, and current-account balances will ever succeed in explaining or predicting a high percentage of the variation in the exchange rate, at least at short or medium-term frequencies.</p><p>A number of researchers have examined net returns due to various trading rules in the foreign exchange markets <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. The general conclusion is that trading rules are sometimes able to earn significant returns net of transaction costs and that this cannot be easily explained as compensation for bearing risk. Neely and Weller <ref type="bibr" target="#b8">[9]</ref> note however that academic investigation of technical trading has not been consistent with the practice of technical analysis. As noted above, technical trading is most popular in the foreign exchange markets where the majority of intraday foreign exchange traders consider themselves technical traders. They trade throughout the day using high-frequency data but aim to end the day with a net open position of zero. This is in contrast to much of the academic literature which has tended to take much longer horizons into account and only consider daily closing prices.</p><p>Goodhart and O'Hara <ref type="bibr" target="#b9">[10]</ref> provide a thorough survey of past work investigating the statistical properties of high-frequency trading data, which has tended to look only at narrow classes of rules. Goodhart and Curcio <ref type="bibr" target="#b10">[11]</ref> examine the usefulness of resistance levels published by Reuters and also examine the performance of various filter rules identified by practitioners. Dempster and Jones <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> examine profitability of the systematic application of the popular channel and head-and-shoulders patterns to intraday FX trading at various frequencies, including with an overlay of statistically derived filtering rules. In subsequent work <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref> upon which this paper expands, they apply a variety of technical trading rules to trade such data (see also Tan <ref type="bibr" target="#b15">[16]</ref>) and also study a genetic program which trades combinations of these rules on the same data <ref type="bibr" target="#b16">[17]</ref>. None of these studies report any evidence of significant profit opportunities, but by focussing on relatively narrow classes of rules their results do not necessarily exclude the possibility that a search over a broader class would reveal profitable strategies. Gencay et al. <ref type="bibr" target="#b17">[18]</ref> in fact assert that simple trading models are able to earn significant returns after transaction costs in various foreign exchange markets using high frequency data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GENETIC ALGORITHMS</head><p>In recent years, the application of artificial intelligence (AI) techniques to technical trading and finance has experienced significant growth. Neural networks have received the most attention in the past and have shown varying degrees of success. However recently there has been a shift in favor of user-transparent, nonblack box evolutionary methods like GAs and in particular genetic programming (GP). An increasing amount of attention in the last several years has been spent on these genetic approaches which have found financial applications in option pricing <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> and as an optimization tool in technical trading applications <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b3">[4]</ref>.</p><p>Evolutionary learning encompasses sets of algorithms that are inspired by Darwinian evolution. GAs are population-based optimization algorithms first proposed by Holland <ref type="bibr" target="#b20">[21]</ref>. They have since become an active research area within the artificial intelligence community and have been successfully applied to a broad range of hard problems. Their success is in part due to their several control parameters that allow them to be highly tuned to the specific problem at hand. GP is an extension proposed by Koza <ref type="bibr" target="#b21">[22]</ref>, whose original goal was to evolve computer programs.</p><p>Pictet et al. <ref type="bibr" target="#b22">[23]</ref> employ a GA to optimize a class of exponentially weighted moving average rules, but run into serious overfitting and poor out-of-sample performance. They report 3.6% to 9.6% annual excess returns net of transaction costs, but as the models of Olsen and Associates are not publicly available their results are difficult to evaluate. Neely and Weller <ref type="bibr" target="#b8">[9]</ref> report that for their GA approach, although strong evidence of predictability in the data is measured out-of-sample when transaction costs are set to zero, no evidence of profitable trading opportunities arise when transaction costs are applied and trading is restricted to times of high market activity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. REINFORCEMENT LEARNING</head><p>Reinforcement learning has so far found only a few financial applications. The reinforcement learning technique is strongly influenced by the theory of MDPs, which evolved from attempts to understand the problem of making sequences of decisions under uncertainty when each decision can depend on the previous decisions and their outcomes. The last decade has witnessed the merging of ideas from the reinforcement learning and control theory communities <ref type="bibr" target="#b23">[24]</ref>. This has expanded the scope of dynamic programming and allowed the approximate solution of problems that were previously considered intractable.</p><p>Although reinforcement learning was developed independently of MDPs, the integration of these ideas with the theory of MDPs brought a new dimension to RL. Watkins <ref type="bibr" target="#b24">[25]</ref> was instrumental in this advance by devising the method of -learning for estimating action-value functions. The nature of reinforcement learning makes it possible to approximate optimal policies in ways that put more effort into learning to make good decisions for frequently encountered situations at the expense of less effort for less frequently encountered situations <ref type="bibr" target="#b25">[26]</ref>. This is a key property which distinguishes reinforcement learning from other approaches for approximate solution of MDP's.</p><p>As fundamental research in reinforcement learning advances, applications to finance have started to emerge. Moody et al. <ref type="bibr" target="#b26">[27]</ref> examine a recurrent reinforcement learning algorithm that seeks to optimize an online estimate of the Sharpe ratio. They also compare the recurrent RL approach to that of -learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. APPLYING OPTIMIZATION METHODS TO TECHNICAL TRADING</head><p>In this paper, following <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b13">[14]</ref>, we consider trading rules defined in terms of eight popular technical indicators used by intraday FX traders. They include both buy and sell signals based on simple trend-detecting techniques such as moving averages as well as more complex rules. The indicators we use are the price channel breakout, adaptive moving average, relative strength index, stochastics, moving average convergence/divergence, moving average crossover, momentum oscillator, and commodity channel index. A complete algorithmic description of these indicators can be found in <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p><p>To define the indicators, we first aggregate the raw tick data into (here) quarter-hourly intervals, and for each compute the bar data-the open, close, high, and low FX rates. Most of the indicators use only the closing price of each bar, so we will introduce the notation to denote the closing GBP:USD FX rate (i.e., the dollar value of one pound) of bar (here we use boldface to indicate random entities).</p><p>We define the market state at time as the binary string of length 16 giving the buy and sell pounds indications of the eight indicators, and define the state space as the set of all possible market states. Here a 1 represents a trading recommendation for an individual indicator whose entry is otherwise 0. In effect, we have constructed from the available tick data a discrete-time data series: at time (the end of the bar interval) we see , compute and must choose whether or not to switch currencies based on the values of the indicators incorporated in and which currency is currently held. We consider this time series to be a realization of a binary string valued stochastic process and make the required trading decisions by solving an appropriate stochastic optimization problem.</p><p>Formally, a trading strategy is a function , , for some current position ( , dollars, or , pounds), telling us whether we should hold pounds ( ) or dollars ( ) over the next timestep. It should be noted that although our trading strategies are formally Markovian (feedback rules), some of our technical indicators require a number of periods of previous values of to decide the corresponding 0-1 entries in . The objective of the trading strategies used in this paper is to maximize the expected dollar return (after transaction costs) up to some horizon : <ref type="bibr" target="#b0">(1)</ref> where denotes expectation, is the proportional transaction cost, and is chosen with the understanding that trading strategies start in dollars, observe and then have the opportunity to switch to pounds. Since we do not have an explicit probabilistic model for how FX rates evolve, we cannot perform the expectation calculation in ( <ref type="formula">1</ref>), but instead adopt the familiar approach of dividing our data series into an in-sample region, over which we optimize the performance of a candidate trading strategy, and an out-of-sample region where the strategy is ultimately tested.</p><p>The different approaches utilized solve slightly different versions of the in-sample optimization problem. The simple heuristic and Markov Chain methods find a rule which takes as input a market state and outputs one of three possible actions: either "hold pounds," "hold dollars" (switching currencies if necessary) or "stay in the same currency."</p><p>The GA and RL approaches find a rule which takes as input the market state and the currency currently held, and chooses between two actions: either to stay in the same currency or switch. Thus the RL and GA method are given slightly more information (their current position) than the heuristic and MDP methods and we might thus expect them to perform better. The GA method also has an extra constraint restricting the complexity of the rules it can generate which is intended to stop overfitting of the in-sample data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. APPLYING RL TO THE TECHNICAL TRADING PROBLEM</head><p>The ultimate goal of reinforcement learning based trading systems is to optimize some relevant measure of trading system performance such as profit, economic utility or risk-adjusted return. A standard RL framework has two central components; an agent and an environment. The agent is the learner and decision maker that interacts with the environment. The environment consists of a set of states and available actions for the agent in each state.</p><p>The agent is bound to the environment through perception and action. At a given time step the agent receives input , which is representative of some state , where is the set of all possible states in the environment. As mentioned in the previous section, is defined here as being a combination of the technical indicator buy and sell pounds decisions prepended to the current state of the agent (0 for holding dollars and 1 for pounds). The agent then selects an action where telling it to hold pounds ( ) or dollars ( ) over the next timestep. This selection is determined by the agent's policy ( , i.e., defined in our case as the trading strategy) which is a mapping from states to probabilities of selecting each of the possible actions.</p><p>For learning to occur while iteratively improving the trading strategy (policy) over multiple passes of the in-sample data, the agent needs a merit function that it seeks to improve. In RL, this is a function of expected return which is the amount of return the agent expects to get in the future as a result of moving forward from the current state. At each learning episode for every time-step the value of the last transition is communicated to the agent by an immediate reward in the form of a scalar reinforcement signal . The expected return from a state is therefore defined as <ref type="bibr" target="#b1">(2)</ref> where is the discount factor and is the final time step. Note that the parameter determines the "far-sightedness" of the agent. If then and the agent myopically tries to maximize reward only at the next time-step. Conversely, as the agent must consider rewards over an increasing number of future time steps to the horizon. The goal of the agent is to learn over a large number of episodes a policy mapping of which maximizes for all as the limit of the approximations obtained from the same states at the previous episode.</p><p>In our implementation, the agent is directly attempting to maximize <ref type="bibr" target="#b0">(1)</ref>. The reward signal is therefore equivalent to actual returns achieved from each state at the previous episode.</p><p>This implies that whenever the agent remains in the base currency, regardless of what happens to the FX rate, the agent is neither rewarded nor penalized.</p><p>Often RL problems have a simple goal in the form of a single state which when attained communicates a fixed reward and has the effect of delaying rewards from the current time period of each learning episode. Maes and Brookes <ref type="bibr" target="#b27">[28]</ref> show that immediate rewards are most effective-when they are feasible. RL problems can in fact be formulated with separate state spaces and reinforcement rewards in order to leave less of a temporal gap between performance and rewards. In particular it has been shown that successive immediate rewards lead to effective learning. Mataric ` <ref type="bibr" target="#b28">[29]</ref> demonstrates the effectiveness of multiple goals and progress estimators, for example, a reward function which provides instantaneously positive and negative rewards based upon "immediate measurable progress relative to specific goals."</p><p>It is for this reason that we chose to define the immediate reward function (2) rather than to communicate the cumulative reward only at the end of each trading episode.</p><p>In reinforcement learning the link between the agent and the environment in which learning occurs is the value function . Its value for a given state is a measure of how "good" it is for an agent to be in that state as given by the total expected future reward from that state under policy . Note that since the agent's policy determines the choice of actions subsequent to a state, the value function evaluated at a state must depend on that policy. Moreover, for any two policies and we say that is preferred to , written , if and only if , . Under suitable technical conditions there will always be at least one policy that is at least as good as all other policies. Such a policy is called an optimal policy and is the target of any learning agent within the RL paradigm. To all optimal policies is associated the optimal value function , which can be defined in terms of a dynamic programming recursion as <ref type="bibr" target="#b2">(3)</ref> Another way to characterize the value of a state is to consider it in terms of the values of all the actions that can be taken from that state assuming that an optimal policy is followed subsequently. This value is referred to as the -value and is given by (4)</p><p>The optimal value function expresses the obvious fact that the value of a state under an optimal policy must equal the expected return for the best action from that state, i.e.,</p><p>The functions and provide the basis for learning algorithms for MDPs.</p><p>-learning <ref type="bibr" target="#b24">[25]</ref> was one of the most important breakthroughs in the reinforcement learning literature <ref type="bibr" target="#b25">[26]</ref>. In this method, the learned action-value function directly approximates the optimal action-value function and dramatically simplifies the analysis of the algorithm to enable convergence proofs. As a bootstrapping approach, -learning estimates the -value function of the problem based on estimates at the previous learning episode. The -learning update is the backward recursion <ref type="bibr" target="#b4">(5)</ref> where the current state-action pair from the previous learning episode. At each iteration (episode) of the learning algorithm, the action-value pairs associated with all the states are updated and over a large number of iterations their values converge to optimality for (4). We note that there are some parameters in (5): in particular, the learning rate refers to the extent with which we update the current -factor based on future rewards, refers to how "far-sighted" the agent is and a final parameter of the algorithm is the policy followed in choosing the potential action at each time step. -learning has been proven to converge to the optimal policy regardless of the policy actually used in the training period <ref type="bibr" target="#b24">[25]</ref>. We find that following a random policy while training yields the best results.</p><p>In order for the algorithm to converge, the learning rate must be set to decrease over the course of learning episodes. Thus has been initially set to 0.15 and converges downwards to 0.000 15 at a rate of , where is the episode (iteration) number which runs from 0 to 10 000. The parameter has been set to 0.9999 so that each state has full sight of future rewards in order to allow faster convergence to the optimal.</p><p>With this RL approach we might expect to be able to outperform all the other approaches on the in-sample data set. However on the out-of-sample data set, in particular at higher slippage values, we suspect that some form of generalization of the input space would lead to more successful performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. APPLYING THE GENETIC ALGORITHM</head><p>The approach chosen extends the genetic programming work initiated in <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b16">[17]</ref>. It is based on the premise that practitioners typically base their decisions on a variety of technical signals, which process is formalized by a trading rule. Such a rule takes as input a number of technical indicators and generates a recommended position (long £, neutral, or long $). The agent applies the rule at each timestep and executes a trade if the rule recommends a different position to the current one.</p><p>Potential rules are constructed as binary trees in which the terminal nodes are one of our 16 indicators yielding a Boolean signal at each timestep and the nonterminal nodes are the Boolean operators AND, OR, and XOR. The rule is evaluated recursively. The value of a terminal node is the state of the associated indicator at the current time; and the value of a nonterminal node is the associated Boolean function applied to its two children. The overall value of the rule is the value of the root node. An overall rule value of one (true) is interpreted as a recommended long £ position and zero (false) is taken as a recommended neutral position. Rules are limited to a maximum depth of four (i.e., a maximum of 16 terminals) to limit complexity. An example rule is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. This definition of a rule generalizes that used in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b13">[14]</ref> which allows trees in the comb form of Fig. <ref type="figure" target="#fig_0">1</ref>, but to depth 10.</p><p>The fitness score of such a rule is defined as the total return cumulated over the appropriate data period [cf. (1)], i.e. <ref type="bibr" target="#b5">(6)</ref> The genetic algorithm is used to search the space of all such rules and is tuned to favor rules that trade successfully (i.e., achieve high fitness scores) in the in-sample training period. An initial population of 250 rules is randomly generated and each rule is evaluated according to <ref type="bibr" target="#b5">(6)</ref>. A new population of rules is generated from this in which high scoring rules are preferred to low scoring rules. This bias means that the fitness scores of the new population should be greater than those of the old population. New rules are generated by two processes: crossover and mutation.</p><p>To use crossover two parent rules are selected from the current population. The selection process is biased toward fitter (better performing) rules: all rules in the current population are ranked in order of fitness score, and are chosen with a probability linearly proportional to their rank. A random subtree is chosen from each parent rule and these two subtrees are swapped between the parent rules to create two new rules, each of which inherits characteristics from both parents. This process is shown in 2. Potential subtrees to swap are checked to ensure that the resulting new rules would not exceed the specified maximum tree depth. Two new rules meeting this criterion are inserted into the new population. For mutation, a single rule is selected from the current population (again biased toward the better performers) and a random node is replaced with a random node of the same type (e.g., an AND might become an OR). The mutated rule is then inserted into the new population.</p><p>New rules are generated using 75% crossover and 25% mutation until a total of 250 new rules are generated, when the new population is evaluated for fitness scores. The average score of the new population should be greater than that of the old due to the favoritism shown to the better performing rules in the old population. This process is repeated 100 times (generations) and the best rule found during the entire run is selected as the output of the genetic algorithm.</p><p>The rules found by this process exhibit a number of desirable properties. First, with careful tuning of the GA they should perform well in-sample. Second, a rule can be understood by humans: it is clear what the rule does, even if it is not clear why it does it. Thirdly, this structure limits (but does not prevent) how much a rule can learn in detail (i.e., overfit) the training data set. It is to be expected that this enforced generalization will lead to better out-of-sample performance with a possible reduction in in-sample performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. MARKOV CHAIN AND SIMPLE HEURISTIC</head><p>In addition to the RL and GA methods we will consider two alternative approaches. The first replaces the in-sample dataset  with a Markov chain on a small set of market states and replaces the problem of maximizing the profit made over the in-sample period with that of maximizing a total expected discounted return assuming Markov dynamics. This approach is described in detail in Section VIII-A.</p><p>The second method is a simple heuristic: with each state we associate a number (which will be interpreted as the expected rise in the exchange FX rate over the next trading periods for some ) and consider strategies which buy pounds if this number exceeds one threshold, and sell pounds when it falls below a second threshold. We then optimize over and the two thresholds to maximize the in-sample profit. More details on this method are given in Section VIII-B.</p><p>These two methods were used to benchmark the success of the true computational learning approaches in maximizing the in-sample profit. Neither are likely to attain the true optimum, but they should perform reasonably well. The heuristic was more successful at solving the in-sample problem with nonzero transaction costs than any of the other approaches, but it does not perform particularly well out-of-sample due to over-fitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. A Markov-Chain Linear Programming Approximation</head><p>Recall that denotes the market-state at time (the values of the indicator recommendations on which the trading decision at time is based). In this section we will let denote the set of all market states which occur in the in-sample dataset.</p><p>We will construct a controlled Markov chain on the set of pairs where denotes a market state present in the in-sample dataset and indicates whether or not pounds are currently held. The controls at each timestep are 0 or 1, indicating the currency we wish to hold over the next timestep as before.</p><p>Denoting by the number of times state appears in the in-sample dataset (excluding the final data-point), and by the number of times state is immediately followed by state , we define a controlled Markov chain ,</p><p>, by fixing and choosing the probability of a transition from to using control to be For , we define an approximation to the expected dollar return over the next timestep given we are in state and hold currency as</p><p>We are now in a position to replace the problem of maximizing the in-sample return with the problem <ref type="bibr" target="#b6">(7)</ref> where is a feedback map from the state-space of the Markov chain to the set of controls and we treat the term as zero (since we must start in dollars). The constant is a discount factor, chosen arbitrarily to be equal to . This is an approximation to the objective <ref type="bibr" target="#b0">(1)</ref>.</p><p>Since the set is quite small, this problem can be solved exactly using the technique of linear programming. To see this, observe that the solution to ( <ref type="formula">7</ref>) is characterized by the optimal value function defined for all as the optimal value (1) when . The function satisfies the dynamic programming recursion <ref type="bibr" target="#b7">(8)</ref> whose solution is unique under various conditions (it suffices that the Markov chain has a finite statespace and that , which is the case here). But a solution to the system above can be obtained by solving the linear program subject to for all and <ref type="bibr" target="#b8">(9)</ref> which must yield the required optimal value function . The optimal action in state can be extracted from the optimal value function by choosing any maximizing the right-hand side of <ref type="bibr" target="#b7">(8)</ref>. The solution to the LP is found for each in-sample period using the CPLEX commercial LP solver.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. A Simple Heuristic</head><p>One objection to the method of the previous section is that when transaction costs are large the solution obtained to the problem in <ref type="bibr" target="#b6">(7)</ref> above may perform badly over the actual in-sample period; worse even than the trivial strategy 'always hold dollars' with a return of 0. As an alternative, we consider a heuristic defined in terms of three parameters : when  when <ref type="bibr" target="#b10">(11)</ref> The expected value in <ref type="bibr" target="#b9">(10)</ref> and ( <ref type="formula">11</ref>) is just the expected return available if we held pounds for the next days given that the current market state is . Since we do not have a stochastic process model for FX rate movements, this expectation must also be estimated from the in-sample data (assuming the ergodic theorem holds) as where is the set . For a several classes of stochastic process models for FX dynamics, the optimal strategy for both very low and very high transaction costs has the form of ( <ref type="formula" target="#formula_0">10</ref>) and <ref type="bibr" target="#b10">(11)</ref>, making it a plausible heuristic in general.</p><p>The optimization of the three parameters of the heuristic is a nonconvex multiextremal problem and for each in-sample period is solved by a simple genetic algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. NUMERICAL EXPERIMENTS</head><p>The results reported below were obtained by applying the approaches described above to the GBP:USD exchange rate data    In-sample fitting performance has been shown for completeness to demonstrate the learning ability of the various approaches. It is clear that on the in-sample data set, the simple heuristic approach consistently outperforms all the other methods except in the no slippage case, when all methods were able to fit the data to essentially the same degree. The out-of-sample test results demonstrate, however, that the heuristic approach was in fact significantly overfitting the data.</p><p>For the out-of-sample back-tests, we note that the genetic algorithm and reinforcement learning approaches tended to outperform the others at lower slippage values. In order to gain further insight into the overall best performing GA, a plot of how often it inferred rules using each indicator for each slippage value is shown in Fig. <ref type="figure" target="#fig_10">11</ref>. Fig. <ref type="figure" target="#fig_11">12</ref> shows the frequencies with which the GA employed specific indicators over the entire four year data period, aggregated for all slippage values and into quarters, with considerable variability in the patterns evident. The GAs reduction in trading frequency with decreasing transaction costs is demonstrated dramatically in Fig. <ref type="figure" target="#fig_12">13</ref>. Similar results apply to the other methods with the exception of the heuristic, whose high trading frequency at realistic transaction costs leads to its poor performance in out-of-sample back-tests. Data on the dealing frequency of all the different approaches is given in Table <ref type="table" target="#tab_1">II</ref> in order to shed light on the risk profiles of the different methods. These results are discussed further in the final Section X.</p><p>In order to evaluate the relative risk-adjusted performance of the trading models further, we now consider several risk measures found in the financial literature. A risk-adjusted measure commonly used to evaluate portfolio models is the Sharpe ratio, defined as Sharpe Ratio <ref type="bibr" target="#b11">(12)</ref> The Sharpe ratio evaluations of our trading models, as shown in Table <ref type="table" target="#tab_2">III</ref> demonstrate that on the dataset used we are able to gain significant risk-adjusted returns up to a slippage value of 1 bp. However the Sharpe ratio is numerically unstable for small variances of returns and cannot consider the clustering of profit and loss trades <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b17">[18]</ref>. Furthermore the Sharpe ratio penalizes strategies for upside volatility and its definition in terms of summary statistics means that a strategy can appear to be successful but in fact suffers from significant drawdown <ref type="bibr" target="#b5">[6]</ref>. Maximum drawdown over a certain period of length is defined as ( <ref type="formula">13</ref>)       where and are the total returns of the periods from to and as defined by ( <ref type="formula">6</ref>) respectively. In our case was defined as on a monthly basis and the mean over the out-ofsample back-test period is reported in Table <ref type="table" target="#tab_3">IV</ref>. We therefore also quote the Stirling ratio, defined as Stirling Ratio <ref type="bibr" target="#b13">(14)</ref> which is the average monthly return divided by the maximum drawdown within that month. This value averaged over the 48 monthly back-test periods is reported in Table <ref type="table" target="#tab_4">V</ref>. The current RL implementation requires about eight minutes CPU time on a 650 MHz Athlon per single training optimization (episode). The GA is implemented in the interpreted language Scheme, but evaluation is parallelised over multiple similar CPUs. It also takes about eight minutes CPU time per optimization on a single machine. The Markov chain and heuristic approaches execute in four seconds and approximately four minutes, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. DISCUSSION AND CONCLUSION</head><p>In this paper we have developed three trading strategies based on computational learning techniques and one simple heuristic based on trading thresholds over a fixed horizon. The strategies based on the genetic (programming) algorithm (GA) and reinforcement ( -) learning train at 15-min intervals on the buy-sell signals from eight popular technical trading indicators-some of which require a number of previous observations-and current positions over a one year period of GBP:USD FX data, while the Markov chain strategy uses the entire set of training data to estimate the relative transition frequencies of the few hundred signal states that occur within a given year. Each of the four trading strategies is then evaluated out-of-sample at 15-min intervals on the next month of indicator signals and this back-testing process is then rolled forward a month and repeated for a total of 48 months.</p><p>It is evident that in-sample, all approaches were able to infer successful trading strategies and also notable that the genetic algorithm consistently underperforms the other methods in-sample. This is undoubtably due to the constraint imposed on the complexity of the rules which was specifically imposed to avoid overfitting. By contrast, the non-GA approaches-in particular the trading threshold heuristic-may end up exploiting noise in the in-sample data set. At zero-slippage (no costs of trading), however, we find that all approaches are able to infer similar strategies and perform similarly out-of-sample. There is evidence that the non-GA approaches do in fact overfit as the GA outperforms the other methods with nonzero transaction costs in the out-of-sample cases up to 8 bp slippage.</p><p>The fact that the techniques investigated here return positive results both in-sample and in out-of-sample back-tests implies that there is useful information in technical indicators that can be exploited. This is consistent with the tenets of technical analysis and contradictory to the efficient market hypothesis. Furthermore, the GAs relatively good out-of-sample performance demonstrates that using a combination of technical indicators leads to better performance than using the individual indicators themselves. In fact, Dempster and Jones <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b13">[14]</ref> demonstrate that with a few exceptions these indicators are largely unprofitable on the same data when considered in isolation. Figs. <ref type="figure" target="#fig_10">11</ref> and<ref type="figure" target="#fig_11">12</ref> demonstrate that some indicators also convey more information than others depending on the slippage value and the market state. We note that the relative strength index (buy/sell) indicators are not used at zero transaction costs but as the slippage is increased, the GA tends to favor them. Indicators such as price channel breakout, stochastics, and moving average crossover (buy) are very important at zero slippage, but the GA appears to disregard the information provided by them at higher slippage values. At zero slippage the GA is able to infer successful strategies without using the current position. However, at higher transaction costs, knowing the current position becomes very important. This lends credence to the argument that this extra position information tends to favor the RL and GA approaches, since the Markov chain approach and the heuristic did not have this information available to them.</p><p>The RL approach, the Markov chain and the heuristic all exploit the fact that of the market possible states only a few hundred actually occur in the in-sample period. This number is small enough that each state may be considered individually when deciding a strategy. However, there are two problems with such a rule when it is back-tested out-of-sample.</p><p>Firstly, we may encounter a state in the out-of-sample data which was not present in the in-sample data. In that case some arbitrary action must be made and both the RL and the Markov chain method choose to hold their current position. This may be a disadvantage if many new states are encountered and it also ignores the fact that some new states may be very similar to states which were present in the in-sample period. The genetic algorithm on the other hand generates a trading rule in the in-sample training period whose structure tends to take the same actions in similar states.</p><p>Secondly, there is a severe danger that these approaches may learn too well (overfit) the specific in-sample data; in other words the in-sample problem they attempt to solve is too specific. Indeed the simple heuristic method demonstrates this quite clearly: it achieves excellent in-sample performance but is mediocre out-of-sample and terrible at realistic transaction costs. The limit on the complexity of the GA is an artificial constraint which reduces the opportunity for the GA to overfit while not prohibiting simple trading rules. This limit effectively forces the GA to work with generalized (classes of specific) states. Thus we hope to improve the current reinforcement learning approach by forcing state generalization and also by improving its convergence properties.</p><p>Another current avenue of research is to find constraints for the in-sample optimization problem which force state generalization (such as the rule-complexity constraint in the GA approach), but for which a heuristic similar to that of Section VIII-B can be applied.</p><p>A further goal is the exploration of generalization methods in the context of a broader RL approach. Neuro-dynamic programming (NDP) <ref type="bibr" target="#b23">[24]</ref> attempts to combine neural networks with the central ideas of dynamic programming in order to address this goal. NDP's employ parametric representations of the value function (such as artificial neural networks) to overcome the curse of dimensionality. The free parameters are tuned using regression or stochastic approximation methods used in combination with classical dynamic programming methods. Further, Wilson's X-classifier system <ref type="bibr" target="#b29">[30]</ref> attempts to merge ideas from reinforcement learning with those from the Classifier System community in order to incorporate generalization into a -Learning-like framework. We also intend to investigate this approach in the present context in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An example rule.</figDesc><graphic coords="5,383.22,62.28,90.00,59.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Genetic algorithm crossover.</figDesc><graphic coords="5,347.94,165.48,160.56,110.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Cumulative in-sample monthly returns at no slippage.</figDesc><graphic coords="6,310.50,257.28,232.32,164.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Cumulative out-of-sample monthly returns at no slippage.</figDesc><graphic coords="6,310.62,452.16,232.08,164.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Cumulative in-sample monthly returns at 1 bp slippage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Cumulative out-of-sample monthly returns at 1 bp slippage.</figDesc><graphic coords="7,48.78,62.28,232.80,164.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Cumulative in-sample monthly returns at 4 bp slippage.</figDesc><graphic coords="7,49.02,263.46,232.32,164.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Cumulative out-of-sample monthly returns at 4 bp slippage.</figDesc><graphic coords="7,312.12,62.28,232.08,165.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Cumulative in-sample monthly returns at 8 bp slippage.</figDesc><graphic coords="7,311.88,267.00,232.56,165.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Cumulative out-of-sample monthly returns at 8 bp slippage.</figDesc><graphic coords="7,311.82,471.72,232.80,163.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Indicators used by the genetic algorithm by slippage.</figDesc><graphic coords="8,326.88,62.28,199.68,169.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Relative frequencies over time of indicators used by the genetic algorithm.</figDesc><graphic coords="8,302.04,270.72,249.36,161.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Genetic algorithm position duration by slippage.</figDesc><graphic coords="8,309.18,480.48,234.96,148.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I OUT</head><label>I</label><figDesc>-OF-SAMPLE AVERAGE ANNUAL RETURNS average monthly returns are shown in TableIfor the various approaches in the out-of-sample case.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II OUT</head><label>II</label><figDesc></figDesc><table /><note><p>-OF-SAMPLE AVERAGE MONTHLY DEALING FREQUENCY</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III OUT</head><label>III</label><figDesc>-OF-SAMPLE SHARPE RATIOS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table><row><cell>OUT-OF-SAMPLE DRAWDOWNS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V OUT</head><label>V</label><figDesc>-OF-SAMPLE STIRLING RATIOS</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. C. Jones for his insightful comments, advice, and proofreading of the paper, and J. Scott for lending his expertise in Scheme.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Publisher Item Identifier S 1045-9227(01)05018-4.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M. A. H. Dempster received the B.</head><p>A. degree from Toronto University, Toronto, ON, Canada, the M.A. degree from Oxford University, Oxford, U.K., and the M.S. and Ph.D. degrees from Carnegie Mellon University, Pittsgurgh, PA, all in mathematics.</p><p>He is currently Professor of Management Studies (Finance and Management Science), Director of the Centre for Financial Research and Director of Research at the Judge Institute of Management Studies in the University of Cambridge. His present research interests include mathematical and computational finance and economics, optimization and nonlinear analysis, stochastic systems, algorithm analysis, decision support, and applications software and telecommunications systems modeling. He is author of more than 100 published research articles and reports and is author, editor or translator of eight books including Mathematics of Derivative Securities (Cambridge, U.K.: Cambridge Univ. Press, 1997).</p><p>Dr. His work focuses on the application on genetic algorithms to building successful automated trading systems.</p><p>Yazann Romahi received the B.Eng. degree in electronics and computer science and the M.Sc. degree in artificial intelligence from Edinburgh University, Edinburgh, U.K. He is pursuing the Ph.D. degree at the Centre for Financial Research at the Judge Institute of Management Studies in the University of Cambridge.</p><p>His Ph.D. work is involved in the investigation of FX Market Dynamics and optimal trading in the FX markets in the presence of transaction costs using artificial intelligence-based techniques.</p><p>G. W. P. Thompson received the M.A. and Ph.D. degrese in mathematics from the Queen's College, Cambridge University, Cambridge, U.K.</p><p>He is a Research Associate at the Centre for Financial Research at the Judge Institute of Management Studies in the University of Cambridge. His Ph.D. work investigated Gaussian models for interest-rates, numerical techniques for pricing complex options in Gaussian markets, and the optimal trading of securities in the presence of transaction costs. His current research interests also include optimization, particularly stochastic programming.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Technical trading rule profitability and foreign exchange intervention</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lebaron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Int. Economics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="124" to="143" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stock market prices do not follow random walks: Evidence froma simple specification test</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Financial Studies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="41" to="66" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">A Nonrandom Walk Down Wall Street</title>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton Univ. Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Is technical analysis in the foreign exchange market profitable? A genetic programming approach</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Neely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dittmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Financial Quantitative Anal</title>
		<imprint>
			<biblScope unit="page" from="405" to="426" />
			<date type="published" when="1997-12">Dec. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The use of technical analysis in the foreign exchange market</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Int. Money Finance</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="304" to="314" />
			<date type="published" when="1992-06">June 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey of empirical research on nominal exchange rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Frankel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Bureau Economic Res</title>
		<imprint>
			<biblScope unit="volume">4865</biblScope>
			<date type="published" when="1994-09">Sept. 1994</date>
		</imprint>
	</monogr>
	<note type="report_type">Working Paper</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The significance of technical trading rule profits in the foreign exchange market: A bootstrap approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Levich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Int. Money Finance</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="451" to="474" />
			<date type="published" when="1993-10">Oct. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Head and shoulders: Not just a flaky pattern</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Osler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Federal Reserve Bank of New York, Staff Papers</title>
		<imprint>
			<date type="published" when="1995-08">Aug. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Intraday technical trading in the foreign exchange market</title>
		<author>
			<persName><forename type="first">C</forename><surname>Neely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Federal Reserve Bank of St. Louis, Working Paper 99-016A</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">High frequency data in financial markets: Issues and applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Goodhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'hara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Empirical Finance</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="73" to="114" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">When support/resistance levels are broken, can profits be made? Evidence from the foreign exchange market</title>
		<author>
			<persName><forename type="first">C</forename><surname>Goodhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Curcio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">London School of Economics</title>
		<imprint>
			<date type="published" when="1992-07">July 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Can channel pattern trading be successfully automated?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A H</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European J. Finance</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Can technical pattern trading be successfully automated? 2. Head and shoulders, Centre Financial Res</title>
		<imprint>
			<date type="published" when="1999-07">July 1999</date>
		</imprint>
		<respStmt>
			<orgName>Judge Inst. Management, Univ. Cambridge</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated Technical Foreign Exchange Trading with High Frequency Data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Centre Financial Res</title>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
		</imprint>
		<respStmt>
			<orgName>Judge Inst. Management, Univ. Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The profitability of intra-day FX trading using technical indicators, Centre Financial Res</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A H</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
		<respStmt>
			<orgName>Judge Inst. Management, Univ. Cambridge</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Topics in foreign exchange trading systems</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
		</imprint>
		<respStmt>
			<orgName>Centre Financial Res., Judge Inst. Management, Univ. Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A real-time adaptive trading system using genetic programming</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A H</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Finance</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time trading models and the statistical properties of foreign exchange rates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gencay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ballocchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dacorogna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pictet</surname></persName>
		</author>
		<idno>1988-12-01</idno>
	</analytic>
	<monogr>
		<title level="m">Internal Document RAG</title>
		<meeting><address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Olsen &amp; Associates</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Option pricing with gas: A second report</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Neural Networks</title>
		<meeting>IEEE Int. Conf. Neural Networks</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An adaptive evolutionary approach to option pricing via genetic programming</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Chidambaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Trigueros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Programming 1998: Proc. 3rd Annu</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Conf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Koza</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Banzhaf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Chellapilla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Deb</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dorigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Fogel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Garzon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Goldberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Iba</surname></persName>
		</editor>
		<editor>
			<persName><surname>Riolo</surname></persName>
		</editor>
		<meeting><address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">July 22-25, 1998</date>
			<biblScope unit="page" from="38" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Univ. Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Genetic Programming: On the Programming of Computers by Means of Natural Selection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Koza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using genetic algorithm for robust optimization in financial applications</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Pictet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Dacorogna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chopard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oudsaidene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schirru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomassini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Network World</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="573" to="587" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<title level="m">Neuro-Dynamic Programming</title>
		<meeting><address><addrLine>Waltham, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Athena Scientific</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning from Delayed Reward</title>
		<author>
			<persName><forename type="first">C</forename><surname>Watkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>Dept. Eng., Univ. Cambridge</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Performance functions and reinforcement learning for trading systems and portfolios</title>
		<author>
			<persName><forename type="first">J</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saffell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Forecasting</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="441" to="470" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to coordinate behaviors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Nat. Conf. Artificial Intell</title>
		<meeting>8th Nat. Conf. Artificial Intell</meeting>
		<imprint>
			<date type="published" when="1990-08-03">July 29-Aug. 3, 1990</date>
			<biblScope unit="page" from="796" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning in multi-robot systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mataric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI-95 Workshop on Adaptation and Learning in Multiagent Systems</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="32" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Classifier fitness based on accuracy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Evolutionary Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="175" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
