<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DeepTriage: Automated Transfer Assistance for Incidents in Cloud Services</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Phuong</forename><surname>Pham</surname></persName>
							<email>phuong.pham@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Redmond</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vivek</forename><surname>Jain</surname></persName>
							<email>vivek.jain@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Redmond</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lukas</forename><surname>Dauterman</surname></persName>
							<email>lukas.dauterman@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Redmond</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Justin</forename><surname>Ormont</surname></persName>
							<email>justin.ormont@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Redmond</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Navendu</forename><surname>Jain</surname></persName>
							<email>navendu@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Redmond</orgName>
								<address>
									<settlement>Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DeepTriage: Automated Transfer Assistance for Incidents in Cloud Services</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3394486.3403380</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As cloud services are growing and generating high revenues, the cost of downtime in these services is becoming significantly expensive. To reduce loss and service downtime, a critical primary step is to execute incident triage, the process of assigning a service incident to the correct responsible team, in a timely manner. An incorrect assignment risks additional incident reroutings and increases its time to mitigate by 10x. However, automated incident triage in large cloud services faces many challenges: (1) a highly imbalanced incident distribution from a large number of teams, (2) wide variety in formats of input data or data sources, (3) scaling to meet production-grade requirements, and (4) gaining engineers' trust in using machine learning recommendations. To address these challenges, we introduce DeepTriage, an intelligent incident transfer service combining multiple machine learning techniques -gradient boosted classifiers, clustering methods, and deep neural networks -in an ensemble to recommend the responsible team to triage an incident. Experimental results on real incidents in Microsoft Azure show that our service achieves 82.9% F1 score. For highly impacted incidents, DeepTriage achieves F1 score from 76.3% âˆ’ 91.3%. We have applied best practices and state-of-the-art frameworks to scale DeepTriage to handle incident routing for all cloud services. Deep-Triage has been deployed in Azure since October 2017 and is used by thousands of teams daily.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Cloud services have become increasingly popular and are expected to gain $331.2 billion in 2022, a 12.6% compound annual growth rate since 2018 <ref type="bibr" target="#b14">[15]</ref>. With this impressive growth, any unplanned service interruption or outage risks customer dissatisfaction as well as a huge economic loss, e.g., $2.5 billion every year for the Fortune 1,000 <ref type="bibr" target="#b1">[2]</ref>. Amazon is estimated to have a $100 million loss due to its 2018 Prime Day outage <ref type="bibr" target="#b15">[16]</ref>.</p><p>Service interruptions can be detected by service monitors (creating live site incidents or LSIs) or reported by customers (creating customer reported incidents or CRIs). In a cloud setting, the incident life cycle is managed via an incident management system (IMS). The fundamental step after incident creation is to route it to the responsible team, called incident triage, to minimize the service downtime. If the assignment is incorrect, it risks a high Time To Mitigate (TTM) as the incident gets rerouted from one team to another while customers are being impacted. Chen et al. <ref type="bibr" target="#b8">[9]</ref> found that 4.11% âˆ’ 91.58% of incidents were rerouted which increases the TTM to more than 10x in a large commercial cloud.</p><p>There are four key challenges making incident routing at cloudscale fundamentally hard:</p><p>â€¢ Large cloud platforms such as Amazon Web Services and Azure comprise tens of thousands of teams, typically organized by feature area or service, with complex inter-dependencies across them. Therefore, a customer issue such as 'virtual machine (VM) not responding' can be due to either the failed compute instance, network being disconnected, VM storage account being down, firewall mis-configuration, etc. Further, this large number of teams poses extreme incident data imbalance as new teams will likely have a smaller scale and lesser incidents compared to older services <ref type="bibr" target="#b22">[23]</ref>. â€¢ Running a cloud service generates a wide variety of monitoring data such as logs, stacktraces, performance counters and service-level indicators. Further, during incident triage, engineers may run diagnostics, execute queries or commands, and discuss the problem over IM or email which are logged in the incident. Therefore, routing the incident requires analyzing such diversity in types of input data and data sources, similar to challenges in bug triage <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>. Further, the content of an incident varies over time as engineers keep adding more information until it is mitigated <ref type="bibr" target="#b9">[10]</ref>. â€¢ Cloud services use agile development to continuously roll out service updates. Similarly, machine learning (ML) model deployments typically follow the same approach in quickly rolling out simple models first, getting user feedback and then building more sophisticated models to incorporate it. Therefore, we need to jointly optimize DeepTriage's accuracy along with the execution time and training cost to continuously deliver business value. â€¢ Finally, engineers, responsible for mitigating incidents, are often used to applying deterministic rules to assign incidents. Given a ML recommendation, engineers have a common ask on how the model came up with the suggestion. Since it is fundamentally challenging to interpret most non-linear ML models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28]</ref>, it is important to bridge this gap to gain engineers' trust to make ML-driven routing decisions.</p><p>While prior work focused on fast incident detection <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b32">33]</ref>, there is little research on automating the incident assignment task <ref type="bibr" target="#b9">[10]</ref>. There has been significant work in triage for software bugs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref>. Some industry approaches provide a rule-based incident triage <ref type="bibr" target="#b28">[29]</ref> but rules can be hard to manage and do not automatically evolve with services. Overall, the complex service dependencies, diversity of data and focus on fast mitigation pose new fundamental challenges for incident triage.</p><p>In this paper, we introduce DeepTriage, an intelligent incident triage service running in Azure since 2017. DeepTriage combines state-of-the-art machine learning techniques -gradient boosted classifiers, clustering methods, and deep neural networks -in an ensemble to handle different types of incident data. To make Deep-Triage run in production, we have applied various best practices in the design and implementation to scale the service on-demand, ensure reliability, and handle the data distribution shift <ref type="bibr" target="#b19">[20]</ref>. These techniques include data sampling and partitioning for class imbalance and reduce training times, model partitioning, performing training and inference steps in parallel, deploying models as cloud web services, decoupling components of the ensemble model for agile iterations, and systematic refresh and validation of the models.</p><p>DeepTriage provides a REST endpoint which is leveraged by customers in various scenarios: (1) finding the right team when user is creating CRIs, (2) full-automated routing for LSIs, (3) integrated in IMS user interface to provide triage recommendations to engineers, (4) automation workflows that combine rule-based triage with ML recommendations. Currently DeepTriage serves thousands of teams daily. Evaluation on hundreds of thousands of incidents show that our approach achieves F1 score equal to 82.9% overall and 76.3% âˆ’ 91.3% in high impacted incidents. Model ablation analysis showed that each of the ML models we used provided a lift in the final ensemble for different incident types. To the best of our knowledge, we are the first one to present a deployed incident triage service for cloud-scale online services.</p><p>This paper makes three key contributions:</p><p>â€¢ We introduce DeepTriage, the first deployed incident triage service based on an ensemble of multiple machine learning techniques to recommend the responsible team for an incident. Experimental results on real data show that our model achieves good performance overall as well as in highly impacted situations. â€¢ We share the best practices and technologies to enable Deep-Triage meeting production requirements at cloud-scale. â€¢ We present lessons learned and implications for deploying an incident triage system to drive down TTM in large online service systems.</p><p>This paper is organized as follow: Section 2 presents the background of an incident management system; Section 3 provides details of DeepTriage; Section 4 shows experimental results; Section 5 describes the deployment of DeepTriage in Azure; Section 6 discusses lessons learned and implications for implementing and deploying an incident triage service at cloud scale; Section 7 presents related work; and Section 8 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND 2.1 Incident Triage in IMS</head><p>A cloud service contains one or more services and each service has many teams. Each incident in an IMS will be assigned to a specific team. An incident life cycle goes through four stages: incident creation, incident triage, incident mitigation and incident resolution. Incident creation could be either via a service monitoring alert or reported by customers. Incidents can have different severity levels e.g., 0-4, where severity 0 represents the highest priority incident having customer impact whereas severity 4 incidents have low impact and typically 2-3 day SLAs and do not need to be dealt with immediately. IMS maintains a roster of on-call engineers (OCEs), who are called or paged if a high priority incident (e.g., Sev 0-2) is received by the IMS. In general, there is one primary OCE and one secondary OCE on the roster. In case the primary OCE does not answer or acknowledge the high priority incident, the IMS calls the secondary OCE. OCEs then acknowledge these incidents and begin their investigation.</p><p>Due to highly complex service dependencies, often incidents are not assigned to the right owners as there are a large number of possible teams (e.g., hundreds or thousands) to which an incident could be assigned. This causes incidents to be mis-routed and repeatedly reassigned across teams before an incident reaches the correct owning team. Figure <ref type="figure">1</ref> shows the rerouting distribution in three scenarios: high severity incidents (0-2), low severity incidents <ref type="bibr" target="#b2">(3)</ref><ref type="bibr" target="#b3">(4)</ref>, and CRIs. We further categorized rerouted incidents into three buckets: only 1 reroute, having 2 reroutes, and more than 2 reroutes. While most rerouted incidents has 1 hop, CRIs pose a big challenge for IMS because nearly one third of the CRIs got rerouted and many of them have more than 2 hops<ref type="foot" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Key Challenges</head><p>There are four key challenges in building an automated incident routing system in cloud deployed IMS.</p><p>â€¢ A large number of possible teams, e.g. tens of thousands of teams, not only challenges machine learning models in terms of complexity but also exhibits extreme data imbalance.</p><p>Figure <ref type="figure">2</ref> shows the ratio of incident distribution of more than 10K teams in Azure over 6 months. While majority teams receive hundreds of thousands of incidents, there are some teams that have only one incident in the same time frame 1 . â€¢ A wide variety of data formats supported in modern IMSs, e.g. HTML content, images, or logged IM, require the routing system to use different approaches to parsing this content and provides useful features information to machine learning models. Figure <ref type="figure" target="#fig_2">3</ref> shows the Venn diagram of incidents having at least a command line, or a query, or a stack trace content. We see that the incidents contain mixed data formats and an automated system cannot focus on a single format. Further, the content of an incident, changing over time as engineers keep adding more information until it is mitigated, may require a sequential approach <ref type="bibr" target="#b9">[10]</ref>.  </p><formula xml:id="formula_0">â€¢</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DEEPTRIAGE OVERVIEW</head><p>DeepTriage is an intelligent incident routing system built upon an ensemble of different machine learning techniques and runs on large scale online services. Besides combining the strength of state-of-the-art machine learning approaches, our system uses best practices in design and implementation to meet production requirements. Next, we present the end to end pipeline of DeepTriage. We start with ingesting data to a distributed database management system for efficient processing (data ingestion); cleaning and partitioning the data for large scale training (data processing); extracting features (feature engineering); and incrementally rolling out the system by adding more advanced machine learning models to address the feedback and improve performance from previous deployments (model architecture).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Ingestion</head><p>DeepTriage uses resolved incidents in IMS as training data. The label for each incident is the first team mitigating the incident and is automatically annotated once a team mitigates an incident. As the data is highly imbalanced (Figure <ref type="figure">2</ref>), we merged all infrequent teams into a special team (class), called Other. A low performance on the infrequent classes will not significantly affect the overall performance. Further, reducing the number of classes decreases model size and complexity, leading to lower training time and execution latency. We extract both textual and contextual data from the incident reports, which has been shown to be effective in prior work <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24]</ref>. Textual data comes from the incident title, summary, and the first three discussion entries. Our analysis indicates that the important information for incident routing is covered in the first three entries and after that, most of the information is about understanding the root cause and logging the troubleshooting steps, as also observed by Chen et al. <ref type="bibr" target="#b9">[10]</ref>. Beside the textual features, we use other important contextual information from IMS such as:</p><p>â€¢ Features related to sources of an incident, e.g. source name (SourceName), the first assigned service (OriginatingServi-ceId), occurring device name (OccurringDeviceName), or raising data center (RaisingDC). â€¢ Features related to characteristics of an incident, e.g. severity (Severity), incident type (IncidentType), or assigned keywords (Keyword).</p><p>Textual data, contextual data, and labels of incident reports are extracted from the SQL database of IMS and ingested into Cosmos <ref type="bibr" target="#b7">[8]</ref>, a distributed computing platform, for efficient batch processing. The ingestion process is done periodically which allows us retraining models with latest data within hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Processing</head><p>To be cost-effective and scale to large datasets, we partition the data into buckets and allow training models in parallel on cloud VMs with commodity CPUs. We sample at most ğ‘› data points from each class and put them into a bucket. The final model is an ensemble of models from different buckets. This approach addresses three problems in the original dataset: 1) reducing the training cost and time because the data size has been reduced significantly, 2) reduce data imbalance by down-sampling majority classes to at most ğ‘› instances, and 3) decrease the variance of predictions as this partitioning is the bagging method for ensemble <ref type="bibr" target="#b17">[18]</ref>.</p><p>We further reduce noisy data by applying domain knowledge from IMS. First, we sub-sample the data with more weights towards more recent data points. Because old data would be outdated as services continue to evolve, e.g. new teams onboarded and old teams deprecated. Second, we set an upper limit of incidents having the same title and mitigated by the same team because many LSIs are generated from the same template and are mitigated by the same teams. Third, we discard most of the low severity incidents and make the majority (e.g., 80%) of the dataset of highly impacted incidents; note that most incidents are LSIs (Table <ref type="table" target="#tab_0">1</ref>) and our analysis revealed many of them are transient (do not need to be transferred to another team).</p><p>For textual data, we perform additional processing:</p><p>â€¢ Cleaning HTML, XML tags, and binary data of embedded images â€¢ Normalizing unicode characters and special entities, e.g. number, GUID, or URL â€¢ Segmentation/tokenization: textual data is segmented into sentences. After that, each sentence is tokenized into individual words (tokens). We use the NLTK toolkit for text segmentation and tokenization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Engineering</head><p>With conventional machine learning models, we categorize contextual data and extract natural language processing (NLP) features for textual data:</p><p>â€¢ Using n-gram hashing to handle the large vocabulary size from incident reports. Besides normal verbal discussion, incident reports have a large vocabulary because engineers put in other information, such as stack traces, error logs, or SQL queries. â€¢ Removing noisy (repeated but not informative) phrases, e.g. "Incident Created" or "resource is unhealthy", and extracting key phrases. We use SysSeive toolkit <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> for key phrase extraction and removing the noisy phrases. With deep learning models, we build domain-specific embeddings for both textual and contextual data.</p><p>â€¢ Textual data: We build fastText embeddings <ref type="bibr" target="#b6">[7]</ref> on the title, summary, and discussion. â€¢ Contextual data: We concatenate all contextual features and build exponential family embeddings <ref type="bibr" target="#b26">[27]</ref>, i.e. an extension of textual word embeddings for high dimensional data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Model Architecture</head><p>DeepTriage is an ensemble approach that combines both conventional machine learning and deep neural networks; ensemble is widely used in Kaggle and has been shown to be effective <ref type="bibr" target="#b17">[18]</ref>. For a production environment, a key requirement is to take an agile approach, i.e., first roll out a base ML model to customers, get feedback, and then drive incremental improvement. We follow the same best practice to incrementally build DeepTriage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Multiple Additive Regression Tree.</head><p>In the first iteration, we built a simple multiple additive regression tree (MART) and partition into multiple models to scale up with the amount of data and classes (teams) in IMS. We build a one-vs-all FastTree <ref type="bibr" target="#b0">[1]</ref> binary classifier, a MART using gradient boosting algorithm in ML.NET.</p><p>In each training step, FastTree builds a decision tree to add to the ensemble of trees from previous steps. The trained MART is the ensemble of these decision trees.</p><p>We observed the diminishing returns on using a large number of features for MART. Based on preliminary experiments on a validation dataset, MART takes the top 30,000 features as its input using Mutual Information feature selection.</p><p>To scale up the system, we partition the data into 10 different buckets leading to 10 MART models. The final recommendations are the top 5 classes ensembled from these 10 models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Light Gradient</head><p>Boosting Machine for CRIs. The second iteration focused on the sparseness and unstructured data in CRIs (as compared to LSIs) by adding a one-vs-all LightGBM which was trained using only CRIs, called LGBM(CRI). LightGBM is an implementation of the gradient boosting machine algorithm. We select the top 50,000 features.</p><p>Since we are only training on CRIs, we partition LGBM(CRI) into 3 buckets. LGBM(CRI) ensembles predictions from these 3 models and outputs the top 5 predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Inverted Index.</head><p>The third iteration bridged the gap in the previous models where new teams or short CRIs usually have low performance because of little training data. To address this cold start problem, we build a simple inverted index (InvertedIndex) consisting of two inverted index tables based on IDF. One table, called local_table, extracts the top 200 words from each team. The other table, called global_table, uses the top 500 words from each team and is re-ranked by IDF scores. We extract unigrams from all textual data as input features. InvertedIndex calculates the confidence score of each team as ğ‘ğ‘œğ‘›ğ‘“ ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’ = ğ›¼ (ğ‘™ğ‘œğ‘ğ‘ğ‘™_ğ‘¡ğ‘ğ‘ğ‘™ğ‘’) + (1 âˆ’ ğ›¼) (ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™_ğ‘¡ğ‘ğ‘ğ‘™ğ‘’) where ğ›¼ = 0.2. The final recommendation list is the top 5 confidence scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">Content-based approach.</head><p>In the fourth iteration, we employed a content-based approach to push improvements on the previous cold start issue as well as on all incidents. We observed that similar incidents are likely to be mitigated by the same teams. We build a locality-sensitive hashing model (SI ), an unsupervised approach approximating nearest neighbor search algorithms, to efficiently find similar incidents for the current incident. Because SI is an unsupervised approach, it can address the cold start issue and scale well with minority classes. In the inference stage, SI loops through all incidents in the training data which is very expensive. We partition training data into 10 buckets so SI can search all the buckets in parallel.  <ref type="figure" target="#fig_4">4</ref>). Both textual and contextual embeddings, extracted from an incident report, are fed through a convolutional block. A convolutional block consists of CNN layers followed by batch normalization (BN) and scaled exponential linear unit (SELU) <ref type="bibr" target="#b18">[19]</ref> layers. We increase the number of filters after each CNN layer, i.e. 32, 64, and 128, to force the network gradually learning good representations of the data. To avoid overfitting, besides BN, we use dropout after the second and the third CNN layer. After the convolutional block, the contextual encoder uses an average pooling layer followed by a fully connected layer while the textual encoder uses a max pooling layer. Both textual and contextual representations are concatenated before forwarded to the classifier component. The classifier component consists of a BN, a dropout, a fully connected layer, and a softmax layer. DNN 's output is the top 5 classes (teams) with the highest scores.  LGBM(CRI)s + 1 InvertedIndex + 1 SI + 1 DNN = 16 models), DeepTriage re-ranks confidence scores of predictions and gives the top 5 recommendations. Different from a classification system, a recommendation system like DeepTriage is effective as long as the correct prediction is within the top ğ‘ (ğ‘ = 5) recommendations. Therefore, we maximize the ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@ğ‘ rather than the ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦@ğ‘ , i.e. keep the highest confidence score of each team across all models and select the top 5 teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION 4.1 Settings &amp; Evaluation Metric</head><p>Our experiment aims to answer three key questions:</p><p>â€¢ Q1: Can DeepTriage give highly accurate recommendations to transfer incidents in IMS? â€¢ Q2: Does DeepTriage have good performance in highly impacted incidents e.g., high severity incidents, incidents in core services, CRIs? â€¢ Q3: Does each incremental model provide a lift in performance for incident routing? We collected six months of data for the training set and retrieved another three days of data for testing. We analyze the results in six scenarios: all incidents (All), high severity incidents (Sev0-2), difficult incidents as having at least 2 hops (Min2Hop), only customer reported incidents (CRI ), high severity incidents from the core services in Azure (Sev0-2@CoreServices), and CRIs having high severity in Azure's core services, called CRI(Sev0-2)@CoreServices.</p><p>The training set has more than 80GB of incident reports, collected from more than 4,000 teams and more than 1,000 services. The data is very imbalanced with the most popular teams having more than hundreds of thousands of incidents while minority teams have only one incident (Figure <ref type="figure">2</ref>). Note that due to the policy of Microsoft, we cannot disclose the actual number of incident reports in this paper.</p><p>As DeepTriage returns an ordered list of 5 recommendations, we use the common performance metrics for recommendation systems or information retrieval, i.e. Precision@N, Recall@N, and F1@N where ğ‘ âˆˆ [1..5].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Result</head><p>Figure <ref type="figure" target="#fig_5">5</ref> shows the performance@N of DeepTriage in each evaluating scenario. In general, DeepTriage achieved a good performance (ğ¹ 1 = 82.95%) on all incidents (Q1) and highly impacted scenarios (Q2): Sev0-2 (ğ¹ 1 = 86.88%), CRI (ğ¹ 1 = 76.38%), Sev0-2@CoreServices (ğ¹ 1 = 91.15%), and CRI(Sev0-2)@CoreServices (ğ¹ 1 = 71.49%). The system struggled with difficult incidents (ğ¹ 1 = 74.14% in Min2Hop).</p><p>Further investigations show that most of the long-hop incidents require multiple teams engage to analyze and find the root cause. For example, a lot of disconnected virtual machines could be due to network device failures or power loss or usage throttling. Finding the right team in these incidents requires additional debugging data. Last but not least, the final model got modest performance at top 1 recommendations. This is due to the current ensemble policy, where DeepTriage is optimized for team coverage but not accuracy.</p><p>To answer Q3, we analyze the model ablation results to find the benefit of adding each model component to DeepTriage. First, combining LGBM(CRI) with MART gave ğ¹ 1 improvements in all evaluated scenarios, especially in CRI. The improvements in ğ¹ 1, ranging from +2% (All) to +29% (CRI ), is credited mostly to the improvements in ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™. Moreover, Sev0-2 also benefited from the MART+LGBM(CRI) model in all performance metrics compared to All. We think this improvement comes from the increasing ratio of CRIs in Sev0-2 (3.55%) compared to All (2.24%). These results suggested that using LGBM(CRI) models, trained specifically on CRI data, will help with routing more CRIs to the right teams.</p><p>Second, adding InvertedIndex upon MART+LGBM(CRI) did not give a significant improvement for DeepTriage. However, we observed some improvements in ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› for incidents in All (+11%) and Sev0-2 (21%) but not much in ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™. This result is expected as InvertedIndex targets the ğ‘ğ‘œğ‘™ğ‘‘ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ situation where the incidents do not frequently appear. Therefore, the ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ metrics did not benefit much from this approach.</p><p>Third, adding SI gave a significant improvement for DeepTriage in all performance metrics. The improvements can be seen clearly in ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›@1 for incidents in All (+23%) and Sev0-2 (+38%). This result implies that many incidents from our data are similar (LSIs generated from templates and mitigated within the same team). The big improvements from ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@4 and ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@5 for CRIs in CRI and CRI(Sev0-2)@CoreServices also implied a counter intuitive assumption, i.e. human-generated incidents are very similar. We analyzed these cases further and found those teams use predefined templates for incidents created toward them. These templates ask users to input required data before transferring the ticket to avoid extra transfers because of missing important information.</p><p>Fourth, DNN slightly improved DeepTriage in All (+2.73% in ğ¹ 1) and Sev0-2 (+3.04% in ğ¹ 1). Interestingly, we observed that DNN gave improvements at top 1 performance from both ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› (+2.41% in All and +1.14% in Sev0-2) and ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ (+1.12% in All and +1.52% in Sev0-2). This top 1 improvement suggested that DNN will bring more value to DeepTriage when we deploy the system as a fully automated routing service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PRODUCTION SYSTEM</head><p>DeepTriage has three main components:</p><p>â€¢ Controller: is implemented as a part of the IMS code base.</p><p>This component handles HTTP requests, collects incident related data, coordinates the other 2 components, and returns top 5 recommendations for each requested incident. â€¢ Predicting: ensembles 16 ML models: 10 MARTs, 3 LGBM(CRI)s, 1 SI, 1 InvertedIndex, 1 SI, and 1 DNN ; which are deployed as Azure Machine Learning (AML) web services. Each web service has a data preprocessing module and a machine learning model which outputs 5 recommended teams and their confidence scores. â€¢ Ensemble: is implemented as an integrated part of the IMS code base. The Ensemble component takes outputs from all models, applies the re-rank algorithm, and returns the top 5 recommendations (teams) to the Controller component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">DeepTriage Usage in Azure</head><p>Implemented as a web service makes it easy to apply DeepTriage into multiple use cases. Our strategy is rolling DeepTriage out as an on-demand assisting service and gradually move humans out of the loop to create a fully automated incident routing service for IMS.</p><p>Next, we describe 4 different use cases that we have been working on to implement the road map. API call: customers use an HTTP Client to call the DeepTriage API. Customers pass an incident ID and receives the top 5 recommended teams that the incident should be transferred to, an auto-suggest. This use case fits the initial stage where we can test the system functionality and allow pilot customers evaluate the correctness of the system without any UI support.</p><p>On the incident's detail web page: when an engineer has problems with selecting a team to transfer an incident to. The engineer can click the Transfer button on IMS portal. DeepTriage will collect the incident ID from the current IMS web page, process, and return the 5 most potential teams for the requested incident.</p><p>At creation time: engineers can also take advantage of DeepTriage right at the time they create incidents. Different from the previous use cases, the incident does not have an incident ID because, literally, it is not created yet. We modify the Controller component to receive title and summary of the incident being created and get top 5 recommendations from DeepTriage.</p><p>Automation workflow: we use the LogicApps (LA) system, an automated workflow based on Azure Logic Apps <ref type="bibr" target="#b3">[4]</ref>, to introduce an initial experience of automated incident routing. We create a workflow listening to all incidents coming to a team. When an incident arrives to the team, the workflow can get 5 recommendations for the incident by calling DeepTriage. The key difference in this use case is the workflow needs to select 1 from the 5 recommendations to transfer the incident. While the top 1 performance of DeepTriage is not perfect, we can improve the performance by incorporating domain knowledge as logic rules in the workflow. We have received a large quantity of positive feedback and observed good results from this kind of machine learning and domain knowledge combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Scaling &amp; Reliability</head><p>5.2.1 Scaling. We have applied best practices in multiple aspects of DeepTriage to scale up in both training (Section 3) and execution. In model design, we partition data to create multiple models trained and executed in parallel. In model building, we use Azure Batch <ref type="bibr" target="#b2">[3]</ref> to acquire VMs on demand and train models in parallel. In model deployment, we deployed the models as AML web services which can be scaled on demand.</p><p>Deployed since 2017 on IMS, DeepTriage serves approximately 1, 000 unique customers with more than 1, 500 API calls per day. The API latency is approximate 833.6ğ‘šğ‘ . LGBM(CRI) added 2% to 29% ğ¹ 1 improvement to scenarios related to CRIs upon MART. Adding InvertedIndex brought 11% to 21% ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› improvement for all incidents or high severity incidents. SI pushed improvements in all metrics, even with top 1 recommendation (ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›@1 had +23% in all incidents and +38% in high severity incidents). DNN lifted ğ¹ 1 in all incidents (+2.73%) and in high severity incidents (+3.04%) as well as top 1 recommendations, e.g. in all incidents ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›@1+2.41%, ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@1+1.12%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.2</head><p>Reliability. Keeping the system's availability high is the key point to support incident triage. As DeepTriage is an ensemble of 16 AML web services and the ranking component is hosted on the IMS system, we have dependencies on these two sources. With AML web services, we observed that most of the errors from AML web services are self-mitigated within a short time and all 16 models have never been down at the same time. We address this problem with a fail-over mechanism. DeepTriage only returns a failure status when all 16 models cannot return any recommendations. Otherwise, the ensemble component will use all available results to pick the top 5 recommendations. A drawback of this mechanism is DeepTriage will miss the correct team when all models suggesting this team all fail. However, this is a reasonable trade off because the chance that many models fail at the same time is very low. Besides, the Controller and the Ensemble components inherit the redundancy mechanism from IMS. These components are run on two independent platforms and only fail when both platforms are down.</p><p>Another reliability problem is data distribution shift: the model's accuracy decreases when data distribution shifts along the time. We setup a retraining pipeline to refresh the models periodically. Currently, we use the last 3 day as testing data. To improve the quality of the test set and make the process more data-driven, we are looking at machine learning approaches as in <ref type="bibr" target="#b11">[12]</ref> to scale up and automate the validation step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">LESSONS LEARNED</head><p>Different customers find DeepTriage helpful in different ways. After deploying DeepTriage, we collected customer feedback for the service.</p><p>Junior engineers found DeepTriage very helpful as they do not have enough experience about teams within the system. For example, "It's really amazing. It helps us to transfer the issue to the right team faster than earlier" or "in general this feature has been useful".</p><p>On the other hand, we did not receive as much positive feedback from senior engineers while the usage from these engineers is as high as the junior engineers. For example, "I knew exactly where I wanted to transfer the incident when I opened it." or "it prompts the teams most suitable but it so happens that teams get re-org so often that scope changes from time to time and looking for the right team becomes a challenge". Further investigations showed that senior engineers used DeepTriage as a "shortcut" to transfer incidents to those teams. Because it takes a single click to transfer an incident with DeepTriage when the correct team is in the recommendation list while it takes more efforts to navigate to the same team from the current UI.</p><p>Provide Insights behind ML recommendations to gain user trust. One of the biggest problems we have when deploying DeepTriage is gaining the trust from our customers, i.e. OCEs, especially the senior engineers who have a lot of domain knowledge and have doubts about the models' suggestions. To quickly address this challenge, we developed a new feature for DeepTriage, called Recommenda-tionInsights, providing additional information about the models' suggestions to strengthen the trust from OCEs. For each recommendation, RecommendationInsights provides how many incidents, which are similar to the current incident, were mitigated in the same team as this recommendation, by how many unique OCEs, and the list of keywords from these similar incidents. This additional information gives OCEs more confidence that they are doing the right thing with DeepTriage.</p><p>Handle every case, no corner cases! One of the main problems with supervised learning is annotated data. While the incident triage problem is self-annotated, we still need to solve the "cold start" problem, where new teams do not have sufficient data. Therefore, DeepTriage includes the InvertedIndex and SI models which are unsupervised approaches. The new teams would rely more on similar incident models until they have sufficient training data.</p><p>A perfect DeepTriage cannot completely drive down transfer hops. The number of hops in some teams will not reduce even with an oracle system. The internal structure of some services requires some transfer loops for communication across the service boundary. For example, internal teams do not have direct connects with customers and need to use another customer-facing team as a communication protocol. Therefore, even if DeepTriage suggests the correct internal team, the incident still takes the transfer loops until it is mitigated (by the recommended team!).</p><p>Identify and address label gaps. From error analysis, we found out some reasons for error predictions in DeepTriage. First, there is a gap in labeling. By internal policy, some teams mitigate incidents even when they are not the teams who are responsible for the incidents. To address this problem, we introduce a new UI component on IMS portal, called ResponsibleTeamId, for each incident. With the new workflow, teams are able to mitigate incidents not belonging to them as long as they set the correct mitigating team for the ResponsibleTeamId.</p><p>Second, some incidents do not have sufficient information for triage. When receiving an incident, on-call engineers would join a call bridge or run some validation scripts on their separated systems to find the root cause and the right triage teams. While the bridge discussions are in IMS and we can incorporate into DeepTriage, the debugging systems are not in IMS yet. We have started working with teams and services to enrich incidents with this information, e.g. using automation workflows to add these information to incidents automatically.</p><p>Combine the best of both worlds, machine learning and domain knowledge. The semi-automated incident triage (LA Workflow) is introduced, teams use their domain knowledge to improve the top 1 performance of DeepTriage.</p><p>The top recommendation from DeepTriage is used when none of the rules can handle an incident. This approach actually boosted the performance of the workflow above 90% accuracy as the rules have very high precision. We think it is a pragmatic way to engage teams to use DeepTriage as an automated service rather than manually triggering. As many teams build their own rules combining with DeepTriage, we can collect those rules and enrich DeepTriage's features to capture all the domain knowledge. However, there is a drawback with this approach as teams need to manage the workflow by themselves. DeepTriage can be used as a fully automated service to route incidents out of a team if the service has a high confidence that the incident should be in another team. We have a plan to develop this fully automated service. One of the key challenges of this is improving the performance@1. This can be augmented by using domain knowledge from current LA workflows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Bug triage is very close to the problem we are solving where the system gives a ranked list of developers (solvers) for a bug report. Early work in bug triage using textual data from the report's description <ref type="bibr" target="#b23">[24]</ref> and contextual features, e.g. product related data, from both the current report and previous reports <ref type="bibr" target="#b30">[31]</ref>. While this approach has suffered from the sparseness between bug reports and new developers, researchers have leveraged developer's expertise to increase the system's accuracy. Matter et al. <ref type="bibr" target="#b22">[23]</ref> extract a developer's expertise from all codes that the developer contributed. On the other hand, Xie et al. <ref type="bibr" target="#b31">[32]</ref> used topic modeling (Latent Dirichlet Allocation) to calculate the probability assigning a developer to the most dominant topic of a bug report.</p><p>In more specific context, researchers tried to reduce number of reassignments (bug tossing) with Markov-based models, called bug tossing graph, from textual data <ref type="bibr" target="#b16">[17]</ref> with contextual (productrelated) data <ref type="bibr" target="#b4">[5]</ref>. In addition to a single approach, Jonsson et al. <ref type="bibr" target="#b17">[18]</ref> showed ensembling multiple models, e.g. Naive Bayes, SVM, KNN, and Decision Tree, will increase the accuracy.</p><p>Recently, with the emergence of deep neural networks, researchers have explored Convolutional Neural Network <ref type="bibr" target="#b19">[20]</ref> with textual data (description and discussion) and sequence to sequence model <ref type="bibr" target="#b29">[30]</ref> on textual content and tossing sequence. Moreover, <ref type="bibr" target="#b19">[20]</ref> also reported their experience when deploying the approach in an industrial environment: using a human assistant instead of fully automated and the need to continuous refreshing (re-training) the model.</p><p>Besides all of the problems managing incidents (bugs) submitted by users, an online service's management system also proactively detects issues from its components using telemetry data (logs) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>Going beyond incident detection, Lou et al. <ref type="bibr" target="#b20">[21]</ref> tried to address the "fixing" stage by analyzing similar incidents and extracting actions to mitigate the current incidents. In additional to logs, an incident management system also handles CRIs <ref type="bibr" target="#b21">[22]</ref>.</p><p>Recently, DeepCT <ref type="bibr" target="#b9">[10]</ref> proposed a Gated Recurrent Unit (GRU) model treating description entries (from both LSIs and CRIs) as a sequence of signal to improve the incident triage process.</p><p>DeepTriage took the best practices from previous work in bug triage and incident triage, i.e. combining textual and contextual data, ensemble multiple approaches including deep neural network, and frequently retraining. While addressing the same incident triage problem, there are major differences between <ref type="bibr" target="#b9">[10]</ref> and our work: we do not only focus on deep neural network but ensemble it with other machine learning approaches and we shared lessons learned when deploying DeepTriage in a production environment. Lee et al. <ref type="bibr" target="#b19">[20]</ref> also reported a deployed bug triage system. However, they aimed to assist human to triage bugs, while we work on online services and follow a road map from assisting human to semi-automated and, eventually, fully-automated triage incidents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION &amp; FUTURE WORK</head><p>In this paper, we introduced DeepTriage, a novel machine learning service that improves the incident triage process by providing recommendations for the right team to mitigate an incident. The system has been deployed on an incident management system for Azure since 2017. We described how DeepTriage was implemented, scaled up, and how it assists on-call engineers at multiple levels from manual to automated. We did performance analysis on the ensemble model of the system and showed how the final prediction incrementally improved from its sub-models. Finally, we share the lessons learned in the development and deployment of DeepTriage.</p><p>In the future, we plan to introduce an auto routing service which automatically tracks incidents assigned to teams. If the auto routing service has a high confidence that the incident belongs to a different responsible team, it will transfer the incident to the correct team automatically. However, a fundamental challenge for this task is the performance@1. As a recommendation system, it does not impact users much when the correct team is one of the top 5 recommendations. However, for auto-routing, we need to improve performance@1 because no human will intervene and correct the choice for DeepTriage. Further, we will improve the DNN model of DeepTriage and experiment more state-of-the-art techniques from Deep Neural Networks such as Transformers to improve the accuracy of DeepTriage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Incident rerouting rate in different scenarios</figDesc><graphic url="image-1.png" coords="3,53.80,321.46,240.25,179.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The agile development model in cloud services require the development and deployment process being flexible and meeting certain production requirements in terms of execution time, or error tolerance to maintain high service availability.â€¢ Finally, introducing a new ML system into an existing workflow of engineers requires gaining their trust in adopting and getting feedback transfer actions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Venn diagram showing distribution of incidents containing command lines, queries, or stack traces (in percentage).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3. 4 . 5</head><label>45</label><figDesc>Deep Neural Network. In the latest iteration, we use deep neural networks (DNN ) with domain-specific textual and contextual encoding. Similar to previous work [10, 20], we use the state-ofthe-art Convolutional Neural Network (CNN) architecture for DNN (Figure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The Convolutional Neural Network architecture</figDesc><graphic url="image-2.png" coords="5,53.80,476.78,240.24,198.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Experimental results: ğ¹ 1 = 82.95% on all incidents and ğ¹ 1 in range 71.49% âˆ’ 91.15% in highly impacted incidents.LGBM(CRI) added 2% to 29% ğ¹ 1 improvement to scenarios related to CRIs upon MART. Adding InvertedIndex brought 11% to 21% ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› improvement for all incidents or high severity incidents. SI pushed improvements in all metrics, even with top 1 recommendation (ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›@1 had +23% in all incidents and +38% in high severity incidents). DNN lifted ğ¹ 1 in all incidents (+2.73%) and in high severity incidents (+3.04%) as well as top 1 recommendations, e.g. in all incidents ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›@1+2.41%, ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@1+1.12%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Distribution of incidents in the train set and test set.</figDesc><table><row><cell>Area</cell><cell cols="2">Train set Test set</cell></row><row><cell>Sev0-2</cell><cell>8.23%</cell><cell>7.07%</cell></row><row><cell>Min2Hop</cell><cell>1.24%</cell><cell>0.70%</cell></row><row><cell>CRI</cell><cell>3.01%</cell><cell>2.17%</cell></row><row><cell>Sev0-2@CoreServices</cell><cell>0.26%</cell><cell>0.33%</cell></row><row><cell>CRI(Sev0-2)@CoreServices</cell><cell>0.03%</cell><cell>0.03%</cell></row><row><cell>All</cell><cell cols="2">100.00% 100.00%</cell></row><row><cell cols="3">3.4.6 Ensemble model (DeepTriage). Taking all outputs from pre-</cell></row><row><cell>vious models (10 MART s + 3</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Due to the policy of Microsoft, we cannot disclose the actual number of incident reports in this paper.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Machine Learning at Microsoft with ML.NET</title>
		<author>
			<persName><forename type="first">Zeeshan</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Amizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogan</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Sheng</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yael</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Dupre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vadim</forename><surname>Eksarevskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Senja</forename><surname>Filipi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monte</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Inglis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Interlandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najeeb</forename><surname>Kazmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gleb</forename><surname>Krivosheev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pete</forename><surname>Luferenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Matantsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergiy</forename><surname>Matusevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahab</forename><surname>Moradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gani</forename><surname>Nazirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Ormont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gal</forename><surname>Oshri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artidoro</forename><surname>Pagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jignesh</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prabhat</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Zeeshan</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shauheen</forename><surname>Zahirazami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwen</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3292500.3330667</idno>
		<ptr target="https://doi.org/10.1145/3292500.3330667" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>Anchorage, AK, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2448" to="2458" />
		</imprint>
	</monogr>
	<note>KDD &apos;19)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Real Cost of Downtime, The Real Potential of DevOps. Retrieved</title>
		<author>
			<persName><surname>Appdynamics</surname></persName>
		</author>
		<ptr target="https://www.appdynamics.com/blog/engineering/idc-devops-cost-downtime" />
		<imprint>
			<date type="published" when="2015-02-13">2015. February 13. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Batch: Cloud-scale job scheduling and compute management</title>
		<ptr target="https://azure.microsoft.com/en-us/services/batch/" />
		<imprint>
			<date type="published" when="2020-02-13">2020. February 13. 2020</date>
			<publisher>Microsoft Azure</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Logic Apps: Quickly build powerful integration solutions</title>
		<ptr target="https://azure.microsoft.com/en-us/services/logic-apps/" />
		<imprint>
			<date type="published" when="2020-02-13">2020. February 13. 2020</date>
			<publisher>Microsoft Azure</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated, highly-accurate, bug assignment using machine learning and tossing graphs</title>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Neamtiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">R</forename><surname>Shelton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="2275" to="2292" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fingerprinting the datacenter: automated classification of performance crises</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bodik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moises</forename><surname>Goldszmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><forename type="middle">B</forename><surname>Woodard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans</forename><surname>Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European conference on Computer systems</title>
				<meeting>the 5th European conference on Computer systems</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="111" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SCOPE: easy and efficient parallel processing of massive data sets</title>
		<author>
			<persName><forename type="first">Ronnie</forename><surname>Chaiken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per-Ã…ke</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darren</forename><surname>Shakib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
				<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1265" to="1276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical investigation of incident triage for online service systems</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingnong</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Continuous incident triage for large-scale online service systems</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingnong</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th IEEE/ACM International Conference on Automated Software Engineering (ASE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="364" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Retain: An interpretable predictive model for healthcare using reverse time attention mechanism</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Taha</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Kulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3504" to="3512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Slice finder: Automated data slicing for model validation</title>
		<author>
			<persName><forename type="first">Yeounoh</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neoklis</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ki</forename><surname>Hyun Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">Euijong</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 35th International Conference on Data Engineering (ICDE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1550" to="1553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Correlating Instrumentation Data to System States: A Building Block for Automated Diagnosis and Control</title>
		<author>
			<persName><forename type="first">Ira</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moises</forename><surname>Goldszmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terence</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Symons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="16" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Capturing, indexing, clustering, and retrieving system history</title>
		<author>
			<persName><forename type="first">Ira</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moises</forename><surname>Goldszmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Symons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terence</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="105" to="118" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Public Cloud Soaring To $331B By 2022 According To Gartner</title>
		<ptr target="https://www.forbes.com/sites/louiscolumbus/2019/04/07/public-cloud-soaring-to-331b-by-2022-according-to-gartner" />
	</analytic>
	<monogr>
		<title level="j">Retrieved</title>
		<imprint>
			<date type="published" when="2019-02-13">2019. February 13. 2020</date>
		</imprint>
	</monogr>
	<note>Forbes</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Amazon&apos;s one hour of downtime on Prime Day may have cost it up to $100 million in lost sales</title>
		<ptr target="https://www.businessinsider.com/amazon-prime-day-website-issues-cost-it-millions-in-lost-sales-2018-7" />
	</analytic>
	<monogr>
		<title level="j">Business Insider</title>
		<imprint>
			<date type="published" when="2018-02-13">2018. February 13. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving bug triage with bug tossing graphs</title>
		<author>
			<persName><forename type="first">Gaeul</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering</title>
				<meeting>the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated bug assignment: Ensemble-based machine learning in large scale industrial contexts</title>
		<author>
			<persName><forename type="first">Leif</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Broman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Sandahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1533" to="1578" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note>Sigrid Eldh, and Per Runeson</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-normalizing neural networks</title>
		<author>
			<persName><forename type="first">GÃ¼nter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="971" to="980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Applying deep learning based automatic bug triager to industrial projects</title>
		<author>
			<persName><forename type="first">Sun-Ro</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Jae</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan-Gun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milhan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaeul</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering</title>
				<meeting>the 2017 11th Joint Meeting on Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="926" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Software analytics for incident management of online services: An experience report</title>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th IEEE/ACM International Conference on Automated Software Engineering (ASE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="475" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Experience report on applying software analytics in incident management of online service</title>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="905" to="941" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Assigning bug reports using a vocabulary-based expertise model of developers</title>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Matter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Nierstrasz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 6th IEEE international working conference on mining software repositories</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automatic bug triage using text categorization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><surname>Cubranic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth International Conference on Software Engineering &amp; Knowledge Engineering</title>
				<meeting>the Sixteenth International Conference on Software Engineering &amp; Knowledge Engineering</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ConfSeer: Leveraging Support Knowledge Bases for Automated Misconfiguration Detection</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Potharaju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luhui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Nita-Rotaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingshi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navendu</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
				<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1828" to="1839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Juggling the jigsaw: Towards automated problem inference from network trouble tickets</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Potharaju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navendu</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Nita-Rotaru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Presented as part of the 10th {USENIX} Symposium on Networked Systems Design and Implementation</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="127" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exponential family embeddings</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="478" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hoggles: Visualizing object detection features</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Tips for Modern NOCs -Alleviating Incident Routing Bottlenecks</title>
		<author>
			<persName><forename type="first">Maui</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="https://www.bigpanda.io/blog/tips-for-modern-nocs-alleviating-incident-routing-bottlenecks/" />
		<imprint>
			<date type="published" when="2019-02-13">2019. February 13. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bug Triaging Based on Tossing Sequence Modeling</title>
		<author>
			<persName><forename type="first">Sheng-Qu</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu-Sheng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="942" to="956" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Accurate developer recommendation for bug resolution</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 20th Working Conference on Reverse Engineering (WCRE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dretom: Developer recommendation based on topic models for bug resolution</title>
		<author>
			<persName><forename type="first">Xihao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th international conference on predictive models in software engineering</title>
				<meeting>the 8th international conference on predictive models in software engineering</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Detecting large-scale system problems by mining console logs</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles</title>
				<meeting>the ACM SIGOPS 22nd symposium on Operating systems principles</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="117" to="132" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
