<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Handwritten Digit Recognition: Applications of Neural Network Chips and Automatic Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Y</forename><surname>Le Cun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">B</forename><surname>Boser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
						</author>
						<author>
							<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Graf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
						</author>
						<title level="a" type="main">Handwritten Digit Recognition: Applications of Neural Network Chips and Automatic Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">273963D64B44860F25FDF08731B327E6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">HIS ARTICLE DESCRIBES TWO NEW METHODS</head><p>for achieving handwritten digit recognition. The task of handwritten digit recognition was chosen for investigation not only because it has considerable practical interest, but because it is relatively well-defined and is sufficiently complex to constitute a meaningful test of connectionist methods.</p><p>Simple classification techniques applied to pixel images do not provide high recognition rates because systems based on these techniques contain little prior knowledge about the topology of the task. Knowledge can be built into the system by changing the representation of a digit from a pixel image to a predefined feature description. The first of our methods implements this idea by performing feature extraction with a neural network chip. The feature representation can then be used by a relatively simple classifier, consisting of a two-layer network trained with back-propagat ion.</p><p>Finding the proper feature representation for a particular problem is a very complex task. To circumvent this, our second method incorporates sufficient knowledge of the task topology into the classifier so that it automatically generates an appropriate change of representation. This is done by using an adaptive network that has constraints on its architecture that capture the two-dimensional topology of the data. The network is trained on pixel images directly using the back-propagation algori t hm.</p><p>The first section describes the database and shows some examples. The following section discusses the first method based on a neural network chip that performs line-thinning and feature extraction using local template matching. The section after that discusses the second method, which is implemented on a digital signal processor. and makes extensive use of constrained automatic learning. Some concluding remarks are made in the final section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Database</head><p>A recurring problem in evaluating character recognition systems is the lack of a reliable measure of task difficulty. In particular. for digit recognition the performance of the system 0163-6804/89/0011-0041 $01 .OO ' 1989 IEEE is highly test-set dependent. A system may successfully recognize 997; of test data consisting of well-formed digits but score only 80% when confronted with the poorly-formed digits that are both routinely produced and easily recognized by people. We choose to perform our experiments on a rather difficult data set: isolated handwritten digits that were taken from postal zip codes. The zip code images were collected by the U.S. Postal Service from envelopes that passed through the Buffalo, N Y Post Office. .4 postal service contractor converted the original zip code images to binary images. and segmented the digits; that is, disaggregated them into five disjointed images. one for each digit of the zip code. The resulting database consists of 9.298 binary images of isolated digits. 7,29 1 of which are used as the training set, while the remaining 2,007 are used as the test set. Most of the images are fairly clean; however, a significant fraction are very blotchy or incomplete. The latter defect is quite common among "5s," in which the top horizontal stroke is often missing. It should be stressed that such mistakes in the segmentation are inevitable. High-level, contextual information is needed to perform a perfectly reliable segmentation on connected character sequences, and no such information is available at the early preprocessing stage without any feedback from the recognition stages.</p><p>In our laboratory. we performed some additional preprocessing to normalize the shape and the skew (tilt) of the digits <ref type="bibr">[2] [9]</ref>. We scaled the bit maps to fit into either a 32 x 32 or 16 x 16 pixel window. Typical scaled and "de-skewed'' examples taken from this data set are shown in Figure <ref type="figure" target="#fig_0">1</ref>. As can be seen. many of the digits are of poor quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digit Recognition Using a Neural Network Template Matching Chip</head><p>For our first attack on this problem [3], extensive preprocessing was done beyond the simple scaling and deskewing described above. The object here was to change the representation ofthe digit from a bit map to a feature map with the expectation that the classes will be more tightly clustered in a well constructed feature map than in a scaled bit map. The features were designed by hand on the basis of neurobiological models and stored on a general-purpose neural network chip, with the dual objectives of speeding a compute-intensive feature extraction process and demonstrating the utility of the chip. The back-propagation algorithm (see, for example, <ref type="bibr">[lo]</ref>) was used to train a network having feature maps as inputs and digit classes as outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Chip</head><p>The chip used for computing the feature map has been described extensively elsewhere [4]; here we will only outline its function. The chip stores 49 templates, each with 49 components. Binary input vectors, up to 49 bits long, are loaded on the chip and compared. in parallel, to each of the 49 stored templates. Comparisons between the input vectors and the stored templates are done by taking an analog dot product of the input with each template. The components ofthe templates can have relative values of 1 (excitation), 0 (don't care), or -2 (inhibition), and are set by the state of two static Random Access Memory (RAM) cells assigned to each template component. (The value -2 arises from differences in the conductance of the P and N channel load transistors.) The dot product for each template plus a programmable bias is then passed through a comparator circuit. When the dot product plus the bias is greater than 0, the comparator reports a " I " (match); otherwise, it reports a "0" (no match).</p><p>All signals and storage elements on the chip are accessed through an external eight-bit bus. This includes the 2,916 RAM cells used for storing templates, as well as the 49 input bits and 49 output bits. It is the external bus and its interface board to the host computer that limits the chip throughput. The chip itself simultaneously calculates the 49 dot products in less than one microsecond, but the experimental interface board can only pass input and output for this data in 20 microseconds.</p><p>In our application, the chip is basically used as an engine to perform parallel, thresholded convolutions. The templates represent the convolution kernels while the input vector is a local neighborhood of the processed image. The size of the neighborhood is either 5 x 5 pixels or 7 x 7 pixels, sequentially scanned through the image. Two sets of convolutions are done: the first is used to "skeletonize" the scaled digit image, and the second is used to extract key features in the skeletonized image to form feature maps. Both of these steps are described below.</p><p>In our application, the chip is basically used as an engine to perform parallel, thresholded convolutions.</p><p>For the low-accuracy dot products required in template matching. the advantage of the analog electronic circuits on our chip over digital circuits is that the analog circuits can be faster and more compact. This is because the summation in the dot product is computed "for free" just by adding the component currents in a summing wire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skeleton ization</head><p>The width of written line strokes for characters varies with character size, writing instrument, and writing style. To compensate for this variation, our 32 x 32 normalized image is processed by a skeletonization or line-thinning step <ref type="bibr">[3]</ref>. Although features can be extracted reliably for any particular width of lines, the width does not carry much information and a smaller number of features suffices to analyze the skeletonized images. The objective for a skeletonizer is to eat away pixels of the image until only a backbone of the character remains. Thus, broad strokes are reduced to skinny lines. This process is traditionally done by scanning a 3 x 3 window across the image, and then using table look-up to determine whether or not the middle pixel in the window ought to be deleted <ref type="bibr">[8]</ref>. The table is designed so that pixels that are crucial to maintaining connectivity are not deleted. With larger windows, such as 5 x 5, table look-up becomes impractical. However, larger windows offer the possibility of more clever skeletonization, which can be less noise sensitive and preserve straight edges. In our experiment, we used 5 x 5 windows to illustrate the potential of neural network hardware.</p><p>Skeletonization with our chip follows this procedure: a 5 x 5 pixel window is raster scanned across the image; the 25 bits representing the pixels in each window are compared to 20 25bit templates stored on the chip; each template tests for a particular condition that allows the deletion of the middle pixel in the window; if the match of the image data to any of the tem- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>plates exceeds a preset threshold, the center pixel is deleted.</p><p>Examples of some of the templates used for skeletonization are shown in Figure <ref type="figure" target="#fig_1">2</ref>; a) -d) shows typical templates used for thinning in the upper left of each box, e) shows a scaled binarized image, and f) shows the result after skeletonization using one pass with 20 templates. Black is excitation, grey is inhibition, and white is don't care. The pixels deleted by each template are shown in grey on the large image in each box. These templates were chosen in a systematic, but ad hoc, manner.</p><p>It should be noted that, although skeletonization is performed in a raster scan fashion, it can be performed entirely in parallel with a sufficient amount of special-purpose hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Extraction</head><p>In the feature extraction process, the skeletonized image is raster scanned with a 7 x 7 pixel window. The templates for feature extraction, which are loaded on the chip after skeletonization is complete, were inspired by results from experimental neurobiology <ref type="bibr">[5]</ref>, but their precise shapes were fine-tuned by hand <ref type="bibr">[3]</ref>, in part to conform to the constraints imposed by the chip. The templates check for the presence of oriented lines, oriented line end-stops, and arcs. Examples of some of the 49 templates are shown in Figure <ref type="figure">3</ref>.</p><p>Whenever a feature template match exceeds the preset threshold, a 1 (for the corresponding feature) is set in the map. Thus. there is a feature map for every template. Some of the templates search for the same feature, but on a different size scale. The maps for such features are logically "0R"ed together after the scan is completed.</p><p>The feature extraction process generates 49 32 x 32 maps from the 32 x 32 normalized image. Some of these maps are combined by logical operations to produce 18 32 x 32 feature maps. To reduce the amount of data, each feature map is coarse-blocked into a 3 x 5 array by simply "0R"ing neighboring bits in each feature map. The 18 3 x 5 feature maps make up a 270-bit vector which is used for digit classification. The coarse blocking also has the effect of building a fair amount of translation and rotation invariance into the processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification and Results of Chip-Based Systems</head><p>The back-propagation algorithm was used to train the final classification network. The network had 270 input units, corresponding to the coarse-blocked feature maps; 40 hidden units, fully connected to the input layer: and 10 output units, one for each digit class, fully connected to the hidden units. Thus, there were about 1 1.000 weights for the classification network. The raw generalization performance on the 2,007 test exam-Fig. <ref type="figure">3</ref>. Feature extraction process.</p><p>ples was around 94% and was obtained after about 15 learning passes through the training set.</p><p>In a realistic application, the user is less interested in the raw error rate than in the number of rejections necessary to reach a given level of accuracy. In our case, we measured the percentage of test patterns that must be rejected in order to get 1% error rate on the remaining test patterns.</p><p>Our rejection criterion was based on three conditions: the activity level of the most active output unit should be larger than a given threshold, t,; the activity level of the second most active unit should be smaller than a given threshold, t,; and finally, the difference between the activity levels of these two units should be larger than a given threshold, td ~ In a realistic application, the user is less interested in the raw error rate than in the number of rejections necessary to reach a given level of accuracy.</p><p>It should be emphasized, however, that the rejection thresholds were obtained using performance measures on the test set. Thus, we measure performance by setting output unit activation criteria, which must be attained in order to accept a classification. For activations below this level we reject the digit as unclassifiable. We find that to obtain a misclassification rate no higher than 1 y 4 we must reject 13% of the digits. We expect that a patient human could achieve the same error rate by rejecting about 5% of the digits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time Budget</head><p>As stated earlier, the chip has enough computing power to evaluate all the templates at one window location in one microsecond. Thus, a few milliseconds should be required for the skeletonization and feature extraction across the whole 32 x 32 image. Actual processing times were about two orders of magnitude slower. Although the chip-host interface costs an order of magnitude in throughput, the bottleneck in the process is the speed at which the host computer formats the pixelwindow data to be sent to the chip. The bottleneck and the input/output problem could be eliminated if the chip were incorporated into a special-purpose image processing system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Degrees of Freedom in the Network</head><p>We can interpret the combination of skeletonization, feature extraction, and classification as one huge feed-forward network. In that case, about 2 million connections must be evaluated to perform the three skeletonization passes and an additional 2 million are required for the feature extraction. Thus, 99.5q of the connection evaluations involve a "hand crafted" change of representation from bit maps to feature maps; the final classification requires only 0.5% of the connections. We note, however, that relatively few bits are required to specify the weights for the skeletonization and feature extraction. There are 25 skeletonization kernels of 25 coefficients each. Each coefficient has one of three values ( = 1.6 bits). Most of the kernels are rotations or reflections ofother kernels. Furthermore, most ofthe kernels have symmetry axes. We estimate that once these geometric constraints are imposed, about 150 bits are required to specify the skeletonization kernels, and by similar arguments, about 400 bits are required to specify the feature extraction kernels. Thus, the network of 4 million connections can be parametrized by only several hundred bits.</p><p>These arguments suggest that by imposing sufficient constraints on the weights in a multilayered network, high recognition accuracy might be achieved by learned convolution kernels. Such a network is discussed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digit Recognition Using Constrained Automatic Learning</head><p>The experiments described above suggest that a large network is probably needed to perform accurate digit recognition. If we were to design a large unconstrained network, it is very unlikely that it could be trained on a database even as large as ours with any hope of achieving good generalizing ability (i.e., good scores on the test data). In fact, we only expect the network to perform well if we include some of our knowledge about the problem into the network design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classical work in visual pattern recognition has demonstrated the advuntage of extracting local features and combining them to-form h igher-order features.</head><p>Classical work in visual pattern recognition has demonstrated the advantage of extracting local features and combining them to form higher-order features. Such knowledge can easily be built into the network by forcing the hidden units to combine only local sources of information. Le <ref type="bibr">Cun [7]</ref> has shown how to incorporate prior knowledge as constraints on the network weights during back-propagation learning. We know that the digit recognition task is a two-dimensional geometric problem, so we should incorporate this knowledge into the network design. One way this can be accomplished is by forcing the early layers in the network to perform twodimensional convolutions over the image. Following this approach, we designed the network shown in Figure <ref type="figure" target="#fig_2">4</ref>. This method is independent of the one in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Architecture</head><p>The input to the network is a 16 x 16 gray-scale image that is formed by normalizing the raw image. The image is grayscale rather than binary since a variable number of pixels in the raw image can fall into a given pixel in the normalized image. It should be emphasized that no further processing (such as skeletonization) was performed.</p><p>All of the connections in the network are adaptive, although heavily constrained, and are trained using back-propagation. This is in contrast with the chip-based method where the first few layers of connections were hand-chosen constants. The architecture is a direct extension of the one proposed in <ref type="bibr">[7]</ref>. In addition to the input and output layer, the network has three hidden layers, labeled H 1, H2, and H3, respectively. Connections entering H1 and H2 are local and heavily constrained.</p><p>H 1 is composed of 12 groups of 64 units arranged as 12 independent 8 x 8 feature maps. These twelve feature maps will be designated by H 1.1 through H 1.12. Each unit in a feature map takes input from a 5 x 5 neighborhood on the input plane. For units in layer H 1 that are one unit apart, their receptive fields (in the input layer) are two pixels apart. Thus, the input image is undersampled and some position information is eliminated in the process. A similar two-to-one undersampling occurs going from layer HI to H2.</p><p>This design is motivated by the consideration that high resolution may be needed to detect whether a feature of a certain shape appears in an image, while the exact position where that feature appears need not be determined with equally high precision. It is also known that the sort of features that are important at one place in the image are likely to be important in other places. Therefore, corresponding connections on each unit in a given feature map are constrained to have the same weights. In other words, all of the 64 units in H1.l use the same set of 25 weights. This is taken into account in the appropriate backpropagation formula. Each unit performs the same operation on corresponding parts of the image. The function performed by a feature map can thus be interpreted as a generalized convolution' with a 5 x 5 kernel.</p><p>Of course, units in another map (say H 1.4) share another set of 25 weights. It is worth mentioning that units do not share their biases (thresholds). Therefore, each unit has 25 input lines plus a bias. Connections extending past the boundaries of the input plane take their input from a virtual background plane whose state is equal to a constant, predetermined background level, in our case, -1. Thus, layer H I comprises 768 units (8 x 8 x 12), 19,968 connections (768 x 26), but only 1,068 free parameters (768 biases + 25 x 12 feature kernels), since many connections share the same weight.</p><p>Layer H2 is also composed of 12 features maps. Each feature map contains 16 units arranged in a 4 x 4 plane. As before, these feature maps will be designated H2.1 through H2.12. The connection scheme between H 1 and H2 is quite similar to the one between the input and H 1, but slightly more complicated because H 1 has multiple two-dimensional maps. Each unit in H2 combines local information coming from eight of the 12 different feature maps in HI. Its receptive field is composed of eight 5 x 5 neighborhoods centered around units that are at identical positions within each of the eight maps. Therefore, a unit in H2 has 200 inputs, 200 weights, and a bias. Ofcourse, all units in a given map are constrained to have identical weight vectors. The eight maps in H 1, on which a map in H2 takes its inputs, are chosen according to the following scheme: there are four maps in the first hidden layer (namely H 1.9 to H 1.12) that are connected to all maps in the next layer and are expected to compute coarsely-tuned features.</p><p>Connections between the remaining eight maps and H2 are as shown in the first eight rows of Table <ref type="table">I</ref>. The idea behind this Table <ref type="table">1</ref>. Connections between H1 and H2.</p><p>x x x x x x x x x x x x x x x x x x x x x x x x x scheme is to introduce a notion of functional contiguity between the eight maps. Because of this architecture, H2 units in consecutive maps receive similar error signals and are expected to perform similar operations. As in the case of H 1, connections falling off the boundaries of H2 maps take their input from a virtual plane whose state is constantly equal to 0. To summarize, layer H2 contains 1 92 units (1 2 x 4 x 4) and there is total of 38,592 connections between layers H 1 and H2 (1 92 units x 20 I input lines). All these connections are controlled by only 2,592 free parameters (12 feature maps x 200 weights + 192 biases).</p><p>Layer H3 has 30 units and is fully connected to H2. The number of connections between H2 and H3 is therefore 5,790 (30 x 192 + 30 biases). The output layer has 10 units and is also fully connected to H3, adding another 310 weights. In summary, the network has 1,256 units, 64,660 connections, and 9,760 independent parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup</head><p>All simulations were performed using the BP simulator SN [ I ] running on a SUN-4/260. Before training, the weights were initialized with random values using a uniform distribution between -2.4/F, and 2.4lF,, where F, is the number of inputs (fan-in) of the unit to which the connection belongs. The output cost function is the usual Mean Squared Error (MSE):</p><p>where P is the number of patterns, 0 is the number of output units, do,, is the desired state for output unit o when pattern p is presented on the input, and xop is the state of output unit o when pattern p is presented.</p><p>During each learning experiment, the patterns were presented in a constant order and the training set was presented 28 times. The weights were updated according to the so-called stochastic gradient or "on-line" procedure (updating after each presentation of a single pattern) as opposed to the "true" gradient procedure (averaging over the whole training set before updating the weights). Experiments show that the stochastic gradient converges significantly faster than the true gradient on highly redundant data sets such as ours. We used a variation of the back-propagation algorithm that computes a diagonal approximation to the Hessian matrix to optimally set the learning rate. This "pseudo-Newton'' procedure is not believed to bring a considerable increase in learning speed, but produces a reliable result without requiring extensive adjustments of the parameters <ref type="bibr">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The MSE on the test set reached a minimum after 23 learning passes through the training set. The network was then saved and retrained for 5 passes using a dataset that had undergone a slightly different preprocessing. The total number of training passes was therefore 28. The MSE was then 2.5 x on the training set and 1.8 x on the test set. The percentage of misclassified patterns was 0.14% on the training set ( 1 0 mistakes) and 5.0% on the test set (102 mistakes). The percentage of rejections would be 12.1% to achieve 1% error on what is left in the test set. To get to this point took three days on a SUN-4 workstation. Figure <ref type="figure" target="#fig_3">5</ref> shows learning curves for the error rate and the log MSE on the test and training set. Due to the highly redundant nature of the data, the best performance on the test set is obtained very quickly.</p><p>Figure <ref type="figure" target="#fig_4">6</ref> shows all 17 of the images in the test set that were misclassified by the network. In most cases there is a reasonable explanation, or at least an apology for the mistake. The main problem, accounting for six of the cases, is erroneous segmentation. Segmentation is a very difficult problem, especially when the characters overlap extensively. Improving the segmentation would greatly improve the overall performance of the system, but would require considerable effort. In four cases, the image is ambiguous even to humans. This contribution to the error rate obviously cannot be eliminated by any method. In three cases, the raw image is unambiguous, but the 16 x 16 image (at the input of the network) is ambiguous because of its low resolution. In two cases, the characters have an unusual style which is not represented in the training set; a modest increase in training set size should reduce the number of such failures. We have no good explanation for the two remaining cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digital Signal Processor Implementation</head><p>During the classification process, almost all of the computation time is spent performing multiply/accumulate operations. A Digital Signal Processor (DSP) is therefore a natural choice for implementing the neural network, because of its efficiency in performing multiply/accumulate operations. We used an off-the-shelf board that contains 256 kBytes of local memory and an AT&amp;T DSP-32C general-purpose DSP with a peak performance of 12.5 million multiply/add operations on 32-bit floating point numbers (25MFLOPS). The DSP operates as a coprocessor, the host is a Personal Computer (PC), which also contains a video acquisition board connected to a camera.</p><p>The PC digitizes an image and binarizes it using an adaptive thresholding technique. Next, the thresholded image is scanned and each connected component (or segment) is isolated. Components that are too small or too large are discarded.</p><p>Finally, the remaining components are sent to the DSP which performs the normalization (including deskewing) and classification steps.</p><p>The overall throughput of the digit recognizer, including image acquisition, is 10-12 classifications per second and is limited mainly by the normalization step. On normalized digits, the DSP performs more than 30 classifications per second.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In past years, much was learned about neural networks by studying small test problems. To make further progress, more can be learned by attacking large. real-world tasks, especially if the tasks have been attempted in the past with other methods. In particular, real applications contain the surprises and secrets of the natural world. Just as in other types of research and engineering, there are aspects of the system that would not appear in a idealized model, and must be discovered through experiments on real systems. We believe that our experiments on digit recognition, described in this article, uncover aspects of real data that cannot be inferred from small problems.</p><p>We have successfully applied neural network methods to a large, real-world task. Our results appear to be the state of the art in digit recognition. We demonstrated that a generalpurpose neural network chip can be incorporated as an accelerator in a large network. We found that real problems with regularity scale well.</p><p>We also showed that a network can be trained on a low-level representation of data that has minimal preprocessing (as opposed to elaborate feature extraction).</p><p>Perhaps the most important lesson is the importance of constrained adaptation. We used a complex network (capable of handling a complex problem) where many connections were specified by relatively few free parameters (which could therefore be determined from relatively small amounts of training data). The network architecture and the constraints on the weights were designed to incorporate geometric knowledge about the task into the system. Because of the redundant nature of the data and because of the constraints imposed on the network, the learning time was relatively short considering the size of the training set. Scaling properties were far better than one would expect just from extrapolating results of backpropagation on smaller, artificial problems.</p><p>The final network of connections and weights obtained by back-propagation learning was readily implementable on commercial digital signal-processing hardware. Throughput rates, from camera to classified image, of more than I O digits per second were obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>46</head><p>November 1989 -IEEE Communications Magazine </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Eiamples qf normalized data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Skeletonization process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Network architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Learning curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Misclassi,ficd images,</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>November 1989 -IEEE Communications Magazine</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>'Because of undersampling and non-linear saturating unit functions, the total effect cannot be expressed as a convolution in the strict sense, although the spirit is the same.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the U.S. Postal Service and its con-The neural network simulator SN is the result of a collabo-tractors for providing us with the database. ration between Leon-Yves Bottou and Yann Le Cun.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SN: A Simulator for Connectionist Models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Le Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeuroNimes &apos;88</title>
		<meeting>of NeuroNimes &apos;88<address><addrLine>Nimes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Moment Normalization of Handprinted Characters</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Casey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. of Res. and Dev</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="548" to="557" />
			<date type="published" when="1970-09">Sept. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural Network Recognizer for Handwritten Zip Code Digits</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Touretzky</surname></persName>
		</editor>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="323" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A CMOS Associative Memory Chip</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>De Vegvar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 1st lnt7 Conf on Neural Networks</title>
		<meeting>IEEE 1st lnt7 Conf on Neural Networks<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">Ill</biblScope>
			<biblScope unit="page" from="461" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Receptive Fields, Binocular Interaction and Functional Architecture in the Cat&apos;s Visual Cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modeles Connexionnistes de I&apos; Apprentissage</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>Universite Pierre et Marie Curie</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generalization and Network Design Strategies</title>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Cun</surname></persName>
		</author>
		<editor>Perspective, R. Pfeifer, Z. Schreter, F. Fogelman, and L Steels</editor>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>North Holland</publisher>
			<biblScope unit="page" from="143" to="155" />
			<pubPlace>Zurich, Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SPTA: A Proposed AlgorithmforThinning Binary Patterns</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Naccache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shingal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, and Cybernetics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Some Studies in the Interactive Design of Character Recognition Systems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Naylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">/€€E Transaction on Computers</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="075" />
			<date type="published" when="1971-09">Sept. 1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning Internal Representations By Error Propagation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Bradford Books</publisher>
			<date type="published" when="1962">1986. 1962</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="106" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Biography The Holmdel Neural Network Group of AT&amp;T Bell Laboratories was founded in 1984 by</title>
		<author>
			<persName><forename type="first">E</forename><surname>Smc-14 ; Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Howard ; Lawrence</surname></persName>
		</author>
		<author>
			<persName><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Both Mr. Howard and Mr. Jackel have Ph.D.s in physics and recent experience in superconductivity, microscience, and microfabrication. Current members of the group are: Bernhard E. Boser: received an electrical engineering diploma from E.T.H. in Zurich and an electrical engineering Ph.D. from Stanford University; John S</title>
		<imprint>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="409" to="418" />
		</imprint>
	</monogr>
	<note>Head of the Microelectronics Research Department. Denker: received a B.S. degree from the California Institute of Technology and a Ph.D. in physics from Cornell University</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Wayne Hubbard: received an electrical engineering degree; Don Henderson: received a B.S. degree in</title>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">E T H</forename><surname>Zurich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Science from Monmouth College; Lawrence D. Jackel: received a B.A. degree in physics from Brandeis University and a Ph.D. from Cornell University; Yann Le Cun: received an electrical engineering diploma from E.S.I.E.E. in Paris and a computer science Ph.D. from the University of Paris VI</title>
		<imprint/>
		<respStmt>
			<orgName>University of Paris VI</orgName>
		</respStmt>
	</monogr>
	<note>Isabelle Guyon: received an engineering diploma from E.S.P.C.I. in Paris and a physical sciences Ph.D. from the</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<title level="m">received a B.S.C. degree in physics from the California Institute of Technology and a Ph.D. in applied physics from Stanford University</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
