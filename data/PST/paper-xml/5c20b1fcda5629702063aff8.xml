<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">STRAIGHT: Hazardless Processor Architecture Without Register Renaming</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hidetsugu</forename><surname>Irie</surname></persName>
							<email>irie@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Toru</forename><surname>Koizumi</surname></persName>
							<email>koizumi@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Akifumi</forename><surname>Fukuda</surname></persName>
							<email>a.fukuda@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seiya</forename><surname>Akaki</surname></persName>
							<email>akaki@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Satoshi</forename><surname>Nakae</surname></persName>
							<email>nakae@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yutaro</forename><surname>Bessho</surname></persName>
							<email>bessho@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ryota</forename><surname>Shioya</surname></persName>
							<email>shioya@ci.i.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Takahiro</forename><surname>Notsu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">FUJITSU LABORATORIES LTD</orgName>
								<address>
									<settlement>Kawasaki</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Katsuhiro</forename><surname>Yoda</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">FUJITSU LABORATORIES LTD</orgName>
								<address>
									<settlement>Kawasaki</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Teruo</forename><surname>Ishihara</surname></persName>
							<email>ishihara@jp.fujitsu.com</email>
							<affiliation key="aff1">
								<orgName type="institution">FUJITSU LABORATORIES LTD</orgName>
								<address>
									<settlement>Kawasaki</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuichi</forename><surname>Sakai</surname></persName>
							<email>sakai@mtl.t.u-tokyo.ac.jp</email>
							<affiliation key="aff2">
								<orgName type="institution">The University of Tokyo Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">STRAIGHT: Hazardless Processor Architecture Without Register Renaming</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/MICRO.2018.00019</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>microprocessor</term>
					<term>instruction-level-parallelism</term>
					<term>out-of-order execution</term>
					<term>register renaming</term>
					<term>computer architecture</term>
					<term>compiler</term>
					<term>power efficiency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The single-thread performance of a processor improves the capability of the entire system by reducing the critical path latency of programs. Typically, conventional superscalar processors improve this performance by introducing out-oforder (OoO) execution with register renaming. However, it is also known to increase the complexity and affect the power efficiency. This paper realizes a novel computer architecture called "STRAIGHT" to resolve this dilemma. The key feature is a unique instruction format in which the source operand is given based on the distance from the producer instruction. By leveraging this format, register renaming is completely removed from the pipeline. This paper presents the practical Instruction Set Architecture (ISA) design, the novel efficient OoO microarchitecture, and the compilation algorithm for the STRAIGHT machine code. Because the ISA has sequential execution semantics, as in general CPUs, and is provided with a compiler, programming for the architecture is as easy as that of conventional CPUs. A compiler, an assembler, a linker, and a cycle-accurate simulator are developed to measure the performance. Moreover, an RTL description of STRAIGHT is developed to estimate the power reduction. The evaluation using standard benchmarks shows that the performance of STRAIGHT is 18.8% better than the conventional superscalar processor of the same issue-width and instruction window size. This improvement is achieved by STRAIGHT's rapid miss-recovery. Compilation technology for resolving the possible overhead of the ISA is also revealed. The RTL power analysis shows that the architecture reduces the power consumption by removing the power for renaming. The revealed performance and efficiencies support that STRAIGHT is a novel viable alternative for designing general purpose OoO processors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In response to the trends in semiconductor technology, processor architecture has been continually evolving to achieve This research was partially supported by JSPS KAKENHI Grant Number 25730028, and 16H05855. Also, this research was partially supported by VLSI Design and Education Center(VDEC), The University of Tokyo with the collaboration with Synopsys Corporation and Mentor Graphics Corporation. higher performance, more functions, and higher power efficiency. Currently, for the wide range of purpose from embedded processors to server processors, the heterogeneous multicore architecture <ref type="bibr" target="#b0">[1]</ref> is adopted, which typically implements various types and various scales of cores into a chip; the most efficient cores among them are in charge for each application depending on its characteristics. This strategy trades off energy efficiency against lower-utilized cores, reflecting the recent dilemma that even though the number of transistors can be increased, they cannot be switched simultaneously <ref type="bibr" target="#b1">[2]</ref>. In this scenario, the CPU is expected to effectively execute the programs that are not parallelized or cannot be parallelized by the programmer. Because they are often critical paths that require the longest execution time among the ongoing tasks, speeding up a single-thread execution is essential to improve the total system performance.</p><p>Currently, a big superscalar core is inevitably accepted as the most powerful and the only feasible architecture to gain this performance. Provided with an out-of-order (OoO) mechanism and a number of predictors, the sophisticated superscalar core can exploit the underlying instruction-level parallelism (ILP) in a thread relatively well. However, a further increase in its performance is challenging because the power of indirect operation increases with the scale of the core, which is critical in today's limited power budgets. Therefore, the recent improvement in single-thread performance is relatively modest compared to those of GPUs and TLP technologies, which demonstrate a performance increase that is proportional to the increase in the number of transistors employed <ref type="bibr">[3] [4]</ref>.</p><p>This paper realizes a novel OoO execution architecture that reduces the amount of indirect operations per instruction. The key idea is that the unique instruction set architecture (ISA) is adopted to skip register renaming. The ISA guarantees that each logical register will be written only once and then discarded in a fixed period. As the paper elaborates later, this rule renders register renaming unnecessary, thus resulting in a simple OoO execution structure as well as a scalable instruction window for exploiting much larger ILP with simple hardware. The architecture is called "STRAIGHT" because it executes each instruction directly without renaming its operands. The architecture actually requires the ISA to be changed; however, the code is easily translated from the staticsingle-assignment (SSA) form <ref type="bibr" target="#b4">[5]</ref>  <ref type="bibr" target="#b5">[6]</ref> intermediate language, which is recently dominant for compiler infrastructures such that the viability is not compromised.</p><p>A cycle-accurate simulation environment and a registertransfer level (RTL) description of STRAIGHT are developed to the evaluation. Also, those environment of OoO RISC-V are developed as a superscalar counterpart. The evaluation result demonstrates that STRAIGHT improves the singlethread performance and reduces the power consumption, both of which are derived from the simpler hardware organization that is enabled by the ISA.</p><p>The concept of the ISA to eliminate register renaming is presented herein <ref type="bibr" target="#b6">[7]</ref>; however, the method to realize the microarchitecture and the compiler of the architecture that can execute any kind of general-purpose programs has not been revealed. By presenting the essential hardware and software technologies, the contribution of this paper are as follows:</p><p>? The practical STRAIGHT ISA is built to write application programs. The ISA feature is that the source operands are given by the distance from the producer instruction. ? The microarchitecture that receives STRAIGHT ISA is realized. We show that this approach completely removes register renaming from the OoO core. This means that the major hotspots and critical paths are eliminated from the front-end pipeline. Furthermore, the simplified architecture achieves the rapid miss-recovery as well as the further reorder buffer (ROB) scalability. ? The compilation algorithm that generates STRAIGHT machine code from the LLVM <ref type="bibr" target="#b7">[8]</ref> intermediate representation (IR) is developed. Padding with simple register move (RMOV) instructions, we show that most operands can be converted to the statically determined distances and the remainder can also be represented using the SPADD instruction. ? A cycle-accurate simulator that faithfully models the pipeline stages of STRAIGHT is developed for the performance evaluation. The compiled code of standard benchmarks (Dhrystone, Coremark) is used. The result shows that STRAIGHT achieves 18.8% better performance than modern OoO superscalar processors while requiring a simpler hardware. STRAIGHT's lower misspenalty enhances the performance. The restriction of STRAIGHT ISA can deteriorate the performance with increasing redundant RMOV instructions; however, most of them are eliminated algorithmically by the compiler. ? The power efficiency is confirmed through RTL power analysis. In-house RTL descriptions of STRAIGHT is prepared. Comparative evaluation reveals that STRAIGHT removes the power of register renaming and improves the entire efficiency of the processor.</p><p>The remainder of this paper is organized as follows: Section II describes the motivation and the basic concept of the STRAIGHT architecture. Section III presents the details of both the ISA and the microarchitecture. Section IV presents the compiler algorithm to generate the STRAIGHT machine code. Section V shows the evaluation settings, followed by section VI, which presents the evaluation results. Section VII discusses the related works, and the paper is concluded in section VIII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MOTIVATION A. Advantages and Disadvantages of Register Renaming</head><p>To enhance the single-thread performance, register renaming is critical in exploiting the additional ILP by solving the false dependency hazard dynamically. In the front-end pipeline, register renaming is applied to every instruction. It converts all operand identifiers from logical register numbers to physical register numbers that indicate the addresses in the internal register file. This operation is implemented by multiple references to the table composed of RAM or CAM that is called the register mapping table (RMT) or the register alias table (RAT).</p><p>In the RAM-based RMT, which has as many rows as the number of logical registers, the RMT stores the corresponding physical register number using the logical register number as an index. The mechanism also has a circular FIFO called freelist that holds all the physical register numbers that do not correspond to any logical register at that time. The operation for each instruction is as follows: i) The RMT is accessed with source register numbers, and source physical register numbers are obtained. The RMT is accessed simultaneously with the destination register number, and the previous dedicated physical register number is obtained for the recovery and retire operation. ii) A physical register number is provided from the head of the free-list, and sent to the next pipeline stage as the destination physical register number. The RMT is simultaneously updated by writing this physical register number. Through these operations, the code is now able to exploit much greater parallelism.</p><p>However, register renaming is reported to be one of the hotspots in terms of both power density and power consumption <ref type="bibr" target="#b8">[9]</ref> [10] <ref type="bibr" target="#b10">[11]</ref>  <ref type="bibr" target="#b11">[12]</ref>. It lowers the efficiency of the OoO CPU cores, with the result that a large fraction of energy is consumed by RMT accesses that are not essential for the execution. Each instruction requires three reads and one write in a cycle, and the required number of read/write ports is multiplied by the number of fetch width, which renders the RMT one of the most multiported tables in the processor. This multiported access also affects the clock frequency because unless the RMT updates are completed, the renaming of the next fetch group cannot start <ref type="bibr" target="#b12">[13]</ref>.</p><p>Moreover, the scalability of the instruction window whose size determines the amount of exploitable ILP is also disturbed by register renaming. The instruction window size is directly related to the ROB, in which all in-flight instructions from the dispatch stage to the retire stage are queued. However, the size of ROB proportionally increases the branch miss-penalty.</p><p>When a mispredicted branch instruction is detected, the RMT must be restored by walking the ROB from the tail (or from the head, depending on the implementation) to the corresponding branch instruction. The penalty is reported as several tens of cycles with the 256-entry ROB on average, which considerably affects the performance <ref type="bibr" target="#b13">[14]</ref>.</p><p>To be exact, a CAM-based RMT can avoid this penalty at the expense of a large amount of RMT checkpoints. However, it still disturbs the ROB scalability because the CAM-based RMT cannot increase the number of physical registers. If the number of physical registers are not sufficient for the number of ROB entries, the stall due to the shortage of free physical registers increases. Although register renaming provides an important contribution to the acceleration of single-thread execution, it also introduces design limitations, that causes the slow progress in core performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. STRAIGHT Architecture Concept</head><p>Instead of managing the physical registers dynamically, the STRAIGHT concept has been presented to solve the false dependency hazard by the compiler, which eliminates register overwrites <ref type="bibr" target="#b6">[7]</ref>. Because the number of registers is finite, each register is freed after a fixed period such that the program length is not limited. To write the looped code without overwrites, a technique is introduced. Register numbers are indicated relatively by the dynamic instruction distance. In the architecture, fetched instructions can be directly dispatched to the scheduler. Not managed by any mapping table, the register file can be built as a simple key-value store that is easy to scale. However, realizing the computer for this novel instruction format involves a number of challenges. Because of the unique operand format, the practical ISA that can write the real application has to be newly constructed. Especially, its viability significantly owes to the code generation, nevertheless, to develop the compiler for this instruction format is a novel challenge. Moreover, in previous STRAIGHT concept, the scalability has been prioritized and the large hardware that is provided with thousands of registers are assumed, which limits its use to the desktop or sever processors.</p><p>Hereafter in this paper, we realize and evaluate STRAIGHT processor by resolving the challenges above. Also We design STRAIGHT microarchitecture as small as conventional mobile processors, which increases the opportunities to be utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EFFICIENT STRAIGHT PROCESSOR CORE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Specifying STRAIGHT ISA</head><p>The developed STRAIGHT instruction set is a collection of simple operations similar to the typical RISC architectures. As in conventional OoO superscalar architectures, it provides a sequential execution model and precise interrupts to the programmer.</p><p>Figure <ref type="figure" target="#fig_0">1</ref>(a) shows a simple example of the STRAIGHT code. Each instruction performs an ordinary operation, but its operands are given by the distance from the instruction that produces the source value. For example, " <ref type="bibr" target="#b0">[1]</ref>" of instruction  I 2 means that the instruction uses the result value of the previous instruction, and " <ref type="bibr" target="#b1">[2]</ref>" means that the other operand is the result value of the second previous instruction. Therefore, this code calculates a Fibonacci series as long as the "ADD <ref type="bibr" target="#b0">[1]</ref> [2]" instruction is repeated. It is noteworthy that an operand is represented as the distance in a control flow. Therefore, it differs from the distance in the static order when a code contains nonsequential program counter (PC) transitions such as jump instructions.</p><p>Based on the above concept, we defined the bit-field format of the STRAIGHT instruction set architecture as shown in figure <ref type="figure" target="#fig_0">1(b)</ref>. Because an instruction does not specify the destination register identifier, each identifier for the source operands can use a larger field. A source operand field can span up to 10 bits, which means that the results of the last 2 10 -1 = 1023 instructions can be referenced. Here, "[0]" is decoded as a zero register. Store (ST) instructions need not make the register output, but to make the distance calculation simple, each instruction occupies one destination register. If it is referred, store value is returned in the current specification. This unique representation contains some characteristics of the dataflow, and satisfies the following restrictions corresponding to the STRAIGHT concept. First, it guarantees the write-once usage of each register. A register is identified by the fetch order of the instruction, with the result that any two instructions never share the same destination. Next, because the operand is identified by the distance in the control flow path, the lifetime of each register is determined by the maximum distance (e.g., 1023 instructions). The value will be never referenced after the succeeding 1023 instructions are executed.</p><p>STRAIGHT requires an additional architectural register, "stack pointer (SP)." This is the only overwritable register, and it guarantees that any complicated algorithm can be written at the least using SP as a memory pointer. We find that adding one instruction, "SPADD" to the instruction set is sufficient to SP-related operations, which reads and modifies the SP by adding the given immediate value as well as writing this result to its destination register. The succeeding load and store instructions can use the SP value by indicating the distance from the SPADD instruction. As described in the compiler section below, the SPADD is utilized to compile the complicated control flows such as function calls. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Realizing Scalable OoO Execution</head><p>The pipeline organization of STRAIGHT is designed as shown in figure <ref type="figure">2</ref>. As the operations of the instruction set are similar to those of conventional RISC architectures, most of the pipelines are also composed of conventional mechanisms. The major differences are in the following mechanisms: the mechanism in the front-end pipeline that determines the operand register number and the retire/recovery mechanism, which is related to the ROB.</p><p>First, the detailed mechanism of the operand determination is shown in figure <ref type="figure">3</ref>. This operation corresponds to the RMT accesses for conventional OoO superscalar processors. To obtain the physical source register numbers from the source distances given by an instruction, a special register, register pointer (RP), is introduced in the hardware. Incremented for each instruction, the RP value provides the destination register number, and the source register numbers are obtained by subtracting the distance from RP. As shown in figure <ref type="figure">3</ref>, multiple instructions in a fetch group can be operated in parallel because the RP value for each instruction is rigidly determined regardless of the operation of the preceding instruction. Therefore, the fetch width can extend as far as it is effective. The RP value returns to zero when it exceeds its maximum value MAX RP.</p><p>Figure <ref type="figure">3</ref> also shows the mechanism related to SP. SP is the only overwritable register and is operated by only the SPADD instruction. As we designed the SPADD instructions to require only an immediate operand, the instruction can update the SP in order at the decode stage. Subsequently, the SPADD instruction writes the copied SP value to its destination register, which can be performed in the OoO manner. Guaranteeing multiple SPADDs in a fetch group requires the cascaded SPADD calculations in a cycle, which possibly affect the clock frequency. The number of SPADD instructions in a fetch group can be restricted by stalling and the performance Next, the retire/recovery mechanism is shown in figure <ref type="figure">4</ref>. Composed of a circular FIFO structure, the ROB maintains the information about each in-flight instruction. One entry maintains the part of the architecture state that will be changed by the corresponding instruction. In STRAIGHT, the RP and the PC of the instruction and the SP value at its decode time are sufficient for an entry. Unlike the conventional architecture, the retire operation only removes the completed instructions in order from the head of the ROB unless the instruction causes the exception or miss-recovery.</p><p>To reduce the hardware, each entry of the ROB does not have to maintain the relevant RP. Only if the RP copy corresponding to the ROB head is maintained, can the rest be derived from the entry position. In addition, storing the SP value for each ROB entry is also redundant because the SP updates are very rare. Providing a small table and maintaining pointers for it in the ROB saves significant ROB capacity.</p><p>The recovery operation from the branch misprediction or other speculation is extremely simple compared to typical superscalar architectures. Only one ROB entry read is sufficient. By using the destination register number of the oldest instruction in the discarded path as a key, the SP and PC (that is obtained by the execution result for branch misprediction recovery) for the restart are obtained from the ROB. That register number is also used for RP restoration. No ROB updates are required except the tail pointer movement. This operation is sufficient to ensure that the microarchitectural changes generated by the mispredicted instructions will be overwritten eventually by the restarted correct path execution. Although not mandatory, to save the power consumed by invalid instructions, a partial flush of the scheduler, pipelined functional units, and the load-store queue can be performed using the corresponding RP value.</p><p>MAX RP physical registers are sufficient to avoid unexpected physical register aliasing because the register number never exceeds that value. Here, one should consider deriving the value of MAX RP to save the register values from the unexpected overwrites. When instruction k that uses k as the destination register number is about to retire, the value of register (kthe maximum distance) must still be maintained. Therefore, the corresponding number must not appear in RP before the retirement of instruction k. Nevertheless, at that time the youngest in-flight instruction receives the register number (k + the number of ROB entries). Thus, MAX RP is given by (the maximum distance + the number of ROB entries).</p><p>As shown, STRAIGHT improves the efficiency of the OoO execution by removing register renaming. Moreover, because it eliminates the ROB walking penalty, STRAIGHT enables the instruction window to be further increased. By eliminating hotspots caused by register renaming, STRAIGHT can operate at the same or higher frequency compared to the conventional OoO superscalar processor with the same issue width and the same number of functional units. Nevertheless, the architecture does not prevent configuring the small efficient core. The number of the physical register required is determined by the ROB size and the maximum distance, therefore smaller core can be configured by shrinking those values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. STRAIGHT COMPILER TECHNOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Compilation Flow of STRAIGHT Compiler</head><p>The STRAIGHT compiler generates the STRAIGHT assembly where every source register is expressed as a distance. In this section, we explain that any program is converted into the STRAIGHT assembly correctly. We adopted LLVM IR as the input of the STRAIGHT compiler. The advantage of adopting it is that LLVM IR is an SSA-formed IR. Every destination register in the SSA-formed IR is not overwritten statically and this manner is similar to the register management of STRAIGHT.</p><p>In the STRAIGHT architecture, every distance is calculated by the number of in-order instructions between the producer and consumer on the execution path. However, if any control flow merges in the control statements including the if-and while-statements, the distance in each path can differ. In this case, the STRAIGHT compiler adds instructions such that the distance is fixed, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Calling Convention</head><p>Basically, the STRAIGHT architecture stores arguments and returns values in registers. Instructions that generate those values are arranged in a fixed order defined by the function, as shown in Figure <ref type="figure" target="#fig_2">5</ref>. In this manner, any caller can pass and receive the variables. For example, Figure <ref type="figure">6</ref> shows how arguments and return values are passed. In this example, the calling convention is to place the producer of argument arg1 just prior to the jump-and-link (JAL) instruction and place the producer of arg0 just before it. As long as callers satisfy this convention, distances between an instruction in the callee to producers of the argument are fixed regardless of which JAL instruction is invoked. In the example, the instruction ADD <ref type="bibr" target="#b3">[4]</ref>  <ref type="bibr" target="#b2">[3]</ref> in the callee always refers arg0 and arg1.</p><p>The return address is passed to the callee by the JAL instruction that writes its PC+4 to its destination register. The jump register (JR) instruction in the callee refers the JAL instruction by the distance, which realizes the return operation. Variable arguments such as printf in C language requires are passed via stack frame. Calling conventions for System calls are defined in a similar manner. Functions can be defined to return one or multiple values by defining the distances between the JR instruction and producers of return values. For example, the ADDi [3] 1 instruction following the JR instruction calculates retval0 plus 1.</p><p>If the producer instructions cannot be arranged as the convention, the register move (RMOV) instructions are used instead. RMOV copies its source register value into its destination register, such that it can arrange the order of the produced values.</p><p>Alive variables are stored in the stack frame using the SP before the function call. The SP is incremented or decremented by the SPADD instruction. SPADD instructions are generated at the entrance and the exit of the function. LD and ST instructions can access the stack frame by referring the relevant SPADD instruction because SPADD writes the updated value of SP into its destination register.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Code Generation</head><p>1) Operation Translation: Figure <ref type="figure">7</ref> shows the compilation flow. The compilation process consists of three steps. First, 2) Distance Fixing on Merging Flow: Here, the STRAIGHT compiler adjusts distances from a consumer instruction to producer instructions to the same length regardless of the control flow. Any control flow is classified as either branching or merging. Figure <ref type="figure" target="#fig_4">8(a)</ref> shows that the distances to the producer instruction are always fixed in the case of branch. However, distances can differ in the case of merge, as shown in Figure <ref type="figure" target="#fig_4">8(b)</ref>. In this case, the STRAIGHT compiler adds RMOVs at the tail of each merging basic block to fix the distance basically, as shown in Figure <ref type="figure" target="#fig_4">8(c)</ref>.</p><p>These RMOVs are added by using the following algorithm. First, the STRAIGHT compiler obtains the information on all possible producers and corresponding merging basic blocks from PHI instructions in LLVM IR. A PHI instruction is appeared when a operand has multiple producer candidates. A distance also varies when there are multiple paths from one producer instruction to its consumer. The information of such producers and merging basic blocks is obtained by liveness analysis as well.</p><p>RMOVs are added at the tail of such merging basic blocks to fix the distance regardless of the control flow. This process is repeated as many times as the number of live variables. RMOVs are stacked up on the tail of merging basic blocks NOPs are also added to eliminate the distance differences that are caused when there are fall-through paths. Although these RMOVs appear to be redundant, the optimization described later can reduce them. Figure <ref type="figure">9</ref> shows an example of the fixed distances of the counter variable in the loop statement. The counter variable is initialized in the BB0 (ADDi [0] 0) and incremented before the conditional statement in the BB2 (ADDi [4] 1). The SLT at the head of the BB1 take the counter variable as its source operand. There are two paths to this operand: from the BB0 and the BB2. The operand of SLTi is fixed as <ref type="bibr" target="#b1">[2]</ref> by adding RMOVs.</p><p>3) Distance Bounding: The STRAIGHT architecture has the maximum distance of source registers. Therefore, the STRAIGHT compiler adds RMOVs that relay the values when any distance exceeds the maximum. Each RMOV is added in the possible maximum distance from the consumer avoiding the added RMOVs. The STRAIGHT compiler repeats this process until every distance is equal to or less than the maximum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Optimization specific to STRAIGHT</head><p>Thus far, the method that convert any program to the STRAIGHT code that satisfies the requirement of the architecture is described. Furthermore, in addition to the basic STRAIGHT code generation, the compiler can optimize the code from the aspect of its specific register management.</p><p>We designed the redundancy elimination that reduces RMOVs of which example is shown in the figure <ref type="figure" target="#fig_5">10</ref>. (a), (b), and (c) are lists of STRAIGHT code that are compiled from the source code above with the different optimization level. Here, "%%" in the list is a pseudo code which generates the indicated variables.</p><p>In the basic compilation algorithm, RMOVs are generated proportionally to the number of live variables that are read</p><formula xml:id="formula_0">ADDi [0] 0 BB0 BB1 BB3 RMOV [1] BB2 NOP BEZ ADDi [4] 1 SLTi [2] 100</formula><p>RMOV <ref type="bibr" target="#b0">[1]</ref> J BB1 Fig. <ref type="figure">9</ref>. Distance fixing of loop-statement through the merging flows. For example, the loop body in the figure <ref type="figure" target="#fig_5">10</ref>(a) contains four RMOVs out of ten instructions. The instructions only for fixing the distance occupy most of the loops, which causes the performance degradation. However, the distances can be fixed without adding RMOVs by rearranging the producer instructions in most cases. In the example of the figure10(b), two ADDi instructions can place instead of RMOVs because their result are not used within the iteration. Now those instructions generate values and adjust distances at the same time. The number of RMOVs is reduced to two out of eight instructions.</p><p>The figure 10(c) shows the other method to remove the RMOV instruction. In the example, the return address "_RETADDR" is stored in the stack frame and loaded after the loop completion. In fact, the variable is never used during the loop execution, therefore the corresponding RMOV only relays the variable. Storing such variables in the stack frame can reduces all RMOVs that only relay the variables. Now the loop contains only one RMOV out of seven instructions. Generally, in cases where the variables are not read in the near future, this method is effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EVALUATION METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulated Models</head><p>STRAIGHT is a novel architecture that has different instruction sets and execution pipelines. To confirm its feasibility for executing application programs, we developed an in-house cycle-accurate simulation environment. A compiler, an assembler, a linker, and a cycle-accurate simulator are developed. The simulator faithfully models all pipeline stages of STRAIGHT, involving OoO scheduling, branch prediction, memory dependency prediction, a load-store queue (LSQ) for memory disambiguation, cache hit/miss prediction, the scheduler replay, a stream prefetcher for data caches, and the mechanisms for the misprediction recovery.</p><p>We also compared STRAIGHT to the conventional superscalar to reveal whether this architecture improves the performance and efficiency. An in-house cycle-accurate simulator of RISC-V (RV32IM) is also developed as a superscalar counterpart. The RAM based ROB is assumed in the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STRAIGHT code void iota( int arr[], int N ) { int i;</head><p>for( i = 0; i &lt; N; ++i ) { arr[i] = i; } } %% arg0 : arr %% arg1 : N %% ?RETADDR Function?iota : ADDi $ZERO, 0 # i = 0 RMOV <ref type="bibr" target="#b3">[4]</ref> # &amp;arr[0] RMOV <ref type="bibr" target="#b3">[4]</ref> # N RMOV <ref type="bibr" target="#b3">[4]</ref> # ?RETADDR RMOV <ref type="bibr" target="#b3">[4]</ref> # i NOP Label?for?cond :</p><formula xml:id="formula_1">SLT [2] [4] BEZ [1] Label?for?end ST [4] [7] ADDi [5] 1 # ++i ADDi [9] 4 # &amp;arr[i]</formula><p>RMOV <ref type="bibr" target="#b0">[1]</ref> # &amp;arr[i] RMOV <ref type="bibr" target="#b9">[10]</ref> # N RMOV <ref type="bibr" target="#b9">[10]</ref> # ?RETADDR RMOV <ref type="bibr" target="#b4">[5]</ref> # i J Label?for?cond Label?for?end : JR <ref type="bibr" target="#b4">[5]</ref> %% arg0 : arr %% arg1 : N %% ?RETADDR Function?iota :</p><formula xml:id="formula_2">ADDi $ZERO 0 # i = 0 NOP Label?for?cond : SLT [2] [4] BEZ [1] Label?for?end ST [4] [7] ADDi [8] 4 # &amp;arr[i]</formula><p>RMOV <ref type="bibr" target="#b7">[8]</ref> # N RMOV <ref type="bibr" target="#b7">[8]</ref> # ?RETADDR ADDi <ref type="bibr" target="#b7">[8]</ref> 1 # ++i J Label?for?cond Label?for?end : JR <ref type="bibr" target="#b4">[5]</ref> %% arg0 : arr %% arg1 : N %% ?RETADDR Function?iota : The front-end is stalled if the walking has not been completed when the first group of re-fetched instructions reaches to the rename stage. The ROB-walking width is same as the speed of frontend-width. Because the back-end pipeline of STRAIGHT is similar to conventional superscalar processors, both simulators can share common codes for the most part. Therefore, this superscalar model is also provided with the same state-of-art ILP technologies as described in above. As the equalization to RV32IM, we set STRAIGHT as a 32bit architecture and disabled the floating-point instructions and modules in the evaluation. The evaluated processor models and their parameters are shown in Table <ref type="table">I</ref>. As shown, the sizes of each module are set to the same value between the "SS" and "STRAIGHT" models to clarify the comparison, which represent the superscalar and STRAIGHT, respectively. We configure two classes named "4way" and "2way" to confirm the behavior of the different typical design scales. "4way" models the high-end CPU cores for desktop PCs and servers in which the OoO execution fully shows its abilities. "2way" models smaller OoO cores for the emerging mobile devices. The maximum distance is set to 31 in STRAIGHT-4way and STRAIGHT-2way models. This value is determined only for equalizing the number of the ROB entries and the number of the physical registers to SS parameters. The architecture's optimal parameter can be different, however the parameter is set to clarify the comparison as described above. As the instruction set is different from each other, the performance is measured by the execution cycles to complete the programs that are compiled from the same Two standard benchmarks are used, Dhrystone 2.1 and CoreMark. Both are representative general-purpose integer benchmarks, which are suited to evaluate the novel processor's fundamental characteristics. The STRAIGHT code is generated by our STRAIGHT compiler that takes the LLVM IR code obtained by using clang 3.8 with -O2 and --target=mips-pc_linux-gnu -S -emit-llvm options as an input. The target option is only for indicating the 32-bit architecture. The specific compiler front-end for STRAIGHT does not exist yet; however, currently the front-end for mips is sufficient to output an intermediate code for the STRAIGHT compiler back-end. For both benchmarks, two STRAIGHT binaries are prepared; STRAIGHT RAW that is generated by the basic algorithm described in Section IV-A to IV-C and STRAIGHT RE+ that is generated by adding the redundancy elimination described in IV-D to STRAIGHT RAW.</p><formula xml:id="formula_3">SPADD 4 ST [2] [1] RMOV [5] # &amp;arr[0] RMOV [5] # N ADDi $ZERO 0 # i = 0 NOP Label?for?cond : SLT [2] [3] BEZ [1] Label?for?end ST [4] [6] ADDi [7] 4 # &amp;arr[i] RMOV [7] # N ADDi [7] 1 # ++i J Label?for?cond Label?for?end : SPADD -4 LD [1] 4 JR [1] source code (a) (b) (c)</formula><p>For the comparison, clang/LLVM is also used for generating the RISC-V code. The back-end for LLVM by lowRISC is used. The code is generated with the -O2 and -march=rv32im --target=riscv32 option.</p><p>The cycles to complete the fixed number of iterations of the benchmark program is measured: 9000 times for Dhrystone, and 9 times for CoreMark. The performances are shown by using the inverse of the execution cycles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. RTL Power Analysis</head><p>To reveal the improvement of the power efficiency, we performed a power analysis in the register-transfer level (RTL). The RTL description of STRAIGHT that faithfully models the OoO execution, speculation, and recovery mechanisms is developed as well as an in-house RTL description of RV32I that involves the state-of-the-art superscalar technology. Similar to our simulator, both descriptions use the common code as much as possible for the comparison. In fact, the only differences are the modules related to front-end stages and ROB. The organizations of the RTL processors are almost the same as that of STRAIGHT-2way and SS-2way in the table I; however, the functions for integer multiply/divide instructions and general system calls are omitted.</p><p>We confirmed that both RTL processors can execute a test code correctly. The power consumed during the test code execution is analyzed using the Joules RTL Power Solution of Cadence. For both processors, the same recent advanced technology node is assumed. The baseline clock frequencies is set to be comparable to that of modern mobile processors. Several clock frequencies are set for the evaluation, in which the RTL processors are synthesized with the relevant time constraint for each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Performance Comparison to the Conventional Superscalar</head><p>Figure <ref type="figure" target="#fig_6">11</ref> shows the performance of STRAIGHT-4way and SS-4way. Each bar shows the relative performance that is normalized to SS-4way. The white bars represent the performances of the superscalar processor and the black bars represent those of STRAIGHT. STRAIGHT on Dhrystone and STRAIGHT-4way RE+ on CoreMark show the better performance than SS-4way, which are by 15.7% on Dhrystone and 18.8% on CoreMark, respectively.</p><p>On the other hand, the possible overhead of STRAIGHT ISA is shown in STRAIGHT-4way RAW on CoreMark that degrades the performance by 4% from the baseline SS. The reason is that a number of RMOV instructions are added by the basic STRAIGHT compiler because CoreMark tends to have the larger number of alive values through the execution than Dhrystone. However, the graph also shows that the overhead can be reduced by the redundancy elimination algorithm, as STRAIGHT-4way RE+ shows the best performance.</p><p>Figure <ref type="figure" target="#fig_7">12</ref> shows the performance comparison of STRAIGHT-2way and SS-2way in the same manner. The relative performance degradation of STRAIGHT-2way RAW is larger than that of the four-way configuration. This is as expected; in the current model, each RMOV instruction behaves as one ALU instruction. The impact of increased RMOV instruction becomes relatively large in the smaller configuration. However, in this small OoO core configuration, STRAIGHT-2way RE+ also shows a comparable or better performance to its superscalar counterpart; it degrades the performance by 7.4% from SS-2way on Dhrystone but improves by 5.5% on CoreMark. The redundant elimination algorithm is also effective for the smaller core.</p><p>As both architectures are configured to have the same pipeline width, instruction window sizes, and predictors, the significant reasons for performance difference are as follows: i) ISA characteristics in STRAIGHT that eliminates register overwrites by adding RMOV instructions or LD/ST instructions. ii) STRAIGHT has fewer misprediction penalties because of its recovery mechanism and shorter front-end pipeline. The former can degrade the performance of STRAIGHT while the latter improves the performance.</p><p>The impact of the rapid recovery of STRAIGHT is shown in Figure <ref type="figure" target="#fig_8">13</ref>. The graph shows the performance of SS and STRAIGHT RE+ as well as the performance when the misprediction penalty of SS is idealized to zero. Both 2way and 4way performances on CoreMark are shown.</p><p>As shown in the graph, the effect of misprediction penalty is significant for the superscalar. The effect is around 20% that is similar amount to the reported in <ref type="bibr" target="#b13">[14]</ref> on the integer programs when RAM based RMT and ROB walking are configured. Although the RMT technologies for reducing this penalty are exist, they increase the RMT power further. As the strong point of STRAIGHT, it reduces this penalty with simple hardware such that the performance and efficiency are both improved.</p><p>Branch prediction technologies can also reduce the recovery penalty. To reveal this impact, we implemented TAGE predictor (8-component CBP-TAGE) <ref type="bibr" target="#b14">[15]</ref> to our simulator. Figure <ref type="figure" target="#fig_0">14</ref> shows the relative performance of CoreMark when TAGE is used instead of the conventional gshare predictor. As expected, relative performances of STRAIGHT is reduced for both 2way and 4-way because the performance of the baseline SS is relatively improved by the reduced recovery penalty. However, STRAIGHT-4way shows 10% better performance even in this configuration. The basic characteristic is kept; STRAIGHT shows comparable or better performance.</p><p>Next, figure <ref type="figure" target="#fig_2">15</ref> shows the number of executed instructions on CoreMark to contrast code characteristics. Each bar is normalized to the total instruction count of SS. The graph also shows the fraction of instruction types for jump or branch, ALU, LD/ST, RMOV, NOP, and others. The graph shows that STRAIGHT RAW requires more code than SS to complete the same program. The increased instructions are shown to be primarily RMOVs to adjust the distance. This is the possible impact of the naive STRAIGHT ISA code in exchange for the simpler hardware.</p><p>STRAIGHT RE+ reduces the instruction count drastically, which shows the impact of the compiler technology for STRAIGHT. The count of increased RMOVs are now reduced to about 20% of the baseline SS. As the performance evaluation shows, the performance of STRAIGHT RE+ is better than SS in the same issue-width for the most case. This means that the increased 20% instructions can be executed in parallel, and they can utilize the empty issue slots that are reserved for the maximum ILP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Sensitivity of STRAIGHT design parameters</head><p>Figure <ref type="figure" target="#fig_10">16</ref> shows the source distance distribution in the cumulative graph. The distribution of source operand distances is measured for all retired instructions. The code that is generated with the uppermost distance limitation (1023) is used for this measurement. The actual maximum distance of the generated code is under 127 for each benchmark. The graph shows that most of the distances between producer instructions and consumer instructions are within 32. The graph also shows that almost 40% of the source operands in Dhrystone and 30% of those in CoreMark are the result of the previous instruction. The result indicates that the short operand field is sufficient to represent the source distance. The distance limitation of STRAIGHT ISA is not severe unless it is set to below 31. This trend helps to reduce the STRAIGHT hardware resources for physical registers as well as to shrink the instruction length. We confirmed this by simulation with CoreMark. The performance degradation is only around 1% when the maximum distance is reduced from 1023 to 31.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Power Reduction</head><p>Figure <ref type="figure" target="#fig_0">17</ref> shows the result of the RTL power analysis. The relative powers of SS and STRAIGHT for various frequencies from the baseline to 4.0 times of the baseline are shown. In the graph the powers for the rename logic, the register file, and "other modules" are shown normalized to the corresponding power of SS when operated in the baseline frequency. "Other modules" involves the rest of the core, but caches, the buses, and the branch predictor are not included. The White bars indicate SS and the black bars indicate STRAIGHT. For "rename logic" of STRAIGHT, the power of the circuit for operand determination (fig <ref type="figure">3</ref>) is shown as the counterpart.</p><p>As clearly shown in the graph, the power corresponding register renaming is almost removed in STRAIGHT. The power efficiency of STRAIGHT is supported because this power is known to one of the major factors of recent processors' power dissipation. The effect increases as the frequency. For the reference, the proportion of the renaming power is 5.7% to the other modules in this analysis. Because the scale of the analyzed processor is small, the proportion will increase when the wider front-end width is configured or check point is introduced to reduce the miss-recovery.</p><p>The power of the register file and other modules show the slight increase in STRAIGHT. The amount is under 18% for the register file and under 5% for other logics. This is the effect of the increased instructions per cycle (IPC) of STRAIGHT.  For the aspect of energy, the performance improvement cancels this increase by the reduced execution time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RELATED WORKS</head><p>The single-thread performance is intensively researched by various approaches because of its significance. While the superscalar architecture achieves the sophisticated OoO execution with the support of register renaming, scheduling, deep pipelining, smart cache managements, and various predictors, its complexity and power consumption per instruction are major drawbacks.</p><p>The limitation and optimization of the superscalar pipeline depth are comprehensively explored around the turn of the century <ref type="bibr" target="#b15">[16]</ref> [17] <ref type="bibr" target="#b17">[18]</ref>, which enforces researchers to explore novel ILP architectures as well as effective microarchitectures. Scalable ILP architectures such as clustered architectures are examples of the representative approaches <ref type="bibr" target="#b12">[13]</ref> [19] <ref type="bibr" target="#b19">[20]</ref>. Their basic idea is to separate the wide-issue core into several execution blocks to maintain the critical loops short regardless of the entire processor's scale.</p><p>The single-thread program often lacks parallelism to fully utilize such wide-issue cores. Speculative multithreading <ref type="bibr">[21] [22]</ref> technologies are presented to supply many instruction streams to the core(s) by speculatively separating a singlethreaded program into multiple threads. Slipstream processors <ref type="bibr" target="#b22">[23]</ref> and Runahead execution <ref type="bibr" target="#b23">[24]</ref> are similar but more drastic technologies that utilize helper threads only for the training of predictors and caches.</p><p>For the recent heterogeneous multicore processors, the technology for "OoO performance with in-order power" is desired for the total chip performance improvement. Kumar et al. <ref type="bibr" target="#b24">[25]</ref> showed the potential of heterogeneous multicore architectures to improve the efficiency of a single-thread execution by switching the dedicated core dynamically. Different scale cores that share the same ISA are implemented in a chip, and an adequate core is selected depending on the ILP amount of the thread. It is known that the adequate configuration for the program changes in less than a thousand instructions <ref type="bibr" target="#b25">[26]</ref>. Composite cores <ref type="bibr" target="#b26">[27]</ref> or FXA <ref type="bibr" target="#b27">[28]</ref> introduces both OoO and in-order mechanisms into a core to enable rapid switching. Mirage Core <ref type="bibr" target="#b11">[12]</ref> virtually increases the number of OoO cores by transferring the scheduled instructions to the smaller inorder (OinO) cores.</p><p>As discussed, register renaming increases the OoO core's power consumption as well as it affect the clock frequency by introducing the critical-loop into the front-end pipeline. Safi et al. <ref type="bibr" target="#b9">[10]</ref> proposes the two-stage pipelined renaming logic to reduce both the power and frequency overheads. Vajapeyam et al. <ref type="bibr" target="#b28">[29]</ref> proposed the renamed trace cache (RTC) to cache renamed operands. Shioya et al. <ref type="bibr" target="#b10">[11]</ref> introduced the distance representation into RTC to extend the caching target. Although conventional RMT is required for the RTC miss, both approaches have the advantage of compatibility.</p><p>TILE architectures target both the simple hardware and wider execution of single-thread performance. By introducing a specific ISA, the architecture maps the dataflow graph almost directly onto its ALU networks <ref type="bibr" target="#b29">[30]</ref>  <ref type="bibr" target="#b30">[31]</ref>. A hybrid approach has been introduced to increase its viability <ref type="bibr" target="#b31">[32]</ref>.</p><p>The concept of STRAIGHT <ref type="bibr" target="#b6">[7]</ref> reduces the required hardware and improves the performance and power efficiency by leveraging the compiler support. Unlike VLIWs <ref type="bibr" target="#b32">[33]</ref>, which also leverages compiler technologies, its scheduling is performed by the hardware, which enables dynamic and speculative ILP execution.</p><p>The instruction format of STRAIGHT has partially similar characteristics to instruction representations of dataflow architectures <ref type="bibr">[34] [35] [36]</ref> in those an operand is represented as a connection between a producer instruction and a consumer instruction. Unlike RISC architectures, a register number (name) is not essential for both dataflow architectures and STRAIGHT; and a value in a register is automatically discarded in a short period. In STRAIGHT, this property leads to the simple hardware structure because temporal values can be maintained in a queue structure instead of a map structure.</p><p>The mechanism to pass the live variables across code blocks often becomes a challenge in such designs because the producer-consumer relation is not so simple in that case. STRAIGHT's approach is to statically prepare code that equalizes the relative distance between a consumer and producers so that the operand fetch behavior is fixed regardless of execution paths. The use of such relative distance is also seen in hybrid dataflow architecture SINAN <ref type="bibr" target="#b36">[37]</ref> that passes arguments according to the relative position in the data segment to improve the inter-block communication. Contrary to typical dataflow architectures where a producer instruction specifies its destinations, the direction is inverse in STRAIGHT, that is, a consumer instruction refers to the source at its execution. This design can avoid the fanout problem but requires a broadcast mechanism in the scheduler.</p><p>Same as RISC architectures, the execution model of STRAIGHT inherits control flow guided by PC, which enables to exploit speculations for pumping instructions into the deep fast pipeline without waiting for actual execution. The two different approach, dataflow and control flow, are bound at the instruction level by RP that is incremented by the control flow and is used as a data pointer. Contrast to the typical dataflow architectures which require hierarchical structure of</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example of STRAIGHT code and bit-field formats</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. The mechanism of operand determination in the front-end pipeline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Instruction Arrangement in Calling Convention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Flows of Basic Blocks in Calling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Distances on control flows</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. STRAIGHT code and optimization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Performance comparison of STRAIGHT and SS (4way)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Performance comparison of STRAIGHT and SS (2way)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. The effect of the misprediction penalty</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 14 .Fig. 15 .</head><label>1415</label><figDesc>Fig. 14. Performance comparison of STRAIGHT and SS with TAGE branch predictor</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Cumulative Fraction of the Source Distance</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>Authors would like to thank <rs type="person">Akifumi Fujita</rs> for the first implementation of our RTL description, and also thank <rs type="person">Makoto Sahoda</rs> for the first implementation of the STRAIGHT simulator.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>inter-block and intra-block, this instruction level unification makes STRAIGHT a simple flat architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>Herein, we presented the practical STRAIGHT architecture by describing its ISA specification, microarchitecture organization, and compiler algorithm. By indicating source operands based on the distance from the producer instruction, the ISA guarantees that each register will be written once and then discarded in a fixed period. These characteristics enable the design of a novel microarchitecture that eliminates register renaming while maintaining a flexible OoO execution. The compiler algorithm that generates code for this novel ISA is first revealed. The key idea is to arrange the alive variables in a fixed order regardless of the control flow variation. The performance is evaluated with a cycle-accurate simulator; the power consumption is evaluated by the RTL power analysis. The same sized superscalar counterpart is also developed for the comparison.</p><p>The evaluation result shows that STRAIGHT achieves a higher performance with the simpler hardware. It shows 18.8% better performance than its superscalar counterpart. The low misprediction penalty delivered by STRAIGHT's simple hardware supports the superiority. The unique ISA of STRAIGHT possibly deteriorates the performance with the naive compiler, however, we also revealed that our redundancy elimination resolves the overhead. STRAIGHT shows better performance than the superscalar processor in the small configuration as well, which demonstrates its suitability for mobile platforms. The RTL power analysis shows that STRAIGHT reduces the power consumption by removing the power for renaming. Therefore the architecture achieves the performance improvement with the lower energy by the simple hardware. The results support that the architecture is a novel viable alternative for designing general purpose OoO processors.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Amdahl&apos;s law in the multicore era</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Marty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dark silicon and the end of multicore scaling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Blem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Amant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The gpu computing era</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nickolls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scale-Out Processors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Picorel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Idgunji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Global Value Numbers and Redundant Computations</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Zadeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symp. on Principles of Programming Languages</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detecting Equality of Variables in Programs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Zadeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symp. on Principles of Programming Languages</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">STRAIGHT: Realizing a Lightweight Large Instruction Window by using Eventually Consistent Distributed Registers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Majima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yoshinaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Workshop on Challenges on Massively Parallel Processors</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Llvm: a compilation framework for lifelong program analysis transformation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Checkpointing alternatives for high-performance, poweraware processors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Low Power Electronics and Design</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two-stage, pipelined register renaming</title>
		<author>
			<persName><forename type="first">E</forename><surname>Safi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Veneris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Very Large Scale Integration Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Energy efficiency improvement of renamed trace cache through the reduction of dependent path length</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shioya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Computer Design</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mirage cores: The illusion of many out-of-order cores using in-order hardware</title>
		<author>
			<persName><forename type="first">S</forename><surname>Padmanabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lukefahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Complexity-Effective Superscalar Processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient register renaming and recovery for high-performance processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ubal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sahuquillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Very Large Scale Integration Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new case for the tage branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Clock Rate versus IPC: The End of the Road for Conventional Microarchitectures</title>
		<author>
			<persName><forename type="first">V</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hrishikesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The optimal logic depth per pipeline stage is 6 to 8 fo4 inverter delays</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hrishikesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shivakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimum power/performance pipeline depth</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hartstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Puzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic Cluster Assignment Mechanisms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Canal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Parcerisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on High-Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Instruction Distribution Heuristics for Quad-Cluster Dynamically-Scheduled, Superscalar Processors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baniasadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiscalar processors</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Breach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vijaykumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A chip-multiprocessor architecture with speculative multithreading</title>
		<author>
			<persName><forename type="first">V</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Study of Slipstream Processors</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Purser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sundaramoorhy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Runahead execution: An effective alternative to large instruction windows</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Single-isa heterogeneous multi-core architectures: the potential for processor power reduction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Architectural contesting</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Najaf-Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on High Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Composite cores: Pushing heterogeneity into a core</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lukefahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Padmanabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Sleiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dreslinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A front-end execution architecture for high energy efficiency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shioya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving superscalar instruction dispatch and issue by exploiting dynamic code sequences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vajapeyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A design space evaluation of grid processor architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Microarchitecture</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluation of the Raw Microprocessor: An Exposed-Wire-Delay Architecture for ILP and Streams</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wentzlaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bratt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Psota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shnidman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Strumpen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Exploring the potential of heterogeneous von neumann/dataflow execution models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nowatzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gangadhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Measuring the parallelism available for very long instruction word architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computers</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A preliminary architecture for a basic dataflow processor</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Misunas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An efficient pipelined dataflow processor architecture</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf. on Supercomputing</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Executing a program on the mit tagged-token dataflow architecture</title>
		<author>
			<persName><forename type="first">Arvind</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nikhil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Computers</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sinan -a forwarding multithreaded architecture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Onder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on High-Performance Computing</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
