<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-time Tracking Using Level Sets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yonggang</forename><surname>Shi</surname></persName>
							<email>yshi@bu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="institution">Boston University</orgName>
								<address>
									<postCode>02215</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">W</forename><forename type="middle">Clem</forename><surname>Karl</surname></persName>
							<email>wckarl@bu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="institution">Boston University</orgName>
								<address>
									<postCode>02215</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Real-time Tracking Using Level Sets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9B3B58A7E5DDFBC412F6AF2A7CF6228E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we propose a novel implementation of the level set method that achieves real-time level-set-based video tracking. In our fast algorithm, the evolution of the curve is realized by simple operations such as switching elements between two linked lists and there is no need to solve any partial differential equations. Furthermore, a novel procedure based on Gaussian filtering is introduced to incorporate boundary smoothness regularization. By replacing the standard curve length penalty with this new smoothing procedure, further speedups are obtained. Another advantage of our fast algorithm is that the topology of the curves can be controlled easily. For the tracking of multiple objects, we extend our fast algorithm to maintain the desired topology for multiple object boundaries based on ideas from discrete topology. With our fast algorithm, a real-time system has been implemented on a standard PC and only a small fraction of the CPU power is used for tracking. Results from standard test sequences and our realtime system are presented.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Real-time tracking of object boundaries is an important task in many vision applications such as video surveillance, video conferencing, and human-computer interaction, etc. Parametric contours have been applied successfully to achieve real-time performance <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">19]</ref>, but they have difficulties in handling topological changes such as the merging and splitting of object regions. For this purpose, the level set method <ref type="bibr" target="#b14">[15]</ref> is a more powerful technique and various models have been proposed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21]</ref>. But the high computational cost of the level set method has limited its popularity in real-time scenarios. In this paper, we propose a novel approach to implement the level set method. Our approach does not need to solve any partial differential equations (PDEs), thus reducing the computation dramatically compared with optimized narrow band techniques proposed before. With our approach, real-time level-set-based video tracking can be achieved.</p><p>Tracking models using level sets can be classified as edge-based or region-based. In <ref type="bibr" target="#b15">[16]</ref>, a geodesic model that combines motion and edge information was proposed. Such edge-based models can be traced back to the snake model in <ref type="bibr" target="#b12">[13]</ref>. Based on morphing images, an early work on region-based tracking was proposed in <ref type="bibr" target="#b1">[2]</ref>. Using the difference between the current frame and a reference background, a region-based model was proposed in <ref type="bibr" target="#b3">[4]</ref>. By generalizing the region competition <ref type="bibr" target="#b21">[22]</ref> idea, statistical approaches become quite popular recently. In <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b20">21]</ref>, the feature distributions of both the object and background regions were used for tracking. In <ref type="bibr" target="#b8">[9]</ref>, a predefined distribution for the object region was tracked by minimizing a Kullback-Leibler or Bhattacharyya distance.</p><p>Considerable work has been done to improve the speed of level-set-based curve evolution. The basic idea has been to limit the solution of the level set PDE to a narrow band around the zero level set <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b15">16]</ref>, but issues such as narrow band construction, reinitialization and step size control still make existing level set methods computationally too expensive for real-time tracking.</p><p>The novel implementation we propose in this paper avoids the above problems. Our approach is based on the key observation that implicitly represented curves can be moved by simply switching elements between two linked lists. We also propose a Gaussian filtering process to replace curvature-based smoothing, and this further speeds up our algorithm. Another advantage of our method is that ideas for controlling topological changes in <ref type="bibr" target="#b10">[11]</ref> can be incorporated into our algorithm easily, which can be important for the tracking of multiple objects and medical imaging applications. With our fast level set implementation, we have developed a region-based real-time video tracking system requiring only a small fraction of the CPU power on a standard PC, leaving computational power available for other tasks, such as recognition, trajectory analysis, etc.</p><p>The rest of the paper is organized as follows. In Section 2, we present the tracking model used in this paper. Our fast level set implementation for the two-region case is then presented in Section 3. For the case of multiple object regions, we extend our fast algorithm to incorporate topology control capabilities in Section 4. Real-time tracking results are presented in Section 5. Finally conclusions are made in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Tracking Model</head><p>In this paper, we use a region-based tracking model based on the region competition <ref type="bibr" target="#b21">[22]</ref> idea, but our fast level set implementation is also applicable for edge-based models.</p><p>We assume each scene of the video sequence is composed of a background region Ω 0 and M object regions</p><formula xml:id="formula_0">Ω 1 , Ω 2 , • • • , Ω M . The boundaries of these M ob- ject regions are denoted as C 1 , C 2 , • • • , C M . We model each region with a feature distribution p(v|Ω m )(m = 0, 1, • • • , M ),</formula><p>where v is the feature vector defined at each pixel. For example, the features can be the color, the output of a filter bank designed to model textures, or other visual cues. Assuming that the feature distribution at each pixel is independent, the tracking result of each frame is the minimum of the following region competition energy:</p><formula xml:id="formula_1">E = - M m=0 Ωm log p(v(x)|Ω m )dx E d + λ M m=1 Cm ds Es (1)</formula><p>where E d is the data fidelity term that represents the likelihood of the current scene, E s is for smoothness regularization and is proportional to the length of all curves, and λ is the non-negative regularization parameter.</p><p>By computing the first variation of this energy, the curve evolution equation for the minimization of this energy is:</p><formula xml:id="formula_2">dC m dt = (F d + F s ) N Cm (m = 1, 2, • • • , M )<label>(2)</label></formula><p>where N Cm is the normal of C m pointing outward, and F d and F s are the speed resulting from E d and E s , respectively. The speed F d represents the competition between two regions and it is</p><formula xml:id="formula_3">F d = log[p(v(x)|Ω m )/p(v(x)|Ω out )],</formula><p>where Ω out denotes the region outside C m at x ∈ C m . The speed F s makes the curve smooth and it is F s = λκ, where κ is the curvature. Since the focus of this paper is on real-time level set implementation for video tracking, we use a simple tracking strategy as follows. For each frame, we use the tracking results from the last frame as the initial curves, and then evolve each curve according to (2) to locate the object boundaries in the current frame. Once it stops, we move on to track the next frame of the video sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Fast Level Set Implementation</head><p>In this section, we present a fast level set implementation of the curve evolution process in (2) when the scene is composed of only the background Ω 0 and a single object region Ω 1 . Extensions are then made to track multiple objects with different feature distributions in the next section.</p><p>To represent the background Ω 0 and the object region Ω 1 , we use a level set function φ which is negative in Ω 1 and positive in Ω 0 . Based on this representation, we define two lists of neighboring pixels L in and L out of C 1 as shown in Fig. <ref type="figure">1</ref>. Formally, they are defined as: L out = {x|φ(x) &gt; 0 and ∃y ∈ N 4 (x) such that φ(y) &lt; 0}, L in = {x|φ(x) &lt; 0 and ∃y ∈ N 4 (x) such that φ(y) &gt; 0} where N 4 (x) is a 4-connected discrete neighborhood of a pixel x with x itself removed.</p><p>In conventional implementations of the level set method, an evolution PDE is solved either globally on the whole domain or locally in a narrow band to evolve the curve according to (2). Our fast level set implementation is based on the key observation that the implicitly represented curve C 1 can be evolved at pixel resolution by simply switching the neighboring pixels between the two lists L in and L out . For example, as we show in Fig. <ref type="figure">2</ref>, the curve C 1 moves outward at pixel A and shrinks and splits at pixel B compared with the curve shown in Fig. <ref type="figure">1</ref>. This motion can be realized by simply switching pixel A from L out to L in , and pixel B from L in to L out . By doing this for all the pixels in L in and L out , the curve can be moved inward or outward for one pixel everywhere in one scan. Since the curve is still represented implicitly, topological changes can be handled automatically. With this idea, we can achieve level-setbased curve evolution at pixel resolution and this is usually enough for many imaging applications. Next we present the details of our fast algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Algorithm</head><p>The data structure used in our implementation is as follows:</p><p>• An array for the level set function φ;</p><p>• An array for the evolution speed F ;</p><p>• Two bi-directionally linked lists of neighboring pixels: L in and L out .</p><p>Besides the inside and outside neighboring pixels contained in L in and L out , we call those pixels inside C 1 but not in L in as interior pixels and those pixels outside C 1 but not in L out as exterior pixels. For faster computation, we define φ as follows:</p><formula xml:id="formula_4">φ(x) =        3 if x is an exterior pixel, 1 if x ∈ L out , -1 if x ∈ L in , -3 if x is an interior pixel.<label>(3)</label></formula><p>To switch pixels between L in and L out , we define two basic procedures on our data structure.</p><p>The procedure switch -in() for a pixel x ∈ L out moves the curve outward one pixel at x by switching it from L out to L in and adding all its neighboring exterior pixels to L out . Formally this procedure is defined as follows:</p><formula xml:id="formula_5">switch -in(x) : • Step 1: Delete x from L out and add it to L in . Set φ(x) = -1.</formula><p>• Step 2: ∀y ∈ N 4 (x) satisfying φ(y) = 3, add y to L out , and set φ(y) = 1.</p><p>Similarly, the switch -out() procedure that moves the curve inward one pixel at x ∈ L in is defined as follows: switch -out(x) :</p><p>• Step 1: Delete x from L in and add it to L out . Set φ(x) = 1.</p><p>• Step 2: ∀y ∈ N 4 (x) satisfying φ(y) = -3, add y to L in , and set φ(y) = -1.</p><p>To track the object boundary, we compute the speed at all pixels in L out and L in and store their sign in the array F . We first scan through the list L out and apply a switch -in() procedure at a pixel if F = +1. After this scan, some of the pixels in L in become interior pixels and they are deleted. We then scan through the list L in and apply a switch -out() procedure for a pixel with F = -1. Similarly, exterior pixels in L out are deleted after this scan. At the end of this iteration, a stopping condition is checked. If it is satisfied, we stop the evolution; otherwise, we continue this iterative process. In our implementation, the following stopping condition is used:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stopping Condition. The curve evolution algorithm stops if either of the following conditions is satisfied:</head><p>(a) The speed at each neighboring pixel satisfies:</p><formula xml:id="formula_6">F (x) ≤ 0 ∀x ∈ L out ; F (x) ≥ 0 ∀x ∈ L in . (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>(b) A pre-specified maximum number of iterations is reached.</p><p>The condition in ( <ref type="formula" target="#formula_6">4</ref>) is very intuitive in the sense of region competition. When the curve is on the object boundary, all the pixels in L out are in the background and all the pixels in L in are in the object region. When (4) is satisfied, they disagree with each other on which direction to move the curve and convergence is reached. When the data is noisy or there is clutter, regularization is necessary and (4) may not be always satisfied in the final curve. Thus part (b) of the condition is also necessary to stop the evolution.</p><p>The above algorithm can be applied to arbitrary speed fields and speeds up the evolution process in (2) dramatically compared with previous narrow band techniques based on solving the level set PDE. For the curve evolution equation in <ref type="bibr" target="#b1">(2)</ref>, we can achieve a further speedup by introducing a novel scheme that separates the evolution driven by the data dependent speed F d and the smoothing speed F s into two different cycles. In spirit, this idea is similar to the work in <ref type="bibr" target="#b9">[10]</ref> which proposed a fast method to implement the Chan-Vese model <ref type="bibr" target="#b4">[5]</ref> over the whole domain, but the two-cycle algorithm we present next is still based on updating the two linked lists L in and L out to evolve the implicitly represented curve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Two-cycle Algorithm</head><p>In the curve evolution equation in <ref type="bibr" target="#b1">(2)</ref>, the speed F s for smoothness regularization is a function of the curvature, which is computationally quite expensive to evaluate generally. However when the level set function is chosen as the signed distance function, the curvature takes a simpler form and equals the Laplacian of φ. From the theory of scale-space <ref type="bibr" target="#b17">[18]</ref>, we know that evolution of a function according to its Laplacian is equivalent to Gaussian filtering the function. Motived by this observation, we propose to incorporate smoothness regularization using a Gaussian filtering process to further speed up our algorithm.</p><p>Let us denote an isotropic Gaussian filter of size N g ×N g as G.</p><p>To smooth the zero level set, we compute the response of φ to the Gaussian filter only at pixels in the two lists L in and L out . Due to the need of maintaining our data structure, we do not take the output of the Gaussian filter directly. Only when the sign of the output is different from the original value of φ at a pixel, we apply a switch -in() or switch -out() procedure to move the zero level set; otherwise, the original value of φ is kept.</p><p>To combine this smoothing process with the evolution of the data dependent speed F d , we propose a two-cycle algorithm. In the first cycle of our algorithm, we evolve the curve according to F d using the fast algorithm proposed in Section 3.1. In the second cycle, we apply the Gaussian filtering process to incorporate smoothness regularization. The details of this algorithm are listed in Table <ref type="table">1</ref>.</p><p>Two factors make this two-cycle algorithm faster than curvature-based regularization. When the noise is low, we can reduce the parameter N g or increase the parameter N a to reduce the percentage of computation allocated for smoothness regularization. The second reason is that we can implement the Gaussian filtering process with integer operations since we only care about the sign of its output.</p><p>To conclude, we will use the two-cycle algorithm in our level-set-based tracking. With this fast implementation, real-time tracking can be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Tracking Multiple Objects</head><p>In this section, we extend our fast algorithm to track multiple objects with different feature distributions.</p><p>For the representation of multiple object regions, we use two functions: one region indication function ψ and one level set function φ. This simple representation is motivated by the work in <ref type="bibr" target="#b7">[8]</ref>. The region indication function is defined as follows:</p><formula xml:id="formula_8">ψ(x) = m, if x ∈ Ω m (m = 0, 1, • • • , M ).<label>(5)</label></formula><p>For the tracking of each frame, we assume the initial curves for all the object regions are separated by the background</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. The Two-cycle Fast Algorithm</head><p>• Step 1: Initialize the array φ, F d , the two lists Lout and Lin.</p><p>•</p><p>Step 2(cycle one): For i=1:Na do -Compute the speed F d for pixels in Lout and Lin; -For each pixel x ∈ Lout, switch-in(x) if F d (x) &gt; 0; -For each pixel x ∈ Lin, if ∀y ∈ N (x), φ(y) &lt; 0, delete x from Lin, and set φ(x) = -3. -For each pixel x ∈ Lin, switch-out(x) if F d (x) &lt; 0; -For each pixel x ∈ Lout, if ∀y ∈ N (x), φ(y) &gt; 0, delete x from Lout, and set φ(x) = 3. -Check the stopping condition. If it is satisfied, go to Step 3; otherwise continue this cycle.</p><p>• Step 3(cycle two): For i=1:Ng do</p><formula xml:id="formula_9">-For every pixel x in Lout, compute G ⊗ φ(x). If G ⊗ φ(x) &lt; 0, switch-in(x);</formula><p>-For each pixel x ∈ Lin, if ∀y ∈ N (x), φ(y) &lt; 0, delete x from Lin, and set φ(x) = -3. -For every pixel x in Lin, compute G ⊗ φ(x). If G ⊗ φ(x) &gt; 0, switch-out(x). -For each pixel x ∈ Lout, if ∀y ∈ N (x), φ(y) &gt; 0, delete x from Lout, and set φ(x) = 3.</p><p>• Step 4: If the stopping condition is satisfied in cycle one, terminate the algorithm; otherwise, go back to</p><p>Step 2.</p><p>region, but arbitrary topology is allowed in the final tracking result. The level set function φ is negative inside all the object regions and positive in the background. For each object region Ω m (1 ≤ m ≤ M ), two lists of neighboring pixels L m in and L m out can be defined as we did for the case of single object region. Here the interior pixels are those pixels inside the object regions but not contained in any L m in , and exterior pixels are those pixels in the background but not in any L m out . Similar to the two region case, the level set function is defined as:</p><formula xml:id="formula_10">φ(x) =          3 if x is an exterior pixel, 1 if x ∈ L m out for any 1 ≤ m ≤ M , -1 if x ∈ L m in for any 1 ≤ m ≤ M , -3 if x is an interior pixel. (6)</formula><p>To evolve the M curves C 1 , C 2 , • • • , C M and keep track of all the regions, we evolve φ and ψ simultaneously while keeping all the object regions from merging with each other. This kind of topology control requirements can be realized easily in our fast algorithms by incorporating ideas in discrete topology <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref>. In the following, we introduce related concepts in the context of video tracking. For more detailed discussion about topological numbers and discrete topology, see <ref type="bibr" target="#b2">[3]</ref>.</p><p>Let N 8 (x) denote the 3 × 3 neighborhood centered at a pixel x but with x removed, and Ω obj denote the union of all the object regions Ω m (1 ≤ m ≤ M ). The topological number of x with respect to Ω obj is the number of 4-connected components in the set Ω obj N 8 (x) and we denote it as T obj (x). The topological number of x with respect to the background region Ω 0 is the number of 8connected components in the set Ω 0 N 8 (x) and we denote it as T bg (x). According to <ref type="bibr" target="#b2">[3]</ref>, the pixel x is a simple point if both T obj (x) = 1 and T bg (x) = 1. For a simple point, its removal or addition to Ω obj will not change the topology of Ω obj .</p><p>Based on the idea of topological numbers, a topology preserving level set method was developed in <ref type="bibr" target="#b10">[11]</ref> which does not permit any splitting or merging of the curve. Here our requirement is more challenging. We want to allow each region Ω m (1 ≤ m ≤ M ) to have more than one connected components and they can merge and split at will if they belong to the same object region, but we also want to prohibit the merging of two connected components if they are from different object regions. To achieve this goal, we propose the concept of the relaxed topological number for a pixel x ∈ L m out (1 ≤ m ≤ M ) as follows:</p><p>Definition. For a pixel x ∈ L m out (1 ≤ m ≤ M ), if the number of object regions that intersect with N 8 (x) is α(x), its topological number with respect to Ω obj is T obj (x), and its topological number with respect to Ω 0 is T bg (x), then the relaxed topological number of x is defined as:</p><formula xml:id="formula_11">T r (x) = min(α(x), max(T obj (x), T bg (x))).</formula><p>If x is a simple point, then T r (x) = 1 and its addition to an object region will not cause two different object regions to merge. If x is not a simple point but α(x) = 1, we still have T r (x) = 1. This means that the addition of x to an object region will cause the merge of connected components from the same object region. For all the other cases, we have T r (x) &gt; 1, thus the relaxed topological number at a pixel can be used to prevent the merging of different object regions while allowing flexible topological changes within each object region. Based on this idea, we modify the switch -in() and switch -out() procedure to update φ and ψ to track the M object regions as we evolve the zero level set. The modified procedures are listed as follows: </p><formula xml:id="formula_12">switch -in(x) for x ∈ L m out (1 ≤ m ≤ M ): • Step 1: Compute T r (x). If T r (x) = 1, continue</formula><p>to step 2; otherwise, exit the procedure.</p><p>• Step 2: Delete x from L m out and add it to L m in . Set φ(x) = -1 and ψ(x) = m.</p><formula xml:id="formula_13">• Step 3: ∀y ∈ N 4 (x) satisfying φ(y) = 3, add y to L m out , and set φ(y) = 1. switch -out(x) for x ∈ L m in (1 ≤ m ≤ M ): • Step 1: Delete x from L m</formula><p>in and add it to L m out . Set φ(x) = 1 and ψ(x) = 0.</p><p>• Step 2: ∀y ∈ N 4 (x) satisfying φ(y) = -3, add y to L m in , and set φ(y) = -1. Similar to the case of a single object region, we use a two-cycle algorithm to track multiple object regions. Compared with the algorithm used to track one object, we need to scan through 2M lists L m in and L m out (m = 1, 2, • • • , M ) in each iteration of cycle one and two to track M objects. After the two-cycle algorithm finishes, we perform a likelihood test for each pixel in L m out (1 ≤ m ≤ M ) with T r (x) &gt; 1 and set its value in the region indication function as:</p><formula xml:id="formula_14">ψ(x) = argmax m∈SM p(v(x)|Ω m )<label>(7)</label></formula><p>where</p><formula xml:id="formula_15">S M = {1 ≤ m ≤ M |Ω m N 4 (x) = ∅}.</formula><p>Here p(•|Ω m ) is the feature distribution for each object region used in <ref type="bibr" target="#b0">(1)</ref>. By performing this likelihood test, we can assign pixels enforced as background before to proper object regions and enable the final tracking result to have arbitrary topology, such as multiple object regions connecting with each other. With all the regions labeled, the final  tracking result is saved in ψ for the current frame and we move on to the next frame. In Fig. <ref type="figure" target="#fig_1">3</ref>, we illustrate an image segmentation example using our algorithm. The noisy original image shown in Fig. <ref type="figure" target="#fig_1">3</ref>(a) is composed of the background region and four object regions. We start with four initial curves to localize the four object regions of different intensities. With our method, successful segmentation is obtained and we show the region indication function in Fig. <ref type="figure" target="#fig_1">3(b)</ref>. Note that only one of the curve is able to split into two parts to localize two connected components that belong to the same object region. This example demonstrates the power of our method to represent and localize multiple regions with the desired topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In this section, we present some real-time tracking results using our fast level set implementation. All the results presented in this section were run on a 1.7GHz PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results of Test Sequences</head><p>We first present tracking results from three standard test sequences.</p><p>In the first example, we track a person in the Hall monitor sequence in CIF format from frame 41 to 65. The first frame of this sequence is used as a reference frame. The feature v used here is the magnitude of the intensity difference between the current frame and the reference frame. A Gaussian distribution is assumed for both the object and background region. As we can see from the tracking results shown in Fig. <ref type="figure" target="#fig_2">4</ref>, we successfully tracked the person and his shadow, and topological changes of the curves are handled automatically as he walks in the hallway. For this sequence, the average tracking time is 0.0069s per frame.</p><p>In the second example, we show the tracking results of 65 frames from the Tennis sequence in SIF format. The Y and V components of the YUV color at each pixel are used as the feature. The feature distribution of the object and background region is modeled with a 32 × 32 histogram. Using the initial curve, we learn the histogram for each region in the first frame of the video sequence. As shown in Fig. <ref type="figure" target="#fig_3">5</ref>, we successfully tracked the player as he moves into the scene. The average tracking time for each frame is 0.005s.</p><p>In the third example, we track the face of the character in the Carphone sequence in QCIF format for 40 frames. The hue and saturation components of the color in the HSV space at each pixel are used as the feature. The transformation of color space from YUV to HSV is performed online. Given the initial curve in the first frame, we learn the distribution of the feature for both the face and the background region and store the results in a histogram of size 32 × 32. Even though the head of the character moves dramatically in a cluttered background in this sequence, we are still able to track the face successfully as shown in Fig. <ref type="figure">6</ref>. The average tracking time for this sequence is 0.0066s per frame.</p><p>From the results of these sequences, we can see that our level set implementation is able to track objects in a video sequence at a rate much faster than the real-time requirement. This makes our algorithm ready to be incorporated into real-time contour tracking systems where only a small fraction of the CPU time can be allocated to the tracking algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results from Our Real-time Tracking System</head><p>As a demonstration, we have implemented a real-time tracking system which includes video capturing, tracking, motion analysis and the displaying of tracking results. This system runs at 24 frames per second on a 1.7GHz PC. A block diagram of our system is shown in Fig. <ref type="figure">7</ref>. We use the image acquisition toolbox of Matlab to capture video sequences from a WebCam. The captured frame is sent to the tracking algorithm implemented in C++. Tracking results from this module are forwarded to an optional motion analysis algorithm once it is available. After that, the final results are sent back to Matlab for displaying. Then the next frame is captured from the WebCam to continue the tracking process. Currently we use color as the feature for tracking.</p><p>We show two examples from our tracking system. For both examples, the size of each frame is 352 × 288. In the first example, we track the motion of two hands as shown in Fig. <ref type="figure" target="#fig_5">8</ref>. This sequence includes various topological changes, such as the merging of curves, the creation of holes, and the splitting of curves. With this example, we demonstrate that complicated topological changes can be tracked in real-time with our system.</p><p>In the second example, we track two objects of different color distributions using the algorithm for the tracking of multiple objects developed in Section 4. In the motion analysis module, we implemented a simple collision detection algorithm by looking for pixels with T r (x) &gt; 1. As we can see from the results shown in Fig. <ref type="figure" target="#fig_6">9</ref>, when the two objects collide, the boundary between these two regions is labeled in white color. By tracking this interface, we can detect and follow the collision process. Meanwhile the deformation and movement of the two objects are tracked successfully in real-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have proposed a fast level set implementation without the need of solving any PDEs. Real-time results have been achieved for the tracking of both single and multiple objects. With our approach, a real-time video tracking system has been implemented on a standard PC.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 CFigure 1 . 1 Figure 2 .</head><label>1112</label><figDesc>Figure 1. The implicit representation of the curve C 1 and the two lists L in and L out in the neighborhood of C 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. (a) The original image and the initial curves(in white). One initial curve is used for each object region. (b) The segmentation result is shown in the region indication function.</figDesc><graphic coords="5,323.38,84.07,86.64,85.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Tracking results of the Hall monitor sequence. Frame 41,49,57,65 are shown.</figDesc><graphic coords="6,118.08,185.83,83.72,57.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Tracking results of the Tennis sequence. Frame 1,38,45,65 are shown.</figDesc><graphic coords="6,209.67,185.83,83.72,57.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Figure 6. Tracking results of the Carphone sequence. Frame 1,20,30,40 are shown.</figDesc><graphic coords="7,118.09,84.65,83.69,68.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. The results of tracking hands using our system. Frame 1, 40, 60, 81,95, 130, 150,and 200 of a sequence are shown.</figDesc><graphic coords="8,118.09,162.13,83.69,68.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The results of tracking the collision of two objects with different color distribution using our system. Frame 41, 44, 52, 60, 70, 76, 78, and 80 of a sequence are shown.</figDesc><graphic coords="8,117.91,363.19,83.92,68.65" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* This work was partially supported by The Air Force Office of Scientific Research under Grant F49620-03-1-0257, The National Institutes of Health under Grant NINDS 1 R01 NS34189, and The Engineering research centers program of the NSF under award EEC-9986821</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A fast level set method for propagating interfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Adalsteinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="269" to="277" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Morphing active contours: A geometric approach to topology-independent image segmentation and tracking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertalmio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">III</biblScope>
			<biblScope unit="page" from="318" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simple points, topological numbers and geodesic neighborhoods in cubic grids</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bertrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detection and tracking of moving objects using a new level set based method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Besson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2000-09">Sept 2000</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1100" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Imag. Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">JPDAF based HMM for real-time contour tracking</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Kernel-based object tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="564" to="577" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A curve evolution approach for image segmentation using adaptive flows</title>
		<author>
			<persName><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Castañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="494" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Acitve contours for tracking distributions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="518" to="526" />
			<date type="published" when="2004-04">Apr 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A fast hybrid k-means level set algorithm for segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gibou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fedkiw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Annual Hawaii Int&apos;l Conf. Statistics and Mathematics</title>
		<meeting>the 4th Annual Hawaii Int&apos;l Conf. Statistics and Mathematics</meeting>
		<imprint>
			<date type="published" when="2005-01">Jan. 2005</date>
			<biblScope unit="page" from="281" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A topology preserving level set method for geometric deformable models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Prince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="755" to="768" />
			<date type="published" when="2003-06">Jun 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ICONDENSATION: Unifying lowlevel and high-level tracking in a stochastic framework</title>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="767" to="781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Snakes:active contour models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Region tracking via level set PDEs without motion computation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mansouri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="947" to="961" />
			<date type="published" when="2002-07">Jul 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fronts propagation with curvaturedependent speed: algorithms based on Hamilton-Jacobi formulations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational physics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="12" to="49" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Geodesic active contours and level sets for the detection and tracking of moving objects</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="266" to="280" />
			<date type="published" when="2000-03">Mar 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A PDE-based fast local level set method</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Merriman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="410" to="438" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="1990-07">Jul 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Smoothing B-spline active contour for fast and robust image and video segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Precioso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP, Sept</title>
		<meeting>ICIP, Sept</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A level-set approach to 3D reconstruction from range data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="231" />
			<date type="published" when="1998">OCT 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Contour-based object tracking with occlusion handling in video acquired using mobile cameras</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1531" to="1536" />
			<date type="published" when="2004">NOv 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Region competition: unifying snake/balloon, region growing, and bayes/mdl/energy for multi-band image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="884" to="900" />
			<date type="published" when="1996-09">Sept 1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
