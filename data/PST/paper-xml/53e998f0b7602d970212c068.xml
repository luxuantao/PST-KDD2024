<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engi-neering</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C7C5F02148E55C2750436264DCCA9E82</idno>
					<idno type="DOI">10.1109/TIP.2012.2197011</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reduced-Reference Image Quality Assessment by Structural Similarity Estimation</head><p>Abdul Rehman, Student Member, IEEE, and Zhou Wang, Member, IEEE Abstract-Reduced-reference image quality assessment (RR-IQA) provides a practical solution for automatic image quality evaluations in various applications where only partial information about the original reference image is accessible. In this paper, we propose an RR-IQA method by estimating the structural similarity index (SSIM), which is a widely used full-reference (FR) image quality measure shown to be a good indicator of perceptual image quality. Specifically, we extract statistical features from a multiscale multiorientation divisive normalization transform and develop a distortion measure by following the philosophy in the construction of SSIM. We find an interesting linear relationship between the FR SSIM measure and our RR estimate when the image distortion type is fixed. A regression-by-discretization method is then applied to normalize our measure across image distortion types. We use six publicly available subject-rated databases to test the proposed RR-SSIM method, which shows strong correlations with both SSIM and subjective quality evaluations. Finally, we introduce the novel idea of partially repairing an image using RR features and use deblurring as an example to demonstrate its application. Index Terms-Divisive normalization transform, image deblurring, image repairing, natural image statistics, reduced-reference image quality assessment (RR-IQA), structural similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>O VER the past years, there has been an exponential increase in the demand for image and video services. Nevertheless, the networks in service are not designed to accommodate the current trends of traffic. In practice, the multimedia content delivered over the networks suffers from various kinds of distortions on its way to the destination. It is important for the service providers to be able to identify and quantify the quality degradations in order to maintain the required quality of service. This gives rise to the desire of accurate and efficient perceptual image quality assessment (IQA) algorithms that can estimate the subjective quality of the image content under various kinds of distortions.</p><p>Much work has been done in the recent past to develop objective quality assessment measures which can automatically measure the perceived distortion in the visual content.</p><p>The most prominent ones include the structure similarity index (SSIM) <ref type="bibr" target="#b0">[1]</ref> and its derivatives <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, visual information fidelity <ref type="bibr" target="#b3">[4]</ref>, visual signal-to-noise ratio <ref type="bibr" target="#b4">[5]</ref>, and the most apparent distortion <ref type="bibr" target="#b5">[6]</ref>. Among these methods, SSIM has often been preferred because of its good tradeoff between accuracy, simplicity, and efficiency <ref type="bibr" target="#b6">[7]</ref>.</p><p>√ 1 -SSIM has been shown to be a valid distance metric (that satisfies the identity and symmetry axioms as well as the triangle inequality) and has a number of useful local and quasi-convexity and distancepreserving properties <ref type="bibr" target="#b7">[8]</ref>. Besides IQA, SSIM has also found a wide variety of applications, ranging from image coding, restoration, and fusion to watermarking and biometrics <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b13">[14]</ref>. The success of SSIM motivated us to use it for visual communication applications. The difficulty is that SSIM is a full-reference IQA (FR-IQA) scheme that requires full availability of the reference image in order to estimate the quality of the distorted image. This makes it impractical in visual communication applications, where we have no access to the reference image at the receiver side. No-reference IQA (NR-IQA) is highly desirable because it does not require access to the reference image. In the literature, most NR-IQA algorithms were designed for specific and limited types of distortions <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b20">[21]</ref>. They may not be good choices in modern communication networks, where the distortions could be a combination of lossy compression, scaling in bit rate and spatial/temporal resolution, network delay and packet loss, and various types of pre-and postprocessing filtering (e.g., error concealment, deblocking filtering, sharpening). On the other hand, general-purpose NR-IQA is still at an immature stage.</p><p>The reduced-reference IQA (RR-IQA) method only requires a limited number features extracted from the reference for the IQA task <ref type="bibr" target="#b21">[22]</ref>. It provides an interesting compromise between FR and NR approaches in terms of both quality prediction accuracy and the amount of information required to describe the reference. A general framework for the use of RR-IQA in visual communications along with image-repairing capability is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. An image x is transmitted to the receiver via a transmission channel, which introduces distortions in the received image y. Meanwhile, RR features X extracted at the transmitter side are sent to the receiver through an ancillary channel. The feature extraction unit at the receiver side calculates the features Y from the received image y in a similar fashion as in the transmitter side. X and Y are compared at the quality assessment unit, which creates a quality score S of the distorted image y. A good RR-IQA approach should achieve a good tradeoff between the rate and accuracy. In general, the larger the rate of the RR features, the more accurate the RR-IQA measure can achieve. In the extreme, when the rate is enough to fully reconstruct the reference, RR-IQA converges to FR-IQA. The performance gap between RR-IQA and FR-IQA may be reduced by selecting RR features that are efficient, perceptually relevant, and sensitive to various kinds of distortions. In addition, since the RR features provide information about what the "correct" image is supposed to look like, they may also be used as side information to repair the received distorted image, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Based on the underlying design philosophy, existing RR-IQA algorithms may be loosely classified into three categories. The first type of methods are primarily built upon models of the image source. Since the reference image is not available in the deterministic sense, these models are often statistical that capture a priori the low-level statistical properties of natural images. The model parameters provide a highly efficient way to summarize the image information, and thus these methods often lead to RR-IQA algorithms with low RR data rate. In <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr" target="#b23">[24]</ref>, the marginal distribution of wavelet subband coefficients is modeled using a generalized Gaussian density (GDD) function, and GGD model parameters are used as RR features are employed to quantify the variations of marginal distributions in the distorted image. The model was further improved in <ref type="bibr" target="#b24">[25]</ref> by employing a nonlinear divisive normalization transform (DNT) after the linear wavelet decomposition, which resulted in enhanced quality prediction performance, especially when images with different distortion types are mixed together. The second category of RR-IQA methods are oriented to capture image distortions. These methods provide useful and straightforward solutions when we have sufficient knowledge about the distortion process that the images underwent, e.g., standard image or video compression <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b28">[29]</ref>. The limitation of such approaches is in their generalization capability. Generally, it is inappropriate to apply these methods beyond the distortions they are designed to capture. The third category of RR-IQA algorithms are based on models of the image receiver [i.e., the hierarchical visualisation system (HVS)] <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, where computational models from physiological and/or psychophysical vision studies may be employed. These methods have demonstrated good performance for JPEG and JPEG2000 compression <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. Among the three classes of RR-IQA approaches, the first and third ones, i.e., methods based on modeling the image source and the receiver, have more potential to be extended for general-purpose applications because the statistical and perceptual features being employed are not restricted to any specific distortion process. There are also interesting conceptual connections between these two types of approaches, because it is a general belief in biological vision science that the HVS is highly tuned for efficient statistical encoding of the natural visual environment <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>.</p><p>This paper focuses on a general-purpose RR-IQA based on natural image statistics modeling. In addition, motivated by the success of the FR SSIM index, we develop our method as an attempt to estimate SSIM rather than directly predicting subjective quality. The benefits of this approach are twofold. First, the successful design principle in the construction of SSIM can be naturally incorporated into the development of the RR algorithm. Second, when the algorithm design involves a supervised learning stage, it is much easier to obtain training data, because SSIM can be readily computed, as opposed to the expensive and time-consuming subjective evaluations. In <ref type="bibr" target="#b33">[34]</ref>, an interesting RR video quality measure based on SSIM estimation was proposed for quantifying visual degradations caused by channel transmission errors. It is based on local spatial statistical features and uses distributed source coding techniques to reduce the required bandwidth to transmit RR features. Our method differs from this approach in three ways. First, our method is based on natural image statistical modeling and makes use of the perceptually and statistically motivated DNT transform. Second, instead of decomposing the problem of SSIM estimation into many local problems and estimating each component in SSIM expression separately, our method uses global statistics to estimate global SSIM value. This allows for a much more efficient description of the image content, and thus significantly lowers the number of RR features. Third, our approach aims for a general-purpose RR-IQA that can be applied to assess images with a wide variety of distortion types.</p><p>The value of RR-IQA measures is beyond quality evaluations. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, they may also be employed to partially "repair" the distorted image. In this paper, we attempt to repair an image by matching the subband statistical properties of the distorted image with those of the reference, and use deblurring as an example to demonstrate the idea.</p><p>The interesting feature of this method is that it requires no knowledge about the blur kernel. Instead, the same repairing procedure is successful in correcting images of not only homogeneous blur (e.g., out-of-focus blur) but also directional blur (e.g., motion blur).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RR-SSIM ESTIMATION</head><p>The proposed RR-SSIM estimation algorithm starts with a feature extraction process of the reference image based on a multiscale multiorientation DNT. Divisive normalization was found to be an effective mechanism to account for many neuronal behaviors in biological perceptual systems <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref>.</p><p>It also provides a useful model to describe the psychophysical visual masking effect <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>. DNT is typically applied after a multiscale linear transform (loosely referred to as wavelet transform) that decomposes the image into transform coefficients representing localized structures in space, frequency (scale), and orientation. The DNT-domain representation of the image is then calculated by dividing each coefficient by a local energy measure based on its neighboring coefficients. It was found that the histogram of DNT coefficients within a wavelet subband can often be well fitted with a zero-mean Gaussian density function <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, which is a one-parameter function that allows efficient summarization of the statistics of the reference image.</p><p>In <ref type="bibr" target="#b24">[25]</ref>, the effect of image distortions on the statistics of DNT coefficients was studied. It was found that different types of distortions modify the statistics of the reference image in different ways, and the levels of statistical differences may be used to quantify image distortions. In order to estimate FR SSIM, we desire the variations of the statistics of the DNT coefficients with respect to different types and levels of distortions to be coherent with the corresponding effects on FR SSIM.</p><p>The Gaussian scale mixture (GSM) model provides a convenient framework to define a DNT <ref type="bibr" target="#b39">[40]</ref>. A vector Y of length N is regarded as a GSM if it can be represented as the product of two independent components: i.e., Y =zU , where z is a scalar random variable called the mixing multiplier, and U is a zeromean Gaussian-distributed random vector with covariance C U . In image processing applications, GSM may be used to model a cluster of wavelet coefficients that are neighbors in space, scale, and orientation. If we assume that z takes a fixed value for each cluster but varies across the image, then putting all z values together constitutes a variance field. DNT can then be accomplished by ν = Y/z, which produces a random vector that is Gaussian. This had been observed in empirical studies in <ref type="bibr" target="#b39">[40]</ref>, where z is replaced by a local estimation ẑ using a maximum-likelihood estimator <ref type="bibr" target="#b39">[40]</ref> </p><formula xml:id="formula_0">ẑ = arg max z {log p(Y |z)} = Y T C -1 U Y N . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>The Gaussianization produced by the DNT process largely reduces the complication in describing the distribution of the subband coefficient</p><formula xml:id="formula_2">x p m (x) = 1 √ 2πσ exp - x 2 2σ 2 (2)</formula><p>where only a single parameter σ needs to be recorded for each subband.</p><p>In addition to σ , the Kullback-Leibler divergence (KLD) <ref type="bibr" target="#b41">[42]</ref> between model Gaussian distribution, p m (x), and the true probability distribution of the DNT-domain coefficients, p(x), denoted by d( p m || p) is extracted as the second feature for each subband</p><formula xml:id="formula_3">d( p m || p) = p m (x) log p m (x) p(x) dx. (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>This improves model accuracy when the probability distribution is not exactly Gaussian.</p><p>The subband distortion of the distorted image can be evaluated by the KLD between the probability distribution of the original image, p(x), and that of the distorted image, q(x)</p><formula xml:id="formula_5">d( p||q) = p(x) log p(x) q(x) dx. (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>Direct computation of this quantity requires full access to p(x), which would require a large number of RR features to be described. Fortunately, the Gaussian model of the DNT coefficients (2) provides a good approximation. Therefore, we can estimate p(x) by</p><formula xml:id="formula_7">d( p||q) = p m (x) log p(x) q(x) dx (5) = d( p m ||q) -d( p m || p)<label>(6)</label></formula><p>where d( p m ||q) is the KLD between the model Gaussian distribution and the distribution computed from the distorted image. Although different types of distortions affect the statistics of the reference image in different manners, they are all summarized in (6) to a single distortion measure.</p><p>An added nice feature of this measure is that it equals zero when the two distributions p(x) and q(x) are identical.</p><p>At the receiver side, the KLD between the subband coefficient probability distributions of the original and distorted images is calculated as in <ref type="bibr" target="#b5">(6)</ref>. By assuming independence between subbands, the subband-level distortion measure of ( <ref type="formula" target="#formula_7">6</ref>) can be combined to provide an overall distortion assessment of the whole image by</p><formula xml:id="formula_8">D = log 1 + 1 D 0 K k=1 dk ( p k ||q k ) (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>where K is the total number of subbands, p k and q k are the probability distributions of the kth subband of the reference and distorted images, respectively, dk represents the KLD between p k and q k , and D 0 is a constant to control the scale of the distortion measure.</p><p>The limitation of the measure in <ref type="bibr" target="#b6">(7)</ref> is that it does not take into account the relationship (or structures) between the distortions across different subbands. Such distortion structure is a critical issue behind the philosophy of the SSIM approach <ref type="bibr" target="#b42">[43]</ref>, which attempts to distinguish structural and nonstructural distortions. To understand this better, let us look at the FR SSIM algorithm <ref type="bibr" target="#b0">[1]</ref>, which is based on measuring the similarities of luminance, contrast, and structure between local image patches x and y extracted from a reference and a distorted images</p><formula xml:id="formula_10">l(x, y) = 2μ x μ y + C 1 μ 2 x + μ 2 y + C 1 (8) c(x, y) = 2σ x σ y + C 2 σ 2 x + σ 2 y + C 2 (9) s(x, y) = 2σ xy + C 3 σ x σ y + C 3 (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where μ, σ , and σ represent the mean, standard derivation, and covariance of the image patches, respectively, and C 1 , C 2 , and C 3 are positive constants used to avoid instability when the denominators are close to zero. Subsequently, the local SSIM index is defined as the product of the three components, which gives</p><formula xml:id="formula_12">SSIM(x, y) = l(x, y) α c(x, y) β s(x, y) γ . (<label>11</label></formula><formula xml:id="formula_13">)</formula><p>The SSIM index of the whole image is obtained by averaging (or weighted averaging) the local SSIM indices obtained using a sliding window that runs across the image. Fig. <ref type="figure" target="#fig_1">2</ref> gives a graphical explanation in the vector space of image components, where the image components can be pixels, wavelet coefficients, or extracted features from the reference image. For the purpose of illustration, 2-D diagrams are shown here. However, the actual dimensions may be equal to the number of pixels or features being compared. The three vectors represent three reference images and the contours around them represent the images with the same distortion level using (a) MSE and (b) SSIM as the distortion/quality measures, respectively. The critical difference is in the shapes of the contours. Unlike MSE (where all three contours have the same size and shape), SSIM is adaptive according to the reference image. In particular, if the "direction" of distortion is consistent with the underlying reference (aligned with the direction of the reference vector), the distortion is nonstructural and is much less objectionable than structural distortions (the distortions perpendicular to the reference vector direction). The formulation of SSIM in <ref type="bibr" target="#b10">(11)</ref> provides a flexible framework to adjust the relative importance between structural (last term) and nonstructural (first two terms) distortions.</p><p>Here we borrow the design philosophy of FR SSIM, but apply it to a completely different domain of image representation. In particular, we attempt to distinguish structural and nonstructural changes of the cluster of statistical features extracted from the DNT coefficients from different subbands. This is intuitively sensible because the distortion that is consistent with the underlying signal in the feature vector space needs to be treated differently as compared to nonstructural distortions. For example, in the case where the distorted image is a globally contrast-scaled (contrast reduction or enhancement) version of the reference image, then the standard deviations of all subbands should scale by the same factor, which is considered consistent nonstructural distortion and is less objectionable than the case where the subband standard deviations change in different ways.</p><p>Let σ r and σ d represent the vectors containing the standard deviation σ values of the DNT coefficients from each subband in the reference and distorted images, respectively. We define a new RR distortion measure as</p><formula xml:id="formula_14">D n = g(σ r , σ d ) log 1 + 1 D 0 K k=1 dk ( p k ||q k ) . (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>Compared with <ref type="bibr" target="#b6">(7)</ref>, the key difference here is the added function g(σ r , σ d ) in the front. This function should serve the purpose of differentiating nonstructural from structural distortion directions in the feature vector space of subband σ values, so as to scale the distortion measure D in a way that penalizes more on structural than nonstructural distortions. Motivated by the successful normalized correlation formulation in SSIM <ref type="bibr" target="#b42">[43]</ref>, we define</p><formula xml:id="formula_16">g(σ r , σ d ) = σ r 2 + σ d 2 + C 2(σ r • σ d ) + C (<label>13</label></formula><formula xml:id="formula_17">)</formula><p>where a positive constant C is included to avoid instability when the dot product σ r • σ d is close to 0. This function is lower-bounded by 1 when σ r and σ d are fully correlated, or in other words, when their directions in the feature vector space are completely aligned (corresponding to nonstructural distortions). With the decrease of correlation, g(σ r , σ d ) increases, and thus imposes more penalty to structural distortions. Fig. <ref type="figure" target="#fig_2">3</ref> plots the D n values computed using distorted images from the LIVE database <ref type="bibr" target="#b43">[44]</ref> for four common distortion types at different distortion levels, and compares them with the corresponding FR SSIM values. Interestingly, for each fixed distortion type, D n exhibits a nearly perfect linear relationship with SSIM. We regard this as a consequence of the similarity between their design principle, even though the principle is applied to completely different domains of signal representation. The clean linear relationship helps in reducing the SSIM estimation problem to the estimation of the slope factor. Once the slope is determined, we can then use the following straight-line relationship to estimate SSIM:</p><formula xml:id="formula_18">Ŝ = 1 -α D n . (<label>14</label></formula><formula xml:id="formula_19">)</formula><p>The slope factor α in ( <ref type="formula" target="#formula_18">14</ref>) varies across distortion types and needs to be learned from examples. Specifically, we adopt a regression-by-discretization approach <ref type="bibr" target="#b44">[45]</ref>, which is a regression scheme that employs a classifier on a copy of the data that has the class attribute discretized, and the predicted value is the expected value of the mean class value for each discretized interval. The training images were obtained from six image databases described in Section III. The classification is performed using random forests <ref type="bibr" target="#b45">[46]</ref>, which are built using |σ r -σ d | and |k rk d | values in each subband as the attributes, where k r and k d are the kurtosis values of the DNT coefficients computed from the reference and distorted images, respectively. It has been observed with the help of ground-truth data that the values of α tend to lie in various closely packed clusters. Each cluster may contain images belonging to one distortion type. It provides a natural order to the distortion types and therefore does not require an undesirable distortion classification stage which limits the generalization capability of the proposed method. Therefore, the proposed method has the potential to extrapolate to extended distortion types that may not be included in the training samples.</p><p>The specification of our implementation is as follows. To extract RR features, the reference image is first decomposed into 12 subbands using a three-scale four-orientation steerable pyramid decomposition <ref type="bibr" target="#b46">[47]</ref>, which is a type of redundant wavelet transform that avoids aliasing in subbands. DNT is then performed using 13 neighboring coefficients, including 9 spatial neighbors from the same subband, 1 from parent subband, and 3 from the same spatial location in the other orientation bands at the same scale. The value of the constant C in ( <ref type="formula" target="#formula_16">13</ref>) is set to 0.1, which is found to be an insensitive parameter in terms of the performance of the proposed IQA measure. Three features, σ r , k r , and d( p m || p), are extracted for each subband, resulting in a total of 36 scalar RR features for a reference image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. VALIDATION OF RR-IQA ALGORITHM</head><p>Six databases were used to test the proposed algorithm and compare its performance with other IQA algorithms. The databases include.</p><p>1) The LIVE database <ref type="bibr" target="#b43">[44]</ref>  p) mean shift (intensity shift); and q) contrast change. 6) The Categorical Image Quality (CSIQ) database <ref type="bibr" target="#b53">[54]</ref> contains 866 distorted images of six types of distortions at 4 and 5 distortion levels. The distortion types include JPEG compression, JPEG2000 compression, global contrast decrements, additive pink Gaussian noise, and Gaussian blurring. To validate the proposed RR-SSIM algorithm, we first test how well it predicts FR SSIM. Fig. <ref type="figure" target="#fig_3">4</ref> shows the scatter plots obtained using all six databases, where each point in the plots represents one test image, and the vertical and horizontal axes are FR-SSIM and RR-SSIM, respectively. If the prediction is perfect, then the point should lie on the diagonal line. To provide a quantitative measure, Table <ref type="table" target="#tab_2">I</ref>     <ref type="bibr" target="#b43">[44]</ref> 0.0317 0.9432 Cornell A57 <ref type="bibr" target="#b47">[48]</ref> 0.0266 0.9299 IVC <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref> 0.0244 0.9211 Toyama-MICT <ref type="bibr" target="#b50">[51]</ref> 0.0119 0.9405 TID2008 <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref> 0.0303 0.9004 CSIQ <ref type="bibr" target="#b53">[54]</ref> 0.0339 0.9243 observed that, for all databases, the points are scattered close to the diagonal lines in Fig. <ref type="figure" target="#fig_3">4</ref> and the correlation coefficients are above 0.9, indicating good prediction accuracy of the proposed method. The breakdown prediction performance for individual distortion types in different databases are provided in Table <ref type="table" target="#tab_2">II</ref>.</p><p>The ultimate goal of RR-IQA algorithms is to predict subjective quality evaluation of images. Therefore, the more important test is to evaluate how well they predict subjective scores. For this purpose, we use five evaluation metrics to assess the performance of IQA measures.</p><p>1) PLCC after a nonlinear mapping between the subjective and objective scores. For the i th image in an image database of size N, given its subjective score o i [mean opinion score (MOS) or difference of MOS (DMOS) between reference and distorted images] and its raw objective score r i , we first apply a nonlinear function to r i given by <ref type="bibr" target="#b54">[55]</ref> </p><formula xml:id="formula_20">q(r ) = a 1 1 2 - 1 1 + exp [a 2 (r -a 3 )] +a 4 r +a 5 (<label>15</label></formula><formula xml:id="formula_21">)</formula><p>where a 1 -a 5 are model parameters found numerically using a nonlinear regression process in MATLAB optimization toolbox to maximize the correlations between subjective and objective scores. The PLCC value can then be computed as</p><formula xml:id="formula_22">PLCC = i (q i -q) * (o i -ō) i (q i -q) 2 * i (o i -ō) 2 . (<label>16</label></formula><formula xml:id="formula_23">)</formula><p>2) MAE is calculated using the converted objective scores after the nonlinear mapping described above</p><formula xml:id="formula_24">MAE = 1 N |q i -o i |.<label>(17)</label></formula><p>3) Root mean-squared (RMS) error is computed similarly as</p><formula xml:id="formula_25">RMS = 1 N (q i -o i ) 2 . (<label>18</label></formula><formula xml:id="formula_26">)</formula><p>4) Spearman's rank correlation coefficient (SRCC) is defined as</p><formula xml:id="formula_27">SRCC = 1 - 6 N i=1 d 2 i N(N 2 -1) (<label>19</label></formula><formula xml:id="formula_28">)</formula><p>where d i is the difference between the i th image's ranks in subjective and objective evaluations. SRCC is a nonparametric rank-based correlation metric, independent of any monotonic nonlinear mapping between subjective and objective scores. 5) Kendall's rank correlation coefficient (KRCC) is another nonparametric rank correlation metric given by</p><formula xml:id="formula_29">KRCC = N c -N d 1 2 N(N -1)<label>(20)</label></formula><p>where N c and N d are the number of concordant and discordant pairs in the dataset, respectively. Among the above metrics, PLCC, MAE, and RMS are adopted to evaluate prediction accuracy <ref type="bibr" target="#b55">[56]</ref>, and SRCC and KRCC are employed to assess prediction monotonicity <ref type="bibr" target="#b55">[56]</ref>. A better objective IQA measure should have higher PLCC, SRCC, and KRCC, with lower MAE and RMS values. All these evaluation metrics are adopted from previous IQA studies <ref type="bibr" target="#b54">[55]</ref>- <ref type="bibr" target="#b56">[57]</ref>. Only the distorted images in the six databases were employed in our tests (i.e., reference images are excluded). This avoids several difficulties in computing the evaluation metrics. Specifically, the reference images have infinite peak signal-to-noise-ratio (PSNR) values, making it hard to perform nonlinear regression and compute PLCC, MAE, and MSE values. In addition, since all reference images are assumed to have perfect quality, there are no natural relative ranks between them, resulting in ambiguities when computing SRCC and KRCC metrics.</p><p>The test results are given in Tables III and IV. To provide background comparisons, we have also included in the tables four other objective IQA algorithms, among which two are FR-IQA measures, i.e., PSNR and SSIM, and three are RR-IQA measures, i.e., wavelet marginal-based method <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref> and DNT marginal-based method <ref type="bibr" target="#b24">[25]</ref>. Other RR-IQA methods are not included in the comparison because they are not designed and tested for general-purpose applications. Although it is unfair to compare RR-IQA with FR-IQA measures, the PSNR and SSIM results supply useful references on the current status of RR approaches. To provide an overall evaluation of the IQA algorithms, we also calculate the direct and weighted average of PLCC, SRCC, and KRCC values across all six databases (where the weight assigned to a database is determined by the number of test images in a database). The average results are given in Table <ref type="table" target="#tab_2">IV</ref>. It can be seen that, in general, the proposed RR-SSIM method performs slightly inferior to SSIM (which is as expected) but significantly outperforms PSNR and the other RR-IQA methods under comparison.</p><p>Statistical significant analysis has been carried out based on variance-based hypothesis testing, which follows the approach introduced in <ref type="bibr" target="#b54">[55]</ref> and subsequently adopted by many later papers in the literature. Specifically, the residual difference between the DMOS and the predicted quality given by each objective IQA algorithm is assumed to be Gaussian-distributed and F-statistic is employed to compare the variances of two sets of sample points. With such a test, we can make a statistically sound judgment of the superiority or inferiority of one IQA algorithm over another. A statistical significance matrix is calculated and given in Table <ref type="table">V</ref>. Each entry in the table consists of six characters which correspond to the six publicly available databases in the order of {LIVE, A57, CSIQ, IVC, Toyama, TID2008}. The symbol "-" denotes that the two IQA methods are statistically indistinguishable, "1" denotes that the IQA method of the row is statistically better than that of the column, and "0" denotes that the IQA method of the column is better than that of the row. It can be observed that FR-SSIM performs the best among the IQA algorithms under comparison and the performance of the proposed RR-SSIM algorithm is quite close to that of SSIM and is superior to all other IQA methods being compared.</p><p>The assumption of Gaussianity is verified with the help of kurtosis values obtained from the prediction residuals. As in <ref type="bibr" target="#b54">[55]</ref>, the residual values are considered to be Gaussiandistributed if the kurtosis value lies between 2 and 4. The results of Gaussianity tests are given in Table <ref type="table" target="#tab_2">VI</ref>, where "1" means the distribution is considered Gaussian and "0" otherwise. It can be observed that the assumption is met in most cases with only a few exceptions.</p><p>To examine how the proposed RR-SSIM method performs for different distortion types, we compare it with five other recently proposed RR-IQA algorithms using individual distortion types as well as the "All data" case of the LIVE database. The results are given in Table <ref type="table" target="#tab_2">VII</ref>, where the best results for each distortion type are highlighted in bold. It can be observed that the proposed method exhibits highly competitive performance in most cases.</p><p>Finally, we compare the computational complexity of the proposed RR-SSIM method with five other RR-IQA algorithms. The results are reported in Table <ref type="table" target="#tab_2">VIII</ref>, where we present the average time taken per image, over all the images in the LIVE database, using a computer with Intel i7 processor at 2.67 GHz (the only exception is the method by DNT marginal <ref type="bibr" target="#b24">[25]</ref> RR-SSIM PSNR ------0 -0 0 0 0 1 ----0 0 -1 --0 0 -0 0 0 0 <ref type="bibr" target="#b23">[24]</ref> 0 ----1 0 0 0 0 0 0 ------0 -----0 0 0 0 0 0 DNT Marginal <ref type="bibr" target="#b24">[25]</ref> 1 -0 --1 0 0 0 0 0 0</p><formula xml:id="formula_30">SSIM 1 -1 1 1 1 ------ 1 1 1 1 1 1 1 1 1 1 1 1 1 --1 -- Wavelet Marginal</formula><formula xml:id="formula_31">1 ----- ------ 0 -0 0 0 0 RR-SSIM 1 -1 1 1 1 0 --0 -- 1 1 1 1 1 1 1 -1 1 1 1 ------</formula><p>Ma et al. <ref type="bibr" target="#b59">[60]</ref>, which was tested on a slightly faster computer). This measurement provides a rough estimate of the relative computational complexity between different RR-IQA algorithms, as no code optimization has been done. It can be seen that the proposed method takes only slightly more time than most of the other methods under comparison, mainly due to the computation of the DNT. The additional computational cost is compensated by the improved quality prediction performance, as shown in Table <ref type="table" target="#tab_2">VII</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMAGE REPAIRING USING RR FEATURES</head><p>Since the RR features reflect certain properties about the reference image and these properties may be altered in the distorted image, they may be employed to partially "repair" the distorted image. Here we provide an example that uses DNT-domain RR features to correct blurred images without any knowledge about the blur kernel.</p><p>Since blur reduces energy at mid-and high-frequencies, the subband standard deviation σ d of DNT coefficients in the distorted image is smaller than that of the reference image σ r . A straightforward way to enforce a "corrected" image to have the same statistical properties as the reference image is to scale up all DNT coefficients in the subband of the distorted image by a fixed scale factor, followed by an inverse DNT to create a reconstructed image. In practice, however, inverting a DNT transform is a nontrivial issue that requires specific conditions of the coefficients and may involve computationally expensive algorithms <ref type="bibr" target="#b60">[61]</ref>.</p><p>Here we propose a different approach that attempts to match DNT-domain statistics but avoids direct inversion of DNT. The idea is to use the DNT-domain statistics to estimate the scale factors and then apply them in the wavelet domain rather than DNT domain. As a result, only inverse wavelet transform is necessary, and the remaining question becomes whether the    desired scale ratio in the DNT domain can be well matched by scaling in the wavelet domain. To ensure this, we apply our approach in an iterative manner, and the resulting algorithm is given by Algorithm 1. In our experiment, we find that this iterative algorithm converges quickly, and typically three iterations are enough to reconstruct a stable repaired image (and thus J = 3 in Algorithm 1) that matches the DNTdomain statistics quite well. This is demonstrated in Fig. <ref type="figure" target="#fig_4">5</ref>, which compares the subband histograms of the reference, distorted, and repaired DNT coefficients. It can be observed that the histogram of the scaled DNT coefficients very well approximates that of the reference image. A similar design philosophy of iteratively synthesizing images by matching desirable statistical features has been used before in the literature for texture synthesis, e.g., <ref type="bibr" target="#b61">[62]</ref>. An interesting feature of the above image deblurring process is that it does not require any information about the blur kernel. Depending on the nature of the blur process, the energy reductions at different subbands are different. For example, out-of-focus blur may lead to uniform energy reduction in all orientation subbands, while motion blur could result in more significant energy reduction along one orientation against another. Since the scale factor s in our algorithm is computed for individual subbands independently, it could automatically adapt the energy correction factors based on the energy reduction occurred in individual subbands. Fig. <ref type="figure" target="#fig_6">6</ref> provides an example, where the homogeneously Gaussian blurred and directionally motion blurred images at different angles are deblurred using exactly the same image repairing algorithm described above. All repaired images appear to be much sharper and have higher contrast than their blurred versions. The visual effect is also reflected by both FR-SSIM and the proposed RR-SSIM evaluations.</p><formula xml:id="formula_32">PSNR 1 1 1 1 1 1 SSIM 1 1 0 0 1 1 Wavelet Marginal [24] 1 1 1 1 1 1 DNT Marginal [25] 1 1 1 1 1 1 RR-SSIM 1 1 1 0 1 1</formula><p>One needs to be aware that the RR features only provide limited amount of additional information about the reference image and such information is global in the current implementation (due to the nature of the extracted RR features). Therefore, the same repairing process may or may not work as effectively as we observe in Fig. <ref type="figure" target="#fig_6">6</ref> for the types of image distortions other than linear blur. In the future, more advanced image repairing methods may be developed that make the best use of the RR features as side information in the image repairing process, though these methods are beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We proposed an RR-IQA algorithm in an attempt to approximate FR-SSIM by making use of DNT-domain image statistical properties and the design principle of the SSIM approach. Experimental results using six publicly available subject-rated image databases showed that the proposed RR-SSIM method exhibits good correlations with not only FR-SSIM but also subjective evaluations of image quality over a wide variety of image distortions. We also demonstrated the concept of image repairing by iteratively matching the DNT-domain statistical properties (available as RR features) of the reference image. The proposed method has a fairly low RR data rate (36 scalar features per image in the current implementation) and has good potential to be employed in visual communications applications for quality monitoring, streaming, and image repairing tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. General framework for the deployment of RR-IQA systems with image repairing capability.</figDesc><graphic coords="2,108.47,53.45,394.22,129.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>OFig. 2 .</head><label>2</label><figDesc>Fig. 2. Equal-distortion contours with respect to the central reference vectors. (a) MSE measure. (b) SSIM measure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Relationship between D n and SSIM for blur, JPEG compression, JPEG2000 compression, and noise contamination distortions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Scatter plots of SSIM versus RR-SSIM estimation Ŝ for six test databases. (a) LIVE Image Database. (b) Cornell A57 Database. (c) CSIQ Database. (d) IVC Database. (e) Toyama-MICT Database. (f) TID 2008 Database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. DNT-coefficient histograms of original, distorted, and repaired images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1 3 )</head><label>13</label><figDesc>Iterative image repairing algorithm 1) Initialization: Let j = 0, x(0) = y, where y is the distorted image 2) Repeat J times a) Wavelet transform: Compute wavelet transform of x( j ) , resulting in wavelet coefficients ω b) DNT stage: Compute DNT from ω, resulting in DNT coefficients ν; For all i , in the i th subband, calculate std of DNT coefficients σ i ν c) Scaling factor calculation: For all i , in the i th subband, compute the scale factor s i = σ i r /σ i ν , where σ i r is the std of DNT coefficients of the reference image (obtained as RR features) d) Wavelet coefficient scaling: For all i , in the i th subband, let ω new = s i ω e) Image reconstruction: Compute inverse wavelet transform of ω new , resulting in x( j +1) f) Increase j by 1 Report reconstructed image: x = x(J )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Repairing homogeneously and directionally burred images using RR features. (a) Original "building" image (cropped for visibility). (b) Homogeneously blurred image, SSIM = 0.7389, ( Ŝ) = 0.7118. (c) Repaired image SSIM = 0.9142, ( Ŝ) = 0.9327. (d) Directionally blurred image (0 degree), SSIM = 0.6734, ( Ŝ) = 0.6821. (e) Repaired image SSIM = 0.7991, ( Ŝ) = 0.8063. (f) Directionally blurred image (45 degree), SSIM = 0.6612, ( Ŝ) = 0.6324. (g) Repaired image SSIM = 0.7896, ( Ŝ) = 0.8135.</figDesc><graphic coords="10,192.59,180.17,110.17,110.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I</head><label>I</label><figDesc></figDesc><table><row><cell cols="3">MAE AND PLCC COMPARISONS BETWEEN SSIM AND</cell></row><row><cell cols="3">RR SSIM ESTIMATION FOR SIX DATABASES</cell></row><row><cell>Database</cell><cell>MAE</cell><cell>PLCC</cell></row><row><cell>LIVE</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the anonymous reviewers for their valuable comments which greatly helped improve this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Natural Sciences and Engineering Research Council of Canada and the Ontario Early Researcher Award Program. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Eli Peli.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiscale structural similarity for image quality assessment</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 37th Asilomar Conf. Signals, Syst., Comput</title>
		<meeting>IEEE 37th Asilomar Conf. Signals, Syst., Comput<address><addrLine>Pacific Grove, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-11">Nov. 2003</date>
			<biblScope unit="page" from="1398" to="1402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Information content weighting for perceptual image quality assessment</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1185" to="1198" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An information fidelity criterion for image quality assessment using natural scene statistics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Veciana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2117" to="2128" />
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">VSNR: A wavelet-based visual signalto-noise ratio for natural images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hemami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2284" to="2298" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Most apparent distortion: Fullreference image quality assessment and the role of strategy</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chandler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electron. Imag</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11006" to="11007" />
			<date type="published" when="2010-03">Jan.-Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mean squared error: Love it or leave it? A new look at signal fidelity measures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="117" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the mathematical properties of the structural similarity index</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Vrscay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1488" to="1499" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SSIM-motivated rate distortion optimization for video coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="516" to="529" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SSIM-inspired divisive normalization for perceptual video coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th IEEE Int. Conf. Image Process</title>
		<meeting>18th IEEE Int. Conf. Image ess<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011</date>
			<biblScope unit="page" from="1657" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CW-SSIM based image classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th IEEE Int. Conf. Image Process</title>
		<meeting>18th IEEE Int. Conf. Image ess<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011</date>
			<biblScope unit="page" from="1249" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SSIM-based non-local means image denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th IEEE Int. Conf. Image Process</title>
		<meeting>18th IEEE Int. Conf. Image ess<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">Sep. 2011</date>
			<biblScope unit="page" from="217" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SSIM-inspired image denoising using sparse representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vrscay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. IEEE Int. Conf. Acoust. Speech Signal Process.</title>
		<imprint>
			<biblScope unit="page" from="1121" to="1124" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<title level="m">Modern Image Quality Assessment</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="2006-03">Mar. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A generalized block-edge impairment metric for video coding</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="317" to="320" />
			<date type="published" when="1997-11">Nov. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Blind measurement of blocking artifacts in images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2000-09">Sep. 2000</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="981" to="984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Vision-model-based impairment metric to evaluate blocking artifact in digital video</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2002-01">Jan. 2002</date>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="154" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">No-reference perceptual quality assessment of JPEG compressed images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2002-09">Sep. 2002</date>
			<biblScope unit="page" from="477" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">No-reference quality assessment using natural scene statistics: JPEG2000</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cormack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1918" to="1927" />
			<date type="published" when="2005-11">Nov. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Perceptual blur and ringing metrics: Application to JPEG2000</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marziliano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dufaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process.: Image Commun</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="172" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Blind image quality assessment</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2002-09">Sep. 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="449" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Objective video quality assessment</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Handbook of Video Databases: Design and Applications</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Furht</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Marques</surname></persName>
		</editor>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2003-09">Sep. 2003</date>
			<biblScope unit="page" from="1041" to="1078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reduced-reference image quality assessment using a wavelet-domain natural image statistic model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2005-01">Jan. 2005</date>
			<biblScope unit="volume">5666</biblScope>
			<biblScope unit="page" from="149" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quality-aware images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1680" to="1689" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reduced-reference image quality assessment using divisive normalization-based image representation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="211" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Spatio-temporal distortion metrics for inservice quality monitoring of any digital video system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Pinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3845</biblScope>
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A reduced-reference perceptual quality metric for in-service image quality assessment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kusuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zepernick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint 1st Workshop Mobile Future Symp. Trends Commun</title>
		<meeting>Joint 1st Workshop Mobile Future Symp. Trends Commun</meeting>
		<imprint>
			<date type="published" when="2003-10">Oct. 2003</date>
			<biblScope unit="page" from="71" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reduced reference picture quality estimation by using local harmonic amplitude information</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P</forename><surname>Gunawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghanbari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. London Commun. Symp</title>
		<meeting>London Commun. Symp</meeting>
		<imprint>
			<date type="published" when="2003-09">Sep. 2003</date>
			<biblScope unit="page" from="137" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reduced-reference image quality assessment using distributed source coding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Varodayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Girod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Multimedia Exposit</title>
		<meeting>IEEE Int. Conf. Multimedia Exposit</meeting>
		<imprint>
			<date type="published" when="2008-04">Apr. 2008</date>
			<biblScope unit="page" from="609" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An image quality assessment method based on perception of structural information</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carnec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Le</forename><surname>Callet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barba</surname></persName>
		</author>
		<idno>III-185-III-188</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2003-09">Sep. 2003</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual features for image quality assessment with reduced reference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carnec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Le</forename><surname>Callet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2005-09">Sep. 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="421" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Possible principles underlying the transformation of sensory messages</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
		</author>
		<editor>Sensory Communication, W. A. Rosenblith</editor>
		<imprint>
			<date type="published" when="1961">1961</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="217" to="234" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Natural image statistics and neural representation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1193" to="1216" />
			<date type="published" when="2001-05">May 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A reducedreference structural similarity approximation for videos corrupted by channel errors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tagliasacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Valenzise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naccari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tubaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multim. Tools Appl</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="471" to="492" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Normalization of cell responses in cat striate cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Neural Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="198" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A model of neuronal responses in visual area MT</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="743" to="761" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visual adaptation as optimal information transmission</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3960" to="3974" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Human luminance pattern mechanisms: Masking experiments require a new model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Foley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1710" to="1719" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Model of visual contrast gain control and pattern masking</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2379" to="2391" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Scale mixtures of Gaussians and the statistics of natural images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="855" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Reduced-reference image quality assessment using divisive normalization-based image representation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="211" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Image and Video Quality Assessment Research at LIVE</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Cormack</surname></persName>
		</author>
		<ptr target="http://live.ece.utexas.edu/research/quality/" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Rule-based machine learning methods for functional prediction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Indurkhya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="383" to="403" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Shiftable multiscale transforms</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="587" to="607" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">VSNR: A wavelet-based visual signal-to-noise ratio for natural images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Hemami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2284" to="2298" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Subjective Quality Assessment IRCCYN/IVC Database</title>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Callet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Autrusseau</surname></persName>
		</author>
		<ptr target="http://www.irccyn.ec-nantes.fr/ivcdb/" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pseudo no reference image quality metric using perceptual data hiding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ninassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Callet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Autrusseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">6057</biblScope>
			<biblScope unit="page" from="60570G" to="60571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Horita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawayoke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Parvez</surname></persName>
		</author>
		<ptr target="http://mict.eng.u-toyama.ac.jp/mictdb" />
		<title level="m">Mict Image Quality Evaluation Database</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">TID2008 -A database for evaluation of full -reference visual quality assessment metrics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ponomarenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lukin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zelensky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Battisti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Modern Radioelectron</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="30" to="45" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Tampere Image Database TID</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ponomarenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<ptr target="http://www.ponomarenko.info/tid" />
		<imprint>
			<date type="published" when="2008">2008. 2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Categorical Image Quality (CSIQ) Database [Online</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chandler</surname></persName>
		</author>
		<ptr target="http://vision.okstate.edu/csiq" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A statistical evaluation of recent full reference image quality assessment algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3440" to="3451" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Final report from the video quality experts group on the validation of objective models of video quality assessment</title>
		<idno>COM 9-80-E</idno>
	</analytic>
	<monogr>
		<title level="m">Video Quality Experts Group (VQEG)</title>
		<meeting><address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-04">Apr. 2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Metrics performance comparison for color image database</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ponomarenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Battisti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Astola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lukin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Int. Workshop Video Process</title>
		<meeting>4th Int. Workshop Video ess<address><addrLine>Scottsdale, AZ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-01">Jan. 2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Reduced reference image quality assessment based on Weibull statistics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int</title>
		<meeting>2nd Int</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Reduced reference image quality assessment based on statistics of edge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2011-01">Jan. 2011</date>
			<biblScope unit="volume">7876</biblScope>
			<biblScope unit="page">787611</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Reduced-reference image quality assessment using reorganized DCT-based image representation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Ngan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="824" to="829" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Non-linear image representation for efficient perceptual coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Malo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Epifanio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="80" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A parametric texture model based on joint statistics of complex wavelet coefficients</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="71" />
			<date type="published" when="2000-12">Dec. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
