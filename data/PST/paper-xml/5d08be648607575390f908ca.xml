<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">QoSMT: Supporting Precise Performance Control for Simultaneous multithreading Architecture</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xin</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yaoyang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bowen</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zihao</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xusheng</forename><surname>Zhan</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Huawei Technologies Co</orgName>
								<address>
									<settlement>Ltd</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huizhe</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sa</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ningmei</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ninghui</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yungang</forename><surname>Bao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory of Computer Architecture</orgName>
								<orgName type="institution">ICT</orgName>
								<address>
									<country>CAS</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">QoSMT: Supporting Precise Performance Control for Simultaneous multithreading Architecture</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3330345.3330364</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>SMT Interference</term>
					<term>Data Center</term>
					<term>QoS</term>
					<term>Performance Predictability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Simultaneous multithreading (SMT) technology improves CPU throughput, but also causes unpredictable performance fluctuations for co-located workloads. Although recent major SMT processors have adopted some techniques to promote hardware support for quality-of-service (QoS), achieving both precise performance control and high throughput on SMT architectures is still a challenging open problem.</p><p>In this paper, we perform some comprehensive experiments on real SMT systems and cycle-accurate simulators. From these experiments, we observe that almost all in-core resources may suffer from severe contention as workloads vary. We consider this observation as the fundamental reason leading to the challenging problem above. Thus, we introduce QoSMT, a novel hardware scheme that leverages a closed-loop controlling mechanism to enforce precise performance control for specific targets, e.g. achieving 85%, 90% or 95% of the performance of a workload running alone respectively. We implement a prototype on GEM5 simulator. Experimental results show that the control error is only 1.4%, 0.5% and 3.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Computer systems organization → Cloud computing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Simultaneous multithreading (SMT) technology is widely adopted in contemporary general-purpose processors. It improves the throughput of a processor by issuing instructions from multiple threads to achieve better utilization of in-core resources such as instruction queue (IQ), reorder buffer (ROB) and load-store queue (LSQ).</p><p>However, SMT may result in unpredictable performance variations when multiple applications run simultaneously on an SMT processor. Recent work has shown that applications may suffer varying performance degradation by as high as 70% due to SMT induced interference <ref type="bibr" target="#b30">[33]</ref>. To confirm this, we conduct some experiments on an Intel i7-4770 server with Hyper-Threading <ref type="bibr" target="#b19">[21]</ref>. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, SMT may hurt the performance of an application (e.g. perlbench) by 1.1X-2.1X when it is co-located with different applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1: Performance variations of Spec2006 workloads</head><p>Recognizing the SMT-induced interference problem, Intel adopts a static partitioning approach to segregate two threads on shared pipeline resources such as IQ and ROB <ref type="bibr" target="#b19">[21]</ref>. But it is inflexible for dynamic resource adjustment and may degrade both threads' performance due to reduced pipeline resources. IBM's POWER series processors allow to assign different priorities to workloads. And they provide different instruction fetch rates to guarantee the performance of high priority workloads <ref type="bibr" target="#b25">[28]</ref>. But this approach makes other workloads hard to utilize in-core resources, against the original motivation of SMT. Although there is previous literature <ref type="bibr" target="#b8">[9]</ref> [10]on hardware design for guarantee of quality-of-service (QoS) on SMT processors, most of their designs require profiling in-advance.</p><p>QoSMT: Supporting Precise Performance Control for SMT ICS '19, June 26-28, 2019, Phoenix, AZ, USA However, due to the limitation of privacy data protection and high operation and maintenance cost, the data center is reluctant to accept the off-line profiling.</p><p>Industrial companies have been struggling with the unpredictable performance caused by SMT. For instance, Microsoft even disables Hyper-Threading on Xeon servers in many data centers <ref type="bibr">[23]</ref>. They hope it can help to guarantee predictable performance for better user experience. However, this will waste tremendous computing resources. Alibaba solicits solutions to perform load balancing among tens of thousands of Intel Xeon servers with Hyper-Threading enabled. This is because unpredictable performance on a single server brought by SMT can make load balancing very difficult in large scale data centers. <ref type="bibr" target="#b0">[1]</ref> In this paper, we ask the following question: Can we obtain guaranteed performance of a high-priority workload on an SMT core, meanwhile achieving reasonable overall throughput? Specifically, multiple workloads are allowed to co-run on an SMT core, but at least one workload with higher priority such as a latency-sensitive workload should strictly satisfy its performance target. This target can be described as, for example, "guaranteeing 90% of the performance of the workload's solo execution".</p><p>We introduce QoSMT, a novel hardware mechanism that is able to guarantee real-time performance requirements for higher priority workloads under SMT-enabled environments without profiling in advance. The key idea is to quantitatively measure SMT-induced performance degradation at run time, locate critical interference caused by lower priority workloads, and make up the performance loss by dynamic resource adjustment. To understand this, consider multiple workloads co-running on an SMT core and a high-priority workload among them * such as web search. The high-priority workload requires achieving at least 90% of the performance of its solo mode(the workload is executed alone on a processor)in term of IPC (instructions per cycle). To this end, we divide the execution into a series of epoches each of which contains tens of thousands cycles. During each epoch, QoSMT will first predict the execution time of the workload's solo mode (T solo ) online, calculate the performance loss between the measured execution time (T shar e ) and T solo . If T sol o T shar e &lt; 0.9, an interference detector will identify the microarchitecture resource contributing most to the performance loss. At last, to eliminate performance interference, a controlling unit will dynamically adjust the resource allocation until the performance requirement is satisfied. To realize this, we need to address these challenges:</p><p>(i) How to identify critical in-core resources causing performance loss?</p><p>There are many microarchitecture resources shared in an SMT core including IQ, ROB, LSQ, instruction L1 cache, data L1 cache, L2 cache and so forth. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, every resource could suffer severe contention. At a high level, we define events of severe interference for each resource, collect stall cycles caused by these events and rank resources according to stall cycles as well as their criticality (see 2.2).</p><p>(ii) How to precisely quantify a workload's performance loss due to SMT?</p><p>When multiple workloads are co-running on an SMT core, it is almost impossible using traditional performance counters to obtain a workload's performance in the solo mode because it is hard to decouple the SMT induced interference from these performance counters. However, performance in solo mode is necessary for calculating performance loss. To address this challenge, we propose a shadow solo-cycle accounting (SSCA) methodology, which monitors all shared in-core resources on the fly and counts the stall cycles caused by other workloads (see 4.2).</p><p>(iii) How to perform timely resource adjustment to meet a workload's performace requirements?</p><p>Hardware-software codesign is needed to address this issue: First, we leverage a mechanism similar to Intel's model-specific register(MSR) <ref type="bibr">[19]</ref> to allow workloads to convey their performance requirements to the underlying hardware. Second, we add control logic to shared resources to enable dynamic resource adjustment. Finally, we design an online algorithm, which takes IPC solo , IPC shar e and status of critical resources as inputs and then tells how many resources should be adjusted. Thus, these operations form a closed-loop controlling mechanism that consists of monitoring, decision and adjustment. (see <ref type="bibr">§4.3)</ref> To show the feasibility of our design, we have implemented QoSMT on GEM5 simulator <ref type="bibr" target="#b2">[3]</ref>. Experimental results on SPECCPU 2006 show that QoSMT is able to achieve performance control for different performance targets (i.e., 85%, 90% and 95% of IPC solo ) with an average error of 1.4%, 0.5% and 3.6%.</p><p>To summarize, we make the following contributions:</p><p>• We demonstrate a thorough analysis of interference induced by SMT from micro-architecture level and reveal two findings that provide important insights about supporting performance guarantee on SMT processors. • We propose a methodology that enables precise performance control with high utilization, i.e. QoSMT which leverages a shadow solo-cycle accounting framework and closed-loop controlling algorithms. • We implement a prototype of QoSMT on GEM5 simulator.</p><p>Through comprehensive experiments, we demonstrate the effectiveness of QoSMT for guaranteeing specific performance target for a given workload while improving SMT resource utilization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section, we briefly introduce pros and cons of SMT, and then illustrate resources causing contention on SMT. Finally, we present current techniques of eliminating contention adopted by three commodity processors, i.e., Intel's SkyLake, IBM's POWER8 and AMD's Zen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SMT's Pros and Cons</head><p>To improve processors' throughput, Tullsen et al. proposed simultaneous multithreading (SMT) that allows multiple logical threads to run on a single physical processor to better utilize pipeline resources.</p><p>In modern commodity multicore processors, each physical core supports two to eight logical threads. Intel and AMD's processors <ref type="bibr" target="#b1">[2]</ref> usually have two logical threads while IBM's POWER8 <ref type="bibr" target="#b26">[29]</ref>supports eight logical threads.</p><p>Many studies demonstrate the efficacy of SMT. For instance, in light of Madonna et.al's evaluation <ref type="bibr" target="#b18">[20]</ref>on IBM POWER8 processors with SMT enabled, running eight instances of 433.milc from SPECCPU2006 on four dual-thread physical cores can approach the performance of running them on eight different physical cores.</p><p>However, resource sharing within a physical core may cause performance degradation for logical threads. As illustrated in previous literature <ref type="bibr" target="#b30">[33]</ref>, a logical thread may suffer performance degradation by up to 70% when its demanding resources are occupied by other threads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Resource Contention on SMT</head><p>In general, there are many shared resources in SMT processors, including: fetch unit, instruction queue (IQ), reorder buffer (ROB), load/store queue (LSQ), L1 I-cache/D-cache, and L2 cache and so forth. A shared resource may encounter a "stall event" due to resource contention, which will prevent instructions from being executed in pipelines. To better understand the SMTinduced interference, We divide these shared resources into three categories according to previous studies <ref type="bibr" target="#b10">[11]</ref>.</p><p>Front-end resources: Instruction fetch unit is the major shared front-end resource. Fetch unit works like a time-sharing scheduler that can fetch one or more instructions during each time slice. In SMT processors, all logical threads share these time slices with a scheduling policy such as round-robin policy. Thus, a fetch stall event may happen for one logical thread when time slices are occupied by other threads.</p><p>Back-end resources: The shared back-end resources include ROB, IQ, and LSQ. A stall event of back-end resources happens when a load or store instruction suffers a long cache miss and finally causes dispatching stall because of back-end resources getting exhausted without commit-ready instructions.</p><p>Cache resources: All threads share the same cache hierarchy. Unfortunately, shared cache contention can result in significant performance degradation. To address this issue, Intel's processors recently support Cache Allocation Technology (CAT) <ref type="bibr" target="#b17">[18]</ref> for L3 cache. But L1 and L2 caches shared by multiple threads still suffer severe contention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Commodity Processors' Efforts</head><p>As illustrated in Table <ref type="table" target="#tab_0">1</ref>, many commodity processors have devoted efforts to alleviating the SMT interference problem.</p><p>Intel Skylake and AMD ZEN attempt to guarantee fairness for two logical threads through statically partitioning back-end resources such as ROB and LSQ. However, static back-end resource partitioning is insufficient to completely eliminate interference. To confirm this argument, we conducted experiments on a server with Intel i7-4770 processors that support Hyper-Threading feature [19] and static partitioning. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, when co-located with other applications on a physical core, almost all applications suffer from performance loss, by even up to 2.1X (e.g. perlbench).</p><p>IBM POWER8 focuses more on controlling front-end resource and adopts an aggressive policy to support differentiated instruction fetch rates to enforce performance guarantee. But the performance Since there is little literature about the impact of the three categories of shared resources on performance variations, it seems that processor vendors do not reach a consensus on how to address the challenge. Thus, it is worthwhile to conduct a comprehensive investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OBSERVATIONS ON SMT INTERFERENCE</head><p>In this section, we present some more in-depth analysis of resources contention by cycle-accurate simulations (see experimental setup in Section 5.1). Specifically, we perform two sets of experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Static Partitioning</head><p>Intel's processors adopt static partitioning for back-end resources, but still exhibit severe performance fluctuations. Since the instruction fetch unit of front-end resources employs a fair round-robin policy, which results in the same effect of static partitioning, a possible reason is because cache resources such as L1/L2 caches are all shared. To test the assumption, we perform experiments to compare three management polices for back-end and cache resources as follows: We implement all these policies on a GEM5 based SMT simulator and run seven workloads of SPECCPU 2006 that are randomly selected on the simulator. For each workload, we run it with other six workload and then measure its averaged IPC and performance variation. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, the All-Shared policy exhibits worst while the Complete-SP policy performs best in terms of performance variation. For instance, the variation of zeusmp's normalized IPC decreases by an order of magnitude, from 0.1 to 0.01. For the Back-end-SP policy, its performance variation is non-trivial,  which means that L1/L2 cache contention should not be neglected if we want to achieve precise performance control.</p><p>However, although the Complete-SP policy is beneficial for decreasing performance variation, it is still insufficient for precise performance control due to two reasons. A fixed quota allocation policy does not guarantee a fixed predictable performance for any given workload. Different workloads may suffer from different performance degradation. For instance, even with Complete-SP policy that each workload gets the same amount of resources, bzip2's normalized IPC decreases by 20% while the normalized IPC of gobmk and hmmer decrease by more than 40%. In addition, static partitioning reduces the amount of available resource capacity for each logical thread, which can result in large performance degradation. Take gobmk as an example, its normalized IPC decreases by almost 30%, compared to the Back-end-SP policy. Therefore, dynamic resource partitioning is necessary to achieve our goal of precise performance control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Demand of Dynamic Resource Partitioning</head><p>We further investigate which resources may require dynamic partitioning. We co-run gcc and omnetpp with six other workloads randomly selected from SPECCPU 2006.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows the behavior of different shared resources. The upper two figures depict normalized stall cycles caused by stall events of back-end resources, while the bottom two figures illustrate the normalized MPKI (miss per kilo-instruction) of cache resources. According to the figures, our findings are as follows:</p><p>• Finding 1. Almost each component suffers from severe interference and potentially becomes a bottleneck. For example, for gcc, the stall cycles of LQ increase modestly by only 3 times while the stall cycles of IQ increase by more than 48 times, indicating that LQ is not a critical resources for gcc. But LQ's stall cycles increase sharply by about 10 times when omnetpp co-runs with mcf.</p><p>• Finding 2. Even one pair of workloads can result in contention on multiple components.</p><p>For example, the workload pair of omnet and hmmer suffer from the contention of not only ROB but also ICache. The case of omnet and mcf is even worse, incurring significant contention of many components including IQ, LQ, SQ, ICache and LLC.</p><p>These findings suggest that resource requirements of workload mixtures change significantly and it is difficult to meet the resource requirements of each logical thread through pre-fixed static resource partitioning. In order to guarantee the performance of a targeted thread, a flexible dynamic resource partitioning for both back-end and cache resources is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGN OF QOSMT</head><p>In this paper, we propose QoSMT that aims to guarantee performance of high-priority threads (HPT) while achieving reasonable overall throughput on SMT processors. QoSMT consists of two modules: contention detection module (CDM) and policy enforcement module (PEM). CDM is responsible for collecting and recording contention data on the three categories of shared resources. Meanwhile, PEM periodically takes the contention data as input to perform dynamic resource allocation.</p><p>There are three main challenges in implementing the two modules described above: (1) CDM needs to identify the most severely interfered resources; (2) CDM needs to predict performance in solomode with SMT enabled; (3) PEM should be able to do efficient dynamic controlling in response to the information gathered above.</p><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the overview design of QoSMT. Among all the components, 1 ○, 3 ○, 5 ○ are responsible for both contention detection and policy enforcement; 2 ○, 4 ○, 7 ○ belongs to CDM; 6 ○ are paths for information gathering.</p><p>Figure <ref type="figure" target="#fig_3">4</ref> also illustrates the QoSMT process of dynamically guaranteeing HPT performance through a real fragment from an evaluation where HPT:astars is co-running with LPT:cactusADM. The whole process is divided into four steps:</p><p>Step1: At beginning, the user or administrator specifies a performance target for the HPT by configuring the MSR register.</p><p>Step2: CDM keeps identifying various interference events with the help of CMT(cache miss table) and counts the stall cycles of each interference event in the CRT(contention resource table) 7</p><p>○. Step2, the HPT's solo performance will be predicted.</p><p>Step4: If the current HPT performance fails to reach the target, PEM will conduct dynamic resource allocation operation. PEM will reallocate the resource of TOP rank in CRT from LPT to HPT. For example, t1 in the figure shows that the current performance does not meet the requirements, and ROB is the performance bottleneck. So HPT gets more ROB resources, increasing the performance .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Critical Resource Detection Mechanism</head><p>In order to guide dynamic resources allocation, we first need to detect the true interference events caused by SMT among various of pipeline stall events. And then find out the most severely interfered resources (critical resources). As defined in earlier sections 2.2, we need to detect front-end contention, back-end contention and cache interference. For the sake of logical sequence, we explain the three detection schemes in reverse order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Cache Interference Detection.</head><p>The main difficulty in detecting cache interference is:</p><p>• How to distinguish whether a HPT cache request miss is caused by low priority thread (LPT)'s eviction or by HPT itself;</p><p>To solve the problem, we devise a shadow tag 1 ○ mechanism. The shadow tag maintains a private LRU stack for HPT. For each cache access, only the access requests issued by HPT will access shadow tag. When an HPT cache miss occurs, but if it hits in the shadow tag, CDM treats this cache miss as an interference event.</p><p>To record the detection results, we design a cache miss table(CMT) 2 ○. CMT has three parts, corresponding to I-cache, D-Cache and L2-Cache respectively. Each part has the same number of entries as the number of MSHRs, which is the maximum number of outstanding miss allowed. CMT is synchronized with MSHR allocation and deallocation. Whenever an MSHR is allocated, its corresponding valid bit in CMT is set, the ID of the logical thread that initiates the cache access will be recorded in the TID field. If a shadow tag hits, we also need to set the interference bit. Whenever an MSHR is released, its corresponding valid bit and interference bit in CMT should be cleared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Back-end Contention Detection.</head><p>There are two main difficulties in detecting back-end contention:</p><p>• How to distinguish whether a back-end stall is caused by LPT occupying shared resources or by HPT itself; • How to trace the root cause of back-end stall under SMT.</p><p>To solve the first problem, we bring the idea of shadow tag to other components, such as shadow ROB, shadow IQ, shadow LQ and shadow SQ 3 ○. We use the shadow queue to emulate HPT's use of the original queue when it would run in solo mode (with the whole physical core monopolized). When the real queue for HPT running in SMT-mode is not full, behaviors of a shadow queue are actually consistent with those of the real queue. When the real queue for HPT is full, the shadow queue's entries continue to be allocated until it reaches the max size of original queue. Once the shadow queue is exhausted, the subsequent stall events should also occur in solo mode, which are caused by HPT itself. As a consequence, by comparing the full state of real queue and shadow queue, we can tell whether SMT induced contention is happening.</p><p>Below we will take shadow ROB as an example to illustrate the maintenance of shadow queue. The shadow ROB can be implemented as a counter, and is incremented whenever an HPT instruction is inserted into ROB. When the ROB blocks HPT, CDM keeps incrementing the shadow ROB counter. When the real ROB is full but the shadow ROB is not yet, the ROB contention is happening. When both of the two queues reach the max size, we will not increment the stall cycles in CRT. Shadow ROB counter is decremented since an HPT instruction is retired from ROB. The other three shadow queue counters are maintained similarly.</p><p>Upon a long-latency load miss, the processor back-end will stall because of the ROB, IQ, or LSQ getting exhausted <ref type="bibr" target="#b13">[14]</ref>. To trace the root cause of back-end stall, shadow queues need to cooperate with CMT. Figure <ref type="figure" target="#fig_4">5</ref> illustrates how to use CMT and shadow queue to detect contention on back-end resources by taking IQ as an example. When HPT is to dispatch instructions and IQ is full, it will read CMT to check whether this blocking is caused by cache interference. Then it will see whether there are outstanding misses or floating point instructions in computation. If neither of situations happens, HPT should not be blocked. So this stall is regarded as a contention in IQ. If there exists such a long latency instruction, we check the shadow IQ counter for further decision. If the shadow IQ counter &lt; maxIQsize, which suggests that the IQ Full event is caused by another thread's contention on IQ, this incident should be regarded as a SMT contention. If the shadow IQ counter = maxIQsize, it is the thread itself filled up the IQ, not to blame SMT. To detect contention at front end 5 ○, we classify the scenarios in which fetch can not supply instructions into three categories.</p><p>(1) I-Cache miss, (2) LPT preempts HPT's timeslice, (3) Stalls at back-end resources.</p><p>In Table <ref type="table">2</ref> we show our contention determination scheme based on HPT's status. Next we give an explanation of Table <ref type="table">2</ref>. Since whether LPT getting a fetch opportunity interferes HPT depends on the status of HPT, the first column of matrix shows HPT's status. Back-end stall by LPT means that HPT has back-end stalls, which is caused by LPT. Yield means that in this cycle HPT has neither I-cache miss nor back-end stall, but LPT takes the fetch opportunity. Other states' name explains themselves. The second column shows whether this cycle should be judged as a contention and what kind of contention it is when HPT does take the fetch opportunity. For example, the third row tells that when HPT's back-end is blocked by LPT, this cycle in the fetch phase should be regarded as Back-end Contention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Prediction Mechanism</head><p>To ensure precise performance control, we need to precisely predict performance in solo-mode as a baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Gathering Contention Information.</head><p>In order to quantify the contention on each shared resource, we design a Critical Resource Table (CRT) to record contention cycles for each stall event by three steps. First, each CDM distributed at each pipeline stage will separately generate contention judgement signals by checking whether HPT is stalled due to contention based on the mechanism mentioned above. Then the signals will be forwarded to the dispatch stage. Finally, the values of the corresponding contention cycle entries of the CRT are updated according to the contention judgement signals at dispatch stage.</p><p>To gather contention judgement signals detected in distributed CDMs, we add some signals along the paths marked by 6 ○. In particular, FC (front-end contention) means that contention is detected at fetch/rename stage, and passed to later stages. BC (back-end contention) means that contention is detected at rename/dispatch stage, and passed to earlier stages. Fetch stage obtains back-end contention information by this path. Signals from CMT to pipeline stages convey cache interference and miss information. They are used in 4.1.2 and 4.1.3.</p><p>For example, when the CDM at rename stage detects a ROB stall event of HPT caused by LPT, it will forward the judgement signals to the dispatch stage and will increment the contention cycle value corresponding to ROB contention entry in the CRT.</p><p>There are two reasons for this design: <ref type="bibr" target="#b0">(1)</ref> The PEM needs to use contention cycles as input. Since contention information is distributed at serval stages, a centralized CRT can avoid long wire delay of reading distributed contention values; (2) Because of the overlap of SMT-induced contention and stalling by itself, performing contention detection at one stage of pipeline could lead to inaccurate result that the amount of collected contention cycles may diverge from the actual amount caused by LPT. In addition, updating CRT at the dispatch stage can achieve a good tradeoff between design complexity and statistical accuracy. The earlier contention detection is performed in the pipeline, the less information and poorer statistical accuracy will be obtained. The later detection is performed in the pipeline, the more complicated the design will be.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Predicting Performance in Solo-Mode.</head><p>Referring to prior work <ref type="bibr" target="#b11">[12]</ref>, we design shadow solo-cycle accounting (SSCA) approach to estimate workloads' execution time in solo mode by T solo = T shar e − T int er f , where T shar e is the execution time in SMT mode and the interference time, T int er f , is the sum of the contention stall cycles stored in the CRT. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Dynamic Controlling</head><p>QoSMT enables users to write the Expected Target Register, which is similar to MSR in Intel processors, to convey performance target requirements. To achieve the expected target, the PEM takes predicted T solo and detected critical resources as input, and leverages resource allocation modules in fetch unit 5 ○, ROB, IQ, LSQ 3 ○ and caches 1 ○, to perform dynamic resource adjustment. Next, we will first introduce the algorithm of the decision and controlling module, and then describe the grain of resource adjustment.</p><p>Algorithm 1 shows the procedure of dynamic controlling. We first calculate current performance target of HPT using solo execution time estimated in 4.2. If current performance is larger than expectation, then we allocate all kinds of resources from HPT to LPT to improve throughput. If not satisfied, the PEM first sorts ResourceList in CRT by corresponding contention cycles in decreasing order. Then PEM chooses the most critical resources from the sorted list, and reallocates resources accordingly.</p><p>The quantum of fetch scheduling is one cycle out of 16 cycles. When HPT needs more fetch quota, one more cycle is allocated from LPT to HPT, or vice versa. Both threads have at least one cycle out of 16 cycles. Assume that size is the capacity of ROB/IQ/LQ/SQ, each thread occupies at least size/16 entries and size/16 is the reallocation unit. For caches, the allocation unit is cache associativity, and each thread occupies at least one way. Initially, all these resources are equally partitioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION 5.1 Experiment setup</head><p>We implement QoSMT on GEM5 simulator. Considering the support of SMT, we choose Alpha ISA. We use 24 benchmarks from SPEC2006 <ref type="bibr" target="#b16">[17]</ref> as workloads. Due to compile or runtime errors, another 5 benchmarks are not used. To extract typical behaviors of workloads, we use SimPoint <ref type="bibr" target="#b22">[25]</ref> to acquire checkpoints for each benchmark. We run different benchmarks from their checkpoints on SMT to achieve workload co-location.</p><p>To obtain typical workload pairs among these benchmarks, we refer to the balanced random method <ref type="bibr" target="#b29">[32]</ref> to select 48 pairs of benchmarks for experiments. Then we run QoSMT with 85%, 90% and 95% as users' expected target. But due to space limitation, we show only 24 pairs without loss of generality. They are selected by first ranking the 48 pairs according to HPT performance, then sampled with a fixed step of 2. They are used through the remaining parts of the evaluation.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the GEM5 configurations. Since both Intel and AMD's processors have two logical threads, we also primarily investigate the configuration of two threads. We assume that fetch buffers are private with round-robin policy by default, but the functional units are shared.</p><p>For convenience, we use some abbreviations to refer all the policies. FR means fetch round-robin. FD means fetch dynamically. BS means back-end sharing. BP means back-end static partitioning. CS means cache sharing. CP means cache static partitioning. Cazorla is a state-of-the-art mechanism presented by Cazorla,e.g., <ref type="bibr" target="#b5">[6]</ref>. QoSMT, our methodology, will dynamically adjust all resources.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation of Different Performance Target</head><p>To verify QoSMT's capability of guaranteeing performance target, we run the selected pairs of workloads with HPT performance targets of 85%, 90% and 95%, respectively. Figure <ref type="figure" target="#fig_5">6</ref> shows the distributions of HPT normalized IPC(IPCshare/IPCreal) † from the selected pairs with different policies. The segment length of each policy on X-axis implies the variation of the performance of HPT. The shorter the segment is, the more predictable performance the policy provides. The centroid of each segment indicates the average performance of HPT. FR-BS-CS is a policy that lets all resources suffer from full contention, which performs the worst predictability for HPT. FR-BP-CS simulates the policy adopted by Intel, but it may suffer from interference in cache. FR-BP-CP supports cache partitioning based on FR-BP-CS. Its distribution is a little more concentrated than FR-BP-CS, yielding a little bit better predictability. However, the centroid moves to the left, suggesting performance loss. It is worth noting that all of these conclusions are consistent with the observations in §3. The centroid of three green segments (QoSMT-85, QoSMT-90 and QoSMT-95) show that QoSMT can let HPT finally achieve average normalized IPC of 86.4%, 89.5%, 91.4% respectively. The segment length of Cazorla-90 is almost the same as that of QoSMT-90, indicating that they have similar performance stability. However, the average normalized IPC of Cazorla-90 is less than 90%, indicating that the ability of Cazorla-90 to satisfied target is less than QoSMT's. From this view, QoSMT provides best performance predictability than all other policies. This is because FD-BS-CP-90 is very interesting. It simulates the policy of online monitoring and adjustment with performance target 90% on an IBM POWER8 machine. But it only obtain 82.2% average normalized IPC for HPT, even being outperformed by QoSMT-85. This is because FD-BS-CP-90 does not deal with back-end resource interference. It also has less predictability (longer segment) than QoSMT. These suggest that back-end resource control is necessary to performance guarantee. We will have further discussions about the details in §5.5.</p><p>To show that QoSMT does not hurt too much throughput with performance guarantee, we calculate the overall normalized IPC on Y-axis in Figure <ref type="figure" target="#fig_5">6</ref>, which is the sum of normalized IPC of both HPT and LPT. FR-BP-CS provides the highest overall normalized IPC because of its balanced resource allocation. But as expected, it does not provide an adequate ability of guarantee performance target. Compared with policies that focus on guaranteeing performance, We can see that QoSMT-95 achieves similar throughput to FD-BS-CP-90. QoSMT-90 provides a better throughput than Cazorla-90, where LPT can still get average 40% normalized IPC. Because Cazorla-90 need a sampling phase dedicated for running in isolation the HPT, which causes performance loss for LPT. In addition, the coarse-grain resources partition of Cazorla-90 will also limit the LPT's performance. As for QoSMT, each operation of resource allocation is based on fine-grain statistics of critical resource. These suggest that QoSMT can achieve reasonable overall throughput through a timely performance prediction and a effective dynamic controlling mechanism, compared with state-of-the-art policies.</p><p>Note that our design is fully compatible with other policies, because QoSMT provides a tuning mechanism between overall throughput and HPT's performance. This is achieved by configuring the parameters of dynamic controlling mechanism introduced in §4.3. For example, if overall throughput is preferred, one can configure QoSMT similar to FR-BP-CS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Further Analysis on 24 Pairs</head><p>To further understand the difference among these policies, Figure <ref type="figure" target="#fig_6">7</ref> lists the HPT performance of all the selected 24 pairs with the expected performance target of 90%. Each pair is named as "X_Y", where "X" is HPT and "Y" is LPT. All pairs are sorted by the HPT performance from left to right. Compared with Figure <ref type="figure" target="#fig_5">6</ref>, Figure <ref type="figure" target="#fig_6">7</ref> implies two more conclusions.</p><p>First, QoSMT outperforms all other policies for most pairs. This is because QoSMT provides dynamic control over all resources. The performance of HPT varies between 85% -95% with QoSMT.</p><p>Second, given an HPT, QoSMT can protect it from being interfered by any other workloads. This can be concluded from the observation that pairs with the same HPT are not far from each other in Figure <ref type="figure" target="#fig_6">7</ref>, since pairs are already sorted by the HPT performance from left to right. For example, running with bwaves or gobmk, GemsFDTD still keeps similar performance with QoSMT.</p><p>There is a special case which bwaves achieves a performance greater than 100%. We find that there are large amount of floating point branches in bwaves. They are not only hard to predict whether it is taken or not, but also highly depend on prior floating point instructions <ref type="bibr" target="#b14">[15]</ref>. Therefore, floating point branches in bwaves will be more likely to stay at the head of ROB. Then, the more instructions in ROB, the higher penalty a branch misprediction results in. Hence bwaves performs better when ROB is smaller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Effect of Prediction Mechanism</head><p>As shown in Figure <ref type="figure" target="#fig_5">6</ref> and Figure <ref type="figure" target="#fig_6">7</ref>, some HPT workloads fail to achieve the performance target. The main reason is that there is a modeling error in the prediction mechanism. To demonstrate the effect of prediction accuracy on achieving target, we show the relationship of "prediction error" versus "expected target gap" of the 24 pairs of QoSMT-90 in Figure <ref type="figure" target="#fig_7">8</ref>, where the prediction error and expected target gap are calculated as IPCsolo_predicted -IPCsolo_real and IPCshare -90%*IPCsolo_real respectively. From Figure <ref type="figure" target="#fig_7">8</ref>, the slope of QoSMT-90 is 1, which means expected target gap is equal to its prediction error. The fewer the prediction error is, the fewer the expected target gap will be.</p><p>We analyze the two sources of prediction error.</p><p>• From the aspect of mirco-architecture, a program's behavior under SMT mode is totally different from that under solo mode. To obtain the cache behavior under solo mode as much precise as possible, QoSMT already uses shadow tag. However, it is very difficult to obtain the pipeline behavior under solo mode, due to the complexity of resource contention. Therefore, the shadow queue mechanism will still introduce certain amount of inaccuracy. • The prediction method of QoSMT is inspired by PTA. PTA uses MLP correction to achieve higher accuracy <ref type="bibr" target="#b11">[12]</ref>. However, we can not get an application's MLP without offline profiling, so this correctness mechanism is not adopted in QoSMT. This may be another source of inaccuracy of prediction.</p><p>As for QoSMT-95, because there is a minimum quota for both threads during resources allocation, QoSMT did not completely guarantee the target in some workloads. For example, L1-D cache have 4 ways, and the minimum quota is one way. In this case, at most 3 ways can be allocated to HPT, which causes performance loss. But this it is not common, and occurs where extremely high performance is expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Effect of Dynamic Controlling</head><p>To have a better understanding about the need of dynamic controlling on both front-end and back-end resources, we plot FD-BS-CP-90 performance distribution in Figure <ref type="figure" target="#fig_7">8</ref>, which only adopts fetch-rate reallocation. If a policy is effective, the expected target gap should be equal to its prediction error. As shown in Figure <ref type="figure" target="#fig_7">8</ref>, the distribution of QoSMT-90 conforms to our hypothesis, while it is not the case for FD-BS-CP-90. That is, there are some situations, where FD-BS-CP-90 knows that the expected target has not been satisfied, but it does not have enough ability to guarantee the target performance. This implies the need of controlling back-end resources, which can help to enforce the performance requirements more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Evaluation of Response Time</head><p>The latency-sensitive application requires quick response time for a performance guarantee policy. To demonstrate the effect of QoSMT dynamic control mechanism on response time, we did an evaluation of response time on the above 24 pairs. Figure <ref type="figure" target="#fig_8">9</ref> shows how long it takes QoSMT to guarantee performance to meet the expected target, where the expected target is 90% IPCsolo. As Figure <ref type="figure" target="#fig_8">9</ref> shows, QoSMT-90 has a significantly faster response time than Cazorla-90. For 90% of pairs, QoSMT only needs to spend less than 450000 cycles to meet the performance target. Taking 2Ghz cpu frequency as an example, the response time of 90% is 225us. For Cazorla-90, Its response time of 90% is 325us. Especially for cache-sensitive workloads, the Cazorla-90 has almost twice the QoSMT response time. We think there are two reasons for this result:1&gt; In order to predict solo-mode performance, Cazorla-90 needs to sample HPT performance by exclusively running, and the sampling phase needs to maintain a certain period to filter the impact of cache interference on sampling accuracy. Thus it inevitably leads to a delay in response time. By using the shadow solo-cycle accounting methodology, QoSMT can timely get the predicted IPC without the delay of waiting for the sampling phase. 2&gt; Cazorla adopts a coarse-grained resource allocation method, like Fetch Rate and Issue bandwidth. It doesn't adjust for critical resources. Through the combination of CMT and CRT, QoSMT can directly locate critical resources in a fine-grained manner and find performance bottlenecks. For example, for a cache sensitive workload, it would not be efficient to allocate more issue bandwidth, while CMT could timely calculate cache interferences, which would prompt QoSMT to allocate more cache resources, thus providing a faster response time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Epoch length Choosing</head><p>Since QoSMT will adjust the resource allocation periodically, we need to address the problem how to choose a suitable epoch length to make QoSMT more effective. We have observed that, if the length is too short, QoSMT will not catch enough event to make a good decision about resource allocation. On the other hand, if the length is too long, QoSMT will not make timely decision to the contention variation. We choose 10 pairs of benchmarks with 90% of performance target, trying different epoch length among {1000, 2000, 5000, 10000, 20000, 40000} cycles. And 10000 cycles and 20000 cycles are better than others from the view of overall performance. Users can choose it according to actual needs. If the user is more concerned about latency, 10000 cycles is preferred. If the user want to achieve lower dynamic power, 20000 cycles is a better choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Overhead</head><p>There are three major concerns about adding QoSMT design into the architecture of general SMT processors:</p><p>• How many extra latency is introduced? • How many hardware resources are required ? • How much extra power consumption is introduced? Latency. QoSMT does not modify the basic architecture of the pipeline logic. Based on our evaluation on GEM5, the added components do not introduce extra latency at all. As Figure <ref type="figure" target="#fig_3">4</ref> shows, CRT and CMT are located on non-critical path. For CDM, We need signals to gather contention information detected in distributed CDMs, We add these signals along the pipe line with refer to data forwarding signals. In addition, the memory requests will be sent to shadow tag and cache tag array simultaneously, they will individually work without any impact on each other.</p><p>Resources. Our design introduces some new components, but most of them are very cheap. The only costly component is the shadow tag. In order to ensure the accuracy of interference detecting, The size of shadow tags are as same as each level cache tag. Other components' overhead mainly depend on the number of entries in each table <ref type="table">:</ref> (1) The CMT requires n × r bits, where n is the number of bits per entry, r is the the maximum number of outstanding miss allowed. For our design, each entry includes 1 bit valid signal, 1 bit interference judgement signal, and 18 bit TID. For L1 cache, the maximum number of outstanding miss allowed is 8, for L2 cache, the number is 32, which is ( 1 + 1 + 18 ) × ( 8 + 8 + 32 ) = 960 bits for CMT; (2) The CRT requires n × r bits, where n is the number of bits per resources contention stall counter and r is the number of contention resource, which is 64 × 8 = 512 bits;</p><p>(3) There are four shadow queue counters for ROB, IQ, LQ, and SQ. The shadow queue counters need log 2 ROB + log 2 IQ + log 2 LSQ, which is 23 bits in our design totally.</p><p>We evaluate the area overhead of QoSMT using McPAT <ref type="bibr" target="#b20">[22]</ref>. The area of the baseline chip based on ALPHA31264 is 47 mm 2 under a 40nm process technology. The area overhead of L2 Shadowtag, L1 Shadowtag, CMT, and CRT in terms of percent (%) are 0.7%, 0.02%, 0.0047%, 0.0045% respectively.</p><p>Power.We use Wattch <ref type="bibr" target="#b4">[5]</ref> to evaluate the power consumption. The most power consumption component is L2 cache shadow tag, which is 1.8 W , while other components power are 1.5W in total. The sum power consumption accounts for 3.6% of total processors power, where the total power of processor is 90 W.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Equal-Silicon-Area Performance</head><p>The area overhead of the shadow tag can be replaced with a 46KB cache. To evaluate normalized performance to an equal-siliconarea non-QoSMT design, we disable shadow tag mechanism and increase the L1 Dcache capacity from 32KB to 128KB. The average normalized IPC of equal-silicon-area non-QoSMT designs with 90% target is 86%, which is worse than QoSMT90. To further evaluate the benefit of shadow tag on eliminating cache interference, we choose a cache sensitive workload hmmer in SPEC2006. When coruns with a memory-intensive workload mcf, the normalized IPC of hmmer drops to 75%. Therefore, shadow tag combining with dynamic cache partitioning is a key component to eliminate cache interference. The area overhead is worth it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK 6.1 Industry Design</head><p>As shown in Table <ref type="table" target="#tab_0">1</ref>, IBM POWER processors adopts more aggressive QoS support than Intel and AMD. Thus, we focus on IBM's design. Generally, IBM introduced two-level control mechanisms <ref type="bibr" target="#b3">[4]</ref> since POWER5 to enable software to adjust instruction fetch rates for specific threads. <ref type="bibr" target="#b21">[24]</ref> evaluates the effect of software controlling approach on POWER5 and POWER6. Their results show that the effect of software controlling is unstable across various microbenchmarks. While max priority can achieve 90%-100% HPT IPC, the co-located LPT only receives as low as 2% -9% of performance in solo mode, indicating huge throughput/utilization loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Resources Contention and Modeling</head><p>Raasch et al. <ref type="bibr" target="#b23">[26]</ref> revealed that industry-favored simple static partitioning policies are able to achieve good overall throughput, but they did not investigate the impact of static partitioning on guaranteeing performance of specific threads.</p><p>Cakarevic et al. <ref type="bibr" target="#b28">[31]</ref> analyzed the impact of shared resources of UltraSPARC T2 that is a somewhat different fine-grain multithreading processor. But their results are unapplicable to mainstream SMT processors because UltraSPARC T2's architecture is pretty different from Intel and AMD's design.</p><p>Recent work SMiTe <ref type="bibr" target="#b30">[33]</ref> uses a set of carefully designed microbenchmarks to perform offline sensitive analysis on various shared resources of SMT cores, and then proposes a decent job scheduler to avoid performance degradation of HPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Software Based Polices</head><p>Eyerman et al. <ref type="bibr" target="#b12">[13]</ref> proposed a job scheduler based on sampling mechanism along with hardware modification to achieve better throughput on SMT processors. Feliu et al. proposed an improved design <ref type="bibr" target="#b15">[16]</ref> without hardware modification, but still focused on overall throughput rather than performance guarantee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Hardware based policies</head><p>The closest work to QoSMT is the design proposed in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>. For their work, whether the prediction IPC is accurate depends on the severity of the interference of LPT at the sampling stage. They use warmup about 5K instructions procedure to filter the interference, however, it will cost millions of instructions to release L2 cache interference. We did evaluate their design with memory intensive benchmark as LPT, the result illustrated that the average performance decreased. In addition, QoSMT does not need a time period of tens of thousands of cycles for sampling, hence is more robust against frequent program phase changes. Transparent thread also aims to maximize HPT's performance with reasonable overall throughput <ref type="bibr" target="#b10">[11]</ref>. Unlike QoSMT, it does not support precise performance control based on user-defined target. There are many studies <ref type="bibr" target="#b6">[7]</ref>[30] <ref type="bibr" target="#b8">[9]</ref>[10] <ref type="bibr" target="#b24">[27]</ref> providing solutions on improving overall SMT throughput and fairness, but they did not take performance control into account. Eyerman et al. <ref type="bibr" target="#b11">[12]</ref> proposed the per-thread cycle accounting (PTA) mechanism that is able to estimate a workload's solo performance in a co-running mode on SMT processors. QoSMT leverages this concept to perform performance prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>This paper presents QoSMT methodology, which enables precise performance guarantee for given performance targets on SMT core. Based on our investigation on the behavior of interference induced by SMT, we find that it is difficult to meet the variable resource requirements for a logical thread through static resource allocation. As a consequence, we design a critical in-core resources identification mechanism and a solo IPC predictor to direct a closed-loop mechanism to dynamically allocate the resources for target thread. We implemented a QoSMT prototype based on GEM5 simulator. As illustrated in our experiment, compared with the state-of-theart, QoSMT are able to enforce a precise performance control for specific IPC targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGEMENT</head><p>We would like to thank anonymous reviewers for their valuable feedbacks and suggestions. We thank our group members, Wenbin Lv, Zhigang Liu, Tianni Xu, Zhiyuan Yan for their help on this work. Especially thank Lan Xiao for her silently concern. This work </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 1 )</head><label>1</label><figDesc>All-Shared: Both back-end and cache resources are shared by all logical thread. (2) Back-end Static Partitioning (Back-end-SP): This is an Intel-like policy. The whole back-end resources are equally partitioned for each logical thread, but L1/L2 cache are still shared. (3) Complete Static Partitioning (Complete-SP): Both backend and cache resources are equally partitioned for each logical thread.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Interference on shared resources: gcc &amp; omnetpp running with other workloads.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The impact of static partitioning on performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The overview design of QoSMT Step3: Based on the number of stall cycles counted in CRT inStep2, the HPT's solo performance will be predicted.Step4: If the current HPT performance fails to reach the target, PEM will conduct dynamic resource allocation operation. PEM will reallocate the resource of TOP rank in CRT from LPT to HPT. For example, t1 in the figure shows that the current performance does not meet the requirements, and ROB is the performance bottleneck. So HPT gets more ROB resources, increasing the performance .</figDesc><graphic url="image-20.png" coords="5,397.20,150.94,149.67,56.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Back-end contention detection.Table 2: Conditions of Fetch Contention Status of HPT Contention Conditions I-Cache Miss by LPT I-Cache Contention I-Cache Miss by HPT Not Contention Back-end Stall by LPT Back-end Contention Back-end Stall by HPT Not Contention Yield Front-end Contention</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Target IPC-Throughput</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: HPT Normalized IPC QoSMT can dynamically control all types of resources, protecting HPT from contention on any resources.FD-BS-CP-90 is very interesting. It simulates the policy of online monitoring and adjustment with performance target 90% on an IBM POWER8 machine. But it only obtain 82.2% average normalized IPC for HPT, even being outperformed by QoSMT-85. This is because FD-BS-CP-90 does not deal with back-end resource interference. It also has less predictability (longer segment) than QoSMT. These suggest that back-end resource control is necessary to performance guarantee. We will have further discussions about the details in §5.5.To show that QoSMT does not hurt too much throughput with performance guarantee, we calculate the overall normalized IPC on Y-axis in Figure6, which is the sum of normalized IPC of both HPT and LPT. FR-BP-CS provides the highest overall normalized IPC because of its balanced resource allocation. But as expected, it does not provide an adequate ability of guarantee performance target. Compared with policies that focus on guaranteeing performance, We can see that QoSMT-95 achieves similar throughput to FD-BS-CP-90. QoSMT-90 provides a better throughput than Cazorla-90, where LPT can still get average 40% normalized IPC. Because Cazorla-90 need a sampling phase dedicated for running in isolation the HPT, which causes performance loss for LPT. In addition, the coarse-grain resources partition of Cazorla-90 will also limit the LPT's performance. As for QoSMT, each operation of resource allocation is based on fine-grain statistics of critical resource. These suggest that QoSMT can achieve reasonable overall throughput through a timely performance prediction and a effective dynamic controlling mechanism, compared with state-of-the-art policies.Note that our design is fully compatible with other policies, because QoSMT provides a tuning mechanism between overall throughput and HPT's performance. This is achieved by configuring the parameters of dynamic controlling mechanism introduced in §4.3. For example, if overall throughput is preferred, one can configure QoSMT similar to FR-BP-CS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Relationship between prediction error and achieved performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Response Time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>was supported in part by National Key R&amp;D Program of China (2016YFB1000201), and the National Natural Science Foundation of China (Grant No. 61420106013 and 61702480), and Primary Research &amp; Development Plan of Shaanxi Province(2019TSLGY08-03) and Youth Innovation Promotion Association of Chinese Academy of Sciences (2013073).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Commodity processors' efforts to eliminating performance interference caused by SMT.</figDesc><table><row><cell></cell><cell></cell><cell>Skylake</cell><cell>Power 8</cell><cell>ZEN</cell></row><row><cell cols="5">Front-end Fetch Unknown Unknown Unknown</cell></row><row><cell></cell><cell cols="2">ROB Partition</cell><cell>Shared</cell><cell>Partition</cell></row><row><cell>Back-end</cell><cell>IQ LQ</cell><cell>Shared Partition</cell><cell>Shared Shared</cell><cell>Partition Shared</cell></row><row><cell></cell><cell>SQ</cell><cell>Partition</cell><cell>Shared</cell><cell>Partition</cell></row><row><cell></cell><cell>L1-I</cell><cell>Shared</cell><cell>Shared</cell><cell>Shared</cell></row><row><cell>Cache</cell><cell cols="2">L1-D Shared</cell><cell>Shared</cell><cell>Shared</cell></row><row><cell></cell><cell>L2</cell><cell>Shared</cell><cell>Shared</cell><cell>Shared</cell></row><row><cell cols="5">target of Power8 is coarse. It only marks a thread as high or low pri-</cell></row><row><cell cols="5">ority, rather than precisely control the performance like achieving</cell></row><row><cell cols="4">"90% of the performance of solo mode".</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell>Configuration List</cell></row><row><cell>resource</cell><cell>configuration</cell></row><row><cell>Width</cell><cell>8</cell></row><row><cell>Fetch buffer size</cell><cell>64 per thread</cell></row><row><cell>ROB entries</cell><cell>224</cell></row><row><cell>IQ size</cell><cell>96</cell></row><row><cell>LQ entries</cell><cell>72</cell></row><row><cell>LQ entries</cell><cell>56</cell></row><row><cell cols="2">Physical Int registers 256</cell></row><row><cell cols="2">Physical FP registers 200</cell></row><row><cell>L1 D-Cache</cell><cell>32KB, 4-way, LRU, 8 MSHRs</cell></row><row><cell>L1 I-Cache</cell><cell>32KB, 4-way, LRU, 8 MSHRs</cell></row><row><cell>L2 Cache</cell><cell>2MB, 8-way, LRU, 32 MSHRs</cell></row><row><cell>Cache latencies</cell><cell>L1(4), L2(40)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">†  IPCreal is the real IPC of HPT running in solo mode that we get it offline. IPCshare is the IPC of HPT running in QoSMT</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><surname>Alibaba</surname></persName>
		</author>
		<ptr target="https://102.alibaba.com/fund/proposalAbout.htm" />
		<title level="m">Alibaba Innovative Research</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><surname>Amd</surname></persName>
		</author>
		<ptr target="http://www.amd.com/en-gb/innovations/software-technologies/zen-cpu" />
		<title level="m">The Zen Core Architecture AMD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradford</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arkaprava</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">R</forename><surname>Hower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somayeh</forename><surname>Sardashti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The gem5 simulator</title>
				<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Software-Controlled Priority Characterization of POWER5 Processor</title>
		<author>
			<persName><forename type="first">C</forename><surname>Boneti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gioiosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Cher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISCA.2008.8</idno>
		<ptr target="https://doi.org/10.1109/ISCA.2008.8" />
	</analytic>
	<monogr>
		<title level="m">2008 International Symposium on Computer Architecture</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="415" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wattch: a framework for architectural-level power analysis and optimizations</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th International Symposium on Computer Architecture (ISCA 2000)</title>
				<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06-10">2000. June 10-14, 2000</date>
			<biblScope unit="page" from="83" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predictable Performance in SMT Processors: Synergy Between the OS and SMTs</title>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rizos</forename><surname>Knijnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Sakellariou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1109/TC.2006.108</idno>
		<ptr target="https://doi.org/10.1109/TC.2006.108" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="785" to="799" />
			<date type="published" when="2006-07">2006. July 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamically Controlled Resource Allocation in SMT Processors</title>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Fernandez</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2004.17</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2004.17" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 37th Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">QoS for high-performance SMT processors in embedded systems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M W</forename><surname>Knijnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sakellariou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fernandez</surname></persName>
		</author>
		<idno type="DOI">10.1109/MM.2004.37</idno>
		<ptr target="https://doi.org/10.1109/MM.2004.37" />
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="24" to="31" />
			<date type="published" when="2004-07">2004. July 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning-Based SMT Processor Resource Distribution via Hill-Climbing</title>
		<author>
			<persName><forename type="first">Seungryul</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Yeung</surname></persName>
		</author>
		<idno type="DOI">10.1145/1150019.1136507</idno>
		<ptr target="https://doi.org/10.1145/1150019.1136507" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="251" />
			<date type="published" when="2006-05">2006. May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hill-climbing SMT Processor Resource Distribution</title>
		<author>
			<persName><forename type="first">Seungryul</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Yeung</surname></persName>
		</author>
		<idno type="DOI">10.1145/1482619.1482620</idno>
		<ptr target="https://doi.org/10.1145/1482619.1482620" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2009-02">2009. Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transparent Threads: Resource Sharing in SMT Processors for High Single-Thread Performance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gautham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Dorai</surname></persName>
		</author>
		<author>
			<persName><surname>Yeung</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=645989.674324" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 International Conference on Parallel Architectures and Compilation Techniques (PACT &apos;02)</title>
				<meeting>the 2002 International Conference on Parallel Architectures and Compilation Techniques (PACT &apos;02)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Per-thread Cycle Accounting in SMT Processors</title>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
		<idno type="DOI">10.1145/1508284.1508260</idno>
		<ptr target="https://doi.org/10.1145/1508284.1508260" />
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="133" to="144" />
			<date type="published" when="2009-03">2009. March 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic Job Symbiosis Modeling for SMT Processor Scheduling</title>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
		<idno type="DOI">10.1145/1735971.1736033</idno>
		<ptr target="https://doi.org/10.1145/1735971.1736033" />
	</analytic>
	<monogr>
		<title level="j">SIGPLAN Not</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="91" to="102" />
			<date type="published" when="2010-03">2010. March 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A performance counter architecture for computing accurate CPI components</title>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejas</forename><surname>Karkhanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1145/1168857.1168880</idno>
		<ptr target="https://doi.org/10.1145/1168857.1168880" />
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="175" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Characterizing the branch misprediction penalty</title>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lieven</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2006</title>
				<meeting><address><addrLine>Austin, Texas, USA, Proceedings</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-03-19">2006. March 19-21, 2006</date>
			<biblScope unit="page" from="48" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Symbiotic job scheduling on the IBM POWER8</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feliu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sahuquillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petit</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCA.2016.7446103</idno>
		<ptr target="https://doi.org/10.1109/HPCA.2016.7446103" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="669" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
		<idno type="DOI">10.1145/1186736.1186737</idno>
		<ptr target="https://doi.org/10.1145/1186736.1186737" />
	</analytic>
	<monogr>
		<title level="m">SPEC CPU2006 Benchmark Descriptions</title>
				<imprint>
			<date type="published" when="2006-09">2006. Sept. 2006</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="https://software.intel.com/en-us/articles/introduction-to-cache-allocation-technology" />
		<title level="m">Introduction to Cache Allocation Technology in the Intel Xeon Processor E5 v4 Family</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmine</forename><surname>Madonna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satish</forename><surname>Kumar Sadasivam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prathiba</forename><surname>Kumar</surname></persName>
		</author>
		<title level="m">Bandwidth-Aware Resource Optimization for SMT Processors</title>
				<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hyperthreading technology in the netburst microarchitecture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koufaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Marr</surname></persName>
		</author>
		<idno type="DOI">10.1109/MM.2003.1196115</idno>
		<ptr target="https://doi.org/10.1109/MM.2003.1196115" />
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2003-03">2003. March 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">McPAT: an integrated power, area, and timing modeling framework for multicore and manycore architectures</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1669112.1669172</idno>
		<ptr target="https://azure.microsoft.com/en-us/pricing/details/sql-database/elastic/" />
	</analytic>
	<monogr>
		<title level="m">42st Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Microsoft</publisher>
			<date type="published" when="2009-12-12">2009. 2009. December 12-16, 2009. 2017</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boneti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gioiosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Cher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1109/TC.2012.34</idno>
		<ptr target="https://doi.org/10.1109/TC.2012.34" />
	</analytic>
	<monogr>
		<title level="m">SMT Malleability in IBM POWER5 and POWER6 Processors</title>
				<imprint>
			<date type="published" when="2013-04">2013. April 2013</date>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="813" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using SimPoint for Accurate and Efficient Simulation. SIGMETRICS Perform</title>
		<author>
			<persName><forename type="first">Erez</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Van Biesbrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<idno type="DOI">10.1145/885651.781076</idno>
		<ptr target="https://doi.org/10.1145/885651.781076" />
	</analytic>
	<monogr>
		<title level="j">Eval. Rev</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="318" to="319" />
			<date type="published" when="2003-06">2003. June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Impact of Resource Partitioning on SMT Processors</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">E</forename><surname>Raasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=942806.943858" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Parallel Architectures and Compilation Techniques (PACT &apos;03)</title>
				<meeting>the 12th International Conference on Parallel Architectures and Compilation Techniques (PACT &apos;03)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive Reorder Buffers for SMT Processors</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Sharkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Balkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Ponomarev</surname></persName>
		</author>
		<idno type="DOI">10.1145/1152154.1152192</idno>
		<ptr target="https://doi.org/10.1145/1152154.1152192" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Parallel Architectures and Compilation Techniques (PACT &apos;06)</title>
				<meeting>the 15th International Conference on Parallel Architectures and Compilation Techniques (PACT &apos;06)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="244" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Balaram</forename><surname>Sinharoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">N</forename><surname>Kalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">M</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">J</forename><surname>Eickemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jody</forename><forename type="middle">B</forename><surname>Joyner</surname></persName>
		</author>
		<title level="m">POWER5 system microarchitecture. IBM journal of research and development</title>
				<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="505" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<author>
			<persName><forename type="first">Balaram</forename><surname>Sinharoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Norstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">J</forename><surname>Eickemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><forename type="middle">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Leenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dung</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Konigsburg</surname></persName>
		</author>
		<author>
			<persName><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><forename type="middle">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><surname>Moreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IBM POWER8 processor core microarchitecture</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Managing SMT Resource Usage Through Speculative Instruction Window Weighting</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>Vandierendonck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2019608.2019611</idno>
		<ptr target="https://doi.org/10.1145/2019608.2019611" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Archit. Code Optim</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2011-10">2011. Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Characterizing the Resourcesharing Levels in the UltraSPARC T2 Processor</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Čakarević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Radojković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Verdú</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Pajuelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">J</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Nemirovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Valero</surname></persName>
		</author>
		<idno type="DOI">10.1145/1669112.1669173</idno>
		<ptr target="https://doi.org/10.1145/1669112.1669173" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42Nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 42Nd Annual IEEE/ACM International Symposium on Microarchitecture<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="481" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Selecting benchmark combinations for the evaluation of multicore throughput</title>
		<author>
			<persName><forename type="first">Ricardo</forename><forename type="middle">A</forename><surname>Velásquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Performance Analysis of Systems and Software (ISPASS), 2013 IEEE International Symposium on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">SMiTe: Precise QoS Prediction on Real-System SMT Processors to Improve Utilization in Warehouse Scale Computers</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Laurenzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1109/MICRO.2014.53</idno>
		<ptr target="https://doi.org/10.1109/MICRO.2014.53" />
	</analytic>
	<monogr>
		<title level="m">2014 47th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="406" to="418" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
