<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DisenQNet: Disentangled Representation Learning for Educational Questions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
							<email>huangzhy@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Lin</surname></persName>
							<email>linx@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
							<email>wanghao3@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
							<email>cheneh@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianhui</forename><surname>Ma</surname></persName>
							<email>jianhui@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
							<email>yusu@iflytek.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">iFLYTEK Research, iFLYTEK</orgName>
								<address>
									<settlement>Ltd</settlement>
									<region>Co</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Tong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Anhui Province Key Laboratory of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DisenQNet: Disentangled Representation Learning for Educational Questions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3447548.3467347</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>question learning</term>
					<term>disentangled representation</term>
					<term>mutual information</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning informative representations for educational questions is a fundamental problem in online learning systems, which can promote many applications, e.g., difficulty estimation. Most solutions integrate all information of one question together following a supervised manner, where the representation results are unsatisfactory sometimes due to the following issues. First, they cannot ensure the presentation ability due to the scarcity of labeled data. Then, the label-dependent representation results have poor feasibility to be transferred. Moreover, aggregating all information into the unified may introduce some noises in applications since it cannot distinguish the diverse characteristics of questions. In this paper, we aim to learn the disentangled representations of questions. We propose a novel unsupervised model, namely DisenQNet, to divide one question into two parts, i.e., a concept representation that captures its explicit concept meaning and an individual representation that preserves its personal characteristics. We achieve this goal via mutual information estimation by proposing three selfsupervised estimators in a large unlabeled question corpus. Then, we propose another enhanced model, DisenQNet+, that transfers the representation knowledge from unlabeled questions to labeled questions in specific applications by maximizing the mutual information between both. Extensive experiments on real-world datasets demonstrate that DisenQNet can generate effective and meaningful disentangled representations for questions, and furthermore, DisenQNet+ can improve the performance of different applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Information extraction; • Computing methodologies → Knowledge representation and reasoning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Online learning systems, such as coursera.org, edX.org and xuetangx.com, have attracted a large number of learners around the world <ref type="bibr" target="#b0">[1]</ref>. In 2020, the Covid19 pandemic has impact promoted the proliferation of online learning. According to the statistics of Cousera (https://www.coursera.org/), over 77 million users are now learning and practicing on the platform.</p><p>Nowadays, online learning systems collect millions of learning materials (e.g., course and question), and facilitate many personalized applications to improve learning experiences of students <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b35">36]</ref>. On one hand, students can select suitable courses or questions to acquire knowledge according to their needs, e.g., selecting similar questions to review required concepts after answering one question incorrectly <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref>. On the other hand, systems personalize necessary services based on students' feedbacks, e.g., recommending easier questions if noticing that students are struggling with current materials <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref>. To support such services, it is necessary to well organize the learning materials in advance <ref type="bibr" target="#b3">[4]</ref>, especially educational questions. This brings out a fundamental research topic of question understanding in AI education <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b34">35]</ref>, with the goal of learning informative representations of educational questions.</p><p>In the literature, focusing on different question-based applications, such as difficulty estimation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref> and similarity analysis <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21]</ref>, many efforts have been developed for understanding question content by taking advantage of natural language processing (NLP) techniques. In general, they design different models to learn question representations as syntactic patterns or semantic encodings, which are directly optimized in specific application tasks. For example, Qiu et al. <ref type="bibr" target="#b23">[24]</ref> extracted semantic representations of multiple-choice questions to predict the difficulty. Though they have gained some achievements, there exist some limitations in practical systems as follows. First, existing models follow supervised manner, which requires sufficient labeled data (e.g., difficulty or similarity in Figure <ref type="figure" target="#fig_0">1</ref>) for optimization. However, getting highquality labels for questions is extremely hard in practice because experts to be competent should acquire enough professional knowledge (so we cannot take crowdsourcing in many traditional domains like e-commerce) <ref type="bibr" target="#b36">[37]</ref>. As indicated in the literatures, for example, labeling similar questions should understand their psychological purpose <ref type="bibr" target="#b17">[18]</ref> and calculating the difficulty scores even requires being examined in standard tests (e.g., GRE test) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26]</ref>. Therefore,  Green parts present their personal information. Right red labels tell us that Q 1 is harder than Q 2 and Q 2 is similar to Q 3 . such models cannot ensure the representation ability sometimes due to the scarce labels. Second, their representation results are taskdependent, which has poor feasibility to be applied across different applications <ref type="bibr" target="#b5">[6]</ref>. That is to say, we have to design different models to represent same questions for different applications. Third, although Yin et al. <ref type="bibr" target="#b35">[36]</ref> pre-trained question representations to enhance the model ability with unlabeled data, all existing solutions equally represent a certain question as one unified vector, where all the information are integrated together. However, questions with same concepts (e.g., "Function") can be quite different from its content to show personal properties (e.g., difficulty) <ref type="bibr" target="#b13">[14]</ref>. For example in Figure <ref type="figure" target="#fig_0">1</ref>, question Q 1 is harder than Q 2 as it has more complicated expressions. Therefore, if we cannot distinguish such differences, it may introduce some noises and mislead the applications.</p><p>To this end, we argue that an ideal question representation model should satisfy three desirable abilities: 1) It can get rid of the labels in specific tasks, which can be optimized by learning questions on their own. 2) It should distinguish the diverse characteristics of questions inherent by an explicit way. 3) The learned representations should be flexible for being applied in different downstream tasks.</p><p>In this paper, we propose a novel unsupervised model, namely DisenQNet, for question representation learning. In DisenQNet, we aim to disentangle one question into two parts: a concept representation and an individual representation. Specifically, we develop three self-supervised estimators to optimize two disentanglements. First, we learn the question semantics by maximizing the mutual information between itself and our two disentangled representations. Second, we enforce the concept representation with explicit meaning by making prediction of its concepts. Third, we propose an adversarial process to ensure two disentanglements independent so that the individual one can preserve the question personality itself. Particularly, DisenQNet can be optimized by learning questions on their own without any additional annotations.</p><p>In addition, we propose another enhanced model, namely Dis-enQNet+, that applies our learned representations to several application tasks. Specifically, since our individual disentanglement especially leaves the personal information of one question without concept, it can be adapted to improve the representation ability of supervised models in different tasks even if owning very limited labeled data. We achieve this goal by maximizing the mutual information between the unsupervised representations and the supervised representations so that the knowledge can be transferred from DisenQNet to supervised models in different applications.</p><p>We perform extensive experiments on three datasets. We empirically show that DisenQNet can generate meaningful disentangled representations of educational questions, and DisenQNet+ can improve the performance on domain-specific applications including difficulty estimation and similarity analysis. To the best of our knowledge, this is the first few attempts to learn disentangled representations for educational questions by distinguishing the concept and individual effects via mutual information estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we summarize the related work as follows.</p><p>Question Understanding. Online learning systems can collect abundant educational materials, e.g., courses and questions, so that provide several intelligent services, such as searching target questions and personalized recommendation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>, which attracts many participations from the public. It is necessary to help systems organize such materials, and thus triggers a fundamental issue in AI education of question understanding. In the earlier time, scholars try to design fine-grained rules or grammars to understand questions, where they can be organized by specific structures like semantic trees or templates <ref type="bibr" target="#b8">[9]</ref>. However, such structures require manually design with strong expertise and cost much time, but could only match very limited questions with weak abilities. Obviously, they are not suitable for online systems nowadays that contain millions of question resources. Therefore, recent advances try to automatically understand question textual content with semantic representations via natural language processing techniques, and support several applications, such as difficulty estimation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref>, similarity search <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref>, question solving <ref type="bibr" target="#b14">[15]</ref> and student performance prediction <ref type="bibr" target="#b18">[19]</ref>. For example, Qiu et al. <ref type="bibr" target="#b23">[24]</ref> extracted semantic representations of multiple-choice questions to predict their difficulty properties. Liu et al. <ref type="bibr" target="#b17">[18]</ref> proposed an attention model to evaluate the similarities of question pairs integrated with the heterogeneous information. Though achieving some success, most of them generally follow a supervised manner, which suffer from two main problems. First, the models require enough labeled data to ensure the performance. However, labeling educational questions is hard in practice because experts to be competent should acquire enough professional knowledge. For example, estimating the difficulties of GRE questions require organizing the exams with volunteers <ref type="bibr" target="#b4">[5]</ref>. Such effort is even harder than traditional domains, such as news, e-commerce <ref type="bibr" target="#b36">[37]</ref>, where crowdsourcing fails in practice. Second, the learned question representations are task-specific, which are incapable of being applied cross tasks. In other words, we should design many complicated models for different tasks.</p><p>Question Pre-training. To deal with the problems of supervised solutions above, pre-training, as a kind of typical unsupervised techniques, can make use of large-scale unlabeled data to enhance the representation ability for different data structures, such as text <ref type="bibr" target="#b7">[8]</ref> and image <ref type="bibr" target="#b9">[10]</ref>. Since we focus on how to learn question representation from its textual content, we generally review some NLP efforts. Generally, representative methods can be divided into two categories: feature-based methods, where text is represented by some sorts of feature extractors as fixed vectors <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, and pre-training based methods, where parameters of models are pretrained on corpus and then fine-tuned in specific tasks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13]</ref>. Specially, BERT <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> and GPT <ref type="bibr" target="#b24">[25]</ref> are two of the most successful methods, which have already performed impressively in many classic NLP tasks including question-answering machine translation, etc, and continuously upgraded in recent years. To the best of our knowledge, Yin et al. <ref type="bibr" target="#b35">[36]</ref> made the first attempt to pre-train the representations of educational questions from the heterogeneous data. In summary, the main goal of pre-training methods is to make full use of large corpus, which try to integrate all the information together to learn one unified representation for each input. However, in practical learning systems, students try to distinguish the differences of questions, e.g., questions with same concepts but have inconsistent difficulty levels. Therefore, these pre-training methods may be unsatisfactory.</p><p>Mutual Information. Mutual information is a fundamental quantity for measuring the dependency between random variables <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17]</ref>. Since the mutual information is historically difficult to compute for high-dimensional variables, recent works employ several non-linear estimators based on deep neural networks to maximize mutual information for representation learning in many domains, such as image <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12]</ref>, graph <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> and recommendation <ref type="bibr" target="#b28">[29]</ref>. For example, Hjelm et al. <ref type="bibr" target="#b11">[12]</ref> proposed Deep InfoMax to learn image representations via Jensen-Shannon divergence. Velickovic et al. <ref type="bibr" target="#b31">[32]</ref> and Sun et al. <ref type="bibr" target="#b30">[31]</ref> proposed DGI and InfoGraph for graph learning in terms of generating node level embeddings and graph level embeddings, respectively. On the basis, Sanchez et al. <ref type="bibr" target="#b27">[28]</ref> employed mutual information estimation to learn image disentangled representations with the shared ones and exclusive ones via pairwise instance learning.</p><p>Our work targets at representation learning for educational questions. We try to propose an unsupervised model to disentangle one question by distinguishing its concept meaning and individual information via mutual information estimation on its own. We also propose a principle way to transfer our learned representations in several downstream tasks, and therefore, provide a solid backbone in use of questions in online learning systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we present the formal problem definition and introduce some basic knowledge of mutual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>We focus on two problems. First, we define unsupervised representation learning problem for educational questions. Then, we present question-based application tasks in online learning systems.</p><formula xml:id="formula_0">3.1.1 Unsupervised Question Representation Learning. Let Q de- note a set of N questions Q = {q 1 , q 2 , • • • , q N }. Each question q ∈ Q is given as its text content with a sequence of M word to- kens q = {x 1 , x 2 , • • • , x M }, along with the concepts k ∈ K, where |K | is the</formula><p>number of all concepts in the system. Please note that each exercise may contain multiple concepts as shown in Table <ref type="table" target="#tab_1">1</ref>. Traditionally, the representation learning for a certain question is to output one unified d-dimensional vector (d ≪ N ), which should capture as much information as possible. However, as we mentioned in Section 1, questions with same concepts can be quite different, so that it is worthwhile to distinguish such differences in an explicit way. Therefore, our goal of disentangled question representation learning transforms to output two d-dimensional vectors including one v k ∈ R d referring to its concept information and the other v i ∈ R d capturing the individual characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Question-based Supervised Tasks. The original question set</head><formula xml:id="formula_1">Q can be divided into two subsets Q L and Q U . Specifically, Q L = {q 1 , q 2 , • • • , q L }</formula><p>represents the labeled questions whose properties have been obtained by expertise or organizations, i.e., {y 1 ,</p><formula xml:id="formula_2">y 2 , • • • , y L }. Comparatively, Q U = {q 1 , q 2 , • • • , q U } is the unlabeled questions whose properties remain unknown. Specifically, Q = Q L ∪ Q U , and |Q L | ≪ |Q U | in most cases.</formula><p>In real-world scenarios, the properties can be specified with different labels, e.g., the difficulty level of one specific question or the similarity score between a pair<ref type="foot" target="#foot_0">1</ref> . Given both Q L and Q U , our general goal of supervised task can be formulated as learning a model to predict the properties of unknown questions. In this paper, we focus on two representative supervised application tasks including difficulty estimation and similarity analysis, which will be discussed in detail in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mutual Information</head><p>In this subsection, we briefly introduce some related basic knowledge of mutual information. In information theory, mutual information I (X , Y ) measures the dependence between two random variables X ∈ X and Y ∈ Y, which can be expressed as the decrease of the uncertainty in one given the other:</p><formula xml:id="formula_3">I (X ; Y ) = H (X ) − H (X |Y ) = H (Y ) − H (Y |X ),<label>(1)</label></formula><p>where, H (X ) and H (X |Y ) are the Shannon entropy and the conditional entropy of X given Y , respectively. Generally, Eq. ( <ref type="formula" target="#formula_3">1</ref>) is equivalent to the Kullback-Leibler (KL) divergence between the joint distribution P(X , Y ) and the product of two marginals P(X ) ⊗ P(Y ) as:</p><formula xml:id="formula_4">I (X ; Y ) = D K L (P(X , Y )||P(X ) ⊗ P(Y )). Intuitively, I (X ; Y )=0 means</formula><p>variables X and Y are independent, and the larger the value is, the stronger the dependence they have. However, directly computing the mutual information I (X ; Y ), if variables X and Y are continuous and high-dimensional, is extremely difficult <ref type="bibr" target="#b2">[3]</ref>. Therefore, Belghazi et al. <ref type="bibr" target="#b2">[3]</ref> developed a nonlinear neural network estimator MINE to measure a tight lower bound of it, which is based on the Donsker-Varadhan representation, a dual representation of KL-divergence as:</p><formula xml:id="formula_5">Î (DV ) θ := D K L (P(X , Y )||P(X ) ⊗ P(Y )) := E P(X,Y ) [T θ (x, y)] − log E P(X )P(Y ) e T θ (x,y) , (2)</formula><p>where T θ (x, y) : X × Y → R is the neural network approximator with parameters θ . In practice, using estimator in Eq. ( <ref type="formula">2</ref>) is not stable because it is sensitive to negative samples. To overcome this problem, noticing that the representation learning work does not focus on the precise value of mutual information, but on maximizing it, Hjelm et al. <ref type="bibr" target="#b11">[12]</ref> introduced a approximate Jensen-Shannon (JS) divergence based estimator as:</p><formula xml:id="formula_6">Î (J S ) θ := D J S (P(X , Y )||P(X ) ⊗ P(Y )) := E P(X,Y ) [−sp(−T θ (x, y))] − E P(X )P(Y ) [sp(T θ (x, y))] ,<label>(3)</label></formula><p>where sp(x) = log(1 + e x ) is the softplus function.</p><p>In this paper, we employ this method in a principle way as we focus on learning representations for educational questions. Readers who are interested in mutual information can refer to the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17]</ref> for more details. </p><formula xml:id="formula_7">v 1 v 2 v M v K v I Concept Estimator L CP MI Estimator L MI Disentangling Estimator L Dis Question Encoder v q Embedding ... { } x 1 x 2 x M q = ... Text Encoder v 1 v 2 v M ... v K v I r q MI Mutual Information Estimator v K Prediction Concept BCE Concept Estimator v K v I Discriminator Joint Marginal</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+ -</head><note type="other">Disentangling Estimator</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY 4.1 DisenQNet</head><p>We propose a novel unsupervised model, namely DisenQNet, for our first problem of question representation learning. Different from most existing models which integrate all the information together <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b35">36]</ref>, our DisenQNet tries to distinguish both the concept information and individual characteristics of one question in an explicit way. Figure <ref type="figure" target="#fig_1">2</ref> illustrates its general model architecture, which consists of the question encoder and self-supervised optimization.</p><p>4.1.1 Question Encoder. We disentangle the final question representation into two parts, i.e., the concept representation v K that captures its concept information and the individual representation v I that preserves the personal characteristics, i.e.,</p><formula xml:id="formula_8">r q = (v K , v I ). Given a certain question q = {x 1 , x 2 , • • • , x M }, we initialize each of them {x n } by a d 0 -dimensional word embedding, i.e., V = {v 1 , v 2 , • • • , v M , v m ∈ R d 0 }.</formula><p>Then, we perform a text encoder, via a neural network, i.e., f θ : R d 0 ×M → R d q , to generate its integrated semantic representation v q from its content input V :</p><formula xml:id="formula_9">v q = f θ ({v m : v m ∈ V }).<label>(4)</label></formula><p>Note that the text encoder f θ can be specified with several models like CNN, LSTM etc. We do not emphasize their differences and implement it by TextCNN <ref type="bibr" target="#b15">[16]</ref>, as it is computationally efficient.</p><p>After that, we try to split this integrate semantics v q into two disentangled representations, i.e., the concept representation v K and the individual representation v I . As shown in Figure <ref type="figure" target="#fig_0">1</ref>, such two disentanglements may focus on different content in the question. For example, some informative words like "odd function" tell what concepts the question Q 1 has, and therefore, contribute more to the concept part. Comparatively, mathematical expressions like "f(-1)=2" bring the detailed information of itself. Therefore, we perform two attention networks to capture such differences in the modeling. Specifically, the two networks are established with same architecture but different parameters, so as to quantify the dominant contents on the target disentanglements, guiding the modeling. As the representative, for obtaining the concept representation v K , the corresponding attention network can be formulated as:</p><formula xml:id="formula_10">v K = M j=1 α j v j , α j = Softmax(MLP(v j , v q )),<label>(5)</label></formula><p>where α j represents the weight score of word x j to the concept vector v K , which is normalized by Softmax function. MLP is the multi-layer perception network that captures the distance between two vectors (v j , v q ). The individual presentation v I is generated with another attention network similarly.</p><p>4.1.2 Self-supervised optimization. Now, we discuss how to optimize DisenQNet to learn two desirable disentanglements. The challenge here is that we can only extract the unique question characteristics itself without any additional explicit labels. Thus, as shown in Figure <ref type="figure" target="#fig_1">2</ref>, we propose three estimators with self-supervised objectives to guide model learning including mutual information (MI) estimator, concept estimator and disentangling estimator. MI Estimator. First, our learned disentangled representations, i.e., r q = (v K , v I ), should capture the given question information in all. We perform the MI estimator on the given question, which maximizes the estimated mutual information between the concatenation r q and the question content V . As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, we perform this MI maximization on each word v j ∈ V in the question, in which every local word information can be estimated with the global concatenation r q smoothly. This objective can be expressed as maximizing the JS-divergence based estimator (Eq. ( <ref type="formula" target="#formula_6">3</ref>)) as:</p><formula xml:id="formula_11">L M I = Î (J S ) θ 1 (r q , V ) = 1 M M j=1 E P(r q ,v j ) −sp(−T θ 1 (r q , v j )) − E P(r q )P(v j ) sp(T θ 1 (r q , v j )) ,<label>(6)</label></formula><p>where the approximator T θ 1 is designed with a multi-layer fully connected network. In practice, it is not easy to directly get P(r q )P(v j ), but we take the similar technique in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b30">31]</ref> to achieve that by shuffling either of them in a batch sampling from P(r q , v j ). Concept Estimator. Next, we ensure our concept representation v K with the explicit concept meaning of the given question. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, we perform the concept estimator to predict its given one-hot concept encoding k ∈ {0, 1} |K | by h ϕ 1 (v K ), where the network h ϕ 1 : R d → R |K | projects the concept disentanglement v K into the prediction. Therefore, this estimator is defined as minimizing the binary cross-entropy (BCE) objective:</p><formula xml:id="formula_12">L C P = 1 |K | |K | j=1 (k j log(h ϕ 1 (v K ) j ) + (1 − k j ) log(1 − h ϕ 1 (v K ) j )).</formula><p>(7) Disentangling Estimator. Last, the disentangling estimator preserves the personal characteristics of the given question in its individual representation v I . Recall the example in Figure <ref type="figure" target="#fig_0">1</ref>, questions with the same concepts ("Function") are different reflected by their properties (e.g., difficulty). Along this line, our ideal individual representation v I must not contain the information captured by the concept one v K , and should be independent with v K . Therefore, our intuitive goal here is to minimize the mutual information between v K and v I . However, as Sanchez et al. <ref type="bibr" target="#b27">[28]</ref> suggested, we cannot directly achieve this goal by minimizing Eq. ( <ref type="formula" target="#formula_6">3</ref>) since the estimator fails to converge when minimizing. As an alternative, in this work, we propose an adversarial process that minimizes the distance between the joint distribution P(v K , v I ) and the marginals P(v K )P(v I ). Specifically, as shown in Figure <ref type="figure" target="#fig_1">2</ref>, our adversarial process contains two components. First, we train a discriminator D Φ to classify the sampled representations drawn from the joint P(v K , v I ) as the real and samples drawn from the marginals P(v K )P(v I ) as the fake. Then, we train our DisenQNet that can fool the discriminator D Φ by shuffling the individual representations of samples in a batch from P(v K , v I ). During this process, our DisenQNet tries to generate the combined disentanglements (v K , v I ) that look like drawn from P(v K )P(v I ), and therefore, ensures the independence as we desire. More formally, we express such adversarial objective which is similar to WGAN with spectral normalization <ref type="bibr" target="#b1">[2]</ref> since it is more stable in the learning process:</p><formula xml:id="formula_13">L Dis = E P(v k ,v i ) D ϕ (v k , v i ) − E P(v k )P(v i ) D ϕ (v k , v i ) . (8)</formula><p>By combining Eq. ( <ref type="formula" target="#formula_11">6</ref>), Eq. ( <ref type="formula">7</ref>) and Eq. ( <ref type="formula">8</ref>), our final objective of DisenQNet is defined with the hyper-parameters λ 1 , λ 2 , and λ 3 as:</p><formula xml:id="formula_14">L DisenQNet = −λ 1 L M I + λ 2 L C P + λ 3 L Dis .<label>(9)</label></formula><p>The overall objective can be minimized using SGD with the Adam optimizer. We will specify the details in the experiments. In summary, our DisenQNet has the following advantages. First, it learns question representations only with the characteristics themselves without requiring additional labels, where large corpus of unlabeled questions could be well leveraged to enhance the ability. Second, it splits questions into two independent disentanglements via mutual information estimation so that it can distinguish the different effects of both concept meaning and personal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DisenQNet+</head><p>In this subsection, we deal with the second goal of question-based tasks based on our representation results. Most of existing solutions <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b17">18]</ref> devote many efforts to several application tasks (e.g., difficulty estimation) in a supervised manner. In practice, they may suffer from the following two problems. First, they are label-hungry, as the performances rely on the sufficient annotations (e.g., difficulty). However, getting high-quality labels is costly with high expertise, which would be easily unsatisfactory. Second, their learned representations are label-dependent, which have poor feasibility to be applied across different tasks. To overcome such issues, we propose an enhanced model to apply our DisenQNet to the downstream tasks for improving the performance. We call it DisenQNet+.</p><p>Note that most applications focus on distinguishing the differences among questions. For example in Figure <ref type="figure" target="#fig_0">1</ref>, even if the three are related to the same "Function" concept, Q 1 is harder than Q 2 since it has more complicated mathematical expressions, and Q 2 is similar to Q 3 due to possible same purpose ("What is the range... "). Therefore, an ideal model should devote more energy to capture the unique information of one question itself rather than the same part. Motivated by this intuition, in our DisenQNet+, we directly transfer our individual representations (from DisenQNet) to downstream models, since this disentanglement especially removes the concept information but leaves its personal characteristics of one question. (We show it experimentally in Section 5.3). The architecture of DisenQNet+ is illustrated in Figure <ref type="figure" target="#fig_2">3</ref>.</p><p>Without loss of generality, we can take the common process for one specific application in the following. Specifically, given </p><formula xml:id="formula_15">L j ∈ Q L , we first design a task model f δ : R d 0 ×M → R d t to produce its task-specific semantic representation v L j ∈ R d t , i.e., v L j = f δ (q L j ).</formula><p>Then, we apply one prediction network h ϕ 2 : R d t → R that outputs the task prediction, i.e., p j = h ϕ 2 (v L j ). In summary, the task loss on label set Q L can be formulated in a supervised manner as:</p><formula xml:id="formula_16">L Sup = |Q L | j=1 L P (p j , y j ), p j = h ϕ 2 (v L j ),<label>(10)</label></formula><p>where L P (p j , y j ) represents the loss function between the prediction p j and the true label y j of the given labeled question q L j . Obviously, due to the scarcity of labeled set, models only trained with Eq. ( <ref type="formula" target="#formula_16">10</ref>) may be overfitting, as the semantic representation v L j may not be optimized very well. Therefore, we design another component to enhance this representation ability, where a pre-trained unsupervised DisenQNet on all question set (Q L , Q U ) is incorporated to generate the individual disentanglement v U I of the given in parallel for being transferred. To achieve the goal, a straightforward way is to concatenate both v U I and v L j , and then make the prediction. However, this simple way may lead to negative transfer problem <ref type="bibr" target="#b30">[31]</ref> since the supervised task model and unsupervised DisenQNet may favor different information in the latent space. Therefore, we propose an effective way to alleviate this adaptation problem. Specifically, we perform another estimator to maximize the mutual information between v U I and v L j , so that the knowledge from DisenQNet can be transferred to the task models in applications more smoothly. Formally, this process can be formulated with the JS-divergence estimator as:</p><formula xml:id="formula_17">L U n = Î (J S ) θ 2 (v U I , v L j ) = E P(v U I ,v L j ) −sp(−T θ 2 (v U I , v L j )) − E P(v U I )P(v L j ) sp(T θ 2 (v U I , v L j )) . (<label>11</label></formula><formula xml:id="formula_18">)</formula><p>where the statistics approximator T θ 2 is also designed with a multi layer fully connected network. Therefore, the overall loss in DisenQNet+ can be summarized with the hyper-parameter λ 4 and λ 5 as:</p><formula xml:id="formula_19">L DisenQNet+ = λ 4 L Sup − λ 5 L U n . (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>Similarly, this objective can be minimized using SGD with the Adam optimizer, which will be specified in details in the experiments. Particularly, our DisenQNet+ is flexible for different downstream tasks with their original supervised loss functions (e.g., ranking loss or classification loss). We will discuss it in detail in Section 5.3. Moreover, the task model f δ can also be specified with any related ones, e.g., TACNN <ref type="bibr" target="#b13">[14]</ref> in difficulty estimation task or MANN <ref type="bibr" target="#b17">[18]</ref> in question search task. In this paper, we do not put much emphasis on comparing the performances of complicated task models, and therefore, we implement f δ by the commonly used and useful TextCNN <ref type="bibr" target="#b15">[16]</ref> in a principle way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We run all experiments on a Linux server with four 2.0GHz Intel Xeon E5-2620 CPUs and a Tesla K80 GPU. Our code is available at https://github.com/bigdata-ustc/DisenQNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We use three datasets in the experiments, namely SYSTEM1, SYS-TEM2, and Math23K. The SYSTEM1 and SYSTEM2 datasets collect the mathematical questions from the online learning system iFLY-TEK Zhixue.com that respectively accord with high-school level and middle-school level. Specifically, SYSTEM1 dataset contains 108,137 questions and 31 concepts in total, while SYSTEM2 consists of 25,293 questions with 21 concepts. The concepts are those commonly required being mastered for high-school and middle-school students, such as "Function", "Geometry" and "Set". The Math23K is a public dataset which is primarily used for math word problem task in NLP <ref type="bibr" target="#b33">[34]</ref>. It contains 23,162 questions for elementary school students. Specifically, questions in Math23K do not have explicit concepts, and are only supplied with mathematical expressions consisting of five elementary operations including addition (+), subtraction (−), multiplication (×), division (÷) and power (∧). Please refer to Wang et al. <ref type="bibr" target="#b33">[34]</ref> for more details. Therefore, we treat such operators (5 in total) as the concepts since they can generally reveal the corresponding calculation knowledge. We focus on several question-based application tasks in online learning systems, and therefore, we get some specific property labels. Specifically, in SYSTEM1, we follow <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26]</ref> and calculate the difficulty scores of questions, which refers to the correct rate of students. To ensure confidence, we just leave the questions that have more than one hundred students answered, and finally, we get 5,291 questions labeled. In SYSTEM2, we invite three experts (i.e., high school teachers) to label similar questions, where each similar pair would only be left when more than two of them agree with the results. As a result, we get 2,944 questions labeled with several similar ones. In Math23K, we do not have the manual labels while we make the following preprocessing to get the difficulty labels. First, without loss of generality, we think that questions would be more difficult if they have longer mathematical expressions (which means students need more calculation steps to get the answers), and thus we treat the expression length as the difficulty. Second, we select 2,000 questions with difficulty labels in the application task. The difficulty scores are normalized in the range [0, 1].</p><p>Table <ref type="table" target="#tab_1">1</ref> presents the deep statistics of all datasets. There are some observations. First, questions in SYSTEM2 are more difficult for representation learning since they have longer length on average (129.96) than those in other two. Second, our labeled data are limited, as the label sparsities in three datasets are 4.9%, 11.6%, and 8.7%, respectively. Note that, although questions having labels take more than 10% in SYSTEM2, they only have 1.29 similar ones on average, which means that comparing with the total corpus, one question still has very limited (unbalanced) annotations in the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">DisenQNet Evaluation</head><p>In this subsection, we first evaluate DisenQNet, where we aim to show the effectiveness of our learned two disentanglements, i.e., the concept representation v K and the individual representation v I . To achieve the goal, we perform the concept prediction, which could be treated as the classification task, with the goal to predict the concepts of questions by model representations.</p><p>Experimental Settings. We initialize the DisenQNet as follows. We set the attention network (Eq. ( <ref type="formula" target="#formula_10">5</ref>)), the MI statistics network f θ 1 (Eq. ( <ref type="formula" target="#formula_11">6</ref>)), the concept network h ϕ 1 (Eq. ( <ref type="formula">7</ref>)) and the discriminator D ϕ (Eq. ( <ref type="formula">8</ref>)) all as the MLP with 2 layers. We also pre-train the word2vec <ref type="bibr" target="#b19">[20]</ref> tool on all our question corpus to ensure better word embedding. Then, we set the dimension d 0 of word embedding vector, d of both disentangled representations all as 128.</p><p>In the training process, we randomly partition all questions into training/test sets with 80%/20%. We follow <ref type="bibr" target="#b10">[11]</ref> and set up the model parameters with He initialization. We set the hyper-parameters in Eq. ( <ref type="formula" target="#formula_14">9</ref>) as: λ 1 =1, λ 2 =1.5, λ 3 =2. The learning rates are 0.0002, 0.001, 0.001 in SYSTEM1, SYSTEM2, Math23K, respectively. We set mini batches as 128 for training and used dropout (with probability 20%).</p><p>Comparison Methods. Please note that we do not put much emphasis on providing the complicated networks for text classification, but perform the disentangled representation effectiveness for educational questions. Therefore, we introduce baseline models as: one commonly used text model TextCNN, two typical pre-training NLP methods ELMo and BERT, and one SOTA pre-training question representation model QuesNet. We also introduce our two disentanglements (i.e., v K and v I ) from DisenQNet into evaluation:</p><p>• TextCNN : TextCNN <ref type="bibr" target="#b15">[16]</ref> is a classical textual model for sentence level classification with convolutional neural network. • ELMo: It is a LSTM based feature extraction method with bidirectional language model as pre-training strategy <ref type="bibr" target="#b22">[23]</ref>. • BERT : It is a popular pre-trained method in NLP featuring Transformer structure and masked language model. As our question content are based on Chinese, we selected Chinese BERT in the experiments <ref type="bibr" target="#b6">[7]</ref>. • QuesNet: QuesNet <ref type="bibr" target="#b35">[36]</ref> is the SOTA pre-trained model for educational question representation learning, with considering heterogeneous data including text, image and side information. We simplify it as just modeling question text. • DisenQNet-v K : We use the concept representation v K in our DisenQNet with a 2 layer MLP for prediction. • DisenQNet-v I : We use the individual representation v I in our DisenQNet with a 2 layer MLP for prediction.</p><p>Table <ref type="table">2</ref>: Concept prediction performance of all methods on three datasets.  </p><formula xml:id="formula_21">Datasets SYSTEM1 SYSTEM2 Math23K Metrics Micro-F1@k Macro-F1@k Micro-F1@k Macro-F1@k Micro-F1@k Macro-F1@k 1 2 1 2 1 2 1 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Concept Prediction</head><p>Performance. We treat the concept prediction task as multi-label classification, as questions in the datasets may related to not only one concept (Table <ref type="table" target="#tab_1">1</ref>). Therefore, we select the widely-used Micro-F1@k and Macro-F1@k as metrics. We repeat all experiments five times and report the average results in Table <ref type="table">2</ref>. There are some observations. First, DisenQNet performs the best on all datasets. This demonstrates distinguishing different information, rather than integrating them all, is reasonable for question representation learning. Second, our learned disentangled representations achieve the expected results. Specifically, the concept representations reach the best compared with all since they capture the concept information of questions. Comparatively, the individual ones, which preserves the personal characteristics, fail on this task. Third, we see that the pre-training models (ElMo, BERT, QuesNet) perform better than the traditional TextCNN, which means that they can extract more semantics with their more sophisticated architectures. Last, there is an interesting result that QuesNet, as the domain-specific model for question pre-training, does not perform consistently better than BERT, especially on SYSTEM2. This is possibly because we just use it as the text-only model, so that overlooking some important effects from the heterogeneous data like image. In summary, DisenQNet can distinguish the concept and individual effects for question representation learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Disentanglement Visualization.</head><p>As we mentioned, DisenQNet can disentangle one question into two parts: a concept representation that captures its concept meaning and an individual representation that preserves its personality. Here, we intuitively demonstrate such representation ability. We choose top 5 frequent concepts, and randomly sample 2000 questions for each in SYSTEM1. Then we project their two disentanglements, i.e., v K and v I , into 2D space by t-SNE for visualization. We mark questions with their concepts using different colors. Figure <ref type="figure" target="#fig_3">4</ref> shows the results. Generally, questions with same concepts from their concept representations are easily . to be grouped, meaning that they have well maintained the concept information. Comparatively, their individual representations are scattered because they are independent with the concept ones that preserve the other personal characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Parameter Sensitivity.</head><p>In DisenQNet, both λ 2 and λ 3 in the objective function Eq. ( <ref type="formula" target="#formula_14">9</ref>) play the important role for modeling learning. Specifically, λ 2 regularizes how much information the concept representations capture, while λ 3 controls the degree of personality in questions to be preserved by the individual representations. Figure <ref type="figure" target="#fig_4">5</ref> shows the model performance with both parameters selecting from {0, 0.1, 0.2, 0.5, 1, 2, 5}. As λ 2 increases, the concept representations perform better and better since they capture concept information of questions as much as possible. However, the individual presentations gradually get lost with the increase of λ 3 . This is because they distinguish both concept and personal information of questions, and just leave the personalities if λ 3 is large. Therefore, they work ideally that help DisenQNet learn good disentangled representations for educational questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Case Study.</head><p>DisenQNet can quantify the dominant content on the learned disentangled representations for educational questions via different attention scores in Eq. ( <ref type="formula" target="#formula_10">5</ref>). Here, we visualize attention results of one question example in SYSTEM1 dataset in Figure <ref type="figure">6</ref>. In the figure, we present the original question text and the English translation on the top. We also mark the words with higher attention scores in its both representations using different colors, i.e., red for the concept representation and blue for the individual one. We can clearly see they focus on different parts. Specifically, the concept representation v K is more related to four words ("Odd function", "monotonically increasing", "inequality", "solution set") which show the concept meaning. Comparatively, the individual representation v I concerns more on mathematical expressions (e.g., "f (−1) = 2"), which means that expression details can reveal personal characteristics of the question itself. </p><formula xml:id="formula_22">.0 0.3 已知 定义 在 R 上 的 奇函数 f ( x ) 在 ) 的 解集 ( 0, + ∞ ) 上 单调 递增， 且 f ( - 1 ) = 2, 则 不等式 f ( x - 1 ) + 2 ≦ 0 在 ( 0, + ∞ 为 &lt;target&gt;.</formula><p>(VK) (VI)</p><p>Given that the odd function f(x) defined on R is monotonically increasing in (0, +∞) and f(-1)=2, then what is the solution set of inequality f(x-1)+2&lt;=0 in (0, +∞)?</p><p>已知 定义 在 R 上 的 奇函数 f ( x ) 在 ( 0, +∞) 上 单调 递增 且 f ( -1 ) = 2, 则 不等式 f ( x -1) + 2 &lt;= 0 在 ( 0, +∞ ) 的 解集 为?</p><p>Figure <ref type="figure">6</ref>: Attention visualization of one example question for its concept presentation and individual representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">DisenQNet+ Evaluation</head><p>We now evaluate DisenQNet+, where we aim to show the effectiveness of our question representations in the downstream tasks. Based on our datasets, we perform the difficulty estimation task <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref> in SYSTEM1 and Math23K, where the goal is to sort the questions from harder ones to the easier under concepts. Then, we perform the similarity analysis task <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref> in SYSTEM2, which targets at ranking questions that are similar to one specific. Experimental Settings. We treat the both as ranking tasks. Therefore, the supervised objective in Eq. ( <ref type="formula" target="#formula_16">10</ref>) can be rewritten as:</p><formula xml:id="formula_23">L Sup = (q,q+,q−)∈Q max(0, µ − h ϕ 2 (v q , v q+ ) + h ϕ 2 (v q , v q− )), (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>where µ=1 is the margin hyperparameter. q, q + , q − mean the pivot, positive and negative questions. For difficulty ranking (SYSTEM1 and Math23K), we sample question pairs, where q + and q − represent the harder and easier ones (we set q as NULL), so that Eq. ( <ref type="formula" target="#formula_23">13</ref>) lets the estimated score of the positive q + be larger than the negative q − . For similarity ranking (SYSTEM2), given one pivot q, we sample the positive q + as its similar questions, and q − as the others, so that Eq. ( <ref type="formula" target="#formula_23">13</ref>) makes the estimated distance between positive pairs (q, q + ) closer, and separates negative pairs (q, q − ) farther.</p><p>In DisenQNet+, we set the MI network f θ 2 (Eq. ( <ref type="formula" target="#formula_19">12</ref>)) and the prediction network h ϕ 2 (Eq. ( <ref type="formula" target="#formula_23">13</ref>)) as 2-layer MLP. We set d t =128 for task-specific representation. In the training process, we set λ 4 =1, λ 5 ∈ [0, 0.1] in Eq. <ref type="bibr" target="#b9">(10)</ref>. Other settings are the same with DisenQNet.</p><p>We train our unsupervised DisenQNet model on all questions in the datasets. In both tasks, we partition the labeled questions into training/test sets with 20%/80%, 40%/60%, 60%/40%, 80%/20% to show the model robustness with different sparsity ratios.</p><p>Comparison Methods. In our work, we aim to show a rigorous comparative analysis of our disentangled question representation effectiveness in a common framework since the task models can be implemented by any ones, as mentioned in Section 4.2. Therefore, we introduce the following comparison models. We use the task model only with labeled data, namely "Supervised". Then, we pretrain ElMo, BERT and QuesNet on all corpus (similar to DisenQNet), and then apply their enhanced representations in the task model. Last, we apply our two disentanglements v K and v I in DisenQNet+.</p><p>Experimental Results. Figure <ref type="figure">7</ref> shows the overall results on all datasets. Specifically, we adopt the ranking metrics including MAP@5, NDCG@5, and F1@5 <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b32">33]</ref> to evaluate similarity analysis task, but replace F1@5 by DOA metric in difficulty estimation task (We can rank all questions in this task, so we use DOA to measure the result of total lists). We calculate the metric scores on each concept and report the average results of all. Generally, DisenQNet+(v I ) performs the best to improve the results significantly on all datasets. Therefore, it gains the better question representations, where the knowledge from DisenQNet can be transferred more effectively to both tasks. Moreover, it outperforms DisenQNet+(v K ). This demonstrates that the individual disentanglements from DisenQNet, preserving the personality of questions, are more capable of being applied to both tasks because they can distinguish the differences among questions without concept meaning. Then, only using the supervised model does not generate satisfactory results since it cannot ensure the representation ability with limited labeled data. Last, although traditional pre-training models (ElMo, BERT, QuesNet) improve the results, they do not perform as well as ours because they may introduce noises by integrating all question information together in application tasks. Our DisenQNet+ has potentials to support several online educational services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we learned disentangled representations of educational questions. We proposed an unsupervised model DisenQNet that divided one question into two parts: a concept representation which captured its explicit concept meaning and an individual representation which preserved its personal characteristics. We also proposed DisenQNet+ to transfer the representation knowledge from DisenQNet in several application tasks including difficulty estimation and similarity analysis. Experimental results showed that DisenQNet could distinguish unique concept and personality effects for question representation learning, and DisenQNet+ improved task performances by incorporating our individual representations.</p><p>There are some directions for further studies. First, we will perform representation learning for educational questions with heterogeneous forms, which some geometry figures can be incorporated. Second, we will design more meaningful question-based online intelligent services. We hope this work could lead to more studies. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Three educational question examples. Blue contents show they are related to "Function" concept. Green parts present their personal information. Right red labels tell us that Q 1 is harder than Q 2 and Q 2 is similar to Q 3 . such models cannot ensure the representation ability sometimes due to the scarce labels. Second, their representation results are taskdependent, which has poor feasibility to be applied across different applications<ref type="bibr" target="#b5">[6]</ref>. That is to say, we have to design different models to represent same questions for different applications. Third, although Yin et al.<ref type="bibr" target="#b35">[36]</ref> pre-trained question representations to enhance the model ability with unlabeled data, all existing solutions equally represent a certain question as one unified vector, where all the information are integrated together. However, questions with same concepts (e.g., "Function") can be quite different from its content to show personal properties (e.g., difficulty)<ref type="bibr" target="#b13">[14]</ref>. For example in Figure1, question Q 1 is harder than Q 2 as it has more complicated expressions. Therefore, if we cannot distinguish such differences, it may introduce some noises and mislead the applications.To this end, we argue that an ideal question representation model should satisfy three desirable abilities: 1) It can get rid of the labels in specific tasks, which can be optimized by learning questions on their own. 2) It should distinguish the diverse characteristics of questions inherent by an explicit way.3) The learned representations should be flexible for being applied in different downstream tasks.In this paper, we propose a novel unsupervised model, namely DisenQNet, for question representation learning. In DisenQNet, we aim to disentangle one question into two parts: a concept representation and an individual representation. Specifically, we develop three self-supervised estimators to optimize two disentanglements. First, we learn the question semantics by maximizing the mutual information between itself and our two disentangled representations. Second, we enforce the concept representation with explicit meaning by making prediction of its concepts. Third, we propose an adversarial process to ensure two disentanglements independent so that the individual one can preserve the question personality itself. Particularly, DisenQNet can be optimized by learning questions on their own without any additional annotations.In addition, we propose another enhanced model, namely Dis-enQNet+, that applies our learned representations to several application tasks. Specifically, since our individual disentanglement especially leaves the personal information of one question without concept, it can be adapted to improve the representation ability of supervised models in different tasks even if owning very limited labeled data. We achieve this goal by maximizing the mutual information between the unsupervised representations and the supervised representations so that the knowledge can be transferred from DisenQNet to supervised models in different applications.We perform extensive experiments on three datasets. We empirically show that DisenQNet can generate meaningful disentangled representations of educational questions, and DisenQNet+ can</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: DisenQNet. Left part shows the model architecture. Right part illustrates three estimator details for optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: DisenQNet+ for downstream application tasks. one labeled question qL j ∈ Q L , we first design a task model f δ : R d 0 ×M → R d t to produce its task-specific semantic representation v L j ∈ R d t , i.e., v L j = f δ (q L j ).Then, we apply one prediction network h ϕ 2 : R d t → R that outputs the task prediction, i.e., p j = h ϕ 2 (v L j ). In summary, the task loss on label set Q L can be formulated in a supervised manner as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Disentanglement visualization with concepts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Results with different parameters λ 2 and λ 3 .to be grouped, meaning that they have well maintained the concept information. Comparatively, their individual representations are scattered because they are independent with the concept ones that preserve the other personal characteristics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3 F1@ 5 Figure 7 :</head><label>357</label><figDesc>Figure 7: Task results: Difficulty estimation on SYSTEM1 (top), Math23K (medium). Similarity analysis on SYSTEM2 (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The statistics of the datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3">SYSTEM1 SYSTEM2 Math23K</cell></row><row><cell>#Questions</cell><cell>108,137</cell><cell>25,293</cell><cell>23,096</cell></row><row><cell>#Concepts</cell><cell>31</cell><cell>21</cell><cell>5</cell></row><row><cell>Avg. question length</cell><cell>48.15</cell><cell>129.96</cell><cell>28.06</cell></row><row><cell>Avg. concepts per question</cell><cell>1.91</cell><cell>1.16</cell><cell>1.9</cell></row><row><cell>#Questions with difficulty label</cell><cell>5,291</cell><cell>/</cell><cell>2000</cell></row><row><cell>Avg. difficulty labels per concept</cell><cell>307</cell><cell>/</cell><cell>772</cell></row><row><cell>#Questions with similarity label</cell><cell>/</cell><cell>2944</cell><cell>/</cell></row><row><cell>#Labeled similar pairs</cell><cell>/</cell><cell>1900</cell><cell>/</cell></row><row><cell>Avg. similarity labels per question</cell><cell>/</cell><cell>1.29</cell><cell>/</cell></row><row><cell>Label sparsity</cell><cell>4.9%</cell><cell>11.6%</cell><cell>8.7%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Please refer to<ref type="bibr" target="#b25">[26]</ref> for more useful question properties like discrimination etc.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This research was partially supported by grants from the National Natural Science Foundation of China (Grants No. 61922073 and U20A20229), the Fundamental Research Funds for the Central Universities (Grant No. WK2150110021), the Foundation of State Key Laboratory of Cognitive Intelligence (No. iED2020-M004), and the iFLYTEK joint research program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Engaging with massive online courses</title>
		<author>
			<persName><forename type="first">Ashton</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on World wide web</title>
				<meeting>the 23rd international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="687" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mutual information neural estimation</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Ishmael Belghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aristide</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sai</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Introducing a framework to assess newly created questions with Natural Language Processing</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Benedetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Cappelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Turrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence in Education</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ensuring the fairness of GRE writing prompts: Assessing differential difficulty</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Broer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Series</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2005">2005. 2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Youngduck</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngnam</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jineon</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmin</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seewoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngmin</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byungsoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewe</forename><surname>Heo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05505</idno>
		<title level="m">Assessment Modeling: Fundamental Pre-training Tasks for Interactive Educational Systems</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08101</idno>
		<title level="m">Pre-training with whole word masking for chinese bert</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Searching questions by identifying question topic and question focus</title>
		<author>
			<persName><forename type="first">Huizhong</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunbo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Acl-08: HLT</title>
				<meeting>Acl-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="156" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rethinking imagenet pretraining</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4918" to="4927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IProceedings of the IEEE international conference on computer vision</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06146</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Question Difficulty Prediction for READING Problems in Standard Tests</title>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongke</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural mathematical solver with enhanced formula structure</title>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weibo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinze</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1729" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Estimating mutual information</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kraskov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Stögbauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Grassberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">66138</biblScope>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Finding similar exercises in online education systems</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zai</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1821" to="1830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ekt: Exercise-aware knowledge tracing for student performance prediction</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="100" to="115" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.4546</idno>
		<title level="m">Distributed representations of words and phrases and their compositionality</title>
				<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Measuring similarity of educational items: An overview</title>
		<author>
			<persName><forename type="first">Radek</forename><surname>Pelánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Learning Technologies</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="354" to="366" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Question difficulty prediction for multiple choice problems in medical exams</title>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="139" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multidimensional item response theory models</title>
		<author>
			<persName><surname>Mark D Reckase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multidimensional item response theory</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Measuring Similarity of Educational Items Using Data on Learners&apos; Performance. International Educational Data Mining Society</title>
		<author>
			<persName><forename type="first">Jirí</forename><surname>Rihák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radek</forename><surname>Pelánek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning disentangled representations via mutual information estimation</title>
		<author>
			<persName><forename type="first">Eduardo</forename><forename type="middle">Hugo</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Serrurier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Ortner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="205" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">GroupIM: A Mutual Information Maximization Framework for Neural Group Recommendation</title>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Sundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1279" to="1288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Answering questions: Methodology for determining cognitive and communicative processes in survey research</title>
		<editor>Norbert Ed Schwarz and Seymour Ed Sudman</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Jossey-Bass/Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization</title>
		<author>
			<persName><forename type="first">Fan-Yun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.01000</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep Graph Infomax</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR (Poster)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MCNE: An end-to-end framework for learning multiple conditional network representations of social network</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongfang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1064" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep neural solver for math word problems</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="845" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting item survival for multiple choice questions in a high-stakes medical exam</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Yaneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janet</forename><surname>Mee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th Language Resources and Evaluation Conference</title>
				<meeting>The 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6812" to="6818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Quesnet: A unified representation for heterogeneous test questions</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1328" to="1336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multi-label inference for crowdsourcing</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xindong</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2738" to="2747" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
