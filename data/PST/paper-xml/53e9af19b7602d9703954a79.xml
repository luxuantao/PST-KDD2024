<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
							<email>rvidal@eecs.berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">O</forename><surname>Shakernia</surname></persName>
						</author>
						<author>
							<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
							<email>sastry@eecs.berkeley.edu</email>
						</author>
						<author>
							<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Shim</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<postCode>94720-1774</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">is with Maxtor Corporation</orgName>
								<address>
									<postCode>95035</postCode>
									<settlement>Milpitas</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1ADCAF6C952C5ED26ED4807C74F2293C</idno>
					<idno type="DOI">10.1109/TRA.2002.804040</idno>
					<note type="submission">Manuscript received March 16, 2001; revised March 16, 2002.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Probabilistic Pursuit-Evasion Games: Theory</term>
					<term>Implementation</term>
					<term>and Experimental Evaluation Autonomous vehicles</term>
					<term>multiagent coordination and control</term>
					<term>multirobot systems</term>
					<term>pursuit-evasion games</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the problem of having a team of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) pursue a second team of evaders while concurrently building a map in an unknown environment. We cast the problem in a probabilistic game theoretical framework, and consider two computationally feasible greedy pursuit policies: local-max and global-max. To implement this scenario on real UAVs and UGVs, we propose a distributed hierarchical hybrid system architecture which emphasizes the autonomy of each agent, yet allows for coordinated team efforts. We describe the implementation of the architecture on a fleet of UAVs and UGVs, detailing components such as high-level pursuit policy computation, map building and interagent communication, and low-level navigation, sensing, and control. We present both simulation and experimental results of real pursuit-evasion games involving our fleet of UAVs and UGVs, and evaluate the pursuit policies relating expected capture times to the speed and intelligence of the evaders and the sensing capabilities of the pursuers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We cast the problem in a probabilistic game theoretical framework that combines pursuit-evasion games and map building in a single problem, which avoids the conservativeness inherent to classical worst-case approaches. We consider two computationally feasible pursuit policies: local-max and global-max. We prove that for the global-max policy, there exists an upper bound on the expected capture time which depends on the size of the arena, and the speed and sensing capabilities of the pursuers.</p><p>In order to implement this pursuit-evasion game scenario on a fleet of UAVs and UGVs, we propose a distributed hierarchical hybrid system architecture that segments the control task into different layers of abstraction: high-level pursuit policy computation, map building and interagent communication, and low-level tactical planning, navigation, regulation, and sensing. Our architecture is modular and scalable, allowing one to "divide and conquer" a complex large-scale system by developing and integrating simpler components. Unlike the traditional sense-model-plan-act decomposition, our architecture takes into consideration the dynamics of each agent so that our system can achieve real-time performance.</p><p>We evaluate the proposed probabilistic framework and hierarchical architecture through simulation and experimental results on our fleet of UAVs and UGVs. Using the expected capture time as the performance criterion, we compare the local-max and global-max pursuit policies on numerous situations, varying the speed and intelligence of the evaders and the sensing capabilities of the pursuers. Our experimental results show that the global-max policy outperforms the local-max policy in a realistic situation, in which the dynamics of each agent are included and computer vision is used to detect the evaders. Furthermore, our experiments show that the global-max policy is robust to changes in the conditions of the game. Even though it is designed for a randomly moving evader, the policy is also successful in catching an intelligent evader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Previous Research in Pursuit-Evasion Games</head><p>The classical approach to pursuit-evasion games is to first build a map of the terrain and then play the game in a known environment. For the map-building stage, several techniques have been proposed, see, e.g., <ref type="bibr" target="#b0">[1]</ref> and references therein. Most of them are based on Bayesian estimation and are implemented using the Extended Kalman Filter. The main problem with these map-building techniques is that they are time consuming and computationally expensive, even in the case of simple two-dimensional (2-D) rectilinear environments <ref type="bibr" target="#b1">[2]</ref>. On the other hand, most of the literature in pursuit-evasion games, see e.g., <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b5">[6]</ref>, assumes worst-case motion for the evaders and an accurate map of the environment. In practice, this results in overly conservative pursuit policies applied to inaccurate maps built from noisy measurements.</p><p>In <ref type="bibr" target="#b6">[7]</ref>, the pursuit-evasion game and map-building problems are combined in a single probabilistic framework. The basic scenario considers multiple pursuers trying to capture a single randomly moving evader. In <ref type="bibr" target="#b7">[8]</ref>, we extended the scenario to consider multiple evaders, and proposed a simple vision-based algorithm for evader detection. We also included supervisory agents, such as a helicopter, that can detect evaders but not capture them. In parallel with our theoretical work on pursuit-evasion games, we have been developing a test bed for multiagent coordination and control. In <ref type="bibr" target="#b8">[9]</ref>, we presented a real-time control system for regulation and navigation of a UAV. In <ref type="bibr" target="#b7">[8]</ref>, we presented an architecture for pursuit-evasion games, and described the implementations of the navigation, communication, and sensing layers. In <ref type="bibr" target="#b9">[10]</ref>, we presented the implementation of the high-level mission coordination, including the components for pursuit policy computation and map building.</p><p>Recent work on pursuit-evasion games considers evaders that actively avoid the pursuers, as described in <ref type="bibr" target="#b10">[11]</ref>, where a dynamic programming solution to a Stackelberg equilibrium of a partial-information Markov process is proposed. There has also been work on vision-based pursuit-evasion games, where the pursuers use optical flow to determine the number of moving evaders as well as their position and orientation <ref type="bibr" target="#b11">[12]</ref>. Implementation and evaluation of these two techniques is forthcoming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Previous Research in Multirobot Systems</head><p>The multiagent pursuit-evasion game scenario considered in this paper fits within the general framework of multirobot systems. There exists a large body of literature in multirobot systems addressing problems such as machine-learning techniques for multiagent systems <ref type="bibr" target="#b12">[13]</ref>, hybrid algorithms for multiagent control <ref type="bibr" target="#b13">[14]</ref>, multirobot localization <ref type="bibr" target="#b14">[15]</ref>, distributed sensor fusion <ref type="bibr" target="#b15">[16]</ref>, and formation control <ref type="bibr" target="#b16">[17]</ref>.</p><p>As for application of multirobot systems in robot soccer, we refer the reader to <ref type="bibr" target="#b17">[18]</ref> and <ref type="bibr" target="#b18">[19]</ref> for centralized coordination and control of multiple robots, and to <ref type="bibr" target="#b19">[20]</ref> and <ref type="bibr" target="#b20">[21]</ref> for completely distributed systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PURSUIT-EVASION SCENARIO</head><p>This section describes the theoretical foundations for probabilistic pursuit-evasion games, including map building, pursuit policies, and evasion policies. We also describe a vision-based algorithm for obstacle and evader detection.</p><p>Notation. We denote by the relevant probability space with the set of all possible events related to the pursuit-evasion game, a family of subsets of forming a algebra, and a probability measure on . Given two sets of events with , we write for the conditional probability of given . Boldface symbols are used to denote random variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Probabilistic Framework</head><p>Consider a finite 2-D environment with square cells containing an unknown number of fixed obstacles, and let ( ) be the set of cells occupied by the pursuers ( evaders). Pursuers and evaders are allowed to move to cells in in which there is no other pursuer, evader, or obstacle. Each pursuer (evader) collects information about at discrete time instants</p><p>. Each measurement is a triple taking values in a measurement space , where denotes the measured positions of the pursuers, and is a set of cells where evaders (obstacles) are detected. We let be the set of all finite sequences of elements in , and be the sequence of measurements taken up to time . In practice, measurements are taken within a certain subset of : the visibility region. We denote the visibility region of pursuer (evader ) at time as . Sensor information is assumed to be imperfect. We use a simple sensor model based on the probability of false positives and false negatives of a pursuer detecting an evader or an obstacle. However, we assume that pursuers have perfect knowledge of their own locations, that is .<ref type="foot" target="#foot_0">1</ref> Capture of an evader is defined as follows: Let and be the estimated positions of ground pursuer and evader at time , respectively. We say that evader is captured by ground pursuer at time if and , where is a metric in and is a prespecified capture distance. Captured evaders are removed from the game. The capture time of all evaders is defined as , where is the time instant at which evader is captured. We assume that aerial pursuers can detect and share information about the positions of evaders, but not capture them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Map Building</head><p>We assume that pursuers are able to identify each evader separately, and that each evader moves independently of the other evaders. Therefore, without loss of generality, we will assume and omit the subscript identifying each evader. Let be the posterior probability of the evader being in cell at time , given the measurement history . Similarly, let be the conditional probability of having an obstacle in cell given . At each , pursuers have estimates of the evader and obstacle maps and , obtain a new measurement , and recursively estimate and in three steps. First, pursuers compute as if or the evader is captured otherwise (1) where is a normalizing constant independent of , and otherwise.</p><p>(</p><formula xml:id="formula_0">)<label>2</label></formula><p>Here, for each , is the number of false positives, is the number of true negatives, is the number of false negatives, and is the number of true positives. Recall that and are the probability of the sensor reporting false positives and false negatives, respectively.</p><p>Second, pursuers compute the obstacle map as otherwise (3) where . Finally, in order to compute , pursuers assume a Markov model for the motion of the evader which is determined by the probability that the evader moves to an unoccupied cell in , where is the set of (up to eight) cells adjacent to . The evader map is updated as (4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Pursuit Policies</head><p>Given the measurement history , the pursuers need to decide where to move at the next time instant. Let be the desired position of the pursuers at time . Since two pursuers must not occupy the same cell, is an element of the control action space for . We define a pursuit policy as the random function <ref type="bibr" target="#b4">(5)</ref> We measure the performance of a specific pursuit policy by the expected capture time . Since the dependence of on the pursuit policy is, in general, very complex <ref type="bibr" target="#b6">[7]</ref>, instead of finding the optimal policy that minimizes , we look for efficiently computable suboptimal policies with good performance. To this end, we first introduce the notion of a persistent pursuit policy <ref type="bibr" target="#b6">[7]</ref> and show that it guarantees a certain degree of success for the pursuers. We then present two computationally efficient greedy policies and show that one of them satisfies the persistence property, given certain assumptions on the distribution of the obstacles and the sensing models.</p><p>1) Persistent on the Average Pursuit Policies: A specific pursuit policy is said to be persistent on the average if there is an integer and some , such that for each , the conditional probability of capturing evader on the set of consecutive time instants starting at is greater than or equal to , i.e. <ref type="bibr" target="#b5">(6)</ref> We call the period of persistence. Persistent on the average pursuit policies satisfy the following <ref type="bibr" target="#b6">[7]</ref>:</p><p>Lemma 1: If is a persistent on the average pursuit policy with period , then , and , with as in <ref type="bibr" target="#b5">(6)</ref>. Lemma 1 shows that for a pursuit policy which is persistent on the average, the probability of capturing evader in finite time is equal to one. Moreover, Lemma 1 gives a simple upper bound on the expected capture time for evader . The following lemma (proved in <ref type="bibr" target="#b21">[22]</ref>) gives a sufficient condition for a policy to be persistent on the average. Lemma 2: Let , be the set of all sequences of measurements of length , associated with evader not being found up to time . A sufficient condition for a pursuit policy to be persistent on the average with period is the existence of some , such that for each and each , there is some for which . In this case, (6) holds with <ref type="bibr" target="#b6">(7)</ref> 2) Admissible Policies, Obstacle Density, and Sensor Models: In order to apply Lemmas 1 and 2 to a specific pursuit policy, we will need some extra assumptions on the dynamics of the pursuers, the distribution of the obstacles, and the sensor models used for evader detection.</p><p>First, we restrict our attention to pursuit policies that respect the dynamics of each vehicle. Let be the set of cells that pursuer can reach from cell in one time step, provided that those cells are empty, and let . <ref type="foot" target="#foot_1">2</ref> We say that a pursuit policy is admissible if for every sequence of measurements , we have</p><p>, where are the pursuers' positions specified by the last measurement in .</p><p>Next, we assume that the density of obstacles in the environment is small enough so that any cell in can be reached in a finite amount of time. More formally Assumption 1: For any , there exists a finite sequence , such that for each . Finally, we assume that in a single time step, the conditional probability of the evader being at a cell does not decay by more than a certain amount, unless one pursuer reaches , in which case, the probability of the evader being at may decay to zero if the evader is not there, or if it is possible to conclude from the measured data that an obstacle is at with probability one. Such an assumption holds for most sensor models.</p><p>Assumption 2: There is a positive constant , such that for any sequence of measurements for which the evader was not captured <ref type="bibr" target="#b7">(8)</ref> for any for which is not in the list of pursuers' positions specified by the last measurement in , and the probability of an obstacle being at any given location given the measurements up to time is strictly less than one for any pursuit policy .</p><p>3) Greedy Policies: Given the assumptions in the previous section, we now focus on finding efficiently computable suboptimal pursuit policies. We consider the following greedy policies: local-max and global-max. Both policies try to maximize the probability of capturing an evader at the next time instant, the difference being that local-max searches only one-step reachable cells, while global-max searches the entire map.</p><p>Local-Max Policy. Under this policy, pursuer moves to the cell in the one-step reachable set with the highest probability of containing an evader over all the evader maps, that is where represents the probability of evader being in cell at time given the measurements . Notice that the local-max policy is advantageous in scalability, since it assigns more importance to local measurements by searching only in , regardless of the size of the environment . This policy is computationally efficient, and can be computed independently by each pursuer in a decentralized pursuit-evasion game. However, it can be shown that in general, the local-max policy is not persistent on the average.</p><p>Global-Max Policy. The global-max policy searches over the entire map in order to compute the control that maximizes the probability of capturing an evader. Therefore, it is more computationally intensive and does not scale as well as the local-max policy with the size of . However, as we will show below, it has the nice property that it is persistent on the average. Take an arbitrary sequence of measurements , and compute the cell in the map with the maximum probability of having an evader <ref type="bibr" target="#b8">(9)</ref> Next define the desired positions of the pursuers as <ref type="bibr" target="#b9">(10)</ref> Now define the global-max pursuit policy as <ref type="bibr" target="#b10">(11)</ref> where is the integer for which . Here, is an underlying "navigation policy" which takes a list of desired positions for the pursuers , together with measurements , and produces a position reachable in a single time step that is "one step closer" to , or concludes that there is an obstacle at . Theorem 1: If Assumptions 1 and 2 hold, then the global-max policy is an admissible pursuit policy which is persistent on the average with period , where is the maximum number of steps needed to travel from one cell to any other. Moreover, , and , with as in <ref type="bibr" target="#b6">(7)</ref> and in Lemma 2. Proof: By definition of the navigation policy, is admissible. In order to prove that is persistent on the average, we show that the hypotheses of Lemma 2 hold. From the definition of in ( <ref type="formula">9</ref>), we have that for any where is the number of cells in . Now, since a pursuer takes, at most, steps to reach , by following policy there must exist some with , such that there is a pursuer just one step away from . Consider such a time and set . Therefore, the conditional probability of finding an evader at time is given by By Assumption 2 and the fact that it takes, at most, steps to reach , we have</p><p>Applying Lemmas 1 and 2 shows that if the first evader to be captured is evader , then and . Therefore, and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Intelligent Evasion</head><p>Even though the pursuit policies described in the previous section are designed for a randomly moving evader only, in Section IV we will apply these policies to the case of an intelligent evader. We allow an intelligent evader to build a map of obstacles and pursuers and to employ either a local-min or global-min policy so as to minimize the probability of being captured. The local-min and global-min evasion policies are defined similarly to the local-max and global-max pursuit policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Vision-Based Detection of Obstacles and Evaders</head><p>Assume that the pursuers are equipped with a camera to sense the environment. We show how to estimate the position of obstacles and evaders from their observed positions in the image plane, the pose (rotation and translation) of the camera, and that of the pursuer. We define the coordinate frames: a) inertial frame, b) UAV frame, c) camera base, d) camera head, and e) UGV frame, and let be the relative pose of frame with respect to frame . Also, let be the skew-symmetric matrix associated with axis , and be the usual basis for . If the observer is a UAV, then , where are the estimates of the yaw, pitch, and roll angles of the helicopter, and is the estimate of its position. is a predefined (known) transformation and , where are the estimates of the pan and tilt angles of the camera. Then, the pose of the camera head with respect to the fixed inertial frame is given by <ref type="bibr" target="#b11">(12)</ref> Let be the estimate of the position of an obstacle (evader) in the image plane. Then its 3-D position is obtained as <ref type="bibr" target="#b12">(13)</ref> where is the (fixed) coordinate of the evader on the ground, assuming a flat terrain, and is the camera calibration matrix.</p><p>If obstacles (evaders) are being observed by a ground pursuer, equation ( <ref type="formula">13</ref>) can still be applied with minor changes. Replace frame b) by frame e), the UGV frame. Then , where is the estimate of the heading of the UGV, is the estimate of the position of the observer, and is also a predefined (fixed) transformation.</p><p>The vision system is also used to estimate the visibility region of each vehicle. For a pursuer or evader, the visibility region is defined as the trapezoid whose vertices are computed from ( <ref type="formula">13</ref>), applied to the vertices of a fixed rectangle located below the horizon on the image plane. For an aerial pursuer, since the camera is pointing down, the rectangle on the image plane is chosen as the whole image, which results in an approximately rectangular visibility region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SYSTEM ARCHITECTURE</head><p>In order to implement the pursuit-evasion game scenario on real UAVs and UGVs, we propose a hierarchical hybrid system architecture that segments the control of each agent into different layers of abstraction, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. The different layers allow for the same high-level intelligent control strategies to be applicable to both UAVs and UGVs. By abstracting away the details of sensing and control of each agent, we gain the interoperability of a unified framework for high-level intelligent pursuit policies across all platforms.</p><p>This section gives an overview of the different layers of abstraction of our system architecture, and some details about the implementation on our fleet of UAVs and UGVs. Our architecture design was inspired by the architectures of automated highway systems <ref type="bibr" target="#b23">[24]</ref>, air traffic management systems <ref type="bibr" target="#b24">[25]</ref>, and flight management systems <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. High Level: Strategy Planner and Map Builder</head><p>The Strategy Planner is responsible for the high-level intelligent control of the vehicles, i.e., the pursuit policy computation described in Section II-C. It maintains a state-space of the system useful for mission planning, and tasks the agents according to mission objectives.</p><p>The Map Builder gathers sensor information from each vehicle and computes probabilistic maps with the locations of obstacles and evaders as described in Section II-B. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Low Level: Tactical Planner, Regulation, and Sensing</head><p>The Tactical Planner uses the state information maintained by the strategy planner for controlling the motion of each vehicle. It converts strategic plans into a sequence of way points or flight modes, which are used by the Trajectory Planner to produce a realizable and safe trajectory based on a dynamic model of the vehicle and safety routines such as obstacle avoidance. The final trajectory is sent to the Regulation Layer, which performs the real-time control of the vehicle along the specified trajectory.</p><p>Each vehicle makes observations about the environment using a vision system and about its state using a variety of sensors for position and orientation. Sensor-fusion techniques are used to improve the quality of the measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation of High Level Control Layers</head><p>We implemented the strategy planner and map builder in a MATLAB/Simulink environment as a part of a unified platform on which to conduct both simulations and experiments. Furthermore, we used a transmission control protocol (TCP) interface to connect the MATLAB-based strategy planner and map builder with the UAVs and UGVs through the wireless LAN.</p><p>With this unified platform, we are able to seamlessly combine experiments and simulations. In simulation mode, the strategy planner sends control commands over TCP to a UAV simulator obtained from system identification <ref type="bibr" target="#b8">[9]</ref> and to a UGV simulator. Visibility regions are simulated according to the state variables of each vehicle, and the detection of evaders and obstacles is simulated with probabilistic sensor models. In experiment mode, the same strategy planner sends commands over TCP to the actual UAVs and UGVs, while the same map builder receives vehicle locations from the GPS/Inertial Navigation System (INS), and visibility regions and locations of obstacles and evaders from the vision system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Implementation of Low Level Control Layers</head><p>Our UAVs fleet consists of custom-designed UAVs based on Yamaha R-50 and R-Max industrial helicopters. The trajectory planner and regulation layers are implemented in C on an embedded PC running the QNX real-time operating system (OS). The low-level controller has a TCP interface that asynchronously receives desired setpoints from the high-level strategy planner, and reports the UAVs' current position. The vision system used to detect obstacles and evaders is implemented in C++ on a second PC running Linux. See <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b26">[27]</ref> for further details.</p><p>Our UGVs fleet consists of ActivMedia Pioneer 2-AT all-terrain ground robots. The tactical/trajectory planner and regulation layer run on a microcontroller, while the vision system runs on a PC running Linux. See <ref type="bibr" target="#b7">[8]</ref> for details.</p><p>UAVs and UGVs share the following components for sensing and communication: IEEE 802.11b wireless LAN connectivity, differential GPS, a PC104 Pentium 233MHz-based PC running Linux, and a color-tracking vision system. All these components are described in detail in <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SIMULATION AND EXPERIMENTAL RESULTS</head><p>In this section, we present simulation and experimental results of pursuit-evasion games on our fleet of UAVs and UGVs. 3 Table I presents the mean capture time of 10 simulations between three pursuers and one evader with random initial conditions. Simulations 1-4 evaluate the performance of the two pursuit policies against a randomly moving evader for two types of visibility regions: an omnidirectional view 4 and a trapezoidal view . 5 Simulations 5-8 evaluate the performance of the global-max policy with a trapezoidal view for different speeds and levels of intelligence of the evader.</p><p>Table <ref type="table">II</ref> presents results of real experiments between three UGV pursuers and one UGV evader. Fig. <ref type="figure" target="#fig_2">3</ref> shows the evolution of Experiment 1 through photographs and corresponding snapshots created by the map builder. The darker cells in the map 3 All the experiments are performed in a 20 m 2 20 m environment with 1 m 2 1 m square cells, p = q = 0:1, and d = 1:5 m.</p><p>4 S (t) is a square of side 5 m, centered at x (t). 5 We are using the set difference operator /-&gt; T (t) = 4(x (t), 45 , 7 m)=4(x (t), 45 , 1 m), where 4(x; ; h) denotes an isosceles triangle with vertex x, height h, and angle .    evader speed was 0.1 m/s, the evader moved randomly, pursuers had trapezoidal visibility regions, and followed the global-max policy. The capture time was 30 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Discussion of Simulation and Experimental Results</head><p>Capture Time versus Visibility Region: Simulations 1-4 in Table <ref type="table">I</ref> and Experiments 1-3 in Table <ref type="table">II</ref> show that, regardless of the pursuit policy, pursuers with trapezoidal vision outperform those with omnidirectional vision. Even though at a given time instant both visibility regions cover approximately the same number of cells, a pursuer with a trapezoidal view can change its heading, thus covering many more new cells than a pursuer with an omnidirectional view. This agrees with natural predator/prey systems.</p><p>Capture Time versus Pursuit Policy: Simulations 1-4 in Table <ref type="table">I</ref> show that the global-max policy generally outperforms the local-max policy. This is expected since the global-max policy is persistent on average, while the local-max is not.</p><p>Capture Time versus Evasion Policy: Simulations 5-8 in Table <ref type="table">I</ref> evaluate the global-max pursuit policy against an evader following either a random or a global-min evasion policy. Since the global-max pursuit policy is designed for a randomly moving evader, there is no guarantee that the expected capture time will be finite for the case of an intelligent evader. We conclude from the simulations that it takes longer to capture an intelligent evader than a randomly moving one. Also, for a fast evader, it takes 300% longer to capture an intelligent one than a randomly moving one, while for a slow evader, it takes only 64% longer.</p><p>Capture Time versus Evader Speed: Simulations 5 and 6 in Table <ref type="table">I</ref> show that it takes longer to capture a slower random evader than a faster random evader. This is because a faster random evader visits more cells in the map, increasing the chances of being detected. This argument can be applied to Fig. <ref type="figure">5</ref>. The higher speed of E1 allows it to move away from the visibility region of P2 for , but E1 soon moves into the visibility region of P3 and is quickly captured.</p><p>UAV Pursuer versus UGV Pursuer: Simulation results in <ref type="bibr" target="#b27">[28]</ref> and Experiment 4 show that the local-max policy has a similar performance with either a UAV or UGV pursuer, while the global-max policy performs better with a UAV pursuer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>We presented a probabilistic approach to pursuit-evasion games involving UAVs and UGVs. We considered two computationally feasible greedy pursuit policies: local-max and global-max. We proved that for the global-max policy there exists an upper bound on the expected capture time which depends on the size of the arena, and the speed and sensing capabilities of the pursuers. Next, we presented an implemention of the scenario on a fleet of UAVs and UGVs based on a hierarchical hybrid system architecture. Finally, we presented several experiments, evaluating the performance of the proposed pursuit policies with respect to the speed and intelligence of the evaders and the sensing capabilities of the pursuers. Our results show that the global-max pursuit policy outperforms the local-max policy in a realistic situation in which the dynamics of each agent are included and computer vision is used to detect the evaders.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Berkeley AeRobot test bed for pursuit-evasion games.</figDesc><graphic coords="1,322.62,172.57,211.09,162.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. System Architecture: Strategy planning and map building are implemented in MATLAB and run in a laptop which is also used for visualization. Tactical planning, regulation, and sensing are implemented in C++ and run in the UAV or UGV computers.</figDesc><graphic coords="5,303.60,62.28,249.12,258.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Experiment 1: An actual game between three UGV pursuers and one UGV evader. The pursuers P1, P2, and P3 (?) move at 0.3 m/s and use the global-max policy with an omnidirectional visibility region. The evader E1 moves randomly at 0.1 m/s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Experiment 2: Three UGV pursuers versus a slow UGV evader.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Experiment 3: Three UGV pursuers versus a fast UGV evader.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I SIMULATION RESULTS</head><label>IRESULTS</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II EXPERIMENTAL RESULTS</head><label>IIRESULTS</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This assumption is unrealistic in general, although valid when a global positioning system (GPS) is used for pursuer localization and vision is used for evader detection.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The one-step reachable set U (x ) can be computed offline as a parametric function of x using polynomial time algorithms based on robust semidefinite programming, as shown in<ref type="bibr" target="#b22">[23]</ref>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors thank J. Hespanha, C. Sharp, and S. Rashid for their contributions to this work.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper was recommended for publication by Associate Editor T. Arai and Editor S. Hutchinson upon evaluation of the reviewers' comments. This work was supported by the Office of Naval Research under Grant N00014-97-1-0946 and Grant N00014-00-1-0621, and by the Army Research Office under Grant DAAH04-96-1-0341. This paper was presented in part at the IEEE Conference on Decision and Control, Orlando, FL, 2001.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>René Vidal received the B.S. degree from the Universidad Católica de Chile in 1997, and the M.S. degree in 2000 from the University of California at Berkeley, where he is currently working toward the Ph.D. <ref type="bibr">de</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A probabilistic approach to concurrent mapping and localization for mobile robots</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learning, Auton. Robots</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How to learn an unknown environment I: The rectilinear case</title>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kameda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="245" />
			<date type="published" when="1998-03">Mar. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Isaacs</surname></persName>
		</author>
		<title level="m">Differential Games</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Olsder</surname></persName>
		</author>
		<title level="m">Dynamic Noncooperative Game Theory</title>
		<meeting><address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visibility-based pursuit-evasion: An extension to curved environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lavalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hinrichsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Robotics and Automation</title>
		<meeting>IEEE Conf. Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1677" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Searching for a mobile intruder in a polygonal region</title>
		<author>
			<persName><forename type="first">I</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamashita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="863" to="888" />
			<date type="published" when="1992-10">Oct. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multiple-agent probabilistic pursuit-evasion games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 38th IEEE Conf. Decision and Control</title>
		<meeting>38th IEEE Conf. Decision and Control</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2432" to="2437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pursuit-evasion games with unmanned ground and aerial vehicles</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shakernia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICRA</title>
		<meeting>IEEE ICRA</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2948" to="2955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical control system synthesis for rotorcraft-based unmanned aerial vehicles</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AIAA Conf. Guidance, Navigation, Control</title>
		<meeting>AIAA Conf. Guidance, Navigation, Control</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="439" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A hierarchical approach to probabilistic pursuit-evasion games with unmanned ground and aerial vehicles</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shakernia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th IEEE Conf. Decision and Control</title>
		<meeting>40th IEEE Conf. Decision and Control</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="634" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Probabilistic pursuit-evasion games: A one-step Nash approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Prandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 39th IEEE Conf. Decision and Control</title>
		<meeting>39th IEEE Conf. Decision and Control</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="2272" to="2277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Vision based detection of autonomous vehicles for pursuit-evasion games</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IFAC World Congr. Automatic Control</title>
		<meeting>IFAC World Congr. Automatic Control</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multiagent systems: A survey from a machine learning perspective</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auton. Robots</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="383" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hybrid algorithms of multi-agent control of mobile robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Timofeev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kolushev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bogdanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Networks</title>
		<meeting>Int. Joint Conf. Neural Networks</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="4115" to="4118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collective localization: A distributed Kalman filter approach to localization of groups of mobile robots</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roumeliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bekey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICRA</title>
		<meeting>IEEE ICRA</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="2958" to="2965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed sensor fusion for object position estimation by multi-robot systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stroupe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Balch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Robotics and Automation</title>
		<meeting>IEEE Conf. Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1092" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Control of changes in formation for a team of mobile robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ostrowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Robotics and Automation</title>
		<meeting>IEEE Conf. Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1556" to="1561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Perception, reasoning and learning of multiple agent systems for robot soccer</title>
		<author>
			<persName><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Robotics and Automation</title>
		<meeting>IEEE Conf. Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3510" to="3515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Perception, reasoning and learning of multiple agent systems for robot soccer</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Kuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Baek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Systems, Man, Cybernetics</title>
		<meeting>IEEE Int. Conf. Systems, Man, Cybernetics</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="728" to="733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robocup: A challenging problem for AI and robotics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kitano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Asada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kuniyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Noda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Osawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Matsubara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RoboCup-97: Robot Soccer World Cup I</title>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1395">1998, 1395</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cooperative behavior acquisition for mobile robots in dynamically changing real worlds via vision-based reinforcement learning and development</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Uchibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hosoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="275" to="292" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Multiple-agent probabilistic pursuit-evasion games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-03">Mar. 1999</date>
			<publisher>Dept. of EECS, Univ. of Calif. at Berkeley</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decidable and semi-decidable controller synthesis for classes of discrete time hybrid systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaffert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shakernia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lygeros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 40th IEEE Conf. Decision and Control</title>
		<meeting>40th IEEE Conf. Decision and Control</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1243" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Verified hybrid controllers for automated vehicles</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lygeros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="522" to="539" />
			<date type="published" when="1998-04">Apr. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A next generation architecture for air traffic management systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lygeros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36th IEEE CDC</title>
		<meeting>36th IEEE CDC</meeting>
		<imprint>
			<date type="published" when="1997-12">Dec. 1997</date>
			<biblScope unit="page" from="2405" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hybrid control of an autonomous helicopter</title>
		<author>
			<persName><forename type="first">T</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sinopoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IFAC Workshop Motion Control</title>
		<meeting>IFAC Workshop Motion Control</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="285" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A vision system for landing an unmanned aerial vehicle</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shakernia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robotics and Automation</title>
		<meeting>IEEE Int. Conf. Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1720" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Design and implementation of multi-agent control: Pursuit &amp; map building</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rashid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Calif. at Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
