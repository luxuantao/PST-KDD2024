<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Research on Improved TBL Based Japanese NER Post-Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wang</forename><surname>Jing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MOE-MS Key Laboratory of Natural Language Processing and Speech</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Dequan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MOE-MS Key Laboratory of Natural Language Processing and Speech</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhao</forename><surname>Tiejun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MOE-MS Key Laboratory of Natural Language Processing and Speech</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Research on Improved TBL Based Japanese NER Post-Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/ALPIT.2008.109</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An Improved TBL based post-processing approach is proposed for Japanese named entity recognition (NER) in this paper. Firstly, tuning rules are automatically acquired from the results of Japanese NER by error-driven learning. And then, the tuning rules are optimized according to given threshold conditions. After filtered, the rules are used to revise the results of Japanese NER. Above all, this approach could be used in special domains perfectly for its learning domain linguistic knowledge automatically. The learnt rules could not go over fit as well. The experimental results show that a high result can be achieved in precision for Japanese NER.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Named Entities (NE) are the basic information units in documents, and they are crucial for understanding the documents correctly. They always imply the main contents of the article. Named Entity was proposed by Message Understanding Conference (MUC) for the first time <ref type="bibr" target="#b0">[1]</ref> . Named Entity Recognition (NER) is a difficult and challenging task, and it is a very important subtask of Information Extraction. In Japanese information processing, Japanese NER is of great importance in Information Retrieval, Text Classification/Clustering, Machine Translation and Chunking.</p><p>The statistical models which were used in Japanese NER, such as Maximum Entropy Model (MEM) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> , Hidden Markov Model (HMM) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> , Condition Random Field (CRF) <ref type="bibr" target="#b5">[6]</ref> , Decision Tree <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> , Support Vector Machine (SVM) <ref type="bibr">[9~12]</ref> , have performed good results, but they also have some limitations. The performance might be degraded due to the differences between the feature distributions of different corpora when the trained model is applied to another area. If we annotate the corpus of this field manually and retrain the statistical model, it would waste a lot of time and manpower. The inconsistency between the training and evaluation corpus is quite common phenomena. In order to make the universal NE annotator would adapt to different environments better, it is necessary to train a learner which can revise the original NE recognition results in accordance with the differences between the results of original annotator and answer corpus.</p><p>This paper proposed an improved TBL based (Transformation Based Learning, TBL) postprocessing approach for Japanese named entity recognition, and this approach could overcome the weaknesses which are described above. The experimental results show that the TBL based approach is effective to Japanese NER post-processing. After annotating a small-scale corpus of this field, it could make full use of the information of existing model and the specifications of the new corpus to obtain the transformation rules <ref type="bibr" target="#b10">[13]</ref> . If only adjust the templates properly and learn again, the NE annotator would adapt to the corpus of the other domains. The post-processing technologies proposed in this paper mainly include templates selection, objective function selection, acquirement of the transformation rules and rule optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Transformation rules Acquirement</head><p>Transformation Based Error-Driven Learning is an effective learning algorithm which was proposed by Eric Brill in 1992 <ref type="bibr" target="#b11">[14]</ref> . It could obtain transformation rules automatically during the learning process. In this paper, the reasons for the use of transformation-based error-driven learning to revise the result of Japanese NER are mainly for the following two points. First, in the statistical model training process, if the training corpus is not large enough or the feature distribution of the training corpus is not balanced, the precision and the recall of the NEs which occur in the training corpus rarely would be degraded <ref type="bibr" target="#b12">[15]</ref> . Second, if the training corpus is limited, it is feasible and effective to use transformation-based error-driven learning strategy to correct the NER error which is typical and unambiguous <ref type="bibr">[16]</ref> .</p><p>International Conference on Advanced Language Processing and Web Information Technology </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TBL learning process</head><p>In this paper, the transformation rules are used to revise the results of Japanese Named Entity recognition. So, we need to analyze the differences between the results of Japanese NE annotator and the formal Japanese corpus which has been annotated NE tags. Then find out the triggering environments. That is to say, under what conditions, the original NE recognition results should be revised. In order to improve the system accuracy and efficiency, it is necessary to use some strategies optimize the candidate transformation rules. After these steps, apply the transformation rules to the evaluation corpus. Figure <ref type="figure" target="#fig_1">1</ref> illustrates how the transformation-based error-driven learning works. The learning process is as follows:</p><p>(1) The unannotated text is passed though an initial NE annotator to get the initial training corpus.</p><p>(2) Construct all possible transformation rules according to the rule templates. Apply the rules to the training corpus to get middle annotated corpus. Compare the middle annotated corpus and the formal annotated corpus to find out the rule which could reduce the maximum number of the NE recognition errors.</p><p>(3) If choose the rule r, use it to revise training corpus, thus, the initial training corpus is updated. Add r to candidate rule set.</p><p>(4) Repeat 2 and 3 steps until the number of NE recognition errors do not reduce.</p><p>(5) Output the transformation rule sets. This error-driven learning method could avoid the complexity as the traditional rule based method revising the results of NER, because error-driven learning acquire the transformation rules according to the error parts of the results automatically. It uses some linguistic knowledge effectively, and adds part of speech and word structure information to the rule templates and transformation rules, so as to the universal NE annotator could adapt to the corpus of certain field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Definition of Rule Space</head><p>The choice of rule template is the key to TBL learning, which determines the learning of the rule space. After sampling analysis of the recognition results of ChaSen, and considering of the characteristics of Japanese Named Entities, the rule templates were Determined. The rule templates used in this paper are shown in table <ref type="table">1</ref>. Using these templates, we could get a huge rule space. TBL learning algorithm just used this huge rule space to search for the proper transformation rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Definition of Objective Function</head><p>In the learning process, the definition of objective function is quite helpful for finding the practical rules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Rule Optimization</head><p>After the transformation-based error-driven learning process described above, we could obtain tens of thousands of transformation rules. If we use all the rules without filtration, the system efficiency will be degraded, and might go over fit. By analysis, how to choose an optimum conversion list of rules from tens of thousands of candidate rules is a NP-complete problem <ref type="bibr" target="#b10">[13]</ref> . So, we adopt an approximate algorithm to optimize the set of candidate rules. Assume that Rall is the learnt candidate rule set, Ropt is the rule set after optimization. The algorithm is described in figure <ref type="figure" target="#fig_3">2</ref>.</p><p>The candidate rule set get from the training corpus by transformation-based error-driven learning is quite large. In order to improve the running efficiency of rule optimization algorithm, it is necessary to filter the rules in candidate rule set in advance. First, remove the low-frequency rules from the candidate rule set. Assume that Cr is the number of the rule r appears in the training corpus, and Cmin is the minimum occur number of an effective transformation rule. If Cr&lt;Cmin, then r is a low-frequency rule, which should be removed from the candidate rule set. If Cr≥Cmin, then r is a high-frequency rule, which should be kept in the candidate rule set. After the pre-filtration, lots of low-frequency rules are removed. So, the efficiency of rule optimization step could be improved. Because of the complexity of Japanese Named Entity's construction and diversity of the corpus, applying one rule to the corpus may revise the error of Japanese NER, and also may lead to the reduction of accuracy. In this paper, we use effectiveness of rule to filter the candidate rule set. Assume that Tr is the total number of the rule r appears in the corpus, Sr is the number of the rule r increases the accuracy, thus the effectiveness of the rule r, denoted by Er, is given by Er =Sr/Tr. Choose the threshold Ebest, if Er&gt;Ebest, then the rule r is effective and add r to Ropt, Otherwise, remove r from Rall. Through the processing method described above, we could acquire the optimum rule set Ropt from the candidate rule set Rall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results and Analysis</head><p>ChaSen is a Japanese morphological analysis system which developed by Nara Institute of Science and Technology in Japan <ref type="bibr">[18]</ref> . The functions of ChaSen include Japanse language segmentation, POS tagging and Named Entity recognition. The performance of ChaSen is better than other Japanese morphological analysis system so far. In this paper, the version of ChaSen is V-2.3.3.</p><p>We use a part of EDR corpus as training samples and another for evaluation. First, use ChaSen to annotate the EDR corpus; then, compare the NE recognition results of ChaSen and the normal EDR corpus by TBL learning and optimization strategies to acquire transformation rules. After that, apply the list of transformation rules to the evaluation corpus. The EDR corpus used for evaluation includes 2,412 person names, 5,711 location names and 1,937 organization names. The experimental results are shown in table 2. Through the above experimental data, it is can be seen that the TBL based technology have a good improvement to the results of Japanese Named Entity recognition. The improvement of F-score of person name, location name and organization name are 0.75% 、2.12%、4.61% respectively. The improvement of organization name recognition is significant. Nevertheless, the accuracy of the experiment results degraded to some extent, as the existence of error made by Japanese segmentation and POS tagging steps and the complexity of Japanese NE, such as nested location name in organization name, some Japanese NE came from the English transliteration and so on.</p><p>In Through the above experimental data, it can be seen that the TBL based technology has a good improvement to the results of Japanese Named Entity recognition. The improvement of F-score of person name, location name and organization name are 2.42% 、2.27%、5.64% respectively. Although the precision of organization name recognition is degraded a little, the F-score is improved significantly. Nevertheless, the accuracy of the experiment results degraded to some extent, as the existence of error made by Japanese segmentation and POS tagging steps and the complexity of Japanese NE, such as nested location name in organization name, some Japanese NE came from the English transliteration and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Based on the Japanese morphological analysis system ChaSen, this paper adopted a TBL based postprocessing approach to Japanese Named Entity recognition, and proposed rule optimization strategy. This technology could acquire tuning rules according to differences between the results of the original NE annotator and normal training corpus, to revise the outputs of the original NE annotator. So we could have the universal NE annotator adopted all kinds of corpora and applications. In this paper, we firstly annotated a small part of corpus as training samples manually; then generated a series of rules according to the specifications of the new corpus to revise the error of the original statistic model. The experimental results show that this is an effective post-processing approach to Japanese Named Entity recognition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>978-0-7695-3273-8/08 $25.00 © 2008 IEEE DOI 10.1109/ALPIT.2008.109</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The Process of Transformation-Based Error-Driven Learning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Table1:</head><label></label><figDesc>The rule templates used in this paper Number and (W1=w) and (W2=z) =&gt;W0 ,W1,W2 merge, a→c 6 (T0=a) and (T1=b)and (W2=w) =&gt;W0 ,W1,W2 merge, a→c 7 (T0=a) and (T1=b) and (T2=c) and (W3=w) =&gt;W0 ,W1,W2,W3 merge, a→d 8 (T0=a) and (T1=b) and (W2=w) and (W3=z) =&gt;W0 ,W1,W2,W3 merge, a→cWhere, W0 refers to the current word, Wi refers to the ith word of the right hand side of W0, T0 refers to the POS tag of the W0, and Ti refers to the POS tag of Wi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Rule optimization algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The experimental results on EDR corpus</figDesc><table><row><cell>Input: R all</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Initialize the training set with Named Entity tags;</cell></row><row><cell>While</cell><cell>(the</cell><cell>value</cell><cell>of</cell><cell>the</cell><cell>objective</cell></row><row><cell cols="3">function&gt;threshold) do</cell><cell></cell><cell></cell><cell></cell></row><row><cell>{</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Apply the rules in R all to the training corpus</cell></row><row><cell cols="2">respectively;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Select r from R all which maximum the</cell></row><row><cell cols="2">objective function;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Add r to R opt ;</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Remove r from R all ;</cell><cell></cell><cell></cell><cell></cell></row><row><cell>}</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Output: R opt</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>addition, In order to validate validity and stability of the proposed method, Part of Mainichi Newspaper (2001) was used as training samples, which include 19,049 person names, 18,502 location names and 7,317 organization names. NTCIR Topics in Japanese was used for evaluation experiments which include 857 person names, 965 location names and 404 organization names. The experimental results are shown in table 3. The experimental results on NTCIR corpus</figDesc><table><row><cell cols="2">NE tag</cell><cell>Person</cell><cell>Locatio n</cell><cell>Organization</cell></row><row><cell></cell><cell>ChaSen</cell><cell>90.40%</cell><cell>87.84%</cell><cell>81.13%</cell></row><row><cell>Precision</cell><cell>ChaSen+ TBL</cell><cell>90.19%</cell><cell>90.24%</cell><cell>77.04%</cell></row><row><cell></cell><cell>ChaSen</cell><cell>85.93%</cell><cell>90.31%</cell><cell>65.15%</cell></row><row><cell>Recall</cell><cell>ChaSen+ TBL</cell><cell>90.87%</cell><cell>92.50%</cell><cell>78.79%</cell></row><row><cell></cell><cell>ChaSen</cell><cell>88.11%</cell><cell>89.09%</cell><cell>72.27%</cell></row><row><cell>F-score</cell><cell>ChaSen+ TBL</cell><cell>90.53%</cell><cell>91.36%</cell><cell>77.91%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Authorized licensed use limited to: Tsinghua University. Downloaded on December 30,2022 at 13:14:50 UTC from IEEE Xplore. Restrictions apply.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledge</head><p>This work is supported by the national natural science foundation of China (No. 60736044) and the National High-Tech Development 863 Program of China (No.2006AA01Z150, 2006AA010108).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Xiao-Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Huo-Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Named Entiy Recognition. Computer Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="44" to="48" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A Maximum Entropy Approach to Named Entity Recognition</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Borthwick</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Doctor&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Named entity extraction based on a maximum entropy model and transformation rules</title>
		<author>
			<persName><forename type="first">Kiyotaka</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaki</forename><surname>Murata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiromi</forename><surname>Ozaku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural Language Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="90" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Lv Xue-qiang, SHI Shui-cai. Chinese Named Entity Identification Using Cascaded Hidden Markov Model</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Hong-Kui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Hua-Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Qun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Communications</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="94" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">HMM Combined with Automatic Rules-extracting for Chinese Named Entity Recognition</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Liao Xian-Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Hai-Bin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><surname>Ting</surname></persName>
		</author>
		<idno>SWCL. 2004</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Applying Conditional Random Fields to Japanese Morphological Analysis</title>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaoru</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A decision tree method for finding and classifying names in Japanese texts</title>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroyuki</forename><surname>Shinnou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Very Large Corpora</title>
				<meeting>the Sixth Workshop on Very Large Corpora</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Japanese Named Entity Recognition based on a Simple Rule Generator and Decision Tree Learning</title>
		<author>
			<persName><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPSJ Journal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1481" to="1491" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Japanese Named Entity Extraction Using Support Vector Machine</title>
		<author>
			<persName><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPSJ Journal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Department of Information Processing Graduate School of Information Science Nara Institute of Science and Technology</title>
		<author>
			<persName><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideto</forename><surname>Kazawa ; Masayuki Asahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Japanese Named Entity Extraction with Redundant Morphological Analysis. HLT-NAACL</title>
				<imprint>
			<date type="published" when="2002">2002. 2003. 2003</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="390" to="396" />
		</imprint>
	</monogr>
	<note>Masayuki Asahara. Corpus-based Japanese morphological analysis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A TBL Based Post-processing Method to NER</title>
		<author>
			<persName><forename type="first">Liu</forename><surname>Li-Gang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tan</forename><surname>Hong-Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Tie-Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Mu-Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">China Chinese Information Society Conference Proceedings of 25th anniversary</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transformation-based error-driven learning and natural language processing: a case study in part of speech tagging</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistic</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="543" to="565" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Statistics Based Chinese Chunk Parsing</title>
		<author>
			<persName><forename type="first">Huang</forename><surname>De-Gen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Ying-Ying ; Liu Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Tie-Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chunk Parsing Based on SVM and Error-Driven Learning Methods</title>
				<imprint>
			<date type="published" when="2000">2006. 2000</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="28" to="32" />
		</imprint>
	</monogr>
	<note>Journal of Chinese Information Processing</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A New Error-driven Learning Approach for Chinese Word Segmentation</title>
		<author>
			<persName><forename type="first">Xia</forename><surname>Xin-Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Jian-Guo</surname></persName>
		</author>
		<ptr target="//chasen.aist-nara.ac.jp" />
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="160" to="164" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
