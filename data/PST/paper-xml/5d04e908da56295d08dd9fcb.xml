<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pangloss: a novel Markov chain prefetcher</title>
				<funder ref="#_8gd4MKm #_c2ZbVF8 #_KdkDEGE #_u3nK4Pv">
					<orgName type="full">United Kingdom EPSRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-06-03">3 Jun 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Philippos</forename><surname>Papaphilippou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">H J</forename><surname>Kelly</surname></persName>
							<email>p.kelly@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wayne</forename><surname>Luk</surname></persName>
							<email>w.luk@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pangloss: a novel Markov chain prefetcher</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-06-03">3 Jun 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1906.00877v1[cs.AR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present Pangloss, an efficient high-performance data prefetcher that approximates a Markov chain on delta transitions. With a limited information scope and space/logic complexity, it is able to reconstruct a variety of both simple and complex access patterns. This is achieved by a highlyefficient representation of the Markov chain to provide accurate values for transition probabilities. In addition, we have added a mechanism to reconstruct delta transitions originally obfuscated by the out-of-order execution or page transitions, such as when streaming data from multiple sources. Our single-level (L2) prefetcher achieves a geometric speedup of 1.7% and 3.2% over selected state-of-the-art baselines (KPCP and BOP). When combined with an equivalent for the L1 cache (L1 &amp; L2), the speedups rise to 6.8% and 8.4%, and 40.4% over non-prefetch. In the multi-core evaluation, there seems to be a considerable performance improvement as well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Markov models have been used extensively in prior research for prefetching purposes, by estimating and utilising address transition probabilities for subsequent accesses. Distance prefetching is a generalisation of the common Markov model prefetchers <ref type="bibr" target="#b0">[1]</ref>, that uses deltas instead of addresses to build more general models (originally for TLBs <ref type="bibr" target="#b1">[2]</ref>). In such cases, the acquired knowledge is applied to other addresses, including previously unseen. A faithful implementation of a Markov-chain for delta transitions would be a directed graph, with deltas as states/nodes and probabilities as weighted transitions/arcs.</p><p>A delta is the difference between two consecutive addresses. As we can see from the simplified example below, given an initial address and a stream of deltas, the address stream can be reconstructed. Address: 1 4 2 7 8 9 Delta:</p><p>3 -2 5 1 1 In real systems, we have page limits, which constrain the reach of deltas. Both the virtual and physical memory space are divided into pages. For security and integrity reasons, the page allocation is usually not considered to be sequential. The page contents are indexed by the remaining least significant address bits and stay unaltered between translations. When prefetching, any predicted addresses that fall outside the page limits are discarded.</p><p>One challenge in distance prefetching is that many pages might be accessed in interleaving patterns and thus obfuscat-ing the produced delta stream. The delta stream, that would otherwise be used in its entirety to update the Markov (or alternative) model, has invalidated deltas, from comparing addresses from different pages, such as when accessing data from many sources iteratively. Our general idea is to track deltas per page instead of globally, but build an accurate Markov model for global decisions.</p><p>The main contribution of this paper is the introduction of an efficient, more-faithful representation of a Markov chain, that provides a metric of delta-transition probability. This results in increased accuracy for exploiting more complex access patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation/ Preliminary Experiment</head><p>We overview the real-world complexity of such deltatransition Markov chains, to gain an insight into related challenges and optimisations. Using a simple experiment, we monitor all the delta transitions using the competition's evaluation framework (see 3.1). We implement a dummy cache prefetcher, where all occurrences of valid delta transitions (from addresses falling in the same page) are counted inside an adjacency matrix.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> on the left, shows a visualisation of the frequencies for the (L2) delta transitions in a run of 607.cactuBSSN_s-3477B. On the right, we can see the produced Markov chain (LLC), with the width of the arrows representing the probability of transition. The sum of the width of all arcs going out of a node sum to 1 (some transitions with low probability are excluded). Figure <ref type="figure" target="#fig_1">2</ref> shows the respective visualisation of the (L2) adjacency matrx for all benchmark traces. There are some interesting observations: 1) The matrices are sparse, but 2) not as sparse to justify only supporting regular strides (such as (1, 1), i.e. the model of the next line/sequential prefetcher).</p><p>3) Instead of only supporting a limited coverage of deltas <ref type="bibr" target="#b2">[3]</ref>, it seems worthwhile to be unbiased, including negative deltas <ref type="bibr" target="#b3">[4]</ref> as well. 4) Matrices that are too sparse or empty (mcf_s1536B), indicate simple patterns or invalidated deltas (see 2.2). Some additional observations: 1) The diagonal lines are most likely from cases of transitions from seemingly-random accesses inside a page, while a regular stride is performed. For example, in a streaming operation with a delta transition (? , ? ), any secondary accesses would yield transitions of the form (? , -? + ? ), where ? is the stride and ? is a new temporary delta. 2) This also explains any vertical and horizontal lines near the axes, as such transitions are preceded and succeeded by the points (? , ? ) and (-? + ? , ? ) respectively. 3) The reason that there seem to be 'inner' bounds that make the overall shape seem like a hexagon is because such outliers would imply two consecutive deltas pointing outside the page margins. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Delta cache: A novel Markov chain representation</head><p>The main structure is an efficient representation of Markov chain for distance prefetching. One challenge in implementing a Markov chain in hardware is that a naive accurate implementation would require N*N positions, where N is the number of states, for maintaining the transition probabilities in an adjacency matrix. For this reason and the fact that it usually has a high sparsity (see 1.1), existing implementations approximate it with associative structures. Those associative structures (such as a fully-associative or set-associative cache) usually employ a Least Recently Used (LRU) <ref type="bibr" target="#b1">[2]</ref> (or approximations <ref type="bibr" target="#b4">[5]</ref>), or a First-In First-Out (FIFO) replacement policy, which are both prone to losing track of important transitions due to thrashing. Moreover, with the information kept by LRU and FIFO, there is no real metric of frequency/probabilities, which is what Markov-chains are originally supposed to provide.</p><p>In figure <ref type="figure" target="#fig_2">3</ref>, we present our Markov chain representation for the level 2 prefetcher. It is a set-associative cache, providing delta transitions based on the current delta. It is indexed by the current delta, and the blocks in each set represent the most frequent immediately-next deltas. Assuming that we observe line-addresses (L2 prefetcher in the framework), there are 64 possible positions (offsets) in a 4KB page. This totals in a delta size of 7 bits, representing values from -64 (excluding, since it points to a different page) to +63.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Delta Cache (Markov-chain)</head><p>Associativity: 16</p><p>Set index: Delta ?{-63, ..., 63} Delta Next <ref type="bibr" target="#b6">(7)</ref>, LFU bits (8) With respect to the replacement, we use an approach similar to the Least Frequently Used (LFU) replacement policy, with the goal to keep the correct transition probabilities, but also give the opportunity of phased-out prominent deltas to be evicted quickly (slight resemblance in <ref type="bibr" target="#b5">[6]</ref>). Each block in a set contains the next delta alongside a counter (LFU bits). This counter is incremented each time there is a hit. When there is an overflow, all blocks in the respective set have their counter values halved. In this way, we retain almost the same count proportions, with the reduced accuracy favouring higher values. In order to find the transition probability, we divide the value with the sum of all values in the set, which can also be calculated progressively. Keeping the proportions is important in both replacement and prioritising prefetches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Page cache: Reconstructing obfuscated delta transitions</head><p>In this subsection we describe a mechanism designed to help reconstruct delta transitions obfuscated by 'unexpected', sometimes temporary, page transitions. There are similar approaches in related work <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>. This does not modify the decision part of Pangloss, as it only helps to increase the number of valid observations for updating the Delta cache.</p><p>In a naive Markov-chain distance prefetcher, the deltas would be calculated by comparing with the latest address. Instead, we modify the algorithm to keep the last address/delta per page, thus maximising the probability of yielding a valid transition (i.e. inside the page limits).</p><p>In figure <ref type="figure" target="#fig_4">4</ref>, we can see an overview of the page cache. The page cache is set-associative, indexed by the page address. Page Tag (10), Delta Prev <ref type="bibr" target="#b6">(7)</ref>, Offset Prev <ref type="bibr" target="#b5">(6)</ref>, NRU bit (1) ? Page tag: to identify the page and distinguish from others in the set. We found that restricting it to only 10 bits had a marginal impact on performance, despite the small probability of false positives.</p><p>? Delta Prev : the previous delta, with which the transition is found. In the L2 prefetcher (cache line address granularity), the deltas are 7 bits long. On insertion, the value -64 is used as an initial value, to indicate that there was no previous delta, since it always points to a different page.</p><p>? Offset Prev : the previous address offset. This is used to calculate the current delta based on the new address. It consumes 6 bits (values from 0 to 63).</p><p>? NRU bit: This bit is used for approximating the LRU replacement policy with 1 bit <ref type="bibr" target="#b4">[5]</ref>, by always evicting the Not-Recently Used (NRU) block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Markov-chain traversal</head><p>Given a prefetch degree and the current delta, the prefetcher must decide how to traverse the approximated Markov chain, to provide the most profitable next deltas. Since the degree can allow paths of length &gt; 1, accurately evaluating the probabilities of all possible paths in the graph becomes expensive. This is because it would require degree -1 matrix multiplications involving the adjacency matrix.</p><p>We propose a simple heuristic to predict the most likely next deltas: recursively, prefetch the addresses occurring from the child deltas with probability &gt; 1/3 and proceed with the highest probable delta for the next iteration, until we count as many prefetches as the prefetch degree.</p><p>Note that if a resulting prefetch address falls out of the current page, it is discarded, but the path remains valid. This is done to preserve subsequent accesses to the same page, even if the same pattern started from other offsets during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Framework and Baseline configurations</head><p>We are using the ChampSim micro-architectural simulator for the competition's baseline configurations for 1-core and 4core simulations. The warmup phase takes 50M instructions and the simulation runs for another 200M. We are using the provided selection of SPEC CPU2017 benchmark traces (with over 1 Misses per K instructions (MPKI)). All runs use the same branch predictor (hashed perceptron) and cache replacement algorithm (LRU).</p><p>We compare the performance of our prefetcher to two state-of-the art prefetchers, the Best-Offset Prefetcher <ref type="bibr" target="#b2">[3]</ref> (BOP) and the prefetcher from KPC <ref type="bibr" target="#b6">[7]</ref> (KPCP). The first was the winner of the previous Data Prefetching Championship (DPC2) and was ported to work as an L2 prefetcher in the current version of ChampSim. The latter is already included in the ChampSim repository and represents the prefetcher part of KPC.</p><p>Our final multi-level prefetcher, 'Proposal L1&amp;L2', includes two versions of the same design, one for L1 and one for L2. In order to be fair with the related work, we also report results for the single-level prefetcher, 'Proposal L2', which is the L2 part in standalone.</p><p>The L1 part had some additional changes to benefit from the fact that the framework allows byte-address granularity for L1. We observed a 64-bit alignment in L1, which resulted in 512 possible offsets in a 4KB page. This increases the number of sets in delta cache to 1024, the offset size to 9 bits and the delta size to 10 bits. The LFU bits are reduced to 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Single-program</head><p>Figure <ref type="figure" target="#fig_5">5</ref> illustrates the single-program evaluation. Our solution achieves a geometric speedup of 6.8% and 8.4% over KPCP and BOP respectively. The geometric speedup over non-prefetch is 40.4%. The respective geometric speedups for the single-level version are 1.7%, 3.2% and 33.5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multi-program</head><p>In order to produce representative program mixes, we divide the 46 traces in two groups, the 'low' and 'high', for those yielded a speedup of 1.3 and below (last 21 from fig. <ref type="figure" target="#fig_5">5</ref>) and those above 1.3 respectively, using 'Proposal L1 &amp; L2'. Then, for each of the 5 group combinations (l-l-l-l, l-l-l-h, ...) we produce 8 random mixes, totalling 40 mixes.</p><p>Figure <ref type="figure" target="#fig_6">6</ref> shows the weighted IPC speedups of 'Proposal L1 &amp; L2' and KPCP over the single-core runs with non-prefetch (i.e. ?(IPCi/IPCalone_i) <ref type="bibr" target="#b7">[8]</ref>). It is clear that the multi-level prefetcher performs generally better than KPCP, while the single-level version (not shown) is roughly in-between.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Resources</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Space budget.</head><p>In table 1, we present the space requirements of our multilevel prefetcher. The total number of bits (59.4 KB) is below the space budget of the competition (64 KB) for the single-core configuration. Since we have not included an LLC prefetcher, the space requirements for the multi-core configuration is multiplied by 4, which is also under the competition's space budget (4?64 KB). In the single-level case, the L2 prefetcher only consumes 13.1 KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logic complexity.</head><p>Pangloss is H/W-friendly. The low associativity in the Page Cache and Delta Cache ensures that there will be few   Table <ref type="table">1</ref>: Single-core configuration budget simultaneous comparisons of few bits. This allows keeping more information in a concise space. The Markov traversal heuristic that selects probabilities above 1/3, implies that up to 2 child deltas will be selected. Thus, one extra comparison is enough to point to the next layer. For a medium prefetch degree, the recursive lookup <ref type="bibr" target="#b4">[5]</ref> remains relatively efficient, although allowing a delay could also prove beneficial for timeliness <ref type="bibr" target="#b2">[3]</ref>.</p><p>According to the use case, many parameters that impact the space/logic complexity, can be explored further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FUTURE WORK AND CONCLUSION</head><p>All prediction mechanisms have some weaknesses. When observing short repeating delta patterns, such as 1, 1, 2, 1, 3, 1, 1, 2, 1, 3, ..., the transitions (1, 1), <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2)</ref> and <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b2">3)</ref> would yield an equal probability. This in combination with other factors, like a low prefetch degree, could have a performance overhead. This does not happen with multiple-delta histories <ref type="bibr" target="#b4">[5]</ref>. However, multiple-delta history matching could be negatively affected by some memory hierarchy effects that reorder or even hide deltas. Systematically evaluating the probability and overhead of pattern conflicts in Pangloss would be desirable. Alternatively, we could evaluate the presence of multiple-delta states in the Markov chain. One mechanism that differs from random walks on a Markov-chain is the traversal heuristic, which can be explored further.</p><p>In this paper, we introduce a H/W-friendly prefetcher with a more-faithful representation of a Markov chain, resulting in a higher accuracy and performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two visualisations for cactuBSSN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Adjacency matrix visualisations for deltatransition frequencies</figDesc><graphic url="image-1.png" coords="2,51.81,259.90,244.00,244.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Delta Cache (in L2 prefetcher)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Each block has 4 fields:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Page Cache (in L2 prefetcher)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Single-program evaluation: speedups over non-prefetch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Multi-program evaluation</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This research was sponsored by dunnhumby. The support of the <rs type="funder">United Kingdom EPSRC</rs> (grant numbers <rs type="grantNumber">EP/L016796/1</rs>, <rs type="grantNumber">EP/N031768/1</rs>, <rs type="grantNumber">EP/P010040/1</rs> and <rs type="grantNumber">EP/L00058X/1</rs>) is gratefully acknowledged.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8gd4MKm">
					<idno type="grant-number">EP/L016796/1</idno>
				</org>
				<org type="funding" xml:id="_c2ZbVF8">
					<idno type="grant-number">EP/N031768/1</idno>
				</org>
				<org type="funding" xml:id="_KdkDEGE">
					<idno type="grant-number">EP/P010040/1</idno>
				</org>
				<org type="funding" xml:id="_u3nK4Pv">
					<idno type="grant-number">EP/L00058X/1</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Data cache prefetching using a global history buffer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Symposium on High Performance Computer Architecture (HPCA&apos;04)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="96" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Going the distance for TLB prefetching: an application-driven study</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Kandiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 29th Annual International Symposium on Computer Architecture</title>
		<meeting>29th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A best-offset prefetcher</title>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Data Prefetching Championship</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Storage efficient hardware prefetching using delta-correlating prediction tables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grannaes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jahre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Natvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction-Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficiently prefetching complex address patterns</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shevgoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koladiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cache decay: Exploiting generational behavior to reduce cache leakage power</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 28th annual international symposium on computer architecture</title>
		<meeting>28th annual international symposium on computer architecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="240" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Kill the program counter: Reconstructing program behavior in the processor cache hierarchy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="737" to="749" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CRUISE: cache replacement and utility-aware scheduling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Najaf-Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Steely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="249" to="260" />
			<date type="published" when="2012">2012</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
