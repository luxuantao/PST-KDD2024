<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Medical Dialogue Response Generation with Pivotal Information Recalling</title>
				<funder ref="#_pVueUh7">
					<orgName type="full">Strategic Emerging Industry Development Special Funds of Shenzhen</orgName>
				</funder>
				<funder ref="#_d3TYsPh #_wG7uGmU">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_NUWr4B9">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-06-17">17 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yu</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yunxin</forename><surname>Li</surname></persName>
							<email>liyunxin987@163.com</email>
						</author>
						<author>
							<persName><forename type="first">Baotian</forename><surname>Hu</surname></persName>
							<email>hubaotian@hit.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
							<email>yuxiang.wu@cs.ucl.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
							<email>qingcai.chen@hit.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
							<email>xlwangsz@hit.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Yuxiang Wu</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Harbin Institute of Technology Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Qingcai Chen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Harbin Institute of Technology Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Xiaolong Wang</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Harbin Institute of Technology Shenzhen</orgName>
								<address>
									<country>China Yuxin Ding</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">Harbin Institute of Technology Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">Min Zhang</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<orgName type="department" key="dep1">Yuxin Ding, and Min Zhang</orgName>
								<orgName type="department" key="dep2">Medical Dialogue Response Generation with Pivotal Information Recalling. In</orgName>
								<address>
									<postCode>2022</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff13">
								<address>
									<addrLine>9 pages</addrLine>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Medical Dialogue Response Generation with Pivotal Information Recalling</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-17">17 Jun 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3542674</idno>
					<idno type="arXiv">arXiv:2206.08611v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>medical dialogue generation, pivotal information recalling</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical dialogue generation is an important yet challenging task. Most previous works rely on the attention mechanism and largescale pretrained language models. However, these methods often fail to acquire pivotal information from the long dialogue history to yield an accurate and informative response, due to the fact that the medical entities usually scatters throughout multiple utterances along with the complex relationships between them. To mitigate this problem, we propose a medical response generation model with Pivotal Information Recalling (MedPIR), which is built on two components, i.e., knowledge-aware dialogue graph encoder and recall-enhanced generator. The knowledge-aware dialogue graph encoder constructs a dialogue graph by exploiting the knowledge relationships between entities in the utterances, and encodes it with a graph attention network. Then, the recall-enhanced generator strengthens the usage of these pivotal information by generating a summary of the dialogue before producing the actual response. Experimental results on two large-scale medical dialogue datasets show that MedPIR outperforms the strong baselines in BLEU scores and medical entities F1 measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Applied computing ? Health care information systems; ? Computing methodologies ? Discourse, dialogue and pragmatics; Natural language generation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Medical dialogue system (MDS) has received much attention due to its high practical value. Previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref> usually model the dialogue history as sequential text and employ the sequenceto-sequence (Seq2Seq) models that built on large-scale pretrained text encoder and decoder to generate medical responses.</p><p>To have a comprehensive understanding of the patient, medical dialogues are always relatively long, and there are rich medical terminologies scattered in multiple utterances. Some works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref> introduce the external medical knowledge into the Seq2Seq models and show that it can improve the performance. But these works fall short in utilizing the complex medical relationships between different utterances, which is important for inducing the next response. As shown in Figure <ref type="figure">1</ref>, the entities tenesmus and enteritis indicate the symptom relationship between utterance#1 and utterance#4. Due to ignoring the medical relationship between utterances, the strong baseline model BERT-GPT-Entity <ref type="bibr" target="#b4">[5]</ref> misses the pivotal entity colitis in the generated response. Our MedPIR derives the colitis from enteritis and generate a more accurate response.</p><p>How to acquire pivotal information from long dialogue history is the core of MDS. Previous works heavily rely on the cross-attention mechanism to use dialogue history, which falls short in locating the key information from a long sequence. This issue may be caused by the fact that the cross-attention mechanism is not trained with explicit supervision signals when recalling pivotal information. phrases and sentences from the dialogue history and incorporate them into response generation via the cross-attention mechanism as well. However, these works bypass the fundamental problem of utilizing medical relations between different utterances, and fail to fully exploit the pivotal information from dialogue history during response generation.</p><p>The above investigation suggest that it is important to model the complex medical relationships between multiple utterances and explicitly guide the decoder to make full use of the pivotal information during response generation. In this work, we propose a Medical response generation model with Pivotal Information Recalling (MedPIR), where we enforce the generator to recall pivotal information during generation. It mainly contains the knowledgeaware dialogue graph encoder and recall-enhanced generator.</p><p>The knowledge-aware dialogue graph encoder exploits the knowledge relationship between medical entities scattered in different utterances to construct the dialogue graph. And its representation acquired with graph attention networks is fed to the generator. Hence, the knowledge-aware dialogue graph encoder can facilitate the generator to use pivotal medical information distributed in multiple utterances from the perspective of the global dialogue structure. The recall-enhanced generator is designed to explicitly generate the pivotal information from long dialogue history first. And then, the pivotal information sequence is used as the prefix of response to prompt to generate more focused responses. In this way, the recall-generator enforces the cross-attention mechanism to fully use the pivotal information from the encoder with the recall signal. Moreover, the recall-enhanced generator also strengthens the interaction between the response and pivotal information recalled from dialogue history via the self-attention mechanism within the decoder. Besides, we also retrieve relevant knowledge from the medical knowledge graph CMeKG <ref type="bibr" target="#b2">[3]</ref> and use the medical pre-trained model to obtain an in-depth understanding of medical knowledge.</p><p>Our contributions can be summarized as follows:</p><formula xml:id="formula_0">1)</formula><p>We propose an MDS model with pivotal information recalling (MedPIR). It can exploit the complex medical relationship between dialogue utterances via the knowledge-aware dialogue graph encoder and recall pivotal information from long dialogue history to produce accurate responses in the recall-enhanced generator.</p><p>2) We conduct extensive experiments on large-scale medical dialogue datasets MedDG <ref type="bibr" target="#b20">[21]</ref> and MedDialog <ref type="bibr" target="#b4">[5]</ref>.The experimental results show that our proposed model achieves new state-of-the-art results by outperforming previous strong baselines VRBot <ref type="bibr" target="#b14">[15]</ref> and BERT-GPT-Entity <ref type="bibr" target="#b20">[21]</ref> on BLEU and medical entities F1 metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Medical Dialogue System (MDS). Previous MDS works mostly adopt a sequence-to-sequence framework <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref>. It consists of a context encoder to encode the dialogue history and a decoder to generate the response. Since the medical dialogue is often long and contains professional medical information, it is difficult for the attention mechanism to attend on the pivotal information in the dialogue history. To recognition key information in medical dialogues, Du et al. <ref type="bibr" target="#b7">[8]</ref> and Zhang et al. <ref type="bibr" target="#b31">[32]</ref> extract patient's symptoms and medical status from history. Most recent, Li et al. <ref type="bibr" target="#b14">[15]</ref> proposed a variational medical dialogue generation model strengthens by summarizing diagnosis history through a key phrase. However, these method only extract key information by phrases and cannot make fully use of the complicated pivotal information scattered in dialogue history. Different from previous works, we build medical dialogue graph that exploits medical relationship between utterances, and train the model to generate the pivotal information before producing the actual response, so that the model can learn to focus on the key information.</p><p>Dialogue Graph Construction. To model the relationship between utterances in a dialogue, Chen et al. <ref type="bibr" target="#b3">[4]</ref>, Sun et al. <ref type="bibr" target="#b27">[28]</ref>, Xu et al. <ref type="bibr" target="#b30">[31]</ref> propose to construct a dialogue structure graph based on dialogue state transitions. Feng et al. <ref type="bibr" target="#b9">[10]</ref> proposed to model the dialogue structure of the meeting by modeling different discourse relations. However, they did not exploit external knowledge base, which is essential for producing medical dialogue response. In contrast, we construct a knowledge-aware dialogue graph by incorporating external medical knowledge from CMeKG.</p><p>Knowledge-grounded Dialogue Generation. Recent works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17]</ref> proposed to improve the performance of dialogue modeling by retrieving relevant knowledge from the commonsense graph, such as ConceptNet <ref type="bibr" target="#b26">[27]</ref>, and incorporating the object facts in generation.</p><p>Dinan et al. <ref type="bibr" target="#b6">[7]</ref>, Kim et al. <ref type="bibr" target="#b12">[13]</ref>, Lian et al. <ref type="bibr" target="#b17">[18]</ref>, Zhao et al. <ref type="bibr" target="#b33">[34]</ref> facilitated knowledge-ground dialogue generation by retrieving from unstructured documents. Li et al. <ref type="bibr" target="#b14">[15]</ref> and Lin et al. <ref type="bibr" target="#b18">[19]</ref> used medical knowledge graph to guide response generation through copy mechanism <ref type="bibr" target="#b23">[24]</ref>, but they did not use medical knowledge graph to exploit dialogue structure. In this work, the external knowledge is used to construct dialogue graph and is also encoded with a knowledge encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>The key information of medical dialogue often scatters throughout the long history, making it difficult for traditional MDS models to acquire pivotal information from the dialogue history. In this section, we first describe the base medical response generation model in Section 3.1. Then, we introduce two techniques to improve the recalling of pivotal information from the dialogue -knowledgeaware dialogue graph encoder (Section 3.2) and recall-enhanced generator (Section 3.3). Finally, the training method of our proposed method is presented in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Base Model</head><p>Most previous works in dialogue response generation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21]</ref> adopt the sequence-to-sequence architecture to model the dialogue history and exploit external medical knowledge <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> to generate the response. For our base model, we follow Chen et al. <ref type="bibr" target="#b4">[5]</ref> and use BERT-GPT as the backbone of our encoder and the generator. Given a dialogue history between a doctor and a patient ? = (? 1 , ? 2 , ..., ? ? ), where ? ? = (? ?,1 , ? ?,2 , ...? ?, |? ? | ) is ?-th utterance in the dialogue history with |? ? | tokens, the context encoder encodes the concatenation of utterances to obtain the context encoding H ??? .</p><p>We also follow previous works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b31">32]</ref> to retrieve external knowledge and use a knowledge encoder to obtain the knowledge encoding H ? (more details are elaborated in Section 4.1.4). The base model produces responses ? = (? 1 , ? 2 , ..., ? |? | ) conditioned on both H ??? and H ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Knowledge-aware Dialogue Graph Encoder</head><p>Since the base dialogue model only views the medical dialogue history as a sequence of utterances, it is hard to model the diverse medical causal relationships between different utterances <ref type="bibr" target="#b9">[10]</ref>, which implies the pivotal medical information for inducing the next response. To tackle this problem, we propose the Knowledge-aware Dialogue Graph Encoder (KDGE) that constructs a dialogue graph with knowledge, and then encodes the graph with a graph attention network.</p><p>First, we transform the sequential dialogue history into a graph. Each utterance is regarded as a vertex, and there are two types of edge between the vertices. One type of edge connects the neighboring utterances, which denotes the normal temporal relations like previous works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31]</ref>. The other type is knowledge-aware edge, which connects the scattered utterances with medical relationships. These knowledge-aware edges incorporates medical knowledge from external medical knowledge graph into the dialogues, allowing the model to represent complex medical relationships of the utterances. More concretely, we first extract medical entities from each utterance, and then look up the relationships between them from an external knowledge graph. <ref type="foot" target="#foot_0">1</ref> We add a knowledge-aware edge between two utterances if there exists a relationship between the medical entities from the two utterances. Fig. <ref type="figure" target="#fig_1">2</ref> shows an example of this construction process. In the left part, the bold words are entities scattered in utterances, and the blue lines connect entities with certain relations. The right part represents the constructed knowledge-aware dialogue graph.</p><p>With the constructed knowledge-aware dialogue graph ?, we then apply Relational Graph Attention Network (RGAT) proposed by Busbridge et al. <ref type="bibr" target="#b1">[2]</ref> to encode these pivotal relational information in the dialogue. For each vertex ? ? in ?, we use a transformer-based encoder to encode its corresponding utterance, and compute the average of the token representations as the utterance embedding. Then the utterance embedding is concatenated with its speaker embedding (a trainable embedding that represents the role of the speaker) to form ? ? 's initial vertex embedding v 0 ? . At last, RGAT is used to compute the updated encoding of the vertices:</p><formula xml:id="formula_1">(v 1 , ..., v ? ) = ???? (v 0 1 , ..., v 0 ? ), ? .<label>(1)</label></formula><p>To perform dialogue recalling, we regard the context encoding as initial history representation, and define recall score ? ? ? as the importance of utterance ? ? for recalling as follows:</p><formula xml:id="formula_2">? ? ? = ? (W ? ? h ??? ) ? (W ? ? v ? ) ,<label>(2)</label></formula><p>where h ??? is mean-pooled from H ??? , W ? ? and W ? ? are trainable parameters, ? denotes the sigmoid function. Then the final structure encoding of ? ? is obtained from the addition of utterance encoding h ? and vertex encoding v ? weighted by the corresponding recall score:</p><formula xml:id="formula_3">h ???,? = ? ? ? (h ? + v ? ).<label>(3)</label></formula><p>The concatenation of {h ???,? } ? ?=1 is the final structure encoding, denoted as H ??? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Recall-Enhanced Generator</head><p>In the base model, the generator first performs unidirectional selfattention with the generated sequence to obtain the decoding state at each time, and then exploits H ??? and H ? by the cross-attention mechanism. When this dialogue model is only trained to produce the response, its attention mechanism is often overwhelmed with  the long dialogue history and fails to focus on the pivotal information. We propose Recall-Enhanced Generator (REG) to explicitly generate the pivotal information R before producing the response. R is a brief summary that contains key medical information of the dialogue history. After producing R, it will continue to generate focused response as follows:</p><formula xml:id="formula_4">? ? = ??? (H ??? , H ? , H ??? , [R; ? &lt;? ]),<label>(4)</label></formula><p>At training time, R is automatically constructed with medical pretrained model PCL-MedBERT (more details introduced in Section 3.4) to serve as a supervision signal to train the model to recall pivotal information. At test time, MedPIR will first produce the recalled information and then generate the response. There are two main advantages of the method: 1) the qualified pre-generated recall R provides a shortcut for the generator to access key history information through self-attention; 2) recalling strengthens the cross-attention mechanism to attend to the pivotal information provided by the encoders.</p><p>As shown in the right half of Fig. <ref type="figure" target="#fig_2">3</ref>, tokens are first converted to embedding through the embedding matrix as the initial hidden state inputting to the generator. Then, REG sequentially generates the recalled pivotal information R, a separator, and finally the target response ? . Note that we use the average pooled knowledge encoding as the embedding of separator to drive the knowledge fusion during generation, as shown in the bottom-right part.</p><p>More specifically, REG consists of multiple layers decoder block. Let h ?-1 ? denote the output of (? -1)-th layer at ? step. The calculating process in ?-th block can be formulated as:</p><formula xml:id="formula_5">h ? ?,? = LayerNorm SA(h ?-1 ? ) + h ?-1 ? ,<label>(5)</label></formula><formula xml:id="formula_6">h ? ?,? = ?????? (H ??? , H ??? , H ? ) + h ? ?,? ,<label>(6)</label></formula><formula xml:id="formula_7">h ? ? = LayerNorm FFN(h ? ?,? ) + h ? ?,? ,<label>(7)</label></formula><p>where SA denotes unidirectional self-attention in decoder, and FFN is a feed-forward network.</p><p>To integrate different type of information from the encoders, we introduce the Fusion(?) operation, a gating mechanism that combines the context encoding H ??? , structure encoding H ??? , and knowledge encoding H ? . It first condenses multifaceted encoding by taking h ? ?,? as the query to perform cross-attention (CA) with H ??? , H ??? and H ? respectively, and then conduct weighted sum of the condensed encodings with the gate scores:</p><formula xml:id="formula_8">?????? (?) = ? ? ??? CA ? (H ??? , h ? ?,? ) + ? ? ? CA ? (H ? , h ? ?,? ) + ? ? ??? CA ? (H ??? , h ? ?,? ),<label>(8)</label></formula><p>where the gate scores ? ??? , ? ??? and ? ? are obtained by a linear layer with sigmoid function:</p><formula xml:id="formula_9">? ? = ? W ? CA ? (H, h ? ?,? ) .<label>(9)</label></formula><p>Then, the three gate scores are normalized by the softmax function to obtain the final gate scores applied in Eq. <ref type="bibr" target="#b7">(8)</ref>. At the last layer, an output projection layer is applied to get the final generating distribution ? ? over vocabulary:</p><formula xml:id="formula_10">? ? = ?? ? ???? W ? h ? ? + ? ? .<label>(10)</label></formula><p>While recalling pivotal information and generating response, the gate-based fusion network dynamically controls the inflows of context encoding, structure encoding, and knowledge encoding. The structure encoding obtained from KDGE provides complementary information to the context encoding, facilitating REG to recall pivotal information. This behavior can be demonstrated by the visualization of the gate scores in the Fig. <ref type="figure">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training</head><p>3.4.1 Recall Supervision Signals. The ideal recall sequence R is a summary of the current dialogue. But medical dialogue summary is not annotated in most cases. To deal with this problem, we introduce PCL-MedBERT to select the utterances that are most relevant to the target response as training signals. First, PCL-MedBERT encodes ? ? and ? into h ? ? and h ? ? respectively, and we use the cosine-similarity between them to score ? ? :</p><formula xml:id="formula_11">???(? ? , ? ) = h ? ? ? h ? ? ?h ? ? ??h ? ? ? . (<label>11</label></formula><formula xml:id="formula_12">)</formula><p>Then, we select ? utterances with highest similarity scores, denoted as ? ? = (? ? 1 ...? ? ? ). The concatenation of ? ? is used as the target recall R for training recall generation. Despite that this is a distantly-supervised method, the utterances extracted by PCL-MedBERT 2 usually contain pivotal information for generating an informative medical response (see Fig. <ref type="figure" target="#fig_3">5</ref> for an example of extracted and generated recall sequence). To further facilitate the model to generate qualify R at inference, we also train it to identify pivotal utterances by supervising the recall score ? ? ? (obtained by Eq. ( <ref type="formula" target="#formula_2">2</ref>)) through binary cross-entropy:</p><formula xml:id="formula_13">L ? = ? ?? ?=1 -? ? log ? ? ? -(1 -? ? ) log(1 -? ? ? ),<label>(12)</label></formula><p>where ? ? ? {0, 1} indicates whether ? ? is in ? ? . The higher ? ? ? , the more important ? ? is for recalling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Overall Training</head><p>Objective. We minimize the negative loglikelihood of the recall sequence R = (? 1 , ? 2 , ..., ? | R | ) and response ? , where ? is generated after R:</p><formula xml:id="formula_14">L R = | R | ?? ?=1 -log ? (? ? |?, ? &lt;? ),<label>(13)</label></formula><formula xml:id="formula_15">L ? = |? | ?? ?=1 -log ? (? ? |?, R, ? &lt;? ).<label>(14)</label></formula><p>Then we jointly optimize L ? , L R and L ? weighted by ? ? , ? R and ? ? , respectively:</p><formula xml:id="formula_16">L = ? ? L ? + ? R L R + ? ? L ? .<label>(15)</label></formula><p>We present the overall training algorithm in Algorithm (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Settings</head><p>4.1.1 Datasets. We adopt two medical dialogue datasets MedDG <ref type="bibr" target="#b20">[21]</ref> and MedDialog <ref type="bibr" target="#b4">[5]</ref> to evaluate our proposed model. Both of them are collected from online consultation websites. In MedDG, the training/development/test sets contain 14864/2000/1000 dialogues respectively, where each utterance is semi-automatically annotated with 5 types with a total of 160 medical entities. Li et al. <ref type="bibr" target="#b14">[15]</ref> pointed that most dialogues in MedDialog have less than 5 utterances, which also contain few medical professional information. Thus, we follow </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Evaluation</head><p>Metrics. We use BLEU <ref type="bibr" target="#b22">[23]</ref> to evaluate the n-gram lexical similarity, and use DISTINCT <ref type="bibr" target="#b15">[16]</ref> to evaluate the diversity of the generated responses. We also take medical entities F1 score as an important metric, which can better evaluate the actuality of medical response than lexical similarity metrics. In MedDG dataset, we use the published script <ref type="foot" target="#foot_1">3</ref> to recognize entities in responses, and evaluate different types of entity respectively. Due to MedDialog is not annotated with entities, we first collect medical entities in CMeKG, then extract entities in responses by string matching with the collected entities. Besides, we conduct human evaluation to evaluate the responses' fluency, coherence, and correctness. The fluency only measures whether the generated response is fluency, while coherence measures whether the generated response is smooth and logical with context. The correctness evaluates whether the responses uses correct medical knowledge. Three metrics are scored by annotators with a range from 1 (bad) to 5 (excellent).</p><p>4.1.3 Baselines. We use Seq2Seq <ref type="bibr" target="#b28">[29]</ref> and HRED <ref type="bibr" target="#b24">[25]</ref> as RNNbased dialogue generation baselines. Compared to Seq2Seq, HRED uses hierarchical encoders to model the dialogue context from token level and utterance level. DialoGPT <ref type="bibr" target="#b32">[33]</ref> and BERT-GPT <ref type="bibr" target="#b4">[5]</ref> are transformers-based pre-trained dialogue response models. Di-aloGPT is pre-trained on open-domain dialogue corpora, while BERT-GPT is pre-trained on medical domain dialogue corpora. We also compared VRBot <ref type="bibr" target="#b14">[15]</ref>, which summarizes patient states and physician actions into phrases through variational method and generate the response. In entity annotated dataset MedDG, we also compare with the entity concatenation method proposed by Liu et al. <ref type="bibr" target="#b20">[21]</ref>, which predict the entities used in the response first, and then concatenate the predicted entities with history to produce the response. Such two stages method has been verified to be effective in MedDG <ref type="bibr" target="#b20">[21]</ref>. In the following, -Entity suffix is used to distinguish the model with entity concatenation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Sequence Metrics</head><p>Entity Metrics B@1 B@2 B@4 D@2 F1 F1-D F1-S F1-A F1-T F1-M Seq2Seq <ref type="bibr" target="#b28">[29]</ref> 0  <ref type="table">1</ref>: Automatic evaluation results on MedDG dataset. The models with '-Entity' suffix denotes their inputs incorporate entities by concatenating them with history directly. The entity F1 scores of different categories: F1-D (Disease), F1-S (Symptom), F1-A (Attribute), F1-T (Test) and F1-M (Medicine). B@n denotes BLEU-n and D@2 denotes DISTINCT-2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">External Knowledge.</head><p>We exploit external knowledge following the previous knowledge-grounding dialogue generation methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15]</ref>, where the retrieved knowledge is encoded and fused in the decoder. As verified by Liu et al. <ref type="bibr" target="#b20">[21]</ref>, predicting the medical entities used in the next response is helpful for informative response generation. Thus, we train our knowledge retrieval model to retrieve medical entities might be used in the response. First, the medical entities appeared in the dialogue history are used as center nodes to select sub-graphs with one-hop relation in CMeKG. Then, we only retrieve entities contained in sub-graphs, which reduces the searching space for effective retrieval. Inspired by the bi-encoder dense retrieval method <ref type="bibr" target="#b11">[12]</ref>, we employ two independent PCL-MedBERT to encodes dialogue history ? and any entity ? (consists of several tokens) respectively, and take the representation at the [???] token as the encoder's output.</p><p>Denote the dialogue history encoding as h ? , and the entity encoding as h ? , the inner product of h ? and h ? denotes the score to retrieve this entity. Let ? + ? be one of the positive entity appeared in the target response, alone with ? negative entities {? - ? } ? ?=1 not appeared. We optimize the loss function as the negative log likelihood of the positive entity:</p><formula xml:id="formula_17">L ? ,? + ? = -log exp(h T ? h ? + ? ) exp(h T ? h ? + ? ) + ? ?=1 exp(h T ? h ? - ? ) .<label>(16)</label></formula><p>The losses produced by all positive entities in each example are averaged as the final loss to train the retriever. We retrieve top 20 entities for each dialogue history. This can be done with a single forward pass over datasets, where the retrieved entities are not changed during training and inference. Then, we employ an another PCL-MedBERT as the knowledge encoder to encode the retrieved entities. The retrieved entities are sorted by their retrieval scores and are concatenated by [???] token to a sequence. The knowledge encoder encodes the sequence to knowledge encoding H ? , and the encoder will be finetuned during training. 4.1.5 Implementation Details. For knowledge-aware graph encoder, the vertex embedding size and speaker embedding size is 512, and we use 2 layers RGAT <ref type="bibr" target="#b1">[2]</ref> to encode the graph. For recall supervised signals construction, we set utterance number ? to 3 in MedDG and 2 in MedDialog, and constrained the recall utterances in the last six rounds of dialogue history. For the RNN-based models, the encoder and decoder consist of one layer LSTM. Both the size of word embedding and hidden states are set to 300. For VRBot, we do not use the additional annotation of response intention for comparable experiments. For pre-trained models BERT-GPT and Di-aloGPT, the configurations are following the original works. We use exploitable pre-trained parameters of BERT-GPT to initialize our model. Due to its decoder uses encoding from encoder through selfattention, we initialize the cross-attention modules from scratch. We also pre-trained our model on medical domain corpus that used in BERT-GPT to improve the performance. For entity prediction in MedDG, we use 10-fold cross-validation models and ensemble results by majority voting method. The learning rate is initialized to 10 -<ref type="foot" target="#foot_2">4</ref> and 10 -5 for the RNN-based model and pre-trained model. The loss coefficients ? ? and ? R are set to 0.9, and ? ? is set to 0.1. We use the Adam optimizer <ref type="bibr" target="#b13">[14]</ref>, learning rate warm-up over the first 3000 steps and linear decay of the learning rate. Models generate responses through beam-sample 4 algorithm, where beam-size and topk are set to 5 and 64. Other generation hyper-parameters keep default settings. We use the NLTK toolkit with SmoothFunction7 to calculate BLEU scores following Liu et al. <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Analysis</head><p>The automatic evaluation results are shown in Table <ref type="table">1</ref> and<ref type="table" target="#tab_3">Table 2</ref>. MedPIR outperforms other models both on BLEU and F1 metrics. As shown in Table <ref type="table">1</ref>, BERT-GPT-Entity is the model with the best all-around performance among comparative models. Our model outperforms the strongest baseline model BERT-GPT-Entity on BLEU-1/2/4 scores by a large margin, and outperforms it by 2 points on F1. In addition, MedPIR outperforms BERT-GPT * by 3 points on F1 and 1 points on BLEU-1 (see Table <ref type="table" target="#tab_3">2</ref>). These experimental results indicate that the proposed model is superior to previous models in terms of fluency and accuracy. We can see that transformer-based models DialoGPT, BERT-GPT * and MedPIR performs significantly better than RNN-based models, e.g. DialoGPT outperforms VRBot by 4 points on F1, suggesting the advantages of transformers-based models in larger dataset. Moreover, the experimental comparisons in DISTINCT-2 metric suggest our model reaches a competitive level in generating diverse responses when achieving new SOTA results on other evaluation metrics.</p><p>We also observe that all the models with -Entity improves the BLEU-1 and F1 scores. It verifies the medical entities are useful knowledge for medical response generation. But we also observe that the entity concatenation method is unstable, e.g., BERT-GPT-Entity obtain worse BLEU-4 than BERT-GPT. It may be caused by the low medical entities prediction accuracy. In addition, it is costly to annotate the entities entailed in utterances. But it is necessary for the entity concatenate method. By comparing the experimental results of MedPIR-KDGE &amp; REG on F1 metric, we found that our knowledge retrieval strategy and gate-based fusion network are more effective and stable than other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>B@1 B@2 B@4 D@2 F1 Seq2Seq <ref type="bibr" target="#b28">[29]</ref> 0 As shown in Table <ref type="table" target="#tab_3">2</ref>, the REG and KDGE improve less in Med-Dialog than in MedDG. We suggest that it may be attributed to the fact that the length of dialogue in MedDialog is relatively short, which is also pointed by Li et al. <ref type="bibr" target="#b14">[15]</ref>. The average number of utterances in MedDialog (9.5, the version cleaned by Li et al. <ref type="bibr" target="#b14">[15]</ref>) is less than MedDG <ref type="bibr">(21.5)</ref>. It shows that MedPIR could focus on pivotal information scattered in long dialogue history and has preferable performance as the conversation length increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Analysis of Multifaceted</head><p>Encoding. We select an example from MedDG and draw the picture to show how the model uses dialogue structure encoding, context encoding and knowledge encoding during recalling pivotal information and generating response. As shown in Fig. <ref type="figure">4</ref>, the blue and red dots represent tokens of response and recall, respectively. The horizontal axis and vertical axis show the gates' scores ? ??? and ? ??? , respectively, and the scale of a dot is proportional to ? ? . We observe that recall tokens distribute in the bottom-right part, and response tokens distribute in the upper-left part. It indicates that the model mainly uses structure encoding when recalling pivotal information and mainly uses context encoding when generating the response. This distribution shows that KDGE provides complementary information to the context encoding and facilitates REG to recall pivotal information. Though the response generation uses less structure encoding, the generator  can access the pre-generated recall sequence by self-attention. The scales of blue dots are larger than red dots, indicating the model access knowledge information more when generating the response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Human Evaluation.</head><p>We conducted the human evaluation of responses in the aspects of fluency, consistency, and entity correctness. We randomly selected 100 samples from the test set of MedDG, and the corresponding responses generated by well-performed models, e.g., DialoGPT, DialoGPT-Entity, BERT-GPT, BERT-GPT-Entity and MedPIR. To ensure the fairness of assessment, the responses of each sample are shuffled and then provided to volunteers for evaluation. The final statistic results are shown in Table <ref type="table" target="#tab_5">3</ref>. Three manual evaluation indicators show that our proposed model still performs the best and far surpasses other models. Especially in aspects of coherence and correctness, MedPIR significantly outperforms other compared models, suggesting that the proposed method improve the quality of responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Case Study.</head><p>We present a case to show the pivotal information recalling method in our MedPIR in Figure <ref type="figure" target="#fig_3">5</ref>. The model generates recalled utterances, including the history utterances ? 5 , ? 14 and ? 8 in order, which are colored correspondingly in the dialogue history. The retrieved knowledge includes the symptoms and examinations about enteritis and colitis are colored by corresponding background colors in the dialogue history. MedPIR generates the responses conditioned on the retrieved knowledge and recalled utterances, which are presented in the second and third columns. The generated response and target response are shown in the last column. We can observe that the generated response's semantics is similar to the target response, where both of them express that the patient may suffer the colitis and should do a colonoscopy. The case indicates MedPIR can generate responses with pivotal information recalling and use retrieved knowledge effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose a medical response generation model with pivotal information recalling (MedPIR) to explicitly generate the pivotal information before producing the response. In this way, the generator strengthens the interaction between the response and pivotal information from dialogue history. MedPIR mainly consists of a knowledge-aware dialogue graph encoder (KDGE) and a recall-enhanced generator (REG). KDGE constructs a dialogue graph by exploiting the knowledge relationships between entities in the utterances, and encodes the graph through a graph encoder. REG equipped with the gate module to incorporate multifaceted encodings, and it recalls the pivotal information and generates the response successively. Our experiments on MedDG and MedDialog datasets demonstrate the effectiveness of MedPIR.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head># 1 Figure 1 :</head><label>11</label><figDesc>Figure 1: An excerpted medical dialogue from MedDG [21]. The colored words are key medical phrases and the underlined parts represent the pivotal information to induce the response. The knowledge graph shown on the right is usefull for diagnosing. The responses generated by the baselines and our proposed method are shown at the bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A part of medical dialogue and the corresponding dialogue graph we construct. The blue edges connect the utterances with medical relations revealed by medical entities, the orange edges connect the neighbouring utterances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The overall architecture of MedPIR. The context encoder encodes dialogue history into context encoding first. Then, the knowledge-aware dialogue graph encoder encodes dialogue graph and uses context encoding as the query to obtain the final structure encoding. The knowledge encoder encodes the retrieved medical knowledge from CMeKG. The right part shows the recall-enhanced generator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An example of recall and response generated by MedPIR in MedDG. The recalled utterances are colored correspondingly in the dialogue history. The bold entities in the history are used to retrieve knowledge. The retrieved knowledge with red-colored words are used in the generated response.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>This kind ? [R] After ? illness The condition ? the colitis.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recall Pivotal Informa?on</cell><cell>Generate Response</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">This kind ? [R] After ? my illness</cell><cell>[RSEP]</cell><cell>The condition? the colitis. [SEP]</cell></row><row><cell>? 1</cell><cell>? 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recall-Enhanced Geneator</cell></row><row><cell>? 4</cell><cell>?3</cell><cell>Dialogue Graph Encoder Knowledge-aware</cell><cell>? ???</cell><cell cols="2">Layer Normaliza?on +</cell></row><row><cell></cell><cell>Construct Graph</cell><cell>query</cell><cell></cell><cell cols="2">Feed Forward Network</cell></row><row><cell cols="2">? ? : I have ? and I feel tenesmus ?</cell><cell></cell><cell>Pooling &amp; MLP</cell><cell></cell><cell>+</cell></row><row><cell cols="2">? ? : Hello, how long has this been ? ? ? : It has been more than a month ?</cell><cell>Context Encoder</cell><cell>? ???</cell><cell></cell><cell>Gate</cell></row><row><cell></cell><cell>? ?</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">? ?? : After the examination , can ?</cell><cell></cell><cell></cell><cell></cell><cell>+</cell></row><row><cell></cell><cell cols="2">Retrieve Knowledge</cell><cell>? ?</cell><cell cols="2">Self-A?en?on &amp; Layer Normaliza?on</cell></row><row><cell cols="2">bacteria symptom examina?on disease medicine</cell><cell>Knowledge Encoder</cell><cell>Pooling &amp; MLP</cell><cell cols="2">Embedding Matrix [CLS] ?</cell><cell>?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>? ?=1 -? ? log ? ? ? -(1 -? ? ) log(1 -? ? ? ) ; Calculate ? (? ? |?, ? &lt;? ) and ? (? ? |?, R, ? &lt;? ) by Eq.(10) ?=1log ? (? ? |?, ? &lt;? ) ; ?=1log ? (? ? |?, R, ? &lt;? ) ; ? ? L ? + ? R L ? + ? ? L ? ;</figDesc><table><row><cell>4</cell><cell cols="2">Calculate {? ? ? } ? ?=1 by Eq.(2);</cell></row><row><cell>6</cell><cell></cell><cell></cell></row><row><cell>7</cell><cell>L R ?</cell><cell>| R |</cell></row><row><cell>8</cell><cell>L ? ?</cell><cell>|? |</cell></row><row><cell>11</cell><cell>end</cell><cell></cell></row><row><cell cols="2">12 end</cell><cell></cell></row><row><cell cols="3">the refined version of MedDialog preprocessed by Li et al. [15]</cell></row><row><cell cols="3">to evaluate our method, where the training/development/test sets</cell></row><row><cell cols="3">include 32723/3000/3000 dialogues respectively.</cell></row></table><note><p>2 https://code.ihub.org.cn/projects/1775 Algorithm 1: Training Algorithm Input: training dialogue dataset D, initial parameter of MedPIR ? , learning rate ?, PCL-MedBERT 1 while not converged do 2 foreach sample (?, ?) in D do 3 Obtain ? ? by PCL-MedBERT; 5 L ? ? 9 L ? 10 ? ? ? -? ?L;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Automatic evaluation results on MedDialog dataset. BERT-GPT * has been pre-trained on the MedDialog. REG indicates recall-enhanced generator, and KDGE indicates knowledge-enhanced dialogue graph encoder.4.2.1 Ablation Study.We also take the ablation experiments to verify the effects of different modules in MedPIR, which are presented in the last four lines of Table1 and Table 2. The experimental results suggest both knowledge-aware dialogue graph encoder (KDGE) and recall-enhanced generator (REG) improve the medical response generation. When we dropout the REG, where the generator produces responses directly, there is an obvious performance degradation on BLEU scores and a slight decrease on F1 score. It suggests the effectiveness of training the model generates pivotal information weakly supervised by PCL-MedBERT. When we only dropout the KDGE (-KDGE), the performance decrease significantly on BLEU and F1 scores. It indicates that the KDGE is vital to facilitate the recall-enhanced generator in MedPIR. Though the model is trained to generate recall, there is only a modest improvement without structure encoding. It is because the structure encoding captures the causal information from dialogue structure, supporting the model recalling long dialogue history effectively. Finally, when we dropout KDGE &amp; REG, the performance decreases the most on BLUE metrics, indicating the effectiveness of the two main components in MedPIR.</figDesc><table><row><cell></cell><cell>.301 0.225 0.163 0.791 0.063</cell></row><row><cell>HRED [25]</cell><cell>0.299 0.226 0.180 0.785 0.080</cell></row><row><cell>DialoGPT [33]</cell><cell>0.275 0.204 0.155 0.706 0.128</cell></row><row><cell>BERT-GPT  *  [5]</cell><cell>0.298 0.232 0.202 0.821 0.145</cell></row><row><cell>VRBot [15]</cell><cell>0.281 0.203 0.147 0.668 0.081</cell></row><row><cell>MedPIR (Ours)</cell><cell>0.308 0.237 0.210 0.811 0.174</cell></row><row><cell>-KDGE</cell><cell>0.291 0.229 0.201 0.825 0.158</cell></row><row><cell>-REG</cell><cell>0.285 0.229 0.202 0.813 0.163</cell></row><row><cell cols="2">-Knowledge encoder 0.296 0.231 0.202 0.817 0.164</cell></row><row><cell>-KDGE &amp; REG</cell><cell>0.291 0.227 0.187 0.827 0.159</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>It could be enteritis with such symptoms. You had better to see a doctor in the gastrointestinal department.</figDesc><table><row><cell>Dialogue History</cell><cell>Generated Recall</cell><cell></cell><cell>Retrieved Knowledge</cell><cell>Generated Response</cell></row><row><cell>? ? : ????????????????????????? ? ? ? : 8??????????????????????????????? ?????????????? ? Had done bowel mirror in August, there was caecal polyp, and I had taken it out. The previous test was done because of the bleeding. Now I'm pooping the red mushy stool all the time. ? ? : ????????????? ??????????????? ? Red mushy stool means the illness is aggravated,you'd better to go to the hospital digestive departmentto review colonoscopy. After the examination, can we figure out what's the cause? I'm really worried about my illness. ? ?? : ??????????????????????????????? ? ?? : ???????????????????? Because accompaniedby tenesmus, we must find the cause. Still need to test blood routine. Long-term defecate bleeds can cause anemia. ? ? : ????????????????????</cell><cell cols="2">??????????????? ???????????[SEP] (It could be enteritis with such symptoms. You had better to see a doctor in the gastrointestinal department. [R] ) ??????? ??????????????? ?????????[R] (After the examination, can we figure out what's the cause? I'm really worried about my illness. [R]) ?????? ??????????????? ????? ?[RSEP] (Red mushy stool means the illness is aggravated, you'd better to go to the hospital digestive department to review colonoscopy. [RSEP])</cell><cell>??? bloody purulent stool ?? symptom ??? colitis examination ?? symptom ?? ?? ???? colonoscopy Tenesmus ???? ?? bleeding colonoscopy ?? symptom enteritis ?? examination ?? ?? symptom ?? Tenesmus</cell><cell>?????????????? ??????????????? (It may not be able to get the cause, do a colonoscopy to rule out the possibility of chronic colitis.) Target Response ?????????????? (The condition can be judged preliminarily, it is best to have a considerationis the colitis.) colonoscopy. The preliminary ???????????????</cell></row><row><cell></cell><cell></cell><cell>????</cell><cell></cell></row><row><cell></cell><cell>context encoding s gate (gctx)</cell><cell>???? ???? ???? ???? ????</cell><cell></cell></row><row><cell></cell><cell></cell><cell>????</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">???? structure encoding s gate (gstc) ???? ????</cell><cell>????</cell></row></table><note><p><p><p><p>'???^?????</p>Figure</p>4</p>: The blue dots and red dots represent tokens of response and recall respectively. The scale of the dot is proportional to the knowledge gate score.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Results of human evaluation. The maximum score of each indicator is 5.</figDesc><table><row><cell></cell><cell cols="3">Fluency Coherence Correctness</cell></row><row><cell>DialoGPT</cell><cell>3.69</cell><cell>3.46</cell><cell>2.76</cell></row><row><cell>DialoGPT-Entity</cell><cell>4.30</cell><cell>3.20</cell><cell>2.84</cell></row><row><cell>BERT-GPT</cell><cell>4.36</cell><cell>3.73</cell><cell>3.06</cell></row><row><cell>BERT-GPT-Entity</cell><cell>4.35</cell><cell>3.74</cell><cell>3.13</cell></row><row><cell>MedPIR</cell><cell>4.42</cell><cell>3.86</cell><cell>3.25</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We choose CMeKG as our medical knowledge graph because it is the largest Chinese medical knowledge graph that is publically available.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://github.com/lwgkzl/MedDG</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://huggingface.co/transformers/internal/generation_utils</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We appreciate the insightful feedback from the anonymous reviewers. This work is jointly supported by grants: <rs type="funder">Natural Science Foundation of China</rs> (No. <rs type="grantNumber">62006061</rs> and <rs type="grantNumber">61872107</rs>), <rs type="programName">Stable Support Program for Higher Education Institutions of Shenzhen</rs> (No. <rs type="grantNumber">GXWD20201230155427003-20200824155011001</rs>) and <rs type="funder">Strategic Emerging Industry Development Special Funds of Shenzhen</rs>(No. <rs type="grantNumber">JCYJ20200109113441941</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_d3TYsPh">
					<idno type="grant-number">62006061</idno>
				</org>
				<org type="funding" xml:id="_wG7uGmU">
					<idno type="grant-number">61872107</idno>
					<orgName type="program" subtype="full">Stable Support Program for Higher Education Institutions of Shenzhen</orgName>
				</org>
				<org type="funding" xml:id="_pVueUh7">
					<idno type="grant-number">GXWD20201230155427003-20200824155011001</idno>
				</org>
				<org type="funding" xml:id="_NUWr4B9">
					<idno type="grant-number">JCYJ20200109113441941</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07">2015. May 7-9, 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Relational Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Busbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dane</forename><surname>Sherburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Cavallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">Y</forename><surname>Hammerla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05811</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Preliminary study on the construction of Chinese medical knowledge graph</title>
		<author>
			<persName><forename type="first">Odma</forename><surname>Byambasuren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongying</forename><surname>Zan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Information Processing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Structured Dialogue Policy with Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sishan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018</title>
		<editor>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pierre</forename><surname>Isabelle</surname></persName>
		</editor>
		<meeting>the 27th International Conference on Computational Linguistics, COLING 2018<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-08-20">2018. August 20-26, 2018</date>
			<biblScope unit="page" from="1257" to="1268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">MedDialog: A Large-scale Medical Dialogue Dataset</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqian</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongchao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruisi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Penghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengtao</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03329</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation</title>
		<author>
			<persName><forename type="first">Xiuyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feilong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="3426" to="3437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Wizard of Wikipedia: Knowledge-Powered Conversational Agents</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06">2019. 2019. May 6-9, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Extracting Symptoms and their Status from Clinical Conversations</title>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1087</idno>
		<ptr target="https://doi.org/10.18653/v1/p19-1087" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Long</forename><surname>Papers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Llu?s</forename><surname>M?rquez</surname></persName>
		</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07-28">2019. 2019. July 28-August 2, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="915" to="925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to Infer Entities, Properties and their Relations from Clinical Conversations</title>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4979" to="4990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dialogue Discourse-Aware Graph Model and Data Augmentation for Meeting Summarization</title>
		<author>
			<persName><forename type="first">Xiachong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinwei</forename><surname>Geng</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2021/524</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2021/524" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event</title>
		<editor>
			<persName><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</editor>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI 2021, Virtual Event<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-08">2021. 19-27 August 2021</date>
			<biblScope unit="page" from="3808" to="3814" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A knowledge-grounded neural conversation model</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dense Passage Retrieval for Open-Domain Question Answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue</title>
		<author>
			<persName><forename type="first">Byeongchang</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07">2015. May 7-9, 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-Supervised Variational Reasoning for Medical Dialogue Generation</title>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3462921</idno>
		<ptr target="https://doi.org/10.1145/3404835.3462921" />
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event</title>
		<editor>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chirag</forename><surname>Shah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Torsten</forename><surname>Suel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pablo</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</editor>
		<meeting><address><addrLine>Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-07-11">2021. July 11-15, 2021</date>
			<biblScope unit="page" from="544" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Diversity-Promoting Objective Function for Neural Conversation Models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter</title>
		<meeting>the 2016 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Zero-resource knowledge-grounded dialogue generation</title>
		<author>
			<persName><forename type="first">Linxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8475" to="8485" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to Select Knowledge for Response Generation in Dialog Systems</title>
		<author>
			<persName><forename type="first">Rongzhong</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">Sarit</forename><surname>Kraus</surname></persName>
		</editor>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10">2019. 2019. August 10-16, 2019</date>
			<biblScope unit="page" from="5081" to="5087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02">2021. February 2-9, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Enhancing dialogue symptom diagnosis with global attention and symptom graph</title>
		<author>
			<persName><forename type="first">Xinzhu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiahui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaixiao</forename><surname>Tou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5033" to="5042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">MedDG: A Large-scale Medical Consultation Dataset for Building Medical Dialogue System</title>
		<author>
			<persName><forename type="first">Wenge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07497</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 (Findings of ACL</title>
		<editor>
			<persName><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2372" to="2394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bleu: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07-06">2002. July 6-12, 2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Get To The Point: Summarization with Pointer-Generator Networks</title>
		<author>
			<persName><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<editor>
			<persName><forename type="first">Long</forename><surname>Papers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</editor>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Michael</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wellman</surname></persName>
		</editor>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016-02-12">2016. February 12-17, 2016</date>
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Summarizing Medical Conversations via Identifying Important Utterances</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhe</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020</title>
		<editor>
			<persName><forename type="first">Donia</forename><surname>Scott</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N?ria</forename><surname>Bel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</editor>
		<meeting>the 28th International Conference on Computational Linguistics, COLING 2020<address><addrLine>Barcelona, Spain (Online)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-08">2020. December 8-13, 2020</date>
			<biblScope unit="page" from="717" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">ConceptNet 5.5: An Open Multilingual Graph of General Knowledge</title>
		<author>
			<persName><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">Satinder</forename><surname>Singh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</editor>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017-02-04">2017. February 4-9, 2017</date>
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced Graph Auto-Encoder</title>
		<author>
			<persName><forename type="first">Yajing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengguang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinpei</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13869" to="13877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08">2014. 2014. December 8-13 2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Samy</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hanna</forename><forename type="middle">M</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rob</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roman</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Long Beach, CA, USA, Isabelle Guyon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Discovering Dialog Structure Graph for Coherent Dialog Generation</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1726" to="1739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MIE: A medical information extractor towards medical dialogues</title>
		<author>
			<persName><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongtao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiwan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6460" to="6469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DIALOGPT: Large-Scale Generative Pre-training for Conversational Response Generation</title>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Low-Resource Knowledge-Grounded Dialogue Generation</title>
		<author>
			<persName><forename type="first">Xueliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. April 26-30, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
