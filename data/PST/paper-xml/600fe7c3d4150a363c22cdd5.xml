<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Efficient and Effective Framework for Session-based Social Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianwen</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hong Kong University of Science and Technology Hong Kong Raymond Chi-Wing Wong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Kong</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Efficient and Effective Framework for Session-based Social Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3437963.3441792</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems â†’ Recommender systems; Social recommendation session-based recommendation</term>
					<term>social recommendation</term>
					<term>social network</term>
					<term>graph neural network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In many applications of session-based recommendation, social networks are usually available. Since users' interests are influenced by their friends, recommender systems can leverage social networks to better understand their users' preferences and thus provide more accurate recommendations. However, existing methods for sessionbased social recommendation are not efficient. To predict the next item of a user's ongoing session, the methods need to process many additional sessions of the user's friends to capture social influences, while non-social-aware methods (i.e., those without using social networks) only need to process one single session. To solve the efficiency issue, we propose an efficient framework for session-based social recommendation. In the framework, first, a heterogeneous graph neural network is used to learn user and item representations that integrate the knowledge from social networks. Then, to generate predictions, only the user and item representations relevant to the current session are passed to a non-social-aware model. During inference, since the user and item representations can be precomputed, the overall model runs as fast as the original non-social-aware model, while it can achieve better performance by leveraging the knowledge from social networks. Apart from being efficient, our framework has two additional advantages. First, the framework is flexible because it is compatible with any existing non-social-aware models and can easily incorporate more knowledge other than social networks. Second, our framework can capture cross-session item transitions while existing methods can only capture intra-session item transitions. Extensive experiments conducted on three public datasets demonstrate the effectiveness and the efficiency of the proposed framework. Our code is available at https://github.com/twchen/SEFrame.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The task of Session-based Recommendation (SR) is to predict the next action given the previous actions in the same session, where a session is a sequence of actions in close temporal proximity. When SR was initially proposed in <ref type="bibr" target="#b3">[5]</ref>, user IDs were not utilized because SR was intended for the use cases where user IDs cannot be tracked or most users generate only one or two sessions <ref type="bibr" target="#b4">[6]</ref>. In these cases, it is impossible or not meaningful to provide recommendations by mining user-item interactions. Instead, SR learns user preferences from sequential transition patterns in anonymous sessions.</p><p>If user IDs can be tracked and most users generate a sufficient number of sessions for the recommender system to learn reliable user preferences, SR can still be applied because it is a common phenomenon that user actions in the same session share a common objective and user actions in different sessions have a weak correlation <ref type="bibr" target="#b0">[2]</ref>. Therefore, it is better to provide recommendations based on sessions. Apart from capturing user interests from sequential properties as in standard SR, user IDs can be utilized so that customized recommendations can be made for users with different preferences when the same session prefix is given. This variant of SR can be called personalized session-based recommendation (PSR). Since the aforementioned phenomenon exists in many online services such as e-commerce and video sharing websites, SR has great practical value and therefore has attracted much attention recently.</p><p>In the scenarios where PSR is applicable, there is usually a social network between users. The service provider itself may have its own social network. For example, in the image sharing app Instagram, the following and being followed relationships between users define a social network. Even if there is no explicit social network in the service, it is still possible to construct a social network by either associating users to external social media platforms (e.g., Facebook) or using existing users' interactions (e.g., in Reddit, two users can be connected if they have replied to each other). The social relationships in the social network can be leveraged to provide more accurate recommendations because users' interests are influenced by their friends and connected users tend to share similar preferences <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b23">25]</ref>. Therefore, the recommender systems can better understand their users' preferences using the social network. Following the convention <ref type="bibr" target="#b12">[14]</ref>, we call this variant of SR sessionbased social recommendation (SSR), which has a broad application due to the prevalence of online social networks.  The general topic, social recommendation, has been greatly studied and many effective methods have been proposed. However, there is not yet much related work on the specific topic SSR because it is relatively new. Existing methods for social recommendation are not suitable for SSR because they do not consider the sequential order of user behaviors. DGRec <ref type="bibr" target="#b12">[14]</ref> is currently the only method for SSR but it is not efficient. To capture social influences, DGRec uses a GNN to aggregate the preferences of neighbors for each user. Each user's preferences depend on those of their neighbors and the dependency is recursive. If an ğ¿-layered GNN is used, the current user's preferences recursively depend on those of at most ğ‘ ğ¿ users, where ğ‘ is the number of sampled neighbors for each user at each layer. Since users' preferences are characterized by their most recent sessions, the model needs to process at most ğ‘ ğ¿ sessions to predict the next item of a single session. In contrast, non-social-aware methods are much more efficient because they only need to process the current session.</p><p>To solve the efficiency issue of DGRec, we propose an efficient framework for SSR, called Social-aware Efficient Framework (SE-Frame), whose overview is shown in Figure <ref type="figure" target="#fig_0">1</ref>. First, we build a heterogeneous knowledge graph from the social network and all historical user behaviors. Then, we use a heterogeneous graph network to learn user and item representations that fuse the knowledge from social relationships, user-item interactions and item transitions. Given a user and his/her current session, the relevant user and item representations are retrieved and passed to a PSR model. Since the user and item representations are social-aware, the PSR model can leverage the knowledge from the social network to provide recommendations. In this way, we have adapted a PSR model to a SSR model. The framework is efficient because the social-aware user and item representations can be precomputed for inference. Therefore, during inference, the SSR model just need to process the current session, which is as efficient as the original PSR model.</p><p>We summarize our contributions as follows.</p><p>â€¢ We propose an efficient framework for SSR called SEFrame. Using this framework, any existing models for SR can be adapted for SSR. The adapted models can leverage the knowledge from the social network to provide more accurate recommendations, while being as efficient as the original models during inference. â€¢ SEFrame is highly flexible because any existing SR models can be plugged in and it is straightforward to integrate more knowledge in addition to the social network.</p><p>â€¢ Due to the way that the knowledge graph is constructed, SEFrame can capture cross-session item transitions, while existing methods can only capture intra-session item transitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢ We also propose an effective model that implements SE-</head><p>Frame. The proposed model could give a higher prediction accuracy than both the baselines that are simple adaptations of existing SR models and the state-of-the-art SSR model, DGRec. â€¢ We conducted extensive experiments to verify the effectiveness and the efficiency of SEFrame. SSR models adapted from existing SR models using SEFrame consistently give a higher prediction accuracy than the original models, while they are as efficient as the original models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we review the related work of session-based recommendation and social recommendation.</p><p>Session-based Recommendation: Session-based Recommendation is a sequential modeling problem, for which recurrent neural networks (RNNs) are natural solutions. Hidasi et al. <ref type="bibr" target="#b3">[5]</ref> first formally defined session-based recommendation and proposed a multi-layered GRU model. Li et al. <ref type="bibr" target="#b5">[7]</ref> incorporated the attention mechanism into GRU to capture users' sequential behaviors and main purposes. Ren et al. <ref type="bibr" target="#b9">[11]</ref> considered the repeat consumption phenomenon using a GRU-based model with a repeat-explore mechanism. Convolutional neural networks (CNNs) are also powerful sequential modeling tools. <ref type="bibr" target="#b21">[23]</ref> applied dilated convolutional layers to effectively modeling long-range dependencies. Recently, graph neural networks (GNNs) have achieved superior performance in a variety of tasks including session-based recommendation. Wu et al. <ref type="bibr" target="#b17">[19]</ref> represented sessions as graphs and applied a gated graph neural network to capture complex item transitions. Chen and Wong <ref type="bibr" target="#b0">[2]</ref> solved two information loss problems of graph neural networks methods for session-based recommendation. Since these methods assume that the sessions are anonymous, they could not provide personalized recommendations.</p><p>Various attempts have been made to utilize user information in session-based recommendation. Quadrana et al. <ref type="bibr" target="#b8">[10]</ref> proposed a hierarchical RNN model to capture users' evolving interests. Wu et al. <ref type="bibr" target="#b18">[20]</ref> extended SR-GNN <ref type="bibr" target="#b17">[19]</ref> for personalized session-based recommendation and used the attention mechanism to explicitly model the effect of user's historical interests on the current session. Guo et al. <ref type="bibr" target="#b2">[4]</ref> enhanced GRU with matrix factorization to model users' long-term interests. These methods could provide more tailored recommendations by modeling users' long-term and evolving interests, but they could not capture the influences between users in social networks. Social Recommendation: Many previous studies attempted to leverage social networks to improve the recommendation results. Ma et al. <ref type="bibr" target="#b7">[9]</ref> incorporated social networks into recommender systems by regularizing the latent user factors so that connected users have similar latent factors. Zhao et al. <ref type="bibr" target="#b23">[25]</ref> extracted additional training instances from the social network for matrix factorization. Wang et al. <ref type="bibr" target="#b15">[17]</ref> distinguished and learned the personalized preferences between strong and weak ties in social networks. Xiao et al. <ref type="bibr" target="#b19">[21]</ref> adopted transfer learning to model user-item interactions and social relationships simultaneously. Wang et al. <ref type="bibr" target="#b14">[16]</ref> enhanced user modeling by integrating the knowledge from multiple heterogeneous social networks. These methods only utilize collaborative information from user-item interactions without considering the sequential order of interactions, and thus they are not suitable for session-based recommendation. Currently, the only method for session-based social recommendation is DGRec <ref type="bibr" target="#b12">[14]</ref>, which models dynamic user behaviors with an RNN and context-dependent social influences with a graph attention network. However, this method is inefficient because it needs to process many additional sessions to predict the next item of the current session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM DEFINITION</head><p>In this section, we formally define three variants of session-based recommendation, including anonymous session-based recommendation, personalized session-based recommendation, and sessionbased social recommendation.</p><p>Anonymous Session-based Recommendation (ASR): Let ğ¼ be the set of items. The dataset of users' historical behaviors D is a set of anonymous sessions. Each session ğ‘† âˆˆ D is a sequence of items clicked by an anonymous user, where ğ‘† [ğ‘¡] âˆˆ ğ¼ denotes the ğ‘¡ ğ‘¡â„ item in session ğ‘†.</p><p>Personalized Session-based Recommendation (PSR): Let ğ‘ˆ and ğ¼ be the sets of users and items, respectively. The dataset of users' historical behaviors D contains all sessions of all users. Each user ğ‘¢ âˆˆ ğ‘ˆ is associated with a set of sessions denoted by</p><formula xml:id="formula_0">D ğ‘¢ = {ğ‘† ğ‘¢ 1 , ğ‘† ğ‘¢ 2 , . . . , ğ‘† ğ‘¢ |D ğ‘¢ | }, where ğ‘† ğ‘¢ ğ‘‡ is the ğ‘‡ ğ‘¡â„ session of ğ‘¢. Each session ğ‘† ğ‘¢</formula><p>ğ‘‡ is a sequence of items clicked by user ğ‘¢, where ğ‘† ğ‘¢ ğ‘‡ [ğ‘¡] âˆˆ ğ¼ denotes the ğ‘¡ ğ‘¡â„ item in session ğ‘† ğ‘¢ ğ‘‡ . For brevity, we may drop the superscript ğ‘¢ and/or the subscript ğ‘‡ in ğ‘† ğ‘¢ ğ‘‡ if there is no ambiguity. Session-based Social Recommendation (SSR): In addition to the dataset of the historical behaviors (i.e., D) in PSR, we have a social network which is a graph S = (ğ‘ˆ , ğ¸). The set of nodes in S is the user set ğ‘ˆ , and the set ğ¸ of edges represents the social relationships between users. An edge (ğ‘¢, ğ‘£) from ğ‘¢ to ğ‘£ means that ğ‘¢ is followed by ğ‘£.</p><p>The objective of all variants is to predict the next item of a new session ğ‘† âˆ‰ D. The prediction model can access all relevant information in D (and S if the problem is SSR).</p><p>Following previous studies <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b17">19]</ref>, we embed the user IDs and item IDs into low-dimensional latent spaces. To make analysis easier, we set the same dimensionality ğ‘‘ for both user and item embeddings. All the embeddings are randomly initialized and learned with other model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SOCIAL-AWARE EFFICIENT FRAMEWORK</head><p>In this section, we introduce our efficient framework for SSR called SEFrame. SEFrame has three components. The first component learns user and item representations from a heterogeneous knowledge graph. We call this component the Knowledge Graph Embedding (KGE) component (Section 4.1) because the learned representations can be viewed as embeddings which fuse knowledge from the heterogeneous graph. The second component called the Personalized Session Embedding (PSE) component (Section 4.2) takes as input the relevant user and item representations of a given session and produces a session-specific embedding that captures the user current interests and items' contextual information. The third component called the prediction component (Section 4.3) generates a probability distribution of the next item from the session embedding, the user embedding and the item embeddings. Next, we detail each component of SEFrame in Sections 4.1 to 4.3. We present the training process of SEFrame in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Knowledge Graph Embedding (KGE) Component</head><p>This KGE component involves two tasks. The first task is to construct a heterogeneous knowledge graph K from all historical user behaviors D and the social network S. The second task is to learn user and item representations that fuse the knowledge from K using a heterogeneous graph neural network (HGNN). Formally, let K = (V, E, A, R, ğœ™,ğœ“ ) be the heterogeneous knowledge graph. The node set V = ğ‘ˆ âˆª ğ¼ consists of all users and items involved in D and S. The edge set E contains four types of directed edges, namely user-user edges, user-item edges, item-user edges and item-item edges. We reuse the symbols for sets of users and items to denote the types of nodes and edges. Specifically, the set of node types is A = {ğ‘ˆ , ğ¼ } and the set of edge types is R = {ğ‘ˆğ‘ˆ , ğ‘ˆ ğ¼, ğ¼ğ‘ˆ , ğ¼ğ¼ }. Each edge in E is associated with a weight which is an integer. ğœ™ : V â†¦ â†’ A is a function that maps a node to its type and ğœ“ : E â†¦ â†’ R is a function that maps an edge to its type.</p><p>The user-user edges represent social relationships between users. A user-user edge (ğ‘¢, ğ‘£) âˆˆ E if user ğ‘¢ is followed by user ğ‘£. We use "is followed by" instead of "follows" because GNNs update node representations using incoming edges and users are more influenced by the users they follow than those following them. The weight of a user-user edge is defined to be 1. The user-item and item-user edges represent user-item interactions. A user-item edge (ğ‘¢, ğ‘–) and an item-user edge (ğ‘–, ğ‘¢) are in E if user ğ‘¢ has clicked item ğ‘– in some sessions. The weight of each of these two edges is defined to be the number of times that the interaction happens. The item-item edges represent item transitions <ref type="bibr" target="#b17">[19]</ref>. An item-item edge (ğ‘–, ğ‘—) âˆˆ E if there is a transition from ğ‘– to ğ‘— in any session. The weight of this edge to be the number of times that the transition happens.</p><p>We include the nodes and edges that must be available under the setting of SSR. It is possible and easy to add other types of nodes and edges that are useful to predict the next items. For example, if we know the categories of items, we can add nodes for the categories and add edges between items and categories. Therefore, it is straightforward to integrate more knowledge into our framework.</p><p>After we obtain the heterogeneous knowledge graph, we do the second task. The second task is to apply a HGNN to learn representations of users and items, where the user representations capture user preferences and the social influences, and the item representations capture collaborative information from user-item interactions and cross-session item transition patterns. We call these representations knowledge graph embeddings (KG embeddings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Personalized Session Embedding (PSE) Component</head><p>The KG embeddings capture the global knowledge in all sessions and the entire social network, without capturing the session-specific context information. However, in SR, user behaviors in the current session ğ‘† are important to capture the user's dynamic interests. Therefore, the PSE component generates a personalized sessionspecific embedding that captures the user's current preferences and the items' contextual properties. It involves two tasks. The first task is to perform an operation called embedding lookup to extract the relevant KG embeddings of the current user and the items in ğ‘† from the KGE component. These extracted KG embeddings includes (1) the KG embedding of the current user in ğ‘†, denoted by ğ’– ğ¾ğº , and (2) the KG embeddings of all items in ğ‘†, denoted by ğ‘º ğ¾ğº [ğ‘¡] where ğ‘¡ = 1, 2, â€¢ â€¢ â€¢ . The second task is to perform an operation called personalized session embedding extraction to compute a personalized session-specific embedding to the extracted KG embeddings. Specifically, this operation is a function Î˜ that takes ğ’– ğ¾ğº and ğ‘º ğ¾ğº as input and computes a personalized session-specific embedding ğ’” ğ‘ƒğ‘’ğ‘Ÿ . That is, ğ’” ğ‘ƒğ‘’ğ‘Ÿ = Î˜(ğ’– ğ¾ğº , ğ‘º ğ¾ğº ).</p><p>Any existing SR model, including existing models for PSR and existing modes for ASR, can be easily plugged into our framework. Firstly, existing models for PSR can be directly plugged into our function Î˜ because the KG embeddings ğ’– ğ¾ğº and ğ‘º ğ¾ğº can be used as the user and item embeddings required by these models. The session representation generated by a PSR model can be used as the personalized session-specific embedding required by this PSE component. Secondly, although original models for ASR does not consider any user information, we could adapt each ASR model to a PSR model by appending the user KG embedding ğ’– ğ¾ğº to each item KG embedding ğ‘º ğ¾ğº [ğ‘¡] to obtain the personalized representation of item ğ‘º ğ¾ğº [ğ‘¡], so that this model could be plugged into our framework too. The personalized item representations are passed as input to the original ASR model. Then, the ASR model can utilize the user information from this personalized item representations and become a PSR model. Thus, this model could be plugged into our framework too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prediction Component</head><p>After we obtain the personalized session embedding ğ’” ğ‘ƒğ‘’ğ‘Ÿ , the prediction component can use it to generate a probability distribution of the next item. Since the user KG embedding ğ’– ğ¾ğº can be viewed as the user's long-term interests, which has been shown to be useful to predict the next item in many previous studies <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b18">20]</ref>, we obtain the final session representation ğ’” from both ğ’” ğ‘ƒğ‘’ğ‘Ÿ and ğ’– ğ¾ğº :</p><formula xml:id="formula_1">ğ’” = MLP ğ’” ğ‘ƒğ‘’ğ‘Ÿ âˆ¥ğ’– ğ¾ğº (1)</formula><p>where âˆ¥ denotes concatenation and MLP(â€¢) is a neural network that transforms the concatenated vector to a vector that has the same dimensionality as item embeddings.</p><p>To generate the probability distribution of the next item, for each item ğ‘– with embedding ğ’Š, we compute its score of being the next item of the current session as follows:</p><formula xml:id="formula_2">ğ‘§ ğ‘– = ğ’Š ğ‘‡ ğ’” (2)</formula><p>Then, the scores in ğ’› are normalized using softmax to obtain a probability distribution Å·. That is, Å· = Softmax(ğ’›). The items with the top-ğ¾ probabilities are recommended as the candidates of the next item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training</head><p>Let ğ’š be the ground-truth probability distribution of the next item, which is a one-hot vector. The loss function is defined to be the cross-entropy of the prediction and the ground truth:</p><formula xml:id="formula_3">L (ğ’š, Å·) = âˆ’ğ’š ğ‘‡ log Å·<label>(3)</label></formula><p>Then, all parameters including the embeddings are randomly initialized and jointly trained in an end-to-end manner using mini-batch stochastic gradient descent. Therefore, existing SR models can be easily adapted for SSR using our framework. The adapted social-aware models can give a higher prediction accuracy than the original non-social-aware models and even the state-of-the-art SSR model. However, we do not stop here. We further propose a model that implements the framework SEFrame and is able to have a better prediction accuracy than these simple adaptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SOCIAL-AWARE EFFICIENT RECOMMENDER</head><p>In this section, we propose a model called Social-aware Efficient Recommender (SERec) that implements SEFrame by concretely defining the KGE and PSE components. The same prediction component and training step described in Sections 4.3 and 4.4 are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementing KGE Component</head><p>For the first task of the KGE component, we adopt the same method to construct the heterogeneous knowledge graph described in Section 4.1. For the second task of the KGE component, to learn the representations of user and item nodes in the graph called the KG embeddings, we design a HGNN based on the attention mechanism, which consists of ğ¿ layers. Let ğ‘¯ ğ‘™ [ğ‘£] denote the representation of node ğ‘£ at layer ğ‘™, where ğ‘£ could be either a user or an item. The initial node representations ğ‘¯ 0 are the user and item embeddings. In the following, we describe the recursive procedure that computes the new node representations ğ‘¯ ğ‘™ at layer ğ‘™ from the old node representations ğ‘¯ ğ‘™âˆ’1 at layer ğ‘™ âˆ’ 1.</p><p>At layer ğ‘™, we compute the new user representations based on two concepts, namely social influences and user preferences. Firstly, we compute the messages passed between users to capture social influences. The message from user ğ‘£ that ğ‘¢ follows is computed as a linear transformation of the node representation of ğ‘£ at layer ğ‘™ âˆ’ 1:</p><formula xml:id="formula_4">Message ğ‘™ ğ‘ˆ ğ‘ˆ (ğ‘£, ğ‘¢) = ğ‘¾ ğ‘™ ğ‘ˆ ğ‘ˆ ğ‘¯ ğ‘™âˆ’1 [ğ‘£] + ğ’ƒ ğ‘™ ğ‘ˆ ğ‘ˆ<label>(4)</label></formula><p>where ğ‘¾ ğ‘™ ğ‘ˆ ğ‘ˆ âˆˆ R ğ‘‘Ã—ğ‘‘ and ğ’ƒ ğ‘™ ğ‘ˆ ğ‘ˆ âˆˆ R ğ‘‘ are learnable parameters. Secondly, we compute messages passed from items to users to capture user preferences. The message from item ğ‘– that ğ‘¢ has clicked before is computed as follows:</p><formula xml:id="formula_5">Message ğ‘™ ğ¼ğ‘ˆ (ğ‘–, ğ‘¢) = ğ‘¾ ğ‘™ ğ¼ğ‘ˆ ğ‘¯ ğ‘™âˆ’1 [ğ‘–] + ğ’ƒ ğ‘™ ğ¼ğ‘ˆ (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where ğ‘¾ ğ‘™ ğ¼ğ‘ˆ âˆˆ R ğ‘‘Ã—ğ‘‘ and ğ’ƒ ğ‘™ ğ¼ğ‘ˆ âˆˆ R ğ‘‘ are learnable parameters. Note that since we consider user preferences which represent how a user prefers different items (or equivalently, how items influence a user), we consider only message passing from items to users (denoting how items influence a user) and thus, we do not need to consider message passing from users to items (denoting how users affects the click of an item).</p><p>To consider both social influences and user preferences, it is common to apply a hierarchical aggregation scheme <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b22">24]</ref>. Specifically, two different aggregation functions are applied to gather the social influences from all neighboring users and the user preferences on all neighboring items:</p><formula xml:id="formula_7">ğ‘® ğ‘™ ğ‘ˆ [ğ‘¢] = Aggregate ğ‘™ ğ‘ˆ ğ‘ˆ ğ‘£ âˆˆğ‘ K ğ‘–ğ‘› (ğ‘¢)âˆ©ğ‘ˆ Message ğ‘™ ğ‘ˆ ğ‘ˆ (ğ‘£, ğ‘¢)<label>(6)</label></formula><formula xml:id="formula_8">ğ‘® ğ‘™ ğ¼ [ğ‘¢] = Aggregate ğ‘™ ğ¼ğ‘ˆ ğ‘– âˆˆğ‘ K ğ‘–ğ‘› (ğ‘¢)âˆ©ğ¼ Message ğ‘™ ğ¼ğ‘ˆ (ğ‘–, ğ‘¢)<label>(7)</label></formula><p>where ğ‘ K ğ‘–ğ‘› (ğ‘¢) denotes the in-neighbors of ğ‘¢ in K. Then, the aggregated information from neighboring users and items is merged using a second-level aggregation:</p><formula xml:id="formula_9">ğ‘¯ ğ‘™ [ğ‘¢] = Aggregate ğ‘™ ğ‘ˆ ğ‘® ğ‘™ ğ‘ˆ [ğ‘¢], ğ‘® ğ‘™ ğ¼ [ğ‘¢]<label>(8)</label></formula><p>However, we found that this hierarchical aggregation scheme has a problem because the numbers of neighboring users and items of a user may be imbalanced. For example, user ğ‘¢ may have clicked many items but just follow one or two users. In this case, the information from neighboring users is noisy while the information from neighboring items is more reliable. To handle this problem, we propose the attention aggregation scheme which can automatically decide to trust the more reliable information source. Specifically, we directly aggregate the messages from both neighboring users and items:</p><formula xml:id="formula_10">ğ‘¯ ğ‘™ [ğ‘¢] = Aggregate ğ‘™ ğ‘ˆ ğ‘£ âˆˆğ‘ K ğ‘–ğ‘› (ğ‘¢),ğ‘’=(ğ‘£,ğ‘¢) Message ğ‘™ ğœ“ (ğ‘’) (ğ‘£, ğ‘¢)<label>(9)</label></formula><p>where ğœ“ (ğ‘’) is the type of edge ğ‘’.</p><p>We define the aggregation function using the attention mechanism. Specifically, we first compute the importance score of the message passed along the edge ğ‘’ = (ğ‘£, ğ‘¢) as follows:</p><formula xml:id="formula_11">Importance ğ‘™ ğœ“ (ğ‘’ ) (ğ‘£, ğ‘¢) = ğ’’ ğ‘™ ğœ“ (ğ‘’ ) ğ‘‡ ğœ ğ‘¾ ğœ“ (ğ‘’ ) ğ‘¯ ğ‘™âˆ’1 [ğ‘£] âˆ¥ğ‘¯ ğ‘™âˆ’1 [ğ‘¢] + ğ’† ğ‘™<label>(10</label></formula><p>) where ğ’’ ğ‘™ ğœ“ (ğ‘’ ) âˆˆ R ğ‘‘ and ğ‘¾ ğ‘™ ğœ“ (ğ‘’ ) âˆˆ R ğ‘‘Ã—2ğ‘‘ are learnable parameters. ğœ denotes the sigmoid activation function and ğ’† ğ‘™ âˆˆ R ğ‘‘ is the feature vector of edge ğ‘’ at layer ğ‘™. Here, for each layer ğ‘™, we embed the weight of each edge into a dense vector as the feature vector ğ’† ğ‘™ of this edge instead of using its original weight value because the influence of the edge on the attention scores may not be monotonic. Note that the same edge could have different feature vectors at different layers to have a higher modeling capacity.</p><p>The importance scores are normalized using softmax to obtain the attention weights:</p><formula xml:id="formula_12">Attention ğ‘™ ğœ“ (ğ‘’ ) (ğ‘£, ğ‘¢) = Softmax ğ‘£ âˆˆğ‘ K ğ‘–ğ‘› (ğ‘¢) Importance ğ‘™ ğœ“ (ğ‘’ ) (ğ‘£, ğ‘¢)<label>(11)</label></formula><p>Then, the influences from all neighboring nodes are computed as the weighted sum of all messages:</p><formula xml:id="formula_13">ğ‘¯ ğ‘™ [ğ‘¢] = ğ‘£ âˆˆğ‘ K ğ‘–ğ‘› (ğ‘¢),ğ‘’=(ğ‘£,ğ‘¢) Attention ğ‘™ ğœ“ (ğ‘’ ) (ğ‘£, ğ‘¢) â€¢ Message ğ‘™ ğœ“ (ğ‘’ ) (ğ‘£, ğ‘¢)<label>(12)</label></formula><p>The aggregation information from all neighboring nodes of items can be computed similarly to that of users. To handle more types of nodes and edges, we generalize the aggregation scheme as follows.</p><p>To aggregate the information from all neighboring nodes of a target node ğ‘¢, we first compute the message passed from each neighboring node ğ‘£ âˆˆ ğ‘ K ğ‘–ğ‘› (ğ‘¢) along the edge ğ‘’ = (ğ‘£, ğ‘¢):</p><formula xml:id="formula_14">Message ğ‘™ ğœ“ (ğ‘’ ) (ğ‘£, ğ‘¢) = ğ‘¾ ğ‘™ ğœ“ (ğ‘’ ) ğ‘¯ ğ‘™âˆ’1 [ğ‘£] + ğ’ƒ ğ‘™ ğœ“ (ğ‘’ )<label>(13)</label></formula><p>which applies an edge-type-specific linear transformation on the feature vector of the source node ğ‘£, so that feature vectors from different node types are transformed into the same feature space. ğ‘¾ ğ‘™ ğœ“ (ğ‘’ ) âˆˆ R ğ‘‘Ã—ğ‘‘ and ğ’ƒ ğ‘™ ğœ“ (ğ‘’ ) âˆˆ R ğ‘‘ are learnable parameters for the edge type ğœ“ (ğ‘’).</p><p>Then, the aggregated information ğ‘¯ ğ‘™ [ğ‘¢] that gathers the messages from all neighbors in ğ‘ K ğ‘–ğ‘› (ğ‘¢) can be computed using Equations <ref type="bibr" target="#b8">(10)</ref> to <ref type="bibr" target="#b11">(13)</ref>. Therefore, it is straightforward to add more types of nodes and items.</p><p>The final step is to compute the new node representation from the aggregated information and the old node representation. To do so, we apply a simple node-specific linear transformation followed by the ReLU activation function:</p><formula xml:id="formula_15">ğ‘¯ ğ‘™ [ğ‘¢] = ReLU ğ‘¾ ğ‘™ ğœ™ (ğ‘¢) ğ‘¯ ğ‘™ [ğ‘¢] âˆ¥ğ‘¯ ğ‘™âˆ’1 [ğ‘¢] + ğ’ƒ ğ‘™ ğœ™ (ğ‘¢)<label>(14)</label></formula><p>where ğ‘¾ ğ‘™ ğœ™ (ğ‘¢) âˆˆ R ğ‘‘Ã—2ğ‘‘ and ğ’ƒ ğ‘™ ğœ™ (ğ‘¢) âˆˆ R ğ‘‘ are learnable parameters for the node type ğœ™ (ğ‘¢).</p><p>In this way, we obtain the node representation ğ‘¯ ğ‘™ [ğ‘¢] at the ğ‘™ ğ‘¡â„ HGNN layer for each node ğ‘¢, which captures both social influences from neighboring users and the user's own preferences on neighboring items. By stacking ğ¿ such HGNN layers, the final node representations ğ‘¯ ğ¿ , called the KG embeddings, capture highly contextualized information within the ğ¿-hop community of each node, which are fed into the PSE component to learn personalized session-specific preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementing PSE Component</head><p>The objective of the PSE component is to extract the current user's dynamic and personalized preferences in the current session. To do so, we propose a GNN model to learn a personalized session-specific embedding ğ’” ğ‘ƒğ‘’ğ‘Ÿ . It involves three tasks.</p><p>The first task is to construct a weighted directed graph called the session-specific graph ğº = (ğ‘‰ , ğ¸) based on an ongoing session ğ‘† of a user ğ‘¢. Specifically, the node set ğ‘‰ contains the unique items The second task is to learn a contextualized feature vector of each item in ğ‘† for user ğ‘¢, representing ğ‘¢'s current interests on items, by performing message passing on the session-specific graph ğº. The message content of a node in ğº for the message passing is initialized based on KG embeddings, including both the item KG embeddings (i.e., ğ‘º ğ¾ğº [1], ğ‘º ğ¾ğº [2], ...) and the user KG embedding (i.e., ğ’– ğ¾ğº ), which could capture ğ‘¢'s personalized preferences on items in ğ‘†. Note that for each item in ğ‘† (represented by ğ‘º ğ¾ğº [ğ‘¡]), there is a corresponding node ğ‘– in ğº. The initial message content is modeled by an initial feature vector of node ğ‘–, denoted by ğ’™ ğ‘– , corresponding to item ğ‘º ğ¾ğº [ğ‘¡] as follows.</p><formula xml:id="formula_16">ğ’™ ğ‘– = ğ‘º ğ¾ğº [ğ‘¡] âˆ¥ğ’– ğ¾ğº</formula><p>The message passing mechanism, which could help to capture ğ‘¢'s current interests by using the session-specific graph ğº, is modeled as follows. Let ğ‘ ğº ğ‘–ğ‘› (ğ‘–) and ğ‘ ğº ğ‘œğ‘¢ğ‘¡ (ğ‘–) denote the incoming and outgoing neighbors of node ğ‘– in ğº, respectively. To learn the contextualized feature vector of ğ‘–, inspired by <ref type="bibr" target="#b17">[19]</ref>, we gather the information from both ğ‘ ğº ğ‘–ğ‘› (ğ‘–) and ğ‘ ğº ğ‘œğ‘¢ğ‘¡ (ğ‘–):</p><formula xml:id="formula_17">ğ’‚ ğ‘–ğ‘› ğ‘– = 1 ğ‘˜ âˆˆğ‘ ğº ğ‘–ğ‘› (ğ‘–) ğ‘¤ ğ‘˜ğ‘– ğ‘˜ âˆˆğ‘ ğº ğ‘–ğ‘› (ğ‘–) ğ‘¤ ğ‘˜ğ‘– â€¢ ğ‘¾ ğ‘–ğ‘› ğ’™ ğ‘˜ (<label>15</label></formula><formula xml:id="formula_18">)</formula><formula xml:id="formula_19">ğ’‚ ğ‘œğ‘¢ğ‘¡ ğ‘– = 1 ğ‘˜ âˆˆğ‘ ğº ğ‘œğ‘¢ğ‘¡ (ğ‘–) ğ‘¤ ğ‘–ğ‘˜ ğ‘˜ âˆˆğ‘ ğº ğ‘œğ‘¢ğ‘¡ (ğ‘–) ğ‘¤ ğ‘–ğ‘˜ â€¢ ğ‘¾ ğ‘œğ‘¢ğ‘¡ ğ’™ ğ‘˜ (<label>16</label></formula><formula xml:id="formula_20">)</formula><formula xml:id="formula_21">ğ’‚ ğ‘– = ğ’‚ ğ‘–ğ‘› ğ‘– âˆ¥ğ’‚ ğ‘œğ‘¢ğ‘¡ ğ‘– (<label>17</label></formula><formula xml:id="formula_22">)</formula><p>where ğ‘¾ ğ‘–ğ‘› , ğ‘¾ ğ‘œğ‘¢ğ‘¡ âˆˆ R ğ‘‘Ã—2ğ‘‘ are learnable parameters and ğ’‚ ğ‘– denotes the aggregated information from ğ‘–'s neighboring nodes. Then, we obtain the contextualized feature vector by applying a gating mechanism to incorporate the information from neighboring nodes (i.e., ğ’‚ ğ‘– ) and the initial feature vector (i.e., ğ’™ ğ‘– ):</p><formula xml:id="formula_23">ğ’‰ ğ‘– = tanh (ğ‘¾ â„ (ğ’‚ ğ‘– âˆ¥ğ’™ ğ‘– ) + ğ’ƒ â„ )<label>(18)</label></formula><formula xml:id="formula_24">ğ’“ ğ‘– = ğœ (ğ‘¾ ğ‘Ÿ (ğ’‚ ğ‘– âˆ¥ğ’™ ğ‘– ) + ğ’ƒ ğ‘Ÿ )<label>(19)</label></formula><formula xml:id="formula_25">ğ’‰ ğ‘– = ğ’“ ğ‘– âŠ™ ğ’‰ ğ‘– + (1 âˆ’ ğ’“ ğ‘– ) âŠ™ ğ‘¾ ğ‘¥ ğ’™ ğ‘– (<label>20</label></formula><formula xml:id="formula_26">)</formula><p>where ğ‘¾ â„ , ğ‘¾ ğ‘Ÿ âˆˆ R ğ‘‘Ã—4ğ‘‘ , ğ‘¾ ğ‘¥ âˆˆ R ğ‘‘Ã—2ğ‘‘ , and ğ’ƒ â„ , ğ’ƒ ğ‘Ÿ âˆˆ R ğ‘‘ are learnable parameters. âŠ™ denotes element-wise multiplication, and ğ’‰ ğ‘– is the contextualized feature vector of node ğ‘–.</p><p>The third task is to obtain the personalized session-specific embedding ğ’” ğ‘ƒğ‘’ğ‘Ÿ by aggregating the contextualized feature vectors of all nodes using the attention mechanism. Specifically, inspired by <ref type="bibr" target="#b17">[19]</ref>, we use the last item to select the important items in ğ‘†. Let ğ’‰ ğ‘™ğ‘ğ‘ ğ‘¡ be the contextualized feature vector of the last item in ğ‘†. Besides, since ğ‘¢'s long-term interests are also important to understand ğ‘¢'s current focus, we also consider the user KG embedding ğ’– ğ¾ğº when the attention mechanism is considered. The importance score of node ğ‘– is defined as:</p><formula xml:id="formula_27">ğœ– ğ‘– = ğ’‘ ğ‘‡ ğœ ğ‘¾ ğ’‰ ğ‘– âˆ¥ğ’‰ ğ‘™ğ‘ğ‘ ğ‘¡ âˆ¥ğ’– ğ¾ğº + ğ’“ (<label>21</label></formula><formula xml:id="formula_28">)</formula><p>where ğ’‘, ğ’“ âˆˆ R ğ‘‘ and ğ‘¾ âˆˆ R ğ‘‘Ã—3ğ‘‘ are learnable parameters.</p><p>Then, the personalized session-specific embedding ğ’” ğ‘ƒğ‘’ğ‘Ÿ is computed as the weighted sum of all contextualized feature vectors:</p><formula xml:id="formula_29">ğ’” ğ‘ƒğ‘’ğ‘Ÿ = 1â‰¤ğ‘¡ â‰¤ |ğ‘† | ğ›½ ğ‘– ğ‘¡ ğ’‰ ğ‘– ğ‘¡ (<label>22</label></formula><formula xml:id="formula_30">)</formula><formula xml:id="formula_31">ğ›½ ğ‘– ğ‘¡ = Softmax 1â‰¤ğ‘¡ â‰¤ |ğ‘† | (ğœ– ğ‘– ğ‘¡ )<label>(23)</label></formula><p>where ğ‘– ğ‘¡ is the node corresponding to the item at time step ğ‘¡ in ğ‘†.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">COMPUTATIONAL COMPLEXITY</head><p>In this section, we show that the methods that implement SEFrame have lower computational complexities than the state-of-the-art SSR model, DGRec, during both training and inference in a minibatch setting. We do not include into analysis the step that computes the probability distribution of the next item (i.e., Equation ( <ref type="formula">2</ref>)) because this step is the same for all models.</p><p>Training Phase: Consider the training phase of DGRec. In Section 1, we have established that DGRec needs to process at most ğ‘ ğ¿ sessions to generate recommendations for each session, where ğ‘ is the number of sampled neighboring users for each user at each layer and ğ¿ is the number of GAT layers. Given a batch of ğµ sessions, DGRec needs to process ğ‘‚ (ğµğ‘ ğ¿ ) sessions. Since DGRec employs LSTM to process sessions, the total running time is ğ‘‚ (ğµğ‘ ğ¿ ğ¿), where ğ¿ is the average session length.</p><p>Consider the training phase of the methods that implement SE-Frame. Given a batch of ğµ sessions, the first step is to obtain the KG embeddings of the users and items involved in the batch (Section 5.1). Since the KG embeddings are not related to a specific session, we just need to find the KG embeddings of the unique users and items, denoted by ğ‘„. Suppose that we apply an ğ¿-layered HGNN to learn the KG embeddings so that each user can be influenced by his/her ğ¿-order neighboring users as in DGRec. For each node ğ‘ âˆˆ ğ‘„, we sample ğ‘ neighboring nodes of ğ‘ for each type of neighbors to obtain its final embedding ğ‘¯ ğ¿ [ğ‘]:</p><formula xml:id="formula_32">ğ‘¯ ğ¿ [ğ‘] = ğ‘“ ({ğ‘¯ ğ¿âˆ’1 [ğ‘£] : ğ‘£ âˆˆ {ğ‘} âˆª ğ‘ ğ¿ ğ‘  (ğ‘)}})<label>(24)</label></formula><p>where ğ‘ ğ¿ ğ‘  (ğ‘) is the sampled neighbors of ğ‘ at layer ğ¿, and ğ‘“ composes the functions defined in Equations ( <ref type="formula" target="#formula_11">10</ref>) to <ref type="bibr" target="#b12">(14)</ref>. It is easy to verify that the complexity of ğ‘“ is ğ‘‚ (|ğ‘ ğ¿ ğ‘  (ğ‘)|) = ğ‘‚ (ğ‘ ), which is proportional to the number of sampled neighbors. Since we sample ğ‘‚ (ğ‘ ) neighbors for each node in ğ‘„, there are in total ğ‘‚ (|ğ‘„ |ğ‘ ) neighbors sampled. Thus, the complexity at layer ğ¿ is ğ‘‚ (|ğ‘„ |ğ‘ ).</p><p>Since ğ‘¯ ğ‘™ recursively depends on ğ‘¯ ğ‘™âˆ’1 , we need to recursively sample neighbors. As a result, layer 1 has the largest total number of neighbors sampled, and thus the complexity of the first whole step is dominated by that of this step at layer 1. Since the total number of sampled neighbors at layer 1 is ğ‘‚ (|ğ‘„ |ğ‘ ğ¿ ), the running time of the first whole step is ğ‘‚ (|ğ‘„ |ğ‘ ğ¿ ). The second step is to generate session-specific embeddings (Section 5.2). Existing methods that are based on GNNs, CNNs and RNNs can compute the session-specific embedding for session ğ‘† in ğ‘‚ (|ğ‘† |) time, where |ğ‘† | denotes the number of items in ğ‘†. Therefore, since ğ¿ is the average session length, the total running time in this step is ğ‘‚ (ğµğ¿).</p><p>The remaining steps which are prediction and training can be finished in ğ‘‚ (ğµ) time.</p><p>Therefore, the total computational complexity of SEFrame is</p><formula xml:id="formula_33">ğ‘‚ (|ğ‘„ |ğ‘ ğ¿ + ğµğ¿ + ğµ) = ğ‘‚ (|ğ‘„ |ğ‘ ğ¿ + ğµğ¿).</formula><p>Comparison: Since the number of unique users and items is usually less than the number of item occurrences in all sessions (i.e., |ğ‘„ | &lt; ğµğ¿) and ğ‘ &gt; 1, we derive that |ğ‘„ |ğ‘ ğ¿ + ğµğ¿ is smaller than ğµğ‘ ğ¿ ğ¿. Therefore, methods that implement SEFrame can be faster than DGRec during training. Inference Phase: Consider the inference phase of the methods that implement SEFrame. We can precompute the KG embeddings, so the computational complexity at inference time is simply dominated by that of the second step in the training phase (i.e., ğ‘‚ (ğµğ¿)).</p><p>Consider the inference phase of DGRec. Since most recent sessions of neighboring users could be different even for the different sessions of the same user, precomputation could not be done in DGRec. Thus, the running time of DGRec in the inference phase is the same as that in the training phase (i.e., ğ‘‚ (ğµğ‘ ğ¿ ğ¿)). Comparison: Therefore, methods that implement SEFrame runs much faster than DGRec during inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTS</head><p>In this section, we first describe the experimental settings, and then make detailed analysis on the experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Settings</head><p>In this subsection, we describe datasets, compared methods and evaluation metrics for experimental settings.</p><p>7.1.1 Datasets. We conducted our experiments on the following three public real-world datasets which are commonly used in the literature of SR and social recommendation <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b17">19]</ref>: (1) Gowalla <ref type="bibr" target="#b11">[13]</ref> contains the check-in data and social network on a location-based social networking website. Following <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b2">4]</ref>, we consider two check--in records in different sessions if the time interval between them is longer than 1 day. (2) Delicious [1] was collected from an online bookmarking system where users can assign a variety of semantic tags to bookmarks. Following <ref type="bibr" target="#b12">[14]</ref>, we consider a sequence of tags with timestamps assigned to a bookmark as a session and the task is to provide personalized tag recommendations. (3) Foursquare <ref type="bibr" target="#b20">[22]</ref> is another large-scale check-in dataset. The social network is collected from an external social media platform. Similar to Gowalla, we set the splitting interval to 1 day.</p><p>For each dataset, we kept the first 60% sessions as the training set. The remaining sessions were evenly divided into the validation set and the test set. Following <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b17">19]</ref>, we first filtered short sessions and infrequent items and then applied a data augmentation technique described in <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b17">19]</ref>. Some statistics of the datasets after preprocessing are shown in Table <ref type="table" target="#tab_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Compared Methods and Evaluation Metrics.</head><p>To evaluate the performance of the proposed framework and model, we used the following representative SR methods: (1) ItemKNN <ref type="bibr" target="#b1">[3]</ref> is a commonly used baseline that recommends items that are most similar to the last item. Each item ğ‘– is represented as a binary vector ğ’™ ğ‘– âˆˆ R ğ‘€ , where ğ‘€ is the number of sessions and ğ’™ ğ‘–,ğ‘— = 1 if item ğ‘– appears in the ğ‘— ğ‘¡â„ session. The similarity between two items is defined to be the cosine similarity between their binary vectors. For LBSN datasets, we also used a variant of ItemKNN denoted by "ItemKNN  <ref type="formula" target="#formula_4">4</ref>) NARM <ref type="bibr" target="#b5">[7]</ref> is an RNN-based method for ASR that integrates attention into GRU to capture users' main purposes and sequential behaviors. ( <ref type="formula" target="#formula_5">5</ref>) STAMP <ref type="bibr" target="#b6">[8]</ref> is an ASR model that applies the attention mechanism to better capture users' short-term interests. ( <ref type="formula" target="#formula_7">6</ref>) SR-GNN <ref type="bibr" target="#b17">[19]</ref> is a method for ASR that utilizes gated graph neural network to capture complex item transitions inside sessions. ( <ref type="formula" target="#formula_8">7</ref>) SSRM <ref type="bibr" target="#b2">[4]</ref> is the state-of-the-art method for streaming SR. Its MF-based attentive session recommender could be used for PSR. ( <ref type="formula" target="#formula_9">8</ref>) DGRec <ref type="bibr" target="#b12">[14]</ref> is the state-of-the-art method for SSR that captures users' dynamic interests and context-dependent social influences using RNNs and a graph attention network. We did not include the methods for social recommendation because they are uncompetitive as shown in <ref type="bibr" target="#b12">[14]</ref>. Following <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b6">8]</ref>, we applied grid search to find the optimal hyper-parameters for all models using the validation sets. The values we searched were: {32, 64, 96, 128} for the embedding size ğ‘‘, {10 âˆ’4 , 10 âˆ’3 , â€¢ â€¢ â€¢ , 10 âˆ’1 } for the learning rate ğœ‚, and {1, 2, 3} for the number of GNN layers ğ¿. We used the Adam optimizer to train the models and the batch size was set to 128. We reported models' performance under their optimal hyper-parameter settings.</p><p>Following <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b2">4,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b21">23]</ref>, we adopted the commonly used HR@K (Hit Rate at K) and MRR@K (Mean Reciprocal Rank at K) as our evaluation metrics. The values of K included {10, 20}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Effectiveness of SEFrame and SERec</head><p>To prove the effectiveness of SEFrame, we plugged the existing non-social-aware SR methods into our framework to obtain socialaware methods for SSR. Then, we compared the performance of the adapted social-aware methods and the original methods. To prove the effectiveness of SERec, we compared SERec with the adapted social-aware methods and the state-of-the-art SSR method, DGRec. The results are shown in Table <ref type="table" target="#tab_3">2</ref>. We denote the socialaware model adapted from an existing non-social-aware model by adding a prefix 'S' to the model name. From the results, we have the following observations. The simple baselines, ItemKNN and FPMC, which only use the last item for prediction, perform much worse than other methods that can consider all previous items, showing the importance of utilizing the complete sequential information. On LBSN datasets, ItemKNN (geo) has the worse performance, meaning that it is not enough to only consider distances in these datasets. Generally, the more information model considers, the better it can perform. In most cases, the PSR model, SSRM, outperforms the ASR models, and the SSR models outperform those non-socialaware models. Therefore, it is of great advantage for SR models to consider personalized preferences and social influences when reliable user information can be obtained.</p><p>All SSR models adapted from non-social-aware methods significantly outperform their original models and even the state-of-theart SSR model, DGRec, which strongly proves the effectiveness of SEFrame. DGRec performs better than the non-social-aware models because it leverages the social network to learn more accurate user preferences. However, it does not perform better than the models that implement SEFrame. One possible reason is that in DGRec, the way of using the information from social networks introduces noise to the model. Specifically, some of the most recent sessions of neighbors and the current session may not have any common items so they are totally uncorrelated. Another reason is that models using SEFrame can leverage more knowledge than DGRec. In addition to the social network, we also integrate all historical user-item interactions and cross-session item transitions into the knowledge graph, so the models can learn more accurate user preferences.</p><p>The proposed model, SERec, outperforms the simple SSR models that are adapted from non-social-aware methods. Compared with SNextItNet, SNARM, SSTAMP and SSR-GNN, SERec considers the user' long-term interests when learning the personalized session embedding. Compared with SSSRM, SERec computes contextualized item embeddings to understand what features the user is focusing on for each item. Therefore, SERec can learn a better session representation that more accurately captures the user's dynamic and personalized interests in the current session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Efficiency of SEFrame</head><p>To prove the efficiency of SEFrame, we compared the models' running time during both training and inference on the largest dataset Foursquare. The embedding size ğ‘‘ is set to 128 and the number of GNN layers ğ¿ is set to 1. The results are shown in Table <ref type="table" target="#tab_4">3</ref>. SSR models adapted from non-social-aware methods run slightly faster than DGRec during training and run as fast as their original models during inference, which is consistent with our theoretical analysis in Section 6. SSR models are much slower than non-socialaware models because they need to process much more information. A larger running time during training is acceptable in practice as long as the model can have a better performance because the model needs to be trained only once in a period. However, a larger running time during inference is less tolerable because inference requires low latency and high throughput in most applications. The inference time of DGRec is more than twice than that of the slowest non-social-aware model, SR-GNN, which greatly limits the practical use of DGRec. In contrast, SSR models adapted from non-social-aware methods using our framework can have a higher prediction accuracy, while the inference time is as fast as that of the original models, making them better choices than DGRec in terms of both accuracy and efficiency. Although the adapted model requires more time and memory for training, during inference, there is no additional time and memory required (the original embeddings can be replaced by the KG embeddings during inference). Therefore, our framework is of great practical value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Ablation Study</head><p>To evaluate the effectiveness of different parts of SEFrame, we conducted an ablation study. We used SERec in the experiment but the results were similar for other models that implement SEFrame.</p><p>We compared the following six variants of SERec with the original SERec: (1) SERec-noPSE has no PSE component. The average of all item KG embeddings is used as ğ’” ğ‘ƒğ‘’ğ‘Ÿ . (2) SERec-noKGE has no KGE component. The original user and item embeddings are used as the KG embeddings. (3) SERec-noUU has no user-user edges in K. (4) SERec-noUIIU has no user-item and item-user edges in K. (5) SERec-noII has no item-item edges in K. (6) SERec-HA uses the hierarchical aggregation scheme instead of the attention aggregation scheme. The second-level aggregation is just defined as a linear transformation. The results are shown in Table <ref type="table" target="#tab_5">4</ref>. Variants with either component completely removed, i.e., SERec-noPSE and SERec-noKGE, have the worst performance, indicating both components have a great contribution to the performance. SERec-noPSE performs worse than SERec-noKGE, so users' dynamic interests are more important than social influences. Variants with some edges removed perform better than SERec-noKGE but are still inferior to the complete model SERec, suggesting that it is beneficial to incorporate the knowledge from social user-item interactions and cross-session item transitions. SERec-HA performs worse than SERec, which proves that the proposed attention aggregation scheme is better than the hierarchical aggregation scheme because the attention aggregation scheme can automatically choose the more reliable information source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this paper, we propose an efficient framework called SEFrame for SSR . In the framework, a heterogeneous knowledge graph is constructed from the social network and historical user behaviors. Then, a heterogeneous GNN is applied to learn KG embeddings of users and items that capture the knowledge from social connections, user-item interactions and cross-session item transitions. The KG embeddings can be fed into a SR model to provide more accurate recommendations by leveraging the information from the knowledge graph. Since the KG embeddings can be precomputed, the overall SSR model can be as efficient as the original SR model during inference while being more accurate. Apart from being efficient and effective, SEFrame is also flexible because it is compatible with any existing SR models and it can incorporate more information other than social networks. To further prove the advantages of SEFrame, we propose an implementation of the framework called SERec which has a better prediction accuracy than the simple baselines. Finally, We prove theoretically and empirically the efficiency of SEFrame, and we conduct extensive experiments to show the effectiveness of SEFrame and SERec. In the future, we want to explore the usage of SEFrame in other applications of SR where more information other than social networks are available. Besides, our current framework has a static heterogeneous knowledge graph, which means that it may be less effective in situations where the intra-and inter-dependencies among users and items are constantly evolving. We would study how to adapt our method for a more dynamic setting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of the proposed framework SEFrame</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Knowledge Graph Embedding (KGE) Component</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>... Social Network</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="7">Personalized Session Embedding (PSE) Component</cell><cell cols="2">Prediction Component</cell></row><row><cell>...</cell><cell>Historical User Behaviors ...</cell><cell>...</cell><cell>...</cell><cell>... Heterogeneous Knowledge Graph</cell><cell>...</cell><cell>Neural Network</cell><cell>Heterogenous Graph</cell><cell></cell><cell>Embedding Lookup</cell><cell>u S</cell><cell>KG</cell><cell>Embedding Extraction</cell><cell>Personalized Session</cell><cell>s</cell><cell>Per</cell><cell>Prediction Function</cell><cell>y KG</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">User and Item Embeddings</cell><cell>Current Session</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>...</cell><cell></cell><cell></cell><cell></cell><cell>U</cell><cell>...</cell><cell>...</cell><cell>I</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>u</cell><cell>KG</cell><cell></cell><cell></cell></row></table><note>L H ...</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Session 9: Search and Recommendation WSDM '21, March 8-12, 2021, Virtual Event, Israel in ğ‘† and edge set ğ¸ contains an edge (ğ‘–, ğ‘—) if there is a transition from item ğ‘– to item ğ‘— in ğ‘†. The weight of edge (ğ‘–, ğ‘—), denoted by ğ‘¤ ğ‘– ğ‘— , is the number of occurrences of ğ‘– â†’ ğ‘— in ğ‘†.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets used in the experiments</figDesc><table><row><cell>Statistic</cell><cell cols="3">Gowalla Delicious Foursquare</cell></row><row><cell># clicks</cell><cell>1,218,599</cell><cell>266,190</cell><cell>3,627,093</cell></row><row><cell># sessions</cell><cell>258,732</cell><cell>60,397</cell><cell>888,798</cell></row><row><cell># users</cell><cell>33,661</cell><cell>1313</cell><cell>39,302</cell></row><row><cell># items</cell><cell>41,229</cell><cell>5793</cell><cell>45,595</cell></row><row><cell cols="2"># social links 283,778</cell><cell>9130</cell><cell>304,030</cell></row><row><cell cols="4">(geo)" which measures the similarity between items by their geo-</cell></row><row><cell cols="4">graphical distances. (2) FPMC [12] is a Markov-chain based method</cell></row><row><cell cols="4">for next-basket recommendation. To adapt it for SR, we consider</cell></row><row><cell cols="4">the next item as the next basket. (3) NextItNet [23] is a CNN-based</cell></row><row><cell cols="4">method for ASR that models long-range dependencies by dilated</cell></row><row><cell>convolution. (</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance of SR methods in %</figDesc><table><row><cell>Model</cell><cell></cell><cell cols="2">Gowalla</cell><cell></cell><cell></cell><cell cols="2">Delicious</cell><cell></cell><cell></cell><cell cols="2">Foursquare</cell><cell></cell></row><row><cell>DGRec</cell><cell>42.18</cell><cell>23.04</cell><cell>49.95</cell><cell>23.58</cell><cell>37.78</cell><cell>20.07</cell><cell>47.36</cell><cell>20.73</cell><cell>57.05</cell><cell>31.53</cell><cell>65.85</cell><cell>32.15</cell></row><row><cell>SERec</cell><cell>46.01</cell><cell>25.14</cell><cell>53.72</cell><cell>25.67</cell><cell>40.02</cell><cell>21.29</cell><cell>49.53</cell><cell>21.98</cell><cell>61.66</cell><cell>34.03</cell><cell>70.05</cell><cell>34.62</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Running time in seconds per 1000 batches</figDesc><table><row><cell>Model</cell><cell cols="2">Training Inference</cell><cell>Model</cell><cell cols="2">Training Inference</cell></row><row><cell>NextItNet</cell><cell>18.77</cell><cell>5.56</cell><cell>SR-GNN</cell><cell>27.73</cell><cell>26.61</cell></row><row><cell>SNextItNet</cell><cell>58.17</cell><cell>5.60</cell><cell>SSR-GNN</cell><cell>50.81</cell><cell>25.96</cell></row><row><cell>NARM</cell><cell>11.95</cell><cell>5.08</cell><cell>SSRM</cell><cell>14.63</cell><cell>5.24</cell></row><row><cell>SNARM</cell><cell>48.37</cell><cell>5.16</cell><cell>SSSRM</cell><cell>45.71</cell><cell>5.20</cell></row><row><cell>STAMP</cell><cell>11.55</cell><cell>4.98</cell><cell>DGRec</cell><cell>62.77</cell><cell>62.85</cell></row><row><cell>SSTAMP</cell><cell>49.11</cell><cell>5.06</cell><cell>SERec</cell><cell>54.62</cell><cell>27.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance of the variants of SERec</figDesc><table><row><cell>Model</cell><cell cols="2">Gowalla</cell><cell cols="2">Delicious</cell><cell cols="2">Foursquare</cell></row><row><cell></cell><cell cols="6">HR@20 MRR@20 HR@20 MRR@20 HR@20 MRR@20</cell></row><row><cell>SERec-noPSE</cell><cell>50.92</cell><cell>23.29</cell><cell>47.09</cell><cell>20.30</cell><cell>68.29</cell><cell>31.16</cell></row><row><cell>SERec-noKGE</cell><cell>52.47</cell><cell>24.50</cell><cell>47.32</cell><cell>21.26</cell><cell>68.55</cell><cell>33.29</cell></row><row><cell>SERec-noUU</cell><cell>53.49</cell><cell>25.58</cell><cell>48.95</cell><cell>21.87</cell><cell>69.75</cell><cell>34.15</cell></row><row><cell>SERec-noUIIU</cell><cell>53.50</cell><cell>25.56</cell><cell>49.13</cell><cell>21.92</cell><cell>68.82</cell><cell>33.58</cell></row><row><cell>SERec-noII</cell><cell>52.58</cell><cell>25.32</cell><cell>49.19</cell><cell>21.91</cell><cell>69.35</cell><cell>34.06</cell></row><row><cell>SERec-HA</cell><cell>53.56</cell><cell>25.53</cell><cell>49.18</cell><cell>21.96</cell><cell>69.95</cell><cell>34.32</cell></row><row><cell>SERec</cell><cell>53.72</cell><cell>25.67</cell><cell>49.53</cell><cell>21.98</cell><cell>70.05</cell><cell>34.62</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements: We are grateful to the anonymous reviewers for their constructive comments on this paper. The research is supported by 16214017.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Handling Information Loss of Graph Neural Networks for Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Tianwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Wing</forename><surname>Wong</surname></persName>
		</author>
		<idno>KDD. 1172-1180</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The YouTube Video Recommendation System</title>
		<author>
			<persName><forename type="first">James</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Liebald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junning</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Palash</forename><surname>Nandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Van Vleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ullas</forename><surname>Gargi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujoy</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Livingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dasarathi</forename><surname>Sampath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Streaming Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinyong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viet</forename><surname>Hung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1569" to="1577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Session-based Recommendations with Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">BalÃ¡zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linas</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domonkos</forename><surname>Tikk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Parallel Recurrent Neural Network Architectures for Feature-rich Sessionbased Recommendations</title>
		<author>
			<persName><forename type="first">BalÃ¡zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
	<note>Alexandros Karatzoglou, and Domonkos Tikk. In RecSys</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Attentive Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">STAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Qiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Refuoe</forename><surname>Mokhosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1831" to="1839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recommender Systems with Social Regularization</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">BalÃ¡zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
	<note>In RecSys</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">RepeatNet: A Repeat Aware Neural Recommendation Machine for Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019-06">Jun Ma, and Maarten de Rijke. 2019</date>
			<biblScope unit="page" from="4806" to="4813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Factorizing Personalized Markov Chains for Next-basket Recommendation</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno>WWW. 811-820</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<ptr target="https://snap.stanford.edu/data/loc-gowalla.html" />
		<title level="m">Gowalla</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Session-based Social Recommendation via Dynamic Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Weiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="555" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Online User Representation Learning Across Heterogeneous Social Networks</title>
		<author>
			<persName><forename type="first">Weiqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingzhong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongjun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="545" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning Personalized Preference of Strong and Weak Ties for Social Recommendation</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<idno>WWW. 1601-1610</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Heterogeneous Graph Attention Network</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno>WWW. 2022-2032</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Session-based Recommendation with Graph Neural Network</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Personalizing Graph Neural Networks with Attention Mechanism for Session-based Recommendation</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning and Transferring Social and Item Visibilities for Personalized Recommendation</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Yongfeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ma</forename><surname>Liu Yiqun</surname></persName>
		</author>
		<author>
			<persName><surname>Shaoping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Dingqi</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://sites.google.com/site/yangdingqi/home/foursquare-dataset" />
		<title level="m">Foursquare</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A Simple Convolutional Generative Network for Next Item Recommendation</title>
		<author>
			<persName><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Arapakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<idno>WSDM. 582-590</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Neural Network</title>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="793" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Leveraging Social Connections to Improve Personalized Ranking for Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="261" to="270" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
