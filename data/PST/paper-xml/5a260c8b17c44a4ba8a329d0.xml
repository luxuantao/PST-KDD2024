<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A c c e p t e d M a n u s c r i p t Operational thermal load forecasting in district heating networks using machine learning and expert advice</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Davy</forename><surname>Geysen</surname></persName>
							<email>davy.geysen@vito.be</email>
							<affiliation key="aff0">
								<orgName type="institution">VITO</orgName>
								<address>
									<addrLine>Boeretang 200</addrLine>
									<postCode>2400</postCode>
									<settlement>Mol</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">EnergyVille</orgName>
								<address>
									<addrLine>Thor Park 8310</addrLine>
									<postCode>3600</postCode>
									<settlement>Genk</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Oscar</forename><surname>De Somer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">VITO</orgName>
								<address>
									<addrLine>Boeretang 200</addrLine>
									<postCode>2400</postCode>
									<settlement>Mol</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">EnergyVille</orgName>
								<address>
									<addrLine>Thor Park 8310</addrLine>
									<postCode>3600</postCode>
									<settlement>Genk</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Johansson</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">NODA</orgName>
								<address>
									<addrLine>Biblioteksgatan 4</addrLine>
									<postCode>374 35</postCode>
									<settlement>Karlshamn</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jens</forename><surname>Brage</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">NODA</orgName>
								<address>
									<addrLine>Biblioteksgatan 4</addrLine>
									<postCode>374 35</postCode>
									<settlement>Karlshamn</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dirk</forename><surname>Vanhoudt</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">VITO</orgName>
								<address>
									<addrLine>Boeretang 200</addrLine>
									<postCode>2400</postCode>
									<settlement>Mol</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">EnergyVille</orgName>
								<address>
									<addrLine>Thor Park 8310</addrLine>
									<postCode>3600</postCode>
									<settlement>Genk</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A c c e p t e d M a n u s c r i p t Operational thermal load forecasting in district heating networks using machine learning and expert advice</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">10D91623D9586241D5CD48FFEF22869D</idno>
					<idno type="DOI">10.1016/j.enbuild.2017.12.042</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>District heating</term>
					<term>Data driven modelling</term>
					<term>Machine learning</term>
					<term>Aggregation rules</term>
					<term>Expert advice</term>
					<term>Ensemble methods</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Forecasting thermal load is a key component for the majority of optimization solutions for controlling district heating and cooling systems. Recent studies have analysed the results of a number of data-driven methods applied to thermal load forecasting, this paper presents the results of combining a collection of these individual methods in an expert system. The expert system will combine multiple thermal load forecasts in a way that it always tracks the best expert in the system. This solution is tested and validated using a thermal load dataset of 27 months obtained from 10 residential buildings located in Rottne, Sweden together with outdoor temperature information received from a weather forecast service. The expert system is composed of the following data-driven methods: linear regression, extremely randomized trees regression, feed-forward neural network and support vector machine. The results of the proposed solution are compared with the results of the individual methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A c c e p t e d M a n u s c r i p t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A key component of enhancing the energy efficiency in current 3 rd and innovative 4 th generation district heating systems (DHS) is the ability of predicting the network's future behaviour. More in particular forecasting the thermal load in the system in order to further optimise the DHS controller. Therefore, the work in this paper is an essential part of the Horizon 2020 STORM project in which a generic district heating and cooling network controller needs to be developed <ref type="bibr" target="#b0">[1]</ref>.</p><p>In recent years, a number of different thermal load forecasting approaches have been investigated, ranging from models solely using historic load data up to more complicated ones incorporating additional parameters like occupancy, meteorological data or physical details of the building. These approaches can be divided in two major classes: the forward and data-driven methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. In the forward or expert rules approach, equations describing the physical behaviour of a system are used to predict the output. The output of the data-driven methods on the other hand is based on data of the historical behaviour of the system. The data-driven methods, which use regression models to find the most accurate function to map the input parameters to the observed output, can be further divided in statistical and machine learning methods. In statistics, the complexity of these functions is often predetermined by the regression model whereas in machine learning this complexity is learned by the method itself <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Forward versus data-driven</head><p>In the forward methods, the thermal load forecast of buildings is approximated based on the physical principles of the building. These equations can A c c e p t e d M a n u s c r i p t range from rather simple estimates of the thermal properties of the building materials up to detailed comprehensive building models <ref type="bibr" target="#b4">[5]</ref>. Developing detailed physical models of a building is often a costly and time-consuming activity because they require a lot of detailed system information and expert knowledge. Therefore many bulding design software tools, such as EnergyPlus <ref type="bibr">[6]</ref> and TRN-SYS [7], already incorporate these complex energy simulation models. They are able to calculate heating and cooling loads as well as simulating energy consumption.</p><p>In contrast to forward methods, a data-driven approach creates a model describing the thermal load of a building based on available data of the historical behaviour of the building. Hence statistical and machine learning methods require collecting historical behavioural data. Statistical methods derive correlations between the target variable, e.g. the thermal load of the building, and influential parameters such as weather information and historic thermal load data. These methods are often used as baseline models for comparison with more elaborate methods. Several case studies indicate that they yield inferior prediction quality compared to machine learning approaches like artificial neural networks (ANNs) or support vector machines (SVMs) <ref type="bibr" target="#b5">[8]</ref><ref type="bibr" target="#b6">[9]</ref><ref type="bibr" target="#b7">[10]</ref><ref type="bibr" target="#b8">[11]</ref>. Neto et al. <ref type="bibr" target="#b9">[12]</ref> compared the consumption forecasting capabilities of ANNs with the above mentioned EnergyPlus software based on a case study. The results showed that even though the EnergyPlus model was setup with very detailed information of the building under consideration, forecast errors were comparable with ANNs trained with 17 months of historic data. Together with the fact that forward methods are costly, time-consuming to develop and poorly generalizable we can conclude that data-driven methods are better suited for thermal load prediction in an operational context. The remainder of this paper will focus on several of these data-driven methods and more in particular on combining different types of data-driven methods in an expert system of thermal load forecasting experts to enhance the performance with respect to the best individual expert.</p><p>A c c e p t e d M a n u s c r i p t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Machine learning</head><p>Machine learning approaches are a subset of the above mentioned datadriven methods. They are used to devise complex models as well as prediction algorithms. In this paper the following techniques are applied: linear regression (LR), ANNs <ref type="bibr" target="#b10">[13]</ref>, SVMs <ref type="bibr" target="#b11">[14]</ref> and extremely randomized (extra) tree regressors (ETRs) <ref type="bibr" target="#b12">[15]</ref>. In the past years these methods have become increasingly popular techniques in forecasting energy consumption <ref type="bibr" target="#b7">[10,</ref><ref type="bibr" target="#b13">[16]</ref><ref type="bibr" target="#b14">[17]</ref><ref type="bibr" target="#b16">[18]</ref><ref type="bibr" target="#b17">[19]</ref><ref type="bibr" target="#b18">[20]</ref><ref type="bibr" target="#b19">[21]</ref>. We will discuss these methods briefly in the next subsections, more information on them can be found in the papers referred to. Thereafter we will elaborate on creating an expert system combining these individual techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Linear regression</head><p>LR is an approach for modelling the relationship between a scalar dependent variable y and one or multiple explanatory variables denoted X. It is often used as a baseline model for the evaluation of machine learning methods, and we continue this practice analogous to the related studies <ref type="bibr" target="#b5">[8]</ref> and <ref type="bibr" target="#b20">[22]</ref>. We shall restrict attention to multiple linear regression (MLR) <ref type="bibr" target="#b21">[23]</ref>, and model the thermal load P at time t by a linear equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Artificial Neural Networks</head><p>ANNs are inspired by the behaviour of biological neural networks, designed to simulate the way of how a human brain processes information <ref type="bibr" target="#b10">[13]</ref>. They assemble their knowledge by detecting patterns and relationships in available Wojdyga <ref type="bibr" target="#b18">[20]</ref> applied ANNs in the context of short-term heat load forecasting for predicting the load at the main campus of the Warsaw University of Technology (WUT), a recent study by <ref type="bibr">Benalcazar et al. [21]</ref> used a similar approach in a Polish municipal district heating system. In a broader energy setting Azadeh et al. <ref type="bibr" target="#b7">[10]</ref> show the use of ANNs to predict electricity consumption in the Iranian agriculture sector, while in the work of Nasr et al. <ref type="bibr" target="#b16">[18]</ref> ANNs are used to forecast gasoline consumption in Lebanon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Support vector machines</head><p>A SVM is a computer algorithm that learns by example to assign labels to objects <ref type="bibr" target="#b11">[14]</ref>. Besides classification, where the target variable takes class labels, SVMs can also be applied for regression to enable continuous target values.</p><p>The basic idea of an SVM is that a non-linear function is learned with an MLR, mapping the input variables to a higher dimensional feature space <ref type="bibr" target="#b22">[24]</ref>.</p><p>According to Li et al. <ref type="bibr" target="#b14">[17]</ref>, who predicted the cooling load in Chinese office building, SVMs have a better prediction accuracy than a standard ANN. Dong et al. state a similar conclusion based on the prediction of energy consumption in several office buildings in Singapore. On the other hand Ekonomo <ref type="bibr" target="#b5">[8]</ref> carried out a performance comparison between the above mentioned LR, ANNs and SVMs based on predicting the energy demand in Greece. In this study the constructed ANN was more accurate than LR and had comparable performance to SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Extremely randomized trees regressor</head><p>In decision tree learning a decision tree is used as a predictive model which maps observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). Idowu et al. <ref type="bibr" target="#b20">[22]</ref> applied several machine learning methods on forecasting the thermal load in a DHS in Sweden and concluded that classical decision trees are outperformed by Page 6 of 29 A c c e p t e d M a n u s c r i p t ANNs and SVMs, which makes them less suited for thermal load forecasting.</p><p>In this paper however we use a tree-based ensemble method called extremely randomized trees or extra-trees <ref type="bibr" target="#b12">[15]</ref>. This algorithm averages predictions of a forest of trees obtained by partitioning the input-space with randomly generated splits, this leads to enhanced generalisation and reduced susceptibility to noise. Another advantage over classical trees and other ensemble methods is the reduced computational complexity of the extra-trees approach. In previous work the authors showed that extra-trees regressors are more accurate for forecasting thermal load than extreme-learning machines <ref type="bibr" target="#b23">[25]</ref>. Extreme learning machines are feed-forward neural networks with a single layer of hidden nodes, the weights between hidden nodes and outputs are learned in a single step while the weights between the input layer and the hidden nodes are chosen randomly <ref type="bibr" target="#b24">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Expert advice</head><p>Rather than comparing the performance of the individual methods described above the main goal of this study is to apply an algorithm able to combine N thermal load forecasting experts, in a way that it always tracks the best of these N experts. To achieve this we apply the concept of prediction with expert advice, this was first introduced by De Santis et al <ref type="bibr" target="#b25">[27]</ref>, in the meanwhile numerous studies on this topic have been published <ref type="bibr" target="#b26">[28]</ref><ref type="bibr" target="#b27">[29]</ref><ref type="bibr" target="#b28">[30]</ref><ref type="bibr" target="#b29">[31]</ref>. Prediction with expert advice allows to consider multiple stochastic models, each having different assumptions, in a single approach. We will discuss the concept of expert advice based on our case study of predicting the hourly thermal load in a DHS. Suppose that every day k a forecaster wants to predict the hourly thermal load of the next 24 hours by combining a fixed set of individual experts. For this we thus have access to the predictions of a fixed and finite set of experts ε = {ε 1 , . . . , ε N }. On day k, all experts will make a thermal load estimate for Page 7 of 29  the next 24 hours based on their available input data, e.g. historic thermal load and forecasted weather data. All experts will therefore return a vector This sequence is shown in algorithm 1.</p><formula xml:id="formula_0">F k = {f 1,k , . . . , f<label>24</label></formula><p>The difference between the forecaster's accumulated loss over day k ( Lk ) and that of an expert i (L i,k ) is called regret. It measures how much the forecaster regrets, in hindsight, of not having followed the advice of a particular expert.</p><p>Our goal is to find an algorithm having a small regret with regards to the best base expert in the class, this comes down to minimizing</p><formula xml:id="formula_1">R k = Lk -min 1≤i≤N L i,k .</formula><p>The next subsection elaborates on several solutions to achieve this goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Aggregation rules</head><p>In order to track the best expert using expert advice, Gaillard and Yannig <ref type="bibr" target="#b30">[32]</ref> discussed four types of aggregation rules, applied on forecasting France's by Littlestone and Warmuth <ref type="bibr" target="#b28">[30]</ref> and by Vovk <ref type="bibr" target="#b27">[29]</ref>. The FS aggregation rules were introduced by Herbster and Warmuth <ref type="bibr" target="#b31">[33]</ref> while ML-poly was introduced by Gaillard et al. <ref type="bibr" target="#b32">[34]</ref> who add multiple learning rates to a version of the polynomially weighted average forecaster described by Cesa-Bianchi and Lugosi <ref type="bibr" target="#b33">[35]</ref>. Both approaches add the notion of weights to algorithm 1. This implies that, based on the losses calculated in step 6, weights are assigned to the different base experts in order to combine the expert advice into the forecaster's prediction, calculated in step 5. These weights will minimize the forecaster's regret R k . In the EWA concept, initially each expert has the same weight</p><formula xml:id="formula_2">w i = 1/N, ∀i ∈ {1, .</formula><p>. . , N }, after that the weight of an expert i at time t is calculated as follows:</p><formula xml:id="formula_3">w i,t = e -η t-1 s=1 (Fi,s,Ys) N n=1 e -η t-1 s=1 (Fn,s,Ys)<label>(1)</label></formula><p>Here η represents a learning rate parameter which needs to be tuned. With proper tuning of η, EWA has a small average regret relative to the best fixed expert <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b34">36]</ref>. FS considers, besides η, also a mixing parameter α which takes into account the number of changes in the sequence of best experts. The initial weights should be chosen as w 1,0 , . . . , w N,0 ≥ 0 such that w 0 = w 1,0 +. . .+w N,0 ≤ 1, this way a higher initial weight can be assigned to certain base experts in the class to increase their importance. After initialization, the weights will be calculated in two steps, first a new loss update is calculated:</p><p>A c c e p t e d M a n u s c r i p t</p><formula xml:id="formula_4">v i,t = w i,t-1 e -η t-1 s=1 (Fi,s,Ys) N n=1 w i,t-1 e -η t-1 s=1 (Fn,s,Ys)<label>(2)</label></formula><p>Here the weights of round t -1 are used together with the accumulated loss of each expert up to round t -1 and learning rate η to calculate the updates.</p><p>Once these updated losses are calculated, α is introduced to calculate the new weights of the experts:</p><formula xml:id="formula_5">w i,t = α N + (1 -α) v i,t where α ∈ [0, 1]<label>(3)</label></formula><p>A positive value of α ensures that every expert has a minimal weight, which enables tracking the best compound action. Choosing α = 0 will reduce the weights of the FS approach to w i,t = v it which is equal to the EWA forecaster.</p><p>For performance comparison we also implemented a version of the ML-Poly forecaster in which the multiple learning parameters are theoretically fixed and do not need to be tuned to the application. In our study the results of the ML-Poly forecaster are as good as the FS forecaster, which confirms the analysis made in <ref type="bibr" target="#b30">[32]</ref>. For the sake of simplicity we will discuss the performance of our expert system based on the results obtained by the FS forecaster. However, more information on the ML-Poly forecaster can be found in <ref type="bibr" target="#b30">[32]</ref> and <ref type="bibr" target="#b32">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Case study</head><p>For this paper, the DHS in Rottne, Sweden, was used as a case study. This MW fossil oil burner. In 2004, the wood burner was refitted to work with more moist wood chip fuels, which lowered the capacity to 1.2 MW. Another biomass burner for wood chip fuels was also installed with a capacity of 1.5 MW. In 2012, the oil burner was upgraded to facilitate the use of biodiesel instead of fossil oil. Since then all heat generation in the Rottne district heating system is based on renewables.</p><p>There are about 200 buildings connected to the district heating system in Rottne, and of these about 150 are single-family domestic dwellings. The rest are connections to commercial customers, and of those the ten largest consumers are connected to the system used in this study. These ten controllable customers represent nearly one-third of the total heat demand, including distribution losses, in the DHS. Each such building is fitted with a district heating substation controlled by an existing controller. During the project a retrofit device was added to this existing controller hardware, which makes it possible to interact with it remotely through an outdoor temperature sensor override mechanism. This makes it possible to control the substation by sending alternative outdoor temperature signals, which the underlying controller will then respond to according to its default settings. Additional sensors were also added to measure temperature data from the supply and return temperature on the heating system side, as well as to read data from the heat meter.</p><p>Although biodiesel is considered renewable it is still quite expensive, and its use should be avoided if at all possible. The operational behaviour of the production units is connected to the supply temperature levels at the production site. If the combined production units are not able to generated the required heat demand, the supply temperature will start to drop. This, in turn, will trigger the diesel burner. This normally happens at a thermal load of about 2.7 MW. Therefore, it is of great importance for the operational optimisation mechanisms to be able to forecast when the system is about to reach such levels, since this facilitates the use of demand side management to minimise or avoid Page 11 of 29</p><p>A c c e p t e d M a n u s c r i p t such peak loads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Available input data</head><p>The input data used in this study is collected directly from the IT platform implemented at the Rottne DHS. This platform enables us to retrieve operational data of the DHS in real-time together with historic control signals,</p><p>thermal load and weather forecast data. Thermal load data and control signals are available on quarter-hourly basis while weather forecasts consist of hourly values. The heat that the buildings extract from the DHS is controlled based on a heating curve. This is a common rule-based control concept which will increase the load of a building when the outdoor temperature decreases. As a result, one can manipulate the heat consumption of a building for a short period of time, typically minutes up to a couple of hours, by adapting the outdoor temperature measurement. As stated in section 5, a network controller is installed which will manipulate these outdoor temperature measurements to enable automatic demand side management. More concretely, the control signal of this network controller consists of the difference between the real outdoor temperature and a fake virtual one. We will therefore refer to these control signals as delta T values. The total raw dataset spans a period of 27 months, from November 2014 up to February 2017.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Dataset analysis and feature selection</head><p>It is of great importance to analyse the relationships between the variables available in the dataset and the target value, e.g. the thermal load. These relationships will enable us to select the appropriate features to use in the forecasting techniques discussed in section 3. °C. From this graph it is also confirmed that in low temperature operation, the peak load is higher on weekdays than in weekends. In order to capture the above relationships, the following features will be included: day of the week, hour of the day and forecasted outdoor temperature.</p><p>The result of the thermal load autocorrelation is shown in figure <ref type="figure" target="#fig_10">2</ref>. It can be seen that the thermal load is also highly correlated with the thermal load lagging a multiple of 24 hours. The correlation drops the further we go back in time. To take into account the historic thermal load and the day of the week variations, the following features are added to the set: the thermal load with a lag of 1 day (24 hours) and 1 week (168 hours). Because the thermal load is also influenced by the control signals (dT) these too are included in the feature set with the same lag, 24 hours and 168 hours, as the thermal load.</p><p>Table <ref type="table" target="#tab_0">1</ref> gives an overview of the different feature sets we applied in our expert system. The first one is the full feature set as described above which takes into of cross-validation <ref type="bibr" target="#b35">[37]</ref>, more information on this can be found in section 7.1.</p><p>Thereafter, the same training set is used to train the models by pairing the input with the known expected target value. In the end, the models included    ). In the next section we will discuss which feature sets are used in combination with the different experts to analyse the impact on the expert system's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Implementation and results</head><p>First we will elaborate on the detailed implementation of the forecasting methods discussed in section 3, secondly we will discuss the results obtained from applying these methods, in combination with the expert system, to the dataset discussed in section 6. It is not our goal to go into all the details of the underlying machine learning methods. However, to provide information up to a level that is necessary for reproducing the results, the use of some machine learning jargon is inevitable. More information on this technical jargon can be found in the numerous references given throughout the discussion.</p><p>A c c e p t e d M a n u s c r i p t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Implementation</head><p>All the code is implemented in Python 2.7 and 3.5 <ref type="bibr" target="#b36">[38]</ref> using the machine learning library scikit-learn <ref type="bibr" target="#b37">[39]</ref>, version 0.17.1 and 0.18.1. For every forecaster the scikit-learn API offers a simple fit method to train the forecaster and a predict method to forecast the target values. The training set will serve as an input to the fit method while results will be obtained by providing the test set to the predict method.</p><p>The first and most straightforward method, LR (section 3.1), is implemented by using the built-in scikit-learn's LinearRegression. No extra parameters have to be defined before training the regressor. We integrated one LR expert, serving as a baseline scenario, which is trained using the full feature set.</p><p>Secondly the ANNs (section 3.2) are implemented using the KerasRegressor functionality. Keras is a neural networks library for Python <ref type="bibr" target="#b38">[40]</ref> capable of using the TensorFlow [41] and Theano [42] backend. Both backends are open-source software libraries able to build neural networks. In this implementation the TensorFlow backend is used but a comparison showed identical results when using Theano. Based on the outcome of several experiments on our dataset we constructed an ANN with two hidden layers each having twelve hidden units, no dropout or regularisation <ref type="bibr" target="#b40">[43]</ref> is used because the ANN is rather small. A rectified linear unit (ReLU) <ref type="bibr" target="#b41">[44]</ref>, the most popular activation function in deep neural networks, is used in both hidden layers. We use cross-validation to find the optimal hyper-parameters, number of epochs and batch size, of the ANN Thirdly the SVMs are implemented using the Epsilon-support vector regression ( -SVR) <ref type="bibr" target="#b42">[45]</ref>. The goal of this -SVR is to find a function f (x) that deviates at most from the observed target value and at the same time is as simple as possible. A radial basis function (RBF) <ref type="bibr" target="#b43">[46]</ref> is chosen as the kernel for the -SVR. As with the ANNs, GridSearchCV is applied to find the optimal values for the regularization parameter C, the kernel parameter γ and . This C pa- Table <ref type="table">2</ref> gives an overview of the eight different estimators contained in the expert system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Results and discussion</head><p>The performance assessment of the individual experts as well as the global forecaster is carried out by comparing the mean absolute percentage error (MAPE), as defined in equation 4, based on an hourly forecast for a 24 hour horizon.</p><formula xml:id="formula_6">M AP E = 100 n n t=1 A t -F t A t<label>(4)</label></formula><p>With F t the predicted value, A t the real value and n the number of predic-      were used as a test set performance analysis. Of all the experts in the system, the LR performs worst while the ANNs and ETRs are slightly better than the SVMs. From the retraining interval analysis we concluded that, in this case study, retraining does not increase the forecaster's performance. This is due to the extensive initial training set together with a DHS that did not change throughout the test set. Over this test set, the expert system achieves our predefined goal of tracking the best expert, the ANN with full feature set, in the system. Beyond this, combining different experts adds robustness to the forecaster and reduces susceptibility to changes in the DHS. Our implementation also allows for easy integration of new experts as long as they provide the fit and predict interface given by scikit-learn. Future research will consist of integrating this expert system in a DHS control solution using the thermal load forecast for peak shaving. It will enable us to implement an automatic demand response system able to control a number of buildings in the DHS to limit the thermal peak load in order to avoid the use of biodiesel burners. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>data and learn through experience. Input values, e.g. historic thermal load information and weather data, are processed across the network topology by a number of weighted linear combinations and non-linear transformations to produce one or more output values, e.g. the forecasted thermal load. In 2014, Page 5 of 29 A c c e p t e d M a n u s c r i p t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>Prediction of thermal load with expert advice 1: Parameters: decision space R ≥0 , outcome space R ≥0 , loss function , set ε of expert indices 2: for k = 1, 2, . . . do 3:prediction of experts {F E,k : E ∈ ε}, expert advice;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 : 5 :</head><label>45</label><figDesc>reveal expert advice to forecaster; prediction of forecaster based on expert advice Pk 6: calculate forecaster's loss Pk , Y k and the expert losses (F E,k , Y k )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>,k } containing their hourly thermal load predictions for the next 24 hours. At each day k the forecaster has access to the set {F E,k : E ∈ ε} representing the "advice" of each individual expert in the system . The forecaster then calculates the hourly thermal load Pk of the next 24 hours based on this set of information. At the end of the day, when the array of real thermal load values Y k is available, the experts' "losses" (F E,k , Y k ) together with the forecaster's losses Pk , Y k are scored individually by a fixed loss function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>A c c e p t e d M a n u s c r i p t</head><label></label><figDesc>daily electricity consumption. Two of them are considered in our work, the fixed share forecaster (FS) and the polynomially weighted average forecaster with multiple learning rates (ML-Poly). Both are efficient generalized implementations of the exponentially weighted average forecaster (EWA) introduced</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>is a traditional 3 3 Page 10 of 29 A c c e p t e d M a n u s c r i p t</head><label>3329</label><figDesc>rd generation DHS located in the south of Sweden and operated by Växjö Energi. The piping in the network is about 10 300 m in length, with a total volume of about 64 m 3 . The production units became operational in 1998 and at the time it consisted of a 1.5 MW burner for dry wood fuel and a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 1a shows an</head><label></label><figDesc>Figure1ashows an analysis of the hourly thermal load based on the mean and 90% confidence interval with regards to the day of the week, with week</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>account timing information, temperature forecast, historic thermal loads and control signals. The second set does not contain the historic control signals (dT) and the third set does not contain historic control signals nor historic thermal load. All these data sets are split into a training and test set. We first use the training set to optimize the hyper-parameters of the models by means</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) The mean and confidence interval of the thermal load per day of the week and hour of the day (top: week days, bottom: weekend days). (b) The correlation between the thermal load and the forecasted outdoor temperature during the week and in the weekend.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Autocorrelation of the thermal load</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>[ 37 ]of 29 A c c e p t e d M a n u s c r i p t 10 .</head><label>372910</label><figDesc>. Cross-validation is a technique to evaluate predictive models by partitioning the original set repeatedly into a training set to train the model, and a test set to evaluate it. Here we execute an exhaustive search over the specified hyper-parameter values by applying scikit-learn's GridSearchCV on the training set. GridSearchCV will repeatedly split the full training set into a subset for training and a subset for testing to evaluate the hyper-parameters. In our case this resulted in initializing the ANN with 200 epochs and a batch size of Page 17 Once the above parameters have been tuned, the ANN is trained with the training set. Two ANNs are included in our expert system, one which is trained with the full feature set and another one which is trained without the historic control signals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>of 29 A c c e p t e d M a n u s c r i p t Table 2 :</head><label>292</label><figDesc>rameter represents a trade-off between misclassification of training samples and the complexity of the decision surface. A high C value can lead to overfitting while a low C value can lead to underfitting. The γ parameter on the other hand defines how far the influence of one training sample reaches. High values of γ result in a close reach, possibly ending up in overfitting and low values of γ result in a far reach, possibly ending up in underfitting. The parameter specifies the margin in which no penalty is given to points predicted within a distance from the actual training value. Based on the GridSearchCV results, the SVMs used in our expert system are initialized with C = 1000, γ = 0.00001 and = 0.01. We added two SVMs to our expert system, trained with training sets analogue to the ANNs discussed above.Lastly the ETRs (section 3.4) are implemented using the ExtraTreeRegressor functionality. Again GridSearchCV was used to determine the optimal hyperparameters. Three ETRs are added to our expert system, each having 100 trees in their forest and a minimum of 7 samples per leaf. The first one is trained with the full set of features, the second one is trained without historic control signals and the third one is trained without historic control signals nor historic thermal load information. The minimum number of samples to split an internal node of a tree is equal to the number of features the tree is trained with plus Page 18 Overview of the experts included in the expert system with linear regression (LR), artificial neural network (ANN), support vector machine (SVM) and extra-trees regressor</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Forecasted thermal load (top) versus real thermal load (middle) and difference (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 4a shows the</head><label></label><figDesc>Figure4ashows the evolution of the individual expert's weights over time while figure4bshows the moving average of the expert's MAPEs. It is clear that the LR performs substantially worse than all the other experts, therefore</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>A c c e p t e d M a n u s c r i p t 2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Expert weights (a) and moving average of MAPEs (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>A c c e p t e d M a n u s c r i p t 9 .</head><label>9</label><figDesc>AcknowledgementThis work has been carried out by Noda, EnergyVille/VITO and Växjö Energi within the context of the STORM project, funded by the European Union's Horizon 2020 programme under grant agreement 649743.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Feature sets with Hour of Day (HoD), Day of Week (DoW), Day of Year (DoY),</figDesc><table><row><cell cols="4">forecasted outdoor temperature ( Tout), yesterday's thermal load (P t-24 ), last week's thermal</cell></row><row><cell cols="4">load (P t-168 ), yesterday's control signal (dT t-24 ) and last week's control signal (P t-168 )</cell></row><row><cell>Timing</cell><cell cols="2">Temp Thermal load</cell><cell>Control signal</cell></row><row><cell>HoD DoW DoY</cell><cell>T out</cell><cell cols="2">P t-24 P t-168 dT t-24 dT t-168</cell></row><row><cell>Full set</cell><cell></cell><cell></cell></row><row><cell>Set-dT</cell><cell></cell><cell></cell></row><row><cell>Set-lags</cell><cell></cell><cell></cell></row><row><cell cols="4">in our expert system are applied to the test set to asses their performance. The</cell></row><row><cell cols="4">27 months long dataset is split up according to the 75/25 principle, this results</cell></row><row><cell cols="4">in 20 months of training data (November 2014 to July 2016), and 7 months of</cell></row><row><cell cols="2">test data (August 2016 to February 2017</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Comparison of of the MAPEs with no retraining (top) and daily retraining (bottom) the lowest weight. It also stands out that the ANN with the full feature set has the best overall performance, followed by the three ETRs.Furthermore, it is interesting to see the performance increase with increased thermal loads, as seen from October 2016 up to February 2017. As the expert system will be used as part of a control system responsible for limiting high thermal loads in the DHS, this is a helpful property of the forecaster. The compound prediction, presented by the forecaster label in graph 4b, performs almost exactly the same as the best forecaster in the system having a MAPE of 12.06%. However if we only take into account the months with high thermal</figDesc><table><row><cell>of the experts</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>LR</cell><cell>ETR</cell><cell>SVM</cell><cell>ANN</cell><cell>Forecaster</cell></row><row><cell>No retrain</cell><cell cols="4">17.34 % 12.34 % 14.54 % 11.92 %</cell><cell>12.06 %</cell></row><row><cell cols="5">Daily retrain 17.27 % 12.42 % 14.72 % 11.56 %</cell><cell>11.95 %</cell></row><row><cell cols="6">it always has loads, October 2016 to February 2017, the forecaster even obtains a MAPE of</cell></row><row><cell>9.75%.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">To obtain the results discussed above the individual forecasters were only</cell></row><row><cell cols="6">trained once, using the available training set of November 2014 to July 2016.</cell></row></table><note><p>The test set however ranges from August 2016 to February 2017. In order to capture potential changes in the DHS or the controllable buildings, we retrained the experts daily by adding the previous day of the test set to the training set.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>presents a comparison of the MAPEs without retraining (top) and the MAPEs with daily retraining (bottom). The table only shows the results of the experts trained with the complete feature set. It is apparent that the results are almost identical, from this we can conclude that no changes took place in the DHS or buildings during the test set.</figDesc><table /><note><p>Page 21 of 29</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Preprint submitted to Journal of L A T E X TemplatesDecember 18, 2017   </p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Vanhoudt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Claessens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Desmedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Johansson</surname></persName>
		</author>
		<title level="m">International Symposium on District Heating and Cooling</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Status of the horizon 2020 storm project</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review on the prediction of building energy consumption</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Magouls</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.rser.2012.02.049</idno>
		<ptr target="http://dx.doi.org/10.1016/j.rser.2012.02.049.URL//www.sciencedirect.com/science/article/pii/S1364032112001438" />
	</analytic>
	<monogr>
		<title level="j">Renewable and Sustainable Energy Reviews</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3586" to="3592" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A review on the basics of building energy estimation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Fumo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.rser.2013.11.040</idno>
		<ptr target="http://dx.doi.org/10.1016/j.rser.2013.11.040.URL//www.sciencedirect.com/science/article/pii/S1364032113007892" />
	</analytic>
	<monogr>
		<title level="j">Renewable and Sustainable Energy Reviews</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="53" to="60" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical modeling: The two cultures (with comments and a rejoinder by the author)</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">10.1214/ss/1009213726</idno>
		<ptr target="http://dx.doi.org/10.1214/ss/1009213726" />
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="231" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Al-Homoud</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0360-1323(00)00026-3</idno>
		<ptr target="http://dx.doi.org/10.1016/S0360-1323(00)00026-3" />
		<title level="m">Computer-aided building energy analysis techniques, Building and Environment</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="421" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Greek long-term energy consumption prediction using artificial neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ekonomou</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.energy.2009.10.018</idno>
		<ptr target="http://dx.doi.org/10.1016/j.energy.2009.10.018.URL//www.sciencedirect.com/science/article/pii/S0360544209004514" />
	</analytic>
	<monogr>
		<title level="m">{ECOS} 200821st International Conference, on Efficiency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="512" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting electricity energy consumption: A comparison of regression analysis, decision tree and neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Tso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Yau</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.energy.2006.11.010</idno>
		<ptr target="http://dx.doi.org/10.1016/j.energy.2006.11.010" />
	</analytic>
	<monogr>
		<title level="j">Energy</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1761" to="1768" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Integration of artificial neural networks and genetic algorithm to predict electrical energy consumption</title>
		<author>
			<persName><forename type="first">A</forename><surname>Azadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghaderi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tarverdian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saberi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amc.2006.08.093</idno>
		<ptr target="http://dx.doi.org/10.1016/j.amc.2006.08.093.URL//www.sciencedirect.com/science/article/pii/S0096300306011088" />
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1731" to="1741" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Forecasting electrical consumption by integration of neural network, time series and {ANOVA}</title>
		<author>
			<persName><forename type="first">A</forename><surname>Azadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghaderi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sohrabkhani</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amc.2006.08.094</idno>
		<ptr target="http://dx.doi.org/10.1016/j.amc.2006.08.094.URL//www.sciencedirect.com/science/article/pii/S0096300306011106" />
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1753" to="1761" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparison between detailed model simulation and artificial neural network for forecasting building energy consumption</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Neto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A S</forename><surname>Fiorelli</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.enbuild.2008.06.013</idno>
		<ptr target="http://dx.doi.org/10.1016/j.enbuild.2008.06.013.URL//www.sciencedirect.com/science/article/pii/S0378778808001448" />
	</analytic>
	<monogr>
		<title level="j">Energy and Buildings</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2169" to="2176" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Cochocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Unbehauen</surname></persName>
		</author>
		<title level="m">Neural Networks for Optimization and Signal Processing, 1st Edition</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">What is a support vector machine?</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Noble</surname></persName>
		</author>
		<idno type="DOI">10.1038/nbt1206-1565</idno>
		<ptr target="http://dx.doi.org/10.1038/nbt1206-1565" />
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1565" to="1567" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ensembles of extremely randomized trees and some generic applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wehenkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Geurts</surname></persName>
		</author>
		<ptr target="http://www.montefiore.ulg.ac.be/services/stochastic/pubs/2006/WEG06" />
	</analytic>
	<monogr>
		<title level="m">Proc. Robust Methods for Power System State Estimation and Load Forecasting</title>
		<meeting>Robust Methods for Power System State Estimation and Load Forecasting<address><addrLine>RTE, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting future hourly residential electrical consumption: A machine learning case study</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>New</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Parker</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.enbuild.2012.03.010</idno>
		<ptr target="http://dx.doi.org/10.1016/j.enbuild.2012.03.010" />
	</analytic>
	<monogr>
		<title level="j">Energy and Buildings</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="591" to="603" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Applying support vector machine to predict hourly cooling load in the building</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mochida</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.apenergy.2008.11.035</idno>
		<ptr target="http" />
	</analytic>
	<monogr>
		<title level="j">Applied Energy</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2249" to="2256" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.apenergy.2008.11.035</idno>
		<ptr target="//dx.doi.org/10.1016/j.apenergy.2008.11.035" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Backpropagation neural networks for modeling gasoline consumption</title>
		<author>
			<persName><forename type="first">G</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Badr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Joun</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0196-8904(02)00087-0</idno>
		<ptr target="http://dx.doi.org/10.1016/S0196-8904(02)00087-0" />
	</analytic>
	<monogr>
		<title level="j">Energy Conversion and Management</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="893" to="905" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Applying support vector machines to predict building energy consumption in tropical region</title>
		<author>
			<persName><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.enbuild.2004.09.009</idno>
		<ptr target="http://dx.doi.org/10.1016/j.enbuild.2004.09.009" />
	</analytic>
	<monogr>
		<title level="j">Energy and Buildings</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="545" to="553" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting heat demand for a district heating systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wojdyga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Energy and Power Engineering</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="237" to="244" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Forecasting short-term heat load using artificial neural networks: the case of a municipal district heating system</title>
		<author>
			<persName><forename type="first">P</forename><surname>Benalcazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaminski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on the Sustainable Energy and Environmental Development</title>
		<meeting><address><addrLine>Poland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Applied machine learning: Forecasting heat load in district heating system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Idowu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saguna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Scheln</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.enbuild.2016.09.068</idno>
		<ptr target="http://dx.doi.org/10.1016/j.enbuild.2016.09.068.URL//www.sciencedirect.com/science/article/pii/S0378778816310155" />
	</analytic>
	<monogr>
		<title level="j">Energy and Buildings</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="478" to="488" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Strong consistency of least squares estimates in multiple regression ii</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1016/0047-259X(79)90093-9</idno>
		<ptr target="http://dx.doi.org/10.1016/0047-259X(79)90093-9" />
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="361" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="273" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Operational demand forecasting in district heating systems using ensembles of online machine learning algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bergkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Somer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geysen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lavesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vanhoudt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on District Heating and Cooling</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Extreme learning machine: Algorithm, theory and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nie</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10462-013-9405-z</idno>
		<ptr target="http://dx.doi.org/10.1007/s10462-013-9405-z" />
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Rev</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="115" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning probabilistic prediction functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Desantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Markowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th Annu</title>
		<meeting>29th Annu<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<author>
			<persName><surname>Prediction</surname></persName>
		</author>
		<author>
			<persName><surname>Learning</surname></persName>
		</author>
		<author>
			<persName><surname>Games</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Aggregating strategies</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Vovk</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=92571.92672" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Annual Workshop on Computational Learning Theory, COLT &apos;90</title>
		<meeting>the Third Annual Workshop on Computational Learning Theory, COLT &apos;90<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="371" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The weighted majority algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Littlestone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Warmuth</surname></persName>
		</author>
		<idno type="DOI">10.1006/inco.1994.1009</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0890540184710091" />
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="212" to="261" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">How to use expert advice</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Helmbold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<idno type="DOI">10.1145/258128.258179</idno>
		<ptr target="http://doi.acm.org/10.1145/258128.258179" />
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="427" to="485" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Forecasting electricity consumption by aggregating experts; how to design a good set of experts</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gaillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goude</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-18732-7</idno>
		<ptr target="www.springer.com/us/book/9783319187310" />
	</analytic>
	<monogr>
		<title level="m">Modeling and Stochastic Learning for Forecasting in High Dimensions</title>
		<title level="s">Lecture Notes in Statistics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Antoniadis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Brossat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Poggi</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="page" from="95" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tracking the best expert</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herbster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1007424614876</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1007424614876" />
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="178" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A second-order bound with excess losses</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gaillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stoltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Van Erven</surname></persName>
		</author>
		<idno>CoRR abs/1402.2044</idno>
		<ptr target="http://arxiv.org/abs/1402.2044" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Potential-based algorithms in on-line prediction and game theory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1022901500417</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1022901500417" />
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="261" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Forecasting electricity consumption by aggregating specialized experts -a review of the sequential aggregation of specialized experts, with an application to slovakian and french country-wide one-day-ahead (half-)hourly predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Devaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gaillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stoltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="260" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cross-validation methods</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<idno type="DOI">10.1006/jmps.1999.1279</idno>
		<ptr target="http://dx.doi.org/10.1006/jmps.1999.1279.tURLhttp://www.sciencedirect.com/science/article/pii/S0022249699912798" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="132" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Python tutorial</title>
		<author>
			<persName><forename type="first">G</forename><surname>Van Rossum</surname></persName>
		</author>
		<idno>CS-R9526</idno>
	</analytic>
	<monogr>
		<title level="m">Centrum voor Wiskunde en Informatica (CWI)</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName><surname>Keras</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<ptr target="https://www.tensorflow.org/" />
		<title level="m">URL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v15/srivastava14a.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On rectified linear units for speech processing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2013.6638312</idno>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3517" to="3521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Support vector regression</title>
		<author>
			<persName><forename type="first">D</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Patranabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Information Processing Letters and Reviews</title>
		<imprint>
			<biblScope unit="page" from="203" to="224" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Buhmann</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9780511543241</idno>
	</analytic>
	<monogr>
		<title level="m">Radial Basis Functions: Theory and Implementations</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
