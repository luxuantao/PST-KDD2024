<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Equilibrium optimizer: A novel optimization algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Afshin</forename><surname>Faramarzi</surname></persName>
							<email>afaramar@hawk.iit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Civil</orgName>
								<orgName type="institution" key="instit1">Architectural, and Environmental Engineering</orgName>
								<orgName type="institution" key="instit2">Illinois Institute of Technology</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Heidarinejad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Civil</orgName>
								<orgName type="institution" key="instit1">Architectural, and Environmental Engineering</orgName>
								<orgName type="institution" key="instit2">Illinois Institute of Technology</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brent</forename><surname>Stephens</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Civil</orgName>
								<orgName type="institution" key="instit1">Architectural, and Environmental Engineering</orgName>
								<orgName type="institution" key="instit2">Illinois Institute of Technology</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seyedali</forename><surname>Mirjalili</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Torrens University Australia</orgName>
								<address>
									<addrLine>Fortitude Valley</addrLine>
									<postCode>4006</postCode>
									<settlement>Brisbane</settlement>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Equilibrium optimizer: A novel optimization algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C42B3043B6B9DEABA37BA27C792544F9</idno>
					<idno type="DOI">10.1016/j.knosys.2019.105190</idno>
					<note type="submission">Received date : 14 June 2019 Revised date : 28 October 2019 Accepted date : 3 November 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Knowledge-Based Systems Optimization</term>
					<term>Metaheuristic</term>
					<term>Genetic Algorithm</term>
					<term>Particle Swarm Optimization</term>
					<term>Physics-based</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is a PDF file of an article that has undergone enhancements after acceptance, such as the addition of a cover page and metadata, and formatting for readability, but it is not yet the definitive version of record. This version will undergo additional copyediting, typesetting and review before it is published in its final form, but we are providing this version to give early visibility of the article. Please note that, during the production process, errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There are two major categories for mathematical optimization methods: (1) deterministic and (2) stochastic. Linear and non-linear programming <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> are some of the most commonly used deterministic methods, characterized by using the gradient information of the problem to search the space and find the solution. Although these methods are efficient for problems with linear search spaces (unimodal), they are prone to local optima entrapment when applying to problems with non-linear search spaces, including real-world non-convex problems <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. To combat this issue one might start from a different initial design, modify, or hybridize the algorithm <ref type="bibr" target="#b4">[5]</ref>.</p><p>Another alternative to these conventional methods is stochastic methods, which, similar to the meta-heuristic algorithms, generate and use random variables. These algorithms are used to globally search the domain to find the global or near global optimal results. Advantages of metaheuristics include their simplicity, independency to the problem, flexibility, and gradient-free nature <ref type="bibr" target="#b5">[6]</ref>. Common sources of inspiration in the development of meta-heuristics are from physical phenomena, animal behavior, or evolutionary concepts. In addition, meta-heuristics are independent of the nature of the problem, meaning they do not need derivative information of the problem since they use a stochastic approach. This is in contrast to mathematical programming that typically requires detailed knowledge about the mathematical problem <ref type="bibr" target="#b4">[5]</ref>. This independency to the nature of the problem renders them a suitable tool for finding optimal solutions for a given optimization problem without being concerned about the nonlinearity types of the problem's search space and its constraints. Another bonus is their flexibility, which allows them to solve any kind of optimization problem without major changes in the algorithms' structure. They treat the problem as a black box with input and output states, and this feature empowers them as a potential candidate for a user-friendly optimizer. In addition, in contrast to the deterministic nature of mathematical methods, they mostly benefit from stochastic operators. Consequently, the probability of entrapment in local optima is reduced compared to conventional deterministic methods. This characteristic also renders them independent to the initial guess of solutions. Due to their ability to globally explore the search space in a reasonable amount of time as well as independency to the problem's nature, these methods become more popular and received significant attention in recent years. Genetic Algorithms (GA) <ref type="bibr" target="#b6">[7]</ref>, Particle Swarm Optimization (PSO) <ref type="bibr" target="#b7">[8]</ref>, Simulated Annealing (SA) <ref type="bibr" target="#b8">[9]</ref>, and Ant Colony Optimization (ACO) <ref type="bibr" target="#b9">[10]</ref> are among some of the most conventional meta-heuristics approaches. Although each of them belongs to different classes of metaheuristics, many researchers in different areas have evaluated their performance. A common approach to assessing novel optimization algorithms is to demonstrate their competitiveness against conventional methods in solving optimization problems. It is worth mentioning that it is impossible to find an algorithm to reach to the global optimum for all class of problems. If an algorithm is tuned for an elevated performance over one class of problems, it is offset by the performance over another class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Meta-heuristics Algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>There are two important features in meta-heuristic optimization algorithms: (1) exploration and (2) exploitation. Exploration is the ability to globally search the space. This ability is associated with escaping from local optima and preventing local optima stagnation. Conversely, exploitation is the ability to locally search around promising solutions in an effort to increase their quality. Good performance is achieved by a suitable tradeoff between these two features. All population-based algorithms use these features but with different operators and mechanisms.</p><p>Based on the source of inspiration, meta-heuristics are mainly divided into four classes of: (i) evolutionary algorithms, (ii) swarm intelligence, and (iii) physics-based, and (iv) human-based methods. Evolutionary algorithms mimic rules in natural evolution. They use operators inspired by biology, such as cross-over and mutation. The most widely used evolutionary algorithm is GA, which is inspired by Darwinian evolutionary theory. GA uses the cross-over concept to produce improved solutions, called offspring, based on some fitted solutions, defined as parents. Cross-over, which naturally occurs in nature and helps maintain diversity in ecosystems; or in this sense, to explore the domain. Mutations cause the offspring to have characteristics different from their parents. This operator in GA is aimed at local search and exploitation of results. Some solutions and their dimensions experience mutation, defined by a function, and selected by a parameter such as mutation probability and percentage. Differential evolution <ref type="bibr" target="#b10">[11]</ref>, evolutionary programming <ref type="bibr" target="#b11">[12]</ref> and evolution strategy <ref type="bibr" target="#b12">[13]</ref> are other examples of this class.</p><p>Swarm intelligence is another class of meta-heuristics, which imitates the social behavior of animals in groups (i.e., flocks, herds, or schools). The main feature of this class is sharing of collective information of all individuals during the optimization process. The most widely used algorithm in this class is PSO, developed by Kennedy and Eberhart <ref type="bibr" target="#b7">[8]</ref>. PSO simulates the behavior of birds flying together in flocks. PSO considers some candidates (particles) that fly over the search space in an effort to find improved solutions. During the search, they all follow the best solutions in their paths. The particles trace this path by considering their own position of best solutions, known as 'pbest,' along with the best solution obtained so far, called 'gbest.' Other methods of this class include: Ant Colony Optimization <ref type="bibr" target="#b9">[10]</ref>, Cuckoo Search <ref type="bibr" target="#b13">[14]</ref>, Grey Wolf Optimizer <ref type="bibr" target="#b5">[6]</ref>, Salp Swarm Algorithm <ref type="bibr" target="#b14">[15]</ref>, and Dolphin Echolocation <ref type="bibr" target="#b15">[16]</ref>.</p><p>The third class of optimization algorithms are physics-based. These algorithms originate from physical laws in nature, and typically characterize the interaction of search agents according to governing rules rooted in physical processes. One of the most widely used algorithms in this class is Simulated Annealing <ref type="bibr" target="#b8">[9]</ref>, which uses thermodynamics laws applied to heating and then controlled cooling of a material to increase the size of its crystals. Gravitational Search Algorithm <ref type="bibr" target="#b16">[17]</ref> employs Newton's gravitational laws between masses and their interactions to update the position toward the optimum point. Charged System Search <ref type="bibr" target="#b17">[18]</ref> takes advantage of combining rules of physics (Coulomb's law of electrostatics) and mechanics (Newtonian laws of mechanics) to perform the optimization.</p><p>The final class of optimization is human-based algorithm, which is inspired by human interactions and human behavior in societies. For example, Imperialist Competitive Algorithm (ICA) <ref type="bibr" target="#b18">[19]</ref> is based on the human socio-political evolution process. The populations (countries) in ICA are divided into two groups: colonies and imperialists states. The core of this algorithm is J o u r n a l P r e -p r o o f based on the competition among imperialists to take control of the colonies. In the competition, weak empires collapse and there will be only one imperialist that takes possession of all colonies. Another human-based algorithm is the Teaching-Learning-Based Optimization (TLBO), which is inspired by the influence of a teacher on learners <ref type="bibr" target="#b19">[20]</ref>. The population in this method is divided into two parts: the "teacher phase," meaning learning from the teacher, and the "learner phase," meaning learning by interacting with other learners. These phases are consequently iterated to produce better results until convergence is achieved. This paper develops a novel algorithm named Equilibrium Optimizer (EO), inspired by physicsbased dynamic source and sink models used to estimate equilibrium states. EO falls into the third class of optimization algorithms, as it originates from physical laws in nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Equilibrium Optimizer</head><p>This section presents the inspiration, mathematical model, and algorithm of the Equilibrium Optimizer (EO).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Inspiration</head><p>The inspiration for the EO approach is a simple well-mixed dynamic mass balance on a control volume, in which a mass balance equation is used to describe the concentration of a nonreactive constituent in a control volume as a function of its various source and sink mechanisms. The mass balance equation provides the underlying physics for the conservation of mass entering, leaving, and generated in a control volume. A first-order ordinary differential equation expressing the generic mass-balance equation <ref type="bibr" target="#b20">[21]</ref>, in which the change in mass in time is equal to the amount of mass that enters the system plus the amount being generated inside minus the amount that leaves the system, is described as:</p><formula xml:id="formula_0">C is the concentration inside the control volume ( ),</formula><p>is the rate of change of mass in the control volume, is the volumetric flow rate into and out of the control volume, represents the concentration at an equilibrium state in which there is no generation inside the control volume, and is the mass generation rate inside the control volume. When reaches to zero, a steady equilibrium state is reached. A rearrangement of Eq (1) allows to solve for as a function of ; where represents the inverse of the residence time, referred to here as , or the turnover rate (i.e., ). Subsequently, Eq (1) can also be rearranged to solve for the concentration in the control volume (C) as a function of time (t):</p><p>J o u r n a l P r e -p r o o f</p><p>Journal Pre-proof <ref type="bibr">Eq (3)</ref> shows the integration of Eq (2) over time:</p><p>This results in:</p><p>In the Eq (4), F is calculated as follows:</p><p>Where and are the initial start time and concentration, dependent on the integration interval. Eq (4) can be used to either estimate the concentration in the control volume with a known turnover rate or to calculate the average turnover rate using a simple linear regression with a known generation rate and other conditions. EO is designed in this sub-section using the above equations as the overall framework. In EO, a particle is analogous to a solution and a concentration is analogous to a particle's position in the PSO algorithm. As Eq (4) shows, there are three terms presenting the updating rules for a particle, and each particle updates its concentration via three separate terms. The first term is the equilibrium concentration, defined as one of the best-so-far solutions randomly selected from a pool, called the equilibrium pool. The second term is associated with a concentration difference between a particle and the equilibrium state, which acts as a direct search mechanism. This term encourages particles to globally search the domain, acting as explorers. The third term is associated with the generation rate, which mostly plays the role of an exploiter, or solution refiner, particularly with small steps, although it sometimes contributes as an explorer as well. Each term and the way they affect the search pattern is defined in the following. is the initial concentration vector of the i-th particle, and denote the minimum and maximum values for the dimensions, Rand i is a random vector in the interval of [0,1], and n is the number of particles as the population. Particles are evaluated for their fitness function and then are sorted to determine the equilibrium candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Equilibrium pool and candidates</head><p>The equilibrium state is the final convergence state of the algorithm, which is desired to be the global optimum. At the beginning of the optimization process, there is no knowledge about the equilibrium state and only equilibrium candidates are determined to provide a search pattern for the particles. Based on different experiments under different type of case problems, these candidates are the four best-so-far particles identified during the whole optimization process plus another particle, whose concentration is the arithmetic mean of the mentioned four particles. These four candidates help EO to have a better exploration capability, while the average helps in exploitation. The number of candidates is arbitrary and based on type of the optimization problem. One might use other numbers of candidates (e.g. 3 or 5), which is consistent with the literature <ref type="bibr" target="#b5">[6]</ref>. For example, GWO uses three best-so-far candidates (alpha, beta, and gamma wolves) to update the positions of the other wolves. However, using less than four candidates degrades the performance of the method in multimodal and composition functions but will improve the results in unimodal functions. More than four candidates will have the opposite effect. These five particles are nominated as equilibrium candidates and are used to construct a vector called the equilibrium pool: Each particle in each iteration updates its concentration with random selection among candidates chosen with the same probability. For instance, in the first iteration, the first particle updates all of its concentrations based on ; then, in the second iteration, it may update its concentrations based on . Until the end of the optimization process, each particle will experience the updating process with all of the candidate solutions receive approximately the same number of updates for each particle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Exponential term ( )</head><p>The next term contributing to the main concentration updating rule is the exponential term (F). An accurate definition of this term will assist EO in having a reasonable balance between exploration and exploitation. Since the turnover rate can vary with time in a real control volume, is assumed to be a random vector in the interval of [0,1].</p><p>Where time, , is defined as a function of iteration (Iter) and thus decreases with the number of iterations:</p><p>J o u r n a l P r e -p r o o f</p><p>Where and present the current and the maximum number of iterations, respectively, and is a constant value used to manage exploitation ability. In order to guarantee convergence by slowing down the search speed along with improving the exploration and exploitation ability of the algorithm, this study also considers:</p><p>Where is a constant value that controls exploration ability. The higher the , the better the exploration ability and consequently the lower exploitation performance. Similarly, the higher the , the better the exploitation ability and the lower the exploration ability. The third component, , effects on the direction of exploration and exploitation. r is a random vector between 0 and 1. For all of the problems subsequently solved in this paper, and are equal to 2 and 1, respectively. These constants are selected through empirical testing of a subset of test functions. However, these parameters can be tuned for other problems as needed.</p><p>Eq. <ref type="bibr" target="#b10">(11)</ref> shows the revised version of Eq. ( <ref type="formula">8</ref>) with the substitution of Eq. ( <ref type="formula">10</ref>) into Eq. ( <ref type="formula">8</ref>):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Generation rate (G)</head><p>The generation rate is one of the most important terms in the proposed algorithm to provide the exact solution by improving the exploitation phase. In many engineering applications, there are many models that can be used to express the generation rate as a function of time <ref type="bibr" target="#b21">[22]</ref>. For example, one multipurpose model that describes generation rates as a first order exponential decay process is defined as:</p><p>Where G 0 is the initial value and k indicates a decay constant. In order to have a more controlled and systematic search pattern and to limit the number of random variables, this study assumes and uses the previously derived exponential term. Thus, the final set of generation rate equations are as follows:</p><p>Where:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Where and are random numbers in [0,1] and GCP vector is constructed by the repetition of the same value resulted from Eq. <ref type="bibr" target="#b14">(15)</ref>. In this equation, GCP is defined as the Generation rate Control Parameter, which includes the possibility of generation term's contribution to the updating process. The probability of this contribution which specifies how many particles use generation term to update their states is determined by another term called Generation Probability (GP). The mechanism of this contribution is determined by Eqs. ( <ref type="formula">14</ref>) and <ref type="bibr" target="#b14">(15)</ref>. Eq. ( <ref type="formula">15</ref>) occurs at the level of each particle. For example, if GCP is zero, G is equal to zero and all the dimensions of that specific particle are updated without a generation rate term. A good balance between exploration and exploitation is achieved with GP = 0.5. Finally, the updating rule of EO will be as follows:</p><p>Where F is defined in Eq. ( <ref type="formula">11</ref>), and V is considered as unit.</p><p>The first term in Eq. 16 is an equilibrium concentration, where the second and third terms represent the variations in concentration. The second term is responsible for globally searching the space to find an optimum point. This term contributes more to exploration, thereby taking advantage of large variations in concentration (i.e., a direct difference between an equilibrium and a sample particle). As it finds a point, the third term contributes to making the solution more accurate. This term thus contributes more to exploitation and benefits from small variations in concentration, which are governed by the generation rate term (Eq. 13). Depending on parameters such as the concentrations of particles and equilibrium candidates, as well as the turnover rate ( ), the second and third terms might have the same or opposite signs. The same sign makes the variation large, which helps to better search the full domain, and the opposite sign makes the variation small, aiding in local searches.</p><p>Although the second term attempts to find solutions relatively far from equilibrium candidates and the third term attempts to refine the solutions closer to the candidates, this is not always happening. Small turnover rates (e.g., 0.05) in the denominator of the third term increase its variation and helps the exploration in some dimensions as well. Fig ( <ref type="figure">1</ref>) demonstrates a 1-D version of how these terms contribute to exploration and exploitation.</p><p>is representative of the second term in Eq. 16 while represents the third term (G is the function of G 0 ). The generation rate terms (Eqs. 13-15) control these variations. Because changes with each dimension's change, this large variation only happens to those dimensions with small values of . It is worth mentioning that this feature works similar to a mutation operator in evolutionary algorithms and greatly helps EO to exploit the solutions. Fig. <ref type="figure" target="#fig_1">2</ref> shows a conceptual sketch of the collaboration of all equilibrium candidates on a sample particle and how they affect concentration updating, one after another, in the proposed algorithm. Since the topological positions of equilibrium candidates are diverse in initial iterations, and the exponential term generates large random numbers, this step by step updating process helps the particles to cover the entire domain in their search. An opposite scenario happens in the last iterations, when the candidates surround the optimum point by similar configurations. At these times, the exponential term generates small random numbers, which helps in refining the solutions by providing smaller step sizes. This concept can also be extended to higher dimensions as a hyperspace whereby the concentration will be updated with the particle's movement in n-dimensional space.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5.">Particle's memory saving</head><p>Adding memory saving procedures assists each particle in keeping track of its coordinates in the space, which also informs its fitness value. This mechanism resembles the pbest concept in PSO. The fitness value of each particle in the current iteration is compared to that of the previous iteration and will be overwritten if it achieves a better fit. This mechanism aids in exploitation capability but can increase the chance of getting trapped in local minima if the method does not benefit from global exploration ability <ref type="bibr" target="#b22">[23]</ref>. The pseudo code of the proposed EO algorithm along with a memory saving function is presented in Fig 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.6.">Exploration ability of EO</head><p>To summarize these terms, there are several parameters and mechanisms in EO that lead to exploration, as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>: controls the exploration quantity (magnitude) of the algorithm. It determines how far the new position would be to the equilibrium candidate. The higher the value, the higher the exploration ability. Note that numbers greater than three would considerably degrade the exploration performance. Since can magnify the concentration variation, it should be large enough to expand the exploration ability. However, based on empirical testing, it was found that values greater than three push the agents to search on boundaries. This recommendation is similar to the recommendation for free parameters in other algorithms. For example, in PSO, it is recommended that the sum of social and cognitive parameter should be less than or equal to four <ref type="bibr" target="#b23">[24]</ref>.</p><p>J o u r n a l P r e -p r o o f  : controls the exploration direction. Since r is in [0,1] with uniform distribution, there is equal probability of negative and positive signs.  Generation probability (GP): controls the participation probability of concentration updating by the generation rate. GP = 1 means that there will be no generation rate term participating in the optimization process. This state emphasizes high exploration capability, and often leads to non-accurate solutions. GP = 0 means that the generation rate term will always be participating in the process, which increases the stagnation probability in local optima. Based on empirical testing, GP = 0.5 provides a good balance between exploration and exploitation phases.  Equilibrium pool: This vector consists of five particles. The selection of five particles is somewhat arbitrary but was chosen based on empirical testing. In the initial iterations, the candidates are all far away from each other in distance. Updating the concentrations based on these candidates improves the algorithm's ability to globally search the space.</p><p>The average particle also helps to discover unknown search spaces at initial iterations when particles are far away from each other. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assign</head><p>Eq <ref type="bibr" target="#b8">(9)</ref> For i=1: number of particles (n) Randomly choose one candidate from the equilibrium pool (vector) Generate random vectors of , from Eq <ref type="bibr" target="#b10">(11)</ref> Construct Eq <ref type="bibr" target="#b10">(11)</ref> Construct Eq <ref type="bibr" target="#b14">(15)</ref> Construct Eq <ref type="bibr" target="#b13">(14)</ref> Construct Eq <ref type="bibr" target="#b12">(13)</ref> Update concentrations Eq <ref type="bibr" target="#b15">(16)</ref> End (For) Iter=Iter+1 End while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.7.">Exploitation ability of EO</head><p>The main parameters and mechanisms to perform exploitation and local search in EO are as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>: this parameter is similar to , but controls the exploitation feature. It determines the quantity (magnitude) of exploitation by digging around the best solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head></head><p>: controls the exploitation quality (direction) as well. It specifies the direction of a local search.  Memory saving: memory saving, saves a number of best-so-far particles and substitutes them for worse particles. This feature directly improves the EO's ability for exploitation.  Equilibrium pool: by lapse of iteration, exploration fades out and exploitation fades in.</p><p>Thus, in the last iterations, where the equilibrium candidates are close to each other, the concentration updating process will aid in local search around the candidates, leading to exploitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.8.">Computational Complexity analysis</head><p>Computational complexity of an optimization algorithm is presented by a function relating the running time of the algorithm to the input size of problem. For this purpose, Big-O notation is used here as a common terminology. Complexity is dependent upon the number of particles (n), the number of dimensions (d), and the number of iterations , and is the cost of function evaluation.</p><p>) Therefore, the overall computational complexity is defined as:</p><p>As it is shown, the complexity is of the polynomial order. Thus, EO can be considered as an efficient algorithm. The complexity of EO with that of PSO and GA (as two of the most wellknown meta-heuristics) is compared in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results on Benchmark Functions</head><p>This section demonstrates the effectiveness of the proposed algorithm on a set of 58 benchmark test functions, including 29 commonly used unimodal, multimodal, and composition functions, as well as another 29 functions from the CEC-BC-2017 test suite <ref type="bibr" target="#b24">[25]</ref>. This study utilizes both quantitative and qualitative validation metrics. Quantitative metrics include the average and standard deviation values for different test functions and qualitative metrics include trajectory, search, optimization, and average fitness history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mathematical optimization test problems</head><p>Fig ( <ref type="formula">4</ref>) shows a two-dimensional version of the three categories of mathematical functions that this study uses to evaluate EO. The first category includes unimodal functions (F1-F7) that have a single optimum solution, which purposefully challenges the exploitation ability of the J o u r n a l P r e -p r o o f algorithm. The second category includes multi-modal functions (F8-F13) that have more than one optimal solution. Local optimal solutions in these functions evaluate the exploration performance of the algorithm, while an algorithm needs to be able to globally search the space and avoid being trapped in local optima in order to find the global optima. The third category includes fixed-dimensional multi-modal functions (F14-F23), which are similar to multi-modal functions but in low and fixed dimensions. These functions along with their dimensions employed in this study and constant coefficients are available in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>To further challenge the performance of EO, this study uses composite test functions (CF1-CF6) that mimic the complexity of a real search domain by having a large number of local optima and different shapes of the functions in different regions. Also, these functions are composed by shifting, rotating, expanding, and hybridizing unimodal and multimodal functions. Consequently, these functions represent more challenging optimization problems. More details about the composition function can be found in CEC 2005 technical report <ref type="bibr" target="#b25">[26]</ref>.</p><p>For all test categories, EO uses 30 particles along with 500 iterations (15,000 maximum function evaluations). Similarly, to provide a fair comparison, the other methods also use 15,000 maximum function evaluations. For example, GA used 30 populations along with 500 generations. The analogous terminology of this configuration for GWO is stated by 30 search agents associated with 500 iterations. In LSHADE-SPACMA, we used 18D (D is dimension) number of initial populations, but since the population linearly decreases over the iteration, we used 15,000 maximum function evaluations for a fair comparison. Table <ref type="table" target="#tab_1">1</ref> shows the setting of parameters for each algorithm.  The comparative methods for this section include three categories of optimization methods: i) Genetic Algorithm (GA) <ref type="bibr" target="#b6">[7]</ref> and Particle Swarm Optimization (PSO) <ref type="bibr" target="#b7">[8]</ref> as the most well-known and well-studied evolutionary and swarm intelligence algorithms; ii) Gravitational Search Algorithm (GSA) <ref type="bibr" target="#b16">[17]</ref>, Grey Wolf Optimizer (GWO) <ref type="bibr" target="#b5">[6]</ref>, and Salp Swarm Algorithm (SSA) <ref type="bibr" target="#b14">[15]</ref> as recent and effective meta-heuristics; and iii) Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) <ref type="bibr" target="#b12">[13]</ref>, Success-History Based Parameter Adaptation Differential Evolution (SHADE) (one of the CEC 2013 competitors) <ref type="bibr" target="#b26">[27]</ref>, and SHADE with linear population size reduction hybridized with semi-parameter adaptation of CMA-ES (LSHADE-SPACMA) (one of the CEC 2017 winners) as high performance optimizers. It is noted that the comparison for all algorithms is done with equal floating-point precision, so the difference between results are due to the performance of the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">EO's performance on unimodal test functions</head><p>Unimodal functions are designed to test the exploitation ability of a method. From the results on unimodal functions in Table <ref type="table" target="#tab_2">2</ref> (F1-F7), it is evident that EO outperformed almost all methods on the majority of functions. As it is seen, EO was able to achieve the first rank in unimodal test functions. This superior performance is also seen on both average and standard deviation in functions of F1, F2, F3, F4, and F7. In F5, EO received the second rank after SHADE with only a slight difference in the average outcome. For the other function (F6), the results of EO were competitive to the other methods. Based on the characteristics of unimodal functions, it can be stated that EO benefits from high exploitation ability.</p><p>J o u r n a l P r e -p r o o f </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">EO's performance on composition functions</head><p>Composite test cases are the most challenging test beds. These functions are designed to evaluate local minima avoidance performance as well as the exploration ability of a method. Table <ref type="table" target="#tab_2">2</ref> (F24-F29) shows the performance of EO on composition functions compared to other methods. Overall, LSHADE-SPACMA showed better performance compared to other methods and ranked first in this category. In most functions, EO ranked fourth among these methods after LSHADE-SPACMA, SHADE, and SSA which are among the high-performance and recent optimizers.</p><p>Although EO gained the fourth rank in this class, its results are competitive to SHADE and SSA in most functions. Since this class of functions are associated with too many local minima, in order to have a better understanding of distribution of results, the boxplot of results for each algorithm and function are shown in Figure <ref type="figure" target="#fig_3">5</ref>. As an example, the local minima stagnation in all algorithms is evident in CF6 of Figure <ref type="figure" target="#fig_3">5</ref>. Based on its boxplot, the results are clustered in two groups around 500 and 900. This is due to the complex topology of this function which makes the algorithms get stuck in local minima. This behavior is more or less observable in CF4 as well.</p><p>To summarize, based on the results of Tables 2, EO showed excellent performance, on unimodal and multimodal functions and very good performance in fixed-dimensional multimodal functions among the other methods compared. The performance of EO in the composition class of functions was lower compared to previous classes. However, it is important to note that SHADE and LSHADE-SPACMA utilize a complex strategy and they are among the strongest competitors and winners of CEC 2013 and 2017, respectively. Based on the Friedman mean rank and overall rank, EO placed as the best performing method (ranked first) among methods considering all types of functions. The mean rank shows that the performance of SHADE and LSHADE-SPACMA is close to EO while performance of these three algorithms is by far better than all other algorithms. EO's overall satisfying performance in this challenging class of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>functions is attributable to the intermittent contribution of the generation rate term for concentration updating. Therefore, the results of this testing indicate that EO is a powerful and robust optimizer designed to conduct well-tuned exploration and exploitation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Sensitivity analysis of EO's parameters</head><p>This section analyzes the sensitivity of three control parameters of EO, which are , and . This analysis indicates which parameters are robust and which parameters are sensitive to different inputs, and which parameters affect the performance of the algorithm. During the development of EO, this study performed a full factorial design with these parameters on one function from each category of unimodal, multimodal, and fixed-dimensional multimodal functions. The first function was picked from each category (i.e., F1, F8, and F14). The values of each parameter for the factorial design are defined as , . Since each of the 3 parameters have 5 values, the full factorial will have 5*5*5=125 combinations of design. Each design is the fitness average of functions with maximum of 15,000 function evaluations and 30 independent runs. Figure <ref type="figure">6</ref> shows this sensitivity analysis for the 3 different functions. The x-axis shows the three control parameters and their associated values while the y-axis shows the average fitness for the functions. In F1 (Fig. <ref type="figure">6a</ref>),</p><p>shows sensitivity to its left boundary while and GP have the similar sensitivity to their right boundary, but all parameters showing robust behavior for their three middle values. In F8 (Fig. <ref type="figure">6b</ref>), shows a sensitive behavior to all values and having the best performance on its middle value ( while other parameters of and GP acted robust on their different range. As showed in F1, the sensitivity is the lowest in their middle range. In F14 (Fig. <ref type="figure">6c</ref>), showed a high sensitivity in its left boundary while showing steady behavior for its right boundary. and GP showed robust behavior for different values. The overall</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head><p>Journal Pre-proof behavior indicates that is more sensitive than and GP. Based on this analysis, the best value for can be suggested as its middle value (i.e., ). For and GP, which are more robust than , any values other than their left and right boundaries can be selected. Being more conservative, the middle values are selected for these parameters (i.e., and ) since the neighboring (left and right) boundaries to the middle value shows less sensitivity compared to other selections. This experiment also suggests that the design of EO accounted for the best value of EO's control parameters in previous sections.  <ref type="figure">7</ref> illustrates the five qualitative metrics used to evaluate efficiency and effectiveness of EO when solving real problems: trajectory, search, optimization, and average fitness history. These metrics are evaluated by solving mathematical functions with an intentionally reduced number of particles/iterations (10/100) to show a clear pattern of search and how particles in EO contribute to finding optimum points. The dimension of the problems did not change and remained intact. Although these functions have high dimensions, the presented 2D views of the functions in Fig. <ref type="figure">7</ref> provide insights on the domain's topology. The first qualitative metric discussed here is the search history, which includes the concentration (position) of particles from the first iteration to the last iteration. The concentration is shown on the counter lines of the search space for better understanding of how particles are able to explore and exploit the domain. Search history can also reveal the pattern that the particles used to search the space. The search history results show that the particles tend to aggregate around the optimum point in unimodal functions more effectively than in multimodal and composite functions. This behavior of EO demonstrates its exploitation ability, while the appropriate scattering of particles in the search space of multimodal and composition functions shows the promising capability of EO's exploration methods.</p><p>The second metric employed here is the optimization history (convergence curve). This metric is the fitness of the best-so-far particle (</p><p>) from the first to the last iteration. It shows how the global optimum is approximated by the algorithm with the lapse of iteration. There are various behaviors of optimization history for different types of functions. For unimodal functions, the curve is relatively smooth; for multimodal functions with high numbers of local optima, the behavior changes from smooth to step-like manner. This means that the algorithm has no improvement on that specified course of iterations due to the complexity of the domain, which can be seen in F8, F14, and CF2.</p><p>Although the history shows how the global optimum is estimated by exploration and exploitation, it does not provide insight on the total behavior of particles participating in the optimization process to improve the result. This trend is shown by the average fitness history in the fourth column of Fig. <ref type="figure">7</ref>. The descending trend of all history curves shows that all the particles are collaborating to improve the results by updating their concentrations to better ones as the iteration number increases. The stability of the curves is due to the memory saving process, which does not allow particles to move toward the regions with lower fitness. Omitting the memory saving feature will lead to fluctuating behavior of average fitness curves. For all of the test functions there is a close similarity between the average fitness and optimization history curves. This similarity reveals a search pattern that all the particles are following, a pattern which emphasizes collaborative searching rules rather than independent acting, led by equilibrium candidates.</p><p>Another qualitative metric is the trajectory of particles, shown in column 5 of Fig. <ref type="figure">7</ref>, which shows the variation of concentration (position) in the first dimension of the first particle. In all of the test functions, there is a sudden and abrupt oscillation in the first iterations, followed by a fade out in the last iterations. These sudden changes demonstrate exploration behavior by J o u r n a l P r e -p r o o f globally searching the domain at the initial iterations, while subsequently stabilizing by local searching as the iteration number increases. According to Berg et al. <ref type="bibr" target="#b27">[28]</ref>, this trend can guarantee that an algorithm will finally converge to a global/local optimum point. Following the trajectory curves, one can notice that the fluctuations are related to the domain complexity. The more complex the domain, the more fluctuations occur. In unimodal functions, there are no fluctuations after a number of iterations. In multimodal functions, fluctuations are greater in magnitude and frequency and persist for greater numbers of iterations. This behavior demonstrates that EO benefits from well-tuned exploitation and exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8. Diversity history for unimodal, multimodal and composition functions</head><p>Although there are some direct and explicit methods such as ancestry tree-based approach <ref type="bibr" target="#b28">[29]</ref> for measuring exploration and exploitation, most researcher use indirect approaches such as diversity to measure these features <ref type="bibr" target="#b29">[30]</ref>. From exploration-exploitation viewpoint, an increase in diversity means that solutions are very different, which indicates that an algorithm is in exploration phase, while a decrease means solutions are within a certain neighborhood, thus showing exploitation behavior <ref type="bibr" target="#b29">[30]</ref>. In order to depict a balanced exploration and exploitation in EO, the diversity histories are presented as the final qualitative metric in Fig 7 . The horizontal axis shows the number of iterations and the vertical axis indicates the average distance between particles (defined as the difference between concentrations). There is a decreasing distance trend J o u r n a l P r e -p r o o f in all curves in <ref type="bibr">Fig 8,</ref><ref type="bibr"></ref> again demonstrating a transient shift from exploration in initial iterations to exploitation in the final iterations. In unimodal functions (F1, F2, F3), this shift occurred very rapidly since EO is able to recognize the global optimum and tries to exploit it further. In multimodal and composite functions, EO showed an oscillating behavior but still kept the overall trend. This behavior is due to a large number of extrema in these functions. This metric can be used as further evidence for a well-defined balance between exploration-exploitation of the proposed EO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Comparative convergence analysis</head><p>The previous section analyzed the convergence behavior of EO using defined qualitative metrics. This section compares the convergence behavior of other methods along with the EO algorithm. In order to have a concise and efficient comparison between algorithms, this study picked the best performing algorithm in each method category, including PSO in the category of most wellstudied algorithms, GWO in the recent methods category, and SHADE in the high-performance optimizers category. This selection is based on the lowest obtained mean ranked among all 29 functions. For the functions, the first function of each category was used: F1 from unimodal, F8 from multimodal, F1 from fix dimensional, and CF1 from composition functions. Figs 9 and 10 show qualitative metrics for the mentioned methods and functions. Since trajectory and diversity have fluctuating behaviors, they are depicted in a separate figure for each algorithm for easy following of the readers.</p><p>In F1, which is a unimodal function, EO and GWO were more successful than PSO and SHADE in recognizing the optimum point and reached better results with fewer iterations. The trajectory and diversity of EO and GWO are similar to each other and have more stable behavior than PSO and SHADE. In the multimodal function (F8), although SHADE has better results than other methods, as shown in the optimization history, the average fitness history of EO has better performance than other methods. It is due to the memory saving feature of EO, which does not allow particles to move toward less fitted regions. The trajectory and diversity of EO and SHADE in this function has more aggressive behavior than PSO and GWO, meaning that they were more successful in exploring the domain. Based on the optimization history of F14 depicted in Fig <ref type="figure">10,</ref><ref type="figure"></ref> EO and SHADE estimated the optimum point in fewer iterations compared to PSO and GWO. One can notice a sudden decrease of fitness for algorithms in the last iterations shown in average fitness history. This decrease is due to the deep and narrow optimum points shaping the topology of F14, which is observable in Fig 7 . In the last iterations where algorithms try to search the neighborhood, gathering the search agents in these regions considerably improve the fitness of search agents.</p><p>Finally, for CF1, the optimization and average fitness history show that EO and SHADE performed better than PSO and GWO. The high magnitude and frequency of oscillation in trajectories of EO and SHADE also demonstrate key differences. The diversity plot of PSO and GWO in this function fades out more rapidly than EO and SHADE. Overall, based on behavioral analysis of Figs 8-10, SHADE has the best exploration ability among the compared methods. However, some diversity plots of SHADE show that it cannot show low diversity in last iterations compared to other methods, which is why SHADE does not perform well in unimodal J o u r n a l P r e -p r o o f functions. Among the compared methods, PSO has the lowest exploration ability, showing fewer fluctuations in trajectory and damping sooner in diversity compared to the other methods. The analyses also indicate that EO showed more balanced behavior, having high fluctuations in initial iterations and low fluctuations in the last iterations in trajectory, and a well-balanced transient from high diversity to low diversity during the course of iterations. While the EO's exploration ability is not comparable to SHADE, the SHADE's exploitation ability is not as good as EO. However, EO's combined exploration and exploitation ability is better than GWO and PSO. The more detailed comparative behavioral analysis with all methods and functions can be considered as independent study. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Scalability analysis of EO</head><p>This section evaluates the performance of the EO algorithm for low-and high-dimensional problems using a scalability analysis. Since real-world optimization problems often involve a large number of variables, the algorithm starts from 10 to 200 dimensions with a step size of 10. To further challenge the performance and demonstrate the efficiency of the proposed algorithm, the test is carried out with a fixed number of iterations (500) and particles <ref type="bibr" target="#b29">(30)</ref> as the dimension increases. This test shows how efficiently the algorithm will perform proportional to the dimension increase, while the number of iterations and particles both remain fixed.</p><p>The test is conducted on two samples of unimodal and multimodal functions to assess the exploration and exploitation ability. The results are compared with those of most well-known algorithms like GA, PSO and GWO as well. Fig. <ref type="figure" target="#fig_6">11</ref> shows the results for two unimodal (F1, F7) and multimodal (F8, F9) functions in logarithmic scale. Clearly, the performance of EO is reduced as the dimension increases. Since the iteration and particles are fixed, this trend is expected. In F1, all algorithms reach close to a steady state as the dimension increases. This shows that the performance of all algorithms is not substantially reduced when dealing with large numbers of variables, while EO has the best trend compared to the others. In another unimodal function, F7, EO performance is similar to GWO at low dimensions, while EO outperforms GWO at higher dimensions (and both are better than PSO and GA). In F8, a multimodal function, EO outperformed GWO and PSO, but had slightly worse performance than GA in low dimensions yet surpassed GA by dimension 50. Since this function has a negative global optimum and the magnitude of the optimum point increases linearly with dimension ( J o u r n a l P r e -p r o o f , the steady behavior with increased dimensionality is not desired here. In other words, as the dimension increases, the expectation is to observe a decrease in fitness with linear behavior. Although all of the tested algorithms in this case have a similar overall behavior, EO again showed a better performance than the others. In the last function, F9, EO demonstrates a very interesting behavior. In all dimensions, EO was able to reach the global optimum point (zero) with perfect performance (and thus it is not shown in Fig. <ref type="figure" target="#fig_6">11</ref>). The scalability test of EO for some samples of unimodal and multimodal functions boast its robustness in exploitation and exploration.</p><p>To summarize these comparisons, the convergence and scalability analysis along with the prior results comparison demonstrates EO as a potential candidate to face and solve mathematical optimization problems. The convergence analysis shows the capability of EO in finding optimum results from a completely random set of solutions, while the scalability analysis demonstrates its robustness with a reliable behavior in finding promising solutions toward the global optimum, even in very high dimensional problems. In order to further challenge the EO algorithm, a more recent and challenging test suite, CEC-BC-2017, which includes shifted and rotated unimodal, multimodal, hybrid, and composition functions <ref type="bibr" target="#b30">[31]</ref>, was employed. It is also worth noting that due to unstable behavior, the f2 function has been removed from this test suite <ref type="bibr" target="#b31">[32]</ref>. The search domain for all functions are [-100,100] considering 10 dimensions. EO's performance was tested against this test suite and the results are compared with the same metaheuristics algorithms used previously. The majority of functions presented in this test suite are among more challenging hybrid and compostion functions. The results for all algorithms are provided based on 50 search agents (populations) along with 1000 iterations associated with 30 independent runs. The parameter setting for each method was the same as mentioned in Table <ref type="table" target="#tab_1">1</ref>. Table <ref type="table" target="#tab_3">3</ref> shows the optimization results of different methods in this test suite.</p><p>The overall rank that was achieved by EO in this test bed was third, following LSHADE-SPACMA and SHADE. This achievement is another demonstration of EO's ability to outperfom well-studied and recent optimizers while also having very competitive results with high performance methods in standard functions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10.">Statistical analysis of EO</head><p>This section performed multiple statistical analysis tests to first understand if the differences in performance of all algorithms in the benchmark functions are statistically significant using the non-parametric Friedman test. In order to have a reliable comparison, there is a need to compare more than 10 benchmark functions with more than 5 different algorithms <ref type="bibr" target="#b32">[33]</ref>. In terms of the number of algorithms, this study has already considered 9 algorithms. Regarding benchmark functions, this study totally tested 3 groups. The first group consists of unimodal, multimodal, fixed-dimensional, and composition functions with 29 functions. The second group is the CEC-2017 test functions, including 29 functions. Finally, the third group which is the combination of first and second groups include 58 functions. The Friedman statistic requires calculating the mean ranked value. Then, a comparison is needed to review the critical values obtained for the considered significance level with Friedman statistics to see whether the null hypothesis is rejected or not. The formula and explanations can be found in <ref type="bibr" target="#b33">[34]</ref> and the critical values are available in appendix B of <ref type="bibr" target="#b34">[35]</ref>. For all three groups of benchmarks, the null hypothesis was rejected, showing that there is a significant difference among the performance of the methods in each group.</p><p>Further steps are needed to see which algorithms' performance are significantly different than EO and which ones are similar. To this end, we run a post hoc statistical analysis of Bonferroni-Dunn <ref type="bibr" target="#b34">[35]</ref>, which demonstrates that the performance of two algorithms are significantly different if the difference in average ranking of methods is larger than the critical distance (CD) <ref type="bibr" target="#b33">[34]</ref>. Since this study plans to compare the performance of EO with respect to the other algorithms, the control algorithm is chosen to be EO. Fig <ref type="figure" target="#fig_7">12</ref> shows the average rank of all algorithms in the 3 function groups. In this figure, the horizontal line represents the threshold for the control algorithm (EO). The control algorithm (EO) is able to outperform those algorithms for which J o u r n a l P r e -p r o o f their average rank is above the threshold line (i.e., the height of the bars exceeds its corresponding line). For two prevalent significance levels of 0.1 and 0.05, two thresholds are defined and depicted in this figure with dotted and dashed lines, respectively. The threshold line of each group is identified by its color (Group 1 is red, Group 2 is blue, and Group 3 is green). In Group 1, EO outperformed all algorithms, with the lowest average rank of 2.86, and performance was significantly better than PSO, GWO, GA, GSA, SSA, and CMA-ES at both significance levels. In Group 2, EO ranked third after LSHADE-SPACMA and SHADE, and EO significantly outperformed GWO, GA and GSA, SSA, and CMA-ES at both levels of significance. Finally, in Group 3, which compares the performance of each method in all benchmark functions, EO placed third with an average rank of 3.41 and significantly outperformed PSO, GWO, GA, GSA, SSA, and CMA-ES.</p><p>One of the weaknesses of Bonferroni-Dunn test is that it is not able to distinguish significant differences of those algorithms that are below the critical line and/or those for which their ranks are close to threshold line (e.g., CMA-ES in Group 2 for</p><p>). Thus, this study also considered another statistical procedure of Holm's <ref type="bibr" target="#b35">[36]</ref> to detect which algorithms are better/worse than EO and at which level of significance. Holm's method is a simple and widely applicable multiple test procedure based on the sequential rejective manner. It sorts all algorithms based on their p value and compares them with , where is the significance level, is the degree of freedom, and is the algorithm number. The method starts with the most significant p value and sequentially rejects null hypothesis as long as . As soon as the method cannot reject the hypothesis, it stops and considers all the remaining hypotheses as accepted. The results for Group 1, shown in Table <ref type="table" target="#tab_4">4</ref>, show that EO significantly outperformed all the algorithms at both significance levels except for SHADE and LSHADE-SPACMA (in other words, the performance of EO, SHADE, and LSHADE-SPACMA are statistically similar to each other in this group). This conclusion is in agreement with previous applications of the Bonferoni-Dunn's test. The results for Group 2, shown in Table <ref type="table" target="#tab_5">5</ref>, show that EO's performance is significantly different from all algorithms except PSO and that it is significantly better than GSA, GA, GWO, SSA, and CMA-ES at both levels and worse than LSHADE-SPACMA and SHADE at both levels. Finally, in Group 3, shown in Table <ref type="table" target="#tab_6">6</ref>, EO's performance is significantly better than all algorithms at both levels except for SHADE and LSHADE-SPACMA, for which their performance is again similar. As the main conclusion drawn from all functions' statistical analysis in this study, overall, EO performs significantly better than PSO, GWO, GA, GSA, SSA, CMA-ES and performs similar to SHADE and LSHADE-SPACMA.   J o u r n a l P r e -p r o o f</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J o u r n a l P r e -p r o o f</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Engineering Optimization Test Problems</head><p>This section tests the EO algorithm on three well-known engineering design problems. A simple constraint handling method, static penalty, is applied here to penalize the objective function with a large value if any constraints at any level are violated from its defined bounds. The penalty coefficient should be large enough to properly penalize the objective function in equality/inequality constraints. It is noted that all the engineering test problems are conducted using the same number of iterations (500) and particles (30) as the mathematical functions described previously. All figures and equations of engineering problems are available in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Pressure vessel design</head><p>This problem is one of the most well-known benchmark design tests with a mixed type of variables (continuous/discrete). A cylindrical pressure vessel capped at both ends with hemispherical heads should work under the pressure of 3,000 psi (2.110 7 Pa) and a minimum volume of 750 ft 3 (21.24 m 3 ) according to the ASME boiler code requirement. The total cost of welding, material, and forming define an objective function to be minimized. Variables include the thickness of the shell (T s ), thickness of the head (T h ), the inner radius (R), and the length of the cylindrical section of the vessel (L). Both thickness variables (T s , T h ) must be integer multiple values of 0.0625 inch, which is the available thickness of rolled steel plates.</p><p>Table <ref type="table" target="#tab_7">7</ref> shows the optimum results obtained by EO and other methods in the literature. Since some researchers considered this case as a continuous problem, the results are presented for EO in both mixed variable and continuous forms and compared only to mixed variable solutions. As Tables <ref type="table" target="#tab_7">7</ref> and<ref type="table" target="#tab_8">8</ref> indicate, EO outperformed other methods. The statistical results are presented in Table <ref type="table" target="#tab_8">8</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Tension/compression spring design</head><p>Another well-known benchmark problem is the design of a tension/compression spring with the objective of weight minimization subject to constraints on minimum deflection, shear stress, surge frequency, and some box constraints. The design variables include wire diameter , mean coil diameter and number of active coils .</p><p>Meta-heuristic algorithms <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54]</ref> have been used to solve this problem. Tables <ref type="table" target="#tab_11">11</ref> and<ref type="table" target="#tab_12">12</ref> present the optimum and statistical summary results. EO obtained better results compared to J o u r n a l P r e -p r o o f</p><p>Journal Pre-proof the other algorithms except T-cell, which accomplished the problem in 36,000 function evaluations, which is roughly 2.4 times computationally more expensive than EO with 15,000 function evaluations. The statistical results show that even with a smaller number of function evaluations, EO had very competitive statistical results compared to the other algorithms such as PSO, GA, and DE. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper proposed a novel physics-based optimization algorithm called Equilibrium Optimizer (EO) which was inspired by a generic mass balance equation for a control volume. The design of the EO algorithm includes high exploratory and exploitative search mechanisms to randomly change solutions. Particles with their concentrations are considered as search agents, equivalent to particles and positions in Particle Swarm Optimization (PSO). Concentrations are randomly updated with respect to fit solutions called equilibrium candidates. This random updating along with a properly defined Generation rate term improves EO's exploratory behavior in initial iterations and exploitative search in the final iterations, aiding in local minima avoidance throughout the whole optimization process. Balancing exploration and exploitation provide adaptive values for the controlling parameter and reduces the magnitude of movement for the particles. The efficiency and effectiveness of EO using quantitative and qualitative metrics were validated by testing it on a total of 58 mathematical benchmark functions along with three engineering problems. Comparisons with several well-studied, recent, and high-performance optimization algorithms showed a high effectiveness of the proposed EO algorithm in obtaining optimal or near-optimal solutions with typically higher efficiency (i.e., less computational time or fewer iterations) for the majority of problems investigated. Future studies should work toward developing binary and multi-objective versions of the EO algorithm to further improve performance.</p><p>J o u r n a l P r e -p r o o f</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1. 1-D presentation of concentrations updating aid in exploration and exploitation J o u r n a l P r e -p r o o f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Equilibrium candidates' collaboration in updating a particles' concentration in 2D dimensions</figDesc><graphic coords="11,167.20,121.89,284.13,253.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. A two-dimensional perspective view for couple of the mathematical benchmark functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Boxplot of composition functions results for different algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Figure 7. Qualitative metrics: search history, optimization history, average fitness history and trajectory in 1st dimension</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>F1F8JFigure 9 .Figure 10 .</head><label>910</label><figDesc>Figure 9. Comparative qualitative metrics for F1 and F8F14</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Robustness comparison of different algorithms in low, high and very high dimensional test cases4.9. EO's performance on CEC-BC-2017 test functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Bonferroni-Dunn test for different algorithms and benchmark groups with</figDesc><graphic coords="31,72.61,121.89,469.12,278.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table><row><cell>parameter settings for algorithms Algorithm Parameter PSO Topology Cognitive and social constant (C 1 , C 2 ) Inertia weight Velocity limit GWO Convergence parameter (a) GA Type Selection Crossover Mutation GSA Alpha, G 0 , Rnorm, Rpower SSA Leader position update probability SHADE Pbest, Arc rate LSHADE-SPACMA Learning rate (c), threshold NP, H, Pbest, Arc rate, Probability variable (Fcp) J o u r n a l P r e -p r o o f Value Fully connected 2, 2 Linear reduction from 0.9 to 0.1 10% of dimension range Linear reduction from 2 to 0 Real coded Roulette wheel (Proportionate) Whole Arithmetic (Probability=0.8, α= [-0.5,1.5]) Gaussian (Probability=0.05) 20, 100, 2, 1 0.5 0.1, 2 0.8, max_nfes/2 18D, 5, 0.11, 1.4, (D=dimension size) 0.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Optimization results and comparison for functionsMultimodal functions can evaluate the exploration ability of an algorithm because of their high number of local optima. The number of locally optimal solutions in these types of functions exponentially increases in proportion to the number of dimensions. The results of EO on multimodal functions are given in Table2for high dimensional (F8-F13) and for fixed dimensional functions (F14-F23). The table shows that EO outperformed other methods on F9, F10, and F11 high dimensional problems. It is worth noting that on F9 and F11, EO was able to obtain the global optimum while most other methods did not. For F8, which is the most difficult function in this class, EO obtained the second rank after SHADE, which reached almost to the global optimum. For F12 and F13, CMA-ES showed better performance than other methods, while still EO showed competitive results especially for F12. It is important to note that in these functions, EO achieved the second-best performance after CMA-ES and actually ranked first in this class overall. In fixed dimensional problems, the performance of all methods was similar, and the results for EO are very competitive with the others. In functions F14, F16, F17, F18, and F19 in this class, EO reached the global optimum. For the remaining functions, EO's results were very close to the global optimum.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Journal Pre-proof</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Function</cell><cell></cell><cell>EO</cell><cell>PSO</cell><cell>GWO</cell><cell>GA</cell><cell>GSA</cell><cell>SSA</cell><cell>CMA-ES</cell><cell>SHADE</cell><cell>LSHADE-SPACMA</cell></row><row><cell></cell><cell></cell><cell>F1</cell><cell cols="4">Ave 3.32E-40 9.59E-06 6.59E-28</cell><cell>0.55492</cell><cell cols="4">2.53E-16 1.58E-07 1.42E-18 1.42E-09</cell><cell>0.2237</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Std</cell><cell cols="3">6.78E-40 3.35E-05 1.58E-28</cell><cell>1.23010</cell><cell cols="4">9.67E-17 1.71E-07 3.13E-18 3.09E-09</cell><cell>0.1480</cell></row><row><cell></cell><cell></cell><cell>F2</cell><cell cols="2">Ave 7.12E-23</cell><cell>0.02560</cell><cell>7.18E-17</cell><cell>0.00566</cell><cell>0.05565</cell><cell>2.66293</cell><cell>2.98E-07</cell><cell>0.0087</cell><cell>21.1133</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Std</cell><cell>6.36E-23</cell><cell>0.04595</cell><cell>7.28E-17</cell><cell>0.01443</cell><cell>0.19404</cell><cell>1.66802</cell><cell>1.7889</cell><cell>0.0213</cell><cell>9.5781</cell></row><row><cell>Unimodal Multimodal (High Multimodal (Fixed-dimensional) Composition</cell><cell>dimensional)</cell><cell cols="10">F3 F4 F5 F6 F7 F8 F9 F10 F11 F12 F13 F14 F15 F16 F17 F18 F19 F20 F21 F22 F23 F24 (CF1) F25 (CF2) F26 (CF3) F27 (CF4) F28 (CF5) F29 J o u r n a l P r e -p r o o f Ave 8.06E-09 82.2687 3.29E-06 846.344 896.534 1709.94 1.59E-05 Std 1.60E-08 97.2105 1.61E-05 161.499 318.955 11242.3 2.21E-05 Ave 5.39E-10 4.26128 5.61E-07 4.55538 7.35487 11.6741 2.01E-06 Std 1.38E-09 0.67730 1.04E-06 0.59153 1.74145 4.1792 1.25e-06 Ave 25.32331 92.4310 26.81258 268.248 67.5430 296.125 36.7946 Std 0.169578 74.4794 0.793246 337.693 62.2253 508.863 33.4614 Ave 8.29E-06 8.89E-06 0.816579 0.56250 2.5E-16 1.80E-07 6.83E-19 5.31E-10 15.4352 9.9489 0.9796 0.7995 24.4743 11.2080 Std 5.02E-06 9.91E-06 0.482126 1.71977 1.74E-16 3.00E-07 6.71E-19 6.35E-10 Ave 0.001171 0.02724 0.002213 0.04293 0.08944 0.1757 0.0275 0.0235 Std 6.54E-04 0.00804 0.001996 0.00594 0.04339 0.0629 0.0079 0.0088 Ave -9016.34 -6075.85 -6123.1 -10546.1 -2821.1 -7455.8 -7007.1 -11713.1 Std 595.1113 754.632 909.865 353.158 493.037 772.811 773.94 230.49 Ave 0 52.8322 0.31052 30.8229 25.9684 58.3708 25.338 8.5332 Std 0 16.7068 0.35214 7.57295 7.47006 20.016 8.5539 2.1959 Ave 8.34E-14 0.00501 1.06E-13 1.63551 0.06208 2.6796 15.587 0.3957 Std 2.53E-14 0.01257 2.24E-13 0.46224 0.23628 0.8275 7.9273 0.5868 Ave 0 0.02381 0.00448 0.56112 27.7015 0.0160 5.76E-15 0.0048 Std 0 0.02870 0.00665 0.26942 5.04034 0.0112 6.18E-15 0.0077 Ave 7.97E-07 0.02764 0.05343 0.03088 1.79961 6.9915 2.87E-16 0.0346 Std 7.69E-07 0.05399 0.02073 0.04092 0.95114 4.4175 5.64E-16 0.0875 Ave 0.029295 0.00732 0.65446 0.36222 8.89908 15.8757 3.66E-04 7.32E-04 Std 0.035271 0.01050 0.00447 0.30975 7.12624 16.1462 0.0020 0.0028 Ave 0.998004 3.84902 4.042493 0.998004 5.859838 1.1965 10.237 0.998004 Std 1.54E-16 3.24864 4.252799 4.23E-12 3.831299 0.5467 7.5445 5.83E-17 Ave 0.002398 0.002434 0.00337 0.005206 0.003673 0.000886 0.0057 0.002374 Std 0.006097 0.006081 0.00625 0.007028 0.001647 0.000257 0.0121 0.0061 Ave -1.03162 -1.03162 -1.03163 -1.03162 -1.03163 -1.03163 -1.03162 -1.03162 Std 6.04E-16 6.51E-16 2.13E-08 1.34E-06 4.88E-16 6.13E-14 6.77E-16 6.51E-16 Ave 0.397887 0.397887 0.397889 0.397890 0.397887 0.397887 0.397887 0.397887 Std 0 0 2.13E-04 1.08E-05 0 3.41E-14 0 3.24E-16 Ave 3 3 3.000028 3.000002 3 3 8.4000 3 Std 1.56E-15 1.97E-15 4.24E-04 4.06E-06 4.17E-15 2.20E-13 20.550 1.87E-15 Ave -3.86278 -3.86278 -3.86263 -3.86278 -3.86278 -3.86278 -3.86278 -3.86278 Std 2.59E-15 2.65E-15 0.00273 1.63E-07 2.29E-15 1.47E-10 2.7E-15 2.69E-15 Ave -3.2687 -3.26651 -3.28654 -3.27443 -3.31778 -3.2304 -3.2903 -3.27047 Std 0.05701 0.06032 0.10556 0.05924 0.023081 0.0616 0.0535 0.0599 Ave -8.55481 -5.9092 -8.7214 -5.72536 -5.95512 -9.6334 -5.6642 -9.2343 Std 2.76377 3.59559 2.6914 3.32622 3.73707 1.8104 3.3543 2.4153 Ave -9.3353 -7.3360 -9.2415 -6.94349 -10.4015 -9.0295 -8.4434 -10.1479 Std 2.43834 3.47381 1.61254 3.56118 2.01408 2.3911 3.3388 1.3969 Ave -9.63655 -8.7482 -10.5343 -7.0208 -10.5364 -9.0333 -8.0750 -10.2809 Std 2.38811 2.55743 0.00125 3.85233 2.6E-15 2.9645 3.5964 1.3995 Ave 66.666 151.18 90.229 86.671 20.000 43.333 209.48 63.333 Std 95.893 123.49 105.51 97.324 48.423 67.891 215.06 80.872 Ave 89.837 204.92 163.56 142.72 186.77 31.133 189.83 40.508 Std 56.366 118.89 89.476 119.58 62.726 52.149 170.79 61.462 Ave 161.73 273.73 210.61 214.67 218.55 235.11 274.20 139.48 Std 33.227 110.87 95.214 73.470 117.02 80.839 213.89 33.366 Ave 356.44 487.45 418.63 447.01 492.33 232.44 372.99 316.62 Std 115.66 151.15 156.16 112.34 99.549 43.643 152.12 96.752 Ave 52.309 214.56 143.81 91.831 232.32 27.538 224.85 39.515 Std 95.565 180.03 149.12 73.898 75.405 41.598 286.23 51.233 Ave 768.48 794.50 837.47 811.21 845.47 628.69 845.26 684.51</cell><cell>88.7746 47.2300 2.1170 0.4928 28.8255 0.8242 0.2489 0.1131 0.0047 0.0019 -3154.4 317.921 67.542 10.016 0.0393 0.0151 0.8948 0.1078 8.18E-04 0.0010 0.0102 0.0103 1.9416 2.9633 3.00E-04 1.93E-19 -1.03162 1.00E-15 0.397887 0 3 1.25E-15 -3.86278 2.7E-15 -3.28234 0.0570 -9.4735 1.7626 -10.2258 0.9704 -10.5364 1.77E-15 3.3333 18.254 0.0000 0.0000 104.29 14.266 278.63 7.0670 2.02E-17 7.69E-17 540.23</cell></row><row><cell></cell><cell></cell><cell>(CF6)</cell><cell>Std</cell><cell>192.94</cell><cell>175.94</cell><cell>136.45</cell><cell>173.11</cell><cell>80.524</cell><cell>184.48</cell><cell>139.52</cell><cell>201.22</cell><cell>122.75</cell></row><row><cell cols="4">Friedman mean rank</cell><cell>2.86</cell><cell>5.95</cell><cell>5.14</cell><cell>6.59</cell><cell>5.62</cell><cell>6.00</cell><cell>5.47</cell><cell>3.47</cell><cell>3.91</cell></row><row><cell></cell><cell></cell><cell>Rank</cell><cell></cell><cell>1</cell><cell>7</cell><cell>4</cell><cell>9</cell><cell>6</cell><cell>8</cell><cell>5</cell><cell>2</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Optimization results and comparison for CEC-BC-2017 test functions</figDesc><table><row><cell>Function</cell><cell>EO</cell><cell>PSO</cell><cell>GWO</cell><cell>GA</cell><cell>GSA</cell><cell>SSA</cell><cell>CMA-ES</cell><cell>SHADE</cell><cell>LSHADE-SPACMA</cell></row><row><cell>CEC-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2017-f1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Holm's test for group 1 functions (EO is the control algorithm)</figDesc><table><row><cell>EO vs.</cell><cell>rank</cell><cell>-value</cell><cell>p-value</cell><cell>(0.05)</cell><cell>(0.1)</cell></row><row><cell>GA</cell><cell>6.5862</cell><cell>5.1782</cell><cell>2.40E-06</cell><cell>0.00625</cell><cell>0.0125</cell></row><row><cell>GSA</cell><cell>5.6206</cell><cell>3.8357</cell><cell>1.26E-05</cell><cell>0.00714</cell><cell>0.0142</cell></row><row><cell>SSA</cell><cell>6.0000</cell><cell>4.3631</cell><cell>1.62E-05</cell><cell>0.00833</cell><cell>0.0166</cell></row><row><cell>PSO</cell><cell>5.9482</cell><cell>4.2911</cell><cell>2.22E-05</cell><cell>0.01</cell><cell>0.02</cell></row><row><cell>CMA-ES</cell><cell>5.4655</cell><cell>3.6199</cell><cell>2.94E-04</cell><cell>0.0125</cell><cell>0.025</cell></row><row><cell>GWO</cell><cell>5.1379</cell><cell>3.1644</cell><cell>0.0016</cell><cell>0.0166</cell><cell>0.0333</cell></row><row><cell>LSHADE-SPACMA</cell><cell>3.9137</cell><cell>1.4623</cell><cell>0.1437</cell><cell>0.025</cell><cell>0.05</cell></row><row><cell>SHADE</cell><cell>3.4655</cell><cell>0.8390</cell><cell>0.4015</cell><cell>0.05</cell><cell>0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Holm's test for group 2 functions (EO is the control algorithm)</figDesc><table><row><cell>EO vs.</cell><cell>rank</cell><cell>-value</cell><cell>p-value</cell><cell>(0.05)</cell><cell>(0.1)</cell></row><row><cell>GSA</cell><cell>7.6896</cell><cell>5.1782</cell><cell>2.40E-06</cell><cell>0.00625</cell><cell>0.0125</cell></row><row><cell>GA</cell><cell>6.6896</cell><cell>3.7877</cell><cell>1.52E-04</cell><cell>0.00714</cell><cell>0.0142</cell></row><row><cell>LSHADE-SPACMA</cell><cell>1.4482</cell><cell>-3.5000</cell><cell>4.65E-04</cell><cell>0.00833</cell><cell>0.0166</cell></row><row><cell>GWO</cell><cell>6.3793</cell><cell>3.3562</cell><cell>7.90E-04</cell><cell>0.01</cell><cell>0.02</cell></row><row><cell>SSA</cell><cell>6.1034</cell><cell>2.9726</cell><cell>0.003</cell><cell>0.0125</cell><cell>0.025</cell></row><row><cell>SHADE</cell><cell>2.0344</cell><cell>-2.6849</cell><cell>0.0073</cell><cell>0.0166</cell><cell>0.0333</cell></row><row><cell>CMA-ES</cell><cell>5.7241</cell><cell>2.4452</cell><cell>0.0145</cell><cell>0.025</cell><cell>0.05</cell></row><row><cell>PSO</cell><cell>4.9655</cell><cell>1.3904</cell><cell>0.1644</cell><cell>0.05</cell><cell>0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Holm's test for group 3 functions (EO is the control algorithm)</figDesc><table><row><cell>EO vs.</cell><cell>rank</cell><cell>-value</cell><cell>p-value</cell><cell>(0.05)</cell><cell>(0.1)</cell></row><row><cell>GSA</cell><cell>6.655172</cell><cell>6.373797</cell><cell>2.38E-09</cell><cell>0.00625</cell><cell>0.0125</cell></row><row><cell>GA</cell><cell>6.637931</cell><cell>6.339894</cell><cell>2.95E-09</cell><cell>0.00714</cell><cell>0.0142</cell></row><row><cell>SSA</cell><cell>6.051724</cell><cell>5.187186</cell><cell>2.29E-06</cell><cell>0.00833</cell><cell>0.0166</cell></row><row><cell>GWO</cell><cell>5.758621</cell><cell>4.610832</cell><cell>1.94E-05</cell><cell>0.01</cell><cell>0.02</cell></row><row><cell>CMA-ES</cell><cell>5.594828</cell><cell>4.288752</cell><cell>2.25E-05</cell><cell>0.0125</cell><cell>0.025</cell></row><row><cell>PSO</cell><cell>5.456897</cell><cell>4.017526</cell><cell>5.95E-05</cell><cell>0.0166</cell><cell>0.0333</cell></row><row><cell>LSHADE-SPACMA</cell><cell>2.681034</cell><cell>-1.44088</cell><cell>0.1496</cell><cell>0.025</cell><cell>0.05</cell></row><row><cell>SHADE</cell><cell>2.75</cell><cell>-1.30527</cell><cell>0.1918</cell><cell>0.05</cell><cell>0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Optimum results and comparison for the pressure vessel design problem</figDesc><table><row><cell>Algorithm</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HGA(2) [37]</cell><cell>1.1250</cell><cell>0.5625</cell><cell>58.1267</cell><cell>44.5941</cell><cell>6832.583</cell></row><row><cell>T-Cell [38]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.098429</cell><cell>190.787695</cell><cell>6390.554</cell></row><row><cell>HGA(1) [37]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.0492</cell><cell>177.2522</cell><cell>6065.821</cell></row><row><cell>CPSO [39]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.091266</cell><cell>176.746500</cell><cell>6061.0777</cell></row><row><cell>BFOA [40]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.096394</cell><cell>176.683231</cell><cell>6060.460</cell></row><row><cell>HAIS-GA [41]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.0931</cell><cell>176.7031</cell><cell>6060.367</cell></row><row><cell>DTS-GA [42]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.097398</cell><cell>176.654047</cell><cell>6059.9463</cell></row><row><cell>ES [43]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.098087</cell><cell>176.640518</cell><cell>6059.745</cell></row><row><cell>CDE [44]</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.098411</cell><cell>176.637690</cell><cell>6059.7340</cell></row><row><cell>EO (Mixed variable)</cell><cell>0.8125</cell><cell>0.4375</cell><cell>42.0984456</cell><cell>176.6365958</cell><cell>6059.7143</cell></row><row><cell>EO (Continuous)</cell><cell>0.7781686507</cell><cell>0.3846491672</cell><cell>40.31961921</cell><cell>199.9999933</cell><cell>5885.3279</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 .</head><label>8</label><figDesc>Statistical results and comparison for the pressure vessel design problem (N.A = not available) The variables shown in Fig 14 are thickness of the weld , length of welded part of the beam , height of the beam , and width of the beam .Others that have studied this problem with different algorithms. Table9summarizes the optimal results for different algorithms while Table 10 provides the statistical summary of results. The results of the tables indicate that EO outperformed other algorithms with less cost compared to others. EO also obtained the results in a low number of function evaluations and with lower values for standard deviation, mean, and worst solutions compared to most other algorithms.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Journal Pre-proof</cell><cell></cell><cell></cell></row><row><cell cols="5">Algorithm HGA(2) [37] T-Cell [38] HGA(1) [37] CPSO [39] BFOA [40] J o u r n a l P r e -p r o o f Best Mean Worst Std 6832.584 7187.314 8012.615 276 6390.554 6737.065 7694.066 357 6065.821 6632.376 8248.003 515 6061.0777 6147.1332 6363.8041 86.4545 6060.460 6074.625 N.A 156</cell><cell>Eval, No 80,000 80,000 80,000 200,000 48,000</cell></row><row><cell>HAIS-GA [41]</cell><cell>6061.1229</cell><cell>6743.0848</cell><cell>7368.0602</cell><cell>457.99</cell><cell>150,000</cell></row><row><cell>DTS-GA [42]</cell><cell>6059.9463</cell><cell>6177.2532</cell><cell>6469.322</cell><cell>130.92</cell><cell>80,000</cell></row><row><cell>ES [43]</cell><cell>6059.746</cell><cell>6850.00</cell><cell>7332.87</cell><cell>426</cell><cell>25,000</cell></row><row><cell>CDE [44]</cell><cell>6059.7340</cell><cell>6085.2303</cell><cell>6371.0455</cell><cell>43.0130</cell><cell>240,000</cell></row><row><cell>EO</cell><cell>6059.7143</cell><cell>6668.114</cell><cell>7544.4925</cell><cell>566.24</cell><cell>15,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 .</head><label>9</label><figDesc>Optimum results and comparison for the welded beam design problem</figDesc><table><row><cell>Algorithm</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SBM [45]</cell><cell>0.2407</cell><cell>6.4851</cell><cell>8.2399</cell><cell>0.2497</cell><cell>2.4426</cell></row><row><cell>BFOA [40]</cell><cell>0.2057</cell><cell>3.4711</cell><cell>9.0367</cell><cell>0.2057</cell><cell>2.3868</cell></row><row><cell>SCA [46]</cell><cell>0.2444</cell><cell>6.2380</cell><cell>8.2886</cell><cell>0.2446</cell><cell>2.3854</cell></row><row><cell>EA [47]</cell><cell>0.2443</cell><cell>6.2201</cell><cell>8.2940</cell><cell>0.2444</cell><cell>2.3816</cell></row><row><cell>T-Cell [38]</cell><cell>0.2444</cell><cell>6.1286</cell><cell>8.2915</cell><cell>0.2444</cell><cell>2.3811</cell></row><row><cell>FSA [48]</cell><cell>0.2444</cell><cell>6.1258</cell><cell>8.2939</cell><cell>0.2444</cell><cell>2.3811</cell></row><row><cell>IPSO [49]</cell><cell>0.2444</cell><cell>6.2175</cell><cell>8.2915</cell><cell>0.2444</cell><cell>2.3810</cell></row><row><cell>DSS-DE [50]</cell><cell>0.2444</cell><cell>6.1275</cell><cell>8.2915</cell><cell>0.2444</cell><cell>2.3810</cell></row><row><cell>HSA-GA [51]</cell><cell>0.2231</cell><cell>1.5815</cell><cell>12.8468</cell><cell>0.2245</cell><cell>2.2500</cell></row><row><cell>CDE [44]</cell><cell>0.2031</cell><cell>3.5430</cell><cell>9.03350</cell><cell>0.2062</cell><cell>1.7335</cell></row><row><cell>CPSO [39]</cell><cell>0.2024</cell><cell>3.5442</cell><cell>9.04821</cell><cell>0.2057</cell><cell>1.7280</cell></row><row><cell>TEO [52]</cell><cell>0.2057</cell><cell>3.4723</cell><cell>9.03513</cell><cell>0.2058</cell><cell>1.7253</cell></row><row><cell>EO</cell><cell>0.2057</cell><cell>3.4705</cell><cell>9.03664</cell><cell>0.2057</cell><cell>1.7249</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 .</head><label>10</label><figDesc>Statistical results and comparison for the welded beam design problem (N.A = not available)</figDesc><table><row><cell>Algorithm</cell><cell>Best</cell><cell>Mean</cell><cell>Worst</cell><cell>Std</cell><cell>Eval, No</cell></row><row><cell>SBM [45]</cell><cell>2.4426</cell><cell>2.5215</cell><cell>2.6315</cell><cell>N.A</cell><cell>19,259</cell></row><row><cell>BFOA [40]</cell><cell>2.3868</cell><cell>2.4040</cell><cell>N.A</cell><cell>0.016</cell><cell>48,000</cell></row><row><cell>SCA [46]</cell><cell>2.3854</cell><cell>3.2551</cell><cell>6.3996</cell><cell>0.9590</cell><cell>33,095</cell></row><row><cell>EA [47]</cell><cell>2.3816</cell><cell>N.A</cell><cell>2.38297</cell><cell>0.00034</cell><cell>28,897</cell></row><row><cell>T-Cell [38]</cell><cell>2.3811</cell><cell>2.4398</cell><cell>2.7104</cell><cell>0.09314</cell><cell>320,000</cell></row><row><cell>FSA [48]</cell><cell>2.3811</cell><cell>2.4041</cell><cell>2.4889</cell><cell>N.A</cell><cell>56,243</cell></row><row><cell>IPSO [49]</cell><cell>2.3810</cell><cell>2.3819</cell><cell>N.A</cell><cell>0.00523</cell><cell>30,000</cell></row><row><cell>HSA-GA [51]</cell><cell>2.2500</cell><cell>2.26</cell><cell>2.28</cell><cell>0.0078</cell><cell>26,466</cell></row><row><cell>CDE [44]</cell><cell>1.7335</cell><cell>1.768158</cell><cell>1.824105</cell><cell>0.022194</cell><cell>240,000</cell></row><row><cell>CPSO [39]</cell><cell>1.7280</cell><cell>1.748831</cell><cell>1.782143</cell><cell>0.012926</cell><cell>200,000</cell></row><row><cell>TEO [52]</cell><cell>1.725284</cell><cell>1.768040</cell><cell>1.931161</cell><cell>0.058166</cell><cell>N.A</cell></row><row><cell>EO</cell><cell>1.724853</cell><cell>1.726482</cell><cell>1.736725</cell><cell>0.003257</cell><cell>15,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 .</head><label>11</label><figDesc>Optimum results and comparison for the spring design problem</figDesc><table><row><cell>Algorithm</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SI [53]</cell><cell>0.050417</cell><cell>0.321532</cell><cell>13.97991</cell><cell>0.013060</cell></row><row><cell>GA(1) [55]</cell><cell>0.051480</cell><cell>0.351661</cell><cell>11.632201</cell><cell>0.012704</cell></row><row><cell>CA [54]</cell><cell>0.050000</cell><cell>0.317395</cell><cell>14.031795</cell><cell>0.012721</cell></row><row><cell>GSA</cell><cell>0.050276</cell><cell>0.323680</cell><cell>13.525410</cell><cell>0.012702</cell></row><row><cell>GA(2) [56]</cell><cell>0.051989</cell><cell>0.363965</cell><cell>10.890522</cell><cell>0.012681</cell></row><row><cell>CPSO [39]</cell><cell>0.051728</cell><cell>0.357644</cell><cell>11.244543</cell><cell>0.012674</cell></row><row><cell>BFOA [40]</cell><cell>0.051825</cell><cell>0.359935</cell><cell>11.107103</cell><cell>0.012671</cell></row><row><cell>CDE [44]</cell><cell>0.051609</cell><cell>0.354714</cell><cell>11.410831</cell><cell>0.012670</cell></row><row><cell>SCA [46]</cell><cell>0.052160</cell><cell>0.368159</cell><cell>10.648442</cell><cell>0.012669</cell></row><row><cell>HGA [57]</cell><cell>0.051302</cell><cell>0.347475</cell><cell>11.852177</cell><cell>0.012668</cell></row><row><cell>T-Cell [38]</cell><cell>0.051622</cell><cell>0.355105</cell><cell>11.384534</cell><cell>0.012665</cell></row><row><cell>EO</cell><cell>0.0516199100</cell><cell>0.355054381</cell><cell>11.38796759</cell><cell>0.012666</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 .</head><label>12</label><figDesc>Statistical results and comparison for the spring design problem (N.A = not available)</figDesc><table><row><cell>Algorithm</cell><cell>Best</cell><cell>Mean</cell><cell>Worst</cell><cell>Std</cell><cell>Eval, No</cell></row><row><cell>SI [53]</cell><cell>0.013060</cell><cell>0.015526</cell><cell>0.018992</cell><cell>N.A</cell><cell>20,000</cell></row><row><cell>GA(1) [55]</cell><cell>0.012704</cell><cell>0.012769</cell><cell>0.012822</cell><cell>3.93E-05</cell><cell>N.A.</cell></row><row><cell>CA [54]</cell><cell>0.012721</cell><cell>0.013568</cell><cell>0.0151156</cell><cell>8.4E-04</cell><cell>50,000</cell></row><row><cell>GA(2) [56]</cell><cell>0.012681</cell><cell>0.012742</cell><cell>0.012973</cell><cell>9.5E-05</cell><cell>80,000</cell></row><row><cell>CPSO [39]</cell><cell>0.012674</cell><cell>0.012730</cell><cell>0.012924</cell><cell>5.19E-05</cell><cell>200,000</cell></row><row><cell>BFOA [40]</cell><cell>0.012671</cell><cell>0.012759</cell><cell>N.A</cell><cell>1.36E-04</cell><cell>48,000</cell></row><row><cell>CDE [44]</cell><cell>0.012670</cell><cell>0.012703</cell><cell>0.012790</cell><cell>2.07E-05</cell><cell>240,000</cell></row><row><cell>SCA [46]</cell><cell>0.012669</cell><cell>0.012922</cell><cell>0.016717</cell><cell>5.92E-04</cell><cell>25,167</cell></row><row><cell>HGA [57]</cell><cell>0.012668</cell><cell>0.013481</cell><cell>0.016155</cell><cell>N.A.</cell><cell>36,000</cell></row><row><cell>T-Cell [38]</cell><cell>0.012665</cell><cell>0.013309</cell><cell>0.012732</cell><cell>9.4E-05</cell><cell>36,000</cell></row><row><cell>EO</cell><cell>0.012666</cell><cell>0.013017</cell><cell>0.013997</cell><cell>3.91E-04</cell><cell>15,000</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J o u r n a l P r e -p r o o fJournal Pre-proof</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>t: iteration, n: Population, d: dimension, c: number of offsprings, m: number of mutated populations, α=coefficient that shows the percentage of sum of offsprings and mutated population to the total number of populations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PSO complexity</head><p>is equal to ; therefore, . Using this equation, the updated GA complexity equation is:</p><p>We consider Thus T=t and c+m=n</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Linear and Nonlinear Programming, Second</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Luenberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex Optimization</title>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Size Optimization of Truss Structures by Cellular Automata</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Faramarzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A novel hybrid cellular automata-linear programming approach for the optimal sizing of planar truss structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Faramarzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Afshar</surname></persName>
		</author>
		<idno type="DOI">10.1080/10286608.2013.820280</idno>
		<ptr target="https://doi.org/10.1080/10286608.2013.820280" />
	</analytic>
	<monogr>
		<title level="j">Civ. Eng. Environ. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="209" to="228" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Application of cellular automata to size and topology optimization of truss structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Faramarzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Afshar</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.scient.2012.04.009</idno>
		<ptr target="https://doi.org/10.1016/j.scient.2012.04.009" />
	</analytic>
	<monogr>
		<title level="j">Sci. Iran</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="373" to="380" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolf</forename><surname>Grey</surname></persName>
		</author>
		<author>
			<persName><surname>Optimizer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.advengsoft.2013.12.007</idno>
		<ptr target="https://doi.org/10.1016/j.advengsoft.2013.12.007" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Softw</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<idno type="DOI">10.1109/MHS.1995.494215</idno>
		<ptr target="https://doi.org/10.1109/MHS.1995.494215" />
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth Int. Symp. Micro Mach. Hum. Sci</title>
		<meeting>Sixth Int. Symp. Micro Mach. Hum. Sci</meeting>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimization by Simulated Annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.220.4598.671</idno>
		<ptr target="https://doi.org/10.1126/science.220.4598.671" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ant colony optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stutzle</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCI.2006.329691</idno>
		<ptr target="https://doi.org/10.1109/MCI.2006.329691" />
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="39" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Differential Evolution -A Simple and Efficient Heuristic for global Optimization over Continuous Spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1008202821328</idno>
		<ptr target="https://doi.org/10.1023/A:1008202821328" />
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence through Simulated Evolution</title>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>John Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reducing the Time Complexity of the Derandomized Evolution Strategy with Covariance Matrix Adaptation (CMA-ES)</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
		<idno type="DOI">10.1162/106365603321828970</idno>
		<ptr target="https://doi.org/10.1162/106365603321828970" />
	</analytic>
	<monogr>
		<title level="j">Evol Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cuckoo search algorithm: a metaheuristic approach to solve structural optimization problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Alavi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00366-011-0241-y</idno>
		<ptr target="https://doi.org/10.1007/s00366-011-0241-y" />
	</analytic>
	<monogr>
		<title level="j">Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.advengsoft.2017.07.002</idno>
		<ptr target="https://doi.org/10.1016/j.advengsoft.2017.07.002" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Softw</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="163" to="191" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A new optimization method: Dolphin echolocation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farhoudi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.advengsoft.2013.03.004</idno>
		<ptr target="https://doi.org/10.1016/j.advengsoft.2013.03.004" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Softw</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="53" to="70" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">GSA: A Gravitational Search Algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rashedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nezamabadi-Pour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saryazdi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2009.03.004</idno>
		<ptr target="https://doi.org/10.1016/j.ins.2009.03.004" />
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="2232" to="2248" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A novel heuristic optimization method: charged system search</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Talatahari</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00707-009-0270-4</idno>
		<ptr target="https://doi.org/10.1007/s00707-009-0270-4" />
	</analytic>
	<monogr>
		<title level="j">Acta Mech</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="267" to="289" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imperialist competitive algorithm: An algorithm for optimization inspired by imperialistic competition, in: 2007 IEEE Congr</title>
		<author>
			<persName><forename type="first">E</forename><surname>Atashpaz-Gargari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lucas</surname></persName>
		</author>
		<idno type="DOI">10.1109/CEC.2007.4425083</idno>
		<ptr target="https://doi.org/10.1109/CEC.2007.4425083" />
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="page" from="4661" to="4667" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Teaching-learning-based optimization: A novel method for constrained mechanical design optimization problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Savsani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Vakharia</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cad.2010.12.015</idno>
		<ptr target="https://doi.org/10.1016/j.cad.2010.12.015" />
	</analytic>
	<monogr>
		<title level="j">Comput.-Aided Des</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="303" to="315" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Nazaroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alvarez-Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Engineering Science</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Review of indoor emission source models. Part 1</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0269-7491(02)00187-2</idno>
		<ptr target="https://doi.org/10.1016/S0269-7491(02)00187-2" />
	</analytic>
	<monogr>
		<title level="j">Overview, Environ. Pollut</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="533" to="549" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A memory based differential evolution algorithm for unconstrained optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Parouha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Das</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2015.10.022</idno>
		<ptr target="https://doi.org/10.1016/j.asoc.2015.10.022" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="501" to="517" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Tuning PSO parameters through sensitivity analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Beielstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahatis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Dortmund</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. Reihe Comput. Intell. CI 12402</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evolutionary programming made faster</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/4235.771163</idno>
		<ptr target="https://doi.org/10.1109/4235.771163" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="82" to="102" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Novel composition test functions for numerical global optimization</title>
		<ptr target="http://ieeexplore.ieee.org/document/1501604/" />
	</analytic>
	<monogr>
		<title level="m">IEEE Conference Publication</title>
		<imprint>
			<date type="published" when="2017-12-04">accessed December 4, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Success-history based parameter adaptation for Differential Evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fukunaga</surname></persName>
		</author>
		<idno type="DOI">10.1109/CEC.2013.6557555</idno>
		<ptr target="https://doi.org/10.1109/CEC.2013.6557555" />
	</analytic>
	<monogr>
		<title level="j">IEEE Congr. Evol. Comput</title>
		<imprint>
			<biblScope unit="page" from="71" to="78" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A study of particle swarm optimization particle trajectories</title>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2005.02.003</idno>
		<ptr target="https://doi.org/10.1016/j.ins.2005.02.003" />
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="937" to="971" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Analysis of Exploration and Exploitation in Evolutionary Algorithms by Ancestry Trees</title>
		<author>
			<persName><forename type="first">M</forename><surname>Črepinšek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJICA.2011.037947</idno>
		<ptr target="https://doi.org/10.1504/IJICA.2011.037947" />
	</analytic>
	<monogr>
		<title level="j">Int J Innov Comput Appl</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="11" to="19" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploration and Exploitation in Evolutionary Algorithms: A Survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Črepinšek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<idno type="DOI">10.1145/2480741.2480752</idno>
		<ptr target="https://doi.org/10.1145/2480741.2480752" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput Surv</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Problem Definitions and Evaluation Criteria for the CEC 2017 Special Session and Competition on Single Objective Real-Parameter Numerical Optimization</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congr. Evol. Comput. CEC</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">CEC 2017 Special Session on Single Objective Numerical Optimization Single Bound Constrained Real-Parameter Numerical Optimization</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congr. Evol. Comput. CEC</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Statistical Comparisons of Classifiers over Multiple Data Sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A parameter control method of evolutionary algorithms using exploration and exploitation measures with a practical application for fitting Sovova&apos;s mass transfer model</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hrnčič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Črepinšek</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2013.05.010</idno>
		<ptr target="https://doi.org/10.1016/j.asoc.2013.05.010" />
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3792" to="3805" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Zar</surname></persName>
		</author>
		<title level="m">Biostatistical Analysis</title>
		<meeting><address><addrLine>Englewood Cliffs</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Simple Sequentially Rejective Multiple Test Procedure</title>
		<author>
			<persName><forename type="first">S</forename><surname>Holm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scand. J. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A new hybrid AIS-GA for constrained optimization problems in mechanical engineering</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C C</forename><surname>Lemonge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Fonseca</surname></persName>
		</author>
		<idno type="DOI">10.1109/CEC.2008.4630985</idno>
		<ptr target="https://doi.org/10.1109/CEC.2008.4630985" />
	</analytic>
	<monogr>
		<title level="j">IEEE Congr. Evol. Comput. IEEE World Congr. Comput. Intell</title>
		<imprint>
			<biblScope unit="page" from="1455" to="1462" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A modified version of a T-Cell Algorithm for constrained optimization problems</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Aragón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Esquivel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<idno type="DOI">10.1002/nme.2904</idno>
		<ptr target="https://doi.org/10.1002/nme.2904" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Numer. Methods Eng</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="351" to="378" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An effective co-evolutionary particle swarm optimization for constrained engineering design problems</title>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.engappai.2006.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.engappai.2006.03.003" />
	</analytic>
	<monogr>
		<title level="j">Eng. Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="89" to="99" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bacterial foraging for engineering design problems: preliminary results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ocana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">4th Mex. Congr. Evol. Comput. COMCEV</title>
		<imprint>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="2008">2008. 2008</date>
			<pubPlace>Mexico</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Hybridizing a genetic algorithm with an artificial immune system for global optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Cortés</surname></persName>
		</author>
		<idno type="DOI">10.1080/03052150410001704845</idno>
		<ptr target="https://doi.org/10.1080/03052150410001704845" />
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="607" to="634" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Use of dominance-based tournament selection to handle constraints in genetic algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Montes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Eng. Syst. Artif. Neural Netw. ANNIE</title>
		<imprint>
			<biblScope unit="page" from="177" to="182" />
			<date type="published" when="2001">2001</date>
			<publisher>ASME press</publisher>
			<pubPlace>St. Louis, Missouri</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An empirical study about the usefulness of evolution strategies to solve constrained optimization problems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mezura-Montes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<idno type="DOI">10.1080/03081070701303470</idno>
		<ptr target="https://doi.org/10.1080/03081070701303470" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Gen. Syst</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="443" to="473" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An effective co-evolutionary differential evolution for constrained optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amc.2006.07.105</idno>
		<ptr target="https://doi.org/10.1016/j.amc.2006.07.105" />
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="340" to="356" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A socio-behavioural simulation for engineering design optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ray</surname></persName>
		</author>
		<idno type="DOI">10.1080/03052150212723</idno>
		<ptr target="https://doi.org/10.1080/03052150212723" />
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="341" to="354" />
			<pubPlace>Eng</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Society and civilization: An optimization algorithm based on the simulation of social behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Liew</surname></persName>
		</author>
		<idno type="DOI">10.1109/TEVC.2003.814902</idno>
		<ptr target="https://doi.org/10.1109/TEVC.2003.814902" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="386" to="396" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An effective multiagent evolutionary algorithm integrating a novel roulette inversion operator for engineering optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amc.2009.01.048</idno>
		<ptr target="https://doi.org/10.1016/j.amc.2009.01.048" />
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">211</biblScope>
			<biblScope unit="page" from="392" to="416" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Derivative-Free Filter Simulated Annealing Method for Constrained Continuous Global Optimization</title>
		<author>
			<persName><forename type="first">A.-R</forename><surname>Hedar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fukushima</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10898-005-3693-z</idno>
		<ptr target="https://doi.org/10.1007/s10898-005-3693-z" />
	</analytic>
	<monogr>
		<title level="j">J. Glob. Optim</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="521" to="549" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An improved particle swarm optimizer for mechanical design optimization problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Prempain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1080/03052150410001704854</idno>
		<ptr target="https://doi.org/10.1080/03052150410001704854" />
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="585" to="605" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Differential evolution with dynamic stochastic selection for constrained optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2008.02.014</idno>
		<ptr target="https://doi.org/10.1016/j.ins.2008.02.014" />
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="3043" to="3074" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A hybrid real-parameter genetic algorithm for function optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aei.2005.09.001</idno>
		<ptr target="https://doi.org/10.1016/j.aei.2005.09.001" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Inform</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="7" to="21" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A novel meta-heuristic optimization algorithm: Thermal exchange optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dadras</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.advengsoft.2017.03.014</idno>
		<ptr target="https://doi.org/10.1016/j.advengsoft.2017.03.014" />
	</analytic>
	<monogr>
		<title level="j">Adv. Softw</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="69" to="84" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Engineering Design Optimization Using a Swarm with an Intelligent Information Sharing Among Individuals</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saini</surname></persName>
		</author>
		<idno type="DOI">10.1080/03052150108940941</idno>
		<ptr target="https://doi.org/10.1080/03052150108940941" />
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="735" to="748" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Efficient evolutionary optimization through the use of cultural algorithm</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Becerra</surname></persName>
		</author>
		<idno type="DOI">10.1080/03052150410001647966</idno>
		<ptr target="https://doi.org/10.1080/03052150410001647966" />
	</analytic>
	<monogr>
		<title level="j">Eng. Optim</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="219" to="236" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Use of a self-adaptive penalty approach for engineering optimization problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0166-3615(99)00046-9</idno>
		<ptr target="https://doi.org/10.1016/S0166-3615(99)00046-9" />
	</analytic>
	<monogr>
		<title level="j">Comput. Ind</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="113" to="127" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Mezura Constraint-handling in genetic algorithms through the use of dominance-based tournament selection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Coello Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<idno type="DOI">10.1016/S1474-0346(02)00011-3</idno>
		<ptr target="https://doi.org/10.1016/S1474-0346(02)00011-3" />
	</analytic>
	<monogr>
		<title level="j">Adv. Eng. Inform</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="193" to="203" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A hybrid genetic algorithm for constrained optimization problems in mechanical engineering, in: 2007 IEEE Congr</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Bernardino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C C</forename><surname>Lemonge</surname></persName>
		</author>
		<idno type="DOI">10.1109/CEC.2007.4424532</idno>
		<ptr target="https://doi.org/10.1109/CEC.2007.4424532" />
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="page" from="646" to="653" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
