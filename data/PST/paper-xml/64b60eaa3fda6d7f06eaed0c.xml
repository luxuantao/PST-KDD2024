<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lightweight ML-based Runtime Prefetcher Selection on Many-core Platforms</title>
				<funder ref="#_2fva6rq">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Erika</forename><forename type="middle">S</forename><surname>Alcorta</surname></persName>
							<email>esalcort@utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin. ? Ampere Computing. ? VMWare Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mahesh</forename><surname>Madhav</surname></persName>
							<email>mahesh@amperecomputing.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin. ? Ampere Computing. ? VMWare Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><surname>Tetrick</surname></persName>
							<email>scott.tetrick@amperecomputing.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin. ? Ampere Computing. ? VMWare Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Neeraja</forename><forename type="middle">J</forename><surname>Yadwadkar</surname></persName>
							<email>neeraja@austin.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin. ? Ampere Computing. ? VMWare Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Gerstlauer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin. ? Ampere Computing. ? VMWare Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Lightweight ML-based Runtime Prefetcher Selection on Many-core Platforms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern computer designs support composite prefetching, where multiple individual prefetcher components are used to target different memory access patterns. However, multiple prefetchers competing for resources can drastically hurt performance, especially in many-core systems where cache and other resources are shared and very limited. Prior work has proposed mitigating this issue by selectively enabling and disabling prefetcher components during runtime. Traditional approaches proposed heuristics that are hard to scale with increasing core and prefetcher component counts. More recently, deep reinforcement learning was proposed. However, it is too expensive to deploy in real-world many-core systems. In this work, we propose a new phase-based methodology for training a lightweight supervised learning model to manage composite prefetchers at runtime. Our approach improves the performance of a state-of-the-art many-core system by up to 25% and by 2.7% on average over its default prefetcher configuration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Hardware data prefetching can reduce memory latency and significantly improve the performance of many applications, provided it accurately and promptly detects their memory access patterns. However, individual prefetchers typically target specific or limited sets of patterns <ref type="bibr" target="#b11">[12]</ref>. To address this limitation, modern processors combine multiple prefetcher components, thus covering a wider range of access patterns than monolithic prefetchers <ref type="bibr" target="#b11">[12]</ref>. Increasing the number of prefetches in the system can lead to higher contention and pollution of shared resources like memory bandwidth and cache space <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Furthermore, in multi-core systems, enabling prefetching can sometimes hurt performance depending on the workload <ref type="bibr" target="#b9">[10]</ref>. Consequently, modern processors offer users the ability to adjust prefetcher components through registers <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b13">[14]</ref>, but selecting when to enable or disable prefetcher components for any program application is a challenging task.</p><p>The variety of dynamic workload behaviors in program applications is very large, and the best prefetcher selection may change depending on the workload behavior. For example, Fig. <ref type="figure">1</ref> shows the execution time of 10 programs from the SPEC CPU Int Rate 2017 multi-programmed benchmark suite <ref type="bibr" target="#b17">[18]</ref> running on a many-core hardware platform with three different prefetcher configurations: ON, OFF, and Def. ON enables all prefetcher components; OFF disables all prefetcher components; and, Def sets the default configuration, which enables one prefetcher. The figure depicts that the best selection is different for each program. While this example only compares three configurations, modern systems offer </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speedup</head><p>Def OFF ON Fig. <ref type="figure">1</ref>. Speedup (higher is better) of SPEC CPU Int Rate 2017 benchmarks with all prefetchers disabled (OFF) and all prefetchers enabled (ON) compared to the default config (Def). The best configuration depends on the workload. more options, increasing the complexity of runtime decisions that map workload behaviors to prefetcher selection.</p><p>Previous research has explored various techniques for tuning prefetcher components at runtime to maximize performance, a task commonly known as runtime adaptive prefetching. Some studies use heuristics and explore all or a subset of configurations during program execution to make decisions <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. However, exploring configurations during runtime misses performance opportunities and does not scale with increasing configurations and core counts. More recent works have used machine learning (ML) models to train a policy offline and evaluate it online <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>. However, they do not provide sufficient proof that their models are generalized enough to handle unseen workloads, and their proposed models are too expensive to implement on a real-world platform. Furthermore, none of these runtime adaptive prefetching studies have investigated many-core platforms, which present unique challenges that do not manifest at lower core counts.</p><p>In this work, we propose a runtime prefetcher selection approach that uses a low-overhead machine learning model to enable or disable prefetcher components based on their expected performance improvement on a state-of-the-art manycore platform. We collect hardware counter data to monitor the system workload and propose a new methodology that uses phase classification <ref type="bibr" target="#b0">[1]</ref> and supervised learning to correlate workload phases with the best selection of prefetcher components. We demonstrate the effectiveness of our approach by deploying a software-based version on a state-of-the-art cloud-scale hardware platform. Our approach can also be implemented in hardware on future processor designs.</p><p>We summarize the contributions of this paper as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Prior work has proposed numerous approaches to reduce the contention generated by prefetchers in multi-core systems. Some work is concerned with extending the design of prefetchers <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b18">[19]</ref> while others have proposed prefetcher-aware cache insertion and eviction policies to manage cache contention <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b18">[19]</ref>. While these solutions focus on tuning an individual prefetcher, our approach is concerned with managing the components of composite prefetchers.</p><p>Various studies in composite prefetching management propose heuristics to select prefetchers at runtime <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. These approaches study different metrics to rank prefetcher configurations based on performance <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b14">[15]</ref> or other heuristics <ref type="bibr" target="#b13">[14]</ref>. The ranking is obtained during execution time by performing an exhaustive search that executes every prefetcher configuration for one sample. The best-ranked configuration is selected for a pre-determined period of time. This process is repeated after either a fixed time window <ref type="bibr" target="#b13">[14]</ref> or a phase change, defined by a fixed percentage change in system performance <ref type="bibr" target="#b10">[11]</ref> or annotated in code <ref type="bibr" target="#b14">[15]</ref>. However, exhaustively searching multiple configurations during runtime is not scalable as the number of prefetchers and applications increases. Additionally, the time spent searching necessarily misses optimization opportunities. Lastly, ranking prefetcher configurations based on the performance of a single sample fails to acknowledge short-term performance variations in workloads <ref type="bibr" target="#b0">[1]</ref>, which may lead to selecting the wrong configuration.</p><p>More recent work has introduced ML-based composite prefetcher management approaches. These models eliminate the need to search the configuration space exhaustively by learning to generalize from fewer samples. In <ref type="bibr" target="#b6">[7]</ref>, the authors proposed formulating the problem with contextual bandits. They train one model per prefetcher component while other prefetchers are always on. However, they do not evaluate the coordination of prefetchers, since the models are not enabled simultaneously. Additionally, they found that they never need to disable some prefetchers in their quad-core system. This is not the case in many-core systems, where it is sometimes beneficial to disable all prefetchers, as was shown in Fig. <ref type="figure">1</ref>. In <ref type="bibr" target="#b8">[9]</ref>, the authors propose using deep reinforcement learning (RL) to coordinate multiple prefetchers. However, deploying deep RL models on real-world systems is very expensive in terms of training, power, storage, and latency costs. In contrast, we propose a supervised learning model with minimal costs that can be either implemented in existing runtime management systems or easily deployed in hardware. Moreover, these studies <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref> only considered multiprogrammed workloads and did not investigate whether their models can improve the performance of unseen (i.e., not used for training) program applications. Our work demonstrates that our proposed lightweight runtime prefetcher selection model can generalize its predictions to unseen and multi-threaded workloads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L2 Prefetcher Register</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PREFETCHER SELECTION MODEL DESIGN</head><p>The task of selecting a prefetcher configuration during runtime with a model is represented in Fig. <ref type="figure" target="#fig_1">2</ref>. The model aims to map a vector of hardware counter values into a prefetcher selection decision. We collect hardware counters by accessing the performance monitoring units (PMU) of the system and set the prefetcher decision through a model-specific register (MSR). This section outlines our proposed method for designing and training such a model. We start by introducing the problem formulation, followed by an explanation of our approach, which involves both offline analysis and online implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><p>The goal of a prefetcher selection policy is to minimize the execution time of a workload, which we define as G. The execution of a workload is represented by a trace of hardware counters, U ? R T ?C , where T is the number of samples and C is the number of collected hardware counters. An observation of U at time t is represented as U t . The hardware counters are transformed into features X t = ?(U t ), X t ? R M , where M is the number of features. For example, this transformation ? includes calculating the IPC with the instructions and cpucycles hardware counters. We use ? t to represent the IPC of a sample at time t, ? t ? X t . We partition the goal of minimizing the execution time into smaller goals that maximize the IPC of each sample, ? t , based on the observation that the average IPC is inversely proportional to the execution time.  At each time step t, a machine learning model, f , predicts an output, y t+1 based on the features X t with the goal of maximizing ? t+1 . The output is a one-hot encoded vector, y t ? {0, 1} N , where N is the number of prefetchers, and each element in the vector indicates whether the prefetcher should be enabled or disabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data Analysis and Model Training</head><p>After partitioning our goal of minimizing a workload's execution time into smaller goals that maximize the IPC of each sample of the workload, we need to define a ground truth in order to train a supervised learning model. We propose a method that analyzes data and generates labels to train a runtime prefetcher selection model in an offline fashion. Our method is depicted in Fig. <ref type="figure">3</ref>, comprising five stages detailed below.</p><p>1) Data Collection: We periodically collected hardware counter data from different workloads to later train our model. For each workload, we collected one trace of hardware counters per prefetcher configuration.</p><p>2) Clustering: In order to compare the samples of different prefetcher configurations, we propose clustering similar PMU behaviors together to find phases within the workloads. Our methodology involves training a clustering model with data from only one prefetcher configuration. We chose OFF as our baseline since it shows workload behaviors without the effects of prefetching. We scaled all features to a range between 0 and 1 using a min-max scaler and clustered all the workload traces of the baseline configuration using k-means. This produces a table of cluster centers, which is then used for phase classification.</p><p>3) Phase Classification: Once the cluster centers have been generated using data from the baseline configuration, we use them to classify the phases of data samples in all traces. Next, we group all samples in the same phase and prefetcher configuration and calculate the average IPC per phase. This allows us to compare the performance of different prefetcher configurations across workload phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Training Set Generation:</head><p>We use the phase classification labels to determine the best prefetcher configuration for each sample, which we define as the configuration that yields the highest average IPC for the corresponding phase. We consider this definition as our ground truth. Associating each sample and its phase classification with the best prefetcher configuration generates a supervised training set that assigns each sample's features X t to the ground truth prefetcher selection, y t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Model Training:</head><p>We use our generated data set to train a decision tree model. We found that it only needs four input features instead of seven while maintaining high prediction accuracy. This reduces the number of hardware counters that we need to collect during runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Runtime Implementation</head><p>We implemented our prefetcher selection model as a program with a thread that is invoked every 100 ms. The thread accesses hardware counter values using perf's system call. Then, it transforms the counters into features and performs inference on the decision tree. Finally, it writes the decision tree output to the corresponding fields in the prefetcher MSR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>We collected data from one multi-programmed benchmark suite, SPEC CPU Int Rate 2017 <ref type="bibr" target="#b17">[18]</ref>, and two multi-threaded Java benchmark suites, DaCapo <ref type="bibr" target="#b1">[2]</ref> and Renaissance <ref type="bibr" target="#b16">[17]</ref>, to evaluate our approach. We use SPEC CPU workloads for training and validation and DaCapo and Renaissance for testing. All workloads run on AmpereOne, a cloud-scale manycore platform with 160 ARMv8.6+ ISA cores, 2MB of L2 cache per core, 64MB of system-level cache, and 256GB of DDR5-4800 memory running Fedora Linux 36. The platform has 12 different prefetcher configurations, which can be tuned with a hardware register. For each prefetcher configuration, we collected one trace of hardware counters per workload, resulting in a total of 120 traces (12 prefetcher options ? 10 workloads). Each trace consisted of C = 7 hardware counters 50 0 50 2 50 5 52 0 52 3 52 5 <ref type="bibr">53</ref>  collected periodically every 100 ms with Linux's perf tool. The hardware counters were transformed into M = 7 features. See Table <ref type="table" target="#tab_2">I</ref> for the lists of hardware counters and features. Fig. <ref type="figure">4</ref> shows the speedup of all SPEC CPU benchmarks when prefetcher selection is enabled and exploring the decision tree depth hyperparameter with depths of 1, 2, and 4. The results are normalized to the system's default prefetcher. The geomean is shown on the right side of the plot. On average, enabling system-wide runtime adaptive prefetching improves the performance of SPEC workloads by 1.9% and up to 5.5% in the best scenario.</p><p>We want to measure the ability of the model to improve performance even with system changes. For this test, we evaluated our models on the same programs but with different binaries. Specifically, we recompiled SPEC CPU benchmarks with a different compiler, gcc-12, which introduces several new code optimizations when compared to previous versions, such as improved vectorization and structure splitting. So although the same work is completed, the data access patterns may vary widely as in the case of 505.mcf. Then, we enabled prefetcher selection with the same models that were previously trained on SPEC programs compiled with gcc-10. The results are shown in Fig. <ref type="figure">5</ref>. The best-performing decision tree has a depth of 4. We observe a similar performance improvement trend between the gcc-10 and gcc-12 experiments and demonstrate that the model still improves performance even when presented with different binary files.</p><p>We further test the performance of our model by presenting it with completely new workloads (not used for training). We ran workloads from the DaCapo and Renaissance suites. Note that in addition to being new workloads, they are multithreaded instead of multi-programmed, written in a different language (Java), and compared to SPEC CPU they spend more time in operating system code, network stack, and synchronization (locking and snooping). We tested our bestperforming decision tree with depth 4 on each suite and show our results in Fig. <ref type="figure">6</ref> and Fig. <ref type="figure">7</ref>. For most of the workloads, dynamic prefetcher selection reduces the execution time, with the best scenario being 25%. However, as opposed to SPEC CPU results, some programs lose performance. Nonetheless, the geomean performance improvements for DaCapo and Renaissance suites are 1.7% and 3%, respectively. The improved performance of all these unseen workloads together is 2.7%. A major benefit of our proposed model, as opposed to prior work, is the lightweight implementation. The decision tree has a maximum depth of 4. It requires storing 15 nodes with two parameters each: the feature ID (in our case, 2 bits for four features) and the compare value (we use 16 bits but can be reduced to 8 bits). Additionally, the eight leaf nodes require storing the prefetcher selection when true or false (4 bits in our case). The total size of our model is only 42 bytes, which makes it easy to fit on any embedded firmware or hardware deployment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION AND FUTURE WORK</head><p>We proposed a lightweight model for runtime prefetcher selection for many-core platforms. It can improve the performance of unseen workloads by up to 25% and 2.7% on average over the default prefetcher.</p><p>These early results suggest that runtime prefetcher selection can be formulated as a workload-agnostic offline supervised learning problem; however, further investigation is required to determine why it performed poorly in a few benchmarks. The investigation should determine whether the problem is training coverage, i.e., the input features are in a different distribution from the training set, or the problem is workload specific, i.e., for the same set of input features, the best prefetcher selection is different depending on the running program. Our proposed approach estimates the best prefetcher selection for all the cores in the system. Future work includes investigating lightweight runtime prefetcher selection that is more practical for per-core decisions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Prefetcher selection overview.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Fig. 3. Proposed analysis to generate our runtime prefetcher selection model.</figDesc><table><row><cell></cell><cell></cell><cell>OFF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">features</cell><cell></cell><cell></cell><cell></cell></row><row><cell>OFF Next config. prefetcher</cell><cell>Data collection Workloads System PMU MSR</cell><cell>1</cell><cell cols="2">PMU PMU PMU HW counter HW counter traces</cell><cell>Phase Classification Clustering 2</cell><cell>phases</cell><cell>phases</cell><cell>IPC Cluster centers Pref. config.</cell><cell>Data Set Generation 4</cell><cell>&lt;X,y&gt;</cell><cell>Model Training</cell><cell>5</cell></row><row><cell></cell><cell></cell><cell cols="2">Other</cell><cell>traces</cell><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">pref. config.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I LISTS</head><label>I</label><figDesc>OF COLLECTED HARDWARE COUNTERS AND FEATURES.</figDesc><table><row><cell>Hardware counters (U )</cell><cell>Features (X = ?(U ))</cell></row><row><cell>Instructions</cell><cell>Instructions per cycle (IPC)</cell></row><row><cell>Memory accesses</cell><cell>Memory accesses per kilo instructions</cell></row><row><cell>Branch misses</cell><cell>Branch misses per kilo instructions</cell></row><row><cell>Cache misses</cell><cell>Cache misses per kilo instructions</cell></row><row><cell>CPU cycles</cell><cell>Cache misses to memory accesses ratio</cell></row><row><cell>L2 data cache refills</cell><cell>L2 data cache refills to cache miss ratio</cell></row><row><cell>L2 instruction cache refills</cell><cell>L2 instruction cache refills to branch</cell></row><row><cell></cell><cell>misses ratio</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Fig. 5. Performance improvement (execution time reduction) of different decision tree model depths over the default prefetcher on SPEC CPU benchmarks compiled with gcc-12.</figDesc><table><row><cell>Performance improvement</cell><cell>1.0% 0.0% 1.0% 2.0% 3.0% 4.0% 5.0% 6.0%</cell><cell>1 54 1 54 8 55 7 GE OM EA N 1 2 4</cell></row><row><cell cols="3">Fig. 4. Performance improvement (execution time reduction) of different deci-</cell></row><row><cell cols="3">sion tree model depths over the default prefetcher on SPEC CPU benchmarks.</cell></row><row><cell>Performance improvement</cell><cell>1.0% 0.0% 1.0% 2.0% 3.0% 4.0% 5.0% 6.0%</cell><cell>50 0 50 2 50 5 52 0 52 3 52 5 53 1 54 1 54 8 55 7 GE OM EA N 1 2 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>-s qu ar e db -s ho ot ou t de c-tre e do tty fin ag le -h ttp fj-km ea ns fu tu re -g en et ic ga us s-m ix lo g-re gr es sio n m ne m on ics m ov ie -le ns na ive -b ay es ne o4 j-a na lyt ics pa ge -ra nk pa r-m ne m on ics ph ilo so ph er s re ac to rs rx -s cr ab bl e sc al a-do ku sc al a-km ea ns sc al a-st m -b en ch 7 sc ra bb le GE OM EA N</figDesc><table><row><cell>Performance improvement</cell><cell>av ro ra ba tik -lg bi oj av a-lg ca ss an dr a ec lip se fo p gr ap hc hi h2 h2 o-ai jm e-lg ka fk a lu in de x lu se ar ch pm d su nf lo w to m ca t tra de be an s tra de so ap xa la nj zx in g GE OM EA N 8.0% 6.0% 4.0% 2.0% 0.0% 2.0% 4.0% 8.0% 6.0%</cell></row><row><cell cols="2">Fig. 6. Performance improvement (execution time reduction) of a runtime</cell></row><row><cell cols="2">prefetcher selection tree of depth 4 trained on SPEC CPU over the default</cell></row><row><cell cols="2">prefetcher on DaCapo benchmarks.</cell></row><row><cell>Performance improvement</cell><cell>ak ka -u ct al s ch i5.0% 0.0% 5.0% 10.0% 15.0% 20.0% 30.0% 25.0%</cell></row></table><note><p>Fig. 7. Performance improvement (execution time reduction) of a runtime prefetcher selection tree of depth 4 trained on SPEC CPU over the default prefetcher on Renaissance benchmarks.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work was supported in part by <rs type="person">Ampere Computing</rs> and <rs type="funder">NSF</rs> grant <rs type="grantNumber">CCF-1763848</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_2fva6rq">
					<idno type="grant-number">CCF-1763848</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning-based Phase-aware Multi-core CPU Workload Forecasting</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gerstlauer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3564929</idno>
		<ptr target="https://doi.org/10.1145/3564929" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2022-12">Dec. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The DaCapo benchmarks: Java benchmarking development and analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bentzur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Guyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hosking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jump</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E B</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Phansalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stefanovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vandrunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dincklage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiedermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN conference on Object-Oriented Programing, Systems, Languages, and Applications</title>
		<meeting>the ACM SIGPLAN conference on Object-Oriented Programing, Systems, Languages, and Applications</meeting>
		<imprint>
			<date type="published" when="2006-10">Oct. 2006</date>
			<biblScope unit="page" from="169" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">COPE: Reducing Cache Pollution and Network Contention by Inter-tile Coordinated Prefetching in NoC-based MPSoCs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palesi</surname></persName>
		</author>
		<idno type="DOI">10.1145/3428149</idno>
		<ptr target="https://doi.org/10.1145/3428149" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Design Automation of Electronic Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2021-12">Dec. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Coordinated control of multiple prefetchers in multi-core systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2009-12">Dec. 2009</date>
			<biblScope unit="page" from="316" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning memory access patterns</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v80/hashemi18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07">Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1919" to="1928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Near-side prefetch throttling: adaptive prefetching for high-performance many-core processors</title>
		<author>
			<persName><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Bois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vandriessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eyerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hur</surname></persName>
		</author>
		<idno type="DOI">10.1145/3243176.3243181</idno>
		<ptr target="https://doi.org/10.1145/3243176.3243181" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>the International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2018-11">Nov. 2018</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Machine Learning for Fine-Grained Hardware Prefetcher Control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hiebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3337821.3337854</idno>
		<ptr target="https://doi.org/10.1145/3337821.3337854" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Processing</title>
		<meeting>the International Conference on Parallel Processing</meeting>
		<imprint>
			<date type="published" when="2019-08">Aug. 2019</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rethinking Belady&apos;s Algorithm to Accommodate Prefetching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2018-06">Jun. 2018</date>
			<biblScope unit="page" from="110" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Managing Prefetchers With Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="108" />
			<date type="published" when="2022-07">Jul. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">To hardware prefetch or not to prefetch? a virtualized environment study and core binding approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Wong</surname></persName>
		</author>
		<idno type="DOI">10.1145/2451116.2451155</idno>
		<ptr target="https://doi.org/10.1145/2451116.2451155" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural support for programming languages and operating systems</title>
		<meeting>the International Conference on Architectural support for programming languages and operating systems</meeting>
		<imprint>
			<date type="published" when="2013-03">Mar. 2013</date>
			<biblScope unit="page" from="357" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">AREP: Adaptive Resource Efficient Prefetching for Maximizing Multicore Performance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Laurenzanoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marsy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Black-Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Architecture and Compilation</title>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
			<biblScope unit="page" from="367" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Division of Labor: A Effective Approach to Prefetching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kondguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2018-06">Jun. 2018</date>
			<biblScope unit="page" from="83" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Application-aware prefetch prioritization in on-chip networks</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2012-09">Sep. 2012</date>
			<biblScope unit="page" from="441" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bandwidth-Aware Dynamic Prefetch Configuration for IBM POWER8</title>
		<author>
			<persName><forename type="first">C</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feliu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>G?mez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sahuquillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1970" to="1982" />
			<date type="published" when="2020-08">Aug. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Intelligent Adaptation of Hardware Knobs for Improving Performance and Power Consumption</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bertran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eichenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moret?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2021-01">Jan. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SPAC: A Synergistic Prefetcher Aggressiveness Controller for Multi-Core Systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Panda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3740" to="3753" />
			<date type="published" when="2016-12">Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Renaissance: benchmarking suite for parallel applications on the JVM</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prokopec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ros?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leopoldseder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Duboscq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>T?ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Studener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bulej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Villaz?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>W?rthinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Binder</surname></persName>
		</author>
		<idno type="DOI">10.1145/3314221.3314637</idno>
		<ptr target="https://doi.org/10.1145/3314221.3314637" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2019-06">Jun. 2019</date>
			<biblScope unit="page" from="31" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">SPEC CPU?2017</title>
		<ptr target="https://www.spec.org/cpu2017/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feedback Directed Prefetching: Improving the Performance and Bandwidth-Efficiency of Hardware Prefetchers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on High Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2007-02">Feb. 2007</date>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
