<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Reproducible Descriptions of Neuronal Network Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-08-07">August 7, 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Eilen</forename><surname>Nordlie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Sciences and Technology</orgName>
								<orgName type="institution">Norwegian University of Life Sciences</orgName>
								<address>
									<settlement>Aas</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc-Oliver</forename><surname>Gewaltig</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Honda Research Institute Europe GmbH</orgName>
								<address>
									<settlement>Offenbach, Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hans</forename><forename type="middle">Ekkehard</forename><surname>Plesser</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Sciences and Technology</orgName>
								<orgName type="institution">Norwegian University of Life Sciences</orgName>
								<address>
									<settlement>Aas</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Biomedical Computing</orgName>
								<orgName type="laboratory">Simula Research Laboratory</orgName>
								<address>
									<settlement>Lysaker</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">RIKEN Brain Science Institute</orgName>
								<address>
									<addrLine>Wako-shi</addrLine>
									<settlement>Saitama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Norwegian University of Life Sciences. M-OG is a paid employee of Honda Research Institute Europe GmbH</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Reproducible Descriptions of Neuronal Network Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-08-07">August 7, 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">44CC204E79C541BA9DF91BABCAA1531E</idno>
					<idno type="DOI">10.1371/journal.pcbi.1000456</idno>
					<note type="submission">Received March 17, 2009; Accepted July 1, 2009;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Progress in science depends on the effective exchange of ideas among scientists. New ideas can be assessed and criticized in a meaningful manner only if they are formulated precisely. This applies to simulation studies as well as to experiments and theories. But after more than 50 years of neuronal network simulations, we still lack a clear and common understanding of the role of computational models in neuroscience as well as established practices for describing network models in publications. This hinders the critical evaluation of network models as well as their re-use. We analyze here 14 research papers proposing neuronal network models of different complexity and find widely varying approaches to model descriptions, with regard to both the means of description and the ordering and placement of material. We further observe great variation in the graphical representation of networks and the notation used in equations. Based on our observations, we propose a good model description practice, composed of guidelines for the organization of publications, a checklist for model descriptions, templates for tables presenting model structure, and guidelines for diagrams of networks. The main purpose of this good practice is to trigger a debate about the communication of neuronal network models in a manner comprehensible to humans, as opposed to machine-readable model description languages. We believe that the good model description practice proposed here, together with a number of other recent initiatives on data-, model-, and softwaresharing, may lead to a deeper and more fruitful exchange of ideas among computational neuroscientists in years to come. We further hope that work on standardized ways of describing-and thinking about-complex neuronal networks will lead the scientific community to a clearer understanding of high-level concepts in network dynamics, and will thus lead to deeper insights into the function of the brain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Science advances human knowledge through learned discourse based on mutual criticism of ideas and observations. This discourse depends on the unambiguous specification of hypotheses and experimental procedures-otherwise any criticism could be diverted easily. Moreover, communication among scientists will be effective only if a publication evokes in a reader the same ideas as the author had in mind upon writing <ref type="bibr" target="#b0">[1]</ref>.</p><p>Scientific disciplines have over time developed a range of abstract notations, specific terminologies and common practices for describing methods and results. These have lifted scientific discourse from handwaving arguments about sloppily ascertained observations to precise and falsifiable reasoning about facts established at a well-defined level of certainty. Well chosen notation and systematization, from Linne ´'s classification of flora and fauna, via the periodic system of the elements to Feynman diagrams have widened the minds of scientists and continue to induce new discoveries.</p><p>Matrix notation provides an illustrative example of the power of notation. Consider a system of three differential equations</p><formula xml:id="formula_0">_ x x~axzbyzcz _ y y~dxzeyzkz _ z z~lxzmyznz:<label>ð1Þ</label></formula><p>Defining p 1 ~x, p 2 ~y, p 3 ~z and A 11 ~a, A 12 ~b, etc., we can write this more compactly as</p><formula xml:id="formula_1">_ p p i ~X 3 j~1 A ij p j for i~1,2,3:<label>ð2Þ</label></formula><p>Introducing matrix notation simplifies this further to</p><formula xml:id="formula_2">_ p p~A : p,<label>ð3Þ</label></formula><p>with multiple advantages: the equation is much more compact, since the summing operation is hidden, as well as the system size; most importantly, the equation is essentially reduced to a simple multiplication. This invites further exploration.</p><p>From the study of one-dimensional differential equations, we know that</p><formula xml:id="formula_3">_ x x~ax<label>ð4Þ</label></formula><p>has the solution</p><formula xml:id="formula_4">x(t)~e at x 0 :<label>ð5Þ</label></formula><p>Comparing the shape of Eq. 4 to Eq. 3 immediately suggests the following solution to Eq. 3</p><formula xml:id="formula_5">p(t)~e At : p 0 ,<label>ð6Þ</label></formula><p>with the formal definition</p><formula xml:id="formula_6">e At ~X ? j~0 (At) j j! :<label>ð7Þ</label></formula><p>This formal solution can be made rigorous, and underlies the exact integration method <ref type="bibr" target="#b1">[2]</ref>. It is hard to see how the inspiration to write down a solution such as Eq. 3 might have arisen from the original form of the differential equations in Eq. 1.</p><p>Note that even though the notion and notation of vectors and matrices is more abstract and, thus, more compact than the original formulation of Eq. 1, it does not lose any detail. The variables x, y, and z from the original system Eq. 1 are still present, not as separate entities, but as components of the vector p. The specific combinations of additions and multiplications are embedded in the multiplication rule for vectors. To arrive at the concise notation of Eq. 2 we must introduce the new mathematical concept of vector spaces. This example illustrates how scientific notation progresses together with scientific concepts.</p><p>Computational neuroscience lags behind mathematics and other fields of science in standardization, expressiveness and power of notation. We assess here the current scientific practice of describing computational models of the brain. We focus on network models built from large numbers of rather simple neurons with an aim to test hypotheses on aspects of brain function. Specifically, we study 14 papers chosen mainly from visual neuroscience <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>; see Table <ref type="table">1</ref> for a brief summary of the models. Our selection of papers is by no means comprehensive, although we have attempted to cover past as well as current work, and to include a range of different approaches to the description of neuronal network models.</p><p>A central motivation for our work is that sharing of materials, methods, and data in the life sciences has received increased attention in recent years, to a large part driven by developments in molecular biology. The UPSIDE (uniform principle for sharing integral</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Summary</head><p>Scientists make precise, testable statements about their observations and models of nature. Other scientists can then evaluate these statements and attempt to reproduce or extend them. Results that cannot be reproduced will be duly criticized to arrive at better interpretations of experimental results or better models. Over time, this discourse develops our joint scientific knowledge. A crucial condition for this process is that scientists can describe their own models in a manner that is precise and comprehensible to others. We analyze in this paper how well models of neuronal networks are described in the scientific literature and conclude that the wide variety of manners in which network models are described makes it difficult to communicate models successfully. We propose a good model description practice to improve the communication of neuronal network models.</p><p>Table <ref type="table">1</ref>. Papers analyzed in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>Abbr. Description</p><p>Brunel <ref type="bibr" target="#b2">[3]</ref> B Unordered network of two populations of integrate-and-fire neurons with current-injecting synapses; random external input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Destexhe et al. [4] D</head><p>One-dimensional network with two layers of point neurons with several ionic currents and conductance based synapses.</p><p>Haeusler and Maass <ref type="bibr" target="#b4">[5]</ref> HM Unordered six-population model of Hodgkin-Huxley-type neurons with conductance-based synapses with short-term dynamics.</p><p>Hayot and Tranchina <ref type="bibr" target="#b5">[6]</ref> HT Two-dimensional network with three populations of firing-rate neurons; spatiotemporally patterned input.</p><p>Hillenbrand and van Hemmen <ref type="bibr" target="#b6">[7]</ref> HvH Model of corticogeniculate loops that tests if the visual cortex controls the spatiotemporal structure of cortical receptive fields via feedback to the lateral geniculate nucleus.</p><p>Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref> IE ''Whole brain'' model covering several brain areas, each composed of layered two-dimensional networks of oscillator neurons with plastic, conductance-based synapses.</p><p>Kirkland and Gerstein <ref type="bibr" target="#b8">[9]</ref> KG Two-dimensional model of three layers of integrate-and-fire neurons with conductance-based synapses driven by spatiotemporally pattered stimuli.</p><p>Lumer et al. <ref type="bibr" target="#b9">[10]</ref> L Two-dimensional model of ten layers, with two neuron populations per layer; integrate-and-fire neurons with conductance-based synapses.</p><p>Marin ˜o et al. <ref type="bibr" target="#b10">[11]</ref> M Two-dimensional model of two layers of Hodgkin-Huxley-type neurons with conductance-based synapses. data and materials expeditiously) doctrine proposed by the Committee on Responsibilities of Authorship in the Biological Sciences of the National Academies of Science (USA) defines the most comprehensive set of rules for data sharing <ref type="bibr" target="#b16">[17]</ref> and has been adopted by several leading journals <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. Sharing of experimental data has received increasing attention in the neurosciences recently <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>. Sejnowski et al. <ref type="bibr" target="#b23">[24]</ref> gave a fine account of the role of modeling in neuroscience 20 years ago, when computational neuroscience as a field just ''took off''. They characterized models as ''provisional framework[s] for organizing possible ways of thinking about the nervous system.'' Since then, modeling activity has multiplied, but reflection about the modeling process has hardly kept up.</p><p>Computational neuroscientists are only now beginning to pay increasing attention to the role of models and simulations, as well as preconditions for the successful exchange of models, as witnessed by recent workshops <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, collaborative reviews of simulation software <ref type="bibr" target="#b26">[27]</ref>, and the development of software providing common interfaces <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> and run-time interaction of simulations on different simulators <ref type="bibr" target="#b29">[30]</ref>. Most of these discussions have been rather technical, though, and little attention has been paid to the intellectual gain as part of the modeling process or to the issue of how to convey models and simulations best in scientific publications. Researchers in ecology, systems biology and physiome modeling appear to be significantly ahead in these issues <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref>. Indeed, De Schutter <ref type="bibr" target="#b37">[38]</ref> recently suggested that computational neuroscience has much to learn from systems biology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The nature of neuronal network models</head><p>Philosophers of science have yet to develop a robust definition and interpretation of models and simulations <ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref>. Most of that debate focuses on models in physics, but Peck <ref type="bibr" target="#b30">[31]</ref> gives an interesting review of models and simulations in ecology, while Aumann <ref type="bibr" target="#b31">[32]</ref> thoroughly discusses requirements of successful modeling of ecological systems; Wooley and Lin <ref type="bibr" target="#b42">[43]</ref> give an overview of modeling and simulation in biology. The only comparable assessment of the role of models and simulations in computational neuroscience is part of a book chapter by Clark and Eliasmith <ref type="bibr" target="#b43">[44]</ref>. A recent appraisal of the role of models in neuroscience <ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref>, based on a general reappraisal of the role of computational models by Humphreys <ref type="bibr" target="#b47">[48]</ref>, has mostly focused on connectionist models.</p><p>We shall not attempt to provide a general analysis of models and simulations in computational neuroscience here. Our aim is more practical: to promote standards for the description of neuronal network models in the literature, to further sharing of knowledge and facilitate critique. Thus, our focus is narrower yet than that of <ref type="bibr">Eliasmith and Anderson [49,</ref><ref type="bibr">Ch. 1.5]</ref>, who proposed a ''Methodology'' of neural engineering. For our purposes, we adopt a quite restricted working definition of a model: A neuronal network model is an explicit and specific hypothesis about the structure and microscopic dynamics of (a part of) the nervous system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Several aspects of this definition deserve note:</head><p>N The model must be explicit, i.e., all aspects of the model must be specified.</p><p>N The model must be specific, i.e., all aspects must be defined so detailed that they can be implemented unequivocally.</p><p>N The model specifies the structure (placement and type of network elements; source, target and type of connections) and dynamics of components (ion channels, membrane potential, spike generation and propagation).</p><p>N The model does not describe the dynamics of the model as a whole, which is an emerging property of the model.</p><p>The model is first of all a mental model formed in the brain of a researcher. It is her hypothesis about the function of a part of the brain. Heinrich Hertz expressed this idea first in his textbook ''Prinzipien der Mechanik'' in 1894: ''We make for ourselves internal images or symbols of the external objects, and we make them in such a way that the consequences of the images that are necessary in thought are always images of the consequences of the depicted objects that are necessary in nature Once we have succeeded in deriving from accumulated previous experience images with the required property, we can quickly develop from them, as if from models, the consequences that in the external world will occur only over an extended period or as a result of our own intervention.'' (cited from <ref type="bibr" target="#b39">[40]</ref>).</p><p>Scientific progress depends critically on the ability of neuroscientists to communicate models, i.e., hypotheses, among each other: When Anna presents her model to Bob and Charlie-will both build the same mental model in their minds as Anna? Or will some nuances be lost, some aspects interpreted differently, some parts misunderstood? Only a precise, unambiguous notation for models will allow Anna, Bob and Charlie to discuss their individual understandings of the model and thus to truly share models. Efficient communication dictates that scientists should use a common notation to describe their models, as it is demanding to thoroughly acquaint ourselves with any advanced notation.</p><p>It is tempting to consider implementations of neuronal network models in a specific simulator software as a sufficient model description, as it is explicit, specific and describes structure and dynamics. We believe this to be a fallacy. Implementations come most often in the form of scripts or computer programs, which tend to be difficult to reverse engineer: It is simply not possible to infer the overall network structure from the bits and pieces of a large script. Secondly, most simulation scripts rely on properties hidden in a simulator, which may even change as a simulator evolves over time. Translating a given implementation first to a mental model and then to a second simulator software for independent testing, opens for errors in both translation steps. We believe that while scientific productivity benefits from sharing simulation code through repositories such as ModelDB <ref type="bibr" target="#b49">[50]</ref> and standard languages such as NeuroML <ref type="bibr" target="#b50">[51]</ref>, implementations do not fill the need for precise human-readable model descriptions in the scientific literature. Based on experiences in systems biology, Wimalaratne et al. <ref type="bibr" target="#b35">[36]</ref> stress that it is crucial to identify biophysical concepts as logical abstractions in order to create meaningful and re-usable model implementations.</p><p>It is also worth mentioning that the translation of a mathematical model into a computer program is lossy and irreversible. The translation is lossy due to the finite precisions of computers. For example, most real numbers cannot be represented on a computer. This is obviously problematic in the analysis of chaotic systems where small errors have a big influence on the state trajectories of the system. The translation is generally not reversible, because the commonly used programming languages are not accessible to formal analysis. It is generally not even possible to prove that a function, implemented in a common language such as C++, is correct. In some cases, one may even have to add equations to models in the computer implementation to preserve stability and obtain results in agreement with experimental observation <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>While mathematical model descriptions can be treated with formal methods, their computer implementations generally cannot. This means that if we want to validate the claims about a model, we must start from the description in the scientific publication. If we start from the model implementation of the authors, we can never refute that the model may be faulty or doing something entirely different than what was claimed in the publication. Taking a given implementation of a model or hypothesis and simply executing it again does not constitute independent testing, nor does it fulfill the criterion of falsifiability: the same program run twice should yield identical results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>We shall now sketch key aspects of neuronal network model descriptions: what is described where and by what means in the computational neuroscience literature? This will introduce the conceptual framework for the subsequent analysis of the papers given in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Components of model descriptions</head><p>A complete model description must cover at least the following three components: (i) The network architecture, i.e., the composition of the network from areas, layers, or neuronal sub-populations. (ii) The network connectivity, describing how neurons are connected among each other in the network. In most cases, connectivity will be given as a set of rules for generating the connections. (iii) The neuron and synapse models used in the network model, usually given by differential equations for the membrane potential and synaptic currents or conductances, rules for spike generation and post-spike reset. Model descriptions should also contain information about (iv) the input (stimuli) applied to the model and (v) the data recorded from the model, just as papers in experimental neuroscience do, since a reproduction of the simulations would otherwise become impossible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Means of model descriptions</head><p>Neuronal network models are usually described by a combination of five means: prose (text), equations, figures, tables and pseudocode. We shall discuss these in turn.</p><p>Prose is a powerful means of communicating ideas, intentions and reasons. It is flexible and, if used carefully, precise. Unfortunately, prose can easily-often unintentionally-become ambiguous. Previous knowledge and ideas in the mind of the reader will shape the reader's understanding of a textual description of a model and may lead to misunderstandings. Prose that strives to be strictly unambiguous and provide all required detail, on the other hand, will often be difficult to read.</p><p>Mathematical notation (equations) is compact and unambiguous. Suitably chosen notation compresses complex relationships in concise expressions, which allow for further manipulation in our mind, as illustrated by the matrix exponentiation in the Introduction. The now common mathematical notation emerged alongside the great scientific achievements of Newton, Leibniz and others between the 17 th and 19 th century <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b53">54]</ref>. Unfortunately, not all mathematical notation is understood easily, and variations in notation, as is common in computational neuroscience (cf. Table <ref type="table">2</ref>), can present serious obstacles to effective communication.</p><p>Figures communicate the architecture and connectivity of network models well, since vision is the dominating sense in most humans. Most readers will first scan the figures in a paper to get an overview of what the paper is about, using figure captions as a guide, and read the full text of the paper only later. Thus, figures and captions will shape the initial idea a reader forms about a neuronal network model, and the ideas thus established may be difficult to correct through textual description. Specifying complex networks precisely in figures can be difficult, and disciplines depending strongly on exact diagrams, such as mechanical and electrical engineering, have developed precise standards for such diagrams (see, e.g., <ref type="bibr" target="#b54">[55]</ref>). Systems biologists have yet to arrive at a definite standard for depicting their models, but they at least have an open debate about graphical representations <ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref>.</p><p>Tables are a useful means of organizing data, especially model parameters. Data presented in table form is far more accessible than data dispersed throughout a text, facilitating, e.g., comparisons of parameter choices between different papers and proofreading of simulation scripts against papers.</p><p>Pseudocode is often used to present algorithms in concise, human readable form, without resorting to a specific programming language. It will be an efficient means of communication only if the pseudocode notation is sufficiently well established to be unambiguous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Placement of model descriptions</head><p>The placement of model descriptions within a scientific publication depends on the focus of the paper and the journal it is published in. Traditionally, model descriptions were either given in the body text of a paper, or in an appendix. It has now become common to give only brief model overviews in the paper itself, and to relegate detailed model descriptions to supplementary material published online, or even to place simulation code online in community repositories such as ModelDB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We will now analyze model descriptions in the 14 papers listed in Table <ref type="table">1</ref>. We study the placement of model descriptions in publications first, followed by a general discussion of the means of description used. We will then investigate in more detail how Table <ref type="table">2</ref>. Membrane potential equations for some papers using conductance-based neurons. specific aspects of models are described. Finally, we propose a good model description practice.</p><formula xml:id="formula_7">Destexhe et al. [4, Eq. 2] C m _ V V R ~{g L (V R {E L ){I Ts {I Na {I K {I AMPA {I GABAA R Lumer et al. [10] t m dV i (t) dt ~{V i zE 0 { X j g j (t)(V i {E j ) Tao et al. [13, Eq. 1] dv j dt ~{g L (v j {V L ){g j E (t)(v j {V E ){g j I (t)(v j {V I )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Placement of description</head><p>Figure <ref type="figure" target="#fig_2">1</ref> summarizes the placement of the description of architecture, connectivity and neuron and synapse models, respectively, across all papers; for details, see Tables <ref type="table">S1,</ref><ref type="table">S2</ref>, S3 in the Supporting files. All papers present at least an overview of the model they investigate in the main body of the paper. Details are frequently provided in supplementary material available online, especially in more recent papers; appendices are used to a lesser degree. Model descriptions in some papers are incomplete in the sense that the authors refer to other publications for details of neuronal dynamics in particular.</p><p>Within the body text of the paper, model descriptions were placed in the ''Methods'' sections in 10 of the 14 papers surveyed, even though the neuronal network model is in itself a product of significant scientific analysis and synthesis <ref type="bibr" target="#b31">[32]</ref>. As such, it would rather belong in the ''Results'' section of a paper. Whether the placement of the model description in the ''Methods'' section genuinely reflects the way in which authors perceive their models, or rather is a consequence of editorial policies shaped by ''wet'' neuroscience, is not clear at present. It is interesting to note in this context that papers in theoretical physics generally do not follow the strict ''methods-results-discussion'' pattern.</p><p>We would like to point out two interesting aspects of the placement of model descriptions. First, the text of a paper manuscript, including the appendix, undergoes thorough peer review and copy editing, ensuring high standards in content and presentation. It is not, at present, clear whether all material published as supplementary material receives the same scrutiny in the review process; it is often not copy-edited to the same standards as the paper proper. Second, source code published in community repositories represents an implementation of a model, not the model itself <ref type="bibr" target="#b51">[52]</ref>. It can thus serve only as a service to the community to facilitate code-reuse, but not to communicate the content of the model proper.</p><p>Incidentally, none of the 14 papers surveyed here describes reuse of neuronal models available in repositories, such as ModelDB <ref type="bibr" target="#b49">[50]</ref>. Nor does any paper mention that the source code for the model implemented in the paper was made available to the community, even though models from several papers are at present available from ModelDB <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15]</ref>. In recent years, though, there appears to be a slowly growing trend to explicitly reference and re-use existing models from ModelDB; see http://senselab. med.yale.edu/modeldb/prm.asp for an up-to-date list (Michael Hines, personal communication).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Means of model descriptions</head><p>Figure <ref type="figure" target="#fig_3">2</ref> shows that equations are mostly used to describe the dynamics of model neurons, while connections are most often presented in a combination of prose and figures, occasionally in form of pseudocode. We will review the quality of these descriptions in detail below. Table <ref type="table" target="#tab_0">3</ref> shows how parameters are presented in papers. It regrettably indicates that too few authors make parameters easily accessible in tables.</p><p>Network model descriptions in the literature show no consistent order of description. Among the papers surveyed here, six begin with a description of the neuron models and then proceed to network architecture, seven papers use the opposite order, while one paper mixes the description of neurons and network. We find the latter option least useful to the reader.</p><p>Authors differ greatly in their efforts to anchor their models in empirical data. Destexhe et al. <ref type="bibr" target="#b3">[4]</ref> go to great lengths to justify the design of their neuron and synapse models with respect to the neurophysiological literature. They thus provide the synthesis document proposed by Aumann <ref type="bibr" target="#b31">[32]</ref> as the basis of any modeling effort. Unfortunately for those readers who want to investigate the resulting model, though, model description and justification are tightly intertwined in the terse methods section, making it quite demanding to extract the model description as such.</p><p>Among all papers surveyed here, only Destexhe et al. <ref type="bibr" target="#b3">[4]</ref> and Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref> show responses of individual synaptic conductances and individual neurons to test stimuli, while all other authors only show responses of the entire network. This means that researchers who attempt to re-implement a model and find themselves unable to reproduce the results from a paper, will not   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network architecture</head><p>Descriptions of network architecture become challenging as network complexity increases. Networks with a small number of populations, random connectivity and no spatial structure are easily described in a few lines of prose, as in Brunel's paper <ref type="bibr" target="#b2">[3]</ref>. A combination of prose and simple figures is usually sufficient to describe architecture of networks composed from a small number of one-or two-dimensional layers of individual neurons; examples are Destexhe et al. <ref type="bibr" target="#b3">[4]</ref> and Kirkland and Gerstein <ref type="bibr" target="#b8">[9]</ref>.</p><p>Complex models spanning several brain areas with detailed spatial, layered, and functional substructure, such as Lumer et al. <ref type="bibr" target="#b9">[10]</ref> and Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref>, are more challenging to describe. Authors generally adopt a top-down approach, giving first an overview of the brain areas involved, before detailing the structure of the individual areas. In models of systems with clearly defined signal flow, areas are often visited in the predominant order of signal flow <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref>, while others present the more complex cortical structures before descending to subcortical structures <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>The most detailed explicit model studied here is the thalamocortical model presented by Lumer et al. <ref type="bibr" target="#b9">[10]</ref>. The description of the cortical areas in this model (Vp and Vs), while complete, lacks in our opinion the clarity desirable of a good model description, and may thus help to identify rules for ideal model descriptions. For one, discussions on model design and properties are embedded in the model description, e.g., the reduction of a total of 32 ''combinations of response selectivities'' to just two included in the model, and a comparison of the number of neurons in the model to that found in animals. We believe that design decisions and model review should be kept separate from the model description proper for the sake of clarity, since they are independent intellectual endeavours <ref type="bibr" target="#b31">[32]</ref>. Second, Lumer et al. mix different views of their layer architecture without providing sufficient guidance to the reader. They begin by describing the Vp layer as a grid of 868 macro-units, with two ''selectivities within a macrounit'', each containing ''a collection of 565 topographic elements, each of which corresponded to a contiguous location in retinal space'', before proceeding to state that ''[t]opographic elements in Vp were organized in maps of 40640 elements for each of the two modeled orientation selectivities.'' We find it difficult to interpret this description unambiguously. We are in particular in doubt about the localization of macro-units and topographic elements in retinal space. In our view, the most parsimonious interpretation is as follows: 565 topographic elements placed in each of 868 macro-units result in a grid of 40640 topographic elements.'' This interpretation is sketched in Fig. <ref type="figure" target="#fig_4">3</ref>.</p><p>Another interesting aspect is that model composition is often described from a perspective orthogonal to the description of connections. Lumer et al. <ref type="bibr" target="#b9">[10]</ref>, e.g., present the primary thalamus and cortex as grids of 40640 topographical units, each containing an excitatory and an inhibitory neuron (thalamus) and a microcolumn composed of 10 neurons organized in three laminae (cortex). Connections are then described by looking at this architecture from an orthogonal perspective: Thalamus is described as two layers, one of excitatory and one of inhibitory neurons, while cortex is split into six layers, one of excitatory and one of inhibitory neurons for each of the three laminae in the model. We believe that it may be more sensible to base the model description on the perspective used in defining connections, as connectivity is the central aspect of a network model.</p><p>Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref> present a significantly more complex model, covering the entire human cortex and thalamus. Concerning the spatial placement, they only state that ''[n]euronal bodies are allocated randomly on the cortical surface, whose coordinates were obtained from anatomical MRI.'' No further information is given on how MRI measurements were converted to neuron densities in space. Thus, even if one had access to MRI data of the human brain, it would be difficult to reproduce the neuron distribution investigated by Izhikevich and Edelman. In such cases it would be advantageous to either use datasets available from community databases or to make data available to others.</p><p>Figures of network architecture vary widely between papers. We will discuss them in the following section together with connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connections</head><p>Describing the connections well is the most challenging task in presenting a neuronal network model. For networks with random connections and no spatial structure, connectivity is easily described in a few sentences <ref type="bibr" target="#b2">[3]</ref>. Haeusler and Maass <ref type="bibr" target="#b4">[5]</ref> additionally represent connection strengths and probabilities in a figure; this works well for their six-population model. If yet more populations were involved, such a figure would soon become cluttered, and it becomes more useful to present connection parameters in tables , cf. supplementary material in ref. <ref type="bibr" target="#b7">[8]</ref>. Even in these simple networks, care must be taken to specify details: N May neurons connect to themselves? N May there be multiple connections between any pair of neurons?</p><p>N Are connection targets chosen at random for a fixed sender neuron (divergent connection), senders chosen at random for fixed target (convergent connection), or are sender and receiver chosen at random for each connection? Few authors are explicit on all these points, although these choices may have significant consequences for network dynamics (Tom Tetzlaff, personal communication; see also Kriener et al. <ref type="bibr" target="#b59">[60]</ref>).</p><p>Models incorporating spatial structure have more complex connection patterns, which we will call topographic connections, since they usually describe the spatial distribution of connection targets relative to the spatial location of the sending neuron, i.e., connections are typically described as divergent connections. In most cases, connections have a random component: they are created with a certain probability. In simple cases, such as Kirkland and Gerstein <ref type="bibr" target="#b8">[9]</ref>, connections are made to neurons in a rectangular mask with equal probability. In more complex models, connection probability depends on the relative locations of the neurons that are candidates for a connection, e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. Unfortunately, few authors provide the equations for these probability functions; Marin ˜o et al. <ref type="bibr" target="#b10">[11]</ref> is a laudable exception. It is somewhat paradoxical if papers present long tables of parameters for these connection probability functions, but do not provide the equation into which these parameters enter.</p><p>Marin ˜o et al. <ref type="bibr" target="#b10">[11]</ref> are the only authors who explicitly discuss self-connections (in their supplementary material), and as far as we can see, no authors have discussed whether multiple connections between any two neurons may be created. Another neglected issue is precisely how probabilistic connections are created. The following approach seems to be implied: For each pair of neurons from the sender and target population, a connection is created if a random number is smaller than the connection probability for the pair. But one might equally well determine the total number of connections to be made first, and then distribute the connections according to the spatial probability profile <ref type="bibr" target="#b60">[61]</ref>. Such schemes offer significant performance gains <ref type="bibr" target="#b61">[62]</ref>. A complete specification of the connection algorithm should thus be given.</p><p>Among the papers surveyed, Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref> has by far the most complex connectivity and the authors go to great lengths to present gray-matter connectivity in figures, tables, and prose. Alas, some information appears to be missing: It is not clear from the text exactly how connections are distributed within the axonal spans, and how they are distributed across dendritic compartments of neurons with more than one compartment in a cortical layer. We have also been unable to find specific information on how synaptic weights and delays were assigned to connections. Finally, no details are provided about the whitematter (long-range) connections, which were based on diffusiontensor imaging (DTI) data. Without access to the DTI data it is thus impossible to re-implement the model presented.</p><p>Paper authors draw network diagrams in quite different ways, both in the overall style of their diagrams and in use of symbols. Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref> have illustrated their brain model using diagrams presenting significantly more detail than in the diagrams shown in our Fig. <ref type="figure" target="#fig_5">4</ref>. Unfortunately, we cannot reproduce Figures <ref type="figure" target="#fig_3">2</ref> and<ref type="figure" target="#fig_10">8</ref> from the supplementary material of the paper by Izhikevich and Edelman here due to copyright issues; the figures are available on the internet at http://www.pnas.org/ content/105/9/3593.figures-only and http://www.pnas.org/content/105/9/3593/suppl/DC1, respectively. Their diagrams, though, provide so much detail of interest to the re-implementer, that the reader will have difficulty to form a clear conceptual model from the diagram. This is in many ways the curse of complex models as the following analogy may illustrate: when a physicist or electrical engineer sees a diagram of an RLC circuit, she will intuitively ''see'' the circuit oscillate. When presented with the complete wiring diagram for a modern analog radio receiver, though, it is hardly likely she will ''hear the music''. The figure in the style of Haeusler and Maass <ref type="bibr" target="#b4">[5]</ref> takes a middle ground. Since the individual populations are homogeneous, they can be represented by one circle each, with annotated lines providing information about connection structure and parameters. By marking connection strength through line width and differentiating excitation and inhibition by line color, the figure appeals quite directly to our intuition. It is clear, though, that any further populations would increase the complexity of the diagram to the point of illegibility.</p><p>There is no established standard for the order in which connections within a network are described. Some authors proceed from local connectivity (e.g., intracortical intralaminar) towards global connectivity <ref type="bibr" target="#b9">[10]</ref>. Others rather follow the signal flow through the network, from retina via LGN to cortex, e.g., Kirkland and Gerstein <ref type="bibr" target="#b8">[9]</ref>, Hayot and Tranchina <ref type="bibr" target="#b5">[6]</ref>, and Troyer et al. <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neuron and synapse models</head><p>Neuron and synapse models are commonly described by a mixture of prose and equations, cf. Fig. <ref type="figure" target="#fig_3">2</ref>; tables are used inconsistently to present parameters, see Table <ref type="table" target="#tab_0">3</ref>. Some authors do not provide complete model specifications in their paper, but rely heavily <ref type="bibr" target="#b3">[4]</ref> or even entirely <ref type="bibr" target="#b4">[5]</ref> on references to earlier work. While the desire to avoid repetition is understandable, we believe that authors here walk a thin line toward incomprehensibility, especially if the models used are spread over three or more publications. Even though the re-use of neuron model implementations provided in repositories such as ModelDB may save effort and contribute to a standardization in the field, none of the papers we studied made use of available model implementations-or the authors failed to point out that they did.</p><p>Table <ref type="table">2</ref> shows the membrane potential equations found in several papers and demonstrates that there is a reasonable amount of variation in the way this central equation is written down. There is in particular no widespread agreement on whether to include the membrane capacitance C m explicitly in the equation or rather to subsume it in a membrane time constant t m . Some authors, such as Tao et al. <ref type="bibr" target="#b12">[13]</ref>, even chose to normalize the membrane potential equation by defining C m :1. Yet greater variation is found in the representation of synaptic currents. This means that phrases such as ''we use the standard equations for integrate-andfire neurons'', which are not uncommon in the literature, are essentially meaningless, since there are no established ''standard equations'' for integrate-and-fire neurons.</p><p>Spike generation and detection, including subsequent reset and refractory behavior, are usually described in prose, sometimes with interspersed equations. ''V i was reset to … E K ~{90 mV, when it exceeded a threshold of … 251 mV …, at which point a spike was recorded, and relayed …,'' is a typical formulation <ref type="bibr" target="#b9">[10]</ref>. Unfortunately, it does not state precisely how threshold crossings are detected, which times are assigned to spikes, or when exactly the reset is executed. All these issues can have significant consequences for network dynamics <ref type="bibr" target="#b63">[64]</ref><ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b65">[66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Good model description practice: a proposal</head><p>The previous sections have documented a wide variety of approaches to model descriptions in the literature. We believe that this variety is detrimental to the field, as it makes it difficult to communicate neuronal network models correctly and efficiently. At the same time, we believe that the field of computational neuroscience is too young to establish exacting standards for model descriptions. We will return to this problem and its various causes in the discussion. As a middle road, we propose to establish a good model description practice for the scientific literature. We will refer to it as ''good practice'' below for brevity. Some of our suggestions are motivated by a recent analysis of modeling techniques in ecology <ref type="bibr" target="#b31">[32]</ref>, but see also <ref type="bibr" target="#b48">[49]</ref>.</p><p>We propose a practice with the following elements: 1. Guidelines for the organization of a model description in a publication.</p><p>2. Checklists for model descriptions helping authors to present all required information in a useful order. 3. Templates for tables describing the essential aspects and components of a model in a compact, easily accessible manner. 4. Guidelines for diagrams visualizing neuronal network models.</p><p>We will discuss these elements in turn below, followed by more detailed discussions about how to render specific aspects of a network model. As an illustrative example, Figures <ref type="figure" target="#fig_7">5</ref> and<ref type="figure" target="#fig_8">6</ref> provide a concise description of the Brunel <ref type="bibr" target="#b2">[3]</ref> model following the good practice format. A similar description of the Lumer et al. <ref type="bibr" target="#b9">[10]</ref> model is given in Figures <ref type="figure" target="#fig_9">7</ref><ref type="figure" target="#fig_10">8</ref><ref type="figure" target="#fig_11">9</ref>.</p><p>We would like to stress that we present the good practice here to stimulate the debate on model descriptions within the computational neuroscience community. If it is adopted widely throughout the community, it will provide numerous advantages: authors will have guidelines that will allow them to check their descriptions for completeness and unambiguousness; referees will more easily be able to assess the correctness and quality of a model; and readers The paper should be written such that readers who are not interested in model derivation and implementation can skip these sections to proceed directly from the model description to the analysis.</p><p>Many journals impose strict limits on the length of a paper, making it impossible to provide a full model description along with an elaborate model analysis. In this case, authors should consider to split their manuscript in two (or more) separate manuscripts: One describing the model, and the other describing the model analysis. The model paper should include the full description of the model but with the model analysis section reduced to only that information which is needed to validate the model and its implementation. In the analysis paper, authors can cite the model paper and reduce the model description to a brief outline of the model, using the tables proposed below. This should offer sufficient room to include a full account of the model analysis.</p><p>Where a companion paper is infeasible, authors should provide a detailed model description as online supplementary materials, although we see two disadvantages in this case: (i) Supplementary material might not be peer-reviewed according to the same high standards as a separate model paper. (ii) Hiding the model in supplementary material deprives both author and model of the proper credit for the intellectual effort that went into the creation of the model.</p><p>Authors should be encouraged to make their model implementation available through community repositories under suitable licensing terms <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b66">67]</ref>, to promote re-use. We expect professionally managed repositories for neuronal network models to emerge that will give equal weight to human comprehensible and machine readable model descriptions, and curate them according to precisely defined quality standards; such efforts are underway in a number of communities <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref>. Once such a repository is firmly established for computational neuroscience, papers might Checklists for model descriptions. Model descriptions should give the reader a good overview of the overall structure of a model. We suggest a description in prose accompanied by figures. The text should give an introduction to each composite part, i.e., stating the number of parts, their size, and what subparts they consist of. We recommend that authors concisely summarize the information for each part in standardized tables (see panel A in Figures <ref type="figure" target="#fig_9">5, 7,</ref> and<ref type="figure" target="#fig_10">8</ref>) and quote only the most necessary pieces in the text. We will discuss network diagrams in detail below.</p><p>Following the principle that models should be presented topdown, we suggest that authors adhere to the following order when describing the parts of their models:</p><p>1. Model composition 2. Coordinate systems and topology 3. Connectivity 4. Neurons, synapses, and channels 5. Model input, output, and free parameters 6. Model validation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Model implementation</head><p>Not all parts will apply to all models, but using such a checklist (i) ensures that all necessary information is included in the paper; (ii) allows referees to systematically check that all information is given; and (iii), facilitates the comparison with other models. We will address each of the items in the list below.</p><p>Past experience indicates that it is essential to review model descriptions after one has implemented a model <ref type="bibr" target="#b31">[32]</ref>. We strongly suggest that authors carefully compare model description and implementation. This ensures that the description is complete and that any choices made during implementation are duly reflected. If possible (and feasible), one should ask a colleague to re-implement the model based on the description.</p><p>The model composition are the groups, or populations, of neurons in a network model. Populations are either unordered, such as Brunel <ref type="bibr" target="#b2">[3]</ref> and Haeusler and Maass <ref type="bibr" target="#b4">[5]</ref>, or ordered, such as the remaining models in Table <ref type="table">1</ref>.</p><p>A good model description should list all populations of the model along with the used neuron model, their properties, their number, and how each population relates to the modeled system. Authors should name each population and use this name consistently throughout the manuscript. Some populations may Even for random selections, we recommend that authors explicitly define the actual range of indices used, to avoid formulations such as ''we recorded from 50 randomly selected neurons'', when indeed a contiguous range of 50 neurons from an unordered population was chosen <ref type="bibr" target="#b2">[3]</ref>.</p><p>Coordinate systems and topologies describe how individual neurons in a population can be addressed, or selected, and, where applicable, the spatial relationships between neurons. Authors should specify all coordinate systems used, because they are central to defining the connectivity of the network.</p><p>The most basic is the index coordinate system which numbers each neuron in the population. Index coordinates are often onedimensional, but if the populations are representing sheets or volumes of nervous tissue, index coordinates may become two-, three-, or even higher dimensional. Index coordinates are unordered, because they do not imply a neighborhood relation between any two neurons, nor do they define a distance function (e.g., Brunel <ref type="bibr" target="#b2">[3]</ref>).</p><p>Many models have additional coordinate systems, e.g., anatomical coordinates, if the coordinates within a population refer to positions in the brain, as in Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref>, or logical coordinates, if the coordinates within a population refer to some logical property, such as stimulus dimensions or response properties, e.g., orientation angle, as in Lumer et al. <ref type="bibr" target="#b9">[10]</ref>. Anatomical or logical coordinates impose a topology on the unordered population, because they allow one to measure distances between neurons.</p><p>For each coordinate system used, authors should state exactly how the coordinates are mapped to the index coordinates of the population. A good model description should also give explicit expressions for all distance functions used.</p><p>The description of the connectivity can now build on the defined populations and coordinate systems. To describe the connections we suggest using prose, equations and figure(s). Authors should start with an overview of the connectivity at the level of populations, followed by all information needed to link connectivity at the level of populations to the connections between individual neurons. The following checklist may assist authors in this task:</p><p>1. Are all populations of pre-and post-synaptic neurons defined? 2. Are all coordinate systems defined which are needed to select pre-and post-synaptic neurons? 3. How are pre-synaptic neurons selected from a population? 4. How are post-synaptic neurons selected from a population? 5. How are boundary effects in topological connections handled? 6. If a pair of pre-and post-synaptic neurons can be chosen more than once, is this connection allowed? 7. If the same neuron can be selected as pre-and post-synaptic neuron, is this connection allowed? 8. How are the parameters (e.g., weight and delay) of a connection determined? 9. If random connections are used, provide the algorithm used to select the pre-and post-synaptic neurons and to determine whether a connection is made. 10. Are all parameters of the connectivity explained and are their numerical values given?</p><p>A figure of the connections in addition to the textual description is of great help to the reader. Suggestions for how to draw connection diagrams are given below.</p><p>To describe the dynamics of neurons, synapses, and channels we suggest a combination of prose and equations. The text should give the overview, the equations the detail, since they are more exact.</p><p>It is important to describe how the neuron behaves over time. For spiking models, the description should encompass how the neuron behaves before, during and after a spike is generated, e.g., state the spike threshold, set the refractory period and define if there is a potential reset. Since this part of a neuron model is often algorithmic, pseudo-code or flow-charts may be an effective means of description. There should also be a description of the synapse type and its behavior, and the algorithms for the plasticity should be given.</p><p>Model input, output, and free parameters are important aspects of a model. Models in computational neuroscience mostly attempt to describe systems rather than phenomena. This is shown by the fact that none of the models we investigated explicitly states its input and output variables.</p><p>By contrast, models in statistics are built around the concepts of independent variables (stimulus), dependent variables (response), and the free parameters of a system. A model is then a function that maps the independent variables onto the dependent variables, using the free parameters. We find this view helpful, because it makes the scope of a model explicit.</p><p>We suggest that authors explicitly list the independent and dependent variables of their model, along with all free parameters. A textual description of the stimuli accompanied by tabulated parameter values will suffice in most cases to recreate the stimuli. In addition, readers will benefit from a figure illustrating nontrivial stimuli, such as Fig. <ref type="figure" target="#fig_2">1</ref> in Hayot and Tranchina <ref type="bibr" target="#b5">[6]</ref>. If the model uses complex stimuli, such as images or sound sequences, authors should make them available online, so that readers can reimplement the model. A good model description should also detail how responses are measured.</p><p>The following checklist may help authors to compile all information for the model description. Most of this information is best placed in the tables, suggested below.  Model validation is crucial to the reliability of modeling studies. Authors should provide information that will allow others to systematically test re-implementations of neuronal network models. To this end, they should include, e.g., membranepotential traces of model neurons in response to current injection and crafted spike trains.</p><p>These figures help readers who attempt to re-implement a network model to validate their implementation of the neuron models; Destexhe et al. <ref type="bibr" target="#b3">[4]</ref> and Izhikevich and Edelman <ref type="bibr" target="#b7">[8]</ref> are fine examples in this respect. Unless the model is new, such figures are best placed in the appendix. For models that are well known in the literature, these figures may be put in the supplementary material.</p><p>Testing that parts of a model behave as expected is an excellent way of reducing the chance of errors at a later stage, and is also known as unit testing <ref type="bibr" target="#b70">[71]</ref>. If performed in stages, unit testing ensures that all components at a given level function properly, such that any difficulties at the next level of integration can be localized to that level. Systems biologists are ahead of neuroscientists in this respect, and have addressed this issue through the development of the SBML Semantic Validation Suite <ref type="bibr" target="#b34">[35]</ref>.</p><p>Authors should specify the model implementation, i.e., list details of the tools and methods that were used to obtain numerical results. The information should be sufficient to allow readers to reimplement the model and its analysis.</p><p>The following list may assist authors in compiling the required information: 4. Consider making your analysis scripts available as supplementary material.</p><p>Templates for tables. To provide a full description of the network model, we encourage authors to detail each model part. Figures <ref type="figure" target="#fig_7">5,</ref><ref type="figure" target="#fig_9">7</ref>, and 8 illustrate how such detailed descriptions may be given in concise form. We invite readers to use these tables as templates for their own publications.</p><p>At present, it does not seem possible, or even desirable, to define precisely how these tables should be formed. Indeed, the reader will notice that we describe the connectivity in the Lumer et al. <ref type="bibr" target="#b9">[10]</ref> model in a rather different way than in the Brunel <ref type="bibr" target="#b2">[3]</ref> model. Lacking any widely adopted formalism for the description of connections, we could at present not see any other way of providing descriptions that were at the same time compact and informative. The connection set algebra recently proposed by Djurfeldt <ref type="bibr" target="#b71">[72]</ref> may eventually evolve into a common formalism for connectivity.</p><p>For now, we have set up our tables pragmatically as follows:</p><p>1. The first table shall always present a concise Model Summary based on the Checklist proposed above; one may compare it to the ''Nutrition facts'' box on food packaging. Non-applicable entries in the table shall be kept in the table to make explicit that a model does not have, e.g., topology or synaptic plasticity. 2. For each non-empty entry in the Model Summary, a table presenting details shall follow. 3. These detailed tables shall in themselves be concise and be presented in the same order as the entries in the Model Summary. 4. The tables shall contain the names (or symbols) used for populations, connections or other model elements in the modeling paper. 5. When model components have been obtained from a model repository, or have a precise definition in a relevant online ontology, accession numbers or ontology reference shall be given.</p><p>The tables proposed here describe the structure of the model. In addition, we propose that all parameters of a model should be given in tables to make them easily accessible; some authors do this already.</p><p>Guidelines for diagrams. Diagrams are a powerful way of expressing relations between parts of a model. Authors should use diagrams to illustrate their model structure and to specify relations between the different model parts. A good model description should use at least one diagram, showing the overall structure of the model. Further diagrams can then be given to elaborate on details and different aspects of the model.</p><p>Diagrams should be precise representations of a model and its parts. To this end, we must use the graphical vocabulary of shapes, lines and graphical styles to convey as much detail as possible without sacrificing clarity.</p><p>To achieve their full potential, diagrams need to follow a common standard, so that readers can perceive and compare diagrams from different publications. We have seen earlier that there are currently no established rules for drawing diagrams of neural network models. At this point, we give some tentative suggestions only, as sketched in Fig. <ref type="figure" target="#fig_8">6</ref>  We will return to the design of network diagrams in the discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Communicating neuronal network models in scientific publications is a challenging task. We have demonstrated above that current publication practices are far from ideal. This has two unfortunate consequences: First of all, it hampers the critical, mutual assessment of published models. As a result, there is no tradition in the computational neuroscience community for scientists to cross-examine each others models thoroughly. The validation of models thus typically remains at the level of individual studies and publications, i.e., not as reliable as is desirable. Other fields, in contrast, have established the validity of their central models beyond any reasonable doubt-and with a clear understanding of their limits of viability-such as the central laws of classical and quantum mechanics, electrodynamics and statistical physics. A second unfortunate consequence of present publication practices is that neuronal network models are rarely re-used by others, thus reducing the overall productivity of the computational neuroscience community. This second consequence follows to a large degree from the first, as few scientists would like to re-use models unless their validity was properly established; in addition, the lack of precision in today's model descriptions often makes re-use difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network diagrams</head><p>The model survey presented here revealed a wide variety of approaches to describing the composition and connectivity of neuronal networks. We believe that this is, at least in part, due to a lack of common high-level concepts for composition and connectivity from a modeling perspective. Developing such highlevel concepts describing, e.g., certain types of randomized connectivity patterns, is thus an important task for the computational neuroscience community. The challenge at hand is perhaps best clarified when trying to draw diagrams representing neuronal network models. Such diagrams have two aims: To give the reader an intuitive understanding of model properties central to the dynamics of the model, and to unambiguously provide the necessary detail to allow a reconstruction of a model. In the absence of a mathematical formalism for model specification, diagrams often seem better suited than prose to present unambiguous detail. Simple models, such as that by Brunel <ref type="bibr" target="#b2">[3]</ref>, can be depicted in a single diagram, as illustrated in Fig. <ref type="figure" target="#fig_8">6</ref>. The four panels in that figure, though, show that one may choose from a wide variety of styles for such diagrams, and it is not a priori clear which style is best. In panels A-C in the figure we propose three ways to differentiate between excitatory and inhibitory connections (line styles and endings) as well as to mark connectivity patterns (line endings, styles, annotations). Panel D differs from the other three in the way the external input is represented. Brunel <ref type="bibr" target="#b2">[3]</ref> states that ''[each neuron] receives C ext ~CE ½ connections from excitatory neurons outside the network. External synapses are activated by independent Poisson processes with rate n ext .'' This is rendered in detail in panel D, which shows C E Poisson generators per modeled neuron. In all other panels, these generators have been collapsed into an external excitatory population E ext with the implicit assumption that this population contains the correct number of Poisson generators required by the model.</p><p>Presenting complex models is even more challenging. In Fig. <ref type="figure" target="#fig_11">9</ref>, we present a set of three figures describing the model by Lumer et al. <ref type="bibr" target="#b9">[10]</ref> at three levels of hierarchy: an overall view in panel A, details of the connectivity within the cortical populations tuned to vertical stimuli in panel B, and finally details of projection patterns into a single cortical population in panel C. All figures are simplifications of the full model, since we have left out the secondary thalamic and cortical areas. We are currently pursuing research to identify drawing styles and a hierarchy of diagrams that will be intuitive to a majority of computational neuroscientists and provide the necessary detail. Results will be presented elsewhere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Why are standards lacking?</head><p>Given the importance of comprehensible and precise model descriptions, it may seem surprising that no standards or good practices have emerged in computational neuroscience to date. Early proposals, such as the Neural Simulation Language <ref type="bibr" target="#b72">[73]</ref> (see also <ref type="bibr">Eliasmith and Anderson [49,</ref><ref type="bibr">Ch. 1.5]</ref> and Kumar <ref type="bibr" target="#b73">[74]</ref>), have not been accepted widely in the community.</p><p>At present, two developments appear promising. NetworkML, which is part of the NeuroML project <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b50">51]</ref>, provides a simulator-agnostic XML-based declarative standard for neuron network model descriptions. Simulation code for tools such as Neuron and Genesis can be generated from models defined in NeuroML. PyNN <ref type="bibr" target="#b28">[29]</ref>, in contrast, is an imperative scripting language that can control a number of common neuronal network simulators, such as NEST, Neuron, and Brian. One reason why neither NetworkML nor PyNN has yet caught on as a means of widespread model exchange may be that neither of the two languages seems to aim at providing human-comprehensible model descriptions that might be included in publications.</p><p>Another reason for the lack of model description standards may be that computational neuroscience has to a large degree been an ancillary science, an appendix of electrophysiology: The vast majority of publications in computational neuroscience compares its modeling results directly to specific sets of experimental data. And even though models have driven the development in some fields of neuroscience <ref type="bibr" target="#b74">[75]</ref>, very few authors have compared the properties of different models with each other; Erwin et al. <ref type="bibr" target="#b75">[76]</ref> is a notable exception. De Schutter <ref type="bibr" target="#b76">[77]</ref> even argues that there currently is a trend away from the investigation of models as such, and back to a one-to-one matching of models to experiments. As long as computational neuroscientists focus on matching their models to specific experiments, rather than either to spar their models against each other, or build their models upon each other, the motivation to use a standard notation is obviously limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Perspectives</head><p>We have no doubt that model sharing will increase in computational neuroscience in years to come. This raises the question of what model sharing precisely entails. At the simplest level, models may be shared as simulator code. While this seems convenient at first, it carries significant risk, as any code is likely to contain errors, in particular errors that may surface only once an existing model is used in a different context than the one in which it was originally developed. Indeed, in at least one case, highprofile publications (outside neuroscience), had to be retracted after a subtle programming error was discovered in a widely shared scientific software <ref type="bibr" target="#b77">[78]</ref>. Some scientists argue that everyone in a field should use the same, carefully maintained simulation software to avoid such problems, and to make computational science reliable <ref type="bibr" target="#b78">[79]</ref>. We beg to differ: monoculture tends to create more problems than it solves.</p><p>Establishing a new publication culture in computational neuroscience will require considerable effort within the community. We hope that the good model description practice that we have outlined in the previous section may be a good starting point. We believe in particular that a clear segregation of model derivation, model description, implementation, and model analysis, as proposed above, will make it easier for readers to discern the model as such, compare it to other models, and evaluate its relevance to their own research. The proposed Checklists for model descriptions will help to ensure that model descriptions themselves are reasonably complete and follow a common pattern, further improving the communication of models, while the Templates for tables invite a standardized presentation of details on various aspects of models; similarly, the Guidelines for diagrams should aid authors in illustrating their network models. Since all our proposals are informal, we hope that authors will find it straightforward to apply them when describing their network models, thus establishing a de facto standard for model descriptions.</p><p>We are optimistic that we are beginning to see changes towards more cooperation within computational neuroscience, as witnessed by several collaborative reports on neuronal network simulations in the last two years <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref> and the development of tools for the integration of various simulation software <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, much helped by the establishment of the International Neuroinformatics Coordinating Facility (INCF) in 2005. The Connection Set Algebra proposed by Djurfeldt <ref type="bibr" target="#b71">[72]</ref> is an encouraging step towards establishing high-level concepts for neuronal network descriptions, i.e., giving us a concise language to talk about our models. There is also much to be learned from model sharing and curation efforts in other communities, such as the IUPS Physiome and the European Virtual physiological human projects <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b79">80]</ref>.</p><p>In closing, let us return to the power of notation, as exemplified by the matrix notation in the introduction. In July 1924, Werner Heisenberg gave a manuscript full of complicated mathematics to his mentor Max Born, unsure whether it was worth publishing. Born worked through Heisenberg's ideas and realized that what Heisenberg had written down, actually amounted to the matrix mechanics of quantum theory. This insight of Born's unleashed the full power of Heisenberg's ideas and let Born discover the noncommutativity of quantum mechanics <ref type="bibr">[81, p. 125f</ref>]. We are looking forward to the day when a good formalism will give us deeper insights into the secrets of signal processing in the brain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supporting Information</head><p>Table <ref type="table">S1</ref>: Network architecture description: placement and means.</p><p>Each table entry gives the number of papers from Table <ref type="table">1</ref> in main paper using a given means (columns) and location (rows) to describe the network architecture of the model used, with rowand column-wise totals to the right and at the bottom. Most papers combine several modes of description; the ''References''-column contains papers that do not give explicit descriptions, but point to published models. The network architecture description is an overview only, and details are left out. That is the reason for why columns ''Eqns'' and ''Tables'' are empty here. See Table <ref type="table">1</ref> in main paper for paper abbreviations. Found at: doi:10.1371/journal.pcbi.1000456.s001 (0.27 MB PDF)</p><p>Table <ref type="table">S2</ref>: Network connectivity description: placement and means.</p><p>The presentation is the same as in Table <ref type="table">S1</ref>. Found at: doi:10.1371/journal.pcbi.1000456.s002 (0.10 MB PDF)</p><p>Table <ref type="table" target="#tab_0">S3</ref>: Neuron and synapse model description: placement and means. The presentation is the same as in Table <ref type="table">S1</ref>. Found at: doi:10.1371/journal.pcbi.1000456.s003 (0.12 MB PDF)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Saam and Eckhorn<ref type="bibr" target="#b11">[12]</ref> SE Two-dimensional model of two layers of pulse-coding neurons.Tao et al. [13] TA Two-dimensional two-layer model of integrate-and-fire neurons with conductance based synapses. Troyer et al. [14] TR Two-dimensional network model with two populations of conductance-based integrate-and-fire neurons. Vogels and Abbott [15] VA Unordered and one-dimensional networks of integrate-and-fire neurons. Wielaard and Sajda [16] WS Two-dimensional two-layer model of integrate-and-fire neurons with conductance based synapses. The table gives a brief overview of the type of model studied and assigns an abbreviation to each paper for reference in other tables. doi:10.1371/journal.pcbi.1000456.t001</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Vogels and Abbott [15, Eq. 2] t dV dt ~(V rest {V )zg ex (E ex {V )zg inh (E inh {V ) The model by Destexhe et al. is a Hodgkin-Huxley style neuron, all others are integrate-and-fire neurons. doi:10.1371/journal.pcbi.1000456.t002</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Placement of description in papers surveyed. Bar graphs show the percentage of papers describing (from top to bottom) model architecture, model connectivity and neuronal dynamics in the body text of the paper, the appendix, and in supplementary material. Many papers spread descriptions over several locations and are thus counted in several categories. For detailed data, see supporting material Tables S1, S2 and S3. doi:10.1371/journal.pcbi.1000456.g001</figDesc><graphic coords="5,58.05,534.27,239.74,116.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Use of different means of description in papers surveyed. Bar graphs show the percentage of papers describing (from top to bottom) model architecture, model connectivity and neuronal dynamics using prose, equations, figures, tables, and references. Many papers combine several means for one purpose and are thus counted in several categories. For detailed data, see supporting material Tables S1, S2, S3. doi:10.1371/journal.pcbi.1000456.g002</figDesc><graphic coords="5,315.10,60.77,239.57,115.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Interpretation of Lumer [10] model architecture. The most parsimonious interpretation of the description of the primary visual cortical area Vp given by Lumer et al, is as two layers of 40640 topographic elements, representing horizontal and vertical orientations, respectively. doi:10.1371/journal.pcbi.1000456.g003</figDesc><graphic coords="6,58.05,376.50,350.53,318.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4</head><label>4</label><figDesc>shows network diagrams of a model loosely based on Einevoll and Plesser [63, Fig. 3], drawn in the style of three of the papers surveyed here. The diagram in the style of Hayot and Tranchina [6] (Fig. 4A) gives a reduced but clear overview of the overall architecture of the model; it provides no details. The style of Haeusler and Maass [5] (Fig. 4B) carries most information, with weights and probabilities shown next to connection lines, and line widths proportional to the product of weight and probability. Figure 4C, which imitates the style of Lumer et al. [10], is rather illustrative: it provides no quantitative information and the structure of the connectivity is less prominent than in the other two figures; on the other hand, it is the only figure hinting at the spatial structure of the network. Interestingly, all three diagram styles use different ways of marking excitatory and inhibitory connections: bars vs circles, black vs red, and arrows vs bars. Indeed, bars at the end of connection lines mark excitatory connections in Hayot and Tranchina's style, but inhibitory connections in the style of Lumer et al, nicely illustrating the lack of standards in the field.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Diagram styles for network models. Diagrams of a model of the thalamocortical pathway drawn using diagram styles from (A) Hayot and Tranchina [6, Fig. 2], (B) Haeusler and Maass [5, Fig. 1], and (C) Lumer et al. [10, Fig. 1]. Numbers on arrows in B mark connection weight and probability of connection, while line width represents the product of the two. In C, open circles show excitatory, filled circles inhibitory neurons. The model depicted is loosely based on Einevoll and Plesser [63, Fig. 3], but the differentiation into two cortical layers, each with excitatory and inhibitory subpopulations, in B and C, as well as the connection weights and probabilities, have been added here for the purpose of illustration. doi:10.1371/journal.pcbi.1000456.g004</figDesc><graphic coords="8,58.05,60.77,496.46,224.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Tabular description of Brunel model [3]. The model is summarized in panel A and detailed in panels B-F. doi:10.1371/journal.pcbi.1000456.g005</figDesc><graphic coords="9,58.05,183.06,403.00,521.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Alternatives for diagrams of simple network models (Brunel [10]). (A) Excitatory connections shown by full lines, inhibitory by dashed lines. Lines beginning with open semicircle and ending in filled circle indicate random convergent connections. (B) Double lines represent multiple connections, solid/dashed marks excitatory/inhibitory connections. Multiplicity of connections marked at line ends. (C) Same as B, but inhibitory connections marked with circles on target side instead of dashed lines. (D) Same as C, but displaying explicitly that there are C E external Poisson inputs (PG) to each neuron, and single lines are used instead of double lines. doi:10.1371/journal.pcbi.1000456.g006</figDesc><graphic coords="10,58.05,59.30,362.98,279.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Tabular description of Lumer et al. model [10], part 1. The model is summarized in panel A and detailed in panels B-I. See Figure 8 for panels E-I. doi:10.1371/journal.pcbi.1000456.g007</figDesc><graphic coords="11,58.05,60.77,403.00,502.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Tabular description Lumer et al. model [10], part 2. See Figure 7 for panels A-D. doi:10.1371/journal.pcbi.1000456.g008</figDesc><graphic coords="12,58.05,60.77,403.00,389.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Hierarchy of diagrams of a complex network model (Lumer et al. [10]). (A) Overview diagram of connectivity between high-level populations. Excitatory connections are marked by arrows, inhibitory connections by circles. Excitatory and inhibitory populations have been lumped in Tp, while Vp(v) and Vp(h) are composed of three layers of excitatory and inhibitory populations, as detailed in B. (B) Detailed diagram of connectivity within cortical population Vp(v), which is tuned to vertically oriented stimuli. Vp(v) is composed of three cortical layers, each with an excitatory (left) and inhibitory (right) subpopulation. Filled arrows mark excitatory, open circles inhibitory connections. Connections to and from corresponding horizontally tuned cortical populations in Vp(h) are shown as dashed lines; black lines show input from the thalamus. Connections to and from higher cortical areas are not shown. (C) Detailed rendition of connection masks and kernels projecting onto one cortical subpopulation Vp(v)LI(e) from panel B, i.e., the excitatory subpopulation of the infragranular layer of Vp(v). Squares show projection masks, gray shade the probability of a connection (black: p~1). Connections are created by centering the mask about each location in the layer and drawing connections according to the probability distribution. Outgoing arrows indicate projections to other populations. Projection masks are scaled down in size to fit all projections into the layer, and grayscales have been adjusted for visibility. Connections are placed to correspond to the layout of panel B: Connections to and from thalamus are at the bottom, connections to and from Vp(v)LI(i) and Vp(h) to the right and connections to and from Vp(v)LS and Vp(v)L4 at the top. doi:10.1371/journal.pcbi.1000456.g009</figDesc><graphic coords="13,58.05,60.77,496.46,182.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>1 .</head><label>1</label><figDesc>Model input (a) Describe the stimulus ensemble; (b) Describe which parts of the model are stimulated; (c) Describe exactly how the stimulus is applied; (d) Describe any scaling or normalization of the stimulus. 2. Model output (a) Describe which quantities are measured; (b) Describe exactly from which parts of the model measurements are taken; (c) Describe exactly how measurements are taken (e.g., specify the sampling rate of the measurements); (d) Describe how output quantities are computed from the measurements (e.g., firing rates from spike-trains).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>3 .</head><label>3</label><figDesc>Free parameters (a) Describe all free parameters of the model; (b) List the chosen values for each parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>1 . 2 .</head><label>12</label><figDesc>Which software was used to analyze the model? (a) If third party software was used, list the name, version, and provider of the software. (b) If self-written software was used, provide sufficient information on the algorithms and numerical methods used, to allow re-implementation. (c) Consider making the simulation program/scripts available as supplementary material. Which parameters, such as integration stepsize and accuracy goals, were used? 3. Which software was used to analyze and visualize the data obtained from the model? (a) If third party software was used, list the name, version, and provider of the software. (b) If self-written software was used, provide sufficient information on the algorithms and numerical methods used, to allow re-implementation. (c) Consider making the simulation program/scripts available as supplementary material.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>(Brunel [3]  model) and Fig. 9 (Lumer et al. [10] model). These figures are based on the following principles: 1. Unordered populations are shown as circles; 2. Populations with spatial structure are shown as rectangles; 3. Pointed arrowheads represent excitatory, round ones inhibitory connections; 4. Arrows beginning/ending outside a population indicate that the arrows represent a set of connections with source/target neurons selected from the population; 5. Probabilistic connection patterns are shown as cut-off masks filled with connection probability as grayscale gradient; the pertaining arrows end on the outside of the mask.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3 .</head><label>3</label><figDesc>Presentation of parameters. find out whether problems arise from neuron model implementations or from a wrong network setup.We will now analyze in detail which difficulties arise in describing a network model, considering in turn network architecture, connectivity, and neuron models, and point out examples of good descriptions.</figDesc><table><row><cell>All</cell><cell>Most</cell><cell>Some</cell><cell>None</cell></row></table><note><p><p><p><p><p>-IE, KG, L, SE HM B, D, HT, HvH, M, TA, TR, VA, WS</p>The table shows the papers presenting all, most, some or none of their parameters in tables. See Table</p>1</p>for paper abbreviations. doi:10.1371/journal.pcbi.1000456.t003</p>be able to</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>August 2009 | Volume 5 | Issue 8 | e1000456</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>PLoS Computational Biology | www.ploscompbiol.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Markus Diesmann and Sven Schrader as well as three anonymous reviewers for stimulating feedback on earlier versions of the manuscript and Kittel Austvoll for help in preparing figures. We are grateful to Mikael Djurfeldt for sharing his Connection Set Algebra manuscript with us prior to publication, and to our colleagues at A ˚s for feedback on table and figure design.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>EN and HEP are grateful to Honda Research Institute Europe GmbH and to the Research Council of Norway (Grant 178892/V30 eNeuro) for financial support. Honda Research Institute Europe participated in this research through the co-authorship of M-OG. The Norwegian University of Life Sciences, the Honda Research Institute Europe GmbH and the Research Council of Norway had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>will find it easier to comprehend and re-implement a model, and to compare different models.</p><p>Guidelines for organization. Many journals require authors to organize their manuscript into the sections Introduction, Results, Methods, and Discussion and the question arises how modeling papers fit into this framework. We believe that this organization is also appropriate for modeling papers if the meaning of the individual section headings are carefully observed.</p><p>Generally, a publication on a computational modeling study should provide the following information:</p><p>1. Hypothesis: a concrete description of the question or problem that the model addresses; 2. Model derivation: a presentation of experimental data that support your hypothesis, your model, or both; 3. Model description: a description of your model, its inputs (stimuli), and its outputs (measured quantities) and all free parameters, according to the good practice proposed below; 4. Implementation: a concise description of the methods used to implement and simulate the model (e.g., details of spike threshold detection, assignment of spike times, time resolution, etc.), as well as a description of all third party tools used, such as simulation software or mathematical packages; 5. Model analysis: a description of all analytical and numerical experiments performed on the model, and the results obtained; 6. Model justification: a presentation of all empirical or theoretical results from the literature that support the results obtained from your model and that were not used to derive the model.</p><p>We suggest that authors organize their presentation according to these six points where possible. When publishing in a journal that requires a traditional organization of manuscripts into Introduction, Results, Methods, and Discussion, we recommend the following structure:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>Wrote the paper: EN M-OG HEP. Conceived the idea and approach: EN M-OG HEP. Performed the literature search: M-OG HEP. Analyzed the data: EN.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The science of scientific writing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Gopen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Swan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Scientist</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="550" to="558" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exact digital simulation of time-invariant linear systems with applications to neuronal modeling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rotter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diesmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol Cybern</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="381" to="402" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brunel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="183" to="208" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ionic mechanisms underlying synchronized oscillations and propagating waves in a model of ferret thalamic slices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Destexhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="2049" to="2070" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A statistical analysis of information-processing properties of laminaspecific cortical microcircuit models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haeusler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb Cortex</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="149" to="162" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling corticofugal feedback and the sensitivity of lateral geniculate neurons to orientation discontinuity</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hayot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tranchina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis Neurosci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="865" to="877" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spatiotemporal adaptation through corticothalamic loops: A hypothesis</title>
		<author>
			<persName><forename type="first">U</forename><surname>Hillenbrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Van Hemmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="107" to="118" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large-scale model of mammalian thalamocortical systems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Izhikevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Edelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci U S A</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="3593" to="3598" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A model of cortically induced synchronization in the lateral geniculate nucleus of the cat: a role for low-threshold calcium channels</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Kirkland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Gerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2007" to="2022" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural dynamics in a model of the thalamocortical system. I. Layers, loops and the emergence of fast synchronous rhythms</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Lumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb Cortex</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="207" to="227" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Invariant computations in local cortical networks with balanced excitation and inhibition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Marin ˜o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schummers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Lyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schwabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Beck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="194" to="201" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lateral spike conduction velocity in the visual cortex affects spatial range of synchronization and receptive field size without visual experience: a learning model with spiking neurons</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eckhorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol Cybern</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="1" to="L9" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An egalitarian network model for the emergence of simple and complex cells in visual cortex</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="366" to="371" />
			<date type="published" when="2004">2004</date>
			<pubPlace>U S A</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Contrast-invariant orientation tuning in cat visual cortex: thalamocortical input tuning and correlation-based intracortical connectivity</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Troyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Krukowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Priebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="5908" to="5927" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Signal propagation and logic gating in networks of integrate-and-fire neurons</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Vogels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="10786" to="10795" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dependence of response properties on sparse connectivity in a spiking neuron model of the lateral geniculate nucleus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wielaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sajda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="3292" to="3308" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sharing Publication-Related Data and Material: Responsibilities of Authorship in the Life Sciences</title>
		<ptr target="http://www.nap.edu/catalog.php?recordid=10613" />
	</analytic>
	<monogr>
		<title level="j">Biological Sciences</title>
		<imprint>
			<date type="published" when="2003-06">2003. June 2009</date>
			<publisher>The National Academies Press</publisher>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Science publishing. The UPSIDE of good behavior: make your data freely available</title>
		<author>
			<persName><forename type="first">E</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page">990</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<ptr target="http://www.ploscompbiol.org/static/policies.action" />
		<title level="m">PLoS Computational Biology Editorial and Publishing Policies</title>
		<imprint>
			<publisher>Public Library of Science</publisher>
			<date type="published" when="2009-01">2009. January 2009</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Value added by data sharing: long-term potentiation of neuroscience research. A commentary on the 2007 SfN Satellite Symposium on data sharing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Ascoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="143" to="145" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data sharing for computational neuroscience</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Teeters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Millman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Sommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="47" to="55" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Domain-specific data sharing in neuroscience: what do we have to learn from each other?</title>
		<author>
			<persName><forename type="first">Jdv</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ball</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="117" to="121" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The neuroscience information framework: a data and knowledge environment for neuroscience</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Akil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Ascoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="149" to="160" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Computational neuroscience</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Churchland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">241</biblScope>
			<biblScope unit="page" from="1299" to="1306" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Interoperability of neuroscience modeling software: Current status and future directions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Cannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Gewaltig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gleeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S</forename><surname>Bhalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cornelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="127" to="138" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">1st INCF workshop on large-scale modeling of the nervous system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Djurfeldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lansner</surname></persName>
		</author>
		<idno type="DOI">10.1038/npre.2007.262.1</idno>
		<ptr target="http://dx.doi.org/10.1038/npre.2007.262.1" />
	</analytic>
	<monogr>
		<title level="j">Nature Precedings</title>
		<imprint>
			<date type="published" when="2007-06">2007. June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simulation of networks of spiking neurons: A review of tools and strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Carnevale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Beeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Neurosci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="349" to="398" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interoperable model components for biologically realistic single neuron and network models implemented in NeuroML</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gleeson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Silver</surname></persName>
		</author>
		<ptr target="http://frontiersin.org/conferences/" />
	</analytic>
	<monogr>
		<title level="m">individual abstract listing. php?conferid = 2&amp;pap = 491&amp;ind abs = 1&amp;pg = 5</title>
		<meeting><address><addrLine>Stockholm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06-30">2008. 2008. 30 June 2009</date>
		</imprint>
	</monogr>
	<note>Frontiers in Neuroinformatics. Conference Abstract: Neuroinformatics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PyNN: a common interface for neuronal network simulators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bru ¨derle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eppler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kremkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Neuroinform</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">MUSIC-multisimulation coordinator: Request for comments</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">¨</forename><surname>Ekeberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Djurfeldt</surname></persName>
		</author>
		<idno type="DOI">10.1038/npre.2008.1830.1</idno>
		<ptr target="http://dx.doi.org/10.1038/npre.2008.1830.1" />
	</analytic>
	<monogr>
		<title level="j">Nature Preceedings</title>
		<imprint>
			<date type="published" when="2008-06">2008. June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simulation as experiment: a philosophical reassessment for biological modeling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Peck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TRENDS in Ecology and Evolution</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="530" to="534" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A methodology for developing simulation models of complex systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Aumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="385" to="396" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A calculus of purpose</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Lander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">164</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Biological systems from an engineer&apos;s point of view</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Software infrastructure for effective communication and reuse of computational models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Finney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hucka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Bornstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Keating</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">System Modeling in Cellular Biology: From Concepts to Nuts and Bolts</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Szallasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Stelling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Periwal</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="355" to="378" />
		</imprint>
	</monogr>
	<note>chapter 17</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Facilitating modularity and reuse: Guidelines for structuring CellML 1.1 models by isolating common biophysical concepts</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wimalaratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mdb</forename><surname>Halstead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Cooling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Crampin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp Physiol</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="472" to="485" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A physiome standards-based model publication paradigm</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Nickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Buist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos Transact A Math Phys Eng Sci</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="1823" to="1844" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Why are computational neuroscience and systems biology so separate?</title>
		<author>
			<persName><forename type="first">De</forename><surname>Schutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">78</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Models in science</title>
		<author>
			<persName><forename type="first">R</forename><surname>Frigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hartmann</surname></persName>
		</author>
		<ptr target="http://plato.stanford.edu/archives/fall2008/entries/models-science/" />
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Zalta</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2008-06">2008. June 2009</date>
		</imprint>
		<respStmt>
			<orgName>Metaphysics Research Lab, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The world as a process: Simulations in the natural and social sciences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hartmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simulation and Modelling in the Social Sciences from the Philosophy of Science Point of View. Dordrecht: Kluwer, Theory and Decision Library</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Hegselmann</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="77" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Simulated experiments: Methodology for a virtual world</title>
		<author>
			<persName><forename type="first">E</forename><surname>Winsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="105" to="125" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Computersimulationen: Modellierungen 2. Ordnung</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ku ¨ppers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lenhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal for General Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="305" to="329" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Catalyzing Inquiry at the Interface of Computing and Biology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Wooley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.nap.edu/catalog/11480.html" />
		<imprint>
			<date type="published" when="2005-06">2005. June 2009</date>
			<publisher>The National Academies Press</publisher>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Philosophical issues in brain theory and connectionism</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eliasmith</surname></persName>
		</author>
		<editor>Arbib M</editor>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="886" to="888" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>Handbook of Brain Theory and Neural Networks. Second edition</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Computational templates, neural network dynamics, and symbolic logic</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lappi</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2007.4371133</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Neural Networks IJCNN 2007. pp 1226-1230</title>
		<meeting>International Joint Conference on Neural Networks IJCNN 2007. pp 1226-1230</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Self-organizing maps as traveling computational templates</title>
		<author>
			<persName><forename type="first">T</forename><surname>Knuuttila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rusanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Honkela</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2007.4371134</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Neural Networks IJCNN 2007. pp 1231-1236</title>
		<meeting>International Joint Conference on Neural Networks IJCNN 2007. pp 1231-1236</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural network templates and their interpretation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rusanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ylikoski</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2007.4371382</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Neural Networks IJCNN 2007</title>
		<meeting>International Joint Conference on Neural Networks IJCNN 2007</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2683" to="2688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Extending Ourselves: Computational Science, Empiricism, and Scientific Method</title>
		<author>
			<persName><forename type="first">P</forename><surname>Humphreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Eliasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<title level="m">Neural Engineering: Computation, Representation, and Dynamics in Neurobiological Systems</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">ModelDB: A database to support computational neuroscience</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Morse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Migliore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Carnevale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Shepherd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="7" to="11" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Towards NeuroML: model description methods for collaborative modelling in neuroscience</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Goddard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hucka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos Trans R Soc Lond B Biol Sci</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="page" from="1209" to="1228" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Validation of simulation: Patterns in the social and natural sciences</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ku ¨ppers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lenhard</surname></persName>
		</author>
		<ptr target="http://jasss.soc.surrey.ac.uk/8/4/3.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Societies and Social Simulation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2005-06">2005. June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A History of Mathematical Notations: Two Volumes Bound as One</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cajori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Dover Publications</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">History of mathematical notation</title>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/" />
	</analytic>
	<monogr>
		<title level="m">History of mathematical notation -Wikipedia, the free encyclopedia</title>
		<imprint>
			<date type="published" when="2008-10-20">2008. 20 October 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A symbolic analysis of relay and switching circuits</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1940">1940</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology. Dept. of Electrical Engineering</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Circuit diagrams for biological networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Aladjem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol Syst Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Using process diagrams for the graphical representation of biological networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kitano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Funahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Biotechnol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="961" to="966" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Molecular interaction maps of bioregulatory networks: a general rubric for systems biology</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Aladjem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pommier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol Biol Cell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Depicting signaling cascades</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Blinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Faeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Hlavacek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Biotechnol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="137" to="138" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Correlations and population dynamics in cortical networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kriener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tetzlaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aertsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diesmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rotter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2185" to="2226" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Data-driven structure representation for large-scale models of layered cortical networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Potjans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diesmann</surname></persName>
		</author>
		<idno type="DOI">10.3389/conf.neuro.11.2008.01.087</idno>
		<ptr target="http://frontiersin.org/conferences/" />
	</analytic>
	<monogr>
		<title level="m">individual abstract listing.php?conferid = 2&amp;pap = 407&amp;ind abs = 1&amp;pg = 7</title>
		<imprint>
			<date type="published" when="2008-06-30">2008. 2008. 30 June 2009</date>
		</imprint>
	</monogr>
	<note>Frontiers in Neuroinformatics. Conference Abstract: Neuroinformatics</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Efficient probabilistic wiring of spatial neuronal network using walker&apos;s alias method</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Plesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Austvoll</surname></persName>
		</author>
		<ptr target="http://www.nwg-goettingen.de/2009/upload/abstractspdf/T26-1C.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Go ¨ttingen Meeting of the German Neuroscience Society. Neurowissenschaftliche Gesellschaft. pp 1277 (T26-1C</title>
		<meeting>the Eighth Go ¨ttingen Meeting of the German Neuroscience Society. Neurowissenschaftliche Gesellschaft. pp 1277 (T26-1C</meeting>
		<imprint>
			<date type="published" when="2009-06-30">2009. 30 June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Linear mechanistic models for the dorsal lateral geniculate nucleus of cat probed using drifting grating stimuli</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Einevoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Plesser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network-Comp Neural</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="503" to="530" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">On numerical simulations of integrate-and-fire neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hansel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Neltner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="467" to="483" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Exact subthreshold integration with continuous spike times in discrete time neural network simulations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Straube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Plesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diesmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="47" to="79" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Lectures in Supercomputational Neuroscience: Dynamics in Complex Brain Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diesmann</surname></persName>
		</author>
		<editor>Beim Graben P, Zhou C, Thiel M, Kuhrts J</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="267" to="278" />
			<pubPlace>Berlin und Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>Maintaining causality in discrete time neuronal network simulations. chapter 10</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The legal framework for reproducible scientific research: Licensing and copyright</title>
		<author>
			<persName><forename type="first">V</forename><surname>Stodden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="35" to="40" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The CellML model repository</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2122" to="2123" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Minimum information requested in the annotation of biochemical models (MIRIAM)</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Nove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">`</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Finney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hucka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S</forename><surname>Campagne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Biotechnol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1509" to="1515" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">BioModels Database: a free, centralized database of curated, published, quantitative kinetic models of biochemical and cellular systems</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Nove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">`</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bornstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Broicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courtot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Donizelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="689" to="D691" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Unit Test Frameworks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hamill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
			<pubPlace>Sebastopol, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">The connection-set algebra-a novel formalism for the representation of connectivity structure in neuronal network models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Djurfeldt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">The Neural Simulation Language: A System for Brain Modeling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Weitzenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Arbib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A neural net compiler system for hierarchical organization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="26" to="36" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Contributions of theoretical modeling to the understanding of neural map development</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Goodhill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="301" to="311" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Models of orientation and ocular dominance columns in the visual cortex: A critical comparison</title>
		<author>
			<persName><forename type="first">E</forename><surname>Erwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schulten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="425" to="468" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Reviewing multi-disciplinary papers: a challenge in neuroscience?</title>
		<author>
			<persName><forename type="first">De</forename><surname>Schutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="253" to="255" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Scientific publishing. a scientist&apos;s nightmare: software problem leads to five retractions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">314</biblScope>
			<biblScope unit="page" from="1856" to="1857" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">15 years of reproducible research in computational harmonic analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">U</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stodden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="8" to="18" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Britten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Cooling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mdb</forename><surname>Halstead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CellML metadata standards, associated tools and repositories</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="1845" to="1867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">The End of the Certain World: The Life and Science of Max Born</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Greenspan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
